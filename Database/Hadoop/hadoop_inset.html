<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Hadoop安装配置 - UBeaRLy</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Hadoop安装配置"><meta property="og:type" content="blog"><meta property="og:title" content="Hadoop安装配置"><meta property="og:url" content="https://xyy15926.github.io/Database/Hadoop/hadoop_inset.html"><meta property="og:site_name" content="UBeaRLy"><meta property="og:description" content="Hadoop安装配置"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:published_time" content="2019-03-21T09:27:37.000Z"><meta property="article:modified_time" content="2019-02-17T03:57:08.000Z"><meta property="article:author" content="UBeaRLy"><meta property="article:tag" content="Database"><meta property="article:tag" content="Hadoop"><meta property="article:tag" content="Installment"><meta property="article:tag" content="Setting"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io/Database/Hadoop/hadoop_inset.html"},"headline":"Hadoop安装配置","image":["https://xyy15926.github.io/img/og_image.png"],"datePublished":"2019-03-21T09:27:37.000Z","dateModified":"2019-02-17T03:57:08.000Z","author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"UBeaRLy","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":"Hadoop安装配置"}</script><link rel="canonical" href="https://xyy15926.github.io/Database/Hadoop/hadoop_inset.html"><link rel="alternate" href="/atom.xml" title="UBeaRLy" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="follow_it-verification-code" content="SVBypAPPHxjjr7Y4hHfn"><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-21T09:27:37.000Z" title="3/21/2019, 5:27:37 PM">2019-03-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-02-17T03:57:08.000Z" title="2/17/2019, 11:57:08 AM">2019-02-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Database/">Database</a><span> / </span><a class="link-muted" href="/categories/Database/Hadoop/">Hadoop</a></span><span class="level-item">an hour read (About 7085 words)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><h1 class="title is-3 is-size-4-mobile">Hadoop安装配置</h1><div class="content"><h2 id="Hadoop安装"><a href="#Hadoop安装" class="headerlink" title="Hadoop安装"></a>Hadoop安装</h2><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li><p>Java</p>
<ul>
<li>具体版本<a target="_blank" rel="noopener" href="http://wiki.apache.org/hadoop/HadoopJavaVersions">http://wiki.apache.org/hadoop/HadoopJavaVersions</a></li>
<li>需要配置好java环境（<code>~/.bashrc</code>）</li>
</ul>
</li>
<li><p>ssh：必须安装且保证sshd一直运行，以便使用hadoop脚本管理
远端hadoop守护进程</p>
<ul>
<li>pdsh：建议安装获得更好的ssh资源管理</li>
<li>要设置免密登陆</li>
</ul>
</li>
</ul>
<h3 id="机器环境配置"><a href="#机器环境配置" class="headerlink" title="机器环境配置"></a>机器环境配置</h3><h4 id="bashrc"><a href="#bashrc" class="headerlink" title="~/.bashrc"></a><code>~/.bashrc</code></h4><p>这里所有的设置都只是设置环境变量</p>
<ul>
<li><p>所以这里所有环境变量都可以放在<code>hadoop-env.sh</code>中</p>
</li>
<li><p>放在<code>.bashrc</code>中不是基于用户隔离的考虑</p>
<ul>
<li>因为hadoop中配置信息大部分放在<code>.xml</code>，放在这里无法
实现用户隔离</li>
<li>更多的考虑是给hive等依赖hadoop的应用提供hadoop配置</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_PREFIX=/opt/hadoop</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 自定义部分</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 此处是直接解压放在`/opt`目录下</span></span><br><span class="line">export HADOOP_HOME=$HADOOP_PREFIX</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_PREFIX</span><br><span class="line"><span class="meta">	#</span><span class="bash"> hadoop common</span></span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_PREFIX</span><br><span class="line"><span class="meta">	#</span><span class="bash"> hdfs</span></span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_PREFIX</span><br><span class="line"><span class="meta">	#</span><span class="bash"> mapreduce</span></span><br><span class="line">export HADOOP_YARN_HOME=$HADOOP_PREFIX</span><br><span class="line"><span class="meta">	#</span><span class="bash"> YARN</span></span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop</span><br><span class="line"></span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.library.path=$HADOOP_COMMON_LIB_NATIVE_DIR&quot;</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这里`-Djava`间不能有空格</span></span><br><span class="line"></span><br><span class="line">export CLASSPATH=$CLASS_PATH:$HADOOP_PREFIX/lib/*</span><br><span class="line">export PATH=$PATH:$HADOOP_PREFIX/sbin:$HADOOP_PREFIX/bin</span><br></pre></td></tr></table></figure>
<h4 id="etc-hosts"><a href="#etc-hosts" class="headerlink" title="/etc/hosts"></a><code>/etc/hosts</code></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">192.168.31.129 hd-master</span><br><span class="line">192.168.31.130 hd-slave1</span><br><span class="line">192.168.31.131 hd-slave2</span><br><span class="line">127.0.0.1 localhost</span><br></pre></td></tr></table></figure>
<ul>
<li>这里配置的ip地址是各个主机的ip，需要自行配置</li>
<li><code>hd-master</code>、<code>hd-slave1</code>等就是主机ip-主机名映射</li>
<li><h1 id="todo-一定需要在-etc-hostname中设置各个主机名称"><a href="#todo-一定需要在-etc-hostname中设置各个主机名称" class="headerlink" title="todo?一定需要在/etc/hostname中设置各个主机名称"></a>todo?一定需要在<code>/etc/hostname</code>中设置各个主机名称</h1></li>
</ul>
<h4 id="firewalld"><a href="#firewalld" class="headerlink" title="firewalld"></a><code>firewalld</code></h4><p>必须关闭所有节点的防火墙</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl stop firewalld.service</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl <span class="built_in">disable</span> firewalld.service</span></span><br></pre></td></tr></table></figure>
<h4 id="文件夹建立"><a href="#文件夹建立" class="headerlink" title="文件夹建立"></a>文件夹建立</h4><ul>
<li>所有节点都需要建立</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir tmp</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir -p hdfs/data hdfs/name</span></span><br></pre></td></tr></table></figure>
<h3 id="Hadoop配置"><a href="#Hadoop配置" class="headerlink" title="Hadoop配置"></a>Hadoop配置</h3><p>Hadoop<strong>全系列</strong>（包括hive、tez等）配置取决于以下两类配置文件</p>
<ul>
<li><p>只读默认配置文件</p>
<ul>
<li><code>core-defualt.xml</code></li>
<li><code>hdfs-default.xml</code></li>
<li><code>mapred-default.xml</code></li>
</ul>
</li>
<li><p>随站点变化的配置文件</p>
<ul>
<li><code>etc/hadoop/core-site.xml</code></li>
<li><code>etc/hadoop/hdfs-site.xml</code></li>
<li><code>etc/hadoop/mapred-site.xml</code></li>
<li><code>etc/hadoop/yarn-env.xml</code></li>
</ul>
</li>
<li><p>环境设置文件：设置随站点变化的值，从而控制<code>bin/</code>中的
hadoop脚本行为</p>
<ul>
<li><code>etc/hadoop/hadoop-env.sh</code>、</li>
<li><code>etc/hadoop/yarn-env.sh</code></li>
<li><code>etc/hadoop/mapred-env.sh</code></li>
</ul>
<p>中一般是环境变量配置，<strong>补充</strong>在shell中未设置的环境变量</p>
</li>
<li><p>注意</p>
<ul>
<li><p><code>.xml</code>配置信息可在不同应用的配置文件中<strong>继承</strong>使用，
如在tez的配置中可以使用<code>core-site.xml</code>中
<code>$&#123;fs.defaultFS&#125;</code>变量</p>
</li>
<li><p>应用会读取/执行相应的<code>*_CONF_DIR</code>目录下所有
<code>.xml</code>/<code>.sh</code>文件，所以理论上可以在<code>etc/hadoop</code>中存放
所以配置文件，因为hadoop是最底层应用，在其他所有应用
启动前把环境均已设置完毕？？？</p>
</li>
</ul>
</li>
</ul>
<p>Hadoop集群有三种运行模式</p>
<ul>
<li>Standalone Operation</li>
<li>Pseudo-Distributed Operation</li>
<li>Fully-Distributed Operation</li>
</ul>
<p>针对不同的运行模式有，hadoop有三种不同的配置方式</p>
<h4 id="Standalone-Operation"><a href="#Standalone-Operation" class="headerlink" title="Standalone Operation"></a>Standalone Operation</h4><p>hadoop被配置为以非分布模式运行的一个独立Java进程，对调试有
帮助</p>
<ul>
<li>默认为单机模式，无需配置</li>
</ul>
<h5 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /path/to/hadoop</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir input</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp etc/hadoop/*.xml input</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar grep input output <span class="string">&#x27;dfs[a-z.]+&#x27;</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat output/*</span></span><br></pre></td></tr></table></figure>
<h4 id="Pseudo-Distributed-Operation"><a href="#Pseudo-Distributed-Operation" class="headerlink" title="Pseudo-Distributed Operation"></a>Pseudo-Distributed Operation</h4><p>在单节点（服务器）上以所谓的伪分布式模式运行，此时每个Hadoop
守护进程作为独立的Java进程运行</p>
<h5 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a><code>core-site.xml</code></h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a><code>hdfs-site.xml</code></h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a><code>mapred-site.xml</code></h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configruration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">preperty</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configruation</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a><code>yarn-site.xml</code></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h4 id="Fully-Distributed-Operation"><a href="#Fully-Distributed-Operation" class="headerlink" title="Fully-Distributed Operation"></a>Fully-Distributed Operation</h4><ul>
<li><strong>单节点配置完hadoop之后，需要将其同步到其余节点</strong></li>
</ul>
<h5 id="core-site-xml-1"><a href="#core-site-xml-1" class="headerlink" title="core-site.xml"></a><code>core-site.xml</code></h5><p>模板：<code>core-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hd-master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>namenode address<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///opt/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>131702<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 为将用户`root`设置为超级代理，代理所有用户，如果是其他用户需要相应的将root修改为其用户名 --&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 是为hive的JDBCServer远程访问而设置，应该有其他情况也需要 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="hdfs-site-xml-1"><a href="#hdfs-site-xml-1" class="headerlink" title="hdfs-site.xml"></a><code>hdfs-site.xml</code></h5><p>模板：<code>hdfs-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///opt/hadoop/hdfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>namenode data directory<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///opt/hadoop/hdfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>datanode data directory<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>replication number<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.directoryscan.throttle.limit.ms.per.sec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>1000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--bug--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="yarn-site-xml-1"><a href="#yarn-site-xml-1" class="headerlink" title="yarn-site.xml"></a><code>yarn-site.xml</code></h5><ul>
<li>模板：<code>yarn-site.xml</code></li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master:9032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master:9030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master:9031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master:9033<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master:9099<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- container --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>maximum memory allocation per container<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>256<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>minimum memory allocation per container<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- container --&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- node --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>maximium memory allocation per node<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>virtual memmory ratio<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- node --&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.resource.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>384<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.command-opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>-Xms128m -Xmx256m<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="mapred-site-xml-1"><a href="#mapred-site-xml-1" class="headerlink" title="mapred-site.xml"></a><code>mapred-site.xml</code></h5><ul>
<li>模板：<code>mapred-site.xml.template</code></li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">		&lt;value&gt;yarn-tez&lt;/value&gt;</span></span><br><span class="line"><span class="comment">		设置整个hadoop运行在Tez上，需要配置好Tez</span></span><br><span class="line"><span class="comment">		--&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- mapreduce --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>256<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>memory allocation for map task, which should between minimum container and maximum<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>256<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>memory allocation for reduce task, which should between minimum container and maximum<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- mapreduce --&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- java heap size options --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>-Xms128m -Xmx256m<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>-Xms128m -Xmx256m<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- java heap size options --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h5><ul>
<li><p><code>yarn.scheduler.minimum-allocation-mb</code>：container内存
单位，也是container分配的内存最小值</p>
</li>
<li><p><code>yarn.scheduler.maximum-allocation-mb</code>：container内存
最大值，应该为最小值整数倍</p>
</li>
<li><p><code>mapreduce.map.memeory.mb</code>：map task的内存分配</p>
<ul>
<li>hadoop2x中mapreduce构建于YARN之上，资源由YARN统一管理</li>
<li>所以maptask任务的内存应设置container最小值、最大值间</li>
<li>否则分配一个单位，即最小值container</li>
</ul>
</li>
<li><p><code>mapreduce.reduce.memeory.mb</code>：reduce task的内存分配</p>
<ul>
<li>设置一般为map task的两倍</li>
</ul>
</li>
<li><p><code>*.java.opts</code>：JVM进程参数设置</p>
<ul>
<li>每个container（其中执行task）中都会运行JVM进程</li>
<li><code>-Xmx...m</code>：heap size最大值设置，所以此参数应该小于
task（map、reduce）对应的container分配内存的最大值，
如果超出会出现physical memory溢出</li>
<li><code>-Xms...m</code>：heap size最小值？#todo</li>
</ul>
</li>
<li><p><code>yarn.nodemanager.vmem-pmem-ratio</code>：虚拟内存比例</p>
<ul>
<li>以上所有配置都按照此参数放缩</li>
<li>所以在信息中会有physical memory、virtual memory区分</li>
</ul>
</li>
<li><p><code>yarn.nodemanager.resource.memory-mb</code>：节点内存设置</p>
<ul>
<li>整个节点被设置的最大内存，剩余内存共操作系统使用</li>
</ul>
</li>
<li><p><code>yarn.app.mapreduce.am.resource.mb</code>：每个Application
Manager分配的内存大小</p>
</li>
</ul>
<h4 id="主从文件"><a href="#主从文件" class="headerlink" title="主从文件"></a>主从文件</h4><h5 id="masters"><a href="#masters" class="headerlink" title="masters"></a><code>masters</code></h5><ul>
<li>设置主节点地址，根据需要设置</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hd-master</span><br></pre></td></tr></table></figure>
<h5 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a><code>slaves</code></h5><ul>
<li>设置从节点地址，根据需要设置</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hd-slave1</span><br><span class="line">hd-slave2</span><br></pre></td></tr></table></figure>
<h4 id="环境设置文件"><a href="#环境设置文件" class="headerlink" title="环境设置文件"></a>环境设置文件</h4><ul>
<li>这里环境设置只是起补充作用，在<code>~/.bashrc</code>已经设置的
环境变量可以不设置</li>
<li>但是在这里设置环境变量，然后把整个目录同步到其他节点，
可以保证在其余节点也能同样的设置环境变量</li>
</ul>
<h5 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a><code>hadoop-env.sh</code></h5><p>设置<code>JAVA_HOME</code>为Java安装根路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/opt/java/jdk</span><br></pre></td></tr></table></figure>
<h5 id="hdfs-env-sh"><a href="#hdfs-env-sh" class="headerlink" title="hdfs-env.sh"></a><code>hdfs-env.sh</code></h5><p>设置<code>JAVA_HOME</code>为Java安装根路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/opt/java/jdk</span><br></pre></td></tr></table></figure>
<h5 id="yarn-env-sh"><a href="#yarn-env-sh" class="headerlink" title="yarn-env.sh"></a><code>yarn-env.sh</code></h5><p>设置<code>JAVA_HOME</code>为Java安装根路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/opt/java/jdk</span><br><span class="line">JAVA_HEAP_MAX=Xmx3072m</span><br></pre></td></tr></table></figure>
<h4 id="初始化、启动、测试"><a href="#初始化、启动、测试" class="headerlink" title="初始化、启动、测试"></a>初始化、启动、测试</h4><h5 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h5><ul>
<li><p>格式化、启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> hdfs namenode -format</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 格式化文件系统</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> start-dfs.sh</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 启动NameNode和DataNode</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 此时已可访问NameNode，默认http://localhost:9870/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> stop-dfs.sh</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfsadmin -report</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 应该输出3个节点的情况</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -mkdir /user</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -mkdir /user/&lt;username&gt;</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 创建执行MapReduce任务所需的HDFS文件夹</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -mkdir input</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -put etc/hadoop/*.xml input</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 复制文件至分布式文件系统</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar grep input output <span class="string">&#x27;dfs[a-z]+&#x27;</span></span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 执行自带样例</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 样例名称取决于版本</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -get output outut</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat output/*</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 检查输出文件：将所有的输出文件从分布式文件系统复制</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 至本地文件系统，并检查</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -cat output/*</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 或者之间查看分布式文件系统上的输出文件</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hadoop jar /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.7.jar \</span></span><br><span class="line"><span class="bash">	-input /path/to/hdfs_file \</span></span><br><span class="line"><span class="bash">	-output /path/to/hdfs_dir \</span></span><br><span class="line"><span class="bash">	-mapper <span class="string">&quot;/bin/cat&quot;</span> \</span></span><br><span class="line"><span class="bash">	-reducer <span class="string">&quot;/user/bin/wc&quot;</span> \</span></span><br><span class="line"><span class="bash">	-file /path/to/local_file \</span></span><br><span class="line"><span class="bash">	-numReduceTasks 1</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sbin/start-yarn.sh</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 启动ResourceManger守护进程、NodeManager守护进程</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 即可访问ResourceManager的web接口，默认：http://localhost:8088/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sbin/stop-yarn.sh</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 关闭守护进程</span></span><br></pre></td></tr></table></figure>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ul>
<li><p><code>hdfs namenode -format</code>甚至可以在datanode节点没有java时
成功格式化</p>
</li>
<li><p>没有关闭防火墙时，整个集群可以正常启动，甚至可以在hdfs里
正常建立文件夹，但是<strong>无法写入文件</strong>，尝试写入文件时报错</p>
</li>
</ul>
<h4 id="可能错误"><a href="#可能错误" class="headerlink" title="可能错误"></a>可能错误</h4><h5 id="节点启动不全"><a href="#节点启动不全" class="headerlink" title="节点启动不全"></a>节点启动不全</h5><ul>
<li><p>原因</p>
<ul>
<li>服务未正常关闭，节点状态不一致</li>
</ul>
</li>
<li><p>关闭服务、删除存储数据的文件夹<code>dfs/data</code>、格式化namenode</p>
</li>
</ul>
<h5 id="文件无法写入"><a href="#文件无法写入" class="headerlink" title="文件无法写入"></a>文件无法写入</h5><blockquote>
<p>   could only be replicated to 0 nodes instead of minReplication (=1).  There are 2 datanode(s) running and 2 node(s) are excluded in this operation.</p>
</blockquote>
<ul>
<li><p>原因</p>
<ul>
<li>未关闭防火墙</li>
<li>存储空间不够</li>
<li>节点状态不一致、启动不全</li>
<li>在log里面甚至可能会出现一个连接超时1000ms的ERROR</li>
</ul>
</li>
<li><p>处理</p>
<ul>
<li>关闭服务、删除存储数据的文件夹<code>dfs/data</code>、格式化
namenode<ul>
<li>这样处理会丢失数据，不能用于生产环境</li>
</ul>
</li>
<li>尝试修改节点状态信息文件<code>VERSION</code>一致<ul>
<li><code>$&#123;hadoop.tmp.dir&#125;</code></li>
<li><code>$&#123;dfs.namenode.name.dir&#125;</code></li>
<li><code>$&#123;dfs.datanode.data.dir&#125;</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="Unhealthy-Node"><a href="#Unhealthy-Node" class="headerlink" title="Unhealthy Node"></a>Unhealthy Node</h5><blockquote>
<p>   1/1 local-dirs are bad: /opt/hadoop/tmp/nm-local-dir; 1/1 log-dirs are bad: /opt/hadoop/logs/userlogs</p>
</blockquote>
<ul>
<li>原因：磁盘占用超过90%</li>
</ul>
<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">scp -r /opt/hadoop/etc/hadoop centos2:/opt/hadoop/etc</span><br><span class="line">scp -r /opt/hadoop/etc/hadoop centos3:/opt/hadoop/etc</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 同步配置</span></span><br><span class="line"></span><br><span class="line">scp /root/.bashrc centos2:/root</span><br><span class="line">scp /root/.bashrc centos3:/root</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 同步环境</span></span><br><span class="line"></span><br><span class="line">rm -r /opt/hadoop/tmp /opt/hadoop/hdfs</span><br><span class="line">mkdir -p /opt/hadoop/tmp /opt/hadoop/hdfs</span><br><span class="line">ssh centos2 rm -r /opt/hadoop/tmp /opt/hadoop/hdfs</span><br><span class="line">ssh centos2 mkdir -p /opt/hadoop/tmp /opt/hadoop/hdfs/name /opt/hadoop/hdfs/data</span><br><span class="line">ssh centos3 rm -r /opt/hadoop/tmp /opt/hadoop/hdfs/name /opt/hadoop/data</span><br><span class="line">ssh centos3 mkdir -p /opt/hadoop/tmp /opt/hadoop/hdfs/name /opt/hadoop/hdfs/data</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 同步清除数据</span></span><br><span class="line"></span><br><span class="line">rm -r /opt/hadoop/logs/*</span><br><span class="line">ssh centos2 rm -r /opt/hadoop/logs/*</span><br><span class="line">ssh centos3 rm -r /opt/hadoop/logs/*</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 同步清除<span class="built_in">log</span></span></span><br></pre></td></tr></table></figure>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><h3 id="依赖-1"><a href="#依赖-1" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li>hadoop：配置完成hadoop，则相应java等也配置完成</li>
<li>关系型数据库：mysql、derby等</li>
</ul>
<h3 id="机器环境配置-1"><a href="#机器环境配置-1" class="headerlink" title="机器环境配置"></a>机器环境配置</h3><h4 id="bashrc-1"><a href="#bashrc-1" class="headerlink" title="~/.bashrc"></a><code>~/.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/opt/hive</span><br><span class="line"><span class="meta">	#</span><span class="bash"> self designed</span></span><br><span class="line">export HIVE_CONF_DIR=$HIVE_HOME/conf</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line">export CLASSPATH=$CLASS_PATH:$HIVE_HOME/lib/*</span><br></pre></td></tr></table></figure>
<h4 id="文件夹建立-1"><a href="#文件夹建立-1" class="headerlink" title="文件夹建立"></a>文件夹建立</h4><h5 id="HDFS-1"><a href="#HDFS-1" class="headerlink" title="HDFS"></a>HDFS</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -rm -r /user/hive</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -mkdir -p /user/hive/warehouse /user/hive/tmp /user/hive/logs</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这三个目录与配置文件中对应</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hdfs dfs -chmod 777 /user/hive/warehouse /user/hive/tmp /user/hive/logs</span></span><br></pre></td></tr></table></figure>
<h5 id="FS"><a href="#FS" class="headerlink" title="FS"></a>FS</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir data</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> chmod 777 data</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> hive数据存储文件夹</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir logs</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> chmod 777 logs</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> <span class="built_in">log</span>目录</span></span><br></pre></td></tr></table></figure>
<h3 id="Hive配置"><a href="#Hive配置" class="headerlink" title="Hive配置"></a>Hive配置</h3><h4 id="XML参数"><a href="#XML参数" class="headerlink" title="XML参数"></a>XML参数</h4><h5 id="conf-hive-site-xml"><a href="#conf-hive-site-xml" class="headerlink" title="conf/hive-site.xml"></a><code>conf/hive-site.xml</code></h5><ul>
<li>模板：<code>conf/hive-default.xml.template</code></li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hd-master:3306/metastore_db?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>org.mariadb.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>1234<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">&lt;property&gt;</span></span><br><span class="line"><span class="comment">	&lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;</span></span><br><span class="line"><span class="comment">	&lt;value&gt;$&#123;system:java.io.tmpdir&#125;/$&#123;system:user.name&#125;&lt;/value&gt;</span></span><br><span class="line"><span class="comment">&lt;/property&gt;</span></span><br><span class="line"><span class="comment">&lt;property&gt;</span></span><br><span class="line"><span class="comment">	&lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;</span></span><br><span class="line"><span class="comment">	&lt;valeu&gt;$&#123;system:java.io.tmpdir&#125;/$&#123;hive.session.id&#125;_resources&lt;/value&gt;</span></span><br><span class="line"><span class="comment">&lt;/property&gt;</span></span><br><span class="line"><span class="comment">&lt;property&gt;«</span></span><br><span class="line"><span class="comment">	&lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt;«</span></span><br><span class="line"><span class="comment">	&lt;value&gt;$&#123;system:java.io.tmpdir&#125;/$&#123;system:user.name&#125;/operation_logs&lt;/value&gt;«</span></span><br><span class="line"><span class="comment">	&lt;description&gt;Top level directory where operation logs are stored if logging functionality is enabled&lt;/description&gt;«</span></span><br><span class="line"><span class="comment">&lt;/property&gt;«</span></span><br><span class="line"><span class="comment">所有`$&#123;system.java.io.tmpdir&#125;`都要被替换为相应的`/opt/hive/tmp`，</span></span><br><span class="line"><span class="comment">可以通过设置这两个变量即可，基本是用于设置路径</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>system:java.io.tmpdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>system:user.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">&lt;property&gt;</span></span><br><span class="line"><span class="comment">	&lt;name&gt;hive.querylog.location&lt;/name&gt;</span></span><br><span class="line"><span class="comment">	&lt;value&gt;/user/hive/logs&lt;/value&gt;</span></span><br><span class="line"><span class="comment">	&lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;</span></span><br><span class="line"><span class="comment">&lt;/property&gt;</span></span><br><span class="line"><span class="comment">这里应该不用设置，log放在本地文件系统更合适吧</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://192.168.31.129:19083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--这个是配置metastore，如果配置此选项，每次启动hive必须先启动metastore，否则hive实可直接启动--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.logging.operation.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 使用JDBCServer时需要配置，否则无法自行建立log文件夹，然后报错，手动创建可行，但是每次查询都会删除文件夹，必须查一次建一次 --&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p><code>/user</code>开头的路径一般表示hdfs中的路径，而<code>$&#123;&#125;</code>变量开头
的路径一般表示本地文件系统路径</p>
<ul>
<li>变量<code>system:java.io.tmpdir</code>、<code>system:user.name</code>在
文件中需要自己设置，这样就避免需要手动更改出现这些
变量的地方</li>
<li><code>hive.querylog.location</code>设置在本地更好，这个日志好像
只在hive启动时存在，只是查询日志，不是hive运行日志，
hive结束运行时会被删除，并不是没有生成日志、<code>$&#123;&#125;</code>表示
HDFS路径</li>
</ul>
</li>
<li><p>配置中出现的目录（HDFS、locaL）有些手动建立</p>
<ul>
<li>HDFS的目录手动建立？</li>
<li>local不用</li>
</ul>
</li>
<li><p><code>hive.metastore.uris</code>若配置，则hive会通过metastore服务
访问元信息</p>
<ul>
<li>使用hive前需要启动metastore服务</li>
<li>并且端口要和配置文件中一样，否则hive无法访问</li>
</ul>
</li>
</ul>
<h4 id="环境设置文件-1"><a href="#环境设置文件-1" class="headerlink" title="环境设置文件"></a>环境设置文件</h4><h5 id="conf-hive-env-sh"><a href="#conf-hive-env-sh" class="headerlink" title="conf/hive-env.sh"></a><code>conf/hive-env.sh</code></h5><ul>
<li>模板：<code>conf/hive-env.sh.template</code></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/java/jdk</span><br><span class="line">export HADOOP_HOME=/opt/hadoop</span><br><span class="line">export HIVE_CONF_DIR=/opt/hive/conf</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 以上3者若在`~/.bashrc`中设置，则无需再次设置</span></span><br><span class="line">export HIVE_AUX_JARS_PATH=/opt/hive/lib</span><br></pre></td></tr></table></figure>
<h5 id="conf-hive-exec-log4j2-properties"><a href="#conf-hive-exec-log4j2-properties" class="headerlink" title="conf/hive-exec-log4j2.properties"></a><code>conf/hive-exec-log4j2.properties</code></h5><ul>
<li><p>模板：<code>hive-exec-log4j2.properties.template</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">property.hive.log.dir=/opt/hive/logs</span><br><span class="line">	# 原为`$&#123;sys:java.io.tmpdir&#125;/$&#123;sys:user.name&#125;`</span><br><span class="line">	# 即`/tmp/root`（root用户执行）</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="conf-hive-log4j2-properties"><a href="#conf-hive-log4j2-properties" class="headerlink" title="conf/hive-log4j2.properties"></a><code>conf/hive-log4j2.properties</code></h5><ul>
<li>模板：<code>hive-log4j2.properties.template</code></li>
</ul>
<h4 id="MetaStore"><a href="#MetaStore" class="headerlink" title="MetaStore"></a>MetaStore</h4><h5 id="MariaDB"><a href="#MariaDB" class="headerlink" title="MariaDB"></a>MariaDB</h5><ul>
<li><p>安装MariaDB</p>
</li>
<li><p>修改MariaDB配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cp /user/share/mysql/my-huge.cnf /etc/my.cnf</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>创建用户，注意新创建用户可能无效，见mysql配置</p>
<ul>
<li>需要注意用户权限：创建数据库权限、修改表权限</li>
<li>初始化时Hive要自己创建数据库（<code>hive-site</code>中配置），
所以对权限比较严格的环境下，可能需要先行创建同名
数据库、赋权、删库</li>
</ul>
</li>
<li><p>下载<code>mariadb-java-client-x.x.x-jar</code>包，复制到<code>lib</code>中</p>
</li>
</ul>
<h5 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> schematool -initSchema -dbType mysql</span></span><br></pre></td></tr></table></figure>
<p>这个命令要在所有配置完成之后执行</p>
<h4 id="服务设置"><a href="#服务设置" class="headerlink" title="服务设置"></a>服务设置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> hive --service metastore -p 19083 &amp;</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 启动metastore服务，端口要和hive中的配置相同</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 否则hive无法连接metastore服务，无法使用</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 终止metastore服务只能根据进程号`<span class="built_in">kill</span>`</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hive --service hiveserver2 --hiveconf hive.server2.thrift.port =10011 &amp;</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 启动JDBC Server</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 此时可以通过JDBC Client（如beeline）连接JDBC Server对</span></span><br><span class="line"><span class="meta">		#</span><span class="bash"> Hive中数据进行操作</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hive --service hiveserver2 --stop</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 停止JDBC Server</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 或者直接<span class="built_in">kill</span></span></span><br></pre></td></tr></table></figure>
<h4 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h4><h5 id="Hive可用性"><a href="#Hive可用性" class="headerlink" title="Hive可用性"></a>Hive可用性</h5><p>需要先启动hdfs、YARN、metastore database（mysql），如果有
设置独立metastore server，还需要在正确端口启动</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span>	<span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> words(id <span class="type">INT</span>, word STRING)</span><br><span class="line">		<span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> &quot; &quot;</span><br><span class="line">		lines terminated <span class="keyword">by</span> &quot;\n&quot;;</span><br><span class="line">hive<span class="operator">&gt;</span>	load data <span class="keyword">local</span> inpath &quot;/opt/hive-test.txt&quot; overwrite <span class="keyword">into</span></span><br><span class="line">		<span class="keyword">table</span> words;</span><br><span class="line">hive<span class="operator">&gt;</span>	<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> words;</span><br></pre></td></tr></table></figure>
<h5 id="JDBCServer可用性"><a href="#JDBCServer可用性" class="headerlink" title="JDBCServer可用性"></a>JDBCServer可用性</h5><ul>
<li><p>命令行连接</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> beeline -u jdbc:hive2://localhost:10011 -n hive -p 1234</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>beeline中连接</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> beeline</span></span><br><span class="line"><span class="meta">beeline&gt;</span><span class="bash"> !connect jdbc:hive2://localhost:10011</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 然后输入用户名、密码（metastore数据库用户名密码）</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h3><h4 id="可能错误-1"><a href="#可能错误-1" class="headerlink" title="可能错误"></a>可能错误</h4><blockquote>
<p>   Failed with exception Unable to move source file</p>
</blockquote>
<ul>
<li>linux用户权限问题，无法操作原文件</li>
<li>hdfs用户权限问题，无法写入目标文件</li>
<li>hdfs配置问题，根本无法向hdfs写入：参见hdfs问题</li>
</ul>
<blockquote>
<p>   org.apache.hive.service.cli.HiveSQLException: Couldn’t find log associated with operation handle: </p>
</blockquote>
<ul>
<li><p>原因：hiveserver2查询日志文件夹不存在</p>
</li>
<li><p>可以在hive中通过</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="keyword">set</span> hive.server2.logging.operation.log.location;</span><br></pre></td></tr></table></figure>
<p>查询日志文件夹，建立即可，默认为
<code>$&#123;system:java.io.tmpdir&#125;/$&#123;system:user.name&#125;/operation_logs</code>
，并设置权限为777</p>
<ul>
<li>好像如果不设置权限为777，每次查询文件夹被删除，每
查询一次建立一次文件夹？#todo</li>
<li>在<code>hive-sitex.xml</code>中配置允许自行创建？</li>
</ul>
</li>
</ul>
<blockquote>
<p>   User: root is not allowed to impersonate hive</p>
</blockquote>
<ul>
<li><p>原因：当前用户（不一定是root）不被允许通过代理操作
hadoop用户、用户组、主机</p>
<ul>
<li>hadoop引入安全伪装机制，不允许上层系统直接将实际用户
传递给超级代理，此代理在hadoop上执行操作，避免客户端
随意操作hadoop</li>
</ul>
</li>
<li><p>配置hadoop的<code>core-site.xml</code>，使得当前用户作为超级代理</p>
</li>
</ul>
<h2 id="Tez"><a href="#Tez" class="headerlink" title="Tez"></a>Tez</h2><h3 id="依赖-2"><a href="#依赖-2" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li>hadoop</li>
</ul>
<h3 id="机器环境配置-2"><a href="#机器环境配置-2" class="headerlink" title="机器环境配置"></a>机器环境配置</h3><h4 id="bashrc-2"><a href="#bashrc-2" class="headerlink" title=".bashrc"></a><code>.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">export TEZ_HOME=/opt/tez</span><br><span class="line">export TEZ_CONF_DIR=$TEZ_HOME/conf</span><br><span class="line"></span><br><span class="line">for jar in `ls $TEZ_HOME | grep jar`; do</span><br><span class="line">	export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/$jar</span><br><span class="line">done</span><br><span class="line">for jar in `ls $TEZ_HOME/lib`; do</span><br><span class="line">	export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/lib/$jar</span><br><span class="line">done</span><br><span class="line"><span class="meta">	#</span><span class="bash"> this part could be replaced with line bellow</span></span><br><span class="line">export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/*:$TEZ_HOME/lib/*</span><br><span class="line"><span class="meta">	#</span><span class="bash"> `hadoop-env.sh`中说`HADOOP_CLASSPATH`是Extra Java CLASSPATH</span></span><br><span class="line"><span class="meta">		#</span><span class="bash"> elements</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这意味着hadoop组件只需要把其jar包加到`HADOOP_CLASSPATH`中既可</span></span><br></pre></td></tr></table></figure>
<h4 id="HDFS-2"><a href="#HDFS-2" class="headerlink" title="HDFS"></a>HDFS</h4><ul>
<li><p>上传<code>$TEZ_HOME/share/tez.tar.gz</code>至HDFS中</p>
<figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -mkdir /apps</span><br><span class="line">$ hdfs dfs -copyFromLocal tez.tar.gz /apps</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="HadoopOnTez"><a href="#HadoopOnTez" class="headerlink" title="HadoopOnTez"></a>HadoopOnTez</h3><p>在hadoop中配置Tez</p>
<ul>
<li><p>侵入性较强，对已有的hadoop集群全体均有影响</p>
</li>
<li><p>所有hadoop集群执行的MapReduce任务都通过tez执行</p>
<ul>
<li>这里所有的任务应该是指直接在hadoop上执行、能在
webRM上看到的任务</li>
<li>hive这样的独立组件需要独立配置</li>
</ul>
</li>
</ul>
<h4 id="XML参数-1"><a href="#XML参数-1" class="headerlink" title="XML参数"></a>XML参数</h4><h5 id="tez-site-xml"><a href="#tez-site-xml" class="headerlink" title="tez-site.xml"></a><code>tez-site.xml</code></h5><ul>
<li>模板：<code>conf/tez-default-tmplate.xml</code></li>
<li>好像还是需要复制到hadoop的配置文件夹中</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;tez.lib.uris&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;$&#123;fs.defaultFS&#125;/apps/tez.tar.gz&lt;/value&gt;</span><br><span class="line">	&lt;!--设置tez安装包位置--&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;tez.container.max.java.heap.fraction&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;0.2&lt;/value&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">内存不足时--&gt;</span><br></pre></td></tr></table></figure>
<h5 id="mapred-site-xml-2"><a href="#mapred-site-xml-2" class="headerlink" title="mapred-site.xml"></a><code>mapred-site.xml</code></h5><ul>
<li>修改<code>mapred-site.xml</code>文件：配置mapreduce基于<code>yarn-tez</code>，
（配置修改在hadoop部分也有）</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn-tez<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="环境参数"><a href="#环境参数" class="headerlink" title="环境参数"></a>环境参数</h4><h3 id="HiveOnTez"><a href="#HiveOnTez" class="headerlink" title="HiveOnTez"></a>HiveOnTez</h3><ul>
<li><p>此模式下Hive可以在mapreduce、tez计算模型下自由切换？</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> hive.execution.engine<span class="operator">=</span>tez;</span><br><span class="line">	# 切换查询引擎为tez</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> hive.execution.engine<span class="operator">=</span>mr;</span><br><span class="line">	# 切换查询引擎为mapreduce</span><br><span class="line">	# 这些命令好像没用，只能更改值，不能更改实际查询模型</span><br></pre></td></tr></table></figure>
</li>
<li><p>只有Hive会受到影响，其他基于hadoop平台的mapreduce作业
仍然使用tez计算模型</p>
</li>
</ul>
<h4 id="Hive设置"><a href="#Hive设置" class="headerlink" title="Hive设置"></a>Hive设置</h4><ul>
<li>若已经修改了<code>mapred-site.xml</code>设置全局基于tez，则无需复制
jar包，直接修改<code>hive-site.xml</code>即可</li>
</ul>
<h5 id="Jar包复制"><a href="#Jar包复制" class="headerlink" title="Jar包复制"></a>Jar包复制</h5><p>复制<code>$TEZ_HOME</code>、<code>$TEZ_HOME/lib</code>下的jar包到<code>$HIVE_HOME/lib</code>
下即可</p>
<h5 id="hive-site-xml"><a href="#hive-site-xml" class="headerlink" title="hive-site.xml"></a><code>hive-site.xml</code></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hive.execution.engine&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;tez&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="其他-2"><a href="#其他-2" class="headerlink" title="其他"></a>其他</h3><h4 id="可能错误-2"><a href="#可能错误-2" class="headerlink" title="可能错误"></a>可能错误</h4><blockquote>
<p>   SLF4J: Class path contains multiple SLF4J bindings.</p>
</blockquote>
<ul>
<li>原因：包冲突的</li>
<li>解决方案：根据提示冲突包删除即可</li>
</ul>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><h3 id="依赖-3"><a href="#依赖-3" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li>java</li>
<li>scala</li>
<li>python：一般安装anaconda，需要额外配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PYTHON_HOME=/opt/anaconda3</span><br><span class="line">export PATH=$PYTHON_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li>
<li>相应资源管理框架，如果不以standalone模式运行</li>
</ul>
<h3 id="机器环境配置-3"><a href="#机器环境配置-3" class="headerlink" title="机器环境配置"></a>机器环境配置</h3><h4 id="bashrc-3"><a href="#bashrc-3" class="headerlink" title="~/.bashrc"></a><code>~/.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_HOME=/opt/spark</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin</span><br><span class="line">export PYTHON_PATH=$PYTHON_PATH:$SPARK_HOME/python:$SPARK_HOME/python/lib/*</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 把`pyshark`、`py4j`模块对应的zip文件添加进路径</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这里用的是`*`通配符应该也可以，手动添加所有zip肯定可以</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 否则无法在一般的python中对spark进行操作</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 似乎只要master节点有设置`/lib/*`添加`pyspark`、`py4j`就行</span></span><br></pre></td></tr></table></figure>
<h3 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h3><h4 id="环境设置文件-2"><a href="#环境设置文件-2" class="headerlink" title="环境设置文件"></a>环境设置文件</h4><h5 id="conf-spark-env-sh"><a href="#conf-spark-env-sh" class="headerlink" title="conf/spark-env.sh"></a><code>conf/spark-env.sh</code></h5><ul>
<li>模板：<code>conf/spark-env.sh.template</code></li>
</ul>
<p>这里应该有些配置可以省略、移除#todo</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/jdk</span><br><span class="line">export HADOOP_HOME=/opt/hadoop</span><br><span class="line">export hADOOP_CONF_DIR=/opt/hadoop/etc/hadoop</span><br><span class="line">export HIVE_HOME=/opt/hive</span><br><span class="line"></span><br><span class="line">export SCALA_HOME=/opt/scala</span><br><span class="line">export SCALA_LIBRARY=$SPARK_HOME/lib</span><br><span class="line"><span class="meta">	#</span><span class="bash"> `~/.bashrc`设置完成之后，前面这段应该就这个需要设置</span></span><br><span class="line"></span><br><span class="line">export SPARK_HOME=/opt/spark</span><br><span class="line">export SPARK_DIST_CLASSPATH=$(hadoop classpath)</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这里是执行命令获取classpath</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> todo</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这里看文档的意思，应该也是类似于`<span class="variable">$HADOOP_CLASSPATH</span>`</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 可以直接添加进`<span class="variable">$CLASSPATH</span>`而不必设置此变量</span></span><br><span class="line">export SPARK_LIBRARY_PATH=$SPARK_HOME/lib</span><br><span class="line"></span><br><span class="line">export SPARK_MASTER_HOST=hd-master</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line">export SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line">export SPARK_WORKER_WEBUI_PORT=8081</span><br><span class="line">export SPARK_WORKER_MEMORY=1024m</span><br><span class="line"><span class="meta">	#</span><span class="bash"> spark能在一个container内执行多个task</span></span><br><span class="line">export SPARK_LOCAL_DIRS=$SPARK_HOME/data</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 需要手动创建</span></span><br><span class="line"></span><br><span class="line">export SPARK_MASTER_OPTS=</span><br><span class="line">export SPARK_WORKER_OPTS=</span><br><span class="line">export SPARK_DAEMON_JAVA_OPTS=</span><br><span class="line">export SPARK_DAEMON_MEMORY=</span><br><span class="line">export SPARK_DAEMON_JAVA_OPTS=</span><br></pre></td></tr></table></figure>
<h5 id="文件夹建立-2"><a href="#文件夹建立-2" class="headerlink" title="文件夹建立"></a>文件夹建立</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir /opt/spark/spark_data</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> <span class="keyword">for</span> `<span class="variable">$SPARK_LOCAL_DIRS</span>`</span></span><br></pre></td></tr></table></figure>
<h4 id="Spark配置"><a href="#Spark配置" class="headerlink" title="Spark配置"></a>Spark配置</h4><h5 id="conf-slaves"><a href="#conf-slaves" class="headerlink" title="conf/slaves"></a><code>conf/slaves</code></h5><p>文件不存在，则在当前主机单节点运行</p>
<ul>
<li>模板：<code>conf/slaves.template</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hd-slave1</span><br><span class="line">hd-slave2</span><br></pre></td></tr></table></figure>
<h5 id="conf-hive-site-xml-1"><a href="#conf-hive-site-xml-1" class="headerlink" title="conf/hive-site.xml"></a><code>conf/hive-site.xml</code></h5><p>这里只是配置Spark，让Spark作为“thrift客户端”能正确连上
metastore server</p>
<ul>
<li>模板：<code>/opt/hive/conf/hive-site.xml</code></li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://192.168.31.129:19083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">description</span>&gt;</span>Thrift URI for the remote metastor. Used by metastore client to connect to remote metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>10011<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--配置spark对外界thrift服务，以便可通过JDBC客户端存取spark--&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--这里启动端口同hive的配置，所以两者不能默认同时启动--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="测试-2"><a href="#测试-2" class="headerlink" title="测试"></a>测试</h4><h5 id="启动Spark服务"><a href="#启动Spark服务" class="headerlink" title="启动Spark服务"></a>启动Spark服务</h5><p>需要启动hdfs、正确端口启动的metastore server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> start-master.sh</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 在执行**此命令**机器上启动master实例</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> start-slaves.sh</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 在`conf/slaves`中的机器上启动worker实例</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> start-slave.sh</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 在执行**此命令**机器上启动worker实例</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> stop-master.sh</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> stop-slaves.sh</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> stop-slave.sh</span></span><br></pre></td></tr></table></figure>
<h5 id="启动Spark-Thrift-Server"><a href="#启动Spark-Thrift-Server" class="headerlink" title="启动Spark Thrift Server"></a>启动Spark Thrift Server</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> start-thriftserver.sh --master spark://hd-master:7077 \</span></span><br><span class="line"><span class="bash">	--hiveconf hive.server2.thrift.bind.host hd-master \</span></span><br><span class="line"><span class="bash">	--hiveconf hive.server2.thrift.port 10011</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这里在命令行启动thrift server时动态指定host、port</span></span><br><span class="line"><span class="meta">		#</span><span class="bash"> 如果在`conf/hive-site.xml`有配置，应该不需要</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 然后使用beeline连接thrift server，同hive</span></span><br></pre></td></tr></table></figure>
<h5 id="Spark-Sql测试"><a href="#Spark-Sql测试" class="headerlink" title="Spark-Sql测试"></a>Spark-Sql测试</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ spark<span class="operator">-</span><span class="keyword">sql</span> <span class="comment">--master spark://hd-master:7077</span></span><br><span class="line">	# 在含有配置文件的节点上启动时，配置文件中已经指定`MASTER`</span><br><span class="line">		# 因此不需要指定后面配置</span><br><span class="line"></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">set</span> spark.sql.shuffle.partitions<span class="operator">=</span><span class="number">20</span>;</span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">select</span> id, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> words <span class="keyword">group</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> id;</span><br></pre></td></tr></table></figure>
<h5 id="pyspark测试"><a href="#pyspark测试" class="headerlink" title="pyspark测试"></a>pyspark测试</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ MASTER=spark://hd-master:<span class="number">7077</span> pyspark</span><br><span class="line">	<span class="comment"># 这里应该是调用`$PATH`中第一个python，如果未默认指定</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> HiveContext</span><br><span class="line">sql_ctxt = HiveContext(sc)</span><br><span class="line">	<span class="comment"># 此`sc`是pyspark启动时自带的，是`SparkContext`类型实例</span></span><br><span class="line">	<span class="comment"># 每个连接只能有一个此实例，不能再次创建此实例</span></span><br><span class="line"></span><br><span class="line">ret = sql_ctxt.sql(<span class="string">&quot;show tables&quot;</span>).collect()</span><br><span class="line">	<span class="comment"># 这里语句结尾不能加`;` </span></span><br><span class="line"></span><br><span class="line">file = sc.textFile(<span class="string">&quot;hdfs://hd-master:9000/user/root/input/capacity-scheduler.xml&quot;</span>)</span><br><span class="line">file.count()</span><br><span class="line">file.first()</span><br></pre></td></tr></table></figure>
<h5 id="Scala测试"><a href="#Scala测试" class="headerlink" title="Scala测试"></a>Scala测试</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="type">MASTER</span>=spark:<span class="comment">//hd-master:7077 spark-shell \</span></span><br><span class="line">	executor-memory <span class="number">1024</span>m \</span><br><span class="line">	--total-executor-cores <span class="number">2</span> \</span><br><span class="line">	--excutor-cores <span class="number">1</span> \</span><br><span class="line">	# 添加参数启动`spark-shell`</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></span><br><span class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> org.apache.spark.sql.hive.<span class="type">HiveContext</span>(sc)</span><br><span class="line">sqlContext.sql(<span class="string">&quot;select * from words&quot;</span>).collect().foreach(println)</span><br><span class="line">sqlContext.sql(<span class="string">&quot;select id, word from words order by id&quot;</span>).collect().foreach(println)</span><br><span class="line"></span><br><span class="line">sqlContext.sql(<span class="string">&quot;insert into words values(7, \&quot;jd\&quot;)&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> df = sqlContext.sql(<span class="string">&quot;select * from words&quot;</span>);</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> df = spark.read.json(<span class="string">&quot;file:///opt/spark/example/src/main/resources/people.json&quot;</span>)</span><br><span class="line">df.show()</span><br></pre></td></tr></table></figure>
<h3 id="Spark-on-YARN"><a href="#Spark-on-YARN" class="headerlink" title="Spark on YARN"></a>Spark on YARN</h3><h3 id="其他-3"><a href="#其他-3" class="headerlink" title="其他"></a>其他</h3><h4 id="可能错误-3"><a href="#可能错误-3" class="headerlink" title="可能错误"></a>可能错误</h4><blockquote>
<p>   Initial job has not accepted any resources;</p>
</blockquote>
<ul>
<li><p>原因：内存不足，spark提交application时内存超过分配给
worker节点内存</p>
</li>
<li><p>说明</p>
<ul>
<li>根据结果来看，<code>pyspark</code>、<code>spark-sql</code>需要内存比
<code>spark-shell</code>少？
（设置worker内存512m，前两者可以正常运行）</li>
<li>但是前两者的内存分配和scala不同，scala应该是提交任务
、指定内存大小的方式，这也可以从web-ui中看出来，只有
spark-shell开启时才算是<em>application</em></li>
</ul>
</li>
<li><p>解决方式</p>
<ul>
<li>修改<code>conf/spark-env.sh</code>中<code>SPARK_WORKER_MEMORY</code>更大，
（spark默认提交application内存为1024m）</li>
<li>添加启动参数<code>--executor-memory XXXm</code>不超过分配值</li>
</ul>
</li>
</ul>
<blockquote>
<pre><code>ERROR KeyProviderCache:87 - Could not find uri with key [dfs.encryption.key.provider.uri] to create a keyProvider
</code></pre></blockquote>
<ul>
<li>无影响</li>
</ul>
<h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><h3 id="依赖-4"><a href="#依赖-4" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li>java</li>
<li>hadoop</li>
<li>zookeeper：建议，否则日志不好管理</li>
</ul>
<h3 id="机器环境"><a href="#机器环境" class="headerlink" title="机器环境"></a>机器环境</h3><h4 id="bashrc-4"><a href="#bashrc-4" class="headerlink" title="~/.bashrc"></a><code>~/.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_HOME=/opt/hbase</span><br><span class="line">export PATH=$PAHT:$HBASE_HOME/bin</span><br><span class="line">export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$HBASE_HOME/lib/*</span><br></pre></td></tr></table></figure>
<h4 id="建立目录"><a href="#建立目录" class="headerlink" title="建立目录"></a>建立目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir /tmp/hbase/tmpdir</span></span><br></pre></td></tr></table></figure>
<h3 id="HBase配置"><a href="#HBase配置" class="headerlink" title="HBase配置"></a>HBase配置</h3><h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><h5 id="conf-hbase-env-sh"><a href="#conf-hbase-env-sh" class="headerlink" title="conf/hbase-env.sh"></a><code>conf/hbase-env.sh</code></h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_MANAGES_ZK=false</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 不使用自带zookeeper</span></span><br></pre></td></tr></table></figure>
<h5 id="conf-zoo-cfg"><a href="#conf-zoo-cfg" class="headerlink" title="conf/zoo.cfg"></a><code>conf/zoo.cfg</code></h5><p>若设置使用独立zookeeper，需要复制zookeeper配置至HBase配置
文件夹中</p>
<figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp /opt/zookeeper/conf/zoo.cfg /opt/hbase/conf</span><br></pre></td></tr></table></figure>
<h4 id="Standalone模式"><a href="#Standalone模式" class="headerlink" title="Standalone模式"></a>Standalone模式</h4><h5 id="conf-hbase-site-xml"><a href="#conf-hbase-site-xml" class="headerlink" title="conf/hbase-site.xml"></a><code>conf/hbase-site.xml</code></h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;HBASE_HOME&#125;/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/zookeeper/zkdata<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="Pseudo-Distributed模式"><a href="#Pseudo-Distributed模式" class="headerlink" title="Pseudo-Distributed模式"></a>Pseudo-Distributed模式</h4><h5 id="conf-hbase-site-xml-1"><a href="#conf-hbase-site-xml-1" class="headerlink" title="conf/hbase-site.xml"></a><code>conf/hbase-site.xml</code></h5><ul>
<li>在Standalone配置上修改</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">proeperty</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hd-master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="Fully-Distributed模式"><a href="#Fully-Distributed模式" class="headerlink" title="Fully-Distributed模式"></a>Fully-Distributed模式</h4><h5 id="conf-hbase-site-xml-2"><a href="#conf-hbase-site-xml-2" class="headerlink" title="conf/hbase-site.xml"></a><code>conf/hbase-site.xml</code></h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hd-master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hd-master,hd-slave1,hd-slave2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/zookeeper/zkdata<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="测试-3"><a href="#测试-3" class="headerlink" title="测试"></a>测试</h4><ul>
<li>需要首先启动HDFS、YARN</li>
<li>使用独立zookeeper还需要先行在每个节点启动zookeeper</li>
</ul>
<figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ start-hbase.sh</span><br><span class="line"><span class="code">	# 启动HBase服务</span></span><br><span class="line"><span class="code">$ local-regionservers.sh start 2 3 4 5</span></span><br><span class="line"><span class="code">	# 启动额外的4个RegionServer</span></span><br><span class="line"><span class="code">$ hbase shell</span></span><br><span class="line"><span class="code">hbase&gt; create &#x27;test&#x27;, &#x27;cf&#x27;</span></span><br><span class="line"><span class="code">hbase&gt; list &#x27;test&#x27;</span></span><br><span class="line"><span class="code">hbase&gt; put &#x27;test&#x27;, &#x27;row7&#x27;, &#x27;cf:a&#x27;, &#x27;value7a&#x27;</span></span><br><span class="line"><span class="code">	put &#x27;test&#x27;, &#x27;row7&#x27;, &#x27;cf:b&#x27;, &#x27;value7b&#x27;</span></span><br><span class="line"><span class="code">	put &#x27;test&#x27;, &#x27;row7&#x27;, &#x27;cf:c&#x27;, &#x27;value7c&#x27;</span></span><br><span class="line"><span class="code">	put &#x27;test&#x27;, &#x27;row8&#x27;, &#x27;cf:b&#x27;, &#x27;value8b&#x27;,</span></span><br><span class="line"><span class="code">	put &#x27;test&#x27;, &#x27;row9&#x27;, &#x27;cf:c&#x27;, &#x27;value9c&#x27;</span></span><br><span class="line"><span class="code">hbase&gt; scan &#x27;test&#x27;</span></span><br><span class="line"><span class="code">hbase&gt; get &#x27;test&#x27;, &#x27;row7&#x27;</span></span><br><span class="line"><span class="code">hbase&gt; disable &#x27;test&#x27;</span></span><br><span class="line"><span class="code">hbase&gt; enable &#x27;test&#x27;</span></span><br><span class="line"><span class="code">hbaee&gt; drop &#x27;test&#x27;</span></span><br><span class="line"><span class="code">hbase&gt; quit</span></span><br></pre></td></tr></table></figure>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="依赖-5"><a href="#依赖-5" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li><p>java</p>
</li>
<li><p>注意：zookeeper集群中工作超过半数才能对外提供服务，所以
一般配置服务器数量为奇数</p>
</li>
</ul>
<h3 id="机器环境-1"><a href="#机器环境-1" class="headerlink" title="机器环境"></a>机器环境</h3><h4 id="bashrc-5"><a href="#bashrc-5" class="headerlink" title="~/.bashrc"></a><code>~/.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin</span><br><span class="line">export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$ZOOKEEPER_HOME/lib</span><br></pre></td></tr></table></figure>
<h4 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h4><ul>
<li>在所有节点都需要创建相应文件夹、<code>myid</code>文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /tmp/zookeeper/zkdata /tmp/zookeeper/zkdatalog</span><br><span class="line">echo 0 &gt; /tmp/zookeeper/zkdatalog/myid</span><br><span class="line"></span><br><span class="line">ssh centos2 mkdir -p /tmp/zookeeper/zkdata /tmp/zookeeper/zkdatalog</span><br><span class="line">ssh centos3 mkdir -p /tmp/zookeeper/zkdata /tmp/zookeeper/zkdatalog</span><br><span class="line">ssh centos2 &quot;echo 2 &gt; /tmp/zookeeper/zkdata/myid&quot;</span><br><span class="line">ssh centos3 &quot;echo 3 &gt; /tmp/zookeeper/zkdata/myid&quot;</span><br></pre></td></tr></table></figure>
<h3 id="Zookeeper配置"><a href="#Zookeeper配置" class="headerlink" title="Zookeeper配置"></a>Zookeeper配置</h3><h4 id="Conf"><a href="#Conf" class="headerlink" title="Conf"></a>Conf</h4><h5 id="conf-zoo-cfg-1"><a href="#conf-zoo-cfg-1" class="headerlink" title="conf/zoo.cfg"></a><code>conf/zoo.cfg</code></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000</span><br><span class="line">	# The number of milliseconds of each tick</span><br><span class="line">initLimit=10</span><br><span class="line">	# The number of ticks that the initial</span><br><span class="line">	# synchronization phase can take</span><br><span class="line">syncLimit=5</span><br><span class="line">	# The number of ticks that can pass between</span><br><span class="line">	# sending a request and getting an acknowledgement</span><br><span class="line">dataDir=/tmp/zookeeper/zkdata</span><br><span class="line">dataLogDir=/tmp/zookeeper/zkdatalog</span><br><span class="line">	# the directory where the snapshot is stored.</span><br><span class="line">	# do not use /tmp for storage, /tmp here is just</span><br><span class="line">	# example sakes.</span><br><span class="line">clientPort=2181</span><br><span class="line">	# the port at which the clients will connect</span><br><span class="line"></span><br><span class="line">autopurge.snapRetainCount=3</span><br><span class="line">	# Be sure to read the maintenance section of the</span><br><span class="line">	# administrator guide before turning on autopurge.</span><br><span class="line">	# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span><br><span class="line">	# The number of snapshots to retain in dataDir</span><br><span class="line">autopurge.purgeInterval=1</span><br><span class="line">	# Purge task interval in hours</span><br><span class="line">	# Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line"></span><br><span class="line">server.0=hd-master:2888:3888</span><br><span class="line">server.1=hd-slave1:2888:3888</span><br><span class="line">server.2=hd-slave2:2888:3888</span><br><span class="line">	# Determine the zookeeper servers</span><br><span class="line">	# fromation: server.NO=HOST:PORT1:PORT2</span><br><span class="line">		# PORT1: port used to communicate with leader</span><br><span class="line">		# PORT2: port used to reelect leader when current leader fail</span><br></pre></td></tr></table></figure>
<h5 id="dataDir-myid"><a href="#dataDir-myid" class="headerlink" title="$dataDir/myid"></a><code>$dataDir/myid</code></h5><ul>
<li><code>$dataDir</code>是<code>conf/zoo.cfg</code>中指定目录</li>
<li><code>myid</code>文件里就一个id，指明当前zookeeper server的id，服务
启动时读取文件确定其id，需要自行创建</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0</span><br></pre></td></tr></table></figure>
<h4 id="启动、测试、清理"><a href="#启动、测试、清理" class="headerlink" title="启动、测试、清理"></a>启动、测试、清理</h4><p>启动zookeeper</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> zkServer.sh start</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 开启zookeeper服务</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> zookeeper服务要在各个节点分别手动启动</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> zkServer.sh status</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 查看服务状态</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> zkCleanup.sh</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 清理旧的快照、日志文件</span></span><br></pre></td></tr></table></figure>
<h2 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h2><h3 id="依赖-6"><a href="#依赖-6" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li>java</li>
</ul>
<h3 id="机器环境配置-4"><a href="#机器环境配置-4" class="headerlink" title="机器环境配置"></a>机器环境配置</h3><h4 id="bashrc-6"><a href="#bashrc-6" class="headerlink" title="~/.bashrc"></a><code>~/.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH=$PATH:/opt/flume/bin</span><br></pre></td></tr></table></figure>
<h3 id="Flume配置"><a href="#Flume配置" class="headerlink" title="Flume配置"></a>Flume配置</h3><h4 id="环境设置文件-3"><a href="#环境设置文件-3" class="headerlink" title="环境设置文件"></a>环境设置文件</h4><h5 id="conf-flume-env-sh"><a href="#conf-flume-env-sh" class="headerlink" title="conf/flume-env.sh"></a><code>conf/flume-env.sh</code></h5><ul>
<li>模板：<code>conf/flume-env.sh.template</code></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/opt/jdk</span><br></pre></td></tr></table></figure>
<h4 id="Conf文件"><a href="#Conf文件" class="headerlink" title="Conf文件"></a>Conf文件</h4><h5 id="conf-flume-conf"><a href="#conf-flume-conf" class="headerlink" title="conf/flume.conf"></a><code>conf/flume.conf</code></h5><ul>
<li>模板：<code>conf/flume-conf.properties.template</code></li>
</ul>
<figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">agent1.channels.ch1.type=memory</span><br><span class="line"><span class="code">	# define a memory channel called `ch1` on `agent1`</span></span><br><span class="line"><span class="code">agent1.sources.avro-source1.channels=ch1</span></span><br><span class="line"><span class="code">agent1.sources.avro-source1.type=avro</span></span><br><span class="line"><span class="code">agent1.sources.avro-source1.bind=0.0.0.0</span></span><br><span class="line"><span class="code">agent1.sources.avro-source1.prot=41414</span></span><br><span class="line"><span class="code">	# define an Avro source called `avro-source1` on `agent1` and tell it</span></span><br><span class="line"><span class="code">agent1.sink.log-sink1.channels=ch1</span></span><br><span class="line"><span class="code">agent1.sink.log-sink1.type=logger</span></span><br><span class="line"><span class="code">	# define a logger sink that simply logs all events it receives</span></span><br><span class="line"><span class="code">agent1.channels=ch1</span></span><br><span class="line"><span class="code">agent1.sources=avro-source1</span></span><br><span class="line"><span class="code">agent1.sinks=log-sink1</span></span><br><span class="line"><span class="code">	# Finally, all components have been defined, tell `agent1` which one to activate</span></span><br></pre></td></tr></table></figure>
<h4 id="启动、测试"><a href="#启动、测试" class="headerlink" title="启动、测试"></a>启动、测试</h4><figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ flume-ng agent --conf /opt/flume/conf \</span><br><span class="line"><span class="code">	-f /conf/flume.conf \</span></span><br><span class="line"><span class="code">	-D flume.root.logger=DEBUG,console \</span></span><br><span class="line"><span class="code">	-n agent1</span></span><br><span class="line"><span class="code">	# the agent name specified by -n agent1` must match an agent name in `-f /conf/flume.conf`</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">$ flume-ng avro-client --conf /opt/flume/conf \</span><br><span class="line"><span class="code">	-H localhost -p 41414 \</span></span><br><span class="line"><span class="code">	-F /opt/hive-test.txt \</span></span><br><span class="line"><span class="code">	-D flume.root.logger=DEBUG, Console</span></span><br><span class="line"><span class="code">	# 测试flume</span></span><br></pre></td></tr></table></figure>
<h3 id="其他-4"><a href="#其他-4" class="headerlink" title="其他"></a>其他</h3><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h3 id="依赖-7"><a href="#依赖-7" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li>java</li>
<li>zookeeper</li>
</ul>
<h3 id="机器环境变量"><a href="#机器环境变量" class="headerlink" title="机器环境变量"></a>机器环境变量</h3><h4 id="bashrc-7"><a href="#bashrc-7" class="headerlink" title="~/.bashrc"></a><code>~/.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PATH=$PATH:/opt/kafka/bin</span><br><span class="line">export KAFKA_HOME=/opt/kafka</span><br></pre></td></tr></table></figure>
<h3 id="多brokers配置"><a href="#多brokers配置" class="headerlink" title="多brokers配置"></a>多brokers配置</h3><h4 id="Conf-1"><a href="#Conf-1" class="headerlink" title="Conf"></a>Conf</h4><h5 id="config-server-1-properties"><a href="#config-server-1-properties" class="headerlink" title="config/server-1.properties"></a><code>config/server-1.properties</code></h5><ul>
<li>模板：<code>config/server.properties</code></li>
<li>不同节点<code>broker.id</code>不能相同</li>
<li>可以多编写几个配置文件，在不同节点使用不同配置文件启动</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">broker.id=0</span><br><span class="line">listeners=PLAINTEXT://:9093</span><br><span class="line">zookeeper.connect=hd-master:2181, hd-slave1:2181, hd-slave2:2181</span><br></pre></td></tr></table></figure>
<h4 id="测试-4"><a href="#测试-4" class="headerlink" title="测试"></a>测试</h4><ul>
<li>启动zookeeper</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kafka-server-start.sh /opt/kafka/config/server.properties &amp;</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 开启kafka服务（broker）</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这里是指定使用单个默认配置文件启动broker</span></span><br><span class="line"><span class="meta">		#</span><span class="bash"> 启动多个broker需要分别使用多个配置启动多次</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kafka-server-stop.sh /opt/kafka/config/server.properties</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kafka-topics.sh --create --zookeeper localhost:2181 \</span></span><br><span class="line"><span class="bash">	--replication-factor 1 \</span></span><br><span class="line"><span class="bash">	--partitions 1 \</span></span><br><span class="line"><span class="bash">	--topic test1</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 开启话题</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kafka-topics.sh --list zookeeper localhost:2181</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> </span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kafka-topics.shd --delete --zookeeper localhost:2181</span></span><br><span class="line">	--topic test1</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 关闭话题</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kafka-console-producer.sh --broker-list localhost:9092 \</span></span><br><span class="line"><span class="bash">	--topic test1</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 新终端开启producer，可以开始发送消息</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kafka-console-consumer.sh --bootstrap-server localhost:9092 \</span></span><br><span class="line"><span class="bash">	--topic test1 \</span></span><br><span class="line"><span class="bash">	--from-beginning</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kafka-console-consumer.sh --zookeeper localhost:2181 \</span></span><br><span class="line"><span class="bash">	--topic test1 \</span></span><br><span class="line"><span class="bash">	--from beginning</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 新终端开启consumer，可以开始接收信息</span></span><br><span class="line"><span class="meta">	#</span><span class="bash"> 这个好像是错的</span></span><br></pre></td></tr></table></figure>
<h3 id="其他-5"><a href="#其他-5" class="headerlink" title="其他"></a>其他</h3><h2 id="Storm"><a href="#Storm" class="headerlink" title="Storm"></a>Storm</h2><h3 id="依赖-8"><a href="#依赖-8" class="headerlink" title="依赖"></a>依赖</h3><ul>
<li>java</li>
<li>zookeeper</li>
<li>python2.6+</li>
<li>ZeroMQ、JZMQ</li>
</ul>
<h3 id="机器环境配置-5"><a href="#机器环境配置-5" class="headerlink" title="机器环境配置"></a>机器环境配置</h3><h4 id="bashrc-8"><a href="#bashrc-8" class="headerlink" title="~/.bashrc"></a><code>~/.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export STORM_HOME=/opt/storm</span><br><span class="line">export PAT=$PATH:$STORM_HOME/bin</span><br></pre></td></tr></table></figure>
<h3 id="Storm配置"><a href="#Storm配置" class="headerlink" title="Storm配置"></a>Storm配置</h3><h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><h5 id="conf-storm-yaml"><a href="#conf-storm-yaml" class="headerlink" title="conf/storm.yaml"></a><code>conf/storm.yaml</code></h5><ul>
<li>模板：<code>conf/storm.yarml</code></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">storm.zookeeper.servers:</span><br><span class="line">	-hd-master</span><br><span class="line">	-hd-slave1</span><br><span class="line">	-hd-slave2</span><br><span class="line">storm.zookeeper.port: 2181</span><br><span class="line"></span><br><span class="line">nimbus.seeds: [hd-master]</span><br><span class="line">storm.local.dir: /tmp/storm/tmp</span><br><span class="line">nimbus.host: hd-master</span><br><span class="line">supervisor.slots.ports:</span><br><span class="line">	-6700</span><br><span class="line">	-6701</span><br><span class="line">	-6702</span><br><span class="line">	-6703</span><br></pre></td></tr></table></figure>
<h4 id="启动、测试-1"><a href="#启动、测试-1" class="headerlink" title="启动、测试"></a>启动、测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">storm nimbus &amp;&gt; /dev/null &amp;</span><br><span class="line">storm logviewer &amp;&gt; /dev/null &amp;</span><br><span class="line">storm ui &amp;&gt; /dev/null &amp;</span><br><span class="line"><span class="meta">	#</span><span class="bash"> master节点启动nimbus</span></span><br><span class="line"></span><br><span class="line">storm sueprvisor &amp;&gt; /dev/null &amp;</span><br><span class="line">storm logviewer &amp;&gt; /dev/nulla &amp;</span><br><span class="line"><span class="meta">	#</span><span class="bash"> worker节点启动</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">storm jar /opt/storm/example/..../storm-start.jar \</span><br><span class="line">	storm.starter.WordCountTopology</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 测试用例</span></span><br><span class="line">stom kill WordCountTopology</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/r3.1.1">http://hadoop.apache.org/docs/r3.1.1</a></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Hadoop安装配置</p><p><a href="https://xyy15926.github.io/Database/Hadoop/hadoop_inset.html">https://xyy15926.github.io/Database/Hadoop/hadoop_inset.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>UBeaRLy</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2019-03-21</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2019-02-17</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Database/">Database</a><a class="link-muted mr-2" rel="tag" href="/tags/Hadoop/">Hadoop</a><a class="link-muted mr-2" rel="tag" href="/tags/Installment/">Installment</a><a class="link-muted mr-2" rel="tag" href="/tags/Setting/">Setting</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=610bd552640e160012f51469&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="https://z3.ax1x.com/2021/08/06/fmAPK0.jpg" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="https://z3.ax1x.com/2021/08/06/fmA9vq.jpg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Rust/struct_enum.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Rust 自定义数据类型</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/CS/Program-Design/design_pattern.html"><span class="level-item">设计模式简介</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "791fe01fc1e234f660aba442fdbdfb06",
            repo: "xyy15926.github.io",
            owner: "xyy15926",
            clientID: "af2bd51bbe151a8f6261",
            clientSecret: "f38f610edfe7bc367d5a20d22d43b10d887199eb",
            admin: ["xyy15926"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            language: "zh-CN",
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#Hadoop安装"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Hadoop安装</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖"><span class="level-left"><span class="level-item">1.1.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境配置"><span class="level-left"><span class="level-item">1.1.2</span><span class="level-item">机器环境配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc"><span class="level-left"><span class="level-item">1.1.2.1</span><span class="level-item">~/.bashrc</span></span></a></li><li><a class="level is-mobile" href="#etc-hosts"><span class="level-left"><span class="level-item">1.1.2.2</span><span class="level-item">/etc/hosts</span></span></a></li></ul></li></ul></li></ul><li><a class="level is-mobile" href="#todo-一定需要在-etc-hostname中设置各个主机名称"><span class="level-left"><span class="level-item">2</span><span class="level-item">todo?一定需要在/etc/hostname中设置各个主机名称</span></span></a><ul class="menu-list"><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#firewalld"><span class="level-left"><span class="level-item">2.1.1.1</span><span class="level-item">firewalld</span></span></a></li><li><a class="level is-mobile" href="#文件夹建立"><span class="level-left"><span class="level-item">2.1.1.2</span><span class="level-item">文件夹建立</span></span></a></li></ul><li><a class="level is-mobile" href="#Hadoop配置"><span class="level-left"><span class="level-item">2.1.2</span><span class="level-item">Hadoop配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Standalone-Operation"><span class="level-left"><span class="level-item">2.1.2.1</span><span class="level-item">Standalone Operation</span></span></a></li><li><a class="level is-mobile" href="#Pseudo-Distributed-Operation"><span class="level-left"><span class="level-item">2.1.2.2</span><span class="level-item">Pseudo-Distributed Operation</span></span></a></li><li><a class="level is-mobile" href="#Fully-Distributed-Operation"><span class="level-left"><span class="level-item">2.1.2.3</span><span class="level-item">Fully-Distributed Operation</span></span></a></li><li><a class="level is-mobile" href="#主从文件"><span class="level-left"><span class="level-item">2.1.2.4</span><span class="level-item">主从文件</span></span></a></li><li><a class="level is-mobile" href="#环境设置文件"><span class="level-left"><span class="level-item">2.1.2.5</span><span class="level-item">环境设置文件</span></span></a></li><li><a class="level is-mobile" href="#初始化、启动、测试"><span class="level-left"><span class="level-item">2.1.2.6</span><span class="level-item">初始化、启动、测试</span></span></a></li></ul></li><li><a class="level is-mobile" href="#其他"><span class="level-left"><span class="level-item">2.1.3</span><span class="level-item">其他</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#注意事项"><span class="level-left"><span class="level-item">2.1.3.1</span><span class="level-item">注意事项</span></span></a></li><li><a class="level is-mobile" href="#可能错误"><span class="level-left"><span class="level-item">2.1.3.2</span><span class="level-item">可能错误</span></span></a></li><li><a class="level is-mobile" href="#常用命令"><span class="level-left"><span class="level-item">2.1.3.3</span><span class="level-item">常用命令</span></span></a></li></ul></li></ul><li><a class="level is-mobile" href="#Hive"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Hive</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖-1"><span class="level-left"><span class="level-item">2.2.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境配置-1"><span class="level-left"><span class="level-item">2.2.2</span><span class="level-item">机器环境配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc-1"><span class="level-left"><span class="level-item">2.2.2.1</span><span class="level-item">~/.bashrc</span></span></a></li><li><a class="level is-mobile" href="#文件夹建立-1"><span class="level-left"><span class="level-item">2.2.2.2</span><span class="level-item">文件夹建立</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Hive配置"><span class="level-left"><span class="level-item">2.2.3</span><span class="level-item">Hive配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#XML参数"><span class="level-left"><span class="level-item">2.2.3.1</span><span class="level-item">XML参数</span></span></a></li><li><a class="level is-mobile" href="#环境设置文件-1"><span class="level-left"><span class="level-item">2.2.3.2</span><span class="level-item">环境设置文件</span></span></a></li><li><a class="level is-mobile" href="#MetaStore"><span class="level-left"><span class="level-item">2.2.3.3</span><span class="level-item">MetaStore</span></span></a></li><li><a class="level is-mobile" href="#服务设置"><span class="level-left"><span class="level-item">2.2.3.4</span><span class="level-item">服务设置</span></span></a></li><li><a class="level is-mobile" href="#测试-1"><span class="level-left"><span class="level-item">2.2.3.5</span><span class="level-item">测试</span></span></a></li></ul></li><li><a class="level is-mobile" href="#其他-1"><span class="level-left"><span class="level-item">2.2.4</span><span class="level-item">其他</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#可能错误-1"><span class="level-left"><span class="level-item">2.2.4.1</span><span class="level-item">可能错误</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Tez"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Tez</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖-2"><span class="level-left"><span class="level-item">2.3.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境配置-2"><span class="level-left"><span class="level-item">2.3.2</span><span class="level-item">机器环境配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc-2"><span class="level-left"><span class="level-item">2.3.2.1</span><span class="level-item">.bashrc</span></span></a></li><li><a class="level is-mobile" href="#HDFS-2"><span class="level-left"><span class="level-item">2.3.2.2</span><span class="level-item">HDFS</span></span></a></li></ul></li><li><a class="level is-mobile" href="#HadoopOnTez"><span class="level-left"><span class="level-item">2.3.3</span><span class="level-item">HadoopOnTez</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#XML参数-1"><span class="level-left"><span class="level-item">2.3.3.1</span><span class="level-item">XML参数</span></span></a></li><li><a class="level is-mobile" href="#环境参数"><span class="level-left"><span class="level-item">2.3.3.2</span><span class="level-item">环境参数</span></span></a></li></ul></li><li><a class="level is-mobile" href="#HiveOnTez"><span class="level-left"><span class="level-item">2.3.4</span><span class="level-item">HiveOnTez</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Hive设置"><span class="level-left"><span class="level-item">2.3.4.1</span><span class="level-item">Hive设置</span></span></a></li></ul></li><li><a class="level is-mobile" href="#其他-2"><span class="level-left"><span class="level-item">2.3.5</span><span class="level-item">其他</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#可能错误-2"><span class="level-left"><span class="level-item">2.3.5.1</span><span class="level-item">可能错误</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Spark"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">Spark</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖-3"><span class="level-left"><span class="level-item">2.4.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境配置-3"><span class="level-left"><span class="level-item">2.4.2</span><span class="level-item">机器环境配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc-3"><span class="level-left"><span class="level-item">2.4.2.1</span><span class="level-item">~/.bashrc</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Standalone"><span class="level-left"><span class="level-item">2.4.3</span><span class="level-item">Standalone</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#环境设置文件-2"><span class="level-left"><span class="level-item">2.4.3.1</span><span class="level-item">环境设置文件</span></span></a></li><li><a class="level is-mobile" href="#Spark配置"><span class="level-left"><span class="level-item">2.4.3.2</span><span class="level-item">Spark配置</span></span></a></li><li><a class="level is-mobile" href="#测试-2"><span class="level-left"><span class="level-item">2.4.3.3</span><span class="level-item">测试</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Spark-on-YARN"><span class="level-left"><span class="level-item">2.4.4</span><span class="level-item">Spark on YARN</span></span></a></li><li><a class="level is-mobile" href="#其他-3"><span class="level-left"><span class="level-item">2.4.5</span><span class="level-item">其他</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#可能错误-3"><span class="level-left"><span class="level-item">2.4.5.1</span><span class="level-item">可能错误</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#HBase"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">HBase</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖-4"><span class="level-left"><span class="level-item">2.5.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境"><span class="level-left"><span class="level-item">2.5.2</span><span class="level-item">机器环境</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc-4"><span class="level-left"><span class="level-item">2.5.2.1</span><span class="level-item">~/.bashrc</span></span></a></li><li><a class="level is-mobile" href="#建立目录"><span class="level-left"><span class="level-item">2.5.2.2</span><span class="level-item">建立目录</span></span></a></li></ul></li><li><a class="level is-mobile" href="#HBase配置"><span class="level-left"><span class="level-item">2.5.3</span><span class="level-item">HBase配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#环境变量"><span class="level-left"><span class="level-item">2.5.3.1</span><span class="level-item">环境变量</span></span></a></li><li><a class="level is-mobile" href="#Standalone模式"><span class="level-left"><span class="level-item">2.5.3.2</span><span class="level-item">Standalone模式</span></span></a></li><li><a class="level is-mobile" href="#Pseudo-Distributed模式"><span class="level-left"><span class="level-item">2.5.3.3</span><span class="level-item">Pseudo-Distributed模式</span></span></a></li><li><a class="level is-mobile" href="#Fully-Distributed模式"><span class="level-left"><span class="level-item">2.5.3.4</span><span class="level-item">Fully-Distributed模式</span></span></a></li><li><a class="level is-mobile" href="#测试-3"><span class="level-left"><span class="level-item">2.5.3.5</span><span class="level-item">测试</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Zookeeper"><span class="level-left"><span class="level-item">2.6</span><span class="level-item">Zookeeper</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖-5"><span class="level-left"><span class="level-item">2.6.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境-1"><span class="level-left"><span class="level-item">2.6.2</span><span class="level-item">机器环境</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc-5"><span class="level-left"><span class="level-item">2.6.2.1</span><span class="level-item">~/.bashrc</span></span></a></li><li><a class="level is-mobile" href="#创建文件夹"><span class="level-left"><span class="level-item">2.6.2.2</span><span class="level-item">创建文件夹</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Zookeeper配置"><span class="level-left"><span class="level-item">2.6.3</span><span class="level-item">Zookeeper配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Conf"><span class="level-left"><span class="level-item">2.6.3.1</span><span class="level-item">Conf</span></span></a></li><li><a class="level is-mobile" href="#启动、测试、清理"><span class="level-left"><span class="level-item">2.6.3.2</span><span class="level-item">启动、测试、清理</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Flume"><span class="level-left"><span class="level-item">2.7</span><span class="level-item">Flume</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖-6"><span class="level-left"><span class="level-item">2.7.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境配置-4"><span class="level-left"><span class="level-item">2.7.2</span><span class="level-item">机器环境配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc-6"><span class="level-left"><span class="level-item">2.7.2.1</span><span class="level-item">~/.bashrc</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Flume配置"><span class="level-left"><span class="level-item">2.7.3</span><span class="level-item">Flume配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#环境设置文件-3"><span class="level-left"><span class="level-item">2.7.3.1</span><span class="level-item">环境设置文件</span></span></a></li><li><a class="level is-mobile" href="#Conf文件"><span class="level-left"><span class="level-item">2.7.3.2</span><span class="level-item">Conf文件</span></span></a></li><li><a class="level is-mobile" href="#启动、测试"><span class="level-left"><span class="level-item">2.7.3.3</span><span class="level-item">启动、测试</span></span></a></li></ul></li><li><a class="level is-mobile" href="#其他-4"><span class="level-left"><span class="level-item">2.7.4</span><span class="level-item">其他</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Kafka"><span class="level-left"><span class="level-item">2.8</span><span class="level-item">Kafka</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖-7"><span class="level-left"><span class="level-item">2.8.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境变量"><span class="level-left"><span class="level-item">2.8.2</span><span class="level-item">机器环境变量</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc-7"><span class="level-left"><span class="level-item">2.8.2.1</span><span class="level-item">~/.bashrc</span></span></a></li></ul></li><li><a class="level is-mobile" href="#多brokers配置"><span class="level-left"><span class="level-item">2.8.3</span><span class="level-item">多brokers配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Conf-1"><span class="level-left"><span class="level-item">2.8.3.1</span><span class="level-item">Conf</span></span></a></li><li><a class="level is-mobile" href="#测试-4"><span class="level-left"><span class="level-item">2.8.3.2</span><span class="level-item">测试</span></span></a></li></ul></li><li><a class="level is-mobile" href="#其他-5"><span class="level-left"><span class="level-item">2.8.4</span><span class="level-item">其他</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Storm"><span class="level-left"><span class="level-item">2.9</span><span class="level-item">Storm</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#依赖-8"><span class="level-left"><span class="level-item">2.9.1</span><span class="level-item">依赖</span></span></a></li><li><a class="level is-mobile" href="#机器环境配置-5"><span class="level-left"><span class="level-item">2.9.2</span><span class="level-item">机器环境配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#bashrc-8"><span class="level-left"><span class="level-item">2.9.2.1</span><span class="level-item">~/.bashrc</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Storm配置"><span class="level-left"><span class="level-item">2.9.3</span><span class="level-item">Storm配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#配置文件"><span class="level-left"><span class="level-item">2.9.3.1</span><span class="level-item">配置文件</span></span></a></li><li><a class="level is-mobile" href="#启动、测试-1"><span class="level-left"><span class="level-item">2.9.3.2</span><span class="level-item">启动、测试</span></span></a></li></ul></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5385776267343559" data-ad-slot="6995841235" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="https://api.follow.it/subscription-form/WWxwMVBsOUtoNTdMSlJ4Z1lWVnRISERsd2t6ek9MeVpEUWs0YldlZGxUdXlKdDNmMEZVV1hWaFZFYWFSNmFKL25penZodWx3UzRiaVkxcnREWCtOYUJhZWhNbWpzaUdyc1hPangycUh5RTVjRXFnZnFGdVdSTzZvVzJBcTJHKzl8aXpDK1ROWWl4N080YkFEK3QvbEVWNEJuQjFqdWdxODZQcGNoM1NqbERXST0=/8" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>