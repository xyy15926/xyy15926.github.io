<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: Math - UBeaRLy</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="UBeaRLy"><meta property="og:url" content="https://xyy15926.github.io/"><meta property="og:site_name" content="UBeaRLy"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:author" content="UBeaRLy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io"},"headline":"UBeaRLy","image":["https://xyy15926.github.io/img/og_image.png"],"author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"UBeaRLy","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":""}</script><link rel="alternate" href="/atom.xml" title="UBeaRLy" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Math</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-13T15:45:15.000Z" title="7/13/2019, 11:45:15 PM">2019-07-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-13T04:03:11.000Z" title="7/13/2019, 12:03:11 PM">2019-07-13</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a></span><span class="level-item">16 minutes read (About 2380 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/func_kernels.html">Kernel Function</a></h1><div class="content"><h2 id="Kernel-Function"><a href="#Kernel-Function" class="headerlink" title="Kernel Function"></a>Kernel Function</h2><blockquote>
<ul>
<li>对输入空间 $X$ （欧式空间 $R^n$ 的子集或离散集合）、特征空间 $H$ ，若存在从映射 $$<pre><code>  \phi(x): X \rightarrow H
</code></pre><script type="math/tex; mode=display">使得对所有 $x, z \in X$ ，函数 $K(x,z)$ 满足</script><pre><code>  K(x,z) = \phi(x) \phi(z)
</code></pre>  $$ 则称 $K(x,z)$ 为核函数、 $\phi(x)$ 为映射函数，其中 $\phi(x) \phi(z)$ 表示内积</li>
</ul>
</blockquote>
<ul>
<li>特征空间 $H$ 一般为无穷维<ul>
<li>特征空间必须为希尔伯特空间（内积完备空间）</li>
</ul>
</li>
</ul>
<h3 id="映射函数-phi"><a href="#映射函数-phi" class="headerlink" title="映射函数 $\phi$"></a>映射函数 $\phi$</h3><ul>
<li><p>映射函数 $\phi$：输入空间 $R^n$ 到特征空间的映射 $H$ 的映射</p>
</li>
<li><p>对于给定的核 $K(x,z)$ ，映射函数取法不唯一，映射目标的特征空间可以不同，同一特征空间也可以取不同映射，如：</p>
<ul>
<li><p>对核函数 $K(x, y) = (x y)^2$ ，输入空间为 $R^2$ ，有</p>
<script type="math/tex; mode=display">\begin{align*}
(xy)^2 & = (x_1y_1 + x_2y_2)^2 \\
& = (x_1y_1)^2 + 2x_1y_1x_2y_2 + (x_2y_2)^2
\end{align*}</script></li>
<li><p>若特征空间为$R^3$，取映射</p>
<script type="math/tex; mode=display">\phi(x) = (x_1^2, \sqrt 2 x_1x_2, x_2^2)^T</script><p>或取映射</p>
<script type="math/tex; mode=display">
\phi(x) = \frac 1 {\sqrt 2} (x_1^2 - x_2^2, 2x_1x_2, x_1^2 + x_2^2)^T</script></li>
<li><p>若特征空间为$R^4$，取映射</p>
<script type="math/tex; mode=display">
\phi(x) = (x_1^2, x_1x_2, x_1x_2, x_2^2)^T</script></li>
</ul>
</li>
</ul>
<h3 id="核函数-K-x-z"><a href="#核函数-K-x-z" class="headerlink" title="核函数 $K(x,z)$"></a>核函数 $K(x,z)$</h3><ul>
<li><p><em>Kernel Trick</em> 核技巧：利用核函数简化映射函数 $\phi(x)$ 映射、内积的计算技巧</p>
<ul>
<li>避免实际计算映射函数</li>
<li>避免高维向量空间向量的存储</li>
</ul>
</li>
<li><p>核函数即在核技巧中应用的函数</p>
<ul>
<li>实务中往往寻找到的合适的核函数即可，不关心对应的映射函数</li>
<li>单个核函数可以对应多个映射、特征空间</li>
</ul>
</li>
<li><p>核技巧常被用于分类器中</p>
<ul>
<li>根据 <em>Cover’s</em> 定理，核技巧可用于非线性分类问题，如在 <em>SVM</em> 中常用</li>
<li>核函数的作用范围：梯度变化较大的区域<ul>
<li>梯度变化小的区域，核函数值变化不大，所以没有区分能力</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li><em>Cover’s</em> 定理可以简单表述为：非线性分类问题映射到高维空间后更有可能线性可分</li>
</ul>
</blockquote>
<h4 id="正定核函数"><a href="#正定核函数" class="headerlink" title="正定核函数"></a>正定核函数</h4><blockquote>
<ul>
<li>设 $X \subset R^n$，$K(x,z)$ 是定义在 $X <em> X$的对称函数，若 $\forall x_i \in \mathcal{X}, i=1,2,…,m$，$K(x,z)$ 对应的 </em>Gram* 矩阵 $$<pre><code>  G = [K(x_i, x_j)]_&#123;m*m&#125;
</code></pre>  $$ 是半正定矩阵，则称 $K(x,z)$ 为正定核</li>
</ul>
</blockquote>
<ul>
<li>可用于指导构造核函数<ul>
<li>检验具体函数是否为正定核函数不容易</li>
<li>正定核具有优秀性质<ul>
<li><em>SVM</em> 中正定核能保证优化问题为凸二次规划，即二次规划中矩阵 $G$ 为正定矩阵</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="欧式空间核函数"><a href="#欧式空间核函数" class="headerlink" title="欧式空间核函数"></a>欧式空间核函数</h2><h3 id="Linear-Kernel"><a href="#Linear-Kernel" class="headerlink" title="Linear Kernel"></a><em>Linear Kernel</em></h3><p>线性核：最简单的核函数</p>
<script type="math/tex; mode=display">
k(x, y) = x^T y</script><ul>
<li>特点<ul>
<li>适用线性核的核算法通常同普通算法结果相同<ul>
<li><em>KPCA</em> 使用线性核等同于普通 <em>PCA</em></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Polynomial-Kernel"><a href="#Polynomial-Kernel" class="headerlink" title="Polynomial Kernel"></a><em>Polynomial Kernel</em></h3><p>多项式核：<em>non-stational kernel</em></p>
<script type="math/tex; mode=display">
K(x, y) = (\alpha x^T y + c)^p</script><ul>
<li><p>特点</p>
<ul>
<li>适合正交归一化后的数据</li>
<li>参数较多，稳定<h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1></li>
</ul>
</li>
<li><p>应用场合</p>
<ul>
<li><p>SVM：<em>p</em> 次多项式分类器</p>
<script type="math/tex; mode=display">
f(x) = sgn(\sum_{i=1}^{N_s} \alpha_i^{*} y_i
  (x_i x + 1)^p + b^{*})</script></li>
</ul>
</li>
</ul>
<h3 id="Gaussian-Kernel"><a href="#Gaussian-Kernel" class="headerlink" title="Gaussian Kernel"></a><em>Gaussian Kernel</em></h3><p>高斯核：<em>radial basis kernel</em>，经典的稳健径向基核</p>
<script type="math/tex; mode=display">
K(x, y) = exp(-\frac {\|x - y\|^2} {2\sigma^2})</script><blockquote>
<ul>
<li>$\sigma$：带通，取值关于核函数效果，影响高斯分布形状<blockquote>
<ul>
<li>高估：分布过于集中，靠近边缘非常平缓，表现类似像线性一样，非线性能力失效</li>
<li>低估：分布过于平缓，失去正则化能力，决策边界对噪声高度敏感</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<ul>
<li><p>特点</p>
<ul>
<li>对数据中噪声有较好的抗干扰能力</li>
</ul>
</li>
<li><p>对应映射：省略分母</p>
<script type="math/tex; mode=display">\begin{align*}
K(x, y) & = exp(-(x - y)^2)  \\
& = exp(-(x^2 - 2 x y - y^2)) \\
& = exp(-x^2) exp(-y^2) exp(2xy) \\
& = exp(-x^2) exp(-y^2) \sum_{i=0}^\infty \frac {(2xy)^i} {i!} \\
& = \phi(x) \phi(y) \\
\phi(x) & = exp(-x^2)\sum_{i=0}^\infty \sqrt {\frac {2^i} {i!}} x^i
\end{align*}</script><p>即高斯核能够把数据映射至无穷维</p>
</li>
<li><p>应用场合</p>
<ul>
<li><p>SVM：高斯<em>radial basis function</em>分类器</p>
<script type="math/tex; mode=display">
f(x) = sgn(\sum_{i=1}^{N_s} \alpha_i^{*} y_i
  exp(-\frac {\|x - y\|^2} {2\sigma^2}) + b^{*})</script></li>
</ul>
</li>
</ul>
<h4 id="Exponential-Kernel"><a href="#Exponential-Kernel" class="headerlink" title="Exponential Kernel"></a><em>Exponential Kernel</em></h4><p>指数核：高斯核变种，仅去掉范数的平方，也是径向基核</p>
<script type="math/tex; mode=display">
K(x, y) = exp(-\frac {\|x - y\|} {2\sigma^2})</script><ul>
<li>降低了对参数的依赖性</li>
<li>适用范围相对狭窄</li>
</ul>
<h4 id="Laplacian-Kernel"><a href="#Laplacian-Kernel" class="headerlink" title="Laplacian Kernel"></a><em>Laplacian Kernel</em></h4><p>拉普拉斯核：完全等同于的指数核，只是对参数$\sigma$改变敏感
性稍低，也是径向基核</p>
<script type="math/tex; mode=display">
K(x, y) = exp(-\frac {\|x - y\|} {\sigma^2})</script><h4 id="ANOVA-Kernel"><a href="#ANOVA-Kernel" class="headerlink" title="ANOVA Kernel"></a><em>ANOVA Kernel</em></h4><p>方差核：径向基核</p>
<script type="math/tex; mode=display">
k(x,y) = \sum_{k=1}^n exp(-\sigma(x^k - y^k)^2)^d</script><ul>
<li>在多维回归问题中效果很好</li>
</ul>
<h4 id="Hyperbolic-Tangent-Sigmoid-Multilayer-Perceptron-Kernel"><a href="#Hyperbolic-Tangent-Sigmoid-Multilayer-Perceptron-Kernel" class="headerlink" title="Hyperbolic Tangent/Sigmoid/Multilayer Perceptron Kernel"></a><em>Hyperbolic Tangent/Sigmoid/Multilayer Perceptron Kernel</em></h4><p>Sigmoid核：来自神经网络领域，被用作人工神经元的激活函数</p>
<script type="math/tex; mode=display">
k(x, y) = tanh(\alpha x^T y + c)</script><ul>
<li><p>条件正定，但是实际应用中效果不错</p>
</li>
<li><p>参数</p>
<ul>
<li>$\alpha$：通常设置为$1/N$，N是数据维度</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>使用Sigmoid核的SVM等同于两层感知机神经网络</li>
</ul>
</blockquote>
<h4 id="Ration-Quadratic-Kernel"><a href="#Ration-Quadratic-Kernel" class="headerlink" title="Ration Quadratic Kernel"></a><em>Ration Quadratic Kernel</em></h4><p>二次有理核：替代高斯核，计算耗时较小</p>
<script type="math/tex; mode=display">
k(x, y) = 1 - \frac {\|x - y\|^2} {\|x - y\|^2 + c}</script><h4 id="Multiquadric-Kernel"><a href="#Multiquadric-Kernel" class="headerlink" title="Multiquadric Kernel"></a><em>Multiquadric Kernel</em></h4><p>多元二次核：适用范围同二次有理核，是非正定核</p>
<script type="math/tex; mode=display">
k(x, y) = \sqrt {\|x - y\|^2 + c^2}</script><h4 id="Inverse-Multiquadric-Kernel"><a href="#Inverse-Multiquadric-Kernel" class="headerlink" title="Inverse Multiquadric Kernel"></a><em>Inverse Multiquadric Kernel</em></h4><p>逆多元二次核：和高斯核一样，产生满秩核矩阵，产生无穷维的
特征空间</p>
<script type="math/tex; mode=display">
k(x, y) = \frac 1 {\sqrt {\|x - y\|^2 + c^2}}</script><h4 id="Circular-Kernel"><a href="#Circular-Kernel" class="headerlink" title="Circular Kernel"></a><em>Circular Kernel</em></h4><p>环形核：从统计角度考虑的核，各向同性稳定核，在$R^2$上正定</p>
<script type="math/tex; mode=display">
k(x, y) = \frac 2 \pi arccos(-\frac {\|x - y\|} \sigma) -
    \frac 2 \pi \frac {\|x - y\|} \sigma
    \sqrt{1- \frac {\|x - y\|^2} \sigma}</script><h4 id="Spherical-Kernel"><a href="#Spherical-Kernel" class="headerlink" title="Spherical Kernel"></a><em>Spherical Kernel</em></h4><p>类似环形核，在$R^3$上正定</p>
<script type="math/tex; mode=display">
k(x, y) = 1 - \frac 3 2 \frac {\|x - y\|} \sigma +
    \frac 1 2 (\frac {\|x - y\|} \sigma)^3</script><h4 id="Wave-Kernel"><a href="#Wave-Kernel" class="headerlink" title="Wave Kernel"></a><em>Wave Kernel</em></h4><p>波动核</p>
<script type="math/tex; mode=display">
k(x, y) = \frac \theta {\|x - y\|} sin(\frac {\|x - y\|}
    \theta)</script><ul>
<li>适用于语音处理场景</li>
</ul>
<h4 id="Triangular-Power-Kernel"><a href="#Triangular-Power-Kernel" class="headerlink" title="Triangular/Power Kernel"></a><em>Triangular/Power Kernel</em></h4><p>三角核/幂核：量纲不变核，条件正定</p>
<script type="math/tex; mode=display">
k(x, y) = - \|x - y\|^d</script><h4 id="Log-Kernel"><a href="#Log-Kernel" class="headerlink" title="Log Kernel"></a><em>Log Kernel</em></h4><p>对数核：在图像分隔上经常被使用，条件正定</p>
<script type="math/tex; mode=display">
k(x, y) = -log(1 + \|x - y\|^d)</script><h4 id="Spline-Kernel"><a href="#Spline-Kernel" class="headerlink" title="Spline Kernel"></a><em>Spline Kernel</em></h4><p>样条核：以分段三次多项式形式给出</p>
<script type="math/tex; mode=display">
k(x, y) = 1 + x^t y + x^t y min(x, y) - \frac {x + y} 2
    min(x, y)^2 + \frac 1 3 min(x, y)^2</script><h4 id="B-Spline-Kernel"><a href="#B-Spline-Kernel" class="headerlink" title="B-Spline Kernel"></a><em>B-Spline Kernel</em></h4><p>B-样条核：径向基核，通过递归形式给出</p>
<script type="math/tex; mode=display">\begin{align*}
k(x, y) & = \prod_{p=1}^d B_{2n+1}(x_p - y_p) \\
B_n(x) & = B_{n-1} \otimes B_0 \\
& = \frac 1 {n!} \sum_{k=0}^{n+1} \binom {n+1} {r}
    (-1)^k (x + \frac {n+1} 2 - k)_{+}^n
\end{align*}</script><blockquote>
<ul>
<li>$x_{+}^d$：截断幂函数<script type="math/tex; mode=display">x_{+}^d = \left \{ \begin{array}{l}
      x^d, & if x > 0 \\
      0, & otherwise \\
  \end{array} \right.</script></li>
</ul>
</blockquote>
<h4 id="Bessel-Kernel"><a href="#Bessel-Kernel" class="headerlink" title="Bessel Kernel"></a><em>Bessel Kernel</em></h4><p>Bessel核：在theory of function spaces of fractional smoothness
中非常有名</p>
<script type="math/tex; mode=display">
k(x, y) = \frac {J_{v+1}(\sigma\|x - y\|)}
    {\|x - y\|^{-n(v + 1)}}</script><ul>
<li>$J$：第一类Bessel函数</li>
</ul>
<h4 id="Cauchy-Kernel"><a href="#Cauchy-Kernel" class="headerlink" title="Cauchy Kernel"></a><em>Cauchy Kernel</em></h4><p>柯西核：源自柯西分布，是长尾核，定义域广泛，可以用于原始维度
很高的数据</p>
<script type="math/tex; mode=display">
k(x, y) = \frac 1 {1 + \frac {\|x - y\|^2} {\sigma}}</script><h4 id="Chi-Square-Kernel"><a href="#Chi-Square-Kernel" class="headerlink" title="Chi-Square Kernel"></a><em>Chi-Square Kernel</em></h4><p>卡方核：源自卡方分布</p>
<script type="math/tex; mode=display">\begin{align*}
k(x, y) & = 1 - \sum_{i=1}^d \frac {(x_i - y_i)^2}
    {\frac 1 2 (x_i + y_i)} \\
& \frac {x^t y} {\|x + y\|}
\end{align*}</script><h4 id="Histogram-Intersection-Min-Kernel"><a href="#Histogram-Intersection-Min-Kernel" class="headerlink" title="Histogram Intersection/Min Kernel"></a><em>Histogram Intersection/Min Kernel</em></h4><p>直方图交叉核：在图像分类中经常用到，适用于图像的直方图特征</p>
<script type="math/tex; mode=display">
k(x, y) = \sum_{i=1}^d min(x_i, y_i)</script><h4 id="Generalized-Histogram-Intersection"><a href="#Generalized-Histogram-Intersection" class="headerlink" title="Generalized Histogram Intersection"></a><em>Generalized Histogram Intersection</em></h4><p>广义直方图交叉核：直方图交叉核的扩展，可以应用于更多领域</p>
<script type="math/tex; mode=display">
k(x, y) = \sum_{i=1}^m min(|x_i|^\alpha, |y_i|^\beta)</script><h4 id="Bayesian-Kernel"><a href="#Bayesian-Kernel" class="headerlink" title="Bayesian Kernel"></a><em>Bayesian Kernel</em></h4><p>贝叶斯核：取决于建模的问题</p>
<script type="math/tex; mode=display">\begin{align*}
k(x, y) & = \prod_{i=1}^d k_i (x_i, y_i) \\
k_i(a, b) & = \sum_{c \in \{0, 1\}} P(Y=c | X_i = a)
    P(Y=c | x_k = b)
\end{align*}</script><h4 id="Wavelet-Kernel"><a href="#Wavelet-Kernel" class="headerlink" title="Wavelet Kernel"></a><em>Wavelet Kernel</em></h4><p>波核：源自波理论</p>
<script type="math/tex; mode=display">
k(x, y) = \prod_{i=1}^d h(\frac {x_i - c} a)
    h(\frac {y_i - c} a)</script><ul>
<li><p>参数</p>
<ul>
<li>$c$：波的膨胀速率</li>
<li>$a$：波的转化速率</li>
<li>$h$：母波函数，可能的一个函数为<script type="math/tex; mode=display">
h(x) = cos(1.75 x) exp(-\frac {x^2} 2)</script></li>
</ul>
</li>
<li><p>转化不变版本如下</p>
<script type="math/tex; mode=display">
k(x, y) = \prod_{i=1}^d h(\frac {x_i - y_i} a)</script></li>
</ul>
<h2 id="离散数据核函数"><a href="#离散数据核函数" class="headerlink" title="离散数据核函数"></a>离散数据核函数</h2><h3 id="String-Kernel"><a href="#String-Kernel" class="headerlink" title="String Kernel"></a><em>String Kernel</em></h3><p>字符串核函数：定义在字符串集合（离散数据集合）上的核函数</p>
<script type="math/tex; mode=display">\begin{align*}
k_n(s, t) & = \sum_{u \in \sum^n} [\phi_n(s)]_u
    [\phi_n(t)]_u \\
& = \sum_{u \in \sum^n} \sum_{(i,j): s(i) = t(j) = u}
    \lambda^{l(i)} \lambda^{l(j)}
\end{align*}</script><blockquote>
<ul>
<li><p>$[\phi<em>n(s)]_n = \sum</em>{i:s(i)=u} \lambda^{l(i)}$：长度
  大于等于n的字符串集合$S$到特征空间
  $\mathcal{H} = R^{\sum^n}$的映射，目标特征空间每维对应
  一个字符串$u \in \sum^n$</p>
</li>
<li><p>$\sum$：有限字符表</p>
</li>
<li><p>$\sum^n$：$\sum$中元素构成，长度为n的字符串集合</p>
</li>
<li><p>$u = s(i) = s(i<em>1)s(i_2)\cdots s(i</em>{|u|})$：字符串s的
  子串u（其自身也可以用此方式表示）</p>
</li>
<li><p>$i =(i<em>1, i_2, \cdots, i</em>{|u|}), 1 \leq i<em>1 &lt; i_2 &lt; … &lt; i</em>{|u|} \leq |s|$：序列指标</p>
</li>
<li><p>$l(i) = i_{|u|} - i_1 + 1 \geq |u|$：字符串长度，仅在
  序列指标$i$连续时取等号（$j$同）</p>
</li>
<li><p>$0 &lt; \lambda \leq 1$：衰减参数</p>
</li>
</ul>
</blockquote>
<ul>
<li><p>两个字符串s、t上的字符串核函数，是基于映射$\phi_n$的
特征空间中的内积</p>
<ul>
<li>给出了字符串中长度为n的所有子串组成的特征向量的余弦
相似度</li>
<li>直观上，两字符串相同子串越多，其越相似，核函数值越大</li>
<li>核函数值可由动态规划快速计算（只需要计算两字符串公共
子序列即可）</li>
</ul>
</li>
<li><p>应用场合</p>
<ul>
<li>文本分类</li>
<li>信息检索</li>
<li>信物信息学</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-13T15:44:28.000Z" title="7/13/2019, 11:44:28 PM">2019-07-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-13T04:03:11.000Z" title="7/13/2019, 12:03:11 PM">2019-07-13</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a></span><span class="level-item">a few seconds read (About 30 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/README.html">函数说明</a></h1><div class="content"><h2 id="约定"><a href="#约定" class="headerlink" title="约定"></a>约定</h2><ul>
<li><p><code>I</code>：示性/指示函数</p>
<ul>
<li>满足条件时取1，否则取0</li>
</ul>
</li>
<li><p><code>sign</code>：符号函数</p>
<ul>
<li><code>&gt;0</code>：取1</li>
<li><code>&lt;0</code>：取-1</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-06-26T17:01:10.000Z" title="6/27/2019, 1:01:10 AM">2019-06-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-06-26T17:01:10.000Z" title="6/27/2019, 1:01:10 AM">2019-06-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">7 minutes read (About 999 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/lagrange_duality.html">Lagrange 对偶</a></h1><div class="content"><h2 id="Langrangian-Duality"><a href="#Langrangian-Duality" class="headerlink" title="Langrangian Duality"></a><em>Langrangian Duality</em></h2><p>拉格朗日对偶</p>
<ul>
<li><p>考虑优化问题：找到$f(x)$满足约束的最好下界</p>
<script type="math/tex; mode=display">
z^{*} = \min_{x} f(x) \\
\begin{align*}
s.t. \quad & g_i(x) \leq 0, i=1,2,\cdots,m \\
   & x \in X
\end{align*}</script></li>
<li><p>考虑方程组</p>
<script type="math/tex; mode=display">
\left \{ \begin{array}{l}
f(x) < v \\
g_i(x) \leq 0, i=1,2,\cdots,m
\end{array} \right.</script><ul>
<li><p><strong>方程组无解</strong>：$v$是优化问题的一个下界</p>
</li>
<li><p><strong>方程组有解</strong>：则可以推出</p>
<script type="math/tex; mode=display">
\forall \lambda \geq 0, \exists x, 
f(x) + \sum_{i=1}^m \lambda_ig_i(x) < v</script><blockquote>
<ul>
<li>显然，取$g_1 + g_2 = 0, g_1(x) &gt; 0$是反例，不能
推出原方程有解</li>
</ul>
</blockquote>
</li>
<li><p>由以上方程组有解逆否命题：方程组无解<strong>充分条件</strong>如下</p>
<script type="math/tex; mode=display">
\exists \lambda \geq 0,
\min_{x} f(x) + \sum _{i=1}^m \lambda_ig_i(x) \geq v</script></li>
</ul>
</li>
<li><p>由此方法推出的最好下界，即拉格朗日对偶问题</p>
<script type="math/tex; mode=display">
v^{*} = \max_{\lambda \geq 0} \min_{x} f(x) +
   \sum_{i=1}^m \lambda_ig_i(x)</script></li>
</ul>
<h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul>
<li><p>拉格朗日对偶对实数域上的优化问题都存在，对目标函数、
约束函数都没有要求</p>
</li>
<li><p>强对偶定理：$v^{<em>} = z^{</em>}$，需要$f,g$满足特定条件才成立</p>
<ul>
<li>线性规划</li>
<li>半正定规划</li>
<li>凸优化</li>
</ul>
<blockquote>
<ul>
<li>即需要给约束条件加以限制，使得<script type="math/tex; mode=display">
 \forall \lambda \geq 0, \exists x, 
 f(x) + \sum_{i=1}^m \lambda_ig_i(x) < v</script> 是上述方程组有解的冲要条件</li>
</ul>
</blockquote>
</li>
<li><p>弱对偶定理：$v^{<em>} \leq z^{</em>}$，永远成立（以上即可证）</p>
<ul>
<li>通过弱对偶定理，可以得到原问题的一个下界</li>
<li>对求解原问题有帮助，比如：分支界限法中快速求下界</li>
</ul>
</li>
<li><p>对偶问题相关算法往往原问题算法在实际应用中往往更加有效</p>
<ul>
<li><em>dual-simplex</em></li>
<li><em>primal-dual interior point method</em></li>
<li><em>augmented Lagrangian Method</em></li>
</ul>
</li>
</ul>
<h2 id="原始问题"><a href="#原始问题" class="headerlink" title="原始问题"></a>原始问题</h2><p>约束最优化问题</p>
<script type="math/tex; mode=display">\begin{array}{l}
\min_{x \in R^n} & f(x) \\
s.t. & c_i(x) \leq 0, i = 1,2,\cdots,k \\
& h_j(x) = 0, j = 1,2,\cdots,l
\end{array}</script><h3 id="Generalized-Lagrange-Function"><a href="#Generalized-Lagrange-Function" class="headerlink" title="Generalized Lagrange Function"></a><em>Generalized Lagrange Function</em></h3><ul>
<li><p>引入<em>Generalized Lagrange Function</em></p>
<script type="math/tex; mode=display">
L(x, \alpha, \beta) = f(x) + \sum_{i=1}^k \alpha_i
   c_i(x) + \sum_{j=1}^l \beta_j h_j(x)</script><blockquote>
<ul>
<li>$x=(x_1, x_2, \cdots, x_n) \in R^n$</li>
<li>$\alpha_i \geq 0, \beta_j$：拉格朗日乘子</li>
</ul>
</blockquote>
</li>
<li><p>考虑关于x的函数</p>
<script type="math/tex; mode=display">
\theta_P(x) = \max_{\alpha, \beta: \alpha_i \geq 0}
   L(x, \alpha, \beta)</script><blockquote>
<ul>
<li>$P$：primal，原始问题</li>
</ul>
</blockquote>
<ul>
<li><p>若x满足原始问题的两组约束条件，则$\theta_P(x)=f(x)$</p>
</li>
<li><p>若x违反等式约束j，取$\beta_j \rightarrow \infty$，
则有$\theta_P(x) \rightarrow \infty$</p>
</li>
<li><p>若x违反不等式约束i，取$\alpha_i \rightarrow \infty$
，则有$\theta_P(x) \rightarrow \infty$</p>
</li>
</ul>
<p>则有</p>
<script type="math/tex; mode=display">\theta_P(x) = \left \{ \begin{array}{l}
f(x), & x 满足原始问题约束条件 \\
+\infty, & 其他
\end{array} \right.</script></li>
<li><p>则极小化问题，称为广义拉格朗日函数的极小极大问题</p>
<script type="math/tex; mode=display">
\min_x \theta_P(x) = \max_{\alpha, \beta: \alpha_i \geq 0}
   L(x, \alpha, \beta)</script><p>与原始最优化问题等价，两问题最优值相同，记为</p>
<script type="math/tex; mode=display">
p^{*} = \min_x \theta_P(x)</script></li>
</ul>
<h2 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h2><ul>
<li><p>定义</p>
<script type="math/tex; mode=display">
\theta_D (\alpha, \beta) = \min_x L(x, \alpha, \beta)</script></li>
<li><p>再考虑极大化$\theta_D(\alpha, \beta)$，得到广义拉格朗日
函数的极大极小问题，即</p>
<script type="math/tex; mode=display">
\max_{\alpha, \beta: \alpha \geq 0}
   \theta_D(\alpha, \beta) =
   \max_{\alpha, \beta: \alpha \geq 0} \min_x
   L(x, \alpha, \beta)</script><p>表示为约束最优化问题如下</p>
<script type="math/tex; mode=display">\begin{align*}
\max_{\alpha, \beta} & \theta_D(\alpha, \beta) =
   \max_{\alpha, \beta} \min_x L(x, \alpha, \beta) \\
s.t. & \alpha_i \geq 0, i=1,2,\cdots,k
\end{align*}</script><p>称为原始问题的对偶问题，其最优值定义记为</p>
<script type="math/tex; mode=display">
d^{*} = \max_{\alpha, \beta: \alpha \geq 0}
   \theta_D(\alpha, \beta)</script></li>
</ul>
<h2 id="原始、对偶问题关系"><a href="#原始、对偶问题关系" class="headerlink" title="原始、对偶问题关系"></a>原始、对偶问题关系</h2><h3 id="定理1"><a href="#定理1" class="headerlink" title="定理1"></a>定理1</h3><blockquote>
<ul>
<li>若原始问题、对偶问题都有最优值，则<script type="math/tex; mode=display">
  d^{*} = \max_{\alpha, \beta: \alpha \geq 0} \min_x
      L(x, \alpha, \beta) \leq
  \min_x \max_{\alpha, \beta: \alpha \geq 0}
      L(x, \alpha, \beta) = p^{*}</script></li>
</ul>
</blockquote>
<ul>
<li><p>$\forall x, \alpha, \beta$有</p>
<script type="math/tex; mode=display">
\theta_D(\alpha, \beta) = \min_x L(x, \alpha, \beta)
   \leq L(x, \alpha, \beta) \leq
   \max_{\alpha, \beta: \alpha \geq 0} = \theta_P(x)</script><p>即</p>
<script type="math/tex; mode=display">
\theta_D(\alpha, \beta) \leq \theta_P(x)</script></li>
<li><p>而原始、对偶问题均有最优值，所以得证</p>
</li>
</ul>
<blockquote>
<ul>
<li>设$x^{<em>}$、$\alpha^{</em>}, \beta^{<em>}$分别是原始问题、对偶
  问题的可行解，且$d^{</em>} = p^{*}$，则其分别是原始问题、
  对偶问题的最优解</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-06-09T15:33:54.000Z" title="6/9/2019, 11:33:54 PM">2019-06-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-02T06:45:49.000Z" title="8/2/2021, 2:45:49 PM">2021-08-02</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a><span> / </span><a class="link-muted" href="/categories/Python/Py3std/">Py3std</a></span><span class="level-item">a few seconds read (About 7 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Python/Py3std/numeric_math.html">数字、数学</a></h1><div class="content"><h2 id="numbers"><a href="#numbers" class="headerlink" title="numbers"></a><code>numbers</code></h2><h2 id="math"><a href="#math" class="headerlink" title="math"></a><code>math</code></h2><h2 id="cmath"><a href="#cmath" class="headerlink" title="cmath"></a><code>cmath</code></h2><h2 id="decimal"><a href="#decimal" class="headerlink" title="decimal"></a><code>decimal</code></h2><h2 id="fractions"><a href="#fractions" class="headerlink" title="fractions"></a><code>fractions</code></h2><h2 id="random"><a href="#random" class="headerlink" title="random"></a><code>random</code></h2><h2 id="statics"><a href="#statics" class="headerlink" title="statics"></a><code>statics</code></h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-06-03T17:18:34.000Z" title="6/4/2019, 1:18:34 AM">2019-06-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:26:19.000Z" title="8/4/2021, 11:26:19 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">16 minutes read (About 2327 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/gredient_based.html">Gradient Descent Method</a></h1><div class="content"><h2 id="思想：最速下降-amp-牛顿"><a href="#思想：最速下降-amp-牛顿" class="headerlink" title="思想：最速下降&amp;牛顿"></a>思想：最速下降&amp;牛顿</h2><p>对目标函数$f(x)$在$x^{(1)}$进行展开</p>
<script type="math/tex; mode=display">
f(x) = f(x^{(1)}) + \nabla f(x^{(1)})(x - x^{(1)})+
    \frac 1 2 \nabla^2 f(x^{(1)})(x - x^{(1)})^2 +
    o((x - x^{(1)})^2)</script><blockquote>
<ul>
<li>最速下降法：只保留一阶项，即使用线性函数近似原目标函数</li>
<li>Newton法：保留一阶、二阶项，即使用二次函数近似</li>
</ul>
</blockquote>
<ul>
<li><p>利用近似函数求解元素问题极小值</p>
<ul>
<li>最速下降法：<strong>线性函数无极值，需要确定步长、迭代</strong></li>
<li>Newton法：<strong>二次函数有极值，直接求导算出极值、迭代</strong></li>
</ul>
</li>
<li><p>最速下降法</p>
<ul>
<li>只考虑一阶导：甚至说根本没有考虑拟合原目标函数</li>
</ul>
</li>
<li><p>Newton法</p>
<ul>
<li>考虑二阶导：每步迭代还考虑了二阶导，即当前更新完毕
后，下一步能够更好的更新（二阶导的意义）</li>
<li>甚至从后面部分可以看出，Newton法甚至考虑是全局特征，
不只是局部性质（前提目标函数性质足够好）</li>
<li>二次函数拟合更接近函数极值处的特征</li>
</ul>
</li>
</ul>
<h2 id="最速下降算法"><a href="#最速下降算法" class="headerlink" title="最速下降算法"></a>最速下降算法</h2><h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><ul>
<li><p>设$x=x(t)$为最优点$x$从初始点、沿负梯度方向经过的曲线，
则有</p>
<script type="math/tex; mode=display">\left \{ \begin{array}{l}
& \frac {dx(t)} {dt} = -\nabla f(x(t)) \\
& x(t_1) = x^{(1)}
\end{array} \right.</script><blockquote>
<ul>
<li>$t_1, x^{(1)}$：初始时刻、初始位置</li>
</ul>
</blockquote>
</li>
<li><p>可以证明，$x(t)$解存在，且$t \rightarrow \infty$时，有
$x(t) \rightarrow x^{ * }$，即得到无约束问题最优解</p>
</li>
<li><p>但微分方程组求解可能很麻烦，可能根本无法求解</p>
<ul>
<li>考虑将以上曲线离散化，每次前进到“不应该”前进为止</li>
<li>然后更换方向，逐步迭代得到最优解</li>
</ul>
</li>
</ul>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><blockquote>
<ul>
<li>搜索方向最速下降方向：负梯度方向</li>
<li>终止准则：$\nabla f(x^{(k)})=0$</li>
</ul>
</blockquote>
<ol>
<li><p>取初始点$x^{(1)}$，置k=1</p>
</li>
<li><p>若$\nabla f(x^{(k)})=0$，则停止计算，得到最优解，
否则置</p>
<script type="math/tex; mode=display">d^{(k)} = -\nabla f(x^{(k)})</script><p>以负梯度作为前进方向</p>
</li>
<li><p>一维搜索，求解一维问题</p>
<script type="math/tex; mode=display">
\arg\min_{\alpha} \phi(\alpha) =
  f(x^{(k)} + \alpha d^{(k)})</script><p>得$\alpha_k$前进步长，置</p>
<script type="math/tex; mode=display">
x^{(k+1)} = x^{(k)} + \alpha_k d^{(k)}</script></li>
<li><p>置k=k+1，转2</p>
</li>
</ol>
<blockquote>
<ul>
<li>最速下降算法不具有二次终止性</li>
</ul>
</blockquote>
<h2 id="叠加惯性"><a href="#叠加惯性" class="headerlink" title="叠加惯性"></a>叠加惯性</h2><p>模拟物体运动时惯性：指数平滑更新步长</p>
<p><img src="/imgs/momentum.png" alt="momentum"></p>
<h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a><em>Momentum</em></h3><p>冲量方法：在<strong>原始更新步</strong>上叠加上次更新步，类似指数平滑</p>
<script type="math/tex; mode=display">
v^{(t)} = \gamma v^{(t-1)} + (1 - \gamma) \eta
    \bigtriangledown_\theta L(\theta^{(t-1)}) \\
\theta^{(t)} = \theta^{(t-1)} - v^{(t)}</script><blockquote>
<ul>
<li>$v^{(t)}$：第$t$步时第k个参数更新步</li>
<li>$L(\theta)$：往往是batch损失函数</li>
</ul>
</blockquote>
<ul>
<li>更新参数时，一定程度<strong>保持</strong>上次更新方向</li>
<li>可以在一定程度上保持稳定性，学习速度更快</li>
<li>能够越过部分局部最优解</li>
</ul>
<h3 id="Nesterov-Momentum"><a href="#Nesterov-Momentum" class="headerlink" title="Nesterov Momentum"></a><em>Nesterov Momentum</em></h3><p><em>NGA</em>：在使用冲量修正最终方向基础上，使用冲量对当前
<strong>参数位置</strong>进行修正，即使用“未来”位置计算梯度</p>
<ul>
<li>先使用冲量更新一步</li>
<li>再在更新后位置计算新梯度进行第二步更新</li>
</ul>
<script type="math/tex; mode=display">
v^{(t)} = \gamma v^{(t-1)} + \eta \bigtriangledown_\theta
    L(\theta^{(t-1)} - \gamma v^{(t-1)}) \\

\theta^{(t)} = \theta^{(t-1)} - v^{(t)}</script><h2 id="动态学习率"><a href="#动态学习率" class="headerlink" title="动态学习率"></a>动态学习率</h2><ul>
<li>学习率太小收敛速率缓慢、过大则会造成较大波动</li>
<li>在训练过程中动态调整学习率大小较好</li>
</ul>
<blockquote>
<ul>
<li>模拟退火思想：达到一定迭代次数、损失函数小于阈值时，减小
  学习速率</li>
</ul>
</blockquote>
<p><img src="/imgs/param_estimation_comparion_1.png" alt="param_estimation_comparion_1">
<img src="/imgs/param_estimation_comparion_2.png" alt="param_estimation_comparion_2"></p>
<h3 id="Vanilla-Gradient-Descent"><a href="#Vanilla-Gradient-Descent" class="headerlink" title="Vanilla Gradient Descent"></a><em>Vanilla Gradient Descent</em></h3><p>每次迭代减小学习率$\eta$</p>
<script type="math/tex; mode=display">
\eta^{(t)} = \frac \eta {\sqrt {t+1}} \\

\theta^{(t)} = \theta^{(t-1)} - \eta^{(t)}
    \bigtriangledown_\theta L(\theta^{(t-1)})</script><ul>
<li>学习率逐渐减小，避免学习后期参数在最优解附近反复震荡</li>
</ul>
<h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a><em>Adagrad</em></h3><p><em>adaptive gradient</em>：训练中<strong>不同参数</strong>学习率随着迭代次数、
梯度动态变化，使得参数收敛更加平稳</p>
<script type="math/tex; mode=display">
v^{(t)}_k = \bigtriangledown_{\theta_k} L(\theta^{(t-1)}) \\

\theta^{(t)}_k = \theta^{(t-1)}_k - \frac \eta
    {\sqrt {\sum_{i=0}^{t-1} (v^{(i)}_k)^2 + \epsilon}}
    v^{(t)}_k</script><blockquote>
<ul>
<li>$\epsilon$：fuss factor，避免分母为0</li>
<li>$\theta^{(t)}_k$：第t轮迭代完成后待估参数第k个分量
  （之前未涉及参数间不同，统一为向量）</li>
</ul>
</blockquote>
<ul>
<li><p>特点</p>
<ul>
<li>较大梯度参数真正学习率会被拉小；较小梯度真正学习率
参数被拉小幅度较小</li>
<li>可以和异步更新参数结合使用，给不常更新参数更大学习率</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>在训练后期，分母中梯度平方累加很大，学习步长趋于0，
收敛速度慢（可能触发阈值，提前结束训练）</li>
</ul>
</li>
</ul>
<h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a><em>RMSprop</em></h3><p><em>root mean square prop</em>：指数平滑更新学习率分母</p>
<script type="math/tex; mode=display">
v^{(t)}_k = \bigtriangledown_{\theta_k} L(\theta^{(t-1)}) \\

\theta^{(t)}_k = \theta^{(t-1)}_k - \frac \eta
    {\sqrt { \gamma \sum_{i=1}^{t-1}(v^{(i)}_k)^2 +
        (1 - \gamma)((v^{(t)})^2 + \epsilon}
    } v^{(t)}</script><ul>
<li>赋予当前梯度更大权重，减小学习率分母，避免学习速率下降
太快</li>
</ul>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a><em>Adam</em></h3><p><em>adptive moment estimation</em>：指数平滑更新步、学习率分母</p>
<script type="math/tex; mode=display">
\begin{align*}
v^{(t)}_k & = \gamma_1 v^{(t-1)}_k + (1 - \gamma_1)
    \bigtriangledown_{\theta_k} L(\theta^{(t-1)}) \\
s^{(t)}_k & = \gamma_2 s^{(t-1)}_k + (1 - \gamma_2)
    \bigtriangledown_{\theta_k} L(\theta^{(t-1)})^2 \\

\hat{v^{(t)}_k} & = \frac {v^{(t)}_k} {1 - \gamma_1^t} \\
\hat{s^{(t)}_k} & = \frac {s^{(t)}_k} {1 - \gamma_2^t} \\

\theta^{(t)}_k & = \theta^{(t-1)}_k - \frac \eta
    {\sqrt{\hat{s^{(t)}_k} + \epsilon}} \hat{v^{(t)}_k}
\end{align*}</script><blockquote>
<ul>
<li>$\gamma_1$：通常为0.9</li>
<li>$\gamma_2$：通常为0.99</li>
<li>$\hat{v^{(t)}_k} = \frac {v^{(t)}_k} {1 - \gamma_1^t}$
  ：权值修正，使得过去个时间步，小批量随机梯度权值之和为1</li>
</ul>
</blockquote>
<ul>
<li><p>利用梯度的一阶矩$v^{(t)}$、二阶矩$s^{(t)}$动态调整每个
参数学习率</p>
</li>
<li><p>类似于<em>mommentum</em>、<em>RMSprop</em>结合</p>
</li>
<li><p>经过偏执矫正后，每次迭代学习率都有确定范围，参数比较平稳</p>
</li>
</ul>
<h3 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a><em>Adadelta</em></h3><p>指数平滑更新学习率（分子）、学习率分母</p>
<script type="math/tex; mode=display">
\begin{align*}
s^{(t)}_k & = \gamma_1 s^{(t-1)}_k + (1 - \gamma_1)
    \bigtriangledown_{\theta_k} L(\theta^{(t-1)})^2 \\

\hat{v^{(t)}_k} & = \sqrt {\frac {\Delta \theta^{(t-1)}_k + \epsilon}
    {s^{(t)}_k + \epsilon}}
    \bigtriangledown_{\theta_k} L(\theta^{(t-1)})^2 \\

\Delta \theta^{(t)}_k & = \gamma_1 \Delta \theta^{(t-1)}_k +
    (1 - \gamma_1) \hat{v^{(t)}_k}^2 \\

\theta^{(t)}_k & = \theta^{(t)}_k - \hat{v^{(t)}_k}
\end{align*}</script><blockquote>
<ul>
<li>$s, \Delta \theta$共用超参$\gamma_1$</li>
</ul>
</blockquote>
<ul>
<li>在<em>RMSprop</em>基础上，使用$\sqrt {\Delta \theta}$作为学习率</li>
<li>$\hat v$：中超参$\gamma_1$在分子、分母“抵消”，模型对
超参不敏感</li>
</ul>
<h2 id="样本量"><a href="#样本量" class="headerlink" title="样本量"></a>样本量</h2><h3 id="Singular-Loss-Stocastic-Gradient-Descent"><a href="#Singular-Loss-Stocastic-Gradient-Descent" class="headerlink" title="Singular Loss/Stocastic Gradient Descent"></a>Singular Loss/Stocastic Gradient Descent</h3><p><em>SGD</em>：用模型在某个样本点上的损失极小化目标函数、计算梯度、
更新参数</p>
<ul>
<li><p>单点损失度量模型“一次”预测的好坏</p>
<ul>
<li>代表模型在单点上的优劣，无法代表模型在总体上性质</li>
<li>具有很强随机性</li>
</ul>
</li>
<li><p>单点损失不常用，SGD范围也不局限于单点损失</p>
</li>
</ul>
<blockquote>
<ul>
<li>损失函数具体参见<em>ml_xxxxx</em></li>
</ul>
</blockquote>
<h3 id="全局估计"><a href="#全局估计" class="headerlink" title="全局估计"></a>全局估计</h3><p>全局损失：用模型在全体样本点上损失极小化目标函数、计算梯度、
更新参数</p>
<script type="math/tex; mode=display">
\theta^{(t)} = \theta^{(t-1)} - \eta \bigtriangledown_\theta
    L_{total}(\theta_{(t-1)})</script><blockquote>
<ul>
<li>$\theta^{(t)}$：第t步迭代完成后待估参数</li>
<li>$\eta$：学习率</li>
<li>$L<em>{total}(\theta) = \sum</em>{i=1}^N L(\theta, x_i, y_i)$：
  训练样本整体损失</li>
<li>$N$：训练样本数量</li>
</ul>
</blockquote>
<ul>
<li><p>若损失函数有解析解、样本量不大，可<strong>一步更新（计算）</strong>
完成（传统参数估计场合）</p>
<ul>
<li>矩估计</li>
<li>最小二乘估计</li>
<li>极大似然估计</li>
</ul>
</li>
<li><p>否则需要迭代更新参数</p>
<ul>
<li>样本量较大场合</li>
<li>并行计算</li>
</ul>
</li>
</ul>
<h3 id="Mini-Batch-Loss"><a href="#Mini-Batch-Loss" class="headerlink" title="Mini-Batch Loss"></a>Mini-Batch Loss</h3><p><em>mini-batch loss</em>：用模型在某个batch上的损失极小化目标函数、
计算梯度、更新参数</p>
<script type="math/tex; mode=display">
\theta^{(t)} = \theta^{(t-1)} - \eta \bigtriangledown_\theta
    L_{batch}(\theta^{(t-1)})</script><blockquote>
<ul>
<li>$L<em>{batch}(\theta)=\sum</em>{i \in B} L(\theta, x_i, y_i)$：
  当前batch整体损失</li>
<li>$B$：当前更新步中，样本组成的集合batch</li>
</ul>
</blockquote>
<ul>
<li><p>batch-loss是模型在batch上的特征，对整体的代表性取决于
batch大小</p>
<ul>
<li>batch越大对整体代表性越好，越稳定；越小对整体代表
越差、不稳定、波动较大、难收敛</li>
<li>batch大小为1时，就是SGD</li>
<li>batch大小为整个训练集时，就是经验（结构）风险</li>
</ul>
</li>
<li><p>batch-loss是学习算法中最常用的loss，SGD优化常指此</p>
<ul>
<li>实际中往往是使用batch-loss替代整体损失，表示经验风险
极小化</li>
<li>batch-loss同样可以带正则化项，表示结构风险极小化</li>
<li>损失极值：SVM（几何间隔最小）</li>
</ul>
</li>
</ul>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>适合样本量较大、无法使用样本整体估计使用</li>
<li>一定程度能避免局部最优（随机batch可能越过局部极值）</li>
<li>开始阶段收敛速度快</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li><p>限于每次只使用单batch中样本更新参数，batch-size较小时，
结果可能不稳定，往往很难得到最优解</p>
</li>
<li><p>无法保证良好的收敛性，学习率小收敛速度慢，学习率过大
则损失函数可能在极小点反复震荡</p>
</li>
<li><p>对所有参数更新应用相同学习率，没有对低频特征有优化
（更的学习率）</p>
</li>
<li><p>依然容易陷入局部最优点</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-06-03T17:18:34.000Z" title="6/4/2019, 1:18:34 AM">2019-06-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-06-03T17:18:34.000Z" title="6/4/2019, 1:18:34 AM">2019-06-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">5 minutes read (About 752 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/newtons.html">Newton&#039;s Method</a></h1><div class="content"><h2 id="Newton法"><a href="#Newton法" class="headerlink" title="Newton法"></a>Newton法</h2><h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><ul>
<li><p>若$x^{ * }$是无约束问题局部解，则有</p>
<script type="math/tex; mode=display">\nabla f(x^{ * }) = 0</script><p>可求解此问题，得到无约束问题最优解</p>
</li>
<li><p>原始问题是非线性，考虑求解其线性逼近，在初始点$x^{(1)}$
处泰勒展开</p>
<script type="math/tex; mode=display">
\nabla f(x) \approx \nabla f(x^{(1)})
   + \nabla^2 f(x^{(1)})(x - x^{(1)})</script><p>解得</p>
<script type="math/tex; mode=display">
x^{(2)} = x^{(1)} - (\nabla^2 f(x^{(1)}))^{-1}
   \nabla f(x^{(1)})</script><p>作为$x^{ * }$的第二次近似</p>
</li>
<li><p>不断迭代，得到如下序列</p>
<script type="math/tex; mode=display">
x^{(k+1)} = x^{(k)} + d^{(k)}</script><blockquote>
<ul>
<li>$d^{(k)}$：Newton方向，即以下方程解<script type="math/tex; mode=display">
 \nabla^2 f(x^{(k)}) d = -\nabla
     f(x^{(k)})</script></li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><ul>
<li><p>初始点 $x^{(1)}$、精度要求 $\epsilon$，置 $k=1$</p>
</li>
<li><p>考虑 $|\nabla f(x^{(k)})| \leq \epsilon$</p>
<ul>
<li>若满足，则停止计算，得到最优解 $x^{(k)}$</li>
<li><p>否则求解如下方程，得到 $d^{(k)}$</p>
<script type="math/tex; mode=display">
\nabla^2 f(x^{(k)}) d = -\nabla f(x^{(k)})</script></li>
</ul>
</li>
<li><p>如下设置，并转2</p>
<script type="math/tex; mode=display">x^{(k+1)} = x^{(k)} + d^{(k)}, k = k+1</script></li>
</ul>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li><p>优点</p>
<ul>
<li>产生点列 ${x^{k}}$ 若收敛，则具有二阶收敛速率</li>
<li>具有二次终止性，事实上对正定二次函数，一步即可收敛</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>可能会在某步迭代时目标函数值上升</li>
<li>当初始点 $x^{(1)}$ 距离最优解 $x^{ * }$ 时，产生的点列
可能不收敛，或者收敛到鞍点</li>
<li>需要计算 <em>Hesse</em> 矩阵<ul>
<li>计算量大</li>
<li><em>Hesse</em> 矩阵可能不可逆，算法终止</li>
<li><em>Hesse</em> 矩阵不正定，<em>Newton</em> 方向可能不是下降方向</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="阻尼-修正-Newton-法"><a href="#阻尼-修正-Newton-法" class="headerlink" title="阻尼/修正 Newton 法"></a>阻尼/修正 <em>Newton</em> 法</h2><ul>
<li>克服 <em>Newton</em> 法目标函数值上升的缺点</li>
<li>一定程度上克服点列可能不收敛缺点</li>
</ul>
<h3 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h3><ul>
<li><p>初始点 $x^{(1)}$、精度要求 $\epsilon$，置 $k=1$</p>
</li>
<li><p>考虑 $|\nabla f(x^{(k)})| \leq \epsilon$</p>
<ul>
<li>若满足，停止计算，得到最优解 $x^{(k)}$</li>
<li>否则求解如下方程得到 $d^{(k)}$<script type="math/tex; mode=display">
\nabla^2 f(x^{(k)}) d = -\nabla f(x^{(k)})</script></li>
</ul>
</li>
<li><p>一维搜索，求解一维问题</p>
<script type="math/tex; mode=display">
\arg\min_{\alpha} \phi(\alpha) = f(x^{(k)} + \alpha d^{(k)})</script><p>得到 $\alpha_k$，如下设置并转2</p>
<script type="math/tex; mode=display">
x^{(k+1)} = x^{(k)} + \alpha_k d^{(k)}, k = k+1</script></li>
</ul>
<h2 id="其他改进"><a href="#其他改进" class="headerlink" title="其他改进"></a>其他改进</h2><ul>
<li><em>Newton</em> 法、修正 <em>Newton</em> 法的改进方向<ul>
<li>结合最速下降方向修正迭代方向</li>
<li><em>Hesse</em> 矩阵不正定情形下的替代</li>
</ul>
</li>
</ul>
<h3 id="结合最速下降方向"><a href="#结合最速下降方向" class="headerlink" title="结合最速下降方向"></a>结合最速下降方向</h3><blockquote>
<ul>
<li>将 <em>Newton</em> 方向和最速下降方向结合</li>
</ul>
</blockquote>
<ul>
<li><p>设 $\theta_k$ 是 $<d^{(k)}, -\nabla f(x^{(k)})>$ 之间夹角，显然希望 $\theta &lt; \frac \pi 2$</p>
</li>
<li><p>则置限制条件 $\eta$，取迭代方向</p>
<script type="math/tex; mode=display">
d^{(k)} = \left \{ \begin{array}{l}
   d^{(k)}, & cos\theta_k \geq \eta \\
   -\nabla f(x^{(k)}), & 其他
\end{array} \right.</script></li>
</ul>
<h3 id="Negative-Curvature"><a href="#Negative-Curvature" class="headerlink" title="Negative Curvature"></a><em>Negative Curvature</em></h3><blockquote>
<ul>
<li>当 <em>Hesse</em> 矩阵非正定时，选择负曲率下降方向 $d^{(k)}$（一定存在）</li>
</ul>
</blockquote>
<ul>
<li><p><em>Hesse</em> 矩阵非正定时，一定存在负特征值、相应特征向量 $u$</p>
<ul>
<li><p>取负曲率下降方向作为迭代方向</p>
<script type="math/tex; mode=display">
d^{(k)} = -sign(u^T \nabla f(x^{(k)})) u</script></li>
<li><p>$x^{(k)}$ 处负曲率方向 $d^{(k)}$ 满足</p>
<script type="math/tex; mode=display">
{d^{(k)}}^T \nabla^2 f(x^{(k)}) d^{(k)} < 0</script></li>
</ul>
</li>
</ul>
<h3 id="修正-Hesse-矩阵"><a href="#修正-Hesse-矩阵" class="headerlink" title="修正 Hesse 矩阵"></a>修正 <em>Hesse</em> 矩阵</h3><ul>
<li><p>取迭代方向 $d^{(k)}$ 为以下方程的解</p>
<script type="math/tex; mode=display">
(\nabla^2 f(x^{(k)}) + v_k I) d = -\nabla f(x^{k})</script></li>
</ul>
<blockquote>
<ul>
<li>$v_k$：大于 $\nabla^2 f(x^{(k)})$ 最大负特征值绝对值</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-05-01T01:58:40.000Z" title="5/1/2019, 9:58:40 AM">2019-05-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:18:28.000Z" title="8/4/2021, 11:18:28 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Probability/">Probability</a></span><span class="level-item">4 minutes read (About 560 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Probability/distributions.html">常见分布</a></h1><div class="content"><h2 id="离散"><a href="#离散" class="headerlink" title="离散"></a>离散</h2><h2 id="连续"><a href="#连续" class="headerlink" title="连续"></a>连续</h2><h3 id="P-stable-Distributions"><a href="#P-stable-Distributions" class="headerlink" title="P-stable Distributions"></a><em>P-stable Distributions</em></h3><p><em>p_stable distribution</em>：随机变量 $\sum_i v_i X_i$ 、随机变量 $(\sum_i |v_i|^p)^{1/p} X$ 具有相同的分布</p>
<blockquote>
<ul>
<li>$v_1, v_2, \cdots, v_n$：任意实数</li>
<li>$X_1, X_2, \cdots, X_n$：独立同分布$D$随机变量</li>
<li>$X$：服从分布$D$随机变量</li>
</ul>
</blockquote>
<ul>
<li><p>$\forall p \in (0, 2]$，稳定分布存在，但仅$p=1,2$时，有解析解</p>
<ul>
<li><p>$p=1$：柯西分布</p>
<script type="math/tex; mode=display">
c(x) = \frac 1 \pi \frac 1 {1+x^2}</script></li>
<li><p>$p=2$：高斯分布</p>
<script type="math/tex; mode=display">
g(x) = \frac 1 {\sqrt {2\pi}} e^{-\frac {x^2} 2}</script></li>
</ul>
</li>
<li><p>可以从$[0,1]$上均匀分布获得稳定分布</p>
<ul>
<li>但是概率分布、密度函数没有解析解</li>
</ul>
</li>
</ul>
<h4 id="性质、用途"><a href="#性质、用途" class="headerlink" title="性质、用途"></a>性质、用途</h4><ul>
<li>若向量 $a$ 中每个元素独立从 <em>p-stable</em> 分布中抽取，则 $|v|_p X = (\sum_i |v_i|^p)^{1/p} X$ 和 $<a,v>$ 同分布<ul>
<li>可用较好计算的内积估计 $|v|_p$</li>
<li>考虑到 $a(v_1 - v_2) = av_1 - av_2$，将内积和点之间 $L_p$ 范数距离 $|v_1 - v_2|_p$ 相联系</li>
</ul>
</li>
</ul>
<h2 id="Exponential-Family-of-Distributions"><a href="#Exponential-Family-of-Distributions" class="headerlink" title="Exponential Family of Distributions"></a><em>Exponential Family of Distributions</em></h2><p>单变量指数分布概率密度/分布</p>
<script type="math/tex; mode=display">\begin{align*}
f_X(x|\theta) &= h(x) e^{\eta(\theta) T(x) - A(\theta)} \\
&= h(x) g(\theta) e^{\eta(\theta) T(x)} \\
&= e^{\eta(\theta) T(x) - A(\theta) + B(x)}
\end{align*}</script><blockquote>
<ul>
<li>$\eta(\theta)$：<em>nutural parameter</em>，自然参数</li>
<li>$h(x)$：<em>underlying measure</em>，底层观测值</li>
<li>$T(x)$：<em>sufficient statistic</em>，随机变量X的充分统计量</li>
<li>$A(\theta)$：<em>log normalizer</em>，对数规范化</li>
</ul>
</blockquote>
<ul>
<li><p>$\eta(\theta), T(x)$：可以是向量，其内积仍为实数</p>
</li>
<li><p>$\eta(\theta) = \theta$时，称分布族为<em>canonical</em>形式</p>
<ul>
<li>总是能够定义$\eta = \eta(\theta)$转为此形式</li>
</ul>
</li>
<li><p>对数规范化$A(\theta)$使得概率密度函数满足积分为1</p>
<script type="math/tex; mode=display">\begin{align*}
f(x|\theta) e^{A(\theta)} & = h(x) e^{\eta(\theta)T(x)} \\
\int e^{A(\theta)} f(x|\theta) dx & = \int h(x) e^{\eta(\theta) T(x)} dx \\
e^{A(\theta)} \int f(x|\theta) dx & = \int h(x) e^{\eta(\theta) T(x)} dx \\
A(\theta) & = ln \int h(x) e^{\eta(\theta) T(x)} dx
\end{align*}</script></li>
</ul>
<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/148776108">https://zhuanlan.zhihu.com/p/148776108</a></li>
</ul>
</blockquote>
<h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><ul>
<li>充分统计量$T(x)$可以使用固定几个值，从大量的独立同分布
数据中获取信息<h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1></li>
</ul>
<h3 id="Bernoulli分布"><a href="#Bernoulli分布" class="headerlink" title="Bernoulli分布"></a><em>Bernoulli</em>分布</h3><ul>
<li>$h(x) = 1$</li>
<li>$T(x) = x$</li>
<li>$\eta = log \frac \theta {1 - \theta}$</li>
<li>$A(\theta) = ln(1+e^{\theta})$</li>
</ul>
<h3 id="Possion"><a href="#Possion" class="headerlink" title="Possion"></a><em>Possion</em></h3><ul>
<li>$\theta = \lambda$</li>
<li>$h(x) = \frac 1 {x!}$</li>
<li>$\eta(\theta) = ln\lambda$</li>
<li>$T(x) = x$</li>
<li>$A(\theta) = \lambda$</li>
</ul>
<h3 id="Normal"><a href="#Normal" class="headerlink" title="Normal"></a><em>Normal</em></h3><ul>
<li>$h(x) = \frac 1 {\sqrt{2\pi\sigma^2}} e^{-\frac {x^2} {2\sigma^2}}$</li>
<li>$T(x) = \frac x \sigma$</li>
<li>$A(\theta) = \frac {\mu^2} {2\sigma^2}$</li>
<li>$\eta(\theta) = \frac \mu \sigma$</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-04-22T17:32:09.000Z" title="4/23/2019, 1:32:09 AM">2019-04-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-04-22T17:32:09.000Z" title="4/23/2019, 1:32:09 AM">2019-04-23</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">12 minutes read (About 1864 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/quasi_newtons.html">Quasi-Newton Method/Variable Metric Method</a></h1><div class="content"><h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><p>拟Newton法/变度量法：不需要求解Hesse矩阵，使用一阶导构造
二阶信息的近似矩阵</p>
<ul>
<li><p>使用迭代过程中信息，创建近似矩阵$B^{(k)}$代替Hesse矩阵</p>
</li>
<li><p>用以下方程组替代Newton方程，其解$d^{(k)}$作为搜索方向</p>
<script type="math/tex; mode=display">
B^{(k)} d = - \triangledown f(x^{(k)})</script></li>
</ul>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><ul>
<li><p>考虑$\triangledown f(x)$在$x^{(k+1)}$处泰勒展开</p>
<script type="math/tex; mode=display">
\triangledown f(x) \approx \triangledown f(x^{(k+1)})
   + \triangledown^2 f(x^{(k+1)})(x - x^{(k+1)})</script></li>
<li><p>取$x = x^{(k)}$，有</p>
<script type="math/tex; mode=display">\begin{align*}
\triangledown f(x^{(k+1)}) - \triangledown f(x^{(k)})
   & \approx \triangledown^2 f(x^{(x+1)})
   (x^{(k+1) } - x^{(k)}) \\
\triangledown^2 f(x^{k+1}) s^{(k)} & \approx y^{(k)}
\end{align*}</script><blockquote>
<ul>
<li>$s^{(k)} = x^{(k+1)} - x^{(k)}$</li>
<li>$y^{(k)} = \triangledown f(x^{(k+1)}) - \triangledown f(x^{(k)})$</li>
</ul>
</blockquote>
</li>
<li><p>要求$B^{(k)}$近似$\triangledown^2 f(x^{(k)})$，带入并将
$\approx$改为$=$，得到拟Newton方程</p>
<script type="math/tex; mode=display">
B^{(k+1)} s^{(k)} = y^{(k)}</script><p>并假设$B^{(k)}$对称</p>
</li>
<li><p>拟Newton方程不能唯一确定$B^{(k+1)}$，需要附加条件，自然
的想法就是$B^{(k+1)}$可由$B^{(k)}$修正得到，即</p>
<script type="math/tex; mode=display">
B^{(k+1)} = B^{(k)} + \Delta B^{(k)}</script><p>且修正项$\Delta B^{(k)}$具有“简单形式”</p>
</li>
</ul>
<h2 id="Hesse矩阵修正"><a href="#Hesse矩阵修正" class="headerlink" title="Hesse矩阵修正"></a>Hesse矩阵修正</h2><h3 id="对称秩1修正"><a href="#对称秩1修正" class="headerlink" title="对称秩1修正"></a>对称秩1修正</h3><p>认为简单指矩阵秩小：即认为$\Delta B^{(k)}$秩为最小值1</p>
<ul>
<li><p>设$\Delta B^{(k)} = u v^T$，带入有</p>
<script type="math/tex; mode=display">\begin{align*}
y^{(k)} & = B^{(k+1)} s^{(k)} \\
& = B^{(k)} s^{(k)} + (v^T s^{(k)}) u \\
y^{(k)} - B^{(k)} s^{(k)} & = (v^T s^{(k)}) u
\end{align*}</script><ul>
<li>这里有的书会设$\Delta B^{(k)} = \alpha u v^T$，
其实对向量没有必要</li>
<li>$v^T s^{(k)}$是数，所以$u$必然与共线，同理也没有必要
考虑系数，直接取相等即可</li>
<li>而且系数不会影响最终结果</li>
</ul>
</li>
<li><p><strong>可取</strong>$u = y^{(k)} - B^{(k)} s{(k)}$，取$v$满足
$v^T s^{(k)}  = 1$</p>
</li>
<li><p>由$B^{(k)}$的对称性、并希望$B^{(k+1)}$保持对称，需要
$u, v$共线，则有</p>
<script type="math/tex; mode=display">\begin{align*}
v & = \lambda u = \lambda (y^{(k)} - B^{(k)} s^{(k)}) \\
1 & = \lambda (y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)}
\end{align*}</script></li>
<li><p>得到$B^{(k)}$的对称秩1修正公式</p>
<script type="math/tex; mode=display">
B^{(k+1)} = B^{(k)} + \frac {(y^{(k) - B^{(k)} s^{(k)}})
   (y^{(k)} - B^{(k)} s^{(k)})^T}
   {(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)}}</script></li>
</ul>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><ol>
<li><p>初始点$x^{(1)}$、初始矩阵$B^{(1)} = I$、精度要求
$\epsilon$、置$k=1$</p>
</li>
<li><p>若$|\triangledown f(x^{(k)})| \leq \epsilon$，停止计算
，得到解$x^{(k)}$，否则求解以下方程得到$d^{(k)}$</p>
<script type="math/tex; mode=display">
B^{(k)} d = -\triangle f(x^{(k)})</script></li>
<li><p>一维搜索，求解</p>
<script type="math/tex; mode=display">
\arg\min_{\alpha} \phi(\alpha)=f(x^{(k)} + \alpha d^{(k)})</script><p>得到$\alpha_k$，置$x^{(k+1)}=x^{(k)} + \alpha_k d^{(k)}$</p>
</li>
<li><p>修正$B^{(k)}$</p>
<script type="math/tex; mode=display">\begin{align*}
s^{(k)} & = x^{(k+1)} - x^{(k)} \\
y^{(k)} & = \triangledown f(x^{(k+1)}) -
  \triangledown f(x^{(k)}) \\
B^{(k+1)} & = B^{(k)} + \frac {(y^{(k) - B^{(k)} s^{(k)}})
  (y^{(k)} - B^{(k)} s^{(k)})^T}
  {(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)}}
\end{align*}</script></li>
<li><p>置$k = k+1$，转2</p>
</li>
</ol>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul>
<li><p>缺点</p>
<ul>
<li><p>要求$(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)} \neq 0$，
否则无法继续计算</p>
</li>
<li><p>不能保证正定性传递，只有
$(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)} &gt; 0$才能保证
$B^{(k+1)}$也正定</p>
</li>
<li><p>即使$(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)} &gt; 0$，
也可能很小，容易产生较大的舍入误差</p>
</li>
</ul>
</li>
</ul>
<h3 id="对称秩2修正"><a href="#对称秩2修正" class="headerlink" title="对称秩2修正"></a>对称秩2修正</h3><ul>
<li><p>为克服秩1修正公式缺点，考虑$\Delta B^{(k)}$秩为2，设</p>
<script type="math/tex; mode=display">
\Delta B^{(k)} = u^{(1)} (v^{(1)})^T
   + u^{(2)} (v^{(2)})^T</script></li>
<li><p>带入拟Newton方程有</p>
<script type="math/tex; mode=display">
B^{(k)} s^{(k)} + ((v^{(1)})^T s^{(k)}) u^{(1)} +
   ((v^{(2)})^T s^{(k)}) u^{(2)} = y^{(k)}</script></li>
<li><p>类似的取</p>
<script type="math/tex; mode=display">\left \{ \begin{array}{l}
u^{(1)} = y^{(k)} \\
(v^{(1)})^T s^{(k)} = 1
\end{array} \right.</script><script type="math/tex; mode=display">\left \{ \begin{array}{l}
u^{(2)} = -B^{(k)} s^{(k)} \\
(v^{(2)})^T s^{(k)} = 1
\end{array} \right.</script></li>
<li><p>同秩1公式保持对称性推导，得到对称秩2修正公式/BFGS公式</p>
<script type="math/tex; mode=display">
B^{(k+1)} = B^{(k)} - \frac {B^{(k)} s^{(k)}
   (s^{(k)})^T B^{(k)}} {(s^{(k)})^T B^{(k)} s^{(k)}}
   + \frac {y^{(k)} (y^{(k)})^T} {(y^{(k)})^T s^{(k)}}</script></li>
</ul>
<h3 id="BFGS算法"><a href="#BFGS算法" class="headerlink" title="BFGS算法"></a>BFGS算法</h3><p>类似同秩1修正算法，仅第4步使用对称秩2修正公式</p>
<h2 id="Hesse逆修正"><a href="#Hesse逆修正" class="headerlink" title="Hesse逆修正"></a>Hesse逆修正</h2><h3 id="对称秩2修正-1"><a href="#对称秩2修正-1" class="headerlink" title="对称秩2修正"></a>对称秩2修正</h3><ul>
<li><p>考虑直接构造近似于$(\triangledown^2 f(x^{(k)}))^{-1}$的
矩阵$H^{(k)}$</p>
</li>
<li><p>这样无需求解线性方程组，直接计算</p>
<script type="math/tex; mode=display">
d^{(k)} = -H^{(k)} \triangledown f(x^{(k)})</script></li>
<li><p>相应拟Newton方程为</p>
<script type="math/tex; mode=display">
H^{(k+1)} y^{(k)} = s^{(k)}</script></li>
<li><p>可得$H^{(k)}$的对称秩1修正公式</p>
<script type="math/tex; mode=display">
H^{(k+1)} = H^{(k)} + \frac {(s^{(k)} - H^{(k)} y^{(k)})
   (s^{(k)} - H^{(k)} y^{(k)})T}
   {(s^{(k)} - H^{(k)} y^{(k)})^T y^{(k)}}</script></li>
<li><p>可得$H^{(k)}$的对称秩2修正公式/DFP公式</p>
<script type="math/tex; mode=display">
H^{(k+1)} = H^{(k)} - \frac {H^{(k)} y^{(k)} (y^{(k)})^T
   H^{(k)}} {(y^{(k)})^T H^{(k)} y^{(k)}} +
   \frac {s^{(k)} (s^{(k)})^T} {(s^{(k)})^T y^{(k)}}</script></li>
</ul>
<h4 id="DFP算法"><a href="#DFP算法" class="headerlink" title="DFP算法"></a>DFP算法</h4><p>类似BFGS算法，只是</p>
<ul>
<li>使用$H^{(k)}$计算更新方向</li>
<li>使用$H^{(k)}$的对称秩2修正公式修正</li>
</ul>
<blockquote>
<ul>
<li>对正定二次函数，BFGS算法和DFP算法效果相同</li>
<li>对一般可微（非正定二次函数），一般认为BFGS算法在收敛性质
  、数值计算方面均由于DFP算法</li>
</ul>
</blockquote>
<h3 id="Hesse逆的BFGS算法"><a href="#Hesse逆的BFGS算法" class="headerlink" title="Hesse逆的BFGS算法"></a>Hesse逆的BFGS算法</h3><ul>
<li><p>考虑</p>
<script type="math/tex; mode=display">\begin{align*}
B^{(k+1)} & = B^{(k)} + u^{(1)} (v^{(1)})^T +
   u^{(2)} (v^{(2)})^T \\
H^{(k+1)} & = (B^{(k+1)})^{-1} \\
& = (B^{(k)} + u^{(1)} (v^{(1)})^T + u^{(2)}
   (v^{(2)})^T)^{-1} \\
\end{align*}</script></li>
<li><p>两次利用<em>Sherman-Morrison</em>公式，可得</p>
<script type="math/tex; mode=display">
H^{(k+1)} = (I - \frac {s^{(k)} (y^{(k)})^T} 
   {(y^{(k)})^T s^{(k)}})
   H^{(k)}
   (I - \frac {s^{(k)} (y^{(k)})^T}
       {(y^{(k)})^T s^{(k)}})^T
   + \frac {s^{(k)} (s^{(k)})^T} {(y^{(k)})^T s^{(k)}}</script></li>
</ul>
<h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><ul>
<li><p>还可以进一步展开</p>
<script type="math/tex; mode=display">
H^{(k+1)} = H^{(k)} + (\frac 1 {(s^{(k)})^T y^{(k)}} +
   \frac {(y^{(k)})^T H^{(k)} y^{(k)}}
   {((s^{(k)})^T y^{(k)})^2}) s^{(k)} (s^{(k)})^T
   - \frac 1 {(s^{(k)})^T y^{(k)}}
   (H^{(k)} y^{(k)} (s^{(k)})^T +
   s^{(k)} (y^{(k)})^T H^{(k)})</script></li>
</ul>
<h2 id="变度量法的基本性质"><a href="#变度量法的基本性质" class="headerlink" title="变度量法的基本性质"></a>变度量法的基本性质</h2><h3 id="算法的下降性"><a href="#算法的下降性" class="headerlink" title="算法的下降性"></a>算法的下降性</h3><h4 id="定理1"><a href="#定理1" class="headerlink" title="定理1"></a>定理1</h4><blockquote>
<ul>
<li>设$B^{(k)}$（$H^{(k)}$）是正定对称矩阵，且有
  $(s^{(k)})^T y^{(k)} &gt; 0$，则由BFGS（DFS）公式构造的
  $B^{(k+1)}$（$H^{(k+1)}$）是正定对称的</li>
</ul>
</blockquote>
<ul>
<li><p>考虑$B^{(k)}$对称正定，有
$B^{(k)} = (B^{(k)})^{1/2} (B^{(k)})^{1/2}$</p>
</li>
<li><p>带入利用柯西不等式即可证</p>
</li>
</ul>
<blockquote>
<ul>
<li>中间插入正定矩阵的向量内积不等式也称为广义柯西不等式</li>
</ul>
</blockquote>
<h4 id="定理2"><a href="#定理2" class="headerlink" title="定理2"></a>定理2</h4><blockquote>
<ul>
<li>若$d^{(k)}$v是下降方向，且<strong>一维搜索是精确的</strong>，设
  $B^{(k)}$（$H^{(k)}$）是正定对称矩阵，则有BFGS（DFP）
  公式构造的$B^{(k+1)}$（$H^{(k+1)}$）是正定对称的</li>
</ul>
</blockquote>
<ul>
<li>精确一维搜索$(d^{(k)})^T \triangledown f(x^{(k+1)}) = 0$</li>
<li>则有$(s^{(k)})^T y^{(k)} &gt; 0$</li>
</ul>
<h4 id="定理3"><a href="#定理3" class="headerlink" title="定理3"></a>定理3</h4><blockquote>
<ul>
<li>若用BFGS算法（DFP算法）求解无约束问题，设初始矩阵
  $B^{(1)}$（$H^{(1)}$）是正定对称矩阵，且一维搜索是精确的
  ，若$\triangledown f(x^{(k)}) \neq 0$，则产生搜索方向
  $d^{(k)}$是下降方向</li>
</ul>
</blockquote>
<ul>
<li>结合上2个结论，数学归纳法即可</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li><p>若每步迭代一维搜索精确，或满足$(s^{(k)})^T y^{(k)} &gt; 0$</p>
<ul>
<li>停止在某一稳定点</li>
<li>或产生严格递减的序列${f(x^{(k)})}$</li>
</ul>
</li>
<li><p>若目标函数满足一定条件我，可以证明变度量法产生的点列
${x^{(k)}}$收敛到极小点，且收敛速率超线性</p>
</li>
</ul>
<h3 id="搜索方向共轭性"><a href="#搜索方向共轭性" class="headerlink" title="搜索方向共轭性"></a>搜索方向共轭性</h3><blockquote>
<ul>
<li>用变度量法BFGS（DFP）算法求解正定二次函数</li>
</ul>
</blockquote>
<pre><code>$$
min f(x) = \frac 1 2 x^T G x + r^T x + \sigma
$$

若一维搜索是精确的，假设已经进行了m次迭代，则
</code></pre><blockquote>
<ul>
<li><p>搜索方向$d^{(1)}, \cdots, d^{(m)}$是m个非零的G共轭方向</p>
</li>
<li><p>对于$j = 1, 2, \cdots, m$，有</p>
</li>
</ul>
</blockquote>
<pre><code>$$
B^&#123;(m+1)&#125; s^&#123;(j)&#125; = y^&#123;(j)&#125;
(H^&#123;(m+1)&#125; y^&#123;(j)&#125; = s^&#123;(j)&#125;)
$$

且$m = n$时有吧

$$
B^&#123;(n+1)&#125; = G(H^&#123;(n+1)&#125; = G^&#123;-1&#125;)
$$
</code></pre><h3 id="变度量法二次终止"><a href="#变度量法二次终止" class="headerlink" title="变度量法二次终止"></a>变度量法二次终止</h3><blockquote>
<ul>
<li>若一维搜索是精确的，则变度量法（BFGS、DFP）具有二次终止</li>
</ul>
</blockquote>
<ul>
<li><p>若$\triangle f(x^{(k)}) = 0, k \leq n$，则得到最优解
$x^{(k)}$</p>
</li>
<li><p>否则得到的搜索方向是共轭的，由扩展空间子定理，
$x^{(n+1)}$是最优解</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-25T16:04:19.000Z" title="3/26/2019, 12:04:19 AM">2019-03-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-19T07:50:35.000Z" title="7/19/2021, 3:50:35 PM">2021-07-19</time></span><span class="level-item"><a class="link-muted" href="/categories/Probability/">Probability</a></span><span class="level-item">2 minutes read (About 329 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Probability/inequality.html">概率不等式</a></h1><div class="content"><h2 id="Inequality"><a href="#Inequality" class="headerlink" title="Inequality"></a>Inequality</h2><h3 id="Azuma-Hoeffding-Inequality"><a href="#Azuma-Hoeffding-Inequality" class="headerlink" title="Azuma-Hoeffding Inequality"></a><em>Azuma-Hoeffding Inequality</em></h3><p><em>Azuma-Hoeffding</em> 不等式：设 ${X<em>i:i=0,1,2,\cdots}$ 是鞅差序列，且 $|X_k - X</em>{k-1}| &lt; c_k$，则</p>
<script type="math/tex; mode=display">\begin{align*}
super-martingale:
P(X_N - X_0 \geq t) \leq exp \left ( \frac {-t^2}
    {2\sum^N_{k=1} c_k^2} \right ) \\

sub-martingale:
P(X_N - X_0 \leq -t) \leq exp \left ( \frac {-t^2}
    {2\sum^N_{k=1} c_k^2} \right ) \\

martingale:
P(|X_N - X_0| \geq t) \leq exp \left ( \frac {-t^2}
    {2\sum^N_{k=1} c_k^2} \right )
\end{align*}</script><h3 id="Hoeffding-Inequality"><a href="#Hoeffding-Inequality" class="headerlink" title="Hoeffding Inequality"></a><em>Hoeffding Inequality</em></h3><p><em>Hoeffding</em> 不等式：考虑随机变量序列 $X_1, X_2, \cdots, X_N, X_i \in [a_i, b_i]$</p>
<ul>
<li><p>对随机变量 $\bar X = \frac 1 N \sum_{i=1}^N {X_i}$，对任意 $t&gt;0$ 满足</p>
<script type="math/tex; mode=display">\begin{align*}
P(\bar X - E \bar X \geq t) \leq exp(\frac {-2N^2t^2}
   {\sum_{i=1}^N (b_i - a_i)^2} ) \\
P(E \bar X - \bar X \geq t) \leq exp(\frac {-2N^2t^2}
   {\sum_{i=1}^N (b_i - a_i)^2} ) \\
\end{align*}</script></li>
<li><p>对随机变量 $S<em>N = \sum</em>{i=1}^N X_i$，对任意 $t&gt;0$ 满足</p>
<script type="math/tex; mode=display">\begin{align*}
P(S_N - E S_N \geqslant t) & \leqslant exp \left (
   \frac {-2t^2} {\sum_{i=1}^n (b_i - a_i)^2} \right ) \\
P(E S_N - S_N \geqslant t) & \leqslant exp \left (
   \frac {-2t^2} {\sum_{i=1}^n (b_i - a_i)^2} \right )  \\
\end{align*}</script></li>
</ul>
<blockquote>
<ul>
<li>两不等式可用绝对值合并，但将不够精确</li>
</ul>
</blockquote>
<h3 id="Bretagnolle-Huber-Carol-Inequility"><a href="#Bretagnolle-Huber-Carol-Inequility" class="headerlink" title="Bretagnolle-Huber-Carol Inequility"></a><em>Bretagnolle-Huber-Carol Inequility</em></h3><p><em>Bretagnolle-Huber-Carol</em> 不等式：${X_i: i=1,2,\cdots,N} i.i.d. M(p1, p_2, \cdots, p_k)$ 服从类别为 $k$ 的多项分布</p>
<script type="math/tex; mode=display">
p{\sum_{i=1}^k |N_i - Np_i| \geq \epsilon} \leq
    2^k exp \left ( \frac {- n\epsilon^2} 2  \right )</script><blockquote>
<ul>
<li>$N_i$：第 $i$ 类实际个数</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-21T09:27:37.000Z" title="3/21/2019, 5:27:37 PM">2019-03-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-03-08T12:42:17.000Z" title="3/8/2019, 8:42:17 PM">2019-03-08</time></span><span class="level-item"><a class="link-muted" href="/categories/C-C/">C/C++</a><span> / </span><a class="link-muted" href="/categories/C-C/Cstd/">Cstd</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/C-C/Cstd/math.html">C 数学库</a></h1><div class="content"></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/tags/Math/page/3/">Previous</a></div><div class="pagination-next"><a href="/tags/Math/page/5/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/tags/Math/">1</a></li><li><a class="pagination-link" href="/tags/Math/page/2/">2</a></li><li><a class="pagination-link" href="/tags/Math/page/3/">3</a></li><li><a class="pagination-link is-current" href="/tags/Math/page/4/">4</a></li><li><a class="pagination-link" href="/tags/Math/page/5/">5</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5385776267343559" data-ad-slot="6995841235" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>