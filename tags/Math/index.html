<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: Math - UBeaRLy</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="UBeaRLy"><meta property="og:url" content="https://xyy15926.github.io/"><meta property="og:site_name" content="UBeaRLy"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:author" content="UBeaRLy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io"},"headline":"UBeaRLy","image":["https://xyy15926.github.io/img/og_image.png"],"author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"UBeaRLy","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":""}</script><link rel="alternate" href="/atom.xml" title="UBeaRLy" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Math</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-19T01:28:38.000Z" title="7/19/2021, 9:28:38 AM">2021-07-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-20T02:25:49.000Z" title="7/20/2021, 10:25:49 AM">2021-07-20</time></span><span class="level-item"><a class="link-muted" href="/categories/Probability/">Probability</a></span><span class="level-item">5 minutes read (About 819 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Probability/stat_inference.html">统计推断</a></h1><div class="content"><h2 id="Likelihood"><a href="#Likelihood" class="headerlink" title="Likelihood"></a><em>Likelihood</em></h2><p>似然函数：表示统计模型参数中似然性的（参数的）函数</p>
<script type="math/tex; mode=display">
L(w|Y) = \alpha P(Y|W=w)</script><blockquote>
<ul>
<li>$Y$：观测所得结果，事件 $Y$</li>
<li>$W$：模型参数</li>
<li>$\alpha$：正常量</li>
</ul>
</blockquote>
<ul>
<li><p>似然函数可以理解为 <strong>条件概率的逆反</strong></p>
<ul>
<li>似然：在已知某些观测所得结果上，对有关事物性质的参数进行估计<ul>
<li>似然性：某个参数为特定值的可能性</li>
<li>单独查看某个似然值无价值，要将各种似然值一起比较</li>
</ul>
</li>
<li>概率：在已知某些参数上，预测之后观测所得到结果</li>
</ul>
</li>
<li><p>形式上，似然函数也是条件概率函数，但关注统计模型中参数</p>
<ul>
<li>似然函数不满足归一性，乘正常数仍然是似然函数</li>
<li>同一似然函数代表的模型中，某个参数具有多种可能，如果存在参数使得似然函数值最大，则该值为最合理的参数值<ul>
<li>假设不同模型（经验得到），选择不同的统计模型</li>
<li>则有不同的概率密度（分布）函数，得到不同的似然函数</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ul>
<li><p>最大似然估计：选取似然函数，整理之后求最大值点</p>
<ul>
<li>实际中一般选取似然函数对数作为求解对象，结果同直接求似然函数最大值点</li>
<li>似然函数最大值点不一定唯一，也不一定存在</li>
<li>相较于矩估计<ul>
<li>精度较高，信息损失少</li>
<li>计算量大</li>
</ul>
</li>
</ul>
</li>
<li><p>似然比检验：利用似然函数检测假设、限制是否有效</p>
<ul>
<li>将加入某个限制的复杂某些的似然函数最大值和简单模型的似然函数最大值比较，检测某个参数限制是否正确<ul>
<li>若参数限制正确，则不应造成似然函数最大值的大幅变动</li>
</ul>
</li>
<li><em>尼曼-尼尔森引理</em> 说明：似然比检验是所有具有同等显著性差异的检验中，最有统计效力的检验</li>
</ul>
</li>
</ul>
<h3 id="条件概率分布似然函数"><a href="#条件概率分布似然函数" class="headerlink" title="条件概率分布似然函数"></a>条件概率分布似然函数</h3><script type="math/tex; mode=display">\begin{align*}
L_P(W|X,Y) &= \prod P(Y|X,W) \\
&= \prod_{x,y} P(Y|X,W)^{N_{x,y}} \\
&= \prod_{x,y} P(Y|X,W)^{N * \tilde P(X,Y)} \\
log(L_P(W|X,Y)) &= N \sum_{x,y} \tilde P(X,Y) log(P(Y|X,W))
\end{align*}</script><blockquote>
<ul>
<li>$P$：（所选择）统计模型的概率分布函数</li>
<li>$\tilde P$：$X,Y$ 的实际分布</li>
<li>$X,Y$：离散随机变量，$X$ 自变量观察值、$Y$ 因变量观察值</li>
<li>$W$：条件概率分布 $P$ 的参数</li>
<li>$N$，$N_{x,y}$：样本数量，取值为 $x,y$ 的样本数量</li>
</ul>
</blockquote>
<ul>
<li><p>这里是条件概率分布的似然函数，用 $(X,Y)$ 联合分布同样</p>
<script type="math/tex; mode=display">\begin{align*}
L_P &= \prod P(X,Y|W) \\
&= \prod P(Y|X,W) P(X|W) \\
&= \prod P(Y|X,W) P(X) \\
&= \prod P(Y|X,W) \prod P(X)
\end{align*}</script><blockquote>
<ul>
<li>考虑 $W$ 是条件分布参数，与 $X$ 分布无关，有 $P(X|W) = P(X)$</li>
<li>再考虑似然函数乘正常数不改变性质，则结果同上</li>
</ul>
</blockquote>
</li>
<li><p>对数似然函数中，样本量 $N$ 可省略</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-12T02:06:33.000Z" title="7/12/2021, 10:06:33 AM">2021-07-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-19T11:00:51.000Z" title="7/19/2021, 7:00:51 PM">2021-07-19</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Statistics/">Statistics</a></span><span class="level-item">a few seconds read (About 111 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Statistics/stat_stats.html">统计量</a></h1><div class="content"><h2 id="统计量"><a href="#统计量" class="headerlink" title="统计量"></a>统计量</h2><p>统计量：统计理论中对数据进行分析、检验的变量</p>
<ul>
<li><p>传统的统计量具有显式解析表达式</p>
<ul>
<li>均值：数据之和除数量</li>
<li>中位数：数据中间者</li>
</ul>
</li>
<li><p>统计量同样可以理解为和数据相关<strong>优化问题的解</strong></p>
<ul>
<li>均值：离差平方和最小</li>
<li>中位数：划分均匀</li>
</ul>
<blockquote>
<ul>
<li>优化问题目标本身也是统计量</li>
</ul>
</blockquote>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-06-09T09:46:15.000Z" title="6/9/2021, 5:46:15 PM">2021-06-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-06-09T09:46:15.000Z" title="6/9/2021, 5:46:15 PM">2021-06-09</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a></span><span class="level-item">a few seconds read (About 5 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/inequality.html">常用不等式</a></h1><div class="content"><h2 id="Cauthy-Schwarz-不等式"><a href="#Cauthy-Schwarz-不等式" class="headerlink" title="Cauthy-Schwarz 不等式"></a><em>Cauthy-Schwarz</em> 不等式</h2><blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/22004031">https://zhuanlan.zhihu.com/p/22004031</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/129033407">https://zhuanlan.zhihu.com/p/129033407</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/70315155">https://zhuanlan.zhihu.com/p/70315155</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/85283405">https://zhuanlan.zhihu.com/p/85283405</a></li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-05-13T09:16:42.000Z" title="5/13/2021, 5:16:42 PM">2021-05-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:35:24.000Z" title="8/4/2021, 11:35:24 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a></span><span class="level-item">a few seconds read (About 40 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/equality.html">常用等式</a></h1><div class="content"><h2 id="常用定理"><a href="#常用定理" class="headerlink" title="常用定理"></a>常用定理</h2><h3 id="Lucas-定理"><a href="#Lucas-定理" class="headerlink" title="Lucas 定理"></a><em>Lucas</em> 定理</h3><script type="math/tex; mode=display">
C(n, m) \% p = (C(n//p, m//p) * C(n\%p, m\%p)) \% p</script><blockquote>
<ul>
<li>$p &lt; 10^5$：必须为素数</li>
</ul>
</blockquote>
<h3 id="Holder-定理"><a href="#Holder-定理" class="headerlink" title="Holder 定理"></a><em>Holder</em> 定理</h3><p>$|x|^{*}_p = |x|_q$</p>
<blockquote>
<ul>
<li>$\frac 1 p + \frac 1 q = 1$</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-26T11:01:08.000Z" title="4/26/2021, 7:01:08 PM">2021-04-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-02T10:44:10.000Z" title="7/2/2021, 6:44:10 PM">2021-07-02</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a></span><span class="level-item">2 minutes read (About 252 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/uncharted_concepts.html">未归类概念</a></h1><div class="content"><h3 id="Radial-Basis-Function"><a href="#Radial-Basis-Function" class="headerlink" title="Radial Basis Function"></a><em>Radial Basis Function</em></h3><ul>
<li><p><em>RBF</em> 径向基函数：取值仅依赖到原点距离的实值函数，即 $\phi(x) = \phi(|x|)$</p>
<ul>
<li>也可以按照距离某中心点 $c$ 的距离定义，即 $\phi(x) = \phi(|x-c|)$</li>
<li>其中距离一般为使用 $L_2$ 范数，即欧式距离</li>
<li>函数 $\phi$ 一般与 $|x|$ 负相关</li>
</ul>
</li>
<li><p>径向基函数最初用于解决多变量插值问题</p>
<ul>
<li>即以各样本为中心创建多个径向基函数</li>
<li>多个径向基函数加权加和即得到拟合的函数曲线，可用于函数插值</li>
</ul>
<p><img src="/imgs/rbf_for_interpolation.png" alt="rbf_for_interpolation"></p>
</li>
</ul>
<h4 id="常见径向基函数"><a href="#常见径向基函数" class="headerlink" title="常见径向基函数"></a>常见径向基函数</h4><blockquote>
<ul>
<li>定义 $r=|x-x_i|$</li>
</ul>
</blockquote>
<ul>
<li><p>高斯函数</p>
<script type="math/tex; mode=display">\phi(r) = e^{-(\epsilon r)^2}</script></li>
<li><p><em>Multiquadric</em> 多二次函数：</p>
<script type="math/tex; mode=display">\phi(r) = \sqrt {1 + (\epsilon r)^2}</script></li>
<li><p><em>Inverse Quadric</em> 逆二次函数：</p>
<script type="math/tex; mode=display">\phi(r) = \frac 1 {1 + (\epsilon r)^2}</script></li>
<li><p><em>Polyharmonic Spline</em> 多重调和样条：</p>
<script type="math/tex; mode=display">\begin{align*}
\phi(r) &= r^k, & k=1,3,5,\cdots \\
\phi(r) &= r^k (ln(r))^{}, & k=2,4,6,\cdots  \\
\end{align*}</script></li>
<li><p><em>Thin Plate Spline</em> 薄板样条（多重调和样条特例）：</p>
<script type="math/tex; mode=display">\phi(r) = r^2 ln(r)</script></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-08-26T01:53:43.000Z" title="8/26/2019, 9:53:43 AM">2019-08-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-08-26T01:53:48.000Z" title="8/26/2019, 9:53:48 AM">2019-08-26</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">10 minutes read (About 1504 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/online_optimization.html">在线最优化</a></h1><div class="content"><h2 id="Truncated-Gradient"><a href="#Truncated-Gradient" class="headerlink" title="Truncated Gradient"></a>Truncated Gradient</h2><h3 id="L1正则化法"><a href="#L1正则化法" class="headerlink" title="L1正则化法"></a>L1正则化法</h3><p>L1正则化</p>
<script type="math/tex; mode=display">
w^{(t+1)} = w^{(t)} - \eta^{(t)}g^{(t)} - \eta^{(t)} \lambda sgn(w^{(t)})</script><blockquote>
<ul>
<li>$\lambda$：正则化项参数</li>
<li>$sgn$：符号函数</li>
<li>$g^{(t)}=\nabla_w L(w^{(t)}, Z^{(t)})$：损失函数对参数梯度</li>
</ul>
</blockquote>
<ul>
<li>L1正则化项在0处不可导，每次迭代使用次梯度计算正则项梯度</li>
<li>OGD中每次根据观测到的一个样本进行权重更新
（所以后面正则项次梯度只考虑非0处？？？）</li>
</ul>
<h3 id="简单截断法"><a href="#简单截断法" class="headerlink" title="简单截断法"></a>简单截断法</h3><p>简单截断法：以$k$为窗口，当$t/k$非整数时，使用标准SGD迭代，
否则如下更新权重</p>
<script type="math/tex; mode=display">\begin{align*}
w^{(t+1)} & = T_0 (w^{(t)} - \eta^{(t)} G^{(t)}, \theta) \\

T_0(v_i, \theta) & = \left \{ \begin{array}{l}
    0, & |v_i| \leq \theta \\
    v_i, & otherwise
\end{array} \right.
\end{align*}</script><blockquote>
<ul>
<li>$w^{(t)}$：模型参数</li>
<li>$g^{(t)}$：损失函数对模型参数梯度</li>
<li>$T_0$：截断函数</li>
<li>$\theta$：控制参数稀疏性</li>
</ul>
</blockquote>
<h3 id="截断梯度法"><a href="#截断梯度法" class="headerlink" title="截断梯度法"></a>截断梯度法</h3><p>截断梯度法：以$k$为窗口，当$t/k$非整数时，使用标准SGD迭代，
否则如下更新权重</p>
<script type="math/tex; mode=display">\begin{align*}
w^{(t+1)} & = T_1(w^{(t)} - \eta^{(t)} g^{(t)}, \lambda^{(t)} \eta^{(t)},
    \theta) \\

T_1(v_i, \alpha, \theta) & = \left \{ \begin{array}{l}
    max(0, v_i - \alpha), & v_i \in [0, \theta] \\
    min(0, v_1 + \alpha), & v_i \in [-\theta, 0] \\
    v_i, & otherwise
\end{array} \right.
\end{align*}</script><blockquote>
<ul>
<li>$\lambda, \theta$：控制参数$w$稀疏性</li>
</ul>
</blockquote>
<ul>
<li><p>对简单截断的改进，避免在实际（OgD）中参数因训练不足过小
而被错误截断，造成特征丢失</p>
<p><img src="/imgs/truncated_gradient_compared_with_l1.png" alt="truncated_gradient_compared_with_l1"></p>
</li>
</ul>
<h2 id="Forward-Backward-Spliting"><a href="#Forward-Backward-Spliting" class="headerlink" title="Forward-Backward Spliting"></a>Forward-Backward Spliting</h2><p>FOBOS：前向后向切分，权重更新方式为<em>proximal method</em>如下</p>
<script type="math/tex; mode=display">\begin{align*}
w^{(t.5)} & = w^{(t)} - \eta^{(t)} g^{(t)} \\
w^{(t+1)} & = \arg\min_w \{ \frac 1 2 \|w - w^{(t.5)}\|
    + \eta^{(t+0.5)} \Phi(w) \} \\
& = \arg\min_w \{ \frac 1 2 \|w - w^{(t)} + \eta^{(t)} g^{(t)}\|
    + \eta^{(t+0.5)} \Phi(w) \}
\end{align*}</script><h3 id="L1-FOBOS"><a href="#L1-FOBOS" class="headerlink" title="L1-FOBOS"></a>L1-FOBOS</h3><p>L1-FOBOS：即令$Phi(w)=\lambda |w|_1$，则根据可加性如下</p>
<script type="math/tex; mode=display">\begin{align*}
w^{(t+1)} & = \arg\min_w \sum_{i=1}^N (\frac 1 2 (w_i - v_i)^2
    + \tilde \lambda |w_i|)
w_i^{(t+1)} = \arg\min_{w_i} (\frac 1 2 (w_i - v_i)^2
    + \tilde \lambda |w_i|)
\end{align*}</script><blockquote>
<ul>
<li>$V=[v_1, v_2, \cdots, v_N]:=w^{(t.5)}$：为方便</li>
<li>$\tilde \lambda := \eta^{t.5} \lambda$：为方便</li>
<li>$\eta^{t.5}$：学习率，常取
  $\eta^{(t)} \in \theta(\frac 1 {\sqrt t})$</li>
</ul>
</blockquote>
<ul>
<li><p>则对$w_i$求次梯度、分类讨论，解得</p>
<script type="math/tex; mode=display">
w_i^{(t+1)} = \left \{ \begin{array}{l}
   v_i - \tilde \lambda, & v_i > \tilde \lambda \\
   0, & |v_i| < \tilde \lambda \\
   v_i + \tilde \lambda, & v_i < -\tilde \lambda
\end{array} \right.</script><ul>
<li><p>可以理解为：到当前样本为止，维度权重小于阈值
$\eta^{(t.5)} \lambda$）时，认为该维度不够重要，
权重置为0</p>
</li>
<li><p>可视为$k=1, \theta=\infty$的Tg算法</p>
</li>
</ul>
</li>
<li><p>另外，显然有$w_i^{(t+1)} v_i \geq 0$</p>
<script type="math/tex; mode=display">\begin{align*}
\frac 1 2 (w_i^{(t+1)} - v_i)^2 + \tilde \lambda |w_i^{(t+1)}|
& = \frac 1 2((w_i^{(t+1)})^2 - 2 w_i^{(t+1)} v_i + v_i^2)
   + \tilde \lambda |w_i^{(t+1)}| \\
& \leq \frac 1 2 v_i^2
\end{align*}</script><blockquote>
<ul>
<li>考虑$w_i^{(t+1)}$使得目标函数最小，带入$w=0$则得</li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="Regularized-Dual-Averaging"><a href="#Regularized-Dual-Averaging" class="headerlink" title="Regularized Dual Averaging"></a>Regularized Dual Averaging</h2><p>RDA算法：正则对偶平均算法，权重更新方式为
<strong>包含[增广]正则项的最速下降</strong></p>
<script type="math/tex; mode=display">
w^{(t+1)} = \arg\min_w {\frac 1 t \sum_{r=1}^t g^{(r)} w + \Phi(w)
    + \frac {\beta^{(t)}} t h(w)}</script><ul>
<li><p>目标函数包括三个部分</p>
<ul>
<li>$\frac 1 t \sum_{r=1}^t g^{(r)} w$：包含之前所有梯度
均值</li>
<li>$\Phi(w)$：正则项</li>
<li>$\frac {\beta^{(t)}} t h(w)$：额外正则项，严格凸，且
不影响稀疏性</li>
</ul>
</li>
<li><p>相较于TG、FOBOS是从另一方面求解在线最优化，更有效地提升
特征权重稀疏性</p>
</li>
</ul>
<h3 id="L1-RDA"><a href="#L1-RDA" class="headerlink" title="L1 RDA"></a>L1 RDA</h3><p>L1 RDA：令$\Phi(w) := \lambda |w|_1$，
再设$h(w) := |w|_2^2$，根据可加性则有</p>
<script type="math/tex; mode=display">\begin{align*}
w^{(t+1)} & = \arg\min_w \{ \frac 1 t \sum_{r=1}^t <g^{(t)}, w>
    + \lambda \|w\|_1 + \frac {\gamma} {2\sqrt t} \|w\|_2^2 \} \\
w_i^{(t+1)} & = \arg\min_{w_i} \{bar g_i^{(t)} w_i + \lambda |w_i|
    \frac {\gamma} {2 \sqrt t} w_i^2 \}
\end{align*}</script><blockquote>
<ul>
<li>$\lambda &gt; 0, \gamma &gt; 0$</li>
<li>$\bar g<em>i^{(t)} = \frac 1 t \sum</em>{r=1}^t g_i^{(r)}$</li>
</ul>
</blockquote>
<ul>
<li><p>对$w_i$求次梯度、置零、求解得</p>
<script type="math/tex; mode=display">
w_i^{(t+1)} = \left \{ \begin{array}{l}
   -\frac {\sqrt t} {\gamma} (\bar g^{(t)} - \lambda),
       & \bar g_i^{(t)} > \lambda \\
   0, & |\bar g_i^{(t)}| \leq \lambda \\
   -\frac {\sqrt t} {\gamma} (\bar g^{(t)} + \lambda),
       & \bar g_i^{(t)} < -\lambda \\
\end{array} \right.</script><ul>
<li>可以理解为：某维度梯度累计均值绝对值$|bar g_i^{(t)}$
小于阈值$\lambda$时，对应权重被置零、产生稀疏性</li>
</ul>
</li>
<li><p>相较于L1-FOBOS的截断</p>
<ul>
<li>截断阈值为常数，更加激进、容易产生稀疏性</li>
<li>截断判断对象为梯度累加均值，避免由于训练不足而产生
截断</li>
<li>只需条件$\lambda$参数，容易权衡精度、稀疏性</li>
</ul>
</li>
</ul>
<h2 id="Follow-the-Regularized-Leader"><a href="#Follow-the-Regularized-Leader" class="headerlink" title="Follow the Regularized Leader"></a>Follow the Regularized Leader</h2><p>FTRL：综合考虑L1-RDA、L1-FOBOS</p>
<h3 id="L1-FOBOS、L1-RDA变换"><a href="#L1-FOBOS、L1-RDA变换" class="headerlink" title="L1-FOBOS、L1-RDA变换"></a>L1-FOBOS、L1-RDA变换</h3><ul>
<li><p>将L1-FOBOS类似近端算法收敛证明中展开、去除无关项、放缩，
得到类似L1-RDA目标函数</p>
<script type="math/tex; mode=display">\begin{align*}
w^{(t+1)} & = \arg\min_w \{ \frac 1 2 \|w - w^{(t)} +
   \eta^{(t)} g^{(t)}\| + \eta^{(t)} \lambda \|w\|_1 \} \\
& = \arg\min_w \{ g^{(t)} w + \lambda \|w\|_1 +
   \frac 1 {2 \eta^{(t)}} \|w - w^{(t)}\|_2^2 \}
\end{align*}</script></li>
<li><p>将L1-RDA目标函数整体整体放缩，得到</p>
<script type="math/tex; mode=display">
w^{(t+1)} = \arg\min_w \{ g^{(1:t)} w + t \lambda \|w\|_1
   + \frac 1 {2\eta^{(t)}} \|w - 0\|_2^2 \}</script><blockquote>
<ul>
<li>$g^{(1:t)} := \sum_{r=1}^t g^{(r)}$</li>
</ul>
</blockquote>
</li>
<li><p>FTRL综合考虑L1-FOBOS、L1-RDA，得到目标函数</p>
<script type="math/tex; mode=display">
w^{(t+1)} = \arg\min_w \{ g^{(1:t)} W + \lambda_1 \|w\|_1
   + \frac {\lambda_2} 2 \|w\|_2^2 + \frac 1 2
   \sum_{r=1}^t \sigma^{(r)} \|w - w^{(r)}\|_2^2 \}</script><ul>
<li>使用累加梯度更新，避免因训练不充分错误截断</li>
<li>包含L1-FOBOS、L1-RDA全部正则化项</li>
</ul>
</li>
</ul>
<h3 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h3><ul>
<li><p>将FTRL中最后一项拆分、去除无关项</p>
<script type="math/tex; mode=display">\begin{align*}
w^{(t+1)} & = \arg\min_w \{(g^{(1:t)} - \sum_{r=1}^t
   \sigma^{(r)} w^{(r)})w + \lambda_1 \|w\|_1 +
   \frac 1 2 (\lambda_2 + \sum_{r=1}^t \sigma^{(r)})
   \|w\|_2^2 + \frac 1 2 \sum_{r=1}^t \sigma^{(r)}
   \|w^{(r)}\|_2^2 \} \\
& = \arg\min_w \{ z^{(t)} w + \lambda_1 \|w\|_1
   + \frac 1 2 (\lambda_2 + \sum_{r=1}^t \sigma^{(r)})
   \|w\|_2^2 \} \\
z^{(t)} &= g^{(1:t)} - \sum_{r=1}^t \sigma^{(r)} w^{(r)}
\end{align*}</script></li>
<li><p>则同样根据可加性，对各分量求次梯度、置零、求解得</p>
<script type="math/tex; mode=display">
w_i^{(t+1)} = \left \{ \begin{array}{l}
   \frac 1 {\lambda_1 + \sum_{r=1}^t \sigma^{(r)}}
       (z_i^{(t)} - \lambda_1 z_i), & z_i > \lambda_1 \\
   0, & |z_i^{(t)}| \leq \lambda_1 \\
   \frac 1 {\lambda_1 + \sum_{r=1}^t \sigma^{(r)}}
       (z_i^{(t)} + \lambda_1 z_i), & z_i < -\lambda_1 \\
\end{array} \right.</script></li>
<li><p>其中学习率$\eta$为类似Adagrad优化器的学习率，但包括可学习
参数$\alpha, \beta$</p>
<script type="math/tex; mode=display">
\eta_i^{(t)} = \frac {\alpha} {\beta + \sqrt{\sum_{r=1}^t
   (g_i^{(r)})^2}}</script></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-29T13:16:01.000Z" title="7/29/2019, 9:16:01 PM">2019-07-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-29T13:16:01.000Z" title="7/29/2019, 9:16:01 PM">2019-07-29</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Algebra/">Math Algebra</a><span> / </span><a class="link-muted" href="/categories/Math-Algebra/Linear-Algebra/">Linear Algebra</a></span><span class="level-item">9 minutes read (About 1383 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Algebra/Linear-Algebra/matrix_decomposition.html">Matrix Decomposition</a></h1><div class="content"><h2 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解"></a>矩阵分解</h2><ul>
<li><p>矩阵加法分解：将矩阵分解为三角阵、对角阵之和</p>
<ul>
<li>常用于迭代求解线性方程组</li>
</ul>
</li>
<li><p>矩阵乘法分解：将矩阵分解为三角镇、对角阵、正交阵之积</p>
</li>
</ul>
<blockquote>
<ul>
<li>以下分解均在实数域上，扩展至复数域需同样将相应因子矩阵
  扩充至复数域上定义</li>
</ul>
</blockquote>
<h2 id="矩阵加法分解"><a href="#矩阵加法分解" class="headerlink" title="矩阵加法分解"></a>矩阵加法分解</h2><h3 id="Jacobi分解"><a href="#Jacobi分解" class="headerlink" title="Jacobi分解"></a>Jacobi分解</h3><p>Jacobi分解：将矩阵分解为对角阵、非对角阵</p>
<p><img src="/imgs/matrix_decomposition_jacobi.png" alt="matrix_decomposition_jacobi"></p>
<h3 id="Gauss-Seidel分解"><a href="#Gauss-Seidel分解" class="headerlink" title="Gauss-Seidel分解"></a>Gauss-Seidel分解</h3><p>Gauss-Seidel分解：将矩阵分解为上、下三角矩阵</p>
<p><img src="/imgs/matrix_decomposition_gauss_seidel.png" alt="matrix_decomposition_gauss_seidel"></p>
<h3 id="Successive-Over-Relaxation"><a href="#Successive-Over-Relaxation" class="headerlink" title="Successive Over Relaxation"></a>Successive Over Relaxation</h3><p>SOR：逐次超松弛迭代法，分解为对角、上三角、上三角矩阵，同时
增加权重$w$调整分解后比例</p>
<p><img src="/imgs/matrix_decomposition_sor.png" alt="matrix_decomposition_sor"></p>
<ul>
<li>利用内在等式应用的平衡性、不动点收敛理论可以快速迭代<ul>
<li>$x$拆分到等式左右两侧，可以视为$y=x$和另外函数交点</li>
<li>根据不动点收敛理论可以进行迭代求解</li>
</ul>
</li>
</ul>
<h2 id="LU系列分解"><a href="#LU系列分解" class="headerlink" title="LU系列分解"></a>LU系列分解</h2><h3 id="LU-Decomposition"><a href="#LU-Decomposition" class="headerlink" title="LU Decomposition"></a>LU Decomposition</h3><p>LU分解：将方阵分解为<em>lower triangualr matrix</em>、
<em>upper triangluar matrix</em></p>
<script type="math/tex; mode=display">\begin{align*}
A & = L U \\

\begin{bmatrix}
a_{1,1} & a_{1,2} & \cdots & a_{1,m} \\
a_{2,1} & a_{2,2} & \cdots & a_{2,m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m,1} & a_{m,2} & \cdots & a_{m,m}
\end{bmatrix} & = 

\begin{bmatrix}
l_{1,1} & 0 & \cdots & 0 \\
l_{2,1} & l_{2,2} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
l_{m,1} & l_{m,2} & \cdots & l_{m,m}
\end{bmatrix}

\begin{bmatrix}
u_{1,1} & u_{1,2} & \cdots & u_{1,m} \\
0 & u_{2,2} & \cdots & u_{2,m} \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & u_{m,m}
\end{bmatrix}

\end{align*}</script><blockquote>
<ul>
<li>$L$：下三角矩阵</li>
<li>$U$：上三角矩阵</li>
</ul>
</blockquote>
<ul>
<li>特别的可以要求某个矩阵对角线元素为1</li>
<li>几何意义：由单位阵出发，经过竖直、水平切变</li>
</ul>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul>
<li><p>LU分解实际上不需要额外存储空间，矩阵L、U可以合并存储</p>
</li>
<li><p>LU分解可以快速求解线性方程组，可以视为高斯消元法的矩阵
形式</p>
<ul>
<li><p>得到矩阵LU分解后，对任意向量b，可使用<strong>已有</strong>LU分解
求解</p>
<ul>
<li>L为消元过程中的行系数和对角线全为1的下三角矩阵
（负系数在矩阵中为正值）</li>
<li>U为消元结果上三角矩阵</li>
</ul>
</li>
<li><p>则解方程组$Ax=b$等价于$LUx=b$</p>
<ul>
<li>先求解$Ly=b$</li>
<li>再求解$Ux=x$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="LDU-Decomposition"><a href="#LDU-Decomposition" class="headerlink" title="LDU Decomposition"></a>LDU Decomposition</h3><p>LDU分解：将矩阵分解为下三角、上三角、对角矩阵</p>
<script type="math/tex; mode=display">\begin{align*}
A & = L D U \\

\begin{bmatrix}
a_{1,1} & a_{1,2} & \cdots & a_{1,m} \\
a_{2,1} & a_{2,2} & \cdots & a_{2,m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m,1} & a_{m,2} & \cdots & a_{m,m}
\end{bmatrix} & = 

\begin{bmatrix}
1 & 0 & \cdots & 0 \\
l_{2,1} & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
l_{m,1} & l_{m,2} & \cdots & 1
\end{bmatrix}

\begin{bmatrix}
u_{1,1} & 0 & \cdots & 0\\
0 & 0 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & u_{m,m}
\end{bmatrix}

\begin{bmatrix}
1 & u_{1,2}/u_{1,1} & \cdots & u_{1,m}/u_{1,1} \\
0 & 1 & \cdots & u_{2,m}/u_{2,2} \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1
\end{bmatrix}

\end{align*}</script><ul>
<li>LU分解可以方便的得到LDU分解：提取对角阵、然后对应矩阵
元素等比缩放</li>
</ul>
<h3 id="PLU-Q-Decomposition"><a href="#PLU-Q-Decomposition" class="headerlink" title="PLU[Q] Decomposition"></a>PLU[Q] Decomposition</h3><blockquote>
<ul>
<li>PLU分解：将方阵分解为置换矩阵、下三角、上三角矩阵</li>
<li>PLUQ分解：将方阵分解为置换矩阵、下三角、上三角、置换矩阵</li>
</ul>
</blockquote>
<ul>
<li>考虑$P^{-1}A=LU$，交换$A$行即可作普通LU分解，PLUQ分解
类似</li>
<li>PLU分解数值稳定性好、实用工具</li>
</ul>
<h3 id="LL-Cholesky-Decomposition"><a href="#LL-Cholesky-Decomposition" class="headerlink" title="LL/Cholesky Decomposition"></a>LL/Cholesky Decomposition</h3><p>LL分解：将对称阵分解为下三角、转置</p>
<script type="math/tex; mode=display">\begin{align*}
A & = L L^T \\

\begin{bmatrix}
a_{1,1} & a_{1,2} & \cdots & a_{1,m} \\
a_{2,1} & a_{2,2} & \cdots & a_{2,m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m,1} & a_{m,2} & \cdots & a_{m,m}
\end{bmatrix} & = 

\begin{bmatrix}
l_{1,1} & 0 & \cdots & 0 \\
l_{2,1} & l_{2,2} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
l_{m,1} & l_{m,2} & \cdots & l_{m,m}
\end{bmatrix}

\begin{bmatrix}
l_{1,1} & l_{2,1} & \cdots & l_{m,1} \\
0 & l_{2,2} & \cdots & l_{m,2} \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & l_{m,m}
\end{bmatrix}

\end{align*}</script><ul>
<li><p>Cholesky分解常用于分解$A^TA$</p>
<ul>
<li>常用于相关分析，分解相关系数阵、协方差阵</li>
</ul>
</li>
<li><p>相较于一般LU分解，Cholesky分解速度更快、数值稳定性更好</p>
</li>
</ul>
<blockquote>
<ul>
<li>类似的有LDL分解，同时提取对角线元素即可</li>
</ul>
</blockquote>
<h2 id="Singular-Value-Decomposition"><a href="#Singular-Value-Decomposition" class="headerlink" title="Singular Value Decomposition"></a>Singular Value Decomposition</h2><p><em>SVD</em>奇异值分解：将矩阵分解为正交矩阵、对角矩阵、正交矩阵</p>
<script type="math/tex; mode=display">
M_{m*n} = U_{m*r} \Sigma_{r*r} V_{n*r}^T</script><ul>
<li><strong>特征值分解</strong>在任意矩阵上推广：相应的特征值、特征向量
被称为奇异值、奇异向量</li>
<li>几何意义：由单位阵出发，经旋转、缩放、再旋转</li>
</ul>
<h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><ul>
<li><p>$\Sigma$对角线元素为$M^T M$、$M M^T$的奇异值</p>
<ul>
<li>可视为在输入输出间进行标量的放缩控制</li>
<li>同$U$、$V$的列向量相对应</li>
</ul>
</li>
<li><p>$U$的列向量称为左奇异向量</p>
<ul>
<li>$M M^T$的特征向量</li>
<li>与$M$正交的“输入”或“分析”基向量</li>
</ul>
</li>
<li><p>$V$的列向量成为右奇异向量</p>
<ul>
<li>$M^T M$的特征向量</li>
<li>与$M$正交的“输出”基向量</li>
</ul>
</li>
</ul>
<h3 id="低阶近似"><a href="#低阶近似" class="headerlink" title="低阶近似"></a>低阶近似</h3><ul>
<li><p>对$m * n$阶原始矩阵$M$</p>
<ul>
<li>设其秩为$K \leq min(m, n)$，奇异值为
$d_1 \geq d_2 \geq \cdots \geq d_K &gt; 0$</li>
<li>不失一般性可以设其均值为0</li>
</ul>
</li>
<li><p>根据<em>Eckart and Young</em>的结果</p>
<script type="math/tex; mode=display">
\forall r \leq K, \sum_{k=1}^r d_k u_k v_k^T =
   \arg\min_{\bar M \in M(r)} \| M - \bar M \|_F^2</script><blockquote>
<ul>
<li>$u_k, v_k$：$U, V$的第$k$列向量</li>
<li>$|M|_F$：矩阵的Frobenius范数</li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="QR-Decomposition"><a href="#QR-Decomposition" class="headerlink" title="QR Decomposition"></a>QR Decomposition</h2><p>QR分解：将矩阵分解为正交矩阵、上三角矩阵</p>
<script type="math/tex; mode=display">\begin{align*}
A = Q R
\end{align*}</script><ul>
<li>几何意义：由单位阵出发，经旋转、切变</li>
</ul>
<h3 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h3><ul>
<li>正交矩阵逆为其转置，同样可以方便求解线性方程组</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-29T13:16:01.000Z" title="7/29/2019, 9:16:01 PM">2019-07-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-29T13:16:01.000Z" title="7/29/2019, 9:16:01 PM">2019-07-29</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">13 minutes read (About 1892 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/proxmial_method.html">Proximal Gredient Method</a></h1><div class="content"><h2 id="Proximal-Operator"><a href="#Proximal-Operator" class="headerlink" title="Proximal Operator"></a><em>Proximal Operator</em></h2><script type="math/tex; mode=display">
prox_{f}(x) = \arg\min_u (f(u) + \frac 1 2 \|u - x\|^2)</script><blockquote>
<ul>
<li>$f(x)$：凸函数</li>
</ul>
</blockquote>
<ul>
<li>由于$L_2$范数的强凸性，近端算子也强凸，解总是唯一存在</li>
<li>直观理解：寻找距离点$x$不太远、$f(u)$尽可能小的$u$</li>
<li>以下算法都是近端算法的特例<ul>
<li><em>shrinkage thresholding algorithm</em></li>
<li><em>projected Landweber</em></li>
<li><em>projected gradient</em></li>
<li><em>alternating projections</em></li>
<li><em>alternating-directions method of multipliers</em></li>
<li><em>alternating split Bregman</em></li>
</ul>
</li>
</ul>
<p><img src="/imgs/proximal_operator.png" alt="proximal_operator"></p>
<blockquote>
<ul>
<li>近端算子连续可微</li>
</ul>
</blockquote>
<h3 id="Moreau-Envolop"><a href="#Moreau-Envolop" class="headerlink" title="Moreau Envolop"></a><em>Moreau Envolop</em></h3><script type="math/tex; mode=display">\begin{align*}
M_{\gamma, f}(x) & = prox_{\gamma, f}(x) \\
&= \arg\min_u (f(u) + \frac 1 {2\gamma} \|u - x\|^2) \\
\nabla prox_{\gamma, f}(x) & = \frac 1 {\gamma}(x - prox_f(x))
\end{align*}</script><ul>
<li>$\gamma &gt; 0$：平衡参数，$\gamma = 1$即为普通近端算子</li>
</ul>
<h3 id="近端算子求解"><a href="#近端算子求解" class="headerlink" title="近端算子求解"></a>近端算子求解</h3><ul>
<li><p>对一般凸$f(x)$，通常使用次梯度进行优化，其近端算子解为
（即解变动方向$p-x$为负次梯度方向）</p>
<script type="math/tex; mode=display">
p = prox_f(x) \Leftrightarrow x - p \in \partial f(p)
   \quad (\forall (x,p) \in R^N * R^N)</script></li>
<li><p>对光滑凸函数$f$，上述等式对其近端算子约简为
（即解变动方向$p-x$为负梯度方向）</p>
<script type="math/tex; mode=display">
p = prox_f(x) \Leftrightarrow x-p = \bigtriangledown f(p)</script></li>
</ul>
<h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><h4 id="分离函数"><a href="#分离函数" class="headerlink" title="分离函数"></a>分离函数</h4><script type="math/tex; mode=display">\begin{align*}
f(x_1, \cdots, x_m) & = \sum_{i=1}^m f_i(x_i) \\
prox_f(x_1, \cdots, x_m) & = [prox_{f_1}(x_1), \cdots, prox_{fm}(x_m)]
\end{align*}</script><ul>
<li><p>取$f(x) = |x|_1$，即可得即软阈值算子</p>
<script type="math/tex; mode=display">
(prox_{\gamma, f}(x))_i = \left \{ \begin{array}{l}
   x_i - \gamma, & x_i \geq \gamma \\
   0, & |x_i| < \gamma \\
   x_i + \gamma, & x_i \leq -\gamma
\end{array} \right.</script><blockquote>
<ul>
<li>参考坐标下降：近端算子中二次项中各分量无关，所以一轮
 迭代即为最优解</li>
</ul>
</blockquote>
</li>
</ul>
<h4 id="仿射函数分解"><a href="#仿射函数分解" class="headerlink" title="仿射函数分解"></a>仿射函数分解</h4><script type="math/tex; mode=display">\begin{align*}
f(x) & = g(Ax + b) \\
prox_f(x) & = x + \frac 1 {\alpha} A^T (prox_{\alpha g}(Ax + b) - Ax - b)
\end{align*}</script><blockquote>
<ul>
<li>$A^T A = \alpha I, \alpha &gt; 0$：线性变换</li>
<li>$g$：良好闭凸函数</li>
</ul>
</blockquote>
<h4 id="第一投影定理"><a href="#第一投影定理" class="headerlink" title="第一投影定理"></a>第一投影定理</h4><blockquote>
<ul>
<li>取$f(x)$为示性函数、约束条件，即得到投影算子</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">\begin{align*}
prox_{\gamma, f}(x) & = proj_C(x) = \arg\min_{u \in C}
    \|u - x\|_2^2 \\
f(x) & = I_C(x) = \left \{ \begin{array}{l}
        0, x \in C \\
        \infty, x \notin C
    \end{array} \right.
\end{align*}</script><h4 id="第二临近定理"><a href="#第二临近定理" class="headerlink" title="第二临近定理"></a>第二临近定理</h4><blockquote>
<ul>
<li>$f$为良好闭凸函数，则以下三条等价<blockquote>
<ul>
<li>$y = prox_f(x)$</li>
<li>$x - y \in \partial f(y)$：由近端算子定义即得</li>
<li>$\forall z, <x - y, z - y> \leq f(z) - f(y)$</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h4 id="Moreau-Decomposition"><a href="#Moreau-Decomposition" class="headerlink" title="Moreau Decomposition"></a><em>Moreau Decomposition</em></h4><script type="math/tex; mode=display">\begin{align*}
prox_f(x) + prox_{f^{*}}(x) & = x \\
prox_{\lambda f}(x) + \lambda prox_{f^{*}/lambda}(x/\lambda) & = x,
    \lambda > 0
\end{align*}</script><h4 id="最小值"><a href="#最小值" class="headerlink" title="最小值"></a>最小值</h4><script type="math/tex; mode=display">\begin{align*}
\min_x prox_f(x) & = \min_x f(x) \\
\arg\min_x prox_f(x) & = \arg\min_x f(x)
\end{align*}</script><p>证明</p>
<script type="math/tex; mode=display">\begin{align*}
f(x_f) & = f(x_f) + \frac 1 2 \|x_f - x_f\|_2^2 \\
& \geq \min_u {f(u) + \frac 1 2 \|u - x_f\|_2^2} \\
& = prox_f(x_f) \\
& \geq prox_f(x_p) \\
& = f(x_p) + \frac 1 2 \|x_p - x_f\|_2^2 \\
& \geq f(x_p) \geq f(x_f)
\end{align*}</script><blockquote>
<ul>
<li>$x_f = \arg\min_x f(x)$</li>
<li>$x_p = \arg\min_x prox_f(x)$</li>
</ul>
</blockquote>
<h3 id="例"><a href="#例" class="headerlink" title="例"></a>例</h3><ul>
<li>$f(x)=c$：<script type="math/tex">prox_{f}(x) = x</script></li>
</ul>
<h4 id="Projection-Operator"><a href="#Projection-Operator" class="headerlink" title="Projection Operator"></a><em>Projection Operator</em></h4><p>投影算子</p>
<script type="math/tex; mode=display">\begin{align*}
proj_C(x) & = \arg\min_{y \in C} \|y - x\|^2 \\
& = \arg\min_{y \in R^N} l_C(x) + \frac 1 2 \|y-x\|^2
\end{align*}</script><ul>
<li>点$x$在凸集$C$上的投影：$X$上距离$x$的欧式距离最近的点</li>
</ul>
<h4 id="Alternating-Projection-Method"><a href="#Alternating-Projection-Method" class="headerlink" title="Alternating Projection Method"></a><em>Alternating Projection Method</em></h4><p><em>POCS/project onto convex sets method</em>：用于解同时满足多个
凸约束的算法</p>
<ul>
<li><p>$f_i$作为非空闭凸集$C_i$示性函数，表示一个约束，则整个
问题约简为<em>convex feasibility problem</em></p>
</li>
<li><p>只需要找到位于所有$C_i$交集的解即可</p>
</li>
<li><p>每次迭代</p>
<script type="math/tex; mode=display">
x^{(k+1)} = P_{C_1}P_{C_2} \cdots P_{C_n}x_k</script></li>
</ul>
<blockquote>
<ul>
<li>在其他问题中投影算子不再适合，需要更一般的算子，在其他
  各种同样的凸投影算子中，近端算子最合适</li>
</ul>
</blockquote>
<h2 id="Proximal-Gradient-Method"><a href="#Proximal-Gradient-Method" class="headerlink" title="Proximal Gradient Method"></a><em>Proximal Gradient Method</em></h2><p>近端算法：分两步分别优化可微凸$F(x)$、凸$R(x)$，近似优化目标
函数整体，不断迭代直至收敛</p>
<script type="math/tex; mode=display">
\min_{x \in \mathcal{H}}F(x) + R(x)</script><blockquote>
<ul>
<li>$F(x)$：可微、凸函数</li>
<li>$\nabla F(x)$：<em>Lipschitz continous</em>、利普希茨常数为$L$</li>
<li>$R(x)$：下半连续凸函函数，可能不光滑</li>
<li>$\mathcal{H}$：目标函数定义域集合，如：希尔伯特空间</li>
</ul>
</blockquote>
<ul>
<li><p><em>gredient step</em>：从$x^{(k)}$处沿$F(x)$负梯度方向微小移动
达到$x^{(k.5)}$</p>
<script type="math/tex; mode=display">
x^{(k.5)} = x^{(k)} - \gamma \nabla F(x^{(k)})</script></li>
<li><p><em>proximal operator step</em>：在$x^{(k.5)}$处应用$R(x)$近端
算子，即寻找$x^{(k.5)}$附近且使得$R(x)$较小点</p>
<script type="math/tex; mode=display">
x^{(k+1)} = prox_{\gamma R}(x^{(k.5)})</script></li>
</ul>
<h3 id="目标函数推导"><a href="#目标函数推导" class="headerlink" title="目标函数推导"></a>目标函数推导</h3><script type="math/tex; mode=display">\begin{align*}
prox_{\gamma R}(x - \gamma \nabla F(x)) & = \arg\min_u
    (R(u) + \frac 1 {2\gamma} \|u - x + \gamma \nabla F(x)\|_2^2) \\
& = \arg\min_u (R(u) + \frac {\gamma} 2 \|\nabla F(x)\|_2^2 +
    \nabla F(x)^T (u-x) + \frac 1 {2\gamma} \|u-x\|_2^2) \\
& = \arg\min_u (R(u) + F(x) + \nabla F(x)^T (u-x) +
    \frac 1 {2\gamma} \|u - x\|_2^2) \\
& \approx \arg\min_u(R(u) + F(u))
\end{align*}</script><blockquote>
<ul>
<li>$\frac {\gamma} 2 |\nabla F(x)|_2^2, F(x)$：与$u$无关
  ，相互替换不影响极值</li>
<li>$0 &lt; \gamma \leq \frac 1 L$：保证最后反向泰勒展开成立</li>
</ul>
</blockquote>
<ul>
<li><p>则$prox_{\gamma R}(x-\gamma \nabla F(x))$解即为
“原问题最优解”（若泰勒展开完全拟合$F(x)$）</p>
<ul>
<li>近端算法中距离微调项部分可加法分离</li>
<li>若$R(x)$部分也可分离，则整个目标函数可以分离，可以
<strong>拆分为多个一元函数分别求极值</strong></li>
</ul>
</li>
<li><p>考虑泰勒展开是局部性质，$u$作为极小值点只能保证在$x$附近
领域成立，可将近端算子解作为下个迭代点</p>
<script type="math/tex; mode=display">
x^{(k+1)} = prox_{\gamma R}(x^{(k)} - \gamma \nabla
   F(x^{(k)}))</script></li>
<li><p>迭代终止条件即</p>
<script type="math/tex; mode=display">
\hat x = prox_{\gamma R}(\hat x - \gamma \nabla F(\hat x))</script></li>
</ul>
<h4 id="二阶近似证明"><a href="#二阶近似证明" class="headerlink" title="二阶近似证明"></a>二阶近似证明</h4><script type="math/tex; mode=display">\begin{align*}
F(u) & = F(x) + \nabla F(x)^T (u - x) + \frac 1 2
    (u - x)^T \nabla^2 F(\zeta)(u - x) \\
& \geq F(x) + \nabla F(x)^T (u - x) \\
& \leq F(x) + \nabla F(x)^T (u - x) + \frac L 2 \|u-x\|^2
\end{align*}</script><blockquote>
<ul>
<li>$\nabla^2 F(\zeta)$：凸函数二阶导正定</li>
<li>$|\nabla F(u) - \nabla F(x)|_2 \leq L |u-x|_2$：
  $\nabla F(x)$利普希茨连续性质</li>
</ul>
</blockquote>
<h3 id="参数确定"><a href="#参数确定" class="headerlink" title="参数确定"></a>参数确定</h3><ul>
<li><p>$L$已知时，可直接确定$\gamma \in (0, \frac 1 L]$，</p>
</li>
<li><p>否则可线性迭代搜索$\gamma := \beta \gamma,\beta &lt; 1$，
直至</p>
<script type="math/tex; mode=display">
F(x - PG_{\gamma R}(x)) \leq F(x) - \nabla F(x) PG_{\gamma R}(x)
   + \frac 1 2 \|PG_{\gamma R}(x)\|_2^2</script><blockquote>
<ul>
<li>$PG<em>{\gamma R}(x)=x-prox</em>{\gamma R}(x-\gamma \nabla F(x))$</li>
<li>直接根据下述利普希茨条件须求Hasse矩阵，计算量较大</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="反向推导"><a href="#反向推导" class="headerlink" title="反向推导"></a>反向推导</h3><ul>
<li><p>对$F(x)+R(x)$在$x_0$附近作泰勒展开</p>
<script type="math/tex; mode=display">
F(u)+R(u) \leq F(x) + \nabla F(x)^T (u - x) +
   \frac 1 {2\gamma} \|u - x\|_2^2 + R(x)</script><blockquote>
<ul>
<li>$\lambda \in (0, \frac 1 L]$</li>
<li>$L$：$F(x)$利普希茨常数</li>
<li>$\leq$：由Lipschitz连续可取</li>
</ul>
</blockquote>
<ul>
<li>则不等式右边就是$F(x)+R(x)$的一个上界，可以对将对其
求极小化转化对此上界求极小</li>
</ul>
</li>
<li><p>考虑对极小化目标添加常数项不影响极值，对不等式右侧添加
与$u$无关项$\frac \gamma 2 |\nabla F(x)|_2^2$、剔除
剔除$F(x)$凑出近端算子</p>
<script type="math/tex; mode=display">\begin{align*}
prox_{\gamma R} & = \arg\min_u (R(u) + \frac {\gamma} 2
   \|\nabla F(x)\|_2^2 + \nabla F(x)^T (u-x) +
   \frac 1 {2\gamma} \|u-x\|_2^2) \\
& = \arg\min_u (R(u) + \|u - x + \frac 1 {2\gamma} \nabla F(x)\|_2^2)
\end{align*}</script></li>
</ul>
<h2 id="近端算法推广"><a href="#近端算法推广" class="headerlink" title="近端算法推广"></a>近端算法推广</h2><h3 id="问题推广"><a href="#问题推广" class="headerlink" title="问题推广"></a>问题推广</h3><blockquote>
<ul>
<li>求解<em>non-differentiable</em>凸优化问题的通用投影形式</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
\min_{x \in R^N} \sum_{i=1}^N f_i(x)</script><blockquote>
<ul>
<li>$f_i(x)$：凸函数，不一定处处可微</li>
</ul>
</blockquote>
<ul>
<li><p>目标函数中包含不处处连续可微函数，整个目标函数不光滑</p>
<ul>
<li>无法使用传统的光滑优化手段，如：最速下降、共轭梯度</li>
<li>极小化条件为$0 \in \partial(F+R)(x)$</li>
</ul>
</li>
<li><p>分开考虑各个函数，对非光滑函数使用近端算子处理</p>
</li>
</ul>
<h3 id="算子推广"><a href="#算子推广" class="headerlink" title="算子推广"></a>算子推广</h3><blockquote>
<ul>
<li>考虑使用<em>Bregman Divergence</em>替代近端算子中欧式距离</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
prox_{\gamma, f}(x) = \arg\min_u (f(u) + \mu(u) - \mu(x) +
    <\nabla \mu(x), u - x>)</script><blockquote>
<ul>
<li>取$\mu(x) = \frac 1 2 |x|_2^2$时，即为普通近端算子</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-29T13:16:01.000Z" title="7/29/2019, 9:16:01 PM">2019-07-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:25:54.000Z" title="8/4/2021, 11:25:54 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">5 minutes read (About 697 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/coordinate_descent.html">Coordinate Descent</a></h1><div class="content"><h2 id="坐标下降"><a href="#坐标下降" class="headerlink" title="坐标下降"></a>坐标下降</h2><p>坐标下降法：在当前点处延一个坐标方向进行一维搜索以求得函数
的局部极小值</p>
<ul>
<li>非梯度优化算法，但能提供超过一阶的信息<ul>
<li>SMO算法就是两块贪心坐标下降</li>
</ul>
</li>
</ul>
<h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul>
<li><p>优化方向从算法一开始就固定，如：选择线性空间中一组基作为
搜索方向</p>
</li>
<li><p>循环极小化各坐标方向上目标函数值，即：若$x^k$给定，则</p>
<script type="math/tex; mode=display">
x_i^{(k+1)} = \arg\min_{x \in R} f(x_1^{k+1}, \cdots,
   x_{i-1}^{k+1}, x, x_{i+1}^{k}, \cdots, x_n^k)</script><blockquote>
<ul>
<li>$k$：第k轮迭代</li>
<li>$i$：某轮迭代中更新第i个方向</li>
</ul>
</blockquote>
</li>
<li><p>对初始值为$X_0$得到迭代序列$X_1, \cdots, X_n$，对精确
一维搜索类似最速下降有</p>
<script type="math/tex; mode=display">
F(X_0) \geq F(X_1) \geq \cdots \geq F(x_n)</script></li>
<li><p>若某轮迭代中目标函数无法被有优化，说明已经达到驻点</p>
</li>
</ul>
<h3 id="Adaptive-Coordinate-Descent"><a href="#Adaptive-Coordinate-Descent" class="headerlink" title="Adaptive Coordinate Descent"></a>Adaptive Coordinate Descent</h3><p>自适应坐标下降：变换坐标系使得在考虑目标函数的情况下，新坐标
间尽可能不相关</p>
<ul>
<li><p>对非可拆分函数（可加？），算法可能无法在较小迭代步数中
求得最优解</p>
<ul>
<li>可采用适当坐标系加速收敛，如：主成分分析进行自适应
编码</li>
<li>性能远超过传统坐标下降算法，甚至可以达到梯度下降的
性能</li>
</ul>
<p><img src="/imgs/adaptive_coordinate_descent_illustration.png" alt="adaptive_coordinate_descent_illustration"></p>
</li>
<li><p>自适应坐标下降具有以下特性，和最先进的进化算法相当</p>
<ul>
<li>缩放不变性</li>
<li>旋转不变性</li>
</ul>
</li>
</ul>
<h3 id="Block-Coordinate-Descent"><a href="#Block-Coordinate-Descent" class="headerlink" title="Block Coordinate Descent"></a>Block Coordinate Descent</h3><p>块坐标下降：在当前点处在一个超平面内方向进行搜索以求得函数
的局部极小值</p>
<ul>
<li>即同时更新一组坐标的坐标下降</li>
</ul>
<h3 id="例"><a href="#例" class="headerlink" title="例"></a>例</h3><h4 id="Lasso求解"><a href="#Lasso求解" class="headerlink" title="Lasso求解"></a>Lasso求解</h4><ul>
<li><p>目标函数</p>
<script type="math/tex; mode=display">
L(x) = RSS(x) + \lambda \|x\|_1 = \frac 1 2 (Ax - y)^T(Ax - y)
   + \lambda \|x\|_1</script></li>
<li><p>RSS求导</p>
<script type="math/tex; mode=display">\begin{align*}
\frac {\partial RSS} {\partial x} & = (Ax - y)^T A \\
(\frac {\partial RSS} {\partial x})_i & = (Ax - y)^T A_{:i} \\
& = (Ax_{i0} - y)^T A_{:i} + x_i A_{:i}^T A_{:i} \\
& = z_i + \rho_i x_i
\end{align*}</script><blockquote>
<ul>
<li>$(\frac {\partial RSS} {\partial x})_i$：RSS对$x$
 导数第$i$分量，即对$x_i$偏导</li>
<li>$A_{:i}$：$A$第$i$列</li>
<li>$x_{i0}$：$x$第$i$分量置零</li>
<li>$z<em>i = (Ax</em>{i0} - y)^T A_{:i}$</li>
<li>$\rho<em>i = A</em>{:i}^T A_{:i}$</li>
</ul>
</blockquote>
</li>
<li><p>则$x_i$整体次梯度为</p>
<script type="math/tex; mode=display">
\frac {\partial L} {\partial x_i} = z_i + \rho_i x_i +
   \left \{ \begin{array}{l}
       -\lambda, & x_i < 0 \\
       [-\lambda, \lambda], & x_i = 0 \\
       \lambda, & x_i > 0
   \end{array} \right.</script></li>
<li><p>分类讨论：令整体次梯度为0求解$x_i$、回带确定参数条件</p>
<script type="math/tex; mode=display">
x_i = \left \{ \begin{array}{l}
   \frac {-z_i + \lambda} {\rho_i}, & z_i > \lambda \\
   0 , & -\lambda < z_i < \lambda \\
   \frac {-z_i - \lambda} {\rho_i}, & z_i < -\lambda
\end{array} \right.</script><blockquote>
<ul>
<li>此算子也称<em>soft threshholding</em></li>
</ul>
</blockquote>
<p><img src="/imgs/lasso_ridge_lse.svg" alt="lasso_ridge_lse"></p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-27T16:24:56.000Z" title="7/28/2019, 12:24:56 AM">2019-07-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-27T16:24:56.000Z" title="7/28/2019, 12:24:56 AM">2019-07-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Algebra/">Math Algebra</a><span> / </span><a class="link-muted" href="/categories/Math-Algebra/Linear-Algebra/">Linear Algebra</a></span><span class="level-item">19 minutes read (About 2878 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Algebra/Linear-Algebra/vector_matrix.html">Vector</a></h1><div class="content"><h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><ul>
<li>线性组合</li>
<li>向量空间</li>
<li>空间的基：向量空间的一组基是张成该空间的一个线性无关向量集</li>
<li>线性相关</li>
</ul>
<p><img src="/imgs/vector_rules_for_addition_and_scaling.png" alt="vector_rules_for_addition_and_scaling"></p>
<h3 id="向量点积"><a href="#向量点积" class="headerlink" title="向量点积"></a>向量点积</h3><ul>
<li><p>向量点积性质</p>
<ul>
<li><p>向量的数乘等比例影响点积，则可为每个向量找到共线单位向量满足 $u \cdot u=1$</p>
<p><img src="/imgs/vector_dot_scaling.gif" alt="vector_dot_scaling"></p>
</li>
<li><p>点积等同于向量 $b$ 左乘矩阵 $a^T$，即把向量 $b$ 压缩（线性变换）至向量 $a$ 方向上</p>
<p><img src="/imgs/vector_dot_as_matrix_production.gif" alt="vector_dot_as_matrix_production"></p>
</li>
</ul>
</li>
<li><p>点积 $a \cdot b$ 与投影关系（假设向量 $a$ 为单位向量）</p>
<ul>
<li><p>投影，即将向量 $b$ <strong>线性变换</strong> 至 $a$ 方向上的标量</p>
<ul>
<li>则投影可以用 $1 * n$ 矩阵表示</li>
<li>投影代表的矩阵则可通过利用基向量的变换结果求解</li>
</ul>
<p><img src="/imgs/vector_projection_as_transformer.gif" alt="vector_projection_as_transformer"></p>
</li>
<li><p>向量 $a$ 本身作为单位向量</p>
<ul>
<li>坐标轴上单位向量与 $a$ 的内积即为 $a$ 该方向分量，也即 $a$ 在该轴上投影</li>
<li>由对称性显然，坐标轴在 $a$ 方向投影等于 $a$ 在轴方向投影</li>
<li>则投影到向量 $a$ 代表的线性变换矩阵即为 $a^T$</li>
</ul>
<p><img src="/imgs/vector_dot_projection_duality.gif" alt="vector_dot_projection_duality"></p>
</li>
<li><p>扩展到一般情况</p>
<ul>
<li>考虑标量乘法对点积影响，坐标轴上向量与任意向量 $a$ 内积等价于投影</li>
<li>投影是线性变换，则对空间一组基的变换可以推导到空间中任意向量 $b$</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>高维空间到标量的线性变换与空间中一个向量对应，即应用线性变换等价于同该向量点积 <img src="/imgs/vector_dot_as_matrix_production_2.gif" alt="vector_dot_as_matrix_production"></li>
</ul>
</blockquote>
<h4 id="点积用途"><a href="#点积用途" class="headerlink" title="点积用途"></a>点积用途</h4><ul>
<li>向量证明基本都是都转换到点积上<ul>
<li>正定：行列式恒&gt;0</li>
<li>下降方向：内积&lt;0</li>
<li>方向（趋于）垂直：内积趋于0</li>
</ul>
</li>
</ul>
<h4 id="求和、积分、点积、卷积"><a href="#求和、积分、点积、卷积" class="headerlink" title="求和、积分、点积、卷积"></a>求和、积分、点积、卷积</h4><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>连续（函数）</th>
<th>离散（向量）</th>
</tr>
</thead>
<tbody>
<tr>
<td>单元累计</td>
<td>积分：按值出现频率加权求和</td>
<td>求和：向量视为分段函数积分</td>
</tr>
<tr>
<td>二元累计</td>
<td>卷积：连续卷积</td>
<td>点积：离散卷积的特殊情况，即仅向量对应位置分量乘积有定义</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<ul>
<li>卷积：累计中各点的值变为需累计的值，即二次累计</li>
</ul>
</blockquote>
<h3 id="向量叉积"><a href="#向量叉积" class="headerlink" title="向量叉积"></a>向量叉积</h3><p><img src="/imgs/vector_cross_formula.png" alt="vector_cross_formula"></p>
<ul>
<li><p>向量叉积意义</p>
<ul>
<li><p>向量叉积即寻找向量（到标量的线性变换），满足与其点积结果为张成的体积</p>
<p><img src="/imgs/vector_cross_as_volume.gif" alt="vector_cross_as_volume"></p>
</li>
<li><p>考虑点积性质，则向量叉积的方向与向量构成超平面垂直、模为超平面大小</p>
<p><img src="/imgs/vector_cross_direction.gif" alt="vector_cross_direction"></p>
</li>
</ul>
</li>
</ul>
<h3 id="一些规定"><a href="#一些规定" class="headerlink" title="一些规定"></a>一些规定</h3><ul>
<li><p>正交方向：向量空间 $R^n$ 中 $k, k \leq n$ 个向量 $q^{(1)}, \cdots, q^{(k)}$ 两两正交，则称其为 $k$ 个正交方向，若满足所有向量非 0，则称为 $k$ 个非 0 正交方向</p>
</li>
<li><p>向量左右</p>
<ul>
<li>左侧：向量逆时针旋转 $[0, \pi]$ 内</li>
<li>右侧：反左侧</li>
</ul>
</li>
</ul>
<h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><ul>
<li><p>矩阵（乘法）：对向量的变换</p>
<ul>
<li>对 $m * n$ 矩阵，即将 $n$ 维空间映射至 $m$ 维空间</li>
</ul>
</li>
<li><p>矩阵相关概念</p>
<ul>
<li>（矩阵）秩：空间维数</li>
<li>（矩阵）零空间/核：变换（左乘矩阵）后落在原点的向量的集合</li>
</ul>
<p><img src="/imgs/matrix_null_space.gif" alt="matrix_null_space"></p>
</li>
</ul>
<blockquote>
<ul>
<li>线性变换：保持空间中坐标轴仍为直线且原点保持不变的变换</li>
<li>此处若无特殊说明，向量均以列向量作为基础</li>
</ul>
</blockquote>
<h3 id="特殊矩阵"><a href="#特殊矩阵" class="headerlink" title="特殊矩阵"></a>特殊矩阵</h3><blockquote>
<ul>
<li>其中正交矩阵、三角阵、对角阵也被成为因子矩阵</li>
</ul>
</blockquote>
<ul>
<li><p><em>Orthogonal Matrix</em> 正交矩阵：和其转置乘积为单位阵的方阵</p>
<ul>
<li><p>左乘正交矩阵几何意义：等价于旋转</p>
<p><img src="/imgs/orthogonal_matrix_geo.png" alt="orthogonal_matrix_geo"></p>
</li>
</ul>
<blockquote>
<ul>
<li>酉矩阵/幺正矩阵：$n$ 个列向量是 $U$ 空间标准正交基的 $n$ 阶复方阵，是正交矩阵往复数域上的推广</li>
</ul>
</blockquote>
</li>
<li><p><em>Diagonal Matrix</em> 对角阵：仅对角线非0的矩阵</p>
<ul>
<li><p>左乘对角阵矩阵几何意义：等价于对坐标轴缩放</p>
<p><img src="/imgs/diagonal_matrix_geo.png" alt="diagonal_matrix_geo"></p>
</li>
</ul>
</li>
<li><p><em>Triangular Matrix</em> 上/下三角矩阵：左下/右上角全为0的方阵</p>
<ul>
<li>三角阵是高斯消元法的中间产物，方便进行化简、逐层迭代求解线性方程组</li>
<li><p>左乘上三角阵几何意义：等价于进行右上切变（水平斜拉）</p>
<p><img src="/imgs/upper_triangular_matrix_geo.png" alt="upper_triangular_matrix_geo"></p>
</li>
<li><p>左乘下三角阵几何意义：等价于进行左下切变（竖直斜拉）</p>
<p><img src="/imgs/lower_triangular_matrix_geo.png" alt="lower_triangular_matrix_geo"></p>
</li>
</ul>
</li>
<li><p><em>Transposation Matrix</em> 置换矩阵：系数只由 0、1 组成，每行、列恰好有一个 1 的方阵</p>
</li>
</ul>
<h3 id="矩阵常用公式"><a href="#矩阵常用公式" class="headerlink" title="矩阵常用公式"></a>矩阵常用公式</h3><h3 id="Sherman-Morrison-公式"><a href="#Sherman-Morrison-公式" class="headerlink" title="Sherman-Morrison 公式"></a><em>Sherman-Morrison</em> 公式</h3><blockquote>
<ul>
<li>设A是n阶可逆矩阵，$u, v$均为n为向量，若
  $1 + v^T A^{-1} u \neq 0$，则扰动后矩阵$A + u v^T$可逆<script type="math/tex; mode=display">
  (A + u v^T)^{-1} = A^{-1} - \frac {A^{-1} u v^T A^{-1}}
      {1 + v^T A^{-1} u}</script></li>
</ul>
</blockquote>
<h2 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h2><ul>
<li><p>矩阵乘法</p>
<ul>
<li><p>向量左乘矩阵：即是对向量进行变换</p>
<p><img src="/imgs/matrix_as_transformer.gif" alt="matrix_as_transformer"></p>
</li>
<li><p>矩阵乘积：复合变换</p>
<p><img src="/imgs/matrix_production.gif" alt="matrix_production"></p>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>矩阵乘法应按照从右往左阅读，右侧矩阵为输入、左侧矩阵为变换（向量默认为列向量时）</li>
</ul>
</blockquote>
<h3 id="Affline-Transformation"><a href="#Affline-Transformation" class="headerlink" title="Affline Transformation"></a><em>Affline Transformation</em></h3><p>仿射变换：对向量空间进行线性变换、平移得到另一个向量空间</p>
<p><img src="/imgs/affline_transformation.png" alt="affline_transformation"></p>
<script type="math/tex; mode=display">\begin{align*}
y &= Ax + b \\
y &= (A|b^T) \begin {bmatrix} x \\ 1 \end {bmatrix}
\end{align*}</script><blockquote>
<ul>
<li>$y \in R^n, x \in R^n$</li>
<li>$A \in R^{n * n}$：可视为产生旋转、放缩</li>
<li>$b \in R^n$：可视为产生平移</li>
</ul>
</blockquote>
<ul>
<li><p>仿射变换可以理解为：放缩、旋转、平移</p>
</li>
<li><p>从仿射变换的角度，对向量空间进行仿射变换</p>
<ul>
<li>$n+1$ 对变换前、变换后向量坐标即可以求解仿射变换的全部参数</li>
<li>变换后的向量之间仍然保留某种相关性，所以 $n+1$ 对向量坐标可以完全确定仿射变换</li>
</ul>
</li>
<li><p>从仿射变换几何含义，将向量空间中向量统一变换</p>
<ul>
<li>$n+1$ 个不共线 $n$ 维向量即唯一确定n维空间</li>
<li>若所有向量变换均遵循同一“线性”变换规则，即进行相同放缩、旋转、平移，则这样的变换可以使用仿射变换表示</li>
</ul>
</li>
<li><p>说明</p>
<ul>
<li>$n$ 变换前、变换后向量坐标可以求解 $A$（不考虑 $b$），但第 $n+1$ 对向量坐标未必满足 $A$ 变换</li>
<li>若 $n+2$ 对向量坐标不满足 $(A|b)$ 的解，则表示不是进行仿射变换</li>
</ul>
</li>
</ul>
<h3 id="Perspective-Transformation"><a href="#Perspective-Transformation" class="headerlink" title="Perspective Transformation"></a><em>Perspective Transformation</em></h3><p>透视变换：将向量空间映射到更高维度，再降维到另一向量空间</p>
<p><img src="/imgs/perspective_transformation.png" alt="perspective_transformation"></p>
<script type="math/tex; mode=display">\begin{align*}
y &= P \begin {bmatrix} x \\ 1 \end {bmatrix} \\
y &= \begin {bmatrix} A & b \\ c & p_{n+1,n+1} \end {bmatrix}
    \begin {bmatrix} x \\ 1 \end {bmatrix}
\end{align*}</script><blockquote>
<ul>
<li>$P \in R^{(n+1) <em> (n+1)}, A \in R^{n </em> n}$</li>
<li>$x \in R^n, y \in R^{n+1}$：这里默认$x$第$n+1$维为1</li>
<li>$c$：可视为产生透视，若其为0向量，则退化为仿射变换</li>
<li>$p_{n+1,n+1}$：可视为决定透视放缩，所以若是已确定新向量空间的“位置”，此参数无效，即 $n+2$ 对向量坐标即可求解变换</li>
</ul>
</blockquote>
<ul>
<li><p>透视变换虽然是向量空间变换至另一向量空间，但仍然存在一个透视“灭点”，作为所有透视线的交点</p>
<ul>
<li>对平面成像而言，“灭点”是成像平面、视角决定</li>
</ul>
</li>
<li><p>变换后 $y$ 维数增加，一般会再次投影、缩放回原维度空间，如原向量空间 $(R^n,1)$</p>
</li>
</ul>
<blockquote>
<ul>
<li>仿射变换可以视为是新的向量空间和原始空间“平行”的透视变换特例</li>
</ul>
</blockquote>
<h4 id="变换矩阵求解"><a href="#变换矩阵求解" class="headerlink" title="变换矩阵求解"></a>变换矩阵求解</h4><script type="math/tex; mode=display">\begin{align*}
\begin {bmatrix} P & b \\ c & p_{n+1,n+1} \end {bmatrix}
    \begin {bmatrix} x \\ 1 \end {bmatrix} &=
    \gamma \begin {bmatrix} x^{'} \\ 1 \end {bmatrix} \\
\Rightarrow Px + b &= \gamma x^{'} \\
    c^Tx + p_{n+1,n+1} &= \gamma \\
\Rightarrow Px + b &= (c^Tx + p_{n+1,n+1}) x^{'}
\end{align*}</script><blockquote>
<ul>
<li>考虑变换后再次缩放回更低维 $(R^n,1)$ 向量空间</li>
<li>$\gamma$：变换后向量缩放比例</li>
</ul>
</blockquote>
<ul>
<li>可解性<ul>
<li>共 $n+2$ 对变换前、后向量坐标，即 $n*(n+2)$ 组方程</li>
<li>对每对向量，其中 $n$ 组方程如上可以看出是齐次方程组，<strong>不包含常数项</strong></li>
<li>则对 $P \in R^{(n+1) * (n+1)}$ 中除 $p_{n+1,n+1}$ 其他项均可被其比例表示（不含常数项）</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>当然 $p_{n+1,n+1}$ 可以置 1 参加运算，不影响结果</li>
</ul>
</blockquote>
<h2 id="Determinant"><a href="#Determinant" class="headerlink" title="Determinant"></a><em>Determinant</em></h2><ul>
<li><p>矩阵行列式几何意义：线性变换对空间的拉伸比例</p>
<ul>
<li>行列式绝对值：拉伸的比例的绝对大小<ul>
<li>行列式为 0 时则表示空间降维</li>
<li>则显然应有 $det(M_1 * M_2) = det(M_1) det(M_2)$</li>
</ul>
</li>
<li>行列式正负号：拉伸的方向</li>
</ul>
<p><img src="/imgs/matrix_determinant_as_stretch.gif" alt="matrix_determinant_as_stretch"></p>
</li>
<li><p>矩阵行列式的用途</p>
<ul>
<li>行列式为 0 意味着矩阵表示降维变换，则对应线性方程组仅在方程组右侧在矩阵张成空间内，即扩展矩阵秩不增时有解</li>
</ul>
</li>
</ul>
<h3 id="特别的"><a href="#特别的" class="headerlink" title="特别的"></a>特别的</h3><ul>
<li><p>$2 * 2$ 矩阵 $\begin{vmatrix} a &amp; b \ c &amp; d \end{vmatrix} = ad - bc$</p>
<ul>
<li>$a, d$ 分别表示 $(1,0)$、$(0,1)$ 正向放缩比例</li>
<li>而 $b, c$ 则相应的为逆向放缩比例</li>
</ul>
<p><img src="/imgs/matrix_2_2_determinant_calculation.png" alt="matrix_2_2_determinant_calculation"></p>
</li>
<li><p>二维三点：行列式绝对值为三点构成三角形面积两倍</p>
<script type="math/tex; mode=display">
\begin{vmatrix}
   x_1 & y_1 & 1 \\
   x_2 & y_2 & 1 \\
   x_3 & y_3 & 1 \\
\end{vmatrix} = 
x_1y_2 + x_3y_1 + x_2y_3 - x_3y_2 - x_2y_1 - x_1y_3</script><blockquote>
<ul>
<li>$q_3$ 位于 $\overrightarrow{q_1q_2}$ 左侧：行列式大于0</li>
<li>$q_3q_1q_2$ 共线：行列式值为 0</li>
</ul>
</blockquote>
</li>
<li><p>三维三点：行列式为三个向量张成的平行六面体体积</p>
</li>
</ul>
<h2 id="Eigen-Value、Eigen-Vector"><a href="#Eigen-Value、Eigen-Vector" class="headerlink" title="Eigen Value、Eigen Vector"></a><em>Eigen Value</em>、<em>Eigen Vector</em></h2><ul>
<li><p>矩阵（变换）特征向量、特征值几何意义</p>
<ul>
<li>特征向量：在线性变换后仍然在自身生成空间中，即保持方向不变，仅是模变化的向量</li>
<li>特征值：对应特征向量模变化的比例</li>
</ul>
</li>
<li><p>特殊变换中的特征向量、特征值情况</p>
<ul>
<li>旋转变换：特征值为 $\pm i$，没有特征向量，即特征值为复数表示某种旋转</li>
<li>剪切变换（$\begin{vmatrix} A^{‘} &amp; 0 \ 0 &amp; 1 \end{vmatrix}$$：必然有特征值为 1，且对应特征向量在坐标轴上</li>
<li>伸缩变换（$\lambda E$）：所有向量都是特征向量</li>
</ul>
</li>
<li><p>矩阵对角化</p>
<ul>
<li>矩阵对角化：即寻找一组基，使得线性变换对该组基向量仅引起伸缩变换</li>
<li>定理：当且仅当 $n$ 阶矩阵 $A$ 有 $n$ 个线性无关的特征向量时，其可以对角化<ul>
<li>即变换后有 $n$ 个线性无关向量在自身生成空间中</li>
<li>也即矩阵对应变换为线性变换</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="线性方程组"><a href="#线性方程组" class="headerlink" title="线性方程组"></a>线性方程组</h2><h3 id="Gaussian-Elimination"><a href="#Gaussian-Elimination" class="headerlink" title="Gaussian Elimination"></a>Gaussian Elimination</h3><p>高斯消元法：初等变换n个线性方程组为等价方程组，新方程组系数矩阵为上三角矩阵</p>
<ul>
<li>三角系数矩阵可以方便的递推求解</li>
<li>初等变换可将系数矩阵变换为上三角矩阵，而不影响方程解</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/av6731067/">https://www.bilibili.com/video/av6731067/</a></li>
<li><a target="_blank" rel="noopener" href="https://charlesliuyx.github.io/2017/10/06/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9A%84%E6%9C%AC%E8%B4%A8/">https://charlesliuyx.github.io/2017/10/06/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9A%84%E6%9C%AC%E8%B4%A8/</a></li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/tags/Math/page/0/">Previous</a></div><div class="pagination-next"><a href="/tags/Math/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/tags/Math/">1</a></li><li><a class="pagination-link" href="/tags/Math/page/2/">2</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/tags/Math/page/5/">5</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5385776267343559" data-ad-slot="6995841235" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>