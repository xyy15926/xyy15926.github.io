<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: Statistics - UBeaRLy</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="UBeaRLy"><meta property="og:url" content="https://xyy15926.github.io/"><meta property="og:site_name" content="UBeaRLy"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:author" content="UBeaRLy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io"},"headline":"UBeaRLy","image":["https://xyy15926.github.io/img/og_image.png"],"author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"UBeaRLy","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":""}</script><link rel="alternate" href="/atom.xml" title="UBeaRLy" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Statistics</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-12T02:06:33.000Z" title="7/12/2021, 10:06:33 AM">2021-07-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-19T11:00:51.000Z" title="7/19/2021, 7:00:51 PM">2021-07-19</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Statistics/">Statistics</a></span><span class="level-item">a few seconds read (About 111 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Statistics/stat_stats.html">统计量</a></h1><div class="content"><h2 id="统计量"><a href="#统计量" class="headerlink" title="统计量"></a>统计量</h2><p>统计量：统计理论中对数据进行分析、检验的变量</p>
<ul>
<li><p>传统的统计量具有显式解析表达式</p>
<ul>
<li>均值：数据之和除数量</li>
<li>中位数：数据中间者</li>
</ul>
</li>
<li><p>统计量同样可以理解为和数据相关<strong>优化问题的解</strong></p>
<ul>
<li>均值：离差平方和最小</li>
<li>中位数：划分均匀</li>
</ul>
<blockquote>
<ul>
<li>优化问题目标本身也是统计量</li>
</ul>
</blockquote>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-12T02:03:58.000Z" title="7/12/2021, 10:03:58 AM">2021-07-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T02:03:58.000Z" title="7/12/2021, 10:03:58 AM">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Statistics/">Statistics</a></span><span class="level-item">7 minutes read (About 1069 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Statistics/stat_derived.html">统计量 - 衍生特征</a></h1><div class="content"><h2 id="Odds-Odds-Ratio"><a href="#Odds-Odds-Ratio" class="headerlink" title="Odds/Odds Ratio"></a><em>Odds/Odds Ratio</em></h2><ul>
<li><p><em>Odds</em>：几率/优势，事件发生与不发生的概率比值</p>
<script type="math/tex; mode=display">
odds = \frac p {1-p}</script><blockquote>
<ul>
<li>$p$：事件发生概率</li>
</ul>
</blockquote>
</li>
<li><p><em>Odds Ratio</em>：优势比，两组事件 <em>odds</em> 的比值</p>
<script type="math/tex; mode=display">
OR = \frac {odds_1} {odds_0}</script></li>
</ul>
<h2 id="WOE-值"><a href="#WOE-值" class="headerlink" title="WOE 值"></a><em>WOE</em> 值</h2><p><em>WOE</em> 值：将预测变量（二分类场景中）集中度作为分类变量编码的数值</p>
<script type="math/tex; mode=display">\begin{align*}
WOE_i & = log(\frac {\%B_i} {\%G_i}) \\
& = log(\frac {\#B_i / \#B_T} {\#G_i / \#G_T}) \\
& = log(\frac {\#B_i / \#G_i} {\#B_T / \#G_T}) \\
& = log(\frac {\#B_i} {\#G_i}) - log(\frac {\#B_T} {\#G_T}) \\
& = log(\frac {\#B_i / ({\#B_i + \#G_i})}
    {\#G_i / (\#B_i + \#G_i)}) -
    log(\frac {\#B_T} {\#G_T}) \\
& = log(odds_i) - log(odds_T)
\end{align*}</script><blockquote>
<ul>
<li>$\%B_i, \%G_i$：分类变量取第 $i$ 值时，预测变量为 <em>B</em> 类、<em>G</em> 类占所有 <em>B</em> 类、<em>G</em> 类比例</li>
<li>$#B_i, #B_T$：分类变量取第 $i$ 值时预测变量为 <em>B</em> 类数量，所有 <em>B</em> 类总数量</li>
<li>$#G_i, #G_T$：分类变量取第 $i$ 值时预测变量为 <em>G</em> 类数量，所有 <em>G</em> 类样本总数量</li>
<li>$odds_i$：分类变量取第 $i$ 值时，预测变量取 <em>B</em> 类优势</li>
<li>$odds_T$：所有样本中，预测变量取 <em>B</em> 类优势</li>
<li>其中 $log$ 一般取自然对数</li>
</ul>
</blockquote>
<ul>
<li><p><em>WOE</em> 编码是有监督的编码方式，可以衡量分类变量各取值中</p>
<ul>
<li><em>B</em> 类占所有 <em>B</em> 类样本比例、<em>G</em> 类占所有 <em>G</em> 类样本比例的差异</li>
<li><em>B</em> 类、<em>G</em> 类比例，与所有样本中 <em>B</em> 类、<em>G</em> 类比例的差异</li>
</ul>
</li>
<li><p><em>WOE</em> 编码值能体现分类变量取值的预测能力，变量各取值 <em>WOE</em> 值方差越大，变量预测能力越强</p>
<ul>
<li><em>WOE</em> 越大，表明该取值对应的取 <em>B</em> 类可能性越大</li>
<li><em>WOE</em> 越小，表明该取值对应的取 <em>G</em> 类可能性越大</li>
<li><em>WOE</em> 接近 0，表明该取值预测能力弱，对应取 <em>B</em> 类、<em>G</em> 类可能性相近</li>
</ul>
</li>
</ul>
<h3 id="OR与WOE线性性"><a href="#OR与WOE线性性" class="headerlink" title="OR与WOE线性性"></a>OR与WOE线性性</h3><script type="math/tex; mode=display">\begin{align*}
log(OR_{j,i}) &= log(odds_i) - log(odds_j) \\
&= WOE_i - WOE_j
\end{align*}</script><ul>
<li><p>即：预测变量对数优势值与 <em>WOE</em> 值呈线性函数关系</p>
<ul>
<li>预测变量在取 $i,j$ 值情况下，预测变量优势之差为取 $i,j$ 值的 <em>WOE</em> 值之差</li>
<li><em>WOE</em> 值编码时，分类变量在不同取值间跳转时类似于线性回归中数值型变量</li>
</ul>
<p><img src="/imgs/woe_encoding_linear_sketch.png" alt="woe_encoding_linear_sketch"></p>
</li>
<li><p>考虑到对数优势的数学形式，单变量 <em>LR</em> 模型中分类型变量 <em>WOE</em> 值可以类似数值型变量直接入模</p>
<ul>
<li>当然，<em>WOE</em> 值编码在多元 <em>LR</em> 中无法保证单变量分类情况下的线性</li>
<li>或者说多变量 <em>LR</em> 中个变量系数值不一定为 1</li>
<li>在基于单变量预测能力优秀在多变量场合也优秀的假设下，<em>WOE</em> 值编码（<em>IV</em> 值）等单变量分析依然有价值</li>
</ul>
</li>
</ul>
<h3 id="Bayes-Factor、WOE-编码、多元-LR"><a href="#Bayes-Factor、WOE-编码、多元-LR" class="headerlink" title="Bayes Factor、WOE 编码、多元 LR"></a><em>Bayes Factor</em>、<em>WOE</em> 编码、多元 <em>LR</em></h3><script type="math/tex; mode=display">\begin{align*}
ln(\frac {P(Y=1|x_1,x_2,\cdots,x_D)}
    {P(Y=0|x_1,x_2,\cdots,x_D)})
    &= ln(\frac {P(Y=1)} {P(Y=0)}) \\
    & \overset {conditionally independent} {=}
        ln (\frac {P(Y=1)} {P(Y=0)}) + 
        \sum_{i=1}^D ln(\frac {P(x_i|Y=1)} {P(x_i|Y=0)}) \\
ln(\frac {P(Y=1|x_1,x_2,\cdots,x_D)} 
    {P(Y=0|x_1,x_2,\cdots,x_D)})
    & \overset {semi} {=} ln (\frac {P(Y=1)} {P(Y=0)}) +
        \sum_{i=1}^D \beta_i ln(\frac {P(x_i|Y=1)}
        {P(x_i|Y=0)})
\end{align*}</script><blockquote>
<ul>
<li>$\frac {P(x_i|Y=1)} {P(x_i|Y=0)}$：贝叶斯因子，常用于贝叶斯假设检验</li>
</ul>
</blockquote>
<ul>
<li><p><em>Naive Bayes</em> 中满足各特征 $X$ 关于 $Y$ 条件独立的强假设下，第二个等式成立</p>
</li>
<li><p><em>Semi-Naive Bayes</em> 中放宽各特征关于 $Y$ 条件独立假设，使用权重体现变量相关性，此时则可以得到多元 <em>LR</em> 的预测变量取值对数 <em>OR</em> 形式</p>
<ul>
<li>则多元 <em>LR</em> 场景中，<em>WOE</em> 值可以从非完全条件独立的贝叶斯因子角度理解</li>
</ul>
</li>
</ul>
<h3 id="IV-值"><a href="#IV-值" class="headerlink" title="IV 值"></a><em>IV</em> 值</h3><script type="math/tex; mode=display">\begin{align*}
IV_i &= (\frac {\#B_i} {\#B_T} - \frac {\#G_i} {\#G_T}) * 
    WOE_i \\
&= (\frac {\#B_i} {\#B_T} - \frac {\#G_i} {\#G_T}) *
    log(\frac {\#B_i / \#B_T} {\#G_i / \#G_T}) \\
IV &= \sum IV_i
\end{align*}</script><blockquote>
<ul>
<li>$IV_i$：特征 $i$ 取值 <em>IV</em> 值</li>
<li>$IV$：特征总体 <em>IV</em> 值</li>
</ul>
</blockquote>
<ul>
<li>特征总体的 <em>IV</em> 值实际上是其各个取值 <em>IV</em> 值的加权和<ul>
<li>类似交叉熵为各取值概率的加权和</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-12T01:55:27.000Z" title="7/12/2021, 9:55:27 AM">2021-07-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T01:55:27.000Z" title="7/12/2021, 9:55:27 AM">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Statistics/">Statistics</a></span><span class="level-item">16 minutes read (About 2441 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Statistics/stat_entropy.html">统计量 - 熵</a></h1><div class="content"><h2 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a><em>Entropy</em></h2><blockquote>
<ul>
<li>（信息）熵：在概率分布上对复杂程度/多样性/不确定性/混乱程度的度量</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
\begin{align*}
HOD(X) & = -E_P log P(x) \\
& = \sum_d^D P(x_d) log \frac 1 {P(x_d)} \\
& = - \sum_d^D p_d log p_d \\
\end{align*}</script><blockquote>
<ul>
<li>$p_d$：随机变量各取值对应概率</li>
<li>事件 $i$ 发生概率 $p_d=0$：约定 $p_d log(p_d)$ 为 0</li>
<li>其中 $log$ 以 2 为底，单位为 <em>bit</em>，以 $e$ 为底，单位为 <em>nat</em></li>
</ul>
</blockquote>
<ul>
<li><p>信息论中，熵越高能传输越多信息</p>
<ul>
<li>可携带的信息量 = 单位消息熵 * 消息长度</li>
<li>熵衡量系统复杂程度，提高系统确定性即削弱系统多样性，降低熵</li>
</ul>
</li>
<li><p>概率分布包含的信息即其复杂程度（可能取值数量）</p>
<ul>
<li>考虑按照 $(p_1,\cdots,p_D)$ 分布、长度为 $N$ 的随机变量序列，其可能排列数为 $\frac {N!} {\prod_d^D (p_d N)!}$</li>
<li><p>则根据 <em>Stirling</em> 公式有</p>
<script type="math/tex; mode=display">\begin{align*}
log (\frac {N!} {\prod_d^D (p_d N)!}) & = log(N!)
  - \sum_d^D log((p_d N)!) \\
& \overset {\lim_{N \rightarrow \infty}} = log(\sqrt {2\pi N}
  ({\frac N e})^N) + \sum_d^D log(\sqrt {2\pi p_dN}
  ({\frac {p_dN} e})^{p_dN}) \\
& = log(\sqrt {2\pi N}) + N(logN-1) - \sum_d^D log(\sqrt {2\pi p_dN})
  - \sum_d^D p_dN (log(p_dN) - 1) \\
& = log(\sqrt {2\pi N} + \sum_d^D log(\sqrt {2\pi p_dN}))
  + N \sum_d^D p_d log p_d \\
& \approx N \sum_d^D p_d log p_d
\end{align*}</script></li>
<li><p>则长度为 $N$ 的随机变量串的多样性、信息量为 $H * N$，其中 $H=\sum_d^D p_d log p_d$ 概率分布的信息熵</p>
</li>
</ul>
</li>
<li><p>某个事件包含的信息可以用编码长度理解</p>
<ul>
<li>对概率 $p$ 事件，编码 $1/p$ 个需编码（2进制编码）长度 $log_2 \frac 1 p$</li>
<li>则概率 $p$ 事件包含信息量可以定义为 $log \frac 1 p$，即事件包含的信息量可用表示事件需要编码的长度表示
（底数则取决于编码元，只影响系数）</li>
<li>则整个随机变量的信息为各事件信息量加权和</li>
</ul>
</li>
<li><p>熵可以视为变量取值概率的加权和</p>
<ul>
<li>只依赖随机变量 $X$ 的分布，与其取值无关，可将其记为 $H(P)$</li>
<li>由定义 $0 \leq H(P) \leq log_2 k$<ul>
<li>$H(p) = 0$：$\exists j, p_j=1$，随机变量只能取一个值，无不确定性</li>
<li>$H(p) = log k$：$\forall j, p_j=1/k$，随机变量在任意取值概率相等，不确定性最大</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li><em>empirical entropy</em>：经验熵，熵中的概率由数据估计时（尤极大似然估计）</li>
<li>参考链接<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)">https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27876027">https://zhuanlan.zhihu.com/p/27876027</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/73710585">https://zhuanlan.zhihu.com/p/73710585</a></li>
</ul>
</blockquote>
</li>
<li><em>Stirling</em> 公式即用积分近似计算 $\sum logn$：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/143992660">https://zhuanlan.zhihu.com/p/143992660</a></li>
</ul>
</blockquote>
<h3 id="熵的性质"><a href="#熵的性质" class="headerlink" title="熵的性质"></a>熵的性质</h3><ul>
<li><p>对称性：事件取值不影响熵</p>
</li>
<li><p>极值性</p>
<ul>
<li><p>所有符号有同等机会出现的情况下，熵达到极大（琴生不等式）</p>
<script type="math/tex; mode=display">\begin{align*}
H(X) & = E[log(\frac 1 {P(X)})] \leq log(E[\frac 1 {P(x)}])
  & = log(n)
\end{align*}</script></li>
<li><p>仅有一个符号确定出现的情况下，熵达到极小 0</p>
</li>
</ul>
</li>
<li><p><em>Continuity</em>连续性：度量连续，概率微小变化只能引起熵微小变化</p>
</li>
<li><p><em>Normalization</em>规范化：$H_2(\frac 1 2, \frac 1 2) = 1$</p>
</li>
<li><p><em>Grouping</em>组合法则/可加和性：熵与过程如何划分无关
（此即要求熵形式为对数）</p>
<ul>
<li><p>若子系统间相互作用已知，则可以通过子系统熵值计算系统整体熵</p>
<script type="math/tex; mode=display">
H(X) = H(X_1,\cdots,X_K) + \sum_{k=1}^K
  \frac {|X_k|} {|X|} H(X_k)</script><blockquote>
<ul>
<li>$X_1,\cdots,X_K$：$K$ 个子系统，可以理解为将随机变量 $X$ 划分为 $K$ 种情况</li>
<li>$H(X_1,\cdots,X_K)$：子系统相互作用熵</li>
</ul>
</blockquote>
<ul>
<li>子系统相互作用熵可以认为是，通过已知信息消除的多样性（即信息增益）</li>
<li>子系统熵之和则是利用已知信息消除多样性之后，系统剩余混乱程度</li>
</ul>
</li>
<li><p>一般的，两个事件 $X,Y$ 熵满足以下计算关系</p>
<script type="math/tex; mode=display">\begin{align*}
H(X, Y) & = H(X) + H(Y|X) \\
& = H(Y) + H(X|Y) \\
& \leqslant H(X) + H(Y) \\
H(X|Y) & \leqslant H(X) \\
\end{align*}</script></li>
<li><p>特别的，若事件 $X, Y$ 相互独立</p>
<script type="math/tex; mode=display">\begin{align*}
H(X|Y) &= H(X) \\
H(X, Y) &= H(X) + H(Y)
\end{align*}</script></li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>满足以上特性的熵定义必然为如下形式</li>
</ul>
</blockquote>
<pre><code>$$
-K \sum P(x)log(P(x))
$$
</code></pre><blockquote>
<ul>
<li>在热力学、信息论等领域，熵有多种不同定义，满足熵性质的测度泛函，只能具有（<em>Shannon</em> 熵和 <em>Hartley</em> 熵）或（<em>von Neumann</em> 熵和 <em>Shannon</em> 熵）线性组合的函数形式，若不要求满足组合法则，还有 <em>Tsallis</em> 熵等</li>
</ul>
</blockquote>
<h3 id="Conditinal-Entropy"><a href="#Conditinal-Entropy" class="headerlink" title="Conditinal Entropy"></a><em>Conditinal Entropy</em></h3><p>条件熵：随机变量 $X$ 给定条件下，随机变量 $Y$ 的<strong>条件概率分布的熵</strong>对 $X$ 的数学期望</p>
<script type="math/tex; mode=display">\begin{align*}
H(Y|X) & = \sum_{i=1}^N p_i H(Y|X=x_i) \\
H(Y|x=x_i) & = - \sum_j P(y_j|x_i) log P(y_j|x_i)
\end{align*}</script><blockquote>
<ul>
<li>$P(X=x<em>i, Y=y_j)=p</em>{i,j}$：随机变量 $(X,Y)$ 联合概率分布</li>
<li>$p_i=P(X=x_i)$</li>
<li>$H(Y|X=x_i)$：后验熵</li>
</ul>
</blockquote>
<ul>
<li><p>特别的，考虑数据集 $D$ 被分为 $D_1,\cdots,D_m$，条件经验熵可计算如下</p>
<script type="math/tex; mode=display">\begin{align*}
H(D|A) & = \sum_{m=1}^M \frac {|D_m|} {|D|} H(D_m) \\
& = -\sum_{m=1}^M \frac {|D_m|} {|D|}
   \sum_{k=1}^K \frac {|D_{m,k}|} {|D_m|}
   log_2 \frac {|D_{m,k}|} {|D_m|}
\end{align*}</script></li>
</ul>
<blockquote>
<ul>
<li><em>postorior entropy</em>：后验熵，随机变量 $X$ 给定条件下，随机变量 $Y$ 的<strong>条件概率分布的熵</strong></li>
<li><em>empirical conditional entropy</em>：经验条件熵，概率由数据估计</li>
</ul>
</blockquote>
<h3 id="Infomation-Gain-Mutual-Infomation"><a href="#Infomation-Gain-Mutual-Infomation" class="headerlink" title="Infomation Gain/Mutual Infomation"></a><em>Infomation Gain</em>/<em>Mutual Infomation</em></h3><p>互信息/信息增益：（经验）熵与（经验）条件熵之差</p>
<script type="math/tex; mode=display">\begin{align*}
g(Y|X) & = H(Y) - H(Y|X) \\
& = \sum_{x \in X} \sum_{y \in Y} P(x,y) log
    \frac {P(x,y)} {P(x)P(y)}
\end{align*}</script><ul>
<li><p>与数据集具体分布有关、与具体取值无关</p>
<ul>
<li>绝对大小同易受熵影响，（经验）熵较大时，互信息也相对较大</li>
<li>由于误差存在，分类取值数目较多者信息增益较大</li>
</ul>
</li>
<li><p>可衡量变量 $X$ 对 $Y$ 预测能力、减少不确定性的能力</p>
<ul>
<li>信息增益越大，变量之间相关性越强，自变量预测因变量能力越强</li>
<li>只能考察特征对整个系统的贡献，无法具体到特征某个取值</li>
<li>只适合作全局特征选择，即所有类使用相同的特征集合</li>
</ul>
</li>
</ul>
<h3 id="Infomation-Gain-Ratio"><a href="#Infomation-Gain-Ratio" class="headerlink" title="Infomation Gain Ratio"></a><em>Infomation Gain Ratio</em></h3><p>信息增益比：信息增益对原始信息熵的比值</p>
<script type="math/tex; mode=display">\begin{align*}
g_R(Y|X) & = \frac {g(Y|X)} {H(X)}
\end{align*}</script><ul>
<li>考虑熵大小，减弱熵绝对大小的影响</li>
</ul>
<h3 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a><em>Cross Entropy</em></h3><blockquote>
<ul>
<li>信息论：基于相同事件测度的两个概率分布 $P, Q$，基于非自然（相较于真实分布 $P$）概率分布 $Q$ 进行编码，在事件集合中唯一标识事件所需 <em>bit</em></li>
<li>概率论：概率分布 $P, Q$ 之间差异</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">\begin{align*}
H(P, Q) & = E_P[-log Q] = \left \{ \begin{array}{l}
    -\sum_{X} P(x) logQ(x), & 离散分布 \\
    -\int_X P(x) log(Q(x)) d(r(x)), & 连续分布
\end{array} \right. \\
& = H(P) + D_{KL}(P||Q)
\end{align*}</script><blockquote>
<ul>
<li>$P(x), Q(x)$：概率分布（密度）函数</li>
<li>$r(x)$：测度，通常是 $Borel \sigma$ 代数上的勒贝格测度</li>
<li>$D_{KL}(P||Q)$：$P$ 到 $Q$ 的 <em>KL</em> 散度（$P$ 相对于 $Q$ 的相对熵）</li>
</ul>
</blockquote>
<ul>
<li>信息论中，交叉熵可以看作是信息片段在错误分布 $Q$ 分布下的期望编码长度<ul>
<li>信息实际分布实际为 $P$，所以期望基于 $P$</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>交叉熵是常用的损失函数：效果等价于 <em>KL</em> 散度，但计算方便</li>
<li><em>sigmoid</em> 激活函数时：相较于二次损失，收敛速度更快</li>
</ul>
</blockquote>
<h2 id="Entropy-衍生指标"><a href="#Entropy-衍生指标" class="headerlink" title="Entropy 衍生指标"></a><em>Entropy</em> 衍生指标</h2><h3 id="Kullback-Leibler-Divergence"><a href="#Kullback-Leibler-Divergence" class="headerlink" title="Kullback-Leibler Divergence"></a><em>Kullback-Leibler Divergence</em></h3><p><em>KL</em> 散度/相对熵：衡量概率分布 $P, Q$ 之间差异的量化指标</p>
<script type="math/tex; mode=display">\begin{align*}
D_{KL}(P||Q) & = E_P[(-log Q(x)) - (-log P(x))] \\
& = E_P[log P(x) - log Q(x)] \\
& = \sum_{d=1}^D P(x_d) (log P(x_d) - log Q(x_d)) \\
& = \sum_{d=1} P(x_d) log \frac {P(x_d)} {Q(x_d)}
\end{align*}</script><ul>
<li><p><em>KL</em> 散度含义</p>
<ul>
<li>原始分布 $P$、近似分布 $Q$ 之间对数差值期望</li>
<li>若使用观察分布 $Q$ 描述真实分布 $P$，还需的额外信息量</li>
</ul>
</li>
<li><p><em>KL</em> 散度不对称，分布 $P$ 度量 $Q$、$Q$ 度量 $P$ 损失信息不同</p>
<ul>
<li>从计算公式也可以看出</li>
<li>KL散度不能作为不同分布之间距离的度量</li>
</ul>
</li>
</ul>
<h3 id="Population-Stability-Index"><a href="#Population-Stability-Index" class="headerlink" title="Population Stability Index"></a><em>Population Stability Index</em></h3><p><em>PSI</em>：衡量分布 $P, Q$ 之间的差异程度</p>
<script type="math/tex; mode=display">\begin{align*}
PSI &= \sum_d^D (P_d - Q_d) * log \frac {P_d} {Q_d} \\
&= \sum_d^D P_d log \frac {P_d} {Q_d} +
    \sum_d^D Q_d log \frac {Q_d} {P_d} \\
&= D_{KL}(P||Q) + D_{KL}(Q||P)
\end{align*}</script><ul>
<li>是 <em>KL</em> 散度的对称操作<ul>
<li>更全面的描述两个分布的差异</li>
</ul>
</li>
</ul>
<h2 id="Gini-指数"><a href="#Gini-指数" class="headerlink" title="Gini 指数"></a><em>Gini</em> 指数</h2><p>基尼指数：可视为信息熵的近似替代</p>
<script type="math/tex; mode=display">\begin{align*}
Gini(p) & = \sum_{k=1}^K p_k(1-p_k) \\
    & = 1 - \sum_{k=1}^K p_k^2
\end{align*}</script><blockquote>
<ul>
<li>$p$：概率分布</li>
<li>异质性最小：<em>Gini</em> 系数为 0</li>
<li>异质性最大：<em>Gini</em> 系数为 $1 - \frac 1 k$</li>
</ul>
</blockquote>
<ul>
<li><em>Gini</em> 指数度量分布的不纯度<ul>
<li>包含类别越多，<em>Gini</em> 指数越大</li>
<li>分布越均匀，<em>Gini</em> 指数越大</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>熵较 <em>Gini</em> 指数对不纯度判罚更重</li>
</ul>
</blockquote>
<p><img src="/imgs/gini_entropy_error_rate_in_binary_classification.png" alt="gini_entropy_error_rate_in_binary_classification"></p>
<blockquote>
<ul>
<li>经济学领域的 <em>Gini</em> 系数更类似 <em>AUC</em> 值</li>
</ul>
</blockquote>
<h3 id="与-Entropy-关系"><a href="#与-Entropy-关系" class="headerlink" title="与 Entropy 关系"></a>与 <em>Entropy</em> 关系</h3><script type="math/tex; mode=display">\begin{align*}
H(X) & = -E_P log P(x) \\
& = - \sum_i^N p_i log p_i \\
& = - \sum_i^N p_i (log (1 + (p_i-1))) \\
& = - \sum_i^N p_i (p_i - 1 + \xi(p_i^{'}-1)) \\
& \approx 1 - \sum_i^N p_i^2
\end{align*}</script><ul>
<li><em>Gini</em> 指数可以视为是熵在 1 附近的一阶泰勒展开近似</li>
</ul>
<h3 id="条件-Gini-指数"><a href="#条件-Gini-指数" class="headerlink" title="条件 Gini 指数"></a>条件 <em>Gini</em> 指数</h3><script type="math/tex; mode=display">
Gini(Y|X) = \sum_{k=1}^K P(X=x_k)Gini(Y|X=x_k)</script><blockquote>
<ul>
<li>性质类似信息增益</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-12T01:53:01.000Z" title="7/12/2021, 9:53:01 AM">2021-07-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T01:53:01.000Z" title="7/12/2021, 9:53:01 AM">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Statistics/">Statistics</a></span><span class="level-item">9 minutes read (About 1370 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Statistics/stat_corrs.html">统计量 - 相关</a></h1><div class="content"><h2 id="Pearson-积矩相关系数"><a href="#Pearson-积矩相关系数" class="headerlink" title="Pearson 积矩相关系数"></a><em>Pearson</em> 积矩相关系数</h2><script type="math/tex; mode=display">
\rho_{X,Y} = \frac {cov(X, Y)} {\sigma_X \sigma_Y}</script><blockquote>
<ul>
<li>$cov(X, Y)$：变量 $X, Y$ 协方差</li>
<li>$\sigma_X, \sigma_Y$：变量 $X, Y$ 方差</li>
</ul>
</blockquote>
<ul>
<li><em>Pearson</em> 积矩相关系数取值范围为 $[-1, 1]$<ul>
<li>$1, -1$ 分别表示变量成正线性、负线性函数关系</li>
</ul>
</li>
</ul>
<h3 id="显著性检验"><a href="#显著性检验" class="headerlink" title="显著性检验"></a>显著性检验</h3><h4 id="Fisher-变换"><a href="#Fisher-变换" class="headerlink" title="Fisher 变换"></a><em>Fisher</em> 变换</h4><script type="math/tex; mode=display">
z = \frac 1 2 ln(\frac {1+r} {1-r}) = arctanh(r)</script><blockquote>
<ul>
<li>$z$：<em>Pearson</em> 积矩相关系数的 <em>Fisher</em> 变换</li>
<li>$r$：样本的 <em>Pearson</em> 积矩相关系数值</li>
</ul>
</blockquote>
<ul>
<li>当 $(X, Y)$ 为二元正态分布时，$z$ 近似正态分布<ul>
<li>均值：$\frac 1 2 ln(\frac {1+\rho} {1-\rho})$</li>
<li>标准差：$\frac 1 {\sqrt {N - 3}}$</li>
</ul>
</li>
</ul>
<h4 id="基于数学的近似方法"><a href="#基于数学的近似方法" class="headerlink" title="基于数学的近似方法"></a>基于数学的近似方法</h4><script type="math/tex; mode=display">
t = r \sqrt{\frac {N - 2} {1 - r^2}}</script><ul>
<li>当 $(X, Y)$ 为二元正态分布且不相关时，$t$ 服从自由度为 $n-2$的 <em>t-分布</em></li>
</ul>
<h2 id="Spearman-秩相关系数"><a href="#Spearman-秩相关系数" class="headerlink" title="Spearman 秩相关系数"></a><em>Spearman</em> 秩相关系数</h2><script type="math/tex; mode=display">\begin{align*}
\rho_{X, Y} & = \frac {cov(Rank(X) - Rank(Y))}
    {\sigma_{Rank(X)} \sigma_{Rank(Y)}} \\
& = 1 - \frac {6 \sum_i^N d_i^2} {N(N^2-1)} \\
\end{align*}</script><blockquote>
<ul>
<li>$Rank(X), Rank(Y)$：变量 $X, Y$ 的秩（应同序）（相同值秩取均值）</li>
<li>$d_i$：变量对 $X, Y$ 中，二者秩差值</li>
</ul>
</blockquote>
<ul>
<li><em>Spearman</em> 秩相关系数被定义为变量秩的 <em>Pearson</em> 相关系数</li>
</ul>
<blockquote>
<ul>
<li><em>Spearman</em> 秩相关系数也可以使用 <em>Fisher</em> 变换检验显著性</li>
</ul>
</blockquote>
<h2 id="Kendell-秩相关系数"><a href="#Kendell-秩相关系数" class="headerlink" title="Kendell 秩相关系数"></a><em>Kendell</em> 秩相关系数</h2><script type="math/tex; mode=display">\begin{align*}
\tau_a &= \frac {N_c - N_d} {N_0} \\
\tau_b &= \frac {N_c - N_d} {\sqrt{(N_0 - N_X)(N_0 - N_Y)}} \\
\tau_c &= \frac {2(N_c - N_d)} {N^2 \frac {M-1} M}
\end{align*}</script><blockquote>
<ul>
<li>$N_0 = \frac {N(N-1)} 2$：变量对数量</li>
<li>$N_c, N_d$：变量对 $X, Y$ 中有序对数量、无序对数量</li>
<li>$N_X, N_Y$：变量对 $X, Y$ 中 $X$ 取值、$Y$ 取值相同对数量</li>
<li>$M$：变量 $X, Y$ 中较小取值数量者取值数量</li>
</ul>
</blockquote>
<ul>
<li><p><em>Kendell</em> 秩相关系数取值范围同样为 $[-1, 1]$</p>
<ul>
<li>-1 仅在变量 $X, Y$ 取值完全反向取到</li>
</ul>
</li>
<li><p>$\tau_a$ 是 $\tau_b$ 在变量不存在取值相同时的特例</p>
</li>
<li><p>$\tau_c$ 适合“层级”数据，即两个变量取值类似划分、内部细分</p>
<p>||A|B|C|
|——-|——-|——-|——-|
|I-1|30|0|0|
|I-2|30|0|0|
|II-1|0|30|0|
|II-1|0|30|0|
|III-2|0|0|30|
|III-2|0|0|30|</p>
<ul>
<li>对以上数据，$\tau_b$ 取值在 0.9 附近，而 $\tau_c$ 取 1</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>有序对：对 $(X_i, Y_i), (X_j, Y_j)$，满足 $X_i &lt; X_j, Y_i &lt; Y_j$ 或 $X_i &gt; X_j,Y_i &gt; Y_j$ 则为有序对</li>
<li>无序对：对$(X_i, Y_i), (X_j, Y_j)$，满足 $X_i &lt; X_j, Y_i &gt; Y_j$ 或 $X_i &gt; X_j, Y_i &lt; Y_j$ 则为无序对</li>
</ul>
</blockquote>
<h2 id="卡方统计量"><a href="#卡方统计量" class="headerlink" title="卡方统计量"></a>卡方统计量</h2><p>卡方统计量：通过观察实际与理论值的偏差确定理论正确与否</p>
<script type="math/tex; mode=display">
\chi^2 = \sum \frac {(A - E)^2} E</script><blockquote>
<ul>
<li>$A$：自变量、因变量组合对应频数观察值</li>
<li>$E$：自变量、因变量组合对应频数期望值</li>
</ul>
</blockquote>
<ul>
<li><p>将模型预测结果视为实际分布、先验分布（均匀分布）视为理论分布</p>
</li>
<li><p>卡方检验：检验定性变量之间相关性，假设两个变量确实独立，观察实际值、理论值偏差程度判断变量之间相关性</p>
<ul>
<li>若偏差足够小，认为误差是自然的样本误差，两者确实独立</li>
<li>若偏差大到一定程度，误差不可能由偶然、测量精度导致，
认为两者相关</li>
</ul>
</li>
<li><p>若模型预测结果同先验分布差别很大，说明模型有效，且卡方统计量值越大表示预测把握越大</p>
</li>
</ul>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>由于随机误差存在，卡方统计量容易<ul>
<li>夸大频数较小的特征影响</li>
<li>相应的，取值数较少（各取值频数相对而言可能较大）特征影响容易被低估</li>
</ul>
</li>
</ul>
<h3 id="分布证明"><a href="#分布证明" class="headerlink" title="分布证明"></a>分布证明</h3><ul>
<li><p>考虑随机变量 $X=(x_1,\cdots,x_D)$ 服从 <em>Multinomial</em> 分布，分布参数为 $n, p=(p_1,\cdots,p_D)$</p>
</li>
<li><p>考虑服从理论分布的随机变量 $X$ 协方差矩阵</p>
<script type="math/tex; mode=display">\begin{align*}
\Sigma = Cov(X) &= \begin{bmatrix}
   np_1(1-p_1) & -np_1p_2 & \cdots & -np_1p_D \\
   np_2p_1 & -np_2(1-p_2) & \cdots & -np_2p_D \\
   \vdots & \vdots & \ddots & \vdots \\
   -np_Dp_1 & -np_Dp_2 & \cdots & np_D(1-p_D)
\end{bmatrix} \\
&= n\begin{bmatrix}
   p_1 & 0 & \cdots & 0 \\
   0 & p_2 & \cdots & 0 \\
   \vdots & \vdots & \ddots & \vdots \\
   0 & 0 & \cdots & p_D
\end{bmatrix} - npp^T \\
\end{align*}</script></li>
<li><p>则由中心极限定理有，如下依分布收敛的结论</p>
<script type="math/tex; mode=display">\begin{align*}
\frac {(X - np)} {\sqrt n} & \overset {D} {\rightarrow} N(0,\Sigma) \\
\end{align*}</script></li>
<li><p>考虑服从理论分布的随机变量 $X$ 的 $\chi^2$ 参数</p>
<script type="math/tex; mode=display">\begin{align*}
\chi^2 &= \frac 1 n (X-np)^T D^2 (X-np) \\
D &= \begin{bmatrix}
   \frac 1 {\sqrt {p_1}} & 0 & \cdots & 0 \\
   0 & \frac 1 {\sqrt {p_2}} & \cdots & 0 \\
   \vdots & \vdots & \ddots & \vdots \\
   0 & 0 & \cdots & \frac 1 {\sqrt {p_D}}
\end{bmatrix}
\end{align*}</script></li>
<li><p>并由连续映射定理可以得到 $D\frac {x-np} {\sqrt n}$ 分布，且其协方差矩阵 $\Sigma_0$ 满足</p>
<script type="math/tex; mode=display">\begin{align*}
D\frac {x-np} {\sqrt n} & \overset {D} {\rightarrow} N(0, D \Sigma D^T) \\
\Sigma_0 &= D \Sigma D^T \\
\Sigma_0^2 &= (E - \sqrt p {\sqrt p}^T)(E - \sqrt p {\sqrt p}^T) = \Sigma_0 \\
\end{align*}</script></li>
<li><p>由以上，$\Sigma_0$ 仅有特征值 0，1</p>
<ul>
<li>特征值 0 对应特征向量有且仅有 $\sqrt p$</li>
<li>特征值 1 对应特征向量有 $D-1$ 个</li>
</ul>
<script type="math/tex; mode=display">\begin{align*}
\Sigma_0 \sqrt p - 0 \sqrt p &= \sqrt p - \sqrt p = 0 \\
\Sigma_0 \lambda - 1 \lambda &= \lambda - \sqrt p {\sqrt p}^T \lambda
   = \sqrt p {\sqrt p}^T \lambda = 0
\end{align*}</script></li>
<li><p>则 $\chi^2$ 统计量依分布收敛于自由度为 $D-1$ 的卡方分布</p>
<script type="math/tex; mode=display">\begin{align*}
\chi^2 &= \sum_{d=1}^D \frac {(x_d - np_d)^2} {np_d}
   \overset {D} {\rightarrow} \chi_{D-1}
\end{align*}</script></li>
<li><p>可据此构造统计量进行卡方检验，检验实际值实际分布频率 $(a_1,\cdots,a_D)$ 是否符合该分布</p>
<ul>
<li>构造卡方统计量 $\chi^2 = \sum_{d=1}^D \frac {(x_d - na_d)^2} {na_d}$</li>
<li>则卡方统计量在随机变量满足多项分布情况下依分布收敛于自由度为 $D-1$ 的卡方分布</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/309694332/answer/952401910">https://www.zhihu.com/question/309694332/answer/952401910</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/198864907">https://zhuanlan.zhihu.com/p/198864907</a></li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-14T12:04:44.000Z" title="7/14/2019, 8:04:44 PM">2019-07-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:32:19.000Z" title="8/4/2021, 11:32:19 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Statistics/">Statistics</a></span><span class="level-item">13 minutes read (About 2022 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Statistics/stat_evaluation.html">常用统计量</a></h1><div class="content"><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><ul>
<li>对比实际类别值、预测类别值，编制混淆矩阵</li>
<li>基于混淆矩阵，计算各类错判率、总错判率（总错判率会受到数据不平衡性的影响）</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>真实情况\预测结果</th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td>正例</td>
<td><em>TP</em>（真正例）</td>
<td><em>FN</em>（假反例）</td>
</tr>
<tr>
<td>反例</td>
<td><em>FP</em>（假正例）</td>
<td><em>TN</em>（真反例）</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/imgs/confusion_matrix.png" alt="confusion_matrix"></p>
<h3 id="F-Measure"><a href="#F-Measure" class="headerlink" title="F-Measure"></a><em>F-Measure</em></h3><p><em>F-测度</em>：准率率和召回率综合值，越大越好</p>
<script type="math/tex; mode=display">
F-measure = \frac {(\beta^2 + 1) * P * R} {\beta^2 * P + R}</script><blockquote>
<ul>
<li>$P = \frac {TP} {TP+FP}$：查准率、精确率</li>
<li>$R = \frac {TP} {TP+FN}$：查全率、召回率、覆盖率</li>
</ul>
</blockquote>
<h4 id="F1-值"><a href="#F1-值" class="headerlink" title="F1 值"></a><em>F1</em> 值</h4><p><em>F1值</em>：$\beta=1$ 时的 <em>F测度</em></p>
<script type="math/tex; mode=display">\begin{align*}
\frac {1} {F_{1}} &= \frac {1} {2} \left( \frac {1} {P} + \frac {1} {R} \right) \\
\Rightarrow F_{1} &= \frac {2 * P * R} {P + R} = \frac {2 * TP} {样例总数 + TP - TN}
\end{align*}</script><h3 id="TPR、FPR"><a href="#TPR、FPR" class="headerlink" title="TPR、FPR"></a><em>TPR</em>、<em>FPR</em></h3><ul>
<li><p><em>TPR</em>、<em>FPR</em> 可视为对 <em>TP</em>、<em>FP</em> 用样本数量归一化的结果</p>
<ul>
<li>样本全体中正、负样本数量往往差距很大，直接比较 <em>TP</em>、<em>FP</em> 不合理</li>
<li>考虑使用样本正、负数量归一化，即计算正比例 <em>TPR</em>、负比例 <em>FPR</em></li>
</ul>
</li>
<li><p><em>TPR</em> 越高越好，<em>FPR</em> 越低越好，但是这两个指标相互制约，两者同时增加、减小</p>
<ul>
<li>模型倾向于将样本 <strong>判定为</strong> 为正例，则 <em>TP</em>、<em>FP</em> 同时增加，<em>TPR</em>、<em>FPR</em> 同时变大</li>
<li>即模型取不同阈值，会产生正相关的 <em>TPR</em>、<em>FPR</em> 的点列</li>
</ul>
</li>
</ul>
<h3 id="Recevier-Operating-Characteristic-Curve"><a href="#Recevier-Operating-Characteristic-Curve" class="headerlink" title="Recevier Operating Characteristic Curve"></a><em>Recevier Operating Characteristic Curve</em></h3><p><em>ROC</em> 曲线：不同 <strong>正样本概率</strong> 划分阈值下 <em>TPR</em>、<em>FPR</em> 绘制的折线/曲线</p>
<script type="math/tex; mode=display">
TPR = \frac {TP} {TP+FN} \\
FPR = \frac {FP} {FP+TN}</script><ul>
<li><p><em>ROC</em> 曲线即以 <em>FPR</em> 为横坐标、<em>TPR</em> 为正坐标绘制曲线</p>
<ul>
<li><em>FPR</em> 接近 1 时，<em>TPR</em> 也接近 1，这是不可避免的</li>
<li>而 <em>FPR</em> 接近 0 时，<em>TPR</em> 越大越好</li>
<li>所以模型 <em>ROC</em> 曲线下方面积越大，模型判断正确效果越好</li>
</ul>
</li>
<li><p>理解</p>
<ul>
<li>将正负样本的正样本概率值分别绘制在 <code>x=1</code>、<code>x=-1</code> 两条直线上</li>
<li>阈值即为 <code>y=threshold</code> 直线</li>
<li><em>TPR</em>、<em>FPR</em> 则为 <code>x=1</code>、<code>x=-1</code> 两条直线在阈值直线上方点数量，与各直线上所有点数量比值</li>
</ul>
</li>
</ul>
<h3 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a><em>Accuracy</em></h3><p>准确率、误分率：评价分类器性能一般指标</p>
<script type="math/tex; mode=display">\begin{align*}
acc & = \frac 1 N sign(y_i = \hat y_i) \\
& = \frac {TP+TN} N \\
mis & = 1 - acc
\end{align*}</script><blockquote>
<ul>
<li>$y_i$：第 $i$ 样本实际类别</li>
<li>$\hat y_i$：第 $i$ 样本预测类别</li>
<li>$N$：样本数量</li>
</ul>
</blockquote>
<ul>
<li>对给定测试集，分类器正确分类样本数与总样本数比值</li>
<li>即 <em>0-1</em> 损失函数时经验风险</li>
</ul>
<h3 id="Top-PR"><a href="#Top-PR" class="headerlink" title="Top PR"></a><em>Top PR</em></h3><p>头部准召：评估模型头部性能</p>
<script type="math/tex; mode=display">
pr_{top} = \frac {TP_{top}} {TOP}</script><blockquote>
<ul>
<li>$TOP$：指定的头部数量</li>
<li>$TP_{top}$：头部中正例数量（正例指已知原 $TOP$ 样本）</li>
</ul>
</blockquote>
<h2 id="Area-Under-Curve"><a href="#Area-Under-Curve" class="headerlink" title="Area Under Curve"></a><em>Area Under Curve</em></h2><p><em>AUC</em> 值：<em>ROC</em> 曲线下方面积，越大越好</p>
<ul>
<li><p><em>AUC</em> 值实际含义：随机抽取一对正、负样本，对其中正样本的正样本预测概率值、大于负样本的正样本预测概率值的概率</p>
<ul>
<li>$=1$：完美预测，存在一个阈值可以让模型 <em>TPR</em> 为 1，<em>FPR</em> 为 0</li>
<li>$(0.5, 1)$ ：优于随机预测，至少存在某个阈值，模型 $TPR &gt; FPR$</li>
<li>$=0.5$：同随机预测，无价值</li>
<li>$[0, 0.5)$：差于随机预测，但是可以反向取预测值</li>
</ul>
</li>
</ul>
<h3 id="AUC-计算"><a href="#AUC-计算" class="headerlink" title="AUC 计算"></a><em>AUC</em> 计算</h3><ul>
<li><p>绘制 <em>ROC</em> 曲线，计算曲线下面积</p>
<ul>
<li>给定一系列阈值（最精确时为样本数量），分别计算 <em>TPR</em>、<em>FPR</em></li>
<li>根据 <em>TPR</em>、<em>FPR</em> 计算 <em>AUC</em></li>
</ul>
</li>
<li><p>正负样本分别配对，计算正样本预测概率大于负样本比例</p>
<script type="math/tex; mode=display">\begin{align*}
auc & = \frac {\sum I(P_P > P_N)} {M * N} \\
I(P_P, P_N) & = \left \{ \begin{array}{l}
   1, & P_P > P_N, \\
   0.5, & P_P = P_N, \\
   0, & P_P < P_N
\end{array} \right.
\end{align*}</script><blockquote>
<ul>
<li>$M, N$：正、负样本数量</li>
</ul>
</blockquote>
</li>
<li><p><em>Mann-Witney U</em> 检验：即正、负样本分别配对的简化公式</p>
<script type="math/tex; mode=display">
auc = \frac {\sum_{i \in Pos} rank(i) - \frac {M * (M+1)} 2} {M * N}</script><blockquote>
<ul>
<li>$Pos$：正样本集合</li>
<li>$rank(i)$：样本 $i$ 的按正样本概率排序的秩（对正样本概率值相同样本，应将秩加和求平均保证其秩相等）</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="Weighted-AUC"><a href="#Weighted-AUC" class="headerlink" title="Weighted-AUC"></a><em>Weighted-AUC</em></h3><p><em>WAUC</em>：给 <strong>每个样本</strong> 赋权，计算统计量时考虑样本权重</p>
<ul>
<li><p><em>FPR</em>、<em>TPR</em> 绘图</p>
<script type="math/tex; mode=display">\begin{align*}
WTPR & = \frac {\sum_{i \in Pos} w_i I(\hat y_i=1)}
   {\sum_{i \in Pos} w_i} \\
WFPR & = \frac {\sum_{j \in Neg} w_j I(\hat y_j=1)}
   {\sum_{j \in Neg} w_j}
\end{align*}</script><blockquote>
<ul>
<li>$WTPR, WFPR$：加权 <em>TPR</em>、加权 <em>FPR</em></li>
<li>$\hat y_i$：样本预测类别</li>
<li>$w_i$：样本权重</li>
</ul>
</blockquote>
</li>
<li><p><em>Mann-Witney U</em> 检验：考虑其意义，带入权重即可得</p>
<script type="math/tex; mode=display">\begin{align*}
auc = \frac {\sum_{i \in Pos} w_i * rank(i) -
   \sum_{i \in Pos} w_i * rank_{pos}(i)}
   {\sum_{i \in Pos} w_i * \sum_{j \in Neg} w_j}
\end{align*}</script><blockquote>
<ul>
<li>$rank_{pos}(i)$：正样本内部排序，样本$i$秩</li>
<li>$Neg$：负样本集合</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="多分类-AUC"><a href="#多分类-AUC" class="headerlink" title="多分类 AUC"></a>多分类 <em>AUC</em></h3><ul>
<li><p><em>Micro-AUC</em>：将每个类别视为样本标签，计算全体样本的正标签、负标签的 <em>AUC</em></p>
<ul>
<li>$n$ 个样本的 $m$ 维标签展平， 则其中有 $n$ 个正样本、$n * (m-1)$ 个负样本</li>
<li>$n$ 个样本的 $m$ 个分类器共 $n * m$ 个得分展平</li>
<li>使用以上预测得分、标签计算 <em>AUC</em></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># one-vs-rest分类器得分</span></span><br><span class="line">y_score = classifer.transform(X_test)</span><br><span class="line"><span class="comment"># 展平后计算fpr、tpr</span></span><br><span class="line">fpr_micro, tpr_micro, threshhold_micro = \</span><br><span class="line">	skilearn.metrics.roc_curve(y_test.ravel(), y_score.ravel())</span><br><span class="line"><span class="comment"># 利用fpr、tpr计算auc</span></span><br><span class="line">auc_micro = skilearn.metrics.auc(fpr_micro, tpr_micro)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等价于直接调用</span></span><br><span class="line">auc_micro = skilearn.metrics.roc_auc_score(y_test, y_score, average=<span class="string">&quot;micro&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><em>Macro-AUC</em>：对各类别，分别以计算 <em>ROC</em> 曲线（即 <em>TPR</em>、<em>FPR</em>），计算平均 <em>ROC</em> 曲线得到 <em>AUC</em></p>
<ul>
<li>对各类别分别计算 <em>TPR</em>、<em>FPR</em>，共 $m$ 组 <em>TPR</em>、<em>FPR</em></li>
<li><p>平均合并 <em>TPR</em>、<em>FPR</em>，计算 <em>AUC</em></p>
<ul>
<li><p>方法1：合并 <em>FPR</em>、去除重复值，使用 $m$ 组 <em>TPR</em>、<em>FPR</em> 分别求合并后 <em>FPR</em> 插值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分别计算各类别fpr、tpr</span></span><br><span class="line">fprs, tprs = [<span class="number">0</span>] * n_classes, [<span class="number">0</span>] * n_classes</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">	fprs[idx], tprs[idx], _ = sklearn.metrics.ruc_curve(</span><br><span class="line">		y_test[:, i], y_score[:, i])</span><br><span class="line"><span class="comment"># 合并fpr</span></span><br><span class="line">all_fpr = np.unique(np.concatenate(fprs))</span><br><span class="line">mean_tpr = np.zeros_like(all_fpr)</span><br><span class="line"><span class="comment"># 计算合并后fpr插值</span></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">	mean_tpr += scipy.interp(all_fpr, fpr[idx], tpr[idx])</span><br><span class="line">mean_tpr /= n_classes</span><br><span class="line">auc_macro = sklearn.metrics.auc(all_fpr, mean_tpr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 但是和以下结果不同</span></span><br><span class="line">auc_macro = sklearn.metrics.roc_auc_score(fprs)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>以上分类器均为 <em>one-vs-rest</em> 分类器，$m$ 个类别则 $m$ 个分类器、每个样本 $m$ 个得分</li>
</ul>
</blockquote>
<h3 id="Kolmogorov-Smirnov-统计量"><a href="#Kolmogorov-Smirnov-统计量" class="headerlink" title="Kolmogorov-Smirnov 统计量"></a><em>Kolmogorov-Smirnov</em> 统计量</h3><p><em>KS</em> 值：刻画区分正负样本能力</p>
<script type="math/tex; mode=display">
KS = max \{|TPR - FPR|\}</script><ul>
<li><em>KS</em> 值体现 <strong>最理想情况</strong> 下，对正负样本区分能力<ul>
<li>即 <em>ROC</em> 曲线与 $TPR = FPR$ 直线的最远距离</li>
</ul>
</li>
</ul>
<h2 id="Squared-Error"><a href="#Squared-Error" class="headerlink" title="Squared Error"></a><em>Squared Error</em></h2><h3 id="Mean-Squared-Error"><a href="#Mean-Squared-Error" class="headerlink" title="Mean Squared Error"></a><em>Mean Squared Error</em></h3><p><em>MSE</em>：均方误差（偏差）</p>
<script type="math/tex; mode=display">
MSE = \frac 1 n \sum_{i=1}^{n} (y_{i} - \hat{y_{i}})^{2}</script><h4 id="Mean-Absolute-Error"><a href="#Mean-Absolute-Error" class="headerlink" title="Mean Absolute Error"></a><em>Mean Absolute Error</em></h4><p><em>MAE</em>：平均绝对误差</p>
<script type="math/tex; mode=display">
MAE = \frac 1 n \sum_{i=1}^n |y_i - \hat {y_i}|</script><h4 id="Mean-Absolute-Percentage-Error"><a href="#Mean-Absolute-Percentage-Error" class="headerlink" title="Mean Absolute Percentage Error"></a><em>Mean Absolute Percentage Error</em></h4><p><em>MAPE</em>：平均绝对百分比误差</p>
<script type="math/tex; mode=display">
MAPE = \frac 1 n \sum_{i=1}^n |\frac {y_i - \hat {y_i}} {y_i}|</script><h4 id="Symmetric-Mean-Absolute-Percentage-Error"><a href="#Symmetric-Mean-Absolute-Percentage-Error" class="headerlink" title="Symmetric Mean Absolute Percentage Error"></a><em>Symmetric Mean Absolute Percentage Error</em></h4><p><em>SMAPE</em>：对称平均绝对百分比误差</p>
<script type="math/tex; mode=display">
MAPE = \frac 1 n \sum_{i=1}^n |\frac {y_i - \hat {y_i}} {(|y_i| + |\hat {y_i}|) / 2}|</script><h3 id="R-2"><a href="#R-2" class="headerlink" title="$R^2$"></a>$R^2$</h3><script type="math/tex; mode=display">\begin{align*}
R^2 & = 1 - \frac {SSE} {SST} = \frac {SSR} {SST} \\
R^2_{adj} & = 1 - \frac {1 - R^2} {n - p - 1}
\end{align*}</script><blockquote>
<ul>
<li>$n, p$：样本量、特征数量</li>
<li>$SSE$：残差平方和</li>
<li>$SSR$：回归平方和、组内平方和</li>
<li>$SST$：离差平方和</li>
<li>$R^2_{adj}$：调整的$R^2$</li>
</ul>
</blockquote>
<h3 id="Akaike-Information-Criterion"><a href="#Akaike-Information-Criterion" class="headerlink" title="Akaike Information Criterion"></a><em>Akaike Information Criterion</em></h3><p><em>AIC</em> ：赤池信息准则</p>
<script type="math/tex; mode=display">\begin{align*}
AIC & = -2log(L(\hat \theta, x)) + 2p \\
& = nln(SSE/n) + 2p
\end{align*}</script><blockquote>
<ul>
<li>$n, p$：样本量、特征数量</li>
<li>$\theta$：带估参数</li>
<li>$L(\theta, x)$：似然函数</li>
<li>$SSE$：残差平方和</li>
</ul>
</blockquote>
<h3 id="Bayesian-Information-Criterion"><a href="#Bayesian-Information-Criterion" class="headerlink" title="Bayesian Information Criterion"></a><em>Bayesian Information Criterion</em></h3><p><em>BIC</em>：贝叶斯信息准则</p>
<script type="math/tex; mode=display">\begin{align*}
BIC & = -2log(L(\hat \theta, x)) + ln(n)p \\
& = nln(SSE/n) + ln(n)p
\end{align*}</script><h3 id="C-p"><a href="#C-p" class="headerlink" title="$C_p$"></a>$C_p$</h3><script type="math/tex; mode=display">\begin{align*}
C_p & = \frac {SSE} {\hat {\sigma^2}} - n + 2p \\
& = (n - m - 1) \frac {SSE_p} {SSE_m} - n + 2p
\end{align*}</script><blockquote>
<ul>
<li>$p$：选模型特征子集中特征数量</li>
<li>$m$：所有特征数量</li>
<li>$SSE_p$：选模型中残差平方和</li>
<li>$SSE_m$：全模型中残差平方和</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-21T09:27:37.000Z" title="3/21/2019, 5:27:37 PM">2019-03-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T12:44:40.000Z" title="7/12/2021, 8:44:40 PM">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Time-Series/">Time Series</a></span><span class="level-item">11 minutes read (About 1580 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Time-Series/models_sure_analysis.html">确定性时序分析</a></h1><div class="content"><h2 id="Time-Series-Decomposition"><a href="#Time-Series-Decomposition" class="headerlink" title="Time Series Decomposition"></a><em>Time Series Decomposition</em></h2><blockquote>
<ul>
<li>因素分解方法：克服其他因素干扰，单纯测度某个确定性因素（季节、趋势、交易日）的序列的影响</li>
<li>指数平滑预测方法：根据序列呈现的确定性特征，选择适当的方法对序列进行综合预测</li>
</ul>
</blockquote>
<h3 id="因素分解模型"><a href="#因素分解模型" class="headerlink" title="因素分解模型"></a>因素分解模型</h3><ul>
<li><p>因素分解模型思想</p>
<ul>
<li>所有序列波动可以归纳为受到以下 4 种因素影响（全部或部分）</li>
<li>导致序列呈现不同的波动特征，即任何时间序列可以用 4 因素的某个函数进行拟合 $x_t = f(T_t, C_t, S_t, I_t)$</li>
</ul>
</li>
<li><p><em>Trend</em>：序列呈现的长期递增、递减的变化趋势</p>
</li>
<li><p><em>Circle</em>：序列呈现的从高到低、在由低到高的反复循环波动</p>
<ul>
<li>很多经济、社会现象确实有循环周期，但是这个周期往往很长、长度不固定</li>
<li>如何观测值序列不够长，没有包含多个周期，周期的一部分会和趋势重合，无法准确、完整地提取周期影响</li>
<li>在经济学领域常用的周期有<ul>
<li>基钦周期：平均 40 个月</li>
<li>朱格拉周期：平均 10 年</li>
<li>库兹涅茨周期：平均 20 年</li>
<li>康德拉季耶夫周期：平均 53.3 年</li>
</ul>
</li>
</ul>
</li>
<li><p><em>Season</em>：和季节变化相关的稳定周期波动</p>
</li>
<li><p><em>Immediate</em>：其他不能用确定性因素解释的序列波动</p>
</li>
</ul>
<h3 id="常用模型（函数）"><a href="#常用模型（函数）" class="headerlink" title="常用模型（函数）"></a>常用模型（函数）</h3><ul>
<li>加法模型：$x_t = T_t + C_t + S_t + I_t$</li>
<li>乘法模型：$x_t = T_t <em> C_t </em> S_t * I_t$</li>
<li>伪加法模型：$x_t = T_t * (S_t + D_t + I_s)$</li>
<li>对数加法模型：$log<em>{x_t} = log</em>{T<em>t} + log</em>{S<em>t} + log</em>{D<em>t} + log</em>{I_t}$</li>
</ul>
<h3 id="考虑节假日"><a href="#考虑节假日" class="headerlink" title="考虑节假日"></a>考虑节假日</h3><ul>
<li><p>有些社会、经济现象显示某些 <strong>特殊日期</strong> 是很显著的影响因素，但是在传统因素分解模型中，没有被纳入研究</p>
<ul>
<li>股票交易受交易日影响</li>
<li>超市销售受周末、节假日影响</li>
<li>交通、运输、旅游同样受到周末、节假日影响</li>
</ul>
</li>
<li><p>如果观察时期不足够长，考虑将模型中 <em>Circle</em>（周期） 改为 <em>Day</em>（节假日）</p>
</li>
</ul>
<h2 id="Exponential-Smoothing"><a href="#Exponential-Smoothing" class="headerlink" title="Exponential Smoothing"></a><em>Exponential Smoothing</em></h2><ul>
<li>根据序列是否具有长期趋势、季节效应，可以把序列分为3大类<ul>
<li>既没有长期趋势、又没有季节效应</li>
<li>只有长期趋势、没有季节效应</li>
<li>有季节效应，无论是否有长期趋势</li>
</ul>
</li>
</ul>
<h3 id="简单指数平滑"><a href="#简单指数平滑" class="headerlink" title="简单指数平滑"></a>简单指数平滑</h3><h4 id="简单移动平均"><a href="#简单移动平均" class="headerlink" title="简单移动平均"></a>简单移动平均</h4><ul>
<li>对无趋势、季节的水平平稳序列<ul>
<li>可以认为序列在比较短时间内，序列取值比较稳定，序列值差异主要是随机波动造成</li>
<li>根据此假定，可以使用最近一段时间内平均值作为未来几期预测值</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">\begin{align*}
\hat x_{t+1} & = \frac {x_t + x_{t-1} + \dots + x_{t_n+1}} n \\
\hat x_{t+2} & = \frac {\hat x_t + x_t + x_{t-1} + \dots + x_{t-n+2}} n \\
\hat x_{t+l} & = \frac {\hat x_{t+1-1} + \hat x_{t+l-2} + \dots +
    \hat x_{t+1} + x_t + \dots + x_{t-n+l}} n \\
\end{align*}</script><blockquote>
<ul>
<li>简单移动平均假定无论时间远近，近 $n$ 期的序列观测值影响力一样</li>
</ul>
</blockquote>
<h4 id="简单指数平滑预测"><a href="#简单指数平滑预测" class="headerlink" title="简单指数平滑预测"></a>简单指数平滑预测</h4><blockquote>
<ul>
<li>实务中，对一般的随机事件，近期的结果对现在的影响更大</li>
</ul>
</blockquote>
<ul>
<li>指数平滑法构造思想<ul>
<li>考虑到事件间隔对事件发展的影响，各期权重随时间间隔增大而指数衰减</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">\begin{align*}
\hat x_{t+1} & = \alpha x_t + \alpha (1-\alpha) x_{t-1} +
    \alpha (1-\alpha)^2 x_{t-2} + \dots \\
& = \alpha x_t (1-\alpha) [\alpha x_{t-1} + \alpha (1-\alpha) x_{t-2} +
    \alpha (1-\alpha)^2 x_{t-3} + \dots] \\
& = \alpha x_t + (1-\alpha) \hat x_t
\end{align*}</script><ul>
<li>初值：很多方法可以确定，最简单指定 $\hat x_1 = x_1$</li>
<li>平滑系数 $\alpha$<ul>
<li>经验值在 $[0.05, 0.3]$，<ul>
<li>对于变化较缓慢的序列，取较小值</li>
<li>对于变化迅速的序列，取较大值</li>
</ul>
</li>
<li>如果 $\alpha$ 过大，说明序列波动性过强，不适合使用简单指数平滑</li>
</ul>
</li>
<li>理论上可以预测任意期值，但是任意期预测值都是常数<ul>
<li>因为没有新的观测值提供新信息</li>
</ul>
</li>
</ul>
<h3 id="Holt-两参数指数平滑"><a href="#Holt-两参数指数平滑" class="headerlink" title="Holt 两参数指数平滑"></a><em>Holt</em> 两参数指数平滑</h3><ul>
<li>两参数指数平滑<ul>
<li>适合对含有线性趋势的序列进行修匀</li>
<li>即分别用指数平滑的方法，结合序列最新观察值，不断修匀参数 $a, b$ 的估计值</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">\begin{align*}
x_t & = a_0 + bt + \epsilon_t \\
& = a_0 + b(t-1) + b + \epsilon \\
& = (x_{t-1} + \epsilon_{t-1}) + b + \epsilon_t \\
& = a(t-1) + b(t)
\end{align*}</script><blockquote>
<ul>
<li>$a(t-1) = x<em>{t-1} - \epsilon</em>{t-1}$</li>
<li>$b(t) = b + \epsilon_t$</li>
</ul>
</blockquote>
<ul>
<li><p>两参数递推公式</p>
<script type="math/tex; mode=display">\begin{align*}
\hat a(t) & = \alpha x_t + (1-\alpha)[\hat \alpha(t-1) + \hat b(t-1)] \\
\hat b(t) & = \beta [\hat a(t) - \hat a(t-1)] + (1-\beta) \hat b(t-1)
\end{align*}</script></li>
<li><p>序列预测公式</p>
<script type="math/tex; mode=display">
\hat x_{t+k} = \hat a(t) + \hat b(t)*k \\</script></li>
<li><p>初值设置</p>
<ul>
<li>$\hat a(0)=x_1$</li>
<li>$\hat b(0)=\frac {x_{n+1} - x_1} n$</li>
</ul>
</li>
</ul>
<h3 id="Holt-Winter-三参数指数平滑"><a href="#Holt-Winter-三参数指数平滑" class="headerlink" title="Holt-Winter 三参数指数平滑"></a><em>Holt-Winter</em> 三参数指数平滑</h3><ul>
<li>三参数指数平滑<ul>
<li>在 <em>Holt</em> 指数平滑的基础上构造，以修匀季节效应</li>
</ul>
</li>
</ul>
<h4 id="加法模型"><a href="#加法模型" class="headerlink" title="加法模型"></a>加法模型</h4><ul>
<li><p>模型表达式</p>
<script type="math/tex; mode=display">\begin{align*}
x_t & = a_0 + bt + c_t + \epsilon_t \\
& = a_0 + b(t-1) + b + c_t + \epsilon_t \\
& = (x_{t-1} - c{t-1} - \epsilon_{t-1}) + b + \epsilon_t + (Sd_j + e_t) \\
& = a(t-1) + b(t) + c(t)
\end{align*}</script><blockquote>
<ul>
<li>$a(t-1) = x<em>{t-1} - c</em>{t-1} - \epsilon_{t-1}$</li>
<li>$b(t) = b + \epsilon_t$</li>
<li>$c_t = Sd_t + e_t, e_t \sim N(0, \sigma_e^2)$</li>
</ul>
</blockquote>
</li>
<li><p>三参数递推式</p>
<script type="math/tex; mode=display">\begin{align*}
\hat a(t) & = \alpha(x_t - c(t-s)) + (1-\alpha)[\hat a(t-1) + \hat b(t-1)] \\
\hat b(t) & = \beta[\hat a(t) - \hat a(t-1)] + (1-\beta)\hat b(t-1) \\
\hat c(t) & = \gamma[x_t - \hat a(t)] + (1-\gamma)c(t-s)
\end{align*}</script></li>
<li><p>序列预测公式</p>
<script type="math/tex; mode=display">
\hat x_{t+k} = \hat a(t) + \hat b(t) + \hat c(t + mod(k,s) -s)</script></li>
</ul>
<h4 id="乘法模型"><a href="#乘法模型" class="headerlink" title="乘法模型"></a>乘法模型</h4><ul>
<li><p>模型表示式</p>
<script type="math/tex; mode=display">\begin{align*}
x_t & = (a_0 + bt + \epsilon_t)c_t \\
& = (a_0 + b(t-1) + b + \epsilon_t)c_t \\
& = [(x_{t-1}/c{t-1} - \epsilon_{t-1})+
   (b + \epsilon_{t-1})](S_j + e_t) \\
& = [a(t-1) + b(t)]c(t)
\end{align*}</script><blockquote>
<ul>
<li>$a(t-1) = x<em>{t-1}/c</em>{t-1} - \epsilon_{t-1}$</li>
<li>$b(t) = b + \epsilon_t$</li>
<li>$c_t = S_j + e_t, e_t \sim N(0, \sigma_e^2)$</li>
</ul>
</blockquote>
</li>
<li><p>三参数递推式</p>
<script type="math/tex; mode=display">\begin{align*}
\hat a(t) & = \alpha(x_t / c(t-s)) + (1-\alpha)[\hat a(t-1) + \hat b(t-1)] \\
\hat b(t) & = \beta[\hat a(t) - \hat a(t-1)] + (1-\beta)\hat b(t-1) \\
\hat c(t) & = \gamma[x_t / \hat a(t)] + (1-\gamma)c(t-s)
\end{align*}</script></li>
<li><p>序列预测公式</p>
<script type="math/tex; mode=display">
\hat x_{t+k} = [\hat a(t) + \hat b(t) * k] \hat c(t + mod(k,s) -s)</script></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-21T09:27:37.000Z" title="3/21/2019, 5:27:37 PM">2019-03-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-02-17T03:57:08.000Z" title="2/17/2019, 11:57:08 AM">2019-02-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Time-Series/">Time Series</a></span><span class="level-item">8 minutes read (About 1227 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Time-Series/co_integration.html">协整与误差修正模型</a></h1><div class="content"><h2 id="Spurious-Regression"><a href="#Spurious-Regression" class="headerlink" title="Spurious Regression"></a><em>Spurious Regression</em></h2><ul>
<li><p>多变量分析中，平稳性非常重要，忽略序列平稳性判断，容易出现伪回归现象</p>
</li>
<li><p><em>Granger</em>、<em>Newbold</em> 的非平稳序列的伪回归随机模型实验（两个独立随机游走模型）表明</p>
<ul>
<li>非平稳场合，参数显著性检验犯弃真错误的概率远大于 $\alpha$，伪回归显著成立</li>
<li>即 $P(|t| \geqslant t_{\alpha/2}(n) | 非平稳序列) \leqslant \alpha$</li>
</ul>
</li>
</ul>
<h3 id="Cointegration-协整关系"><a href="#Cointegration-协整关系" class="headerlink" title="Cointegration 协整关系"></a><em>Cointegration</em> 协整关系</h3><script type="math/tex; mode=display">
y_t = \beta_0 + \sum_{i=1}^k \beta_i x_{it} + \epsilon_t</script><blockquote>
<ul>
<li>${x_1}, {x_2}, \cdots, {x_k}$：自变量序列</li>
<li>$y_t$：响应变量序列</li>
<li>${\epsilon_t}$：平稳回归残差序列</li>
</ul>
</blockquote>
<h4 id="协整检验"><a href="#协整检验" class="headerlink" title="协整检验"></a>协整检验</h4><ul>
<li><p>假设条件</p>
<ul>
<li>$H_0: \epsilon_t ~ I(k), k \geqslant 1$：多元非平稳序列之间不存在协整关系</li>
<li>$H_1: \epsilon_t ~ I(0)$：多元非平稳序列之间存在协整关系</li>
</ul>
</li>
<li><p>建立响应序列与输入序列之间的回归模型</p>
</li>
<li>对回归残差序列进行 <em>EG</em> 平稳性检验</li>
</ul>
<h3 id="Error-Correction-Model"><a href="#Error-Correction-Model" class="headerlink" title="Error Correction Model"></a><em>Error Correction Model</em></h3><p><em>ECM</em>：误差修正模型，解释序列短期波动关系</p>
<ul>
<li><em>Granger</em> 证明协整模型、误差修正模型具有 <em>1-1</em> 对应关系<ul>
<li>协整模型度量序列之间长期均衡关系</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>实务中，响应序列与解释序列很少处于均衡点上，实际观测的是序列间短期或非均衡关系</li>
</ul>
</blockquote>
<h4 id="Granger-表述定理"><a href="#Granger-表述定理" class="headerlink" title="Granger 表述定理"></a><em>Granger</em> 表述定理</h4><blockquote>
<ul>
<li>如果变量 $X$、$Y$ 是协整的，则他们之间的短期非均衡关系总能用一个误差修正模型表述 $$<pre><code>  \Delta Y_t = lagged(\Delta Y, \Delta X) - \lambda ECM_&#123;t-1&#125; + \epsilon_t
</code></pre>  $$</li>
</ul>
</blockquote>
<ul>
<li><p>对关系 $y_t = \beta x_t + \epsilon_t$</p>
<script type="math/tex; mode=display">\begin{align*}
y_t - y_{t-1} & = \beta x_t - \beta x_{t-1} - \epsilon_{t-1} + \epsilon_t \\
\Delta y_t & = \beta \delta x_t - ECM_{t-1} + \epsilon_t
\end{align*}</script></li>
<li><p>响应序列当期波动 $\Delta y_t$ 主要受到三方面短期波动影响</p>
<ul>
<li>$\Delta x_t$：输出序列当前波动</li>
<li>$ECM_{t-1}$：上一期误差</li>
<li>$\epsilon_t$：纯随机波动</li>
</ul>
</li>
</ul>
<h4 id="误差修正模型"><a href="#误差修正模型" class="headerlink" title="误差修正模型"></a>误差修正模型</h4><script type="math/tex; mode=display">
\Delta y_t = \beta_0 \Delta x_t + \beta_1 ECM_{t-1} + \epsilon_t</script><ul>
<li>$\beta_1 &lt; 0$：表示负反馈机制<ul>
<li>$ECM_{t-1} &gt; 0$：正向误差，则会导致下一期值负向变化</li>
<li>$ECM_{t-1} &lt; 0$：负向误差，则会导致下一期值正向变化</li>
</ul>
</li>
</ul>
<h3 id="Granger-因果关系"><a href="#Granger-因果关系" class="headerlink" title="Granger 因果关系"></a><em>Granger</em> 因果关系</h3><ul>
<li><p>因果关系：原因导致结果</p>
<ul>
<li>时间角度：原因发生在前，结果发生在后</li>
<li>影响效果：$X$ 事件发生在前，且对 $Y$ 事件发展结果有意义</li>
</ul>
</li>
<li><p><em>Granger</em> 检验可检验统计学意义上的 <em>Granger</em> 因果关系</p>
<ul>
<li>统计意义上的因果关系和现实意义上因果关系不同</li>
<li>现实意义上变量因果关系强调逻辑自洽</li>
</ul>
</li>
</ul>
<h4 id="Granger-因果关系-1"><a href="#Granger-因果关系-1" class="headerlink" title="Granger 因果关系"></a><em>Granger</em> 因果关系</h4><blockquote>
<ul>
<li><p>序列 $X$ 是序列 $Y$ 的 <em>Granger</em> 原因，当且仅当最优线性预测函数使得下式成立 $$</p>
<pre><code>  \theta^2(y_&#123;t+1&#125;|I_t) \leq \theta^2(y_&#123;t+1&#125;|I_t-X_t)
</code></pre><p>  $$</p>
</li>
<li><p>$I<em>t = { x_t, x</em>{t-1}, \cdots, y<em>t, y</em>{t-1}, \cdots }$：$t$ 时刻所有有用信息集合</p>
</li>
<li>$X<em>t = { x_t, x</em>{t-1}, \cdots }$：t时刻所有序列信息集合</li>
<li>$\theta^2(y_{t+1}|I_t)$：使用所有可获得历史信息 （包括 ${x}$ 序列历史信息）得到的一期预测值方差</li>
<li>$\theta^2(y_{t+1}|I_t-X_t)$：从所有信息中刻意扣除 ${x}$ 序列历史信息得到的一期预测值方差</li>
</ul>
</blockquote>
<ul>
<li><em>Granger</em> 因果关系分类<ul>
<li>$(x, y)$：相互独立</li>
<li>$(x \leftarrow y)$：$x$ 是 $y$ 的 <em>Granger</em> 原因</li>
<li>$(x \rightarrow y)$：$y$ 是 $x$ 的 <em>Granger</em> 原因</li>
<li>$(x \leftrightarrow y)$：互为因果</li>
</ul>
</li>
</ul>
<h4 id="Granger-因果检验"><a href="#Granger-因果检验" class="headerlink" title="Granger 因果检验"></a><em>Granger</em> 因果检验</h4><ul>
<li><p>建立回归方程</p>
<script type="math/tex; mode=display">
y_t = \alpha_0 + \sum_{i=1}^m \alpha_i x_{t-i} +
   \sum_{j=1}^n b_j y_{t-j} + \sum_k cz_{t-k} +
   \epsilon_t</script><blockquote>
<ul>
<li>$z_t$：其他解释变量集合</li>
<li>$\epsilon_t \sim I(0)$</li>
</ul>
</blockquote>
</li>
<li><p>假设</p>
<ul>
<li>$H_0: \alpha_1 = \alpha_2 = \cdots = \alpha_m = 0$</li>
<li>$H_1: \alpha_i 不全为0$</li>
</ul>
</li>
<li><p>检验统计量：F统计量</p>
<script type="math/tex; mode=display">
F = \frac {(SSE_r - SSE_u) / q} {SSE_u/n-q-p-1} \sim F(q, n-p-q-1)</script></li>
</ul>
<h4 id="Granger-因果检验说明"><a href="#Granger-因果检验说明" class="headerlink" title="Granger 因果检验说明"></a><em>Granger</em> 因果检验说明</h4><ul>
<li><p><em>Granger</em> 因果检验思想：对响应变量预测精度有显著提高的自变量，就视为响应变量的因</p>
<ul>
<li>因果性可以推出预测精度提高，但预测精度提高不能等价推出因果性</li>
<li>即使检验结果显著拒绝原假设，也不能说明两个序列之间有真正因果关系</li>
</ul>
</li>
<li><p><em>Granger</em> 因果检验是处理复杂变量关系时的工具</p>
<ul>
<li>借助因果检验信息，可以帮助思考模型结果</li>
<li>不一定准确，但是提供信息比完全没有信息好</li>
</ul>
</li>
<li><p><em>Granger</em> 因果结果说明</p>
<ul>
<li>检验结果严重依赖解释变量的延迟阶数，不同延迟阶数可能会得到不同的检验结果</li>
<li>检验结果会受到样本随机性影响，样本容量越小随机性越大，所以最好在样本容量比较大时进行检验</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-21T09:27:37.000Z" title="3/21/2019, 5:27:37 PM">2019-03-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-02-17T03:57:08.000Z" title="2/17/2019, 11:57:08 AM">2019-02-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Time-Series/">Time Series</a></span><span class="level-item">2 minutes read (About 337 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Time-Series/stat_tests.html">统计检验</a></h1><div class="content"><h2 id="JJ-检验"><a href="#JJ-检验" class="headerlink" title="JJ 检验"></a><em>JJ</em> 检验</h2><h3 id="检验思想"><a href="#检验思想" class="headerlink" title="检验思想"></a>检验思想</h3><ul>
<li><em>JJ</em> 检验：检验 $VAR(k)$ 模型的协整关系<ul>
<li>参考多元分析中典型相关分析的构造思想</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">\begin{align*}
Y_t & = c + \Pi_1 Y_{t-1} + \Pi_2 Y_{t-2} + \cdots +
    \Pi_k Y_{t-k} + u_t + \Phi D_t \\
\Delta Y_t & = y_{t-1} + \Pi Y_{t-1} + \Gamma_1 \Delta Y_{t-2}
    + \cdots + \Gamma_{k-1} \Delta Y_{t-p+1} + \epsilon_t + \Phi D_t
\end{align*}</script><blockquote>
<ul>
<li>$Y<em>t = (y</em>{1,t}, y<em>{2,t}, \cdots, y</em>{N,t})^T \sim I(1)$</li>
<li>$\Pi = \sum_{i=1}^k \Pi_i - I$</li>
<li>$\Gamma<em>i = -\sum</em>{j=i+1}^k$</li>
</ul>
</blockquote>
<ul>
<li>基础协整关系 = $\Pi$ 非零特征根数量<ul>
<li>基础协整关系的任意线性组合依然是协整的</li>
<li>系统中协整关系至少为非零特征根数量</li>
</ul>
</li>
</ul>
<h3 id="检验方法"><a href="#检验方法" class="headerlink" title="检验方法"></a>检验方法</h3><blockquote>
<ul>
<li>假设 $\lambda_1 \geq \lambda_2  \geq \cdots \lambda_m$ 是 $\Pi$ 的所有特征根</li>
</ul>
</blockquote>
<h4 id="最大特征根检验"><a href="#最大特征根检验" class="headerlink" title="最大特征根检验"></a>最大特征根检验</h4><ul>
<li><p>检验统计量：<em>Bartlette</em> 统计量 $Q = -Tln(1-\lambda_i^2)$</p>
</li>
<li><p>假设</p>
<ul>
<li>原假设：$H_0: \lambda_i = 0$</li>
</ul>
</li>
<li><p>检验流程</p>
<ul>
<li>从 $\lambda_1$ 开始检验是否显著不为 0</li>
<li>直到某个 $\lambda_k$ 非显著不为0，则系统有 $k-1$ 个协整关系</li>
</ul>
</li>
</ul>
<h4 id="迹检验"><a href="#迹检验" class="headerlink" title="迹检验"></a>迹检验</h4><ul>
<li><p>检验统计量：<em>Bartlette</em> 统计量 $Q = -T \sum_{j=i}^m ln(1-\lambda_j^2)$</p>
</li>
<li><p>假设</p>
<ul>
<li>原假设：$H<em>0: \sum</em>{j=i}^m \lambda_j = 0$</li>
</ul>
</li>
<li><p>检验流程</p>
<ul>
<li>从 $\sum_{j=1}^m \lambda_j = 0$ 开始检验是否显著不为 0</li>
<li>直到某个 $\sum_{j=k}^m ln(1-\lambda_j^2)$ 非显著不为 0，说明系统存在$k-1$个协整关系</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-21T09:27:37.000Z" title="3/21/2019, 5:27:37 PM">2019-03-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T12:45:58.000Z" title="7/12/2021, 8:45:58 PM">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Time-Series/">Time Series</a></span><span class="level-item">5 minutes read (About 810 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Time-Series/stat_time_series.html">时间序列分析</a></h1><div class="content"><h2 id="时间序列分析"><a href="#时间序列分析" class="headerlink" title="时间序列分析"></a>时间序列分析</h2><ul>
<li><p>时间序列数据：在不同时间点收集到的数据，反映某事物、现象随实际变化状态、程度</p>
</li>
<li><p>描述性时序分析：通过直观的数据比较、绘图观测，寻找序列中蕴含的发展规律</p>
<ul>
<li>操作简单、直观有效，是时序分析的第一步</li>
<li>但是只能展示非常明显的规律性</li>
<li>最早的时序分析方法，所有时序分析的基础</li>
<li>帮助人们找到自然规律<ul>
<li>尼罗河的泛滥</li>
<li>范蠡稳定粮价</li>
<li>小麦价格指数序列</li>
<li>太阳黑子运动规律</li>
</ul>
</li>
</ul>
</li>
<li><p>确定性时序分析：根据序列的观察特征，先构想一个序列运行的理论，默认序列按照此理论确定性运作</p>
<ul>
<li>侧重于确定性信息的提取</li>
<li>通常不能通过分析误差自行修正模型，只能通过新的模型假定，
推翻旧模型实现分析方法的改进</li>
<li>假定条件决定了序列的拟合精度，如果确定性的假定条件不对，
误差将很大，因此限制其使用范围</li>
</ul>
</li>
</ul>
<h3 id="时域分析"><a href="#时域分析" class="headerlink" title="时域分析"></a>时域分析</h3><h3 id="确定性时域分析"><a href="#确定性时域分析" class="headerlink" title="确定性时域分析"></a>确定性时域分析</h3><ul>
<li><p>原理：事件的发展通常具有一定的<strong>惯性</strong>，用统计语言描述就是序列值之间存在一定的相关关系，即某种统计规律</p>
</li>
<li><p>目的：寻找序列值之间的相关关系的统计规律，并拟合适当数学模型描述，进而用于预测</p>
</li>
<li><p>特点</p>
<ul>
<li>理论基础扎实</li>
<li>操作步骤规范</li>
<li>分析结果易于解释</li>
</ul>
</li>
</ul>
<h4 id="常用领域"><a href="#常用领域" class="headerlink" title="常用领域"></a>常用领域</h4><ul>
<li><p>宏观经济领域的 <em>Time Series Decomposition</em></p>
</li>
<li><p>确定性趋势预测</p>
<ul>
<li>趋势预测：线性趋势预测、非线性趋势预测</li>
<li>指数平滑预测：简单、两参、三参指数平滑</li>
</ul>
</li>
</ul>
<h3 id="随机性时域分析"><a href="#随机性时域分析" class="headerlink" title="随机性时域分析"></a>随机性时域分析</h3><ul>
<li><p>原理：假设序列为随机变量序列，利用对随机变量分析方法研究序列</p>
</li>
<li><p>特点</p>
<ul>
<li>预测精度更高</li>
<li>分析结果可解释性差</li>
<li>是目前时域分析的主流方法</li>
</ul>
</li>
</ul>
<h3 id="频域分析"><a href="#频域分析" class="headerlink" title="频域分析"></a>频域分析</h3><ul>
<li>思想：假设任何一种无趋势的实现序列，都可以分解成若干不同频率的周期波动（借助傅里叶变换，用三角函数逼近）</li>
</ul>
<h2 id="时域分析发展"><a href="#时域分析发展" class="headerlink" title="时域分析发展"></a>时域分析发展</h2><h3 id="启蒙阶段"><a href="#启蒙阶段" class="headerlink" title="启蒙阶段"></a>启蒙阶段</h3><ul>
<li><em>AR</em> 模型：<em>George Undy Yule</em></li>
<li><em>MA</em> 模型、<em>Yule-Walker</em> 方程：<em>Sir Gilbert Thomas Walker</em></li>
</ul>
<h3 id="核心阶段"><a href="#核心阶段" class="headerlink" title="核心阶段"></a>核心阶段</h3><ul>
<li><em>ARIMA</em>：经典时间序列分析方法，是时域分析的核心内容<ul>
<li><em>Box &amp; Jenkins</em> 书中系统的阐述了ARIMA模型的识别、估计、检验、预测原理和方法</li>
</ul>
</li>
</ul>
<h3 id="完善阶段"><a href="#完善阶段" class="headerlink" title="完善阶段"></a>完善阶段</h3><ul>
<li><p>异方差场合</p>
<ul>
<li><em>ARCH</em>：<em>Robert Fry Engle</em></li>
<li><em>GARCH</em>：<em>Bollerslov</em></li>
<li><em>GARCH</em> 衍生模型<ul>
<li><em>EGARH</em></li>
<li><em>IGARCH</em></li>
<li><em>GARCH-M</em></li>
<li><em>NGARCH</em></li>
<li><em>QGARCH</em></li>
<li><em>TGARCH</em></li>
</ul>
</li>
</ul>
</li>
<li><p>多变量场合</p>
<ul>
<li><em>ARIMAX</em>：<em>Box &amp; Jenkins</em></li>
<li><em>Co-intergration and error correction model</em>：<em>C.Granger</em>，协整理论</li>
<li><em>SYSLIN</em>：<em>Klein</em>，宏观经济连理方程组模型</li>
<li><em>Vector Autoregressive Model</em>：<em>Sims</em>，货币政策及其影响</li>
</ul>
</li>
<li><p>非线性场合</p>
<ul>
<li><em>Threshold Autoregressive Model</em></li>
<li><em>Artificical Neural Network</em></li>
<li><em>Hebbian Learning</em>：神经可塑性假说</li>
<li><em>Multivariate Adaptive Regression Splines</em></li>
<li><em>Linear Classifier</em></li>
<li><em>Support Vector Machines</em></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-21T09:27:37.000Z" title="3/21/2019, 5:27:37 PM">2019-03-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T12:42:40.000Z" title="7/12/2021, 8:42:40 PM">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Time-Series/">Time Series</a></span><span class="level-item">14 minutes read (About 2167 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Time-Series/stat_var.html">Vector Auto-regression Model</a></h1><div class="content"><h2 id="Vector-Auto-regression-Model"><a href="#Vector-Auto-regression-Model" class="headerlink" title="Vector Auto-regression Model"></a><em>Vector Auto-regression Model</em></h2><p><em>VAR</em> 模型：向量自回归模型</p>
<ul>
<li><p>模型特点</p>
<ul>
<li>不以经济理论为基础</li>
<li>结构简介明了</li>
<li>预测精度高</li>
</ul>
</li>
<li><p>模型方程特点</p>
<ul>
<li>采用多方程联立的形式</li>
<li>需要估计 $m(mp+1)$ 个参数的，对样本数量要求高</li>
<li>模型的每个方程中，<strong>内生变量</strong> 对模型的全部内生变量滞后项进行回归，估计全部内生变量的动态关系</li>
</ul>
</li>
<li><p>模型用途</p>
<ul>
<li>脉冲响应分析</li>
<li>方差分解</li>
</ul>
</li>
</ul>
<h3 id="VAR-模型参数"><a href="#VAR-模型参数" class="headerlink" title="VAR 模型参数"></a><em>VAR</em> 模型参数</h3><ul>
<li><p><em>VAR</em> 模型系数由统计相关性估计</p>
<ul>
<li>不具有逻辑上的因果关系</li>
<li>通常不直接解读 <em>VAR</em> 模型每个方程的经济学意义</li>
</ul>
</li>
<li><p><em>VAR</em> 模型参数不进行参数显著性检验，但是允许研究人员对参数施加特殊约束</p>
</li>
<li><p><em>VAR</em> 模型通常是由一系列 <strong>非平稳序列构造的平稳系统</strong></p>
<ul>
<li>所以若包含非平稳变量，其中至少存在 1 个协整关系</li>
<li>协整关系具有经济学意义，可以解读系数（所以需要进行协整检验）</li>
</ul>
</li>
</ul>
<h2 id="VAR模型形式"><a href="#VAR模型形式" class="headerlink" title="VAR模型形式"></a>VAR模型形式</h2><h3 id="两变量-VAR-1"><a href="#两变量-VAR-1" class="headerlink" title="两变量 VAR(1)"></a>两变量 <em>VAR(1)</em></h3><ul>
<li><p>方程组形式</p>
<script type="math/tex; mode=display">\begin{cases}
& y_{1,t} = c_1 + \pi_{1,1}y_{1,t-1} + \pi_{1,2}y_{2,t-1}
   + u_{1t} \\
& y_{2,t} = c_2 + \pi_{2,1}y_{1,t-1} + \pi_{2,2}y_{2,t-1}
   + u_{2t} \\
\end{cases}</script></li>
<li><p>矩阵形式</p>
<script type="math/tex; mode=display">
\begin{bmatrix} y_{1,t} \\ y_{2,t} \end{bmatrix} =
\begin{bmatrix} c_1 \\ c_2 \end{bmatrix} +
\begin{bmatrix}
   \pi_{1,1} & \pi_{1,2} \\
   \pi_{2,1} & \pi_{2,2} \\
\end{bmatrix}
\begin{bmatrix} y_{1,t-1} \\ y_{2,t-1} \end{bmatrix} +
\begin{bmatrix} u_{1,t} \\ u_{2,t} \end{bmatrix}</script></li>
</ul>
<blockquote>
<ul>
<li>$u<em>{1,t}, u</em>{2,t} \overset {i.i.d.} {\sim} (0, \theta^2)$：随机波动项，$Cov(u<em>{1,t}, u</em>{2,t}) = 0$</li>
</ul>
</blockquote>
<h3 id="多变量的-VAR-k-（含外生变量）"><a href="#多变量的-VAR-k-（含外生变量）" class="headerlink" title="多变量的 VAR(k)（含外生变量）"></a>多变量的 <em>VAR(k)</em>（含外生变量）</h3><script type="math/tex; mode=display">
Y_t = C + \Pi_1 Y_{t-1} + \Pi_2 Y_{t-2} + \cdots + \Pi_k Y_{t-k} + U_t + \Phi Z_t</script><blockquote>
<ul>
<li>$Y<em>t = (y</em>{1,t}, y<em>{2,t}, \cdots, y</em>{N,t})^T$：内生变量</li>
<li>$C = (c_1, c_2, \cdots, c_N)^T$：常数项</li>
<li>$\Pi_j = \begin{bmatrix}<pre><code>  \pi_&#123;11,j&#125; &amp; \pi_&#123;12,j&#125; &amp; \cdots &amp; \pi_&#123;1N,j&#125; \\
  \pi_&#123;21,j&#125; &amp; \pi_&#123;22,j&#125; &amp; \cdots &amp; \pi_&#123;2N,j&#125; \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  \pi_&#123;N1,j&#125; &amp; \pi_&#123;N2,j&#125; &amp; \cdots &amp; \pi_&#123;NN,j&#125; \\
</code></pre>  \end{bmatrix}$：内生变量待估参数</li>
<li>$U<em>t = (u</em>{1,t}, u<em>{2,t}, \cdots, u</em>{N,t})^T \overset {i.i.d.} {\sim} (0, \Omega)$：随机波动项</li>
<li>$Z<em>t = (z</em>{1,t}, z<em>{2,t}, \cdots, z</em>{N, t})^T$：外生变量</li>
</ul>
</blockquote>
<h4 id="VAR-k-变换"><a href="#VAR-k-变换" class="headerlink" title="VAR(k) 变换"></a><em>VAR(k)</em> 变换</h4><blockquote>
<ul>
<li><em>VAR(k)</em> 模型可通过变换附加伴随矩阵式，改写为 <em>VAR(1)</em></li>
</ul>
</blockquote>
<script type="math/tex; mode=display">\begin{align*}
 Y_t & = \Pi_1 Y_{t-1} + \Pi_2 Y_{t-2} + \cdots + \Pi_k Y_{t-k} + U_t \\
& = \begin{bmatrix} \Pi_1 & \Pi_2 & \cdots & \Pi_k \end{bmatrix}
    \begin{bmatrix}
        Y_{t-1} \\ Y_{t-2} \\
        \vdots \\ Y_{t-k}
    \end{bmatrix} + U_t \\
& = AY + U_t
\end{align*}</script><h3 id="Structured-VAR"><a href="#Structured-VAR" class="headerlink" title="Structured VAR"></a><em>Structured VAR</em></h3><p><em>SVAR</em>：结构 <em>VAR</em> 模型，在 <em>VAR</em> 模型基础上加入内生变量当期值</p>
<ul>
<li>即解释变量中含有当期变量</li>
</ul>
<h4 id="两变量-SVAR-1"><a href="#两变量-SVAR-1" class="headerlink" title="两变量 SVAR(1)"></a>两变量 <em>SVAR(1)</em></h4><script type="math/tex; mode=display">
\begin{cases}
& y_{1t} = c_1 + \pi_{11}y_{2t} + \pi_{12}y_{1,t-1} +
    \pi_{13}y_{1,t-2} + u_1 \\
& y_{2t} = c_2 + \pi_{21}y_{1t} + \pi_{22}y_{1,t-1} +
    \pi_{23}y_{1,t-2} + u_2 \\
\end{cases}</script><h3 id="含外生变量-VAR-1"><a href="#含外生变量-VAR-1" class="headerlink" title="含外生变量 VAR(1)"></a>含外生变量 <em>VAR(1)</em></h3><script type="math/tex; mode=display">\begin{align*}
AY_t & = D + BY_{t-1} + FZ_t + V_t \\
Y_t & = A^{-1}D + A^{-1}BY_{t-1} + A^{-1}FZ_t + A^{-1}v_t \\
    & = C + \Pi_1 Y_{t-1} + HZ_t + U_t
\end{align*}</script><blockquote>
<ul>
<li>$Y_t, Z_t, V_t$：内生变量向量、外生变量向量、误差项向量</li>
<li>$A, D, B, F$：模型结构参数</li>
<li>$C=A^{-1}D, \Pi_1=A^{-1}B, H=A^{-1}F, U_t=A^{-1}V_t$</li>
</ul>
</blockquote>
<h2 id="VAR-模型稳定性"><a href="#VAR-模型稳定性" class="headerlink" title="VAR 模型稳定性"></a><em>VAR</em> 模型稳定性</h2><ul>
<li>把脉冲施加在 <em>VAR</em> 模型中某个方程的 <em>Iinnovation</em> 过程上<ul>
<li>随着时间推移，冲击会逐渐消失，则模型稳定</li>
<li>冲击不消失的则模型不稳定</li>
</ul>
</li>
</ul>
<h3 id="一阶-VAR-模型分析"><a href="#一阶-VAR-模型分析" class="headerlink" title="一阶 VAR 模型分析"></a>一阶 <em>VAR</em> 模型分析</h3><script type="math/tex; mode=display">\begin{align*}
Y_t & = C + \Pi_1Y_{t-1} + U_t \\
    & = (I + \Pi_1 + \Pi_1^2 + \cdots + \Pi_1^{t-1})C +
        \Pi_1^tY_0 + \sum_{i=0}^{t-1} \Pi_1^i U_{t-i}
\end{align*}</script><blockquote>
<ul>
<li>$\mu = (I + \Pi_1 + \Pi_2^2 + \cdots + \Pi_1^{t-1})C$：漂移向量</li>
<li>$Y_0$：初始向量</li>
<li>$U_t$：新息向量</li>
</ul>
</blockquote>
<ul>
<li><p>$t \rightarrow \infty$ 时有</p>
<script type="math/tex; mode=display">
I + \Pi_1 + \Pi_2^2 + \cdots + \Pi_1^{t-1} = (I-\Pi_1)^{-1}</script></li>
</ul>
<h4 id="两变量-VAR-1-稳定条件"><a href="#两变量-VAR-1-稳定条件" class="headerlink" title="两变量 VAR(1) 稳定条件"></a>两变量 <em>VAR(1)</em> 稳定条件</h4><script type="math/tex; mode=display">
Y_t = C + \Pi_1 Y_{t-1} + U_t</script><ul>
<li>稳定条件<ul>
<li>特征方程$|\Pi_1 - \lambda I|=0$根都在单位圆内</li>
<li>相反的特征方程$|I - L\Pi_1|=0$根都在单位圆外</li>
</ul>
</li>
</ul>
<h4 id="VAR-k-稳定条件"><a href="#VAR-k-稳定条件" class="headerlink" title="VAR(k) 稳定条件"></a><em>VAR(k)</em> 稳定条件</h4><script type="math/tex; mode=display">\begin{align*}
\begin{bmatrix} Y_t \\ Y_{t-1} \\ Y_{t-2} \\ \vdots \\
    Y_{t-k+1} \end{bmatrix} & =
\begin{bmatrix} C \\ 0 \\0 \\ \vdots \\ 0 \end{bmatrix} +
\begin{bmatrix}
    \Pi_1 & \Pi_2 & \cdots & \Pi_{k-1} & \Pi_{k} \\
    I & 0 & \cdots & 0 & 0 \\
    0 & I & \cdots & 0 & 0 \\
    \vdots & \vdots & \ddots & \vdots & \vdots \\
    0 & 0 & \cdots & I & 0
\end{bmatrix}
\begin{bmatrix} Y_{t-1} \\ Y_{t-2} \\ Y_{t-3} \\ \vdots \\
    Y_{t-k} \end{bmatrix} +
\begin{bmatrix} U_t \\ 0 \\ 0 \\ \vdots \\ 0 \end{bmatrix} \\
    & = [C|0]^T + AY + U
\end{align*}</script><blockquote>
<ul>
<li>$A$：$Nk$ 阶方阵</li>
<li>$N$：回归向量维度</li>
<li>$k$：自回归阶数</li>
</ul>
</blockquote>
<ul>
<li>稳定条件<ul>
<li>特征方程 $|A - \lambda I| = 0$ 根全在单位圆内</li>
<li>相反的特征方程 $|I - LA| = 0$ 根全在单位圆外</li>
</ul>
</li>
</ul>
<h2 id="VEC-模型"><a href="#VEC-模型" class="headerlink" title="VEC 模型"></a><em>VEC</em> 模型</h2><h3 id="N-变量-VEC-k"><a href="#N-变量-VEC-k" class="headerlink" title="N 变量 VEC(k)"></a><em>N</em> 变量 <em>VEC(k)</em></h3><script type="math/tex; mode=display">\begin{align*}
\Delta Y_t & = y_{t-1} + \Pi Y_{t-1} + \Gamma_1 \Delta Y_{t-2}
    + \cdots + \Gamma_{k-1} \Delta Y_{t-p+1} + U_t + \Phi Z_t
\end{align*}</script><blockquote>
<ul>
<li>$\Pi = \sum_{i=1}^k \Pi_i - I$：影响矩阵</li>
<li>$\Gamma<em>i = -\sum</em>{j=i+1}^k$</li>
</ul>
</blockquote>
<h3 id="VEC-1"><a href="#VEC-1" class="headerlink" title="VEC(1)"></a>VEC(1)</h3><script type="math/tex; mode=display">\begin{align*}
\Delta Y_{t} & = \Pi Y_{t-1} + \Gamma \Delta Y_{t-1} \\
    & = \alpha \beta^{'} Y_{t-1} + \Gamma \Delta Y_{t-1} \\
    & = \alpha ECM_{t-1} + \Gamma \Delta Y_{t-1}
\end{align*}</script><h2 id="Impulse-Response-Function"><a href="#Impulse-Response-Function" class="headerlink" title="Impulse-Response Function"></a><em>Impulse-Response Function</em></h2><p>脉冲响应函数：描述内生变量对误差冲击的反应</p>
<ul>
<li><p>脉冲响应函数含义</p>
<ul>
<li>在随机误差下上施加标准查大小的冲击后，对内生变量当期值和未来值所带来的影响</li>
<li>即将 <em>VAR</em> 模型表示为无限阶的向量 $MA(\infty)$ 过程</li>
</ul>
</li>
<li><p>对脉冲响应函数的解释的困难源于，实际中各方程对应误差项不是完全非相关</p>
<ul>
<li>误差相关时，其有一个共同组成部分，不能被任何特定变量识别</li>
<li>故，左乘变换矩阵 $M$ 得到 $V_t =  MU_t$ 修正相关性（常用 <em>Cholesky</em> 分解求解）<ul>
<li>即将其协方差矩阵变换为对角矩阵 $V_t = MU_t \sim (0, \Omega)$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="VAR-1-转换为-MA"><a href="#VAR-1-转换为-MA" class="headerlink" title="VAR(1) 转换为 MA"></a><em>VAR(1)</em> 转换为 <em>MA</em></h3><script type="math/tex; mode=display">
\begin{align*}
Y_t & = AY_{t-1} + U_t \\
(I - LA)Y_t & = U_t \\
Y_t & = (I-LA)^{-1} U_t \\
    & = U_t + AU_{t-1} + A^2U_{t-2} + \cdots + A^sU_t + \cdots\\
Y_{t+s} & = U_{t+s} + \Psi_1U_{t+s-1} + \Psi_2U_{t+s-2}
    + \cdots + \Psi_sU_t + \cdots
\end{align*}</script><blockquote>
<ul>
<li>$\Psi<em>s = A^s = \frac {\partial Y</em>{t+s}} {\partial U_t}$</li>
<li>$\Psi<em>s[i, j] = \frac {\partial y</em>{i,t+s}} {\partial u<em>{j,t}}$：脉冲响应函数，表示其他误差项在任何时期都不变条件下，第 $j$ 个变量 $y</em>{j,t}$ 在对应误差项 $u<em>{j,t}$ 在 $t$ 期受到一个单位冲击后，对第 $i$ 个内生变量 $y</em>{i,t}$ 在 $t+s$ 期造成的影响</li>
</ul>
</blockquote>
<h2 id="方差分解"><a href="#方差分解" class="headerlink" title="方差分解"></a>方差分解</h2><p>方差分解：分析未来 $t+s$ 期 $y_{j, t+s}$ 的预测误差受不同新息冲击影响比例</p>
<h3 id="均方误差"><a href="#均方误差" class="headerlink" title="均方误差"></a>均方误差</h3><ul>
<li><p>误差可以写为 <em>MA</em> 形式</p>
<script type="math/tex; mode=display">
Y_{t+s} - \hat Y_{t+s|t} = U_{t+s} + \Psi_1U_{t+s-1} +
   \Psi_2U_{t+s-2} + \cdots + \Psi_{s-1}U_{t+1}</script></li>
<li><p>则预测s期的均方误差为</p>
<script type="math/tex; mode=display">\begin{align*}
MSE(\hat Y_{t+s|t}) & = E[(Y_{t+s} - \hat Y_{t+s|t})
   (Y_{t+s} - \hat Y_{t+s|t})^T] \\
& = \Omega + \Psi_1\Omega\Psi_1^T + \cdots +
   \Psi_{s-1}\Omega\Psi_{s-1}^T
\end{align*}</script></li>
</ul>
<blockquote>
<ul>
<li>$\Omega = E(U_tU_t^T)$：不同期 $U_t$ 协方差阵为 0</li>
</ul>
</blockquote>
<h3 id="计算比例"><a href="#计算比例" class="headerlink" title="计算比例"></a>计算比例</h3><script type="math/tex; mode=display">\begin{align*}
U_t &=  MV_t  \\
    &= m_1v_{1,t} + m_2v_{2,t} + \cdots + m_Nv_{N,t} \\
\Omega & = E(U_t, U_t^T) \\
    & = (MV_t)(MV_t)^T \\
    & = m_1m_1^TVar(v_{1,t} + \cdots + m_Nm_N^TVar(v_{N,t})
\end{align*}</script><blockquote>
<ul>
<li>$v<em>{1,t}, v</em>{2,t}, \cdots, v_{N,t}$不相关</li>
</ul>
</blockquote>
<ul>
<li>将 $\Omega$ 带入 <em>MSE</em> 表达式中，既可以得到第 $j$ 个新息对 $s$ 期预测量 $\hat Y_{t+s|t}$ 的方差贡献比例</li>
</ul>
<h2 id="VAR-建模"><a href="#VAR-建模" class="headerlink" title="VAR 建模"></a><em>VAR</em> 建模</h2><p><img src="/imgs/var_procedure.png" alt="var_procedure"></p>
<ul>
<li><p>进行单变量平稳性检验</p>
</li>
<li><p>拟合 <em>VAR(p)</em> 模型</p>
<ul>
<li>确定模型阶数<ul>
<li>理论上初步模型阶数可以任意确定</li>
<li>然后根据 <em>AIC</em>、<em>BIC</em>、对数似然函数值选择相对最优阶数</li>
</ul>
</li>
</ul>
</li>
<li><p>若所有变量平稳，则 <em>Granger</em> 因果检验</p>
<ul>
<li><em>VAR</em> 模型通过平稳性检验，理论上就可以利用模型进行分析、预测</li>
<li>但 <em>VAR</em> 模型是超系数模型，默认所有内生变量互为因果<ul>
<li>但实际上变量之间因果关系复杂</li>
<li>可通过 <em>Granger</em> 因果检验判断变量之间长期、短期因果关系</li>
</ul>
</li>
</ul>
</li>
<li><p>若有变量非平稳</p>
<ul>
<li>检验模型平稳性</li>
<li><em>Granger</em> 因果检验</li>
<li>协整检验：<em>JJ</em> 检验<ul>
<li>非平稳系统必然存在协整关系，具有经济学意义</li>
<li>所以需要找出存在的基础协整关系，解读其代表的长期、短期相关影响</li>
</ul>
</li>
<li>构建 <em>VEC</em> 模型<ul>
<li>如果协整检验显示基本协整关系满秩，说明系统中每个序列都是平稳序列，直接建立VAR模型</li>
<li>如果协整检验限制基本协整关系为 0 秩，则系统不存在协整关系，通常说明系统不平稳，需要重新选择变量， 或者适当差分后建模</li>
<li>最常见情况是协整检验显示基本协整关系数量处于 0 至满秩中间，此时建立 $VEC$ 模型</li>
</ul>
</li>
</ul>
</li>
<li><p>脉冲响应分析</p>
</li>
<li><p>方差分析</p>
</li>
<li><p>模型预测</p>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/tags/Statistics/page/0/">Previous</a></div><div class="pagination-next"><a href="/tags/Statistics/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/tags/Statistics/">1</a></li><li><a class="pagination-link" href="/tags/Statistics/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5385776267343559" data-ad-slot="6995841235" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>