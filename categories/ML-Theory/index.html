<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: ML Theory - UBeaRLy</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="UBeaRLy"><meta property="og:url" content="https://xyy15926.github.io/"><meta property="og:site_name" content="UBeaRLy"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:author" content="UBeaRLy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io"},"headline":"UBeaRLy","image":["https://xyy15926.github.io/img/og_image.png"],"author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"UBeaRLy","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":""}</script><link rel="alternate" href="/atom.xml" title="UBeaRLy" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="follow_it-verification-code" content="SVBypAPPHxjjr7Y4hHfn"><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">ML Theory</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-08-29T10:12:36.000Z" title="8/29/2019, 6:12:36 PM">2019-08-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-08-29T10:12:43.000Z" title="8/29/2019, 6:12:43 PM">2019-08-29</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Model-Enhencement/">Model Enhencement</a></span><span class="level-item">a few seconds read (About 1 word)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Model-Enhencement/lightgbm.html">LightGBM</a></h1><div class="content"><h2 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-08-25T13:53:20.000Z" title="8/25/2019, 9:53:20 PM">2019-08-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T09:40:21.000Z" title="8/4/2021, 5:40:21 PM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Loss/">Loss</a></span><span class="level-item">21 minutes read (About 3154 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Loss/loss_thoery.html">损失函数理论</a></h1><div class="content"><h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><ul>
<li><p>矩估计：<strong>建立参数和总体矩的关系</strong>，求解参数</p>
<ul>
<li>除非参数本身即为样本矩，否则基本无应用价值</li>
<li>应用场合<ul>
<li>均值：对应二次损失 $\arg\min<em>{\mu} \sum</em>{i=1}^N (x_i - \mu)^2$</li>
<li>方差：对应二次损失?</li>
</ul>
</li>
</ul>
</li>
<li><p>极大似然估计：极大化似然函数，求解概率上最合理参数</p>
<ul>
<li>需知道（假设）总体 <strong>概率分布形式</strong></li>
<li>似然函数形式复杂，求解困难<ul>
<li>往往无法直接给出参数的解析解，只能求数值解</li>
</ul>
</li>
<li>应用场合<ul>
<li>估计回归参数：对数损失
$\mathop{\arg\min}<em>{\beta} \sum</em>{i=1}^N lnP(y_i|x_i, \beta)$</li>
</ul>
</li>
</ul>
</li>
<li><p>损失函数估计：极小化损失函数，求解损失最小的参数</p>
<ul>
<li>最泛用的参数求解方法<ul>
<li>适合求解有大量参数的待求解的问题</li>
<li>往往通过迭代方式逐步求解</li>
</ul>
</li>
<li>特别的<ul>
<li>线性回归使用 <em>MSE</em> 作为损失函数时，也被称为最小二乘估计</li>
<li>极大似然估计同对数损失函数</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>参数估计都可以找到合适损失函数，通过迭代求解损失最小化</li>
</ul>
</blockquote>
<h3 id="随机模拟估计参数"><a href="#随机模拟估计参数" class="headerlink" title="随机模拟估计参数"></a>随机模拟估计参数</h3><ul>
<li>需要<strong>设计随机模拟实验</strong>估计参数</li>
<li>应用场合<ul>
<li>蒙特卡洛类似算法：随机化损失</li>
</ul>
</li>
</ul>
<h3 id="迭代求解参数"><a href="#迭代求解参数" class="headerlink" title="迭代求解参数"></a>迭代求解参数</h3><ul>
<li><p>损失函数定义不同</p>
<ul>
<li>包含样本量数量不同</li>
<li>惩罚项设置不同</li>
</ul>
</li>
<li><p>异步更新参数</p>
<ul>
<li>同时求解参数数量：全部、部分、单个</li>
<li>参数升维</li>
</ul>
</li>
<li><p>更新方向</p>
<ul>
<li>梯度</li>
<li>海瑟矩阵</li>
<li>次梯度</li>
</ul>
</li>
<li><p>更新方式</p>
<ul>
<li>叠加惯性</li>
<li>动态学习率</li>
</ul>
</li>
</ul>
<h2 id="Loss-Models"><a href="#Loss-Models" class="headerlink" title="Loss Models"></a><em>Loss Models</em></h2><p>模型（目标函数）在样本整体的损失：度量模型整体预测效果</p>
<ul>
<li>代表模型在整体上的性质，有不同的设计形式</li>
<li><p>可以用于 <strong>设计学习策略、评价模型</strong></p>
<ul>
<li>风险函数</li>
<li>评价函数</li>
</ul>
</li>
<li><p>有时在算法中也会使用整体损失</p>
</li>
</ul>
<h3 id="Expected-Risk-Expected-Loss-Generalization-Loss"><a href="#Expected-Risk-Expected-Loss-Generalization-Loss" class="headerlink" title="Expected Risk / Expected Loss / Generalization Loss"></a><em>Expected Risk</em> / <em>Expected Loss</em> / <em>Generalization Loss</em></h3><p>期望风险（函数）：损失函数 $L(Y, f(X))$（随机变量）期望</p>
<script type="math/tex; mode=display">
R_{exp}(f) = E_p[L(Y, f(X))] = \int_{x*y} L(y,f(x))P(x,y) dxdy</script><blockquote>
<ul>
<li>$P(X, Y)$：随机变量 $(X, Y)$ 遵循的联合分布，未知</li>
</ul>
</blockquote>
<ul>
<li><p>风险函数值度量模型预测错误程度</p>
<ul>
<li>反映了学习方法的泛化能力</li>
<li>评价标准（<strong>监督学习目标</strong>）就应该是选择期望风险最小</li>
</ul>
</li>
<li><p>联合分布未知，所以才需要学习，否则可以直接计算条件分布概率，而计算期望损失需要知道联合分布，因此监督学习是一个病态问题</p>
</li>
</ul>
<h3 id="Empirical-Risk-Empirical-Loss"><a href="#Empirical-Risk-Empirical-Loss" class="headerlink" title="Empirical Risk / Empirical Loss"></a><em>Empirical Risk</em> / <em>Empirical Loss</em></h3><p>经验风险：模型关于给定训练数据集的平均损失</p>
<script type="math/tex; mode=display">\begin{align*}
R_{emp}(f) & = \sum_{i=1}^N D_i L(y_i, f(x_i;\theta)) \\
E(R_{emp}(f)) & = R_{exp}(f)
\end{align*}</script><blockquote>
<ul>
<li>$\theta$：模型参数</li>
<li>$D_i$：样本损失权重，常为 $\frac 1 N$，在 <em>Boosting</em> 框架中不同</li>
</ul>
</blockquote>
<ul>
<li><p>经验风险损失是模型 $f(x)$ 的函数</p>
<ul>
<li>训练时，模型是模型参数的函数</li>
<li>即其为模型参数函数</li>
</ul>
</li>
<li><p>根据大数定律，样本量容量 $N$ 趋于无穷时，$R<em>{emp}(f)$ 趋于 $R</em>{exp}(f)$</p>
<ul>
<li>但是现实中训练样本数目有限、很小</li>
<li>利用经验风险估计期望常常并不理想，需要对经验风险进行矫正</li>
</ul>
</li>
<li><p>例子</p>
<ul>
<li><em>maximum probability estimation</em>：极大似然估计<ul>
<li>模型：条件概率分布（贝叶斯生成模型、逻辑回归）</li>
<li>损失函数：对数损失函数</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Structual-Risk-Structual-Loss"><a href="#Structual-Risk-Structual-Loss" class="headerlink" title="Structual Risk / Structual Loss"></a><em>Structual Risk</em> / <em>Structual Loss</em></h3><p>结构风险：在经验风险上加上表示 <strong>模型复杂度</strong> 的 <em>regularizer</em>（<em>penalty term</em>）</p>
<script type="math/tex; mode=display">
R_{srm} = \frac 1 N \sum_{i=1}^N L(y_i, f(x_i)) +
    \lambda J(f)</script><blockquote>
<ul>
<li>$J(f)$：模型复杂度，定义在假设空间$F$上的泛函</li>
<li>$\lambda$：权衡经验风险、模型复杂度的系数</li>
</ul>
</blockquote>
<ul>
<li>结构风险最小化<ul>
<li>添加 <em>regularization</em>（正则化），调节损失函数（目标函数）</li>
</ul>
</li>
<li>模型复杂度 $J(f)$ 表示对复杂模型的惩罚：模型 $f$ 越复杂，复杂项 $J(f)$ 越大</li>
<li>案例<ul>
<li><em>maximum posterior probability estimation</em>：最大后验概率估计<ul>
<li>损失函数：对数损失函数</li>
<li>模型复杂度：模型先验概率对数后取负</li>
<li>先验概率对应模型复杂度，先验概率越小，复杂度越大</li>
</ul>
</li>
<li>岭回归：平方损失 + $L<em>2$ 正则化
$\mathop{\arg\min}</em>{\beta} \sum_{i=1}^N (y_i - f(x_i, \beta))^2 + |\beta|$</li>
<li><em>LASSO</em>：平方损失 + $L<em>1$ 正则化
$\mathop{\arg\min}</em>{\beta} \sum_{i=1}^N (y_i - f(x_i, \beta))^2 + |\beta|_1$</li>
</ul>
</li>
</ul>
<h2 id="Generalization-Ability"><a href="#Generalization-Ability" class="headerlink" title="Generalization Ability"></a><em>Generalization Ability</em></h2><p>泛化能力：方法学习到的模型对未知数据的预测能力，是学习方法本质、重要的性质</p>
<ul>
<li>测试误差衡量学习方法的泛化能力不可靠，其依赖于测试集，而测试集有限</li>
<li>学习方法的泛化能力往往是通过研究泛化误差的概率上界进行</li>
</ul>
<h3 id="Generalization-Error-Bound"><a href="#Generalization-Error-Bound" class="headerlink" title="Generalization Error Bound"></a>Generalization Error Bound</h3><p>泛化误差上界：泛化误差的 <strong>概率</strong> 上界</p>
<ul>
<li>是样本容量函数，样本容量增加时，泛化上界趋于 0</li>
<li>是假设空间容量函数，假设空间容量越大，模型越难学习，泛化误差上界越大</li>
</ul>
<h4 id="泛化误差"><a href="#泛化误差" class="headerlink" title="泛化误差"></a>泛化误差</h4><ul>
<li><p>根据 <em>Hoeffding</em> 不等式，泛化误差满足</p>
<script type="math/tex; mode=display">\begin{align*}
& \forall h \in H, & P(|E(h) - \hat E(h)| \geq \epsilon) \leq 2 e^{-2 N \epsilon^2} \\
\Rightarrow & \forall h \in H, & P(|E(h) - \hat E(h)|
   \leq \epsilon) \geq 1 - 2|H|e^{-2N\epsilon^2}
\end{align*}</script><blockquote>
<ul>
<li>$H$：假设空间</li>
<li>$N$：样本数量</li>
<li>$E(h) := R_{exp}(h)$</li>
<li>$\hat E(h) := R_{emp}(h)$</li>
</ul>
</blockquote>
</li>
<li><p>证明如下：</p>
<script type="math/tex; mode=display">\begin{align*}
P(\forall h \in H: |E(h) - \hat E(h)| \leq \epsilon|)
   & = 1 - P(\exists h \in H: |E(h) - \hat E(h)|
   \geq \epsilon) \\
& = 1 - P((|E(h_1) - \hat E(h_1) \geq \epsilon) \vee \cdots
   \vee (|E(h_{|H|}) - \hat E_{|H|}| \geq \epsilon)) \\
& \geq 1 - \sum_{i=1}^{|H|} P(|E(h_i) - \hat E(h_i)|
   \geq \epsilon) \\
& \geq 1 - 2|H|e^{-2N \epsilon^2}
\end{align*}</script></li>
<li><p>对任意 $\epsilon$，随样本数量 $m$ 增大， $|E(h) - \hat E(h)| \leq \epsilon$ 概率增大，可以使用经验误差近似泛化误差</p>
</li>
</ul>
<h4 id="二分类泛化误差上界"><a href="#二分类泛化误差上界" class="headerlink" title="二分类泛化误差上界"></a>二分类泛化误差上界</h4><ul>
<li><p>由 <em>Hoeffding</em> 不等式</p>
<script type="math/tex; mode=display">\begin{align*}
P(E(h) - \hat E(h) & \geq \epsilon) \leq exp(-2N\epsilon^2) \\
P(\exists h \in H: E(h) - \hat E(h) \geq \epsilon) & =
   P(\bigcup_{h \in H} \{ E(h) - \hat E(h) \geq \epsilon \}) \\
& \leq \sum_{h \in H} P(E(h) - \hat E(h) \geq \epsilon) \\
& \leq |H| exp(-2 N \epsilon^2)
\end{align*}</script></li>
<li><p>则 $\forall h \in H$，有</p>
<script type="math/tex; mode=display">
P(E(h) - \hat E(h) < \epsilon) \geq 1 - |H| exp(-2 N \epsilon)</script><p>则令 $\sigma = |H| exp(-2N\epsilon^2)$，则至少以概率 $1-\sigma$ 满足如下，即得到泛化误差上界</p>
<script type="math/tex; mode=display">\begin{align*}
E(h)  & \leq \hat E(h) + \epsilon(|H|, N, \sigma) \\
\epsilon(|H|, N, \sigma) & = \sqrt
   {\frac 1 {2N} (log |H| + log \frac 1 {\sigma})}
\end{align*}</script></li>
</ul>
<h3 id="Probably-Approximate-Correct-可学习"><a href="#Probably-Approximate-Correct-可学习" class="headerlink" title="Probably Approximate Correct 可学习"></a><em>Probably Approximate Correct</em> 可学习</h3><p><em>PAC</em> 可学习：在短时间内利用少量（多项式级别）样本能够找到假设 $h^{‘}$，满足</p>
<script type="math/tex; mode=display">
P(E(h^{'}) \leq \epsilon) \geq 1 - \sigma, 0 < \epsilon, \sigma < 1</script><ul>
<li><p>即需要假设满足两个 <em>PAC</em> 辨识条件</p>
<ul>
<li>近似条件：泛化误差 $E(h^{‘})$ 足够小</li>
<li>可能正确：满足近似条件概率足够大</li>
</ul>
</li>
<li><p>同等条件下</p>
<ul>
<li>模型越复杂，泛化误差越大</li>
<li>满足条件的样本数量越大，模型泛化误差越小</li>
</ul>
</li>
<li><p><em>PAC</em> 学习理论关心能否从假设空间 $H$ 中学习到好的假设 $h$</p>
<ul>
<li>由以上泛化误差可得，取 $\sigma = 2|H|e^{-2N\epsilon^2}$，则样本量满足 $N = \frac {ln \frac {2|H|} \sigma} {2 \epsilon^2}$ 时，模型是 <em>PAC</em> 可学习的</li>
</ul>
</li>
</ul>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a><em>Regularization</em></h2><p>正则化：（向目标函数）添加额外信息以求解病态问题、避免过拟合</p>
<ul>
<li><p>常应用在机器学习、逆问题求解</p>
<ul>
<li>对模型（目标函数）复杂度惩罚</li>
<li>提高学习模型的泛化能力、避免过拟合</li>
<li>学习简单模型：稀疏模型、引入组结构</li>
</ul>
</li>
<li><p>有多种用途</p>
<ul>
<li>最小二乘也可以看作是简单的正则化</li>
<li>岭回归中的 $\mathcal{l_2}$ 范数</li>
</ul>
</li>
</ul>
<h3 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h3><p>模型复杂度：经常作为正则化项添加作为额外信息添加的，衡量模型复杂度方式有很多种</p>
<ul>
<li><p>函数光滑限制</p>
<ul>
<li>多项式最高次数</li>
</ul>
</li>
<li><p>向量空间范数</p>
<ul>
<li>$\mathcal{L_0} - norm$：参数个数</li>
<li>$\mathcal{L_1} - norm$：参数绝对值和</li>
<li>$\mathcal{L_2}$- norm$：参数平方和</li>
</ul>
</li>
</ul>
<h3 id="mathcal-L-0-norm"><a href="#mathcal-L-0-norm" class="headerlink" title="$\mathcal{L_0} - norm$"></a>$\mathcal{L_0} - norm$</h3><ul>
<li>$\mathcal{l_0} - norm$ 特点<ul>
<li>稀疏化约束</li>
<li>解 $\mathcal{L_0}$ 范数正则化是 <em>NP-hard</em> 问题</li>
</ul>
</li>
</ul>
<h3 id="mathcal-L-1-norm"><a href="#mathcal-L-1-norm" class="headerlink" title="$\mathcal{L_1} - norm$"></a>$\mathcal{L_1} - norm$</h3><ul>
<li><p>$\mathcal{L_1} - norm$ 特点</p>
<ul>
<li>$\mathcal{L_1}$ 范数可以通过凸松弛得到 $\mathcal{L_0}$ 的近似解</li>
<li>有时候出现解不唯一的情况</li>
<li>$\mathcal{L_1}$ 范数凸但不严格可导，可以使用依赖次梯度的方法求解极小化问题</li>
</ul>
</li>
<li><p>应用</p>
<ul>
<li><em>LASSO</em></li>
</ul>
</li>
<li><p>求解</p>
<ul>
<li><em>Proximal Method</em></li>
<li><em>LARS</em></li>
</ul>
</li>
</ul>
<h3 id="mathcal-L-2-norm"><a href="#mathcal-L-2-norm" class="headerlink" title="$\mathcal{L_2} - norm$"></a>$\mathcal{L_2} - norm$</h3><ul>
<li>$\mathcal{L_2} - norm$ 特点<ul>
<li>凸且严格可导，极小化问题有解析解</li>
</ul>
</li>
</ul>
<h3 id="mathcal-L-1-L-2"><a href="#mathcal-L-1-L-2" class="headerlink" title="$\mathcal{L_1 + L_2}$"></a>$\mathcal{L_1 + L_2}$</h3><ul>
<li><p>$\mathcal{L_1 + L_2}$ 特点</p>
<ul>
<li>有组效应，相关变量权重倾向于相同</li>
</ul>
</li>
<li><p>应用</p>
<ul>
<li><em>Elastic Net</em></li>
</ul>
</li>
</ul>
<h3 id="稀疏解产生"><a href="#稀疏解产生" class="headerlink" title="稀疏解产生"></a>稀疏解产生</h3><p>稀疏解：待估参数系数在某些分量上为 0</p>
<h4 id="mathcal-L-1-norm-稀疏解的产生"><a href="#mathcal-L-1-norm-稀疏解的产生" class="headerlink" title="$\mathcal{L_1} - norm$ 稀疏解的产生"></a>$\mathcal{L_1} - norm$ 稀疏解的产生</h4><blockquote>
<ul>
<li>$\mathcal{L_1}$ 范数在参数满足 <strong>一定条件</strong> 情况下，能对 <strong>平方损失</strong> 产生稀疏效果</li>
</ul>
</blockquote>
<ul>
<li><p>在 $[-1,1]$ 内 $y=|x|$ 导数大于 $y=x^2$（除 0 点）</p>
<ul>
<li>则特征在 0 点附近内变动时，为了取到极小值，参数必须始终为 0</li>
<li>高阶项在 0 点附近增加速度较慢，所以 $\mathcal{L_1} - norm$ 能产生稀疏解是很广泛的</li>
<li>$mathcal{L_1} - norm$ 前系数（权重）越大，能够容许高阶项增加的幅度越大，即压缩能力越强</li>
</ul>
</li>
<li><p>在 0 附近导数 “不小”，即导数在 0 点非 0</p>
<ul>
<li>对多项式正则化项<ul>
<li>$\mathcal{L_1} - norm$ 项对稀疏化解起决定性作用</li>
<li>其他项对稀疏解无帮助</li>
</ul>
</li>
<li>对“非多项式”正则化项<ul>
<li>$e^{|x|}-1$、$ln(|x|+1)$ 等在0点泰勒展开同样得到 $\mathcal{L_1} - norm$ 项</li>
<li>但是此类正则化项难以计算数值，不常用</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="mathcal-L-1-norm-稀疏解推广"><a href="#mathcal-L-1-norm-稀疏解推广" class="headerlink" title="$\mathcal{L_1} - norm$ 稀疏解推广"></a>$\mathcal{L_1} - norm$ 稀疏解推广</h4><ul>
<li><p>正负差异化：在正负设置权重不同的 $\mathcal{L_1}$，赋予在正负不同的压缩能力，甚至某侧完全不压缩</p>
</li>
<li><p>分段函数压缩：即只要保证在 0 点附近包含 $\mathcal{L_1}$ 用于产生稀疏解，远离 0 处可以设计为常数等不影响精确解的值</p>
<ul>
<li><p><em>Smoothly Clipped Absolute Deviation</em></p>
<script type="math/tex; mode=display">
R(x|\lambda, \gamma) = \left \{ \begin{array} {l}
  \lambda|x| \qquad & if |x| \leq \lambda \\
  \frac {2\gamma\lambda|x| - x^2 - {\lambda}^2 }
      {2(\gamma - 1)} &
      if \gamma< |x| <\gamma\lambda \\
  \frac { {\lambda}^2(\gamma+1)} 2 &
      if |x| \geq \gamma\lambda
\end{array} \right.</script></li>
<li><p><em>Derivate of SCAD</em></p>
<script type="math/tex; mode=display">
R(x; \lambda, \gamma) = \left \{ \begin{array} {l}
  \lambda \qquad & if |x| \leq \gamma \\
  \frac {\gamma\lambda - |x|} {\gamma - 1} &
      if \lambda < |x| < \gamma\lambda \\
  0 & if |x| \geq \gamma\lambda
\end{array} \right.</script></li>
<li><p><em>Minimax Concave Penalty</em></p>
<script type="math/tex; mode=display">
R_{\gamma}(x;\lambda) = \left \{ \begin{array} {l}
  \lambda|x| - \frac {x^2} {2\gamma} \qquad &
      if |x| \leq \gamma\lambda \\
  \frac 1 2 \gamma{\lambda}^2 &
      if |x| > \gamma\lambda
\end{array} \right.</script></li>
</ul>
</li>
<li><p>分指标：对不同指标动态设置 $\mathcal{L_0}$ 系数</p>
<ul>
<li><em>Adaptive Lasso</em>：$\lambda \sum_J w_jx_j$</li>
</ul>
</li>
</ul>
<h4 id="稀疏本质"><a href="#稀疏本质" class="headerlink" title="稀疏本质"></a>稀疏本质</h4><p>稀疏本质：极值、<strong>不光滑</strong>，即导数符号突然变化</p>
<ul>
<li><p>若某约束项导数符号突然变化、其余项在该点处导数为 0，为保证仍然取得极小值，解会聚集（极小）、疏远（极大）该点（类似坡的陡峭程度）</p>
<ul>
<li>即此类不光滑点会<strong>抑制解的变化</strong>，不光滑程度即导数变化幅度越大，抑制解变化能力越强，即吸引、排斥解能力越强</li>
<li>容易构造压缩至任意点的约束项</li>
<li>特殊的，不光滑点为 0 时，即得到稀疏解</li>
</ul>
</li>
<li><p>可以设置的多个极小不光滑点，使得解都在不连续集合中</p>
<ul>
<li>可以使用三角函数、锯齿函数等构造，但此类约束项要起效果，必然会使得目标函数非凸<ul>
<li>但是多变量场合，每个变量实际解只会在某个候选解附近，其邻域内仍然是凸的</li>
<li>且锯齿函数这样的突变非凸可能和凸函数具有相当的优秀性质</li>
</ul>
</li>
<li>当这些点均为整数时，这似乎可以近似求解 <strong>整数规划</strong></li>
</ul>
</li>
</ul>
<h2 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a><em>Early Stopping</em></h2><p><em>Early Stopping</em>：提前终止（训练）</p>
<ul>
<li><em>Early Stopping</em> 也可以被视为是 <em>regularizing on time</em><ul>
<li>迭代式训练随着迭代次数增加，往往会有学习复杂模型的倾向</li>
<li>对时间施加正则化，可以减小模型复杂度、提高泛化能力</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-08-02T15:17:39.000Z" title="8/2/2019, 11:17:39 PM">2019-08-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T08:41:29.000Z" title="8/4/2021, 4:41:29 PM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Loss/">Loss</a></span><span class="level-item">9 minutes read (About 1280 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Loss/model_evaluation.html">模型评估</a></h1><div class="content"><h2 id="评估方向"><a href="#评估方向" class="headerlink" title="评估方向"></a>评估方向</h2><h3 id="模型误差"><a href="#模型误差" class="headerlink" title="模型误差"></a>模型误差</h3><blockquote>
<ul>
<li>给定损失函数时，基于损失函数的误差显然评估学习方法的标准</li>
</ul>
</blockquote>
<ul>
<li>回归预测模型：模型误差主要使用 <em>MSE</em></li>
<li>分类预测模型：模型误差主要是分类错误率 <em>ERR=1-ACC</em></li>
</ul>
<blockquote>
<ul>
<li>模型训练时采用损失函数不一定是评估时使用的</li>
</ul>
</blockquote>
<h4 id="Training-Error"><a href="#Training-Error" class="headerlink" title="Training Error"></a><em>Training Error</em></h4><p>训练误差：模型在训练集上的误差，损失函数 $L(Y, F(X))$ 均值</p>
<script type="math/tex; mode=display">
e_{train} = R_{emp}(\hat f) = \frac 1 N \sum_{i=1}^N
    L(y_i, \hat {f(x_i)})</script><blockquote>
<ul>
<li>$\hat f$：学习到的模型</li>
<li>$N$：训练样本容量</li>
</ul>
</blockquote>
<ul>
<li>训练时采用的损失函数和评估时一致时，训练误差等于经验风险</li>
<li>训练误差对盘对给定问题是否容易学习是有意义的，但是本质上不重要<ul>
<li>模型训练本身就以最小化训练误差为标准，如：最小化 <em>MSE</em>、最大化预测准确率，一般偏低，不能作为模型预测误差的估计</li>
<li>训练误差随模型复杂度增加单调下降（不考虑模型中随机因素）</li>
</ul>
</li>
</ul>
<h4 id="Test-Error"><a href="#Test-Error" class="headerlink" title="Test Error"></a><em>Test Error</em></h4><p>测试误差：模型在测试集上的误差，损失函数 $L(Y, f(X))$ 均值</p>
<script type="math/tex; mode=display">
e_{test} = \frac 1 {N^{'}} \sum_{i=1}^{N^{'}}
    L(y_i,\hat {f(x_i)})</script><blockquote>
<ul>
<li>$\hat f$：学习到的模型</li>
<li>$N$：测试样本容量</li>
</ul>
</blockquote>
<ul>
<li><p>测试误差反映了学习方法对未知测试数据集的预测能力，是模型 <em>generalization ability</em> 的度量，可以作为模型误差估计</p>
</li>
<li><p>测试误差随模型复杂度增加呈U型</p>
<ul>
<li>偏差降低程度大于方差增加程度，测试误差降低</li>
<li>偏差降低程度小于方差增加程度，测试误差增大</li>
</ul>
</li>
<li>训练误差小但测试误差大表明模型过拟合，使测试误差最小的模型为理想模型</li>
</ul>
<h3 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h3><blockquote>
<ul>
<li><em>approximation error</em>：近似误差，模型偏差，代表模型对训练集的拟合程度</li>
<li><em>estimation error</em>：估计误差，模型方差，代表模型对训练集波动的稳健性</li>
</ul>
</blockquote>
<ul>
<li><p>模型复杂度越高</p>
<ul>
<li>低偏差：对训练集的拟合充分</li>
<li>高方差：模型紧跟特定数据点，受其影响较大，预测结果不稳定</li>
<li>远离真实关系，模型在来自同系统中其他尚未观测的数据集上预测误差大</li>
</ul>
</li>
<li><p>而训练集、测试集往往不完全相同</p>
<ul>
<li>复杂度较高的模型（过拟合）在测试集上往往由于其高方差效果不好，而建立模型最终目的是用于预测未知数据</li>
<li>所以要兼顾偏差和方差，通过不同建模策略，找到恰当模型，其复杂度不太大且误差在可接受的水平</li>
<li>使得模型更贴近真实关系，泛化能力较好</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>简单模型：低方差高偏差</li>
<li><p>复杂模型：低偏差高方差</p>
</li>
<li><p>模型复杂度衡量参<em>data_science/loss</em></p>
</li>
</ul>
</blockquote>
<h4 id="Over-Fitting"><a href="#Over-Fitting" class="headerlink" title="Over-Fitting"></a><em>Over-Fitting</em></h4><p>过拟合：学习时选择的所包含的模型复杂度大（参数过多），导致模型对已知数据预测很好，对未知数据预测效果很差</p>
<ul>
<li>若在假设空间中存在“真模型”，则选择的模型应该逼近真模型（参数个数相近）</li>
<li>一味追求对训练集的预测能力，复杂度往往会比“真模型”更高</li>
</ul>
<h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><ul>
<li>减少预测变量数量<ul>
<li>最优子集回归：选择合适评价函数（带罚）选择最优模型</li>
<li>验证集挑选模型：将训练集使用 <em>抽样技术</em> 分出部分作为 <em>validation set</em>，使用额外验证集挑选使得损失最小的模型</li>
<li>正则化（罚、结构化风险最小策略）<ul>
<li>岭回归：平方损失，$L_2$ 范数</li>
<li><em>LASSO</em>：绝对值损失，$L_1$ 范数</li>
<li><em>Elastic Net</em></li>
</ul>
</li>
</ul>
</li>
<li>减弱变量特化程度：仅适合迭代求参数的方法<ul>
<li><em>EarlyStop</em>：提前终止模型训练</li>
<li><em>Dropout</em>：每次训练部分神经元</li>
</ul>
</li>
</ul>
<h3 id="模型信息来源"><a href="#模型信息来源" class="headerlink" title="模型信息来源"></a>模型信息来源</h3><ul>
<li>训练数据包含信息</li>
<li>模型形成过程中提供的先验信息<ul>
<li>模型：采用特定内在结构（如深度学习不同网络结构）、条件假设、其他约束条件（正则项）</li>
<li>数据：调整、变换、扩展训练数据，让其展现更多、更有用的信息</li>
</ul>
</li>
</ul>
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><ul>
<li><p><em>Classification</em> 分类问题：输出变量$Y$为有限个离散变量</p>
<ul>
<li>混淆矩阵<ul>
<li><em>F-Measure</em></li>
<li><em>TPR</em>、<em>FPR</em></li>
</ul>
</li>
<li><em>ROC</em></li>
<li><em>AUC</em></li>
</ul>
</li>
<li><p><em>Tagging</em> 标注问题：输入 $X^{(1)}, X^{(2)}, \cdots, X^{(n)}$、输出 $Y^{(1)}, Y^{(2)}, \cdots, Y^{(n)}$ <strong>均为变量序列</strong></p>
<ul>
<li>类似分类问题</li>
</ul>
</li>
<li><p><em>Regression</em> 回归问题</p>
<ul>
<li><em>Squared Error</em><ul>
<li><em>MSE</em></li>
<li>$R^2$、$R^2_{Adj}$</li>
<li><em>AIC</em></li>
<li><em>BIC</em></li>
</ul>
</li>
<li><em>Absolute Error</em><ul>
<li><em>MAE</em></li>
<li><em>MAPE</em></li>
<li><em>SMAPE</em></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>经验损失、结构损失总是能用作评价模型，但是意义不明确</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-31T17:48:22.000Z" title="8/1/2019, 1:48:22 AM">2019-08-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T07:06:49.000Z" title="7/16/2021, 3:06:49 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Loss/">Loss</a></span><span class="level-item">9 minutes read (About 1379 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Loss/func_loss.html">Loss Function</a></h1><div class="content"><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><ul>
<li>损失函数可以视为<strong>模型与真实的距离</strong>的度量<ul>
<li>因此损失函数设计关键即，寻找可以代表模型与真实的距离的统计量</li>
<li>同时为求解方便，应该损失函数最好应满足导数存在</li>
</ul>
</li>
</ul>
<h3 id="Surrogate-Loss"><a href="#Surrogate-Loss" class="headerlink" title="Surrogate Loss"></a>Surrogate Loss</h3><p>代理损失函数：用优化方便的损失函数代替难以优化的损失函数，间接达到优化原损失函数的目标</p>
<ul>
<li>如 0-1 损失难以优化，考虑使用二次损失、交叉熵损失替代</li>
</ul>
<h3 id="损失函数设计"><a href="#损失函数设计" class="headerlink" title="损失函数设计"></a>损失函数设计</h3><ul>
<li><p>对有监督学习：<strong>真实</strong> 已知，可以直接设计损失函数</p>
</li>
<li><p>对无监督学习：<strong>真实</strong> 未知，需要给定 <strong>真实标准</strong></p>
<ul>
<li><em>NLP</em>：需要给出语言模型</li>
<li><em>EM</em> 算法：熵最大原理</li>
</ul>
</li>
</ul>
<h2 id="常用损失函数"><a href="#常用损失函数" class="headerlink" title="常用损失函数"></a>常用损失函数</h2><p><img src="/imgs/01_se_ce_hinge_loss.png" alt="01_se_ce_hinge_loss"></p>
<h3 id="0-1-Loss"><a href="#0-1-Loss" class="headerlink" title="0-1 Loss"></a>0-1 Loss</h3><script type="math/tex; mode=display">
L(y, f(x)) = \left \{ \begin{array}{l}
    1, & y \neq f(x) \\
    0, & y = f(x)
\end{array} \right.</script><ul>
<li><p>0-1 损失函数梯度要么为 0、要么不存在，无法通过梯度下降方法优化 0-1 损失</p>
</li>
<li><p>适用场合</p>
<ul>
<li>二分类：<em>Adaboost</em></li>
<li>多分类：<em>Adaboost.M1</em></li>
</ul>
</li>
</ul>
<h3 id="Quadratic-Squared-Error-Loss"><a href="#Quadratic-Squared-Error-Loss" class="headerlink" title="Quadratic / Squared Error Loss"></a><em>Quadratic</em> / <em>Squared Error Loss</em></h3><script type="math/tex; mode=display">
L(y, f(x)) = \frac 1 2 (y - f(x))^2</script><ul>
<li><p>平方错误损失函数可导，可以基于梯度下降算法优化损失函数</p>
</li>
<li><p>适用场合</p>
<ul>
<li>回归预测：线性回归</li>
<li>分类预测：0-1 二分类（根据预测得分、阈值划分）</li>
</ul>
</li>
</ul>
<h3 id="Logistic-SE"><a href="#Logistic-SE" class="headerlink" title="Logistic SE"></a><em>Logistic SE</em></h3><ul>
<li><p>平方损失用于二分类时存在如下问题（模型输出无限制）</p>
<ul>
<li>若模型对某样本非常确信为正例，给出大于1预测值</li>
<li>此时模型会进行不必要、开销较大的优化</li>
</ul>
</li>
<li><p>考虑对模型输出进行 <em>sigmoid</em> 变换后作为预测值，再应用平方错误损失函数</p>
<script type="math/tex; mode=display">
L(y, f(x)) = \frac 1 2 (y - \sigma(f(x)))^2</script><ul>
<li><em>Logistic SE</em> 损失函数曲线对 0-1 损失拟合优于平方损失</li>
<li>但负区间存在饱和问题，损失最大只有 0.5</li>
</ul>
</li>
</ul>
<h3 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a><em>Cross Entropy</em></h3><p>交叉熵损失</p>
<script type="math/tex; mode=display">\begin{align*}
L(y, f(x)) & = -ylog(f(x)) \\
& = - \sum_{k=1}^K y_k log f(x)_k
\end{align*}</script><blockquote>
<ul>
<li>$y$：样本实际值</li>
<li>$f(x)$：各类别预测概率</li>
<li>$K$：分类数目</li>
</ul>
</blockquote>
<ul>
<li><p>交叉熵损失综合二次损失、<em>logistic SE</em> 优势，以正样本为例</p>
<ul>
<li>预测值较大时：损失接近 0，避免无效优化</li>
<li>预测值较小时：损失偏导趋近于 -1，不会出现饱和现象</li>
</ul>
</li>
<li><p>$y$ 为 <em>one-hot</em> 编码时实际值时</p>
<ul>
<li>分类问题仅某分量为 1：此时交叉熵损失同对数损失（负对数极大似然函数）</li>
<li>标签问题则可有分量为 1</li>
</ul>
</li>
<li><p>适合场合</p>
<ul>
<li>多分类问题</li>
<li>标签问题</li>
</ul>
</li>
</ul>
<h3 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a><em>Hinge Loss</em></h3><script type="math/tex; mode=display">\begin{align*}
L(y, f(x)) & = [1 - yf(x)]_{+} \\
[z]_{+} & = \left \{ \begin{array}{l}
    z, & z > 0 \\
    0, & z \leq 0
\end{array} \right.
\end{align*}</script><blockquote>
<ul>
<li>$y \in {-1, +1}$</li>
</ul>
</blockquote>
<ul>
<li><p>合页损失函数：0-1 损失函数的上界，效果类似交叉熵损失函数</p>
<ul>
<li>要求分类不仅正确，还要求确信度足够高损失才为 0</li>
<li>即对学习有更高的要求</li>
</ul>
</li>
<li><p>适用场合</p>
<ul>
<li>二分类：线性支持向量机</li>
</ul>
</li>
</ul>
<h3 id="收敛速度对比"><a href="#收敛速度对比" class="headerlink" title="收敛速度对比"></a>收敛速度对比</h3><ul>
<li><p>指数激活函数时：相较于二次损失，收敛速度更快</p>
</li>
<li><p>二次损失对 $w$ 偏导</p>
<script type="math/tex; mode=display">
\frac {\partial L} {\partial w} = (\sigma(z) - y) \sigma^{'}(z) x</script><blockquote>
<ul>
<li>$\sigma$：<em>sigmoid</em>、<em>softmax</em> 激活函数</li>
<li>$z = wx + b$</li>
</ul>
</blockquote>
<ul>
<li>考虑到 <em>sigmoid</em> 函数输入值绝对值较大时，其导数较小</li>
<li>激活函数输入 $z=wx+b$ 较大时，$\sigma^{‘}(z)$ 较小，更新速率较慢</li>
</ul>
</li>
<li><p><em>Softmax</em> 激活函数时，交叉熵对 $w$ 偏导</p>
<script type="math/tex; mode=display">\begin{align*}
\frac {\partial L} {\partial w} & = -y\frac 1 {\sigma(z)}
   \sigma^{'}(z) x \\
& = y(\sigma(z) - 1)x
\end{align*}</script></li>
<li><p>特别的，对 <em>sigmoid</em> 二分类</p>
<script type="math/tex; mode=display">\begin{align*}
\frac {\partial L} {\partial w_j} & = -(\frac y {\sigma(z)}
   - \frac {(1-y)} {1-\sigma(z)}) \sigma^{'}(z) x \\
& = -\frac {\sigma^{'}(z) x} {\sigma(z)(1-\sigma(z))}
   (\sigma(z) - y) \\
& = x(\sigma(z) - y)
\end{align*}</script><ul>
<li>考虑 $y \in {(0,1), (1,0)}$、$w$ 有两组</li>
<li>带入一般形式多分类也可以得到二分类结果</li>
</ul>
</li>
</ul>
<h2 id="不常用损失函数"><a href="#不常用损失函数" class="headerlink" title="不常用损失函数"></a>不常用损失函数</h2><h3 id="Absolute-Loss"><a href="#Absolute-Loss" class="headerlink" title="Absolute Loss"></a><em>Absolute Loss</em></h3><p>绝对损失函数</p>
<script type="math/tex; mode=display">
L(y, f(x)) = |y-f(x)|</script><ul>
<li>适用场合<ul>
<li>回归预测</li>
</ul>
</li>
</ul>
<h3 id="Logarithmic-Loss"><a href="#Logarithmic-Loss" class="headerlink" title="Logarithmic Loss"></a><em>Logarithmic Loss</em></h3><p>对数损失函数（负对数极大似然损失函数）</p>
<script type="math/tex; mode=display">
L(y, P(y|x)) = -logP(y|x)</script><ul>
<li>适用场合<ul>
<li>多分类：贝叶斯生成模型、逻辑回归</li>
</ul>
</li>
</ul>
<h3 id="Exponential-Loss"><a href="#Exponential-Loss" class="headerlink" title="Exponential Loss"></a><em>Exponential Loss</em></h3><p>指数函数函数</p>
<script type="math/tex; mode=display">
L(y, f(x)) = exp\{-yf(x)\}</script><ul>
<li>适用场合<ul>
<li>二分类：前向分步算法</li>
</ul>
</li>
</ul>
<h3 id="Pseudo-Loss"><a href="#Pseudo-Loss" class="headerlink" title="Pseudo Loss"></a><em>Pseudo Loss</em></h3><p>伪损失：考虑个体损失 $(x_i, y_i)$ 如下，据此构造伪损失</p>
<ul>
<li>$h(x_i, y_i)=1, \sum h(x_i, y)=0$：完全正确预测</li>
<li>$h(x_i, y_i)=0, \sum h(x_i, y)=1$：完全错误预测</li>
<li>$h(x_i, y_i)=1/M$：随机预测（M为分类数目）</li>
</ul>
<script type="math/tex; mode=display">
L(y, f(x)) = \frac 1 2 \sum_{y^{(j)} \neq f(x)} w_j (1 - f(x, y) + f(x, y^{(j)}))</script><blockquote>
<ul>
<li>$w_j$：样本个体错误标签权重，对不同个体分布可不同</li>
<li>$f(x, y^{(j)})$：分类器将输入 $x$ 预测为第 $j$ 类 $y^{(j)}$ 的置信度</li>
</ul>
</blockquote>
<ul>
<li><p>伪损失函数考虑了预测 <strong>标签</strong> 的权重分布</p>
<ul>
<li>通过改变此分布，能够更明确的关注难以预测的个体标签，而不仅仅个体</li>
</ul>
</li>
<li><p>伪损失随着分类器预测准确率增加而减小</p>
<ul>
<li>分类器 $f$ 对所有可能类别输出置信度相同时，伪损失最大达到 0.5，此时就是随机预测</li>
<li>伪损失大于 0.5 时，应该将使用 $1-f$</li>
</ul>
</li>
<li><p>适用场景</p>
<ul>
<li>多分类：<em>Adaboost.M2</em></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-23T00:39:04.000Z" title="7/23/2019, 8:39:04 AM">2019-07-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-23T00:39:04.000Z" title="7/23/2019, 8:39:04 AM">2019-07-23</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Model-Enhencement/">Model Enhencement</a></span><span class="level-item">6 minutes read (About 890 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Model-Enhencement/stacking.html">Stacked Generalization</a></h1><div class="content"><h2 id="Stacked-Generalization"><a href="#Stacked-Generalization" class="headerlink" title="Stacked Generalization"></a>Stacked Generalization</h2><p>堆栈泛化：使用<strong>多种模型</strong>分别训练训练，将其结果叠加作为下层
模型的输入，最终得到预测输出</p>
<p><img src="/imgs/stacking.png" alt="stacking"></p>
<ul>
<li><p>属于异源集成模型，可以视为</p>
<ul>
<li><p>复合函数</p>
<p><img src="/imgs/stacking_workflow_2.png" alt="stacing_workflow_2"></p>
</li>
<li><p>短路网络</p>
<p><img src="/imgs/stacking_workflow_1.png" alt="stacing_workflow_1"></p>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>从某种意义上，复杂模型都是stacking</li>
</ul>
</blockquote>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><ul>
<li><p>不同模型侧重于获取数据不同方面的特征</p>
<ul>
<li>使用基学习器抽取数据特征进行表示学习，提取不同角度的
数据高维特征</li>
<li>考虑到使用全量训练数据训练、预测作为下层模型输入会
导致过拟合，可使用K折交叉验证避免过拟合</li>
<li>有些基学习器只使用适合其部分特征训练<ul>
<li>GBDT、DNN适合低维稠密特征</li>
</ul>
</li>
</ul>
</li>
<li><p>元学习器组合多个基学习器的输出</p>
<ul>
<li>从数据高维特征学习数据模式，具有更好的泛化能力，避免
过拟合</li>
</ul>
</li>
</ul>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><blockquote>
<ul>
<li>输入：模型$M<em>1, M_2, \cdots, M_d$、训练特征：$X</em>{n*m}$、
  训练标签$Y_{n}$、测试特征$X^{‘}$</li>
<li>输出：stacking模型、预测标签</li>
</ul>
</blockquote>
<ul>
<li><p>将训练数据K折划分，对第$i$轮划分</p>
<ul>
<li>使用模型$M<em>1, M_2, \cdots, M_d$分别在相应训练集
$[X[:n_i,:], X[n</em>{i+1}:,:]]$、
$[Y[:n<em>i], Y[n</em>{i+1}:]]$上训练</li>
<li>在相应验证集$X[n<em>i:n</em>{i+1}, :]$上验证、并记录验证
结果</li>
<li>将验证集验证结果叠加得到部分样本新特征
$N[n<em>i: n</em>{i+1}, d]$</li>
</ul>
</li>
<li><p>将K轮划分得到的部分新特征拼接得到训练集的完整新特征
$N_{n * d}$，将新特征作为输入，训练下层模型，得到最终
stacking模型</p>
</li>
<li><p>将测试特征如上作为输入经过两层模型预测，得到最终预测结果</p>
</li>
</ul>
<blockquote>
<ul>
<li>以上以2层stacking为例，有深层stacking</li>
</ul>
</blockquote>
<h2 id="常用模型"><a href="#常用模型" class="headerlink" title="常用模型"></a>常用模型</h2><h3 id="基学习器"><a href="#基学习器" class="headerlink" title="基学习器"></a>基学习器</h3><ul>
<li>交叉项、原始特征本身也可以视为线性基学习器学习到的特征</li>
</ul>
<blockquote>
<ul>
<li>具体模型参见
  <em>ml_specification/rec_system/ctr_stacking_models</em></li>
</ul>
</blockquote>
<h4 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h4><p><img src="img/gbdt_in_stacking.png" alt="gbdt_in_stacking"></p>
<blockquote>
<ul>
<li>各树中各节点对应元学习器一维输入特征</li>
</ul>
</blockquote>
<ul>
<li><p>适合低维稠密通用特征，对输入特征分布没有要求</p>
</li>
<li><p>GBDT树根据熵增益（Gini系数增益）划分节点，每条路径
都代表一定区分能力</p>
<ul>
<li>以叶子节点（路径）作为特征，相当于自动进行特征
转换、组合、选择、离散化，得到<strong>高维组合特征</strong></li>
</ul>
</li>
<li><p>GDBT相较于单棵树、或RF更适合stacking</p>
<ul>
<li>单棵树表达能力弱，无法表达多个有区分性特征组合，
集成模型可将样本映射为多个特征</li>
<li>GBDT拟合残差意味着各树对样本区分度不同，对各特征
区别对待更合理</li>
</ul>
</li>
</ul>
<h4 id="DNN"><a href="#DNN" class="headerlink" title="DNN"></a>DNN</h4><ul>
<li>适合普通稠密特征、embedding特征</li>
<li>模型表达能力强，能抽取有良好分布数据的深层次特征，提高
模型准确性、泛化能力</li>
<li>容易扩充其他类别特征，如：图片、文字</li>
</ul>
<h3 id="元学习器"><a href="#元学习器" class="headerlink" title="元学习器"></a>元学习器</h3><ul>
<li><p>LR</p>
<ul>
<li>适合低维稀疏特征，可对所有特征离散化以引入非线性</li>
</ul>
</li>
<li><p>FM</p>
<ul>
<li>适合低维稀疏特征</li>
<li>LR基础上自动组合二阶交叉项</li>
</ul>
</li>
<li><p>Linear：训练模型、对训练结果线性加权</p>
</li>
</ul>
<p>?</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Model-Enhencement/">Model Enhencement</a></span><span class="level-item">20 minutes read (About 2987 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Model-Enhencement/model_enhancement.html">Model Enhancement</a></h1><div class="content"><h2 id="Emsemble-Learning"><a href="#Emsemble-Learning" class="headerlink" title="Emsemble Learning"></a>Emsemble Learning</h2><blockquote>
<ul>
<li>集成学习：训练多个基模型，并将其组合起来，以达到更好的
  预测能力、泛化能力、稳健性</li>
<li><em>base learner</em>：基模型，基于<strong>独立样本</strong>建立的、一组
  <strong>具有相同形式</strong>的模型中的一个</li>
<li>组合预测模型：由基模型组合，即集成学习最终习得模型</li>
</ul>
</blockquote>
<ul>
<li><p>源于样本均值抽样分布思路</p>
<ul>
<li>$var(\bar{X}) = \sigma^2 / n$</li>
<li>基于独立样本，建立一组具有相同形式的基模型</li>
<li>预测由这组模型共同参与</li>
<li>组合预测模型稳健性更高，类似于样本均值抽样分布方差
更小</li>
</ul>
</li>
<li><p>关键在于</p>
<ul>
<li>获得多个独立样本的方法</li>
<li>组合多个模型的方法</li>
</ul>
</li>
</ul>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul>
<li><p><em>homogenous ensemble</em>：同源集成，基学习器属于同一类型</p>
<ul>
<li><em>bagging</em></li>
<li><em>boosting</em></li>
</ul>
</li>
<li><p><em>heterogenous ensemble</em>：异源集成，基学习器不一定属于同
一类型</p>
<ul>
<li><em>[genralization] stacking</em></li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>Target</th>
<th>Data</th>
<th>parallel</th>
<th>Classifier</th>
<th>Aggregation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bagging</td>
<td>减少方差</td>
<td>基于boostrap随机抽样，抗异常值、噪声</td>
<td>模型间并行</td>
<td>同源不相关基学习器，一般是树</td>
<td>分类：投票、回归：平均</td>
</tr>
<tr>
<td>Boosting</td>
<td>减少偏差</td>
<td>基于误分分步</td>
<td>模型间串行</td>
<td>同源若学习器</td>
<td>加权投票</td>
</tr>
<tr>
<td>Stacking</td>
<td>减少方差、偏差</td>
<td>K折交叉验证数据、基学习器输出</td>
<td>层内模型并行、层间串行</td>
<td>异质强学习器</td>
<td>元学习器</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<ul>
<li>以上都是指原始版本、主要用途</li>
</ul>
</blockquote>
<h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p>提升方法：将弱可学习算法<strong>提升</strong>为强可学习算法的组合元算法</p>
<ul>
<li>属于加法模型：即基函数的线性组合</li>
<li>各模型之间存在依赖关系</li>
</ul>
<p><img src="/imgs/boosting.png" alt="boosting"></p>
<h4 id="分类Boosting"><a href="#分类Boosting" class="headerlink" title="分类Boosting"></a>分类Boosting</h4><blockquote>
<ul>
<li><strong>依次</strong>学习多个基分类器</li>
<li>每个基分类器<strong>依之前分类结果调整权重</strong></li>
<li><strong>堆叠</strong>多个分类器提高分类准确率</li>
</ul>
</blockquote>
<ul>
<li><p>boosting通过组合多个误分率略好于随机猜测的分类器得到
误分率较小的分类器，因此boosting适合这两类问题</p>
<ul>
<li>个体之间难度有很大不同，boosting能够更加关注较难的
个体</li>
<li>学习器对训练集敏感，boosting驱使学习器在趋同的、
“较难”的分布上学习，此时boosting就和bagging一样能够
使得模型更加稳健（但原理不同）</li>
</ul>
</li>
<li><p>boosting能减小预测方差、偏差、过拟合</p>
<ul>
<li><p>直觉上，使用在不同的样本上训练的基学习器加权组合，
本身就能减小学习器的随机变动</p>
</li>
<li><p>基于同样的理由，boosting同时也能减小偏差</p>
</li>
<li><p>过拟合对集成学习有些时候有正面效果，其带来多样性，
使模型泛化能力更好，前提是样本两足够大，否则小样本
仍然无法提供多样性</p>
</li>
</ul>
</li>
</ul>
<h4 id="回归Boosting"><a href="#回归Boosting" class="headerlink" title="回归Boosting"></a>回归Boosting</h4><blockquote>
<ul>
<li><strong>依次</strong>训练多个基学习器</li>
<li>每个基学习器以<strong>之前学习器拟合残差</strong>为目标</li>
<li><strong>堆叠</strong>多个学习器减少整体损失</li>
</ul>
</blockquote>
<ul>
<li><p>boosting组合模型整体损失（结构化风险）</p>
<script type="math/tex; mode=display">
R_{srm} = \sum_{i=1}^N l(y_i, \hat y_i) +
   \sum_{t=1}^M \Omega(f_t)</script><blockquote>
<ul>
<li>$l$：损失函数</li>
<li>$f_t$：基学习器</li>
<li>$\Omega(f_t)$：单个基学习器的复杂度罚</li>
<li>$N, M$：样本数目、学习器数目</li>
</ul>
</blockquote>
</li>
<li><p>基学习器损失</p>
<script type="math/tex; mode=display">
obj^{(t)} = \sum_{i=1}^N l(y_i, \hat y_i^{(t)}) +
   \Omega(f_t)</script></li>
</ul>
<h4 id="最速下降法"><a href="#最速下降法" class="headerlink" title="最速下降法"></a>最速下降法</h4><p>使用线性函数拟合$l(y_i, \hat y_i^{(t)})$</p>
<script type="math/tex; mode=display">\begin{align*}
obj^{(t)} & = \sum_i^N l(y_i, \hat y_i^{(t-1)} + f_t(x_i)) +
    \Omega(f_t) \\
& \approx \sum_{i=1}^N [l(y_i, \hat y^{(t-1)}) + g_i f_t(x_i)]
    + \Omega(f_t)
\end{align*}</script><blockquote>
<ul>
<li>$g<em>i = \partial</em>{\hat y} l(y_i, \hat y^{t-1})$</li>
</ul>
</blockquote>
<ul>
<li>一次函数没有极值</li>
<li>将所有样本损失视为向量（学习器权重整体施加），则负梯度
方向损失下降最快，考虑使用负梯度作为伪残差</li>
</ul>
<h4 id="Newton法"><a href="#Newton法" class="headerlink" title="Newton法"></a>Newton法</h4><p>使用二次函数拟合$l(y_i, \hat y_i^{(t)}$</p>
<script type="math/tex; mode=display">\begin{align*}
obj^{(t)} & = \sum_i^N l(y_i, \hat y_i^{(t-1)} + f_t(x_i)) +
    \Omega(f_t) \\
& \approx \sum_{i=1}^N [l(y_i, \hat y^{(t-1)}) + g_i f_t(x_i)
    + \frac 1 2 h_i f_t^2(x_i)] + \Omega(f_t) \\
\end{align*}</script><blockquote>
<ul>
<li>$h<em>i = \partial^2</em>{\hat y} l(y_i, \hat y^{t-1})$</li>
</ul>
</blockquote>
<ul>
<li>二次函数本身有极值</li>
<li>可以结合复杂度罚综合考虑，使得每个基学习器损失达到最小</li>
</ul>
<h3 id="Boosting-amp-Bagging"><a href="#Boosting-amp-Bagging" class="headerlink" title="Boosting&amp;Bagging"></a>Boosting&amp;Bagging</h3><ul>
<li><p>基分类器足够简单时，boosting表现均显著好于bagging</p>
<ul>
<li>仅靠单次决策（单个属性、属性组合）分类</li>
</ul>
</li>
<li><p>使用C4.5树作为基分类器时，boosting仍然具有优势，但是不够
有说服力</p>
</li>
</ul>
<blockquote>
<ul>
<li>结论来自于<em>Experiments with a New Boosting Algorithm</em></li>
</ul>
</blockquote>
<h4 id="Boosting-amp-Bagging-1"><a href="#Boosting-amp-Bagging-1" class="headerlink" title="Boosting&amp;Bagging"></a>Boosting&amp;Bagging</h4><ul>
<li><p>基分类器足够简单时，boosting表现均显著好于bagging</p>
<ul>
<li>仅靠单次决策（单个属性、属性组合）分类</li>
</ul>
</li>
<li><p>使用C4.5树作为基分类器时，boosting仍然具有优势，但是不够
有说服力</p>
</li>
</ul>
<blockquote>
<ul>
<li>结论来自于<em>Experiments with a New Boosting Algorithm</em></li>
</ul>
</blockquote>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p><em>probably approximately correct</em>：概率近似正确，在概率近似
正确学习的框架中</p>
<ul>
<li><p><em>strongly learnable</em>：强可学习，一个概念（类），如果存在
一个多项式的学习算法能够学习它，并且<strong>正确率很高</strong>，那么
就称为这个概念是强可学习的</p>
</li>
<li><p><em>weakly learnable</em>：弱可学习，一个概念（类），如果存在
一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测
略好，称此概念为弱可学习的</p>
</li>
<li><p><em>Schapire</em>证明：在PAC框架下强可学习和弱可学习是等价的</p>
</li>
</ul>
<h3 id="具体措施"><a href="#具体措施" class="headerlink" title="具体措施"></a>具体措施</h3><blockquote>
<ul>
<li>弱学习算法要比强学习算法更容易寻找，所以具体实施提升就是
  需要解决的问题</li>
</ul>
</blockquote>
<ul>
<li><p><strong>改变训练数据权值、概率分布的方法</strong></p>
<ul>
<li>提高分类错误样本权值、降低分类正确样本权值</li>
</ul>
</li>
<li><p><strong>将弱学习器组合成强学习器的方法</strong></p>
<ul>
<li><em>competeing</em></li>
<li><em>simple majority voting</em></li>
<li><em>weighted majority voting</em></li>
<li><em>confidence-based weighting</em></li>
</ul>
</li>
</ul>
<h3 id="学习器组合方式"><a href="#学习器组合方式" class="headerlink" title="学习器组合方式"></a>学习器组合方式</h3><blockquote>
<ul>
<li>很多模型无法直接组合，只能组合预测结果</li>
</ul>
</blockquote>
<ul>
<li><p><em>simple majority voting</em>/<em>simple average</em>：简单平均</p>
<script type="math/tex; mode=display">
h = \frac 1 K \sum_{k=1}_K h_k</script><blockquote>
<ul>
<li>$h_k$：第k个预测</li>
</ul>
</blockquote>
</li>
<li><p><em>weighted majority voting</em>/<em>weighted average</em>：加权平均</p>
<script type="math/tex; mode=display">
h = \frac {\sum_{k=1}^K w_k h_k} {\sum_{k=1}^K w_k}</script><blockquote>
<ul>
<li>$w_k$：第k个预测权重，对分类器可以是准确率</li>
</ul>
</blockquote>
</li>
<li><p><em>competing voting</em>/<em>largest</em>：使用效果最优者</p>
</li>
<li><p><em>confidence based weighted</em>：基于置信度加权</p>
<script type="math/tex; mode=display">\begin{align*}
h = \arg\max_{y \in Y} \sum_{k=1}^K ln(\frac {1 - e_k}
   {e_k}) h_k
\end{align*}</script><blockquote>
<ul>
<li>$e_k$：第k个模型损失</li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="Meta-Learning"><a href="#Meta-Learning" class="headerlink" title="Meta Learning"></a>Meta Learning</h2><p>元学习：自动学习关于关于机器学习的元数据的机器学习子领域</p>
<ul>
<li><p>元学习主要目标：使用学习到元数据解释，自动学习如何
<em>flexible</em>的解决学习问题，借此提升现有学习算法性能、
学习新的学习算法，即学习学习</p>
</li>
<li><p>学习算法灵活性即可迁移性，非常重要</p>
<ul>
<li>学习算法往往基于某个具体、假象的数据集，有偏</li>
<li>学习问题、学习算法有效性之间的关系没有完全明白，对
学习算法的应用有极大限制</li>
</ul>
</li>
</ul>
<h3 id="要素"><a href="#要素" class="headerlink" title="要素"></a>要素</h3><ul>
<li>元学习系统必须包含子学习系统</li>
<li>学习经验通过提取元知识获得经验，元知识可以在先前单个
数据集，或不同的领域中获得</li>
<li>学习<em>bias</em>（影响用于模型选择的前提）必须动态选择<ul>
<li><em>declarative bias</em>：声明性偏见，确定假设空间的形式
，影响搜索空间的大小<ul>
<li>如：只允许线性模型</li>
</ul>
</li>
<li><em>procedural bias</em>：过程性偏见，确定模型的优先级<ul>
<li>如：简单模型更好</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Recurrent-Neural-networks"><a href="#Recurrent-Neural-networks" class="headerlink" title="Recurrent Neural networks"></a><em>Recurrent Neural networks</em></h3><p>RNN：<em>self-referential</em> RNN理论上可以通过反向传播学习到，
和反向传播完全不同的权值调整算法</p>
<h3 id="Meta-Reinforcement-Learning"><a href="#Meta-Reinforcement-Learning" class="headerlink" title="Meta Reinforcement Learning"></a><em>Meta Reinforcement Learning</em></h3><p>MetaRL：RL智能体目标是最大化奖励，其通过不断提升自己的学习
算法来加速获取奖励，这也涉及到自我指涉</p>
<h2 id="Additional-Model"><a href="#Additional-Model" class="headerlink" title="Additional Model"></a>Additional Model</h2><p>加法模型：将模型<strong>视为</strong>多个基模型加和而来</p>
<script type="math/tex; mode=display">
f(x) = \sum_{m=1}^M \beta_m b(x;\theta_m)</script><blockquote>
<ul>
<li>$b(x;\theta_m)$：基函数</li>
<li>$\theta_m$：基函数的参数</li>
<li>$\beta_m$：基函数的系数</li>
</ul>
</blockquote>
<ul>
<li><p>则相应风险极小化策略</p>
<script type="math/tex; mode=display">
\arg\min_{\beta_m, \theta_m} \sum_{i=1}^N
   L(y_i, \sum_{m=1}^M \beta_m b(x_i;\theta_m))</script><blockquote>
<ul>
<li>$L(y, f(x))$：损失函数</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="Forward-Stagewise-Algorithm"><a href="#Forward-Stagewise-Algorithm" class="headerlink" title="Forward Stagewise Algorithm"></a>Forward Stagewise Algorithm</h3><p>前向分步算法：从前往后，每步只学习<strong>加法模型</strong>中一个基函数
及其系数，逐步逼近优化目标函数，简化优化复杂度</p>
<ul>
<li><p>即每步只求解优化</p>
<script type="math/tex; mode=display">
\arg\min_{\beta, \theta} \sum_{i=1}^N
   L(y_i, \hat f_m(x_i) + \beta b(x_i;\theta))</script><blockquote>
<ul>
<li>$\hat f_m$：前m轮基函数预测值加和</li>
</ul>
</blockquote>
</li>
</ul>
<h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><blockquote>
<ul>
<li>输入：训练数据集$T={(x_1,y_1), \cdots, (x_N,y_N)}$，损失
  函数$L(y,f(x))$，基函数集${b(x;\theta)}$</li>
<li>输出：加法模型$f(x)$</li>
</ul>
</blockquote>
<ul>
<li><p>初始化$f_0(x)=0$</p>
</li>
<li><p>对$m=1,2,\cdots,M$，加法模型中M个基函数</p>
<ul>
<li><p>极小化损失函数得到参数$\beta_m, \theta_m$</p>
<script type="math/tex; mode=display">
(\beta_m, \theta_m) = \arg\min_{\beta, \theta}
  \sum_{i=1}^N L(y_i, f_{m-1}(x_1) +
  \beta b(x_i; \theta))</script></li>
<li><p>更新</p>
<script type="math/tex; mode=display">
f_m(x) = f_{m-1}(x) + \beta_m b(x;y_M)</script></li>
</ul>
</li>
<li><p>得到加法模型</p>
<script type="math/tex; mode=display">
f(x) = f_M(x) = \sum_{i=1}^M \beta_m b(x;\theta_m)</script></li>
</ul>
<h3 id="AdaBoost-amp-前向分步算法"><a href="#AdaBoost-amp-前向分步算法" class="headerlink" title="AdaBoost&amp;前向分步算法"></a>AdaBoost&amp;前向分步算法</h3><p>AdaBoost（基分类器loss使用分类误差率）是前向分步算法的特例，
是由基本分类器组成的加法模型，损失函数是指数函数</p>
<ul>
<li><p>基函数为基本分类器时加法模型等价于AdaBoost的最终分类器
$f(x) = \sum_{m=1}^M \alpha_m G_m(x)$</p>
</li>
<li><p>前向分步算法的损失函数为指数函数$L(y,f(x))=exp(-yf(x))$
时，学习的具体操作等价于AdaBoost算法具体操作</p>
<ul>
<li><p>假设经过m-1轮迭代，前向分步算法已经得到</p>
<script type="math/tex; mode=display">\begin{align*}
f_{m-1}(x) & = f_{m-2}(x) + \alpha_{m-1}G_{m-1}(x) \\
  & = \alpha_1G_1(x) + \cdots +
  \alpha_{m-1}G_{m-1}(x)
\end{align*}</script></li>
<li><p>经过第m迭代得到$\alpha_m, G_m(x), f_m(x)$，其中</p>
<script type="math/tex; mode=display">\begin{align*}
(\alpha_m, G_m(x)) & = \arg\min_{\alpha, G}
      \sum_{i=1}^N exp(-y_i(f_{m-1}(x_i) +
      \alpha G(x_i))) \\
  & = \arg\min_{\alpha, G} \sum_{i=1}^N \bar w_{m,i}
      exp(-y_i \alpha G(x_i))
\end{align*}</script><blockquote>
<ul>
<li>$\bar w<em>{m,i}=exp(-y_i f</em>{m-1}(x_i))$：不依赖
$\alpha, G$</li>
</ul>
</blockquote>
</li>
<li><p>$\forall \alpha &gt; 0$，使得损失最小应该有
（提出$\alpha$）</p>
<script type="math/tex; mode=display">\begin{align*}
G_m^{*}(x) & = \arg\min_G \sum_{i=1}^N \bar w_{m,i}
      exp(-y_i f_{m-1}(x_i)) \\
  & = \arg\min_G \sum_{i=1}^N \bar w_{m,i}
      I(y_i \neq G(x_i))
\end{align*}</script><p>此分类器$G_m^{*}$即为使得第m轮加权训练误差最小分类器
，即AdaBoost算法的基本分类器</p>
</li>
<li><p>又根据</p>
<script type="math/tex; mode=display">\begin{align*}
\sum_{i=1}^N \bar w_{m,i} exp(-y_i \alpha G(x_i)) & =
  \sum_{y_i = G_m(x_i)} \bar w_{m,i} e^{-\alpha} +
  \sum_{y_i \neq G_m(x_i)} \bar w_{m,i} e^\alpha \\
& = (e^\alpha - e^{-\alpha}) \sum_{i=1}^N (\bar w_{m,i}
  I(y_i \neq G(x_i))) + e^{-\alpha}
  \sum_{i=1}^N \bar w_{m,i}
\end{align*}</script><p>带入$G_m^{*}$，对$\alpha$求导置0，求得极小值为</p>
<script type="math/tex; mode=display">\begin{align*}
\alpha_m^{*} & = \frac 1 2 log \frac {1-e_m} {e_m} \\
e_m & = \frac {\sum_{i=1}^N (\bar w_{m,i}
      I(y_i \neq G_m(x_i)))}
  {\sum_{i=1}^N \bar w_{m,i}} \\
& = \frac {\sum_{i=1}^N (\bar w_{m,i}
      I(y_i \neq G_m(x_i)))} {Z_m} \\
& = \sum_{i=1}^N w_{m,i} I(y_i \neq G_m(x_i))
\end{align*}</script><blockquote>
<ul>
<li>$w_{m,i}, Z_M$同AdaBoost中</li>
</ul>
</blockquote>
<p>即为AdaBoost中$\alpha_m$</p>
</li>
<li><p>对权值更新有</p>
<script type="math/tex; mode=display">
\bar w_{m+1,i} = \bar w_{m,i} exp(-y_i \alpha_m G_m(x))</script><p>与AdaBoost权值更新只相差规范化因子$Z_M$</p>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T07:11:28.000Z" title="7/16/2021, 3:11:28 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Model-Enhencement/">Model Enhencement</a></span><span class="level-item">15 minutes read (About 2228 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Model-Enhencement/adaboost.html">AdaBoost</a></h1><div class="content"><h2 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h2><p>通过改变训练样本权重，学习多个分类器，并将分类器进行线性
组合，提高分类性能</p>
<ul>
<li>对离群点、奇异点敏感</li>
<li>对过拟合不敏感</li>
</ul>
<h3 id="Boosting实现"><a href="#Boosting实现" class="headerlink" title="Boosting实现"></a>Boosting实现</h3><blockquote>
<ul>
<li><p>改变训练数据权值或概率分布：提高分类错误样本权值、降低
  分类正确样本权值</p>
</li>
<li><p>弱分类器组合：加权多数表决，即加大分类误差率小的弱分类器
  权值，使其在表决中起更大作用；减小分类误差率大的弱分类器
  权值，使其在表决中起更小作用</p>
</li>
</ul>
</blockquote>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><p><img src="/imgs/adaboost_steps.png" alt="adaboost_steps"></p>
<blockquote>
<ul>
<li>输入：训练数据集$T={(x_1, y_1), \cdots, (x_N, y_N)}$，
  弱分类器算法$G(x)$<blockquote>
<ul>
<li>$x_i \in \mathcal{X \subset R^n}$</li>
<li>$y_i \in \mathcal{Y} = {-1, +1 }$</li>
</ul>
</blockquote>
</li>
<li>输出：最终分类器$G(x)$</li>
</ul>
</blockquote>
<ul>
<li><p>初始化训练数据权值分布：
$D<em>1=(w</em>{11}, \cdots, w<em>{1N}), w</em>{1i}=\frac 1 N$</p>
</li>
<li><p>对$m=1,2,\cdots,M$（即训练M个弱分类器）</p>
<ul>
<li><p>使用具有<strong>权值分布</strong>$D_m$的训练数据学习，得到基本
分类器</p>
<script type="math/tex; mode=display">
G_m(x):\mathcal{X} \rightarrow \{-1, +1\}</script></li>
<li><p>计算$G_m(x)$在训练数据集上的<strong>分类误差率</strong></p>
<script type="math/tex; mode=display">\begin{align*}
e_m & = P(G_m(x_i)) \neq y_i) \\
  & = \sum_{i=1}^N w_{mi}I(G_m(x_i) \neq y_i) \\
  & = \sum_{G_m(x_i) \neq y_i} w_{mi}
\end{align*}</script></li>
<li><p>计算$G_m(x)$组合为最终分类器时权重</p>
<script type="math/tex; mode=display">
\alpha = \frac 1 2 log \frac {1-e_m} {e_m}</script><blockquote>
<ul>
<li>$\alpha_m$表示就简单分类器$G_m(x)$在最终分类器中
的重要性，随$e_m$减小而增加
（弱分类器保证$e_m \leq 1/2$）</li>
</ul>
</blockquote>
</li>
<li><p>更新训练集权值分布</p>
<script type="math/tex; mode=display">\begin{align*}
D_{m+1} & = (w_{m+1,1}, \cdots, w_{m+1,N}) \\
w_{m+1,i} & = \frac {w_{mi}} {Z_m}
  exp(-\alpha y_i G_m(x_i)) = \left \{
  \begin{array}{l}
      \frac {w_mi} {Z_m} e^{-\alpha_m},
          & G_m(x_i) = y_i \\
      \frac {w_mi} {Z_m} e^{\alpha_m},
          & G_m(x_i) \neq y_i \\
  \end{array} \right. \\
Z_m & = \sum_{i=1}^N w_{mi} exp(-\alpha_m y_i G_m(x_i))
\end{align*}</script><blockquote>
<ul>
<li>$Z<em>m$：规范化因子，是第m轮调整后的权值之和，其
使得$D</em>{m+1}$成为概率分布</li>
<li>误分类样本权值相当于被放大
$e^{2\alpha_m} = \frac {e_m} {1 - e_m}$倍</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>构建基本分类器线性组合</p>
<script type="math/tex; mode=display">
f(x) = \sum_{m=1}^M \alpha_m G_m(x)</script><p>得到最终分类器</p>
<script type="math/tex; mode=display">
G(x) = sign(f(x)) = sign(\sum_{m=1}^M \alpha_m G_m(x))</script><blockquote>
<ul>
<li>这里$\alpha_m$没有规范化，和不为1，规范化没有必要</li>
<li>$f(x)$符号决定分类预测结果，绝对值大小表示分类确信度</li>
</ul>
</blockquote>
</li>
</ul>
<blockquote>
<ul>
<li>AdaBoost中分类器学习和之后的分类误差率“无关”，基分类器
  学习算法中的loss不是分类误差率，可以是其他loss，只是需要
  考虑训练数据的权值分布<blockquote>
<ul>
<li>好像基学习器的loss就要是和集成部分调权的loss一致<h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1></li>
<li><strong>按权值分布有放回的抽样</strong>，在抽样集上进行训练</li>
<li>各样本loss按权重加权，类似分类误差率中加权</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h3 id="训练误差边界"><a href="#训练误差边界" class="headerlink" title="训练误差边界"></a>训练误差边界</h3><p>AdaBoost算法最终分类器的训练误差边界为</p>
<script type="math/tex; mode=display">
\frac 1 N \sum_{i=1}^N I(G(x_i) \neq y_i) \leq
    \frac 1 N \sum_i exp(-y_if(x_i)) = \prod_m Z_m</script><ul>
<li><p>$G(x_i) \neq y_i$时，$y_if(x_i)&lt;0$，所以
$exp(-y_i f(x_i)) \geq 1$，则不等式部分可证</p>
</li>
<li><script type="math/tex; mode=display">\begin{align*}
\frac 1 N \sum_i exp(-y_i f(x_i))
   & = \frac 1 N \sum_i exp(-\sum_{m=1}^M
       \alpha_m y_i G_m(x_i)) \\
   & = \sum_i (w_{1,i} \prod_{m=1}^M
       exp(-\alpha_m y_i G_m(x_i))) \\
   & = \sum_i (Z_1 w_{2,i} \prod_{m=2}^M
       exp(-\alpha_m y_i G_m(x_i))) \\
   & = \prod_{m=1}^M Z_i \sum_i w_{M+1,i} \\
   & = \prod_{m=1}^M Z_i
\end{align*}</script></li>
</ul>
<blockquote>
<ul>
<li>AdaBoost训练误差边界性质的关键：权重调整与基本分类器权重
  调整<strong>共系数</strong>（形式不完全一样）</li>
<li>这也是AdaBoost权重调整设计的依据，方便给出误差上界</li>
</ul>
</blockquote>
<h4 id="二分类训练误差边界"><a href="#二分类训练误差边界" class="headerlink" title="二分类训练误差边界"></a>二分类训练误差边界</h4><script type="math/tex; mode=display">
\prod_{m=1}^M Z_m = \prod_{m=1}^M (2\sqrt{e_m(1-e_m)})
    = \prod_{m=1}^M \sqrt{(1-4\gamma_m^2)}
    \leq exp(-2\sum_{m=1}^M \gamma_m^2)</script><blockquote>
<ul>
<li>$\gamma_m = \frac 1 2 - e_m$</li>
</ul>
</blockquote>
<ul>
<li><script type="math/tex; mode=display">\begin{align*}
Z_m & = \sum_{i=1}^N w_{m,i} exp(-\alpha y_i G_m(x_i)) \\
   & = \sum_{y_i = G_m(x_i)} w_{m,i}e^{-\alpha_m} +
       \sum_{y_i \neq G_m(x_i)} w_{m,i}e^{\alpha_m} \\
   & = (1-e_m)e^{-\alpha_m} + e_m e^{\alpha_m} \\
   & = 2\sqrt{e_m(1-e_m)} \\
   & = \sqrt{1-4\gamma^2}
\end{align*}</script></li>
<li><p>由$\forall x \in [0, 0.5], e^{-x} &gt; \sqrt{1-2x}$可得，
$\sqrt{1-4\gamma_m^2} \leq exp(-2\gamma_m^2)$</p>
</li>
</ul>
<blockquote>
<ul>
<li>二分类AdaBoost误差边界性质的关键：$\alpha$的取值，也是
  前向分步算法（损失函数）要求</li>
<li>若存$\gamma &gt; 0$，对所有m有$\gamma_m \geq \gamma$，则<script type="math/tex; mode=display">
  \frac 1 N \sum_{i=1}^N I(G(x_i) \neq y_i) \neq
      exp(-2M\gamma^2)</script>  即AdaBoost的训练误差是<strong>指数下降</strong>的</li>
<li>分类器下界$\gamma$可以未知，AdaBoost能适应弱分类器各自
  训练误差率，所以称为<em>adptive</em></li>
</ul>
</blockquote>
<h2 id="Adaboost-M1"><a href="#Adaboost-M1" class="headerlink" title="Adaboost.M1"></a><em>Adaboost.M1</em></h2><p>Adaboost.M1是原版AdaBoost的多分类升级版，基本思想同Adaboost</p>
<h3 id="Boosting实现-1"><a href="#Boosting实现-1" class="headerlink" title="Boosting实现"></a>Boosting实现</h3><ul>
<li><p>基分类器组合方式</p>
<ul>
<li>仍然是加权投票，且投票权重同Adaboost</li>
<li>出于多分类考虑，没有使用<code>sign</code>符号函数</li>
</ul>
</li>
<li><p>改变训练数据权值或概率分布：和Adaboost形式稍有不同，但
相对的错误分类样本提升比率完全相同</p>
<ul>
<li>被上个分类器错误分类样本，权值保持不变</li>
<li>被上个分类器正确分类样本，权值缩小比例是Adaboost平方</li>
</ul>
</li>
</ul>
<h3 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h3><ul>
<li><p>输入</p>
<ul>
<li>训练集：$T={x_i, y_i}, i=1,\cdots,N; y_i \in C, C={c_1, \cdots, c_m}$</li>
<li>训练轮数：T</li>
<li>弱学习器：I</li>
</ul>
</li>
<li><p>输出：提升分类器</p>
<script type="math/tex; mode=display">
H(x) = \arg\max_{y \in C} \sum_{m=1}^M
   ln(\frac 1 {\beta_m}) [h_m(x) = y]</script><blockquote>
<ul>
<li>$h_t, h_t(x) \in C$：分类器</li>
<li>$\beta_t$：分类器权重</li>
</ul>
</blockquote>
</li>
</ul>
<p><img src="/imgs/adaboostm1_steps.png" alt="adaboostm1_steps"></p>
<h3 id="误分率上界"><a href="#误分率上界" class="headerlink" title="误分率上界"></a>误分率上界</h3><blockquote>
<ul>
<li>对弱学习算法产生的伪损失$\epsilon<em>1,\cdots,\epsilon_t$，
  记$\gamma_t = 1/2 \epsilon_t$，最终分类器$h</em>{fin}$误分率
  上界有<script type="math/tex; mode=display">
  \frac 1 N |\{i: h_{fin}(x_i) \neq y_i \}| \leq
      \prod_{t-1}^T \sqrt {1-4\gamma^2} \leq
      exp(-2 \sum_{t-1}^T \gamma^2)</script></li>
</ul>
</blockquote>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>Adaboost.M1和Adaboost基本上没有区别</p>
<ul>
<li>类别数目为2的Adaboost.M1就是Adaboost</li>
<li>同样无法处理对误分率高于0.5的情况，甚至在多分类场合，
误分率小于0.5更加难以满足</li>
<li>理论误分率上界和Adaboost相同</li>
</ul>
<h2 id="Adaboost-M2"><a href="#Adaboost-M2" class="headerlink" title="Adaboost.M2"></a><em>Adaboost.M2</em></h2><p>AdaboostM2是AdaboostM1的进阶版，更多的利用了基分类器信息</p>
<ul>
<li>要求基学习器能够输出更多信息：输出对样本分别属于各类别
的置信度向量，而不仅仅是最终标签</li>
<li>要求基分类器更加精细衡量错误：使用伪损失代替误分率
作为损失函数</li>
</ul>
<h3 id="Psuedo-Loss"><a href="#Psuedo-Loss" class="headerlink" title="Psuedo-Loss"></a><em>Psuedo-Loss</em></h3><script type="math/tex; mode=display">\begin{align*}
L & = \frac 1 2 \sum_{(i,y) \in B} D_{i,y}
    (1 - h(x_i, y_i) + h(x_i, y)) \\
& = \frac 1 2 \sum_{i=1}^N D_i (1 - h(x_i, y_i) +
    \sum_{y \neq y_i} (w_{i,y} h(x_i, y)))
\end{align*}</script><blockquote>
<ul>
<li>$D$：权重分布（行和为1，但不满足列和为1）<blockquote>
<ul>
<li>$D_{i,y}$：个体$x_i$中错误标签$y$的权重，代表从个体
 $x_i$中识别出错误标签$y$的重要性</li>
</ul>
</blockquote>
</li>
<li>$B = {(i, y)|y \neq y_i, i=1,2,\cdots,N }$</li>
<li>$w$：个体各错误标签权重边际分布</li>
<li>$h(x, y)$：模型$h$预测样本$x$为$y$的置信度<blockquote>
<ul>
<li>$h(x_i,y_i)$：预测正确的置信度</li>
<li>$h(x_i,y), y \neq y_i$：预测$x_i$为错误分类$y$置信度</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<ul>
<li>伪损失函数同时考虑了样本和<strong>标签</strong>的权重分布</li>
<li>通过改变此分布，能够更明确的关注难以预测的个体标签，
而不仅仅个体</li>
</ul>
<h3 id="Boosting实现-2"><a href="#Boosting实现-2" class="headerlink" title="Boosting实现"></a>Boosting实现</h3><ul>
<li><p>改变数据权值或者概率分布</p>
<ul>
<li>使用<em>psuedo-loss</em>替代误分率，以此为导向改变权值</li>
<li>对多分类每个错误分类概率分别计算错误占比，在此基础上
分别计算</li>
</ul>
</li>
<li><p>基分类器组合方式：同Adaboost.M1</p>
</li>
</ul>
<h3 id="步骤-2"><a href="#步骤-2" class="headerlink" title="步骤"></a>步骤</h3><p><img src="/imgs/adaboostm2_steps.png" alt="adaboostm2_steps"></p>
<h3 id="训练误差上界"><a href="#训练误差上界" class="headerlink" title="训练误差上界"></a>训练误差上界</h3><blockquote>
<ul>
<li>对弱学习算法产生的伪损失$\epsilon<em>1,\cdots,\epsilon_t$，
  记$\gamma_t = 1/2 \epsilon_t$，最终分类器$h</em>{fin}$误分率
  上界有</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
\frac 1 N |\{i: h_{fn}(x_i) \neq y_i \}| \leq
    (M-1) \prod_{t-1}^T \sqrt {1-4\gamma^2} \leq
    (M-1) exp(-2 \sum_{t-1}^T \gamma^2)</script><h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><ul>
<li><p>基于伪损失的Adaboost.M2能够提升稍微好于随机预测的分类器</p>
</li>
<li><p>Adaboosting.M2能够较好的解决基分类器对噪声的敏感性，但是
仍然距离理论最优<em>Bayes Error</em>有较大差距，额外误差主要
来自于</p>
<ul>
<li>训练数据</li>
<li>过拟合</li>
<li>泛化能力</li>
</ul>
</li>
<li><p>控制权值可以有效的提升算法，减小最小训练误差、过拟合
、泛化能力</p>
<ul>
<li>如对权值使用原始样本比例作为先验加权</li>
</ul>
</li>
<li><p>其分类结果不差于AdaBoost.M1（在某些基分类器、数据集下）</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Model-Enhencement/">Model Enhencement</a></span><span class="level-item">6 minutes read (About 847 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Model-Enhencement/bagging.html">Bagging</a></h1><div class="content"><h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a><em>Bagging</em></h2><p><em>bagging</em>：<em>bootstrap aggregating</em>，每个分类器随机从原样本
中做<strong>有放回的随机抽样</strong>，在抽样结果上训练基模型，最后根据
多个基模型的预测结果产生最终结果</p>
<ul>
<li>核心为bootstrap重抽样自举</li>
</ul>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ul>
<li><p>建模阶段：通过boostrap技术获得k个自举样本
$S_1, S_2,…, S_K$，以其为基础建立k个相同类型模型
$T_1, T_2,…, T_K$</p>
</li>
<li><p>预测阶段：组合K个预测模型</p>
<ul>
<li>分类问题：K个预测模型“投票”</li>
<li>回归问题：K个预测模型平均值</li>
</ul>
</li>
</ul>
<h3 id="模型性质"><a href="#模型性质" class="headerlink" title="模型性质"></a>模型性质</h3><ul>
<li>相较于单个基学习器，Bagging的优势<ul>
<li>分类Bagging几乎是最优的贝叶斯分类器</li>
<li>回归Bagging可以通过降低方差（主要）降低均方误差</li>
</ul>
</li>
</ul>
<h4 id="预测误差"><a href="#预测误差" class="headerlink" title="预测误差"></a>预测误差</h4><p>总有部分观测未参与建模，预测误差估计偏乐观</p>
<ul>
<li><p><em>OOB</em>预测误差：<em>out of bag</em>，基于袋外观测的预测误差，
对每个模型，使用没有参与建立模型的样本进行预测，计算预测
误差</p>
</li>
<li><p>OOB观测比率：样本总量n较大时有</p>
<script type="math/tex; mode=display">
r = (1 - \frac 1 n)^n \approx \frac 1 e = 0.367</script><ul>
<li>每次训练样本比率小于10交叉验证的90%</li>
</ul>
</li>
</ul>
<h2 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a><em>Random Forest</em></h2><p>随机森林：随机建立多个有较高预测精度、弱相关（甚至不相关）
的决策树（基础学习器），多棵决策树共同对新观测做预测</p>
<ul>
<li><p>RF是Bagging的扩展变体，在以决策树为基学习器构建Bagging
集成模型的基础上，在训练过程中引入了<strong>随机特征选择</strong></p>
</li>
<li><p>适合场景</p>
<ul>
<li>数据维度相对较低、同时对准确率有要求</li>
<li>无需很多参数调整即可达到不错的效果</li>
</ul>
</li>
</ul>
<h3 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h3><ul>
<li><p>样本随机：Bootstrap自举样本</p>
</li>
<li><p>输入属性随机：对第i棵决策树通过随机方式选取K个输入变量
构成候选变量子集$\Theta_I$</p>
<ul>
<li><p>Forest-Random Input：随机选择$k=log_2P+1或k=\sqrt P$
个变量</p>
</li>
<li><p>Forest-Random Combination</p>
<ul>
<li>随机选择L个输入变量x</li>
<li>生成L个服从均匀分布的随机数$\alpha$</li>
<li>做线性组合
$v<em>j = \sum</em>{i=1}^L \alpha_i x_i, \alpha_i \in [-1, 1]$</li>
<li>得到k个由新变量v组成的输入变量子集$\Theta_i$</li>
</ul>
</li>
</ul>
</li>
<li><p>在候选变量子集中选择最优变量构建决策树</p>
<ul>
<li>生成决策树时不需要剪枝</li>
</ul>
</li>
<li><p>重复以上步骤构建k棵决策树，用一定集成策略组合多个决策树</p>
<ul>
<li>简单平均/随机森林投票</li>
</ul>
</li>
</ul>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li><p>样本抽样、属性抽样引入随机性</p>
<ul>
<li>基学习器估计误差较大，但是组合模型偏差被修正</li>
<li>不容易发生过拟合、对随机波动稳健性较好</li>
<li>一定程度上避免贪心算法带来的局部最优局限</li>
</ul>
</li>
<li><p>数据兼容性</p>
<ul>
<li>能够方便处理高维数据，“不用做特征选择”</li>
<li>能处理分类型、连续型数据</li>
</ul>
</li>
<li><p>训练速度快、容易实现并行</p>
</li>
<li><p>其他</p>
<ul>
<li>可以得到变量重要性排序</li>
<li>启发式操作</li>
<li>优化操作</li>
</ul>
</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>决策树数量过多时，训练需要资源多</li>
<li>模型解释能力差，有点黑盒模型</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Model-Enhencement/">Model Enhencement</a></span><span class="level-item">29 minutes read (About 4279 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Model-Enhencement/gradient_boosting.html">Boosting</a></h1><div class="content"><h2 id="Gredient-Boosting"><a href="#Gredient-Boosting" class="headerlink" title="Gredient Boosting"></a>Gredient Boosting</h2><p><em>GB</em>：（利用）梯度提升，将提升问题视为优化问题，前向分步算法
利用最速下降思想实现</p>
<ul>
<li><p>一阶展开拟合损失函数，沿负梯度方向迭代更新</p>
<ul>
<li>损失函数中，模型的样本预测值$f(x)$是因变量</li>
<li>即$f(x)$应该沿着损失函数负梯度方向变化</li>
<li>即下个基学习器应该以负梯度方向作为优化目标，即负梯度
作为<strong>伪残差</strong></li>
</ul>
<blockquote>
<ul>
<li>类似复合函数求导</li>
</ul>
</blockquote>
</li>
<li><p>对基学习器预测值求解最优加权系数</p>
<ul>
<li>最速下降法中求解更新步长体现</li>
<li>前向分布算法中求解基学习器权重</li>
</ul>
</li>
</ul>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>基学习器拟合目标：损失函数的负梯度在当前模型的值</p>
<script type="math/tex; mode=display">
-\left [ \frac {\partial L(y, \hat y_i)}
    {\partial y_i} \right ]_{\hat y_i=\hat y_i^{(t-1)}}</script><h4 id="平方损失"><a href="#平方损失" class="headerlink" title="平方损失"></a>平方损失</h4><p>平方损失：$L(y, f(x)) = \frac 1 2 (y - f(x))^2$（回归）</p>
<ul>
<li><p>第m-1个基学习器伪残差为</p>
<script type="math/tex; mode=display">
r_{m,i} = y_i - f_{m-1}(x_i), i=1,2,\cdots,N</script><blockquote>
<ul>
<li>$N$：样本数量</li>
</ul>
</blockquote>
</li>
<li><p>第m个基学习器为</p>
<script type="math/tex; mode=display">\begin{align*}
h_m & = \arg\min_h \sum_{i=1}^N \frac 1 2
   (y_i - (f_{m-1}(x_i) + h(x)))^2 \\
& = \arg\min_h \sum_{i=1}^N \frac 1 2
   (C_{m,i} - h(x))^2 \\
C_{m,i} & = y_i - f_{m-1}(x_i)
\end{align*}</script></li>
<li><p>第m轮学习器组合为</p>
<script type="math/tex; mode=display">
f_m = f_{m-1} + \alpha_m h_m</script><blockquote>
<ul>
<li>$\alpha_m$：学习率，留给之后基模型学习空间</li>
</ul>
</blockquote>
<ul>
<li>这里只是形式上表示模型叠加，实际上树模型等不可加，
应该是模型预测结果叠加</li>
</ul>
</li>
</ul>
<h4 id="指数损失"><a href="#指数损失" class="headerlink" title="指数损失"></a>指数损失</h4><p>指数损失：$L(y, f(x)) = e^{-y f(x)}$（分类）</p>
<ul>
<li><p>第m-1个基学习器伪残差</p>
<script type="math/tex; mode=display">
r_{m,i} = -y_i e^{-y_i f_{m-1}(x_i)}, i=1,2,\cdots,N</script></li>
<li><p>基学习器、权重为</p>
<script type="math/tex; mode=display">\begin{align*}
h_m & = \arg\min_h \sum_{i=1}^N exp(-y_i(f_{m-1}(x_i)
   + \alpha f(x_i))) \\
& = \arg\min_h \sum_{i=1}^N C_{m,i}
   exp(-y_i \alpha f(x_i)) \\
C_{m,i} & = exp(-y_i f_{m-1}(x_i))
\end{align*}</script></li>
<li><p>第m轮学习器组合为</p>
<script type="math/tex; mode=display">
f_m = f_{m-1} + \alpha_m h_m</script></li>
</ul>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><blockquote>
<ul>
<li>输入：训练数据集$T={(x_1, y_1), \cdots, (x_N, y_N)}$，
  损失函数$L(y, f(x))$<blockquote>
<ul>
<li>$x_i \in \mathcal{X \subset R^n}$</li>
<li>$y_i \in \mathcal{Y} = {-1, +1 }$</li>
</ul>
</blockquote>
</li>
<li>输出：回归树$\hat f(x)$</li>
</ul>
</blockquote>
<ul>
<li><p>初始化模型</p>
<script type="math/tex; mode=display">
\hat y_i^{(0)} = \arg\min_{\hat y} \sum_{i=1}^N
   L(y_i, \hat y)</script></li>
<li><p>对$m=1,2,\cdots,M$（即训练M个若分类器）</p>
<ul>
<li><p>计算伪残差</p>
<script type="math/tex; mode=display">
r_i^{(t)} = -\left [ \frac {\partial L(y, \hat y_i)}
  {\partial y_i} \right ]_{\hat y_i=\hat y_i^{(t-1)}}</script></li>
<li><p>基于${(x_i, r_i^{(t)})}$生成基学习器$h_t(x)$</p>
</li>
<li><p>计算最优系数</p>
<script type="math/tex; mode=display">
\gamma = \arg\min_\gamma \sum_{i=1}^N
  L(y_i, \hat y_i^{(t-1)} + \gamma h_t(x_i))</script></li>
<li><p>更新预测值</p>
<script type="math/tex; mode=display">
\hat y_i^{(t)} = \hat y_i^{(t-1)} + \gamma_t h_t (x)</script></li>
</ul>
</li>
<li><p>得到最终模型</p>
<script type="math/tex; mode=display">
\hat f(x) = f_M(x) = \sum_{t=1}^M \gamma_t h_t(x)</script></li>
</ul>
<h3 id="Gradient-Boosted-Desicion-Tree"><a href="#Gradient-Boosted-Desicion-Tree" class="headerlink" title="Gradient Boosted Desicion Tree"></a>Gradient Boosted Desicion Tree</h3><p><em>GBDT</em>：梯度提升树，以回归树为基学习器的梯度提升方法</p>
<ul>
<li><p>GBDT会累加所有树的结果，本质上是回归模型（毕竟梯度）</p>
<ul>
<li>所以一般使用CART回归树做基学习器</li>
<li>当然可以实现分类效果</li>
</ul>
</li>
<li><p>损失函数为平方损失（毕竟回归），则相应伪损失/残差</p>
<script type="math/tex; mode=display">
r_{t,i} = y_i - f_{t-1}(x_i), i=1,2,\cdots,N</script></li>
</ul>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul>
<li>准确率、效率相较于RF有一定提升</li>
<li>能够灵活的处理多类型数据</li>
<li>Boosting类算法固有的基学习器之间存在依赖，难以并行训练
数据，比较可行的并行方案是在每轮选取最优特征切分时，并行
处理特征</li>
</ul>
<h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p><em>Extreme Gradient Boost</em>/<em>Newton Boosting</em>：前向分步算法利用
Newton法思想实现</p>
<ul>
<li><p>二阶展开拟合损失函数</p>
<ul>
<li>损失函数中，模型的样本预测值$\hat y_i$是因变量</li>
<li>将损失函数对$\hat y_i$二阶展开拟合</li>
<li>求解使得损失函数最小参数</li>
</ul>
</li>
<li><p>对基学习器预测值求解最优加权系数</p>
<ul>
<li>阻尼Newton法求解更新步长体现</li>
<li>前向分布算法中求解基学习器权重</li>
<li>削弱单个基学习器影响，让后续基学习器有更大学习空间</li>
</ul>
</li>
</ul>
<h3 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h3><ul>
<li><p>第t个基分类器损失函数</p>
<script type="math/tex; mode=display">\begin{align*}
obj^{(t)} & = \sum_{i=1}^N l(y_i, \hat y_i^{(t)}) +
   \Omega(f_t) \\

& = \sum_i^N l(y_i, \hat y_i^{(t-1)} + f_t(x_i)) +
   \Omega(f_t) \\

& \approx \sum_{i=1}^N [l(y_i, \hat y^{(t-1)}) + g_i
   f_t(x_i) + \frac 1 2 h_i f_t^2(x_i)] + \Omega(f_t) \\

& = \sum_{i=1}^N [l(y_i, \hat y^{(t-1)}) + g_i f_t(x_i) +
   \frac 1 2 h_i f_t^2(x_i)] + \gamma T_t +
   \frac 1 2 \lambda \sum_{j=1}^T {w_j^{(t)}}^2 \\

\Omega(f_t) & = \gamma T_t + \frac 1 2 \lambda
   \sum_{j=1}^T {w_j^{(t)}}^2
\end{align*}</script><blockquote>
<ul>
<li>$f_t$：第t个基学习器</li>
<li>$f_t(x_i)$：第t个基学习器对样本$x_i$的取值</li>
<li>$g<em>i = \partial</em>{\hat y} l(y_i, \hat y^{t-1})$</li>
<li>$h<em>i = \partial^2</em>{\hat y} l(y_i, \hat y^{t-1})$</li>
<li>$\Omega(f_t)$：单个基学习器的复杂度罚</li>
<li>$T_t$：第t个基学习器参数数量，即$L_0$罚<blockquote>
<ul>
<li>线性回归基学习器：回归系数数量</li>
<li>回归树基学习器：叶子节点数目</li>
</ul>
</blockquote>
</li>
<li>$\gamma$：基学习器$L_0$罚系数，模型复杂度惩罚系数</li>
<li>$w_j = f_t$：第t个基学习器参数值，即$L_2$罚<blockquote>
<ul>
<li>线性回归基学习器：回归系数值</li>
<li>回归树基学习器：叶子节点</li>
</ul>
</blockquote>
</li>
<li>$\lambda$：基学习器$L_2$罚系数，模型贡献惩罚系数</li>
<li>$\approx$：由二阶泰勒展开近似</li>
</ul>
</blockquote>
</li>
<li><p>对损失函数进行二阶泰勒展开（类似牛顿法）拟合原损失函数，
同时利用一阶、二阶导数求解下个迭代点</p>
</li>
<li><p>正则项以控制模型复杂度</p>
<ul>
<li>降低模型估计误差，避免过拟合</li>
<li>$L_2$正则项也控制基学习器的学习量，给后续学习器留下
学习空间</li>
</ul>
</li>
</ul>
<h3 id="树基学习器"><a href="#树基学习器" class="headerlink" title="树基学习器"></a>树基学习器</h3><p>XGBoost Tree：以回归树为基学习器的XGBoost模型</p>
<ul>
<li><p>模型结构说明</p>
<ul>
<li>基学习器类型：CART</li>
<li>叶子节点取值作惩罚：各叶子节点取值差别不应过大，否则
说明模型不稳定，稍微改变输入值即导致输出剧烈变化</li>
<li>树复杂度惩罚：叶子结点数量</li>
</ul>
</li>
<li><p>XGBoost最终损失（结构风险）有</p>
<script type="math/tex; mode=display">\begin{align*}
R_{srm} & = \sum_{i=1}^N l(y_i, \hat y_i) +
   \sum_{t=1}^M \Omega(f_t)
\end{align*}</script><blockquote>
<ul>
<li>$N, M$：样本量、基学习器数量</li>
<li>$\hat y_i$：样本$i$最终预测结果</li>
</ul>
</blockquote>
</li>
</ul>
<h4 id="损失函数-2"><a href="#损失函数-2" class="headerlink" title="损失函数"></a>损失函数</h4><ul>
<li><p>以树作基学习器时，第$t$基学习器损失函数为</p>
<script type="math/tex; mode=display">\begin{align*}
obj^{(t)} & = \sum_{i=1}^N l(y_i, \hat y_i^{(t)}) +
   \Omega(f_t) \\

& \approx \sum_{i=1}^N [l(y_i, \hat y^{(t-1)}) + g_i
   f_t(x_i) + \frac 1 2 h_i f_t^2(x_i)] + \gamma T_t
   + \frac 1 2 \lambda \sum_{j=1}^T {w_j^{(t)}}^2 \\

& = \sum_{j=1}^{T_t} [(\sum_{i \in I_j} g_i) w_j^{(t)} +
   \frac 1 2 (\sum_{i \in I_j} h_i + \lambda)
   {w_j^{(t)}}^2] + \gamma T_t + \sum_{i=1}^N
   l(y_i, \hat y^{(t)}) \\

& = \sum_{j=1}^{T_t} [G_i w_j^{(t)} + \frac 1 2
   (H_j + \lambda){w_j^{(t)}}^2] + \gamma T_t +
   \sum_{i=1}^N l(y_i, \hat y^{(t)}) \\

& = \sum_{j=1}^{T_t} [G_i w_j^{(t)} + \frac 1 2
   (H_j + \lambda)(w_j^{(t)})^2] + \gamma T_t +
   \sum_{i=1}^N l(y_i, \hat y^{(t)}) \\

\end{align*}</script><blockquote>
<ul>
<li>$f_t, T_t$：第t棵回归树、树叶子节点</li>
<li>$f_t(x_i)$：第t棵回归树对样本$x_i$的预测得分</li>
<li>$w_j^{(t)} = f_t(x)$：第t棵树中第j叶子节点预测得分</li>
<li>$g<em>i = \partial</em>{\hat y} l(y_i, \hat y^{t-1})$</li>
<li>$h<em>i = \partial^2</em>{\hat y} l(y_i, \hat y^{t-1})$</li>
<li>$I_j$：第j个叶结点集合</li>
<li>$G<em>j = \sum</em>{i \in I_j} g_i$</li>
<li>$H<em>j = \sum</em>{i \in I_j} h_i$</li>
</ul>
</blockquote>
<ul>
<li><p>对回归树，正则项中含有$(w_j^{(t)})^2$作为惩罚，能够
和损失函数二阶导合并，不影响计算</p>
</li>
<li><p>模型复杂度惩罚项惩罚项是针对树的，定义在叶子节点上，
而平方损失是定义在样本上，合并时将其改写</p>
</li>
</ul>
</li>
<li><p>第t棵树的整体损失等于<strong>其各叶子结点损失加和</strong>，且
各叶子结点取值之间独立</p>
<ul>
<li><p>则第t棵树各叶子结点使得损失最小的最优取值如下
（$G_j, H_j$是之前所有树的预测得分和的梯度取值，在
当前整棵树的构建中是定值，所以节点包含样本确定后，
最优取值即可确定）</p>
<script type="math/tex; mode=display">
w_j^{(*)} = -\frac {\sum_{i \in I_j} g_i}
  {\sum_{i \in I_j} h_i + \lambda}
= -\frac {G_j} {H_j + \lambda}</script></li>
<li><p>整棵树结构分数（最小损失）带入即可得</p>
<script type="math/tex; mode=display">
obj^{(t)} = -\frac 1 2 \sum_{j=i}^M \frac {G_j^2}
  {H_j + \lambda} + \gamma T</script></li>
<li><p>则在结点分裂为新节点时，树损失变化量为</p>
<script type="math/tex; mode=display">
l_{split} = \frac 1 2 \left [
\frac {(\sum_{i \in I_L} g_i)^2} {\sum_{i \in I_L h_i}
  + \lambda} +
\frac {(\sum_{i \in I_R} g_i)^2} {\sum_{i \in I_R h_i}
  + \lambda} -
\frac {(\sum_{i \in I} g_i)^2} {\sum_{i \in I h_i} +
  \lambda}
\right ] - \gamma</script><blockquote>
<ul>
<li>$I_L, I_R$：结点分裂出的左、右结点</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>则最后应根据树损失变化量确定分裂节点、完成树的分裂，精确
贪心分裂算法如下</p>
<p><a href="/imgs/xgb_exact_greedy_algorithm_for_split_finding.png">!xgb_exact_greedy_algorithm_for_split_finding</a></p>
<ul>
<li><p>对于连续型特征需遍历所有可能切分点</p>
<ul>
<li>对特征排序</li>
<li>遍历数据，计算上式给出的梯度统计量、损失变化</li>
</ul>
</li>
<li><p>不适合数据量非常大、或分布式场景</p>
</li>
</ul>
</li>
</ul>
<h4 id="模型细节"><a href="#模型细节" class="headerlink" title="模型细节"></a>模型细节</h4><ul>
<li><p><em>shrinkage</em>：对新学习的树使用系数$\eta$收缩权重</p>
<ul>
<li>类似SGD中学习率，降低单棵树的影响，给后续基模型留下
学习空间</li>
</ul>
</li>
<li><p><em>column subsampling</em>：列抽样</p>
<ul>
<li>效果较传统的行抽样防止过拟合效果更好
（XGB也支持行抽样）</li>
<li>加速计算速度</li>
</ul>
</li>
</ul>
<h3 id="XGB树分裂算法"><a href="#XGB树分裂算法" class="headerlink" title="XGB树分裂算法"></a>XGB树分裂算法</h3><blockquote>
<ul>
<li>线性回归作为基学习器时，XGB相当于L0、L2正则化的
  Logistic回归、线性回归</li>
</ul>
</blockquote>
<h4 id="近似分割算法"><a href="#近似分割算法" class="headerlink" title="近似分割算法"></a>近似分割算法</h4><p>XGB近似分割算法：根据特征分布选取分位数作为候选集，将连续
特征映射至候选点划分桶中，统计其中梯度值、计算最优分割点</p>
<p><a href="/imgs/xgb_approximate_algorithm_for_split_finding.png">!xgb_approximate_algorithm_for_split_finding</a></p>
<ul>
<li><p>全局算法：在树构建初始阶段即计算出所有候选分割点，之后
所有构建过程均使用同样候选分割点</p>
<ul>
<li>每棵树只需计算一次分割点的，步骤少</li>
<li>需要计算更多候选节点才能保证精度</li>
</ul>
</li>
<li><p>局部算法：每次分裂都需要重新计算候选分割点</p>
<ul>
<li>计算步骤多</li>
<li>总的需要计算的候选节点更少</li>
<li>适合构建较深的树</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>分位点采样算法参见
  <em>ml_model/model_enhancement/gradient_boost</em></li>
</ul>
</blockquote>
<h4 id="Sparsity-aware-Split-Finding"><a href="#Sparsity-aware-Split-Finding" class="headerlink" title="Sparsity-aware Split Finding"></a>Sparsity-aware Split Finding</h4><p>稀疏特点分裂算法：为每个树节点指定默认分裂方向，缺失值对应
样本归为该方向</p>
<p><img src="/imgs/xgb_sparsity_aware_split_finding.png" alt="xgb_sparsity_aware_split_finding"></p>
<ul>
<li><p>仅处理非缺失值，算法复杂度和随无缺失数据集大小线性增加，
减少计算量</p>
</li>
<li><p>按照升许、降序分别扫描样本两轮，以便将缺失值样本分别归为
两子节点，确定最优默认分裂方向</p>
<p><img src="/imgs/xgb_sparsity_aware_split_finding_example.png" alt="xgb_sparsity_aware_split_finding_example"></p>
</li>
</ul>
<h3 id="XGB系统设计"><a href="#XGB系统设计" class="headerlink" title="XGB系统设计"></a>XGB系统设计</h3><h4 id="Column-Block-for-Parallel-Learning"><a href="#Column-Block-for-Parallel-Learning" class="headerlink" title="Column Block for Parallel Learning"></a>Column Block for Parallel Learning</h4><blockquote>
<ul>
<li>建树过程中最耗时的部分为寻找最优切分点，而其中最耗时部分
  为数据排序</li>
</ul>
</blockquote>
<p>XGB对每列使用block结构存储数据</p>
<ul>
<li><p>每列block内数据为CSC压缩格式</p>
<ul>
<li>特征排序一次，之后所有树构建可以复用（忽略缺失值）</li>
<li>存储样本索引，以便计算样本梯度</li>
<li>方便并行访问、处理所有列，寻找分裂点</li>
</ul>
</li>
<li><p>精确贪心算法：将所有数据（某特征）放在同一block中</p>
<ul>
<li>可同时对所有叶子分裂点进行计算</li>
<li>一次扫描即可得到所有叶子节点的分割特征点候选者统计
数据</li>
</ul>
</li>
<li><p>近似算法：可以使用多个block、分布式存储数据子集</p>
<ul>
<li>对local策略提升更大，因为local策略需要多次生成分位点
候选集</li>
</ul>
</li>
</ul>
<h4 id="Cache-aware-Access"><a href="#Cache-aware-Access" class="headerlink" title="Cache-aware Access"></a>Cache-aware Access</h4><blockquote>
<ul>
<li>列block结构通过索引获取数据、计算梯度，会导致非连续内存
  访问，降低CPU cache命中率</li>
</ul>
</blockquote>
<ul>
<li><p>精确贪心算法：使用<em>cache-aware prefetching</em></p>
<ul>
<li>对每个线程分配连续缓冲区，读取梯度信息存储其中，再
统计梯度信息</li>
<li>对样本数量较大时更有效</li>
</ul>
</li>
<li><p>近似算法：合理设置block大小为block中最多的样本数</p>
<ul>
<li>过大容易导致命中率低、过小导致并行化效率不高</li>
</ul>
</li>
</ul>
<h4 id="Blocks-for-Out-of-core-Computation"><a href="#Blocks-for-Out-of-core-Computation" class="headerlink" title="Blocks for Out-of-core Computation"></a>Blocks for Out-of-core Computation</h4><ul>
<li><p>数据量过大不能全部存放在主存时，将数据划分为多个block
存放在磁盘上，使用独立线程将block读入主存
（这个是指数据划分为块存储、读取，不是列block）</p>
</li>
<li><p>磁盘IO提升</p>
<ul>
<li><em>block compression</em>：将block按列压缩，读取后使用额外
线程解压</li>
<li><em>block sharding</em>：将数据分配至不同磁盘，分别使用线程
读取至内存缓冲区</li>
</ul>
</li>
</ul>
<h2 id="分位点采样算法—XGB"><a href="#分位点采样算法—XGB" class="headerlink" title="分位点采样算法—XGB"></a>分位点采样算法—XGB</h2><h3 id="Quantile-Sketch"><a href="#Quantile-Sketch" class="headerlink" title="Quantile Sketch"></a>Quantile Sketch</h3><h4 id="样本点权重"><a href="#样本点权重" class="headerlink" title="样本点权重"></a>样本点权重</h4><blockquote>
<ul>
<li>根据已经建立的$t-1$棵树可以得到数据集在已有模型上误差，
  采样时根据误差对样本分配权重，对误差大样本采样粒度更大</li>
</ul>
</blockquote>
<ul>
<li><p>将树按样本点计算损失改写如下</p>
<script type="math/tex; mode=display">
\sum_{i=1}^N \frac 1 2 h_i(f_t(x_i) - \frac {g_i} {h_i})^2
   + \Omega(f_t) + constant</script></li>
<li><p>则对各样本，其损失为$f_t(x_i) - \frac {g_i} {h_i}$
平方和$h_i$乘积，考虑到$f_t(x_i)$为样本点在当前树预测
得分，则可以</p>
<ul>
<li>将样本点损失视为“二次损失”</li>
<li>将$\frac {g_i} {h_i}$视为样本点“当前标签”</li>
<li>相应将$h_i$视为<strong>样本点权重</strong></li>
</ul>
</li>
<li><p>样本权重取值示例</p>
<ul>
<li>二次损失：$h_i$总为2，相当于不带权</li>
<li>交叉熵损失：$h_i=\hat y(1-\hat y)$为二次函数，
则$\hat y$接近0.5时权重取值大，此时该样本预测值
也确实不准确，符合预期</li>
</ul>
</li>
</ul>
<h4 id="Rank函数"><a href="#Rank函数" class="headerlink" title="Rank函数"></a>Rank函数</h4><ul>
<li><p>记集合$D={(x_1, h_1), \cdots, (x_n, h_n)}$</p>
</li>
<li><p>定义rank函数$r_D: R \rightarrow [0, +\infty)$如下</p>
<script type="math/tex; mode=display">
r_D(z) = \frac 1 {\sum_{(x, h) \in D} h}
   \sum_{(x, h) \in D, x < z} h</script><ul>
<li>即集合$D$中权重分布中给定取值分位数</li>
<li>即取值小于给定值样本加权占比，可视为加权秩</li>
</ul>
</li>
</ul>
<h4 id="分位点抽样序列"><a href="#分位点抽样序列" class="headerlink" title="分位点抽样序列"></a>分位点抽样序列</h4><ul>
<li><p>分位点抽样即为从集合$D$特征值中抽样，找到升序点序列
$S = {s_1, \cdots, s_l}$满足</p>
<script type="math/tex; mode=display">
|r_D(s_j - r_D(s_{j+1})| < \epsilon</script><blockquote>
<ul>
<li>$\epsilon$：采样率，序列长度$l = 1/\epsilon$</li>
<li>$s<em>1 = \min</em>{i} x_i$：特征最小值</li>
<li><p>$s<em>l = \max</em>{i} x_i$：特征最大值</p>
</li>
<li><p>各样本等权分位点抽样已有成熟方法，加权分位点抽样方法
 为XGB创新，如下</p>
</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="Weighted-Quantile-Sketch"><a href="#Weighted-Quantile-Sketch" class="headerlink" title="Weighted Quantile Sketch"></a>Weighted Quantile Sketch</h3><h4 id="Formalization"><a href="#Formalization" class="headerlink" title="Formalization"></a>Formalization</h4><ul>
<li><p>记$D<em>k={(x</em>{1,k}, h<em>1), \cdots, (x</em>{n,k}, h_n)}$为各
训练样本第$k$维特征、对应二阶导数</p>
<ul>
<li>考虑到数据点可能具有相同$x, h$取值，$D_k$为可能包含
重复值的multi-set</li>
</ul>
</li>
<li><p>对于多重集$D$，额外定义两个rank函数</p>
<script type="math/tex; mode=display">\begin{align*}
r_D^{-}(y) & = \sum_{(x,h) \in D, x<y} h \\
r_D^{+}(y) & = \sum_{(x,h) \in D, x \leq y} h
\end{align*}</script><p>定义相应权重函数为</p>
<script type="math/tex; mode=display">
w_D(y) = r_D^{+}(y) - r_D^{-}(y) =
   \sum_{(x,h) \in D, x=y} h</script></li>
<li><p>多重集$D$上全部权重和定义为</p>
<script type="math/tex; mode=display">
w(D) = \sum_{(x, w) \in D} w</script></li>
</ul>
<h4 id="Quantile-Summary-of-Weighted-Data"><a href="#Quantile-Summary-of-Weighted-Data" class="headerlink" title="Quantile Summary of Weighted Data"></a>Quantile Summary of Weighted Data</h4><ul>
<li><p>定义加权数据上的quantile summary为
$Q(D)=(S, \tilde r_D^{+}, \tilde r_D^{-}, \tilde w_D)$</p>
<ul>
<li><p>$S$为$D$中特征取值抽样升序序列，其最小、最大值分别
为$D$中特征最小、最大值</p>
</li>
<li><p>$\tilde r_D^{+}, \tilde r_D^{-}, \tilde w_D$为定义在
$S$上的函数，满足</p>
<script type="math/tex; mode=display">\begin{align*}
\tilde r_D^{-}(x_i) & \leq r_D^{-}(x_i) \\
\tilde r_D^{+}(x_i) & \leq r_D^{+}(x_i) \\
\tilde w_D(x_i) & \leq w_D(x_i) \\
\tilde r_D^{-}(x_i) + \tilde w_D(x_i) & \leq
  \tilde r_D^{-}(x_{i+1}) \\
\tilde r_D^{+}(x_i) + \tilde w_D(x_i) & \leq
  \tilde r_D^{+}(x_{i+1}) \\
\end{align*}</script></li>
</ul>
</li>
<li><p>$Q(D)$满足如下条件时，称为
$\epsilon$-approximate quantile summary</p>
<script type="math/tex; mode=display">
\forall y \in D_X, \tilde r_D^{+}(y) - \tilde r_D(y) -
   \tilde w_D(y) \leq \epsilon w(D)</script><ul>
<li>即对任意$y$的秩估计误差在$\epslion$之内</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>$\phi-quantile$：秩位于$\phi * N$的元素（一般向下取整）</li>
<li>$\epsilon-\phi-quantile$：秩位于区间
  $[(\phi-\epsilon)<em>N, (\phi+\epsilon)</em>N]$的元素</li>
</ul>
</blockquote>
<h4 id="构建-epsilon-Approximate-Qunatile-Summary"><a href="#构建-epsilon-Approximate-Qunatile-Summary" class="headerlink" title="构建$\epsilon$-Approximate Qunatile Summary"></a>构建$\epsilon$-Approximate Qunatile Summary</h4><ul>
<li><p>初始化：在小规模数据集
$D={(x_1,h_1), \cdots, (x_n,h_n)}$上构建初始
初始quantile summary
$Q(D)=(S, \tilde r_D^{+}, \tilde r_D^{-}, \tilde w_D)$
满足</p>
<script type="math/tex; mode=display">\begin{align*}
\tilde r_D^{-}(x_i) & \leq r_D^{-}(x_i) \\
\tilde r_D^{+}(x_i) & \leq r_D^{+}(x_i) \\
\tilde w_D(x_i) & \leq w_D(x_i)
\end{align*}</script><ul>
<li>即初始化$Q(D)$为0-approximate summary</li>
</ul>
</li>
<li><p><em>merge operation</em>：记
$Q(D<em>1)=(S_1, \tilde r</em>{D<em>1}^{+}, \tilde r</em>{D<em>1}^{-}, \tilde w</em>{D<em>1})$、
$Q(D_2)=(S_2, \tilde r</em>{D<em>2}^{+}, \tilde r</em>{D<em>2}^{-}, \tilde w</em>{D_2})$、
$D = D_1 \cup D_2$，则归并后的
$Q(D)=(S, \tilde r_D^{+}, \tilde r_D^{-}, \tilde w_D)$
定义为</p>
<script type="math/tex; mode=display">\begin{align*}
S & S_1 \cup S_2 \\
\tilde r_D^{-}(x_i) & = \tilde r_{D_1}^{-}(x_i) +
   \tilde r_{D_2}^{-}(x_i) \\
\tilde r_D^{+}(x_i) & = \tilde r_{D_1}^{+}(x_i) +
   \tilde r_{D_2}^{+}(x_i) \\
\tilde w_D(x_i) & = \tilde w_{D_1}(x_i) +
   \tilde w_{D_2}(x_i)
\end{align*}</script></li>
<li><p><em>prune operation</em>：从给定
$Q(D)=(S, \tilde r_D^{+}, \tilde r_D^{-}, \tilde w_D)$，
（其中$S = {x_1, \cdots, x_k }$），构建新的summary
$\acute Q(D)=(\acute S, \tilde r_D^{+}, \tilde r_D^{-}, \tilde w_D)$</p>
<ul>
<li><p>仅定义域从$S$按如下操作抽取
$\acute S={\acute x<em>1, \cdots, \acute x</em>{b+1}}$</p>
<script type="math/tex; mode=display">
\acute x_i = g(Q, \frac {i-1} b w(D))</script></li>
<li><p>$g(Q, d)$为查询函数，对给定quantile summary $Q$、
秩$d$返回秩最接近$d$的元素</p>
<p><img src="/imgs/xgb_weighted_quantile_sketch_query_function.png" alt="xgb_weighted_quantile_sketch_query_function"></p>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-14T12:02:42.000Z" title="7/14/2019, 8:02:42 PM">2019-07-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-19T10:13:53.000Z" title="7/19/2021, 6:13:53 PM">2021-07-19</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a></span><span class="level-item">27 minutes read (About 4115 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/machine_learning.html">Data Science</a></h1><div class="content"><h2 id="名词"><a href="#名词" class="headerlink" title="名词"></a>名词</h2><h3 id="Statistic-Frequentist-and-Bayesian"><a href="#Statistic-Frequentist-and-Bayesian" class="headerlink" title="Statistic - Frequentist and Bayesian"></a><em>Statistic - Frequentist and Bayesian</em></h3><p>统计：数学分支，概率论和优化的交集，是数据科学其他分支的理论基础</p>
<ul>
<li><p>分析方法：验证式分析</p>
<ul>
<li>统计建模：基于数据构建统计模型，并验证假设</li>
<li>模型预测：运用模型对数据进行预测、分析</li>
</ul>
</li>
<li><p>理论依据：模型驱动，严格的数理支撑</p>
<ul>
<li>理论体系<ul>
<li>概率论、信息论、计算理论、最优化理论、计算机学科等多个领域的交叉学科</li>
<li>并在发展中形成独自的理论体系、方法论</li>
</ul>
</li>
<li>基本假设：同类数据具有一定的统计规律性，可以用概率统计方法加以处理，推断总体特征，如<ul>
<li>随机变量描述数据特征</li>
<li>概率分布描述数据统计规律</li>
</ul>
</li>
</ul>
</li>
<li><p>分析对象：以样本为分析对象</p>
<ul>
<li>从数据出发，提取数据特征、抽象数据模型、发现数据知识，再回到对数据的分析与预测</li>
<li>数据多种多样，包括数字、文字、图像、音视频及其组合</li>
<li>假设数据独立同分布产生</li>
<li>训练数据集往往是人工给出的</li>
</ul>
</li>
</ul>
<h3 id="Data-Mining"><a href="#Data-Mining" class="headerlink" title="Data Mining"></a><em>Data Mining</em></h3><ul>
<li><p>从现有的信息中提取数据的 <em>pattern</em>、<em>model</em>，即精选最重要、可理解的、有价值的信息</p>
<ul>
<li>核心目的在于找到 <strong>数据变量之间的关系</strong></li>
<li><strong>不是证明假说的方法，而是构建假说的方法</strong></li>
<li><strong>大数据</strong> 的发展，传统的数据分析方式无法处理大量“不相关”数据</li>
</ul>
</li>
<li><p>常用技术</p>
<ul>
<li><em>cluster analysis</em>：聚类分析，揭示数据内在结构</li>
<li><em>classification</em>：判别分析，数据预测</li>
<li><em>regression/decision trees</em>：决策树，模型图形化展示</li>
<li><em>neural networks</em>：神经网络</li>
</ul>
</li>
<li><p>联系</p>
<ul>
<li>本质上看起来像是 <em>ML</em>、<em>AI</em> 的基础</li>
<li>会使用大量机器学习算法，但是特定的环境、目的和ML不同</li>
</ul>
</li>
<li><p>建模一般策略：类似机器学习</p>
<ul>
<li>将数据视为高维空间中的点，在高维空间中找到分类面、回归面</li>
</ul>
</li>
</ul>
<h3 id="Artificial-Intelligence"><a href="#Artificial-Intelligence" class="headerlink" title="Artificial Intelligence"></a><em>Artificial Intelligence</em></h3><ul>
<li>研究如何创造智能 <em>agent</em>，并不一定涉及学习、归纳</li>
<li>但是大部分情况下，<strong>智能</strong> 需要从过去的经验中进行归纳，所以 <em>AI</em> 中很大一部分是 <em>ML</em></li>
</ul>
<h2 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a><em>Machine Learning</em></h2><p>机器学习：从有限观测数据中学习一般性规律，并将规律应用到未观测样本中进行预测（最基本的就是在不确定中得出结论）</p>
<ul>
<li>分析方法：归纳式、探索式分析</li>
<li>理论依据：数据驱动，从数据中中学习知识，</li>
<li>分析对象：对样本要求低，样本往往不具有随机样本的特征</li>
<li>机器学习建模：不假设，通过对高维空间的搜索，找到数据隐藏规律的恰当概括</li>
</ul>
<h3 id="Shallow-Learning"><a href="#Shallow-Learning" class="headerlink" title="Shallow Learning"></a><em>Shallow Learning</em></h3><p>浅层学习：不涉及特征学习，特征抽取依靠人工经验、特征转换方法</p>
<p><img src="/imgs/shallowing_learning_procedures.png" alt="shallowing_learning_procedures.png"></p>
<ul>
<li><p>传统机器学习可以视为浅层学习</p>
</li>
<li><p>步骤</p>
<ul>
<li>数据预处理</li>
<li>特征提取</li>
<li>特征转换</li>
<li>预测</li>
</ul>
</li>
</ul>
<h3 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a><em>Deep Learning</em></h3><p>深度学习：将原始数据特征通过多步特征转换得到更高层次、抽象的特征表示，进一步输入到预测函数得到最终结果</p>
<p><img src="/imgs/deep_learning_procedures.png" alt="deep_learning_procedures"></p>
<ul>
<li><p>主要目的是从数据中自动学习到<strong>有效的特征表示</strong></p>
<ul>
<li>替代人工设计的特征，避免“特征”工程</li>
<li>模型深度不断增加，特征表示能力越强，后续预测更容易</li>
</ul>
</li>
<li><p>相较于浅层学习：需要解决的关键问题是<strong>贡献度分配问题</strong></p>
<ul>
<li>从某种意义上说，深度学习也可以视为强化学习</li>
<li>内部组件不能直接得到监督信息，需要通过整个模型的最终监督信息得到，有延时</li>
</ul>
</li>
<li><p>目前深度学习模型主要是神经网络模型</p>
<ul>
<li>神经网络可以使用反向传播算法，较好的解决贡献度分配问题</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li><p><em>credit assignment problem</em>：贡献度分配问题，系统中不同组件、参数对最终系统输出结果的贡献、影响</p>
</li>
<li><p>深度：原始数据进行<strong>非线性特征转换的次数</strong>，将深度学习系统看作有向图结构，深度可以看作是从输入节点到输出节点经过最长路径长度</p>
</li>
</ul>
</blockquote>
<h3 id="Representing-Learning"><a href="#Representing-Learning" class="headerlink" title="Representing Learning"></a><em>Representing Learning</em></h3><p>表示学习：自动学习有效特征、提高最终机器学习模型性能的学习</p>
<ul>
<li><p>好的学习标准</p>
<ul>
<li>较强的表示能力：同样大小向量可以表示更多信息</li>
<li>简化后续学习任务：需要包含更高层次语义信息</li>
<li>具有一般性，是任务、领域独立的：期望学到的表示可以容易迁移到其他任务</li>
</ul>
</li>
<li><p>要学习好的高层语义（分布式表示），需要从底层特征开始，经过多步非线程转换得到</p>
<ul>
<li>深层结构的优点式可以增加特征重用性，指数级增加表示能力</li>
<li>所以表示学习的关键是构建具有一定深度、多层次特征表示</li>
</ul>
</li>
<li><p>传统机器学习中也有关于特征学习的算法，如：主成分分析、线性判别分析、独立成分分析</p>
<ul>
<li>通过认为设计准则，用于选取有效特征</li>
<li>特征学习、最终预测模型的学习是分开进行的，学习到的特征不一定可以用于提升最终模型分类性能</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li><em>Semantic Gap</em>：语义鸿沟，输入数据底层特征和高层语义信息之间不一致性、差异性</li>
</ul>
</blockquote>
<h4 id="表示"><a href="#表示" class="headerlink" title="表示"></a>表示</h4><ul>
<li><p><em>Local Representation</em>：局部表示，离散表示/符号表示</p>
<ul>
<li>通常可以表示为 <em>one-hot</em> 向量形式<ul>
<li>每个特征作为高维局部表示空间中轴上点</li>
</ul>
</li>
<li>不足<ul>
<li><em>one-hot</em> 维数很高、不方便扩展</li>
<li>不同特征取值相似度无法衡量</li>
</ul>
</li>
</ul>
</li>
<li><p><em>Distributed Representation</em>：分布式表示</p>
<ul>
<li>通常可以表示为 <strong>低维、稠密</strong> 向量<ul>
<li>分散在整个低维嵌入空间中中</li>
</ul>
</li>
<li>表示能力强于局部表示<ul>
<li>维数低</li>
<li>容易计算相似度</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>神经网络可以用于将高维局部空间 $R^{|V|}$ 映射到非常低维分布式表示空间 $R^d$</li>
</ul>
</blockquote>
<h3 id="End-to-End-Learning"><a href="#End-to-End-Learning" class="headerlink" title="End-to-End Learning"></a><em>End-to-End Learning</em></h3><p>端到端学习/训练：学习过程中不进行分模块、分阶段训练，直接优化任务的总体目标</p>
<ul>
<li>不需要给出不同模块、阶段功能，中间过程不需要认为干预</li>
<li>训练数据为“输入-输出”对形式，无需提供其他额外信息</li>
<li>和深度学习一样，都是要解决“贡献度分配”问题<ul>
<li>大部分神经网络模型的深度学习可以看作是端到端学习</li>
</ul>
</li>
</ul>
<h2 id="Learning-Components"><a href="#Learning-Components" class="headerlink" title="Learning Components"></a><em>Learning Components</em></h2><h3 id="Model-Hypothesis-Opimizee-Learner-Learning-Algorithm"><a href="#Model-Hypothesis-Opimizee-Learner-Learning-Algorithm" class="headerlink" title="Model/Hypothesis/Opimizee/Learner/Learning Algorithm"></a><em>Model</em>/<em>Hypothesis</em>/<em>Opimizee</em>/<em>Learner</em>/<em>Learning Algorithm</em></h3><p>模型/假说/优化对象/学习器/学习算法：待学习的条件概率分布 $P(Y|X)$、决策函数 $Y=f(X)$</p>
<ul>
<li>概率模型：适合用条件概率分布 $P(Y|X)$ 表示的模型</li>
<li>非概率模型：用决策函数 $Y=f(x)$ 表示的模型</li>
</ul>
<blockquote>
<ul>
<li><em>learner</em>：某类模型的总称</li>
<li><em>hypothesis</em>：训练好的模型实例，有时也被强调作为学习器应用在某个样本集（如训练集）上得到的结果</li>
<li><em>learning algorithm</em>：模型、策略、算法三者的模型总体</li>
</ul>
</blockquote>
<h4 id="Hypothesis-Space"><a href="#Hypothesis-Space" class="headerlink" title="Hypothesis Space"></a><em>Hypothesis Space</em></h4><p>假设空间：特征空间（输入空间）到输出空间的映射集合</p>
<ul>
<li><p>假设空间可以定义为决策函数/条件概率的集合，通常是由参数向量 $\theta$ 决定的函数/条件分布族</p>
<ul>
<li>假设空间包含所有可能的条件概率分布或决策函数</li>
<li>假设空间的确定意味着学习范围的确定</li>
</ul>
</li>
<li><p>概率模型假设空间可表示为：$F={P|P_{\theta}(Y|X), \theta \in R^n}$</p>
</li>
<li><p>非概率模型假设空间可表示为：$F={f|Y=f(x),\Theta \in R^n }$</p>
</li>
</ul>
<blockquote>
<ul>
<li>以下大部分情况使用决策函数，同时也可以代表概率分布</li>
</ul>
</blockquote>
<h3 id="Strategy-Goal"><a href="#Strategy-Goal" class="headerlink" title="Strategy/Goal"></a><em>Strategy</em>/<em>Goal</em></h3><p>策略/目标：从假设空间中，根据 <em>evaluation criterion</em> 选择最优模型，使得其对已知训练数据、未知训练数据在给定评价准则下有最优预测</p>
<ul>
<li><p>选择合适策略，监督学习问题变为经验风险、结构风险函数 <strong>最优化问题</strong></p>
</li>
<li><p>在某些学习方法中，最优化问题目标函数也有可能不是风险函数，如：<em>SVM</em>，是和模型紧密相关的损失函数，但逻辑是一样的</p>
</li>
</ul>
<h4 id="Empirical-Risk-Minimiation"><a href="#Empirical-Risk-Minimiation" class="headerlink" title="Empirical Risk Minimiation"></a><em>Empirical Risk Minimiation</em></h4><p><em>ERM</em>：经验风险最小化策略认为，经验风险最小模型就是最优模型</p>
<ul>
<li><p>按经验风险最小化求最优模型，等价于求最优化问题</p>
<script type="math/tex; mode=display">
\min_{f \in F} \frac 1 N \sum_{i=1}^N L(y_i, f(x_i))</script></li>
<li><p>样本容量足够大时，经验风险最小化能保证有较好的学习效果，现实中也被广泛采用</p>
</li>
</ul>
<h4 id="Structural-Risk-Minimization"><a href="#Structural-Risk-Minimization" class="headerlink" title="Structural Risk Minimization"></a><em>Structural Risk Minimization</em></h4><p><em>SRM</em>：结构风险最小化，为防止过拟合提出的策略</p>
<ul>
<li><p>结构化风险最小化策略认为结构风险最小的模型是最优模型，则求解最优模型等价于求解最优化问题</p>
<script type="math/tex; mode=display">
arg \min_{f \in F} \frac 1 N \sum_{i=1}^N L(y_i, f(x_i)) + \lambda J(f)</script></li>
<li><p>结构风险小需要经验风险与模型复杂度同时小，此时模型往往对训练数据、未知的测试数据都有较好的预测</p>
</li>
<li><p>结构化风险最小策略符合 <em>Occam’s Razor</em> 原理</p>
</li>
</ul>
<blockquote>
<ul>
<li><em>Occam’s Razor</em>：奥卡姆剃刀原理，在所有可能选择的模型中，能够很好的解释已知数据并且十分简单才是最好的模型</li>
</ul>
</blockquote>
<h3 id="Algorithm-Optimizer"><a href="#Algorithm-Optimizer" class="headerlink" title="Algorithm/Optimizer"></a><em>Algorithm</em>/<em>Optimizer</em></h3><p>算法/优化器：学习模型（选择、求解最优模型）的具体计算方法
（求解最优化问题）</p>
<ul>
<li><p>如果最优化问题有显式解析解，比较简单</p>
</li>
<li><p>但通常解析解不存在，需要用数值计算方法求解</p>
<ul>
<li>保证找到全局最优解</li>
<li>高效求解</li>
</ul>
</li>
</ul>
<h2 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a><em>Supervised Learning</em></h2><p>监督学习：学习一个模型，使得模型能够对任意给定输入、输出，做出好的预测</p>
<ul>
<li><p>从给定的、有限的、用于学习的 <em>train data</em> $T={(x_1,y_1), (x_2,y_2), \cdots, (x_N, y_N)}$ 中学习</p>
</li>
<li><p>预测 “未知” <em>test data</em> $T={(x_1,y_1), (x_2,y_2), \cdots, (x_N^{‘}, y_N^{‘})}$</p>
</li>
</ul>
<h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><ul>
<li><em>input space</em>：输入空间 $\chi$，所有输入 $X$ 可能取值的集合</li>
<li><em>output space</em>：输出空间 $\gamma$，所有输出 $Y$ 可能取值集合</li>
<li><em>feature space</em>：特征空间，表示输入实例 <em>feature vector</em> 存在的空间<ul>
<li>特征空间每维对应一个特征</li>
<li>模型实际上是定义在特征空间上的</li>
<li>特征空间是输入空间的象集，有时等于输入空间</li>
</ul>
</li>
</ul>
<h3 id="学习方法分类"><a href="#学习方法分类" class="headerlink" title="学习方法分类"></a>学习方法分类</h3><h4 id="Generative-Approach"><a href="#Generative-Approach" class="headerlink" title="Generative Approach"></a><em>Generative Approach</em></h4><p>生成方法：由数据学习联合概率分布 $P(X, Y)$，然后求出条件概率分布 $P(Y|X)$ 作为 <em>generative model</em></p>
<ul>
<li>方法学习给定输入X产生输出Y的生成关系（联合概率分布）</li>
<li><p><em>generative model</em>：生成模型，由生成方法学习到的模型 $P(Y|X) = \frac {P(X, Y)} {P(X}$</p>
<ul>
<li>朴素贝叶斯法</li>
<li>隐马尔可夫模型</li>
</ul>
</li>
<li><p>特点</p>
<ul>
<li>可以还原联合概率分布 $P(X, Y)$</li>
<li>生成方法学习收敛速度快，样本容量增加时，学习到的模型可以快速收敛到真实模型</li>
<li>存在隐变量时，仍可以使用生成方法学习</li>
</ul>
</li>
</ul>
<h4 id="Discriminative-Approach"><a href="#Discriminative-Approach" class="headerlink" title="Discriminative Approach"></a><em>Discriminative Approach</em></h4><p>判别方法：由数据直接学习决策函数 $f(x)$、条件概率分布 $P(Y|X)$ 作为 <em>discriminative model</em></p>
<ul>
<li><p>判别方法关心的是对给定输入 $X$，预测输出$Y$</p>
</li>
<li><p><em>discriminative model</em>：判别模型</p>
<ul>
<li><em>KNN</em></li>
<li>感知机</li>
<li>决策树</li>
<li>逻辑回归</li>
<li>最大熵模型</li>
<li>支持向量机</li>
<li>提升方法</li>
<li>条件随机场</li>
</ul>
</li>
<li><p>特点</p>
<ul>
<li>直接学习条件概率、决策函数</li>
<li>直面预测，学习准确率更高</li>
<li>可以对数据进行各种程度抽象、定义特征、使用特征，简化学习问题</li>
</ul>
</li>
</ul>
<h3 id="问题分类"><a href="#问题分类" class="headerlink" title="问题分类"></a>问题分类</h3><ul>
<li><p><em>well-posed problem</em>：好解问题，指问题解应该满足以下条件</p>
<ul>
<li>解存在</li>
<li>解唯一</li>
<li>解行为随着初值<strong>连续变化</strong></li>
</ul>
</li>
<li><p><em>ill-posed problem</em>：病态问题，解不满足以上三个条件</p>
</li>
</ul>
<h4 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a><em>Classification</em></h4><p>分类问题：输出变量$Y$为有限个离散变量</p>
<ul>
<li>学习过程：根据已知训练数据集，利用有效学习方法学习分类器 $P(Y|X))$、$Y=F(X)$</li>
<li>分类过程：利用学习的分类器对新输入实例进行分类</li>
<li><p>可用学习方法</p>
<ul>
<li><em>KNN</em></li>
<li>感知机</li>
<li>朴素贝叶斯</li>
<li>决策树</li>
<li>决策列表</li>
<li>逻辑回归</li>
<li>支持向量机</li>
<li>提升方法</li>
<li>贝叶斯网络</li>
<li>神经网络</li>
</ul>
</li>
<li><p>不存在分类能力弱于随机预测的分类器（结论取反）</p>
</li>
</ul>
<h4 id="Tagging"><a href="#Tagging" class="headerlink" title="Tagging"></a><em>Tagging</em></h4><p>标注问题：输入、输出 <strong>均为变量序列</strong></p>
<ul>
<li>可认为是分类问题的一个推广、更复杂 <em>structure prediction</em> 简单形式</li>
<li>学习过程：利用已知训练数据集构建条件概率分布模型 $P(Y^{(1)}, Y^{(2)}, \cdots, Y^{(n)}|X^{(1)}, X^{(2)}, \cdots, X^{(n)})$<blockquote>
<ul>
<li>$X^{(1)}, X^{(2)}, \cdots, X^{(n)}$：每个输入序列</li>
<li>$Y^{(1)}, Y^{(2)}, \cdots, Y^{(n)}$：所有可能标记</li>
</ul>
</blockquote>
</li>
<li>标注过程：按照学习到的条件概率分布，标记新的输入观测序列</li>
<li>可用模型<ul>
<li>隐马尔可夫模型</li>
<li>条件随机场</li>
</ul>
</li>
</ul>
<h4 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a><em>Regression</em></h4><p>回归问题：输入（自变量）、输出（因变量）均为连续变量</p>
<ul>
<li>回归模型的拟合等价于函数拟合：选择函数曲线很好的拟合已知数据，且很好的预测未知数据</li>
<li>学习过程：基于训练数据构架模型（函数）$Y=f(X)$<ul>
<li>最常用损失函数是平方损失函数，此时可以使用最小二乘求解</li>
</ul>
</li>
<li>预测过程：根据学习到函数模型确定相应输出</li>
</ul>
<h2 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a><em>Unsupervised Learning</em></h2><p>无监督学习：没有给定实现标记过的训练示例，自动对输入的数据进行分类</p>
<ul>
<li>主要目标：预训练一般模型（称识别、编码）网络，供其他任务使用</li>
<li>目前为止，有监督模型一般比无监督的预训练模型表现得好<ul>
<li>主要原因：有监督模型对数据的 <strong>特性编码</strong> 更好</li>
</ul>
</li>
</ul>
<h3 id="问题分类-1"><a href="#问题分类-1" class="headerlink" title="问题分类"></a>问题分类</h3><h4 id="Clustering-聚类"><a href="#Clustering-聚类" class="headerlink" title="Clustering 聚类"></a><em>Clustering</em> 聚类</h4><ul>
<li><em>Hierarchy Clustering</em></li>
<li><em>K-means</em></li>
<li><em>Mixture Models</em></li>
<li><em>DBSCAN</em></li>
<li><em>OPTICS Algorithm</em></li>
</ul>
<h4 id="Anomaly-Detection-异常检测"><a href="#Anomaly-Detection-异常检测" class="headerlink" title="Anomaly Detection 异常检测"></a><em>Anomaly Detection</em> 异常检测</h4><ul>
<li><em>Local Outlier Factor</em></li>
</ul>
<h4 id="Neural-Networks-神经网络"><a href="#Neural-Networks-神经网络" class="headerlink" title="Neural Networks 神经网络"></a><em>Neural Networks</em> 神经网络</h4><ul>
<li><em>Auto-encoders</em></li>
<li><em>Deep Belief Nets</em></li>
<li><em>Hebbian Learning</em></li>
<li><em>Generative Adversarial Networks</em></li>
<li><em>Self-organizing Map</em></li>
</ul>
<h4 id="隐变量学习"><a href="#隐变量学习" class="headerlink" title="隐变量学习"></a>隐变量学习</h4><ul>
<li><em>Expectation-maximization Algorithm</em></li>
<li><em>Methods of Moments</em></li>
<li><em>bind signal separation techniques</em><ul>
<li><em>Principal Component analysis</em></li>
<li><em>Independent Component analysis</em></li>
<li><em>Non-negative matrix factorization</em></li>
<li><em>Singular Value Decomposition</em></li>
</ul>
</li>
</ul>
<h2 id="Semi-Supervised-Learning"><a href="#Semi-Supervised-Learning" class="headerlink" title="Semi-Supervised Learning"></a><em>Semi-Supervised Learning</em></h2><p>半监督学习：利用少量标注数据和大量无标注数据进行学习的方式</p>
<ul>
<li>可以利用大量无标注数据提高监督学习的效果</li>
</ul>
<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a><em>Reinforcement Learning</em></h2><p>强化学习：从与环境交互中不断学习的问题、以及解决这类问题的方法</p>
<ul>
<li><p>强化学习问题可以描述为：智能体从与环境的交互中不断学习以完成特定目标</p>
</li>
<li><p>强化学习的关键问题：<strong>贡献度分配问题</strong></p>
<ul>
<li>每个动作不能直接得到监督信息，需要通过整个模型的最终 监督信息得到，且具有时延性</li>
<li>给出的监督信息也非“正确”策略，而是策略的延迟回报，并通过调整策略以取得最大化期望回报</li>
</ul>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/categories/ML-Theory/page/0/">Previous</a></div><div class="pagination-next"><a href="/categories/ML-Theory/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/categories/ML-Theory/">1</a></li><li><a class="pagination-link" href="/categories/ML-Theory/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5385776267343559" data-ad-slot="6995841235" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="https://api.follow.it/subscription-form/WWxwMVBsOUtoNTdMSlJ4Z1lWVnRISERsd2t6ek9MeVpEUWs0YldlZGxUdXlKdDNmMEZVV1hWaFZFYWFSNmFKL25penZodWx3UzRiaVkxcnREWCtOYUJhZWhNbWpzaUdyc1hPangycUh5RTVjRXFnZnFGdVdSTzZvVzJBcTJHKzl8aXpDK1ROWWl4N080YkFEK3QvbEVWNEJuQjFqdWdxODZQcGNoM1NqbERXST0=/8" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>