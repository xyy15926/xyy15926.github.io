{"pages":[],"posts":[{"title":"","text":"AHAA depository for all kinds of configuration files and notes","link":"/uncategorized/README.html"},{"title":"Database Parser","text":"Parser综述Parser：分析器，将SQL语句切分为token，根据一定语义规则解析 成AST todo查询计划/树 查询计划：由一系列内部操作符组成，操作符按照一定运算关系构成 查询的一个执行方案 形式上：二叉树 树叶是每个单表对象 两个树叶的父节点是连接操作符连接后的中间结果 每个结点即临时“关系” 查询的基本操作：选择、投影、连接 选择、投影的优化规则适用于select-projection-join 操作和非SPY（SPY+Groupby）操作 连接操作包括两表连接、多表连接 结点类型 单表结点：从物理存储到内存解析称逻辑字段的过程 考虑数据获取方式 直接IO获取 索引获取 通过索引定位数据位置后再经过IO获取相应数据块 两表结点：内存中元组进行连接的过程 完成用户语义的局部逻辑操作，完成用户全部语义需要配合 多表连接顺序的操作 不同连接算法导致连接效率不同 考虑两表 连接方式 代价 连接路径 多表中间结点：多个表按照“最优”顺序连接过程 考虑代价最小的“执行计划”的多表连接顺序 Schema Catalog元数据信息：表的模式信息 表的基本定义：表名、列名、数据类型 表的数据格式：json、text、parquet、压缩格式 表的物理位置","link":"/Database/parser.html"},{"title":"物理查询优化","text":"查询代价估算代价模型代价估计模型：基于CPU代价、IO代价 \\begin{align*} 总代价 &= IO代价 + CPU代价 \\\\ COST &= P * CPUTimePerPage + W * T \\end{align*} $P$：计划访问的页面数 $CPUTimePerPage$：读取每个页面的时间花费 $T$：访问的元组数，索引扫描应包括索引读取花费 反映CPU代价，因为访问页面上的元组需要解析元组结构， 消耗CPU $W$：selectivity，选择率/权重因子，表明IO、CPU的相关性 Selectivity选择率：在关系R中，满足条件A &lt;cond_op&gt; a的元组数R和 所有元组数N的比值 在CBO中占有重要地位 其精确程度直接影响最优计划的选择 估计方法 Non-Parametric Method：非参方法，使用ad-hoc数据结构、 直方图维护属性值分布 Parametric Method：参数方法，使用预先估计的分布函数 逼近真实分布 Curve Fitting：曲线拟合法，使用多项式函数、最小标准差 逼近属性值分布 Sampling：抽样法，从数据库中抽取部分元组，针对样本进行 查询，收集统计数据 需要足够多样本被测试才能达到足够精度 综合法 单表扫描算法索引两表联接算法todoNested Loop嵌套循环联接算法：扫描外表，读取记录根据join字段上的 索引去内表中查询 适合场景 外表记录较少（&lt;1w） 内表已经创建索引、性能较好 inner、left outer、left semi、left antisemi join 嵌套循环联接算法 搜索时扫描整个表、索引 1234for each row R1 in the outer table: for each row R2 in the inner table: if R1 join with R2: return (R1, R2) 外部循环逐行消耗外部输入表，当其数据量很大时可以并行扫描 内表 内表被外表驱动：内部循环为每个外部行执行，在内表中搜索 匹配行 基于块嵌套循环联接算法 每次IO申请以“块”为单位尽量读入多个页面 改进获取元组的方式 12345678910for each chunk c1 of t1 if c1 not in memory: read chunk c1 to memory for each row r1 in chunk c1: for each chunk c2 of t2: if c2 not in memory: read chunk c2 into memory for each row r2 in c2: if r1 join with r2: return(R1, R2) 内存循环最后一个块使用后作为下次循环循环使用的第一个块 可以节省一次IO 索引嵌套循环联接算法 索引嵌套循环连结：在内表中搜索时使用索引，可以加快联接 速度 临时索引嵌套循环连结：为查询临时生成索引作为查询计划的 一部分，查询完成后立刻将索引破坏 (Sort)Merge Join排序归并联接算法 适合场景 联接字段已经排序，如B+树索引 inner、left outer、left semi、left anti semi、 right outer、right semi、right anti semi join、union 等值、非等值联接，除!=/&lt;&gt; 算法 确保两个关联表都是按照关联字段进行排序 若关联字段已经有排序一致的可用索引，可以利用索引直接 进行merge join操作 否则先对关联字段进行排序，表过大无法一次载入内存时 需要分块载入 从每个表分别取记录开始匹配（升序） 若符合关联条件，放入结果集 否则丢关联字段较小记录，取对应表中下条记录继续 匹配，直到整个循环结束 对于多对join，通常需要使用临时表进行操作todo Hash Join哈希联接：利用Hash Match联接 HJ处理代价非常高，是服务器内存、CPU头号杀手，需要对数据 进行分区时，还会造成大量异步磁盘I/O，避免大数据的HJ， 尽量转化为高效的SMJ、NLJ 表结构设计：冗余字段 索引调整设计 SQL优化 冗余表：静态表存储统计结果 类似任何hash算法，内存小、数据偏斜严重时，散列冲突会比较 严重，此时应该考虑使用NIJ 适合场景 两表数据量相差非常大 对CPU消耗明显，需要CPU资源充足 只适合（不）等值查询 In-Memory Hash Join build阶段以操作涉及字段为hash key构造hash表 从构造输入表中取记录，使用hash函数生成hash值 hash值对应hash表中的buckets，若一个hash值对应多个桶， 则使用链表将联接桶 构造输入表处理完毕之后，其中记录都被桶关联 build表构建的hash表需要频繁访问，最好能全部加载在内存中 ，因此尽量选择小表，避免使用GHJ probe阶段 从探测输入中取记录，使用同样hash函数生成hash值 根据hash值，在构造阶段构造的hash表中搜索对应桶 为避免冲突，bucket可能会联接到其他bucket，探测操作 会搜索整个冲突链上的buckets查找匹配记录 具体操作以下操作内部实现其实都是hash join，只是对应算符不同而已 join操作 使用join字段计算hash值 使用顶端输入构造hash表，底端输入进行探测 按照联接类型规定的模式输出（不）匹配项 若多个联接使用相同的联接列，这些操作将分组为一个 哈希组 grouby操作、unique操作 使用groupby字段、所有select字段计算hash值 使用输入构造hash表，删除重复项、计算聚合表达式 扫描hash表输出所有项 union操作、需要去除重复记录操作 所有select字段计算hash值 第一个输入构建hash表，删除重复项 第二个输入进行探测 若第二个输入没有重复项，直接返回没有匹配的项， 扫描hash表返回所有项 若第二个输入有重复项，则应该需要继续构建hash表， 最后统一输出整个hash表 Grace Hash Joingrace hash join：磁盘分块HJ 将两表按照相同hash函数分配至不同分片中 在磁盘上为各分片、表建立相应文件 对表输入计算哈希值，根据哈希值写入分片、表对应文件 再对不同分片进行普通in-memory hash join 若分片依然不能全部加载至内存，可以继续使用 grace hash join 123456789101112131415grace_hash_join(t1, t2): // Grace Hash Join实现 // 输入：待join表t1、t2 for row in t1: hash_val = hash_func(row) N = hash_val % PART_COUNT write row to file t1_N for row in t2: hash_val = hash_func(row) N = hash_val % PART_COUNT write row to file t2_N for i in range(0, PART_COUNT): join(t1_i, t2_i) 分片数量PART_COUNT决定磁盘IO效率 分片数量过小：无法起到分治效果，分片仍然需要进行 grace hash join，降低效率 分片数量过大：磁盘是块设备，每次刷盘刷一定数量块才 高效，频繁刷盘不经济 即分片数量在保证刷盘经济的情况下，越大越好，这需要 优化器根据表统计信息确定 特点 有磁盘I/O代价，会降低效率 适合参与join表非常大，无法同时载入内存中 Hybrid Hash Joinhybrid hash join：GHJ基础上结合IMHJ的改进 对build表分片过程中，尽量多把完整分片保留在内存中 对probe表分片时，对应分片可以直接进行probe操作 hybrid hash join有时也被直接视为grace hash join， 不做区分 比较 资源消耗 HJ：CPU计算、内存（磁盘）中创建临时hash表 SMJ：磁盘I/O（扫描表、索引） NLJ：磁盘I/O 性能 通常情况：HJ &gt; NPJ &lt;&gt; SMJ 全表扫描比索引范围扫描再进行表访问更可取时，SMJ 优于NPJ？？？ 而表特别小、特别大时，全表扫描优于索引范围扫描 但若关联字段已排序，SMJ性能最优 首条搜索结果 NPJ能快速返回首条搜索结果 HJ、SMJ返回首条结果较慢 多表联接算法多表联接算法：找到最优连接顺序（执行路径） 表联接顺序对于查询结果没有影响，但是对资源消耗、性能影响 巨大 随着需要联接表数目增加，可能的联接排列非常多，基本不能 对所有可能穷举分析 left-deep tree/linear (processing)tree：$n!$ bushy tree：$\\frac {2(n-1)!} {(n-1)!}$ （包括left-deep tree、right-deep tree） 事实上查询优化器不会穷尽搜索所有可能联接排列，而是使用 启发式算法进行搜索 Dynamic Programming动态规划算法：依次求解各数量表最优联接顺序，直到求出最终结果 构造第一层关系：每个关系的最优路径就是关系的最优单表扫描 方式 迭代依次构造之后n-1层关系联接最优解 左深联接树方式：将第k-1层每个关系同第1层关系联接 紧密树联接方式：将第m(m &gt; 2)层每个关系同第k-m层关系 联接 Heuristic AlgorithmGreedy Algorithm贪心算法：认为每次连接表的连接方式都是最优的，即从未联接表中 选择使得下次联接代价最小者 多表排序一般为 常量表最前 其他表按可访问元组数量升序排序 贪心算法得到的联接方式都是最优的 则每次联接主要求解要联接表对象的最佳访问方式 即每次代价估计的重点在于单表扫描的代价 求解结束后，局部最优查询计划生成 得到左深树 最初始表位于最左下端叶子节点处 System RSystem R：对动态规划算法的改进 保留子树查询最优、次优查询计划，用于上层查询计划生成， 使得查询计划整体较优 Genetic Algorithm遗传算法：模拟自然界生物进化过程，采用人工进化的方式对目标 空间进行搜索 本质是高效、并行、全局搜索方法 能在搜索过程中自动获取、积累有关搜索空间的知识，并自适应 的控制搜索过程以求的最佳解 思想 将问题域中可能解看作是染色体，将其编码为符号串的形式 对染色体群体反复进行基于遗传学的操作：选择、交叉、变异 根据预定目标适应度函数对每个个体进行评价，不断得到更优 群体，从中全局并行搜索得到优化群体中最优个体 实体 population：群体，GA的遗传搜索空间 individual：个体，搜索空间中可能解 chromosome：染色体，个体特征代表 由若干段基因组成 GA中基本操作对象 gene：基因 染色体片段 fitness：适应度，个体对环境的适应程度 基本操作 selection：选择，根据个体适应度在群体中按照一定概率 选择个体作为父本 适应度大个体被选择概率高 体现了适者生存、优胜劣汰的进化规则 crossover：交叉，将父本个体按照一定概率随机交换基因 形成新个体 mutate：变异，按照一定概率随机改变某个体基因值 涉及问题 串编码方式 把问题的各种参数用二进串进行编码构成子串 把子串拼接成染色体 串长度、编码方式对算法收敛影响极大 适应度/对象函数确定 一般可以把问题模型函数作为对象函数 GA超参设置 群体大小$n$：过小难以求出最优解，过大难收敛，一般取 $n = 30 ~ 160$ 交叉概率$P_c$：太小难以前向搜索，太大容易破坏高适应 值结构，一般取$P_c = 0.25 ~ 0.75$ 变异概率$P_m$：太小难以产生新结构，太大则变为单纯 随机搜索，一般取$P_m = 0.01 ~ 0.2$ 算法 随机初始化种群 估初始种群：为种群每个个体计算适应值、排序 若没有达到预定演化数，则继续，否则结束算法 选择父体 杂交：得到新个体 变异：对新个体变异 计算新个体适应值，把适应值排名插入种群，淘汰最后个体 重复3","link":"/Database/optimizer_physical.html"},{"title":"DBMS 查询优化","text":"查询优化技术查询优化技术：求解给定查询语句的高效执行计划过程 目标：在数据库查询优化引擎生成执行策略的过程中，尽量减小 查询总开销 SQL层面上的局部优化，区别于数据库调优的全局优化 广义数据库查询优化 查询重用技术 查询重写规则 查询算法优化技术 并行查询优化技术 分布式查询优化技术 狭义数据库查询优化 查询重写规则：代数/逻辑优化，RBO 查询算法优化技术：非代数/物理优化，CBO 代数/逻辑优化代数/逻辑优化：依据关系代数的等价变换做逻辑变换 语法级：查询语句层、基于语法进行优化 代数级：使用形式逻辑、关系代数原理进行优化 语义级：根据完整性约束，对查询语句进行语义理解，推知可 优化操作 非代数/物理优化非代数/物理优化：根据数据读取、表连接方式、排序等技术对查询 进行优化 物理级：物理优化技术，基于代价估计模型，比较得出各执行 方式中代价最小者 查询算法优化：运用基于代价估算的多表连接算法求解最小 花费计算 查询重用技术查询重用：尽可能利用先前执行的结果，以节约全过程时间、减少 资源消耗 查询结果的重用：分配缓冲块存放SQL语句、最后结果集 查询计划的重用：缓存查询语句执行计划、相应语法树结构 优势：节约CPU、IO消耗 弊端 结果集很大回消耗放大内存资源 同样SQL不同用户获取的结果集可能不完全相同 查询重写规则查询重写：查询语句的等价转换 基于关系代数，关系代数的等价变换规则为查询重写提供了理论 支持 查询重写后，查询优化器可能生成多个连接路径，可以从候选者 中择优 目标 将查询转换为等价、效率更高的形式 低效率谓词转换为高效率谓词 消除重复条件 将查询重写为等价、简单、不受表顺序限制的形式，为 物理查询阶段提供更多选择 优化方向 过程性查询转换为描述性查询：视图重写 复杂查询尽可能转换为多表连接查询：嵌套子查询、外连接、 嵌套连接等 低效率谓词转换为高效率谓词：等价谓词重写 利用（不）等式性质简化where、having、on条件 查询算法优化技术todoRule-Based OptimizerRBO：基于规则的优化器 对AST/LP进行遍历，模式匹配能够满足特定规则的结点，进行 等价转换，得到等价的另一棵树 剪枝：删除一些无用计算 合并：合并多个计算步骤 经验式、启发式的固定transformation，手动设置（硬编码） 在数据库中规则决定SQL执行计划 经典优化规则 predicate pushdown：谓词下推 constant folding：常量累加 column pruning：列值裁剪 combine limits：Limits合并 inner join只访问单表：降为semi join 特点 操作简单、能快速确定连接方式 规则虽然有效但不敏感 数据分布发生变化时，RBO是不感知的 基于RBO生成的执行计划不能确保是最优的 启发式规则只能排除一些明显不好的存取路径 Cost-Base OptimizerCBO：基于成本的优化器 根据SQL的执行成本制定、优化查询作业执行计划，生成可能 的执行计划中代价最小的计划 数据表统计数据 基/势 唯一值数量 空值数量 平均、最大长度 SQL执行路径I/O 网络资源 CPU使用情况 以上执行信息获取方式取决于不同平台、数据库 执行SQL前抽样分析数据 每次执行SQL都会记录统计信息 特殊概念 cardinality：集的势，结果集的行数 表示SQL执行成本值 SQL执行返回的结果集包含的行数越多，成本越大 selectivity：可选择率，施加指定谓语条件后返回 结果集的记录数占未施加任何谓语条件的原始结果集记录数 的比率 值越小，说明可选择性越好 值越大，说明可选择性越差，成本值越大 常见优化规则 hash-join 选择正确hash建表方 选择正确join类型：广播hash、全洗牌hash join reorder：调整多路join顺序 尽量减小中间shuffle数据集大小，达到最优输出 特点 对各种可能情况进行量化比较，可以得到花费最小的情况 CBO本身需要耗费一定资源，需要平衡CBO和查询计划优化程度 数据表的数据统计资源耗费 优化查询计划即时资源耗费，如果组合情况比较多则花费 判断时间较多 并行查询优化技术并行数据库系统中查询优化的目标：寻找具有最小响应时间的查询 执行计划 具有最小执行代价的计划不一定具有最快相应时间，需要考虑 把查询工作分解为可以并行运行的子工作 查询能否并行取决于 系统中可用资源 CPU数目 运算中特定代数运算符 查询并行可以分为 操作内并行：将同一操作如单表扫描、两表连接、排序操作 等分解为多个独立子操作 操作间并行：一条SQL查询语句分解为多个子操作 分布式查询优化技术分布式数据库系统：查询策略优化、局部处理优化是查询优化重点 查询策略优化：主要是数据传输策略优化 主要考虑因素：数据的通信开销 主要目标：以减少传输次数、数据量 局部处理优化：传统单结点数据库的查询优化技术 代价估计模型：总代价 = IO代价 + CPU代价 + 通信代价","link":"/Database/optimizer.html"},{"title":"Abstract Data Type","text":"概述概念 data：数据，对客观事物的符号表示，在计算机科学中，指 所以能输入计算机中、并被计算机处理的符号总称 data element：数据元素，数据基本单位，在计算机中通常 作为整体考虑 data item：数据项，数据元素的组成部分 data object：数据对象，性质相同的数据元素的集合，数据 的子集 Data Structure数据结构：相互直接存在一种或多种特定关系的数据元素的集合 使用基本类型不断组合形成的层次结构 某种意义上，数据结构可以看作是一组具有相同结构的值 Data_Structure = (D, S) $D$：数据元素有限集 $S$：结构/关系有限集，数据元素之间相互之间的逻辑关系 集合：结构中数据元素只有同属一个集合的关系 线性结构：结构中数据元素之间存在一对一关系 存在唯一一个被称为“第一个”的数据元素 存在唯一一个被称为“最后一个”的数据元素 除第一个外，每个数据元素均只有一个前驱 除最后一个外，每个数据元素均只有一个后继 树型结构：结构中数据元素存在一对多关系 图状/网状结构：结构中数据元素存在多对多的关系 关系表示 逻辑结构：数据结构中描述的逻辑关系 物理/存储结构：数据结构在计算机中的表示（映像） 数据元素之间关系在计算机中映像/表示方法/存储结构 顺序映像：借助元素在存储器中的相对位置表示数据元素 之间的逻辑关系 需要使用地址连续的存储单元依次存储数据元素 所以需要静态分配空间，即给可能数据对象预分配空间 ，空间不够时只能重新分配 由此得到顺序存储结构 非顺序/链式映像：借助指示元素存储地址的指针表示数据 元素之间的逻辑关系 可以使用任意存储单元存储数据元素，另外存储一个指示 其直接后继的信息 常用动态分配空间，即在需要创建数据对象时给其分配空间 也可以静态分配空间，使用地址连续的存储单元存储数据 对象，此时指示元素可以是序号 由此得到链式存储结构 node：节点，数据元素信息、直接后继元素信息的存储映像 数据域：存储元素信息的域 指针域：存储直接后继位置的域 Data Type数据类型：值的集合和定义在值集上的一组操作的总称 atomic data type：原子类型，值不可分解 fixed-aggregate data type：固定聚合类型，值由确定数目 的成分按某种结构组成 variable-aggregate data type：可变聚合类型，值的成分 数目不确定 结构类型：固定、可变聚合类型的统称，值由若干成分按某种 结构组成，可分解，其成分可以是结构或非结构 结构类型可以看作是由一种数据结构和定义在其上的一组 操作组成 在计算机中，每个处理核心（硬件、软件）都提供了一组原子 类型或结构类型 从硬件角度，引入数据类型是作为解释计算机内存中信息 含义的手段 对使用者而言，实现了信息的隐蔽 Abtract Data TypeADT：抽象数据类型，一个数学模型已经定义在该模型上的 一组操作 Data_Type = (D, S, P) $D$：数据对象 $S$：D上的关系集 $P$：对D的基本操作集 根据其行为而不是其内部表示定义类型 实质上与数据类型是同一个概念，“抽象”的意义在于数据类型的 数学抽象特性 或者说抽象数据类型范畴更广，包括自定义数据类型 抽象层次越高，含有该抽象数据类型的程序复用程度越高 面向对象 ADT是面向对象编程的核心 将对象行为和其实现相分离，这也是面向对象编程的基本 技术 simplicity：简单性，隐藏细节方便理解 flexibility：灵活性，类通过对外行为被定义，可以 自由改变内部实现 security：安全性，扮演防火墙，确保实现、用户彼此 分离","link":"/Algorithm/data_structure_abstract.html"},{"title":"代码","text":"基础数据类型整形值无额外空交换 异或 123a = a^bb = a^ba = a^b 加减 123a = a+bb = a-ba = a-b 当然，对某些语言可以同时交换，如：python 取整 向下取整：mid = (left + right) // 2 向上取整：mid = (left + right + 1) // 2 运算溢出 正数：边界值1、0x7FFF FFFF、0xFFFF FFFF 负数：边界值0x8000 0000、0xFFFF FFFF 忽略语言特性：如long类型常量不加LL 初值选取0值未考虑浮点值 浮点取整：尽量避免混用使用向上取整、向下取整，容易混淆 浮点型相等比较：不应使用==，应该使用相差&lt;某常数 123a, b = 1.11111, 1.11111111if abs(a - b) &lt; 0.00001: print(&quot;equal&quot;) 数据结构线性表 常用初值 数值型：0、-1、sys.maxsize、float('inf') 字符串型：&quot;&quot; 迭代过程中可能取值：输出列表首个元素 判断条件 是否为初值 是否越界 对比迭代技巧 从左至右、从右至左分别遍历 原始列表、排序后列表分别遍历 边界条件限制 判断语句中：先列出边界条件，利用短路求值简化代码 双指针 迭代操作注意事项 保证退出循环 所有值均被检验 数据处理、移动指针的顺序 相向双指针：两指针均向中间靠拢不断缩小搜索空间 明确切片范围：是否包括端点，并尽量保持不变 据此明确搜索空间范围，则搜索空间为空时结束循环 滑动窗口：两指针同时向一侧移动，检验窗口内切片 分类 固定间隔双指针 不同条件移动双指针 示例 快慢指针：两指针同时迭代、但运动速度不同 示例 判断单链表是否成环 端点利用 两端限位器：在数据端点添加标记数据，便于 指示“指针”已经到达数据端点 简化特殊情况代码 将循环中的判断条件合并 端点标记数据符合一般情况，无需特殊处理 示例 数组末尾添加查找键（查询问题）：在顺序查找中可以 将判断数组越界、查找键比较合并 末端点为空闲位置：存储有效值 队列、栈插入元素：末端点处为空闲位置，可直接使用 数组迭代比较：末端点处存储有效值，先比较再更新指针 末端点为非空闲位置 队列、栈：可以直接使用其末尾元素作为上次添加的元素， 简化代码 链表特性 头指针/节点：添加链表头，保证特殊情况链表正常工作 示例 删除只包含一个元素的链表 自设外部指针 使用时注意有时会改变内部节点值 12// 修改链表内节点值outer.next.val = 4 HashXXX hash数据结构查询是常数时间，非常合适缓冲记录结果 HashSet：常数时间判断元素存在性 HashDict：键元素、值元素出现次数，记录次数 特殊、常用键 有重复元素：有序tuple、字符串 无重复元素：frozen set 逻辑运算符 注意运算符优先级 =结合不等号 同时使用&lt;=、&gt;=，容易造成死循环、遗漏等 尽量只使用&gt;=号，不再使用&lt;=号 递归终止条件递归终止条件主要有两种设计方案 最后元素：判断元素是否是最后元素，终止递归调用 空（无效）元素：判断元素是空（无效）元素，终止递归调用 需要确保最终能够进入该分支，而不是停止在最后一步 预处理方法排序 预排序是简化问题的好方法 分治 缩小搜索空间：按特征排序后，根据该特征是否满足条件 即可缩小搜索空间 组合 组合后剔除重复：可重复组合排序后唯一，方便剔除重复元素 组合前保证唯一：对组合候选集“预排序”，保证取用元素位序 不减（可重复）、单增（不可重复） 相当于提前对结果排序，保证得到组合结果唯一 “预排序”指候选集中顺序有意义，无需真正排序 特殊测试用例字符串 空字符串 长度1字符串、长度2字符串 字符相同字符串 普通列表 空列表 若在循环外即已取值，应该提前判断列表是否空 长度1列表、长度2列表 元素相同列表 树、二叉树 空树、只有根元素 12node.val = value; # 未考虑空树 只有左子树、右子树 文件边界条件 首个字符 最末字符、倒数第二个字符 代码优化考量 保持程序设计风格：把经常使用的工具性代码编辑成已验证 用规范的格式处理、保存数据 区分代码与数据：与代码无关的数据应该尽可能区分开来，尽量 把数据保存在常量数组中 代码执行速度 输入输出方式过慢：cin等高级输入、输出方式比较慢 程序结构优化 栈溢出：数组等大局部变量保存到栈，少量递归即会发生栈溢出 输入、输出将输入、输出流重定向到文件中，避免频繁测试时频繁输入 输入放在in.txt文件中 输出到out.txt中 输出执行时间 C/C++1234567891011121314#ifdef SUBMITfreopen(&quot;in.txt&quot;, &quot;r&quot;, stdin); // input datafreopen(&quot;out.txt&quot;, &quot;w&quot;, stdout); // outputlong _begin_time = clock();#endif// put code here#ifdef SUBMITlong _end_time = clock();printf(&quot;time = %ld ms\\n&quot;, _end_time - begin_time);#endif Python12345678910import sysimport timesys.stdin = open(&quot;in.txt&quot;, &quot;r&quot;)sys.stdout = open(&quot;out.txt&quot;, &quot;w&quot;)__tstart = time.time() # code here__trange = time.time() - __tstartprint(&quot;time used: %f&quot; % __trange)","link":"/Algorithm/twists.html"},{"title":"Python Readme","text":"函数书写声明123456return = func( essential(type), optional=defaults/type, *args, **kwargs) 格式说明参数 essential参数：essential(type) 没有= 在参数列表开头 (type)：表示参数可取值类型 optional参数：optional=defaults/type defaults若为具体值，表示默认参数值 默认值首字母大写 默认参数值为None 函数内部有默认行为 None（默认行为等价参数值） type：之后表示可能取值类型 *args参数：[参数名]=defaults/type 首参数值为具体值表示函数默认行为（不是默认值，args 参数没有默认值一说） 其后为可取参数值类型 说明 参数名仅是标记作用，不能使用关键字传参 []：代表参数“可选” **kwargs参数：[param_name=defaults/type] 参数默认为可选参数，格式规则类似args参数 POSITION_ONLY参数：[param_name](defaults/type) POSITION_ONLY参数同样没有默认值一说，只是表示默认 行为方式（对应参数值） 参数名后有?表示参数名待确定 参数首字母大写表示唯一参数 返回值返回值类型由返回对象名称蕴含 对象类型 obj(type)：type表示包含元素类型","link":"/Python/Readme/README.html"},{"title":"Java安装设置","text":"Java 概念 Java 平台包括 Standard Edition / SE：桌面、简单服务器应用平台 Enterprise Edition / EE：在 SE 基础上添加企业级技术标准、模块 包括 JDBC、EJB 等 适合复杂服务器应用 Oracle 已停止更新，类似一般模块 Micro Edition / ME：手机等小型设备 Java 版本号包含小数、整数两种方式 以 SE 平台为例 J2SE 1.4 使用小数点后一位标识大版本 Java SE 5 后使用整数标识大版本 Java 平台对应的 JDK 版本 JDK 1.9 使用小数点后一位标识大版本 JDK 10 使用整数标识大版本 J2 / Java 2 曾经用于标识 Java 版本 Java Virtual Machine JVM：运行java字节码（.class)的虚拟机 无法直接执行.java文件，需要编译为.class java能够跨平台的关键，在所有平台上都有JVM的实现，可以 直接执行编译后的.class文件 JVM版本 Google dalvik ART Oracle JRE 自带 JVM Java Runtime Environment JRE：Java 运行环境，运行 Java 编写的应用 JRE = JVM + .class库文件 + 其他支持文件 Java Development Kits JDK：Java 开发工具集合 JDK = Java 开发工具 + JRE 包括 complier、debugger，用于开发 Java 应用 Java 发行版 Java 常见的发行版本两个：OpenJDK 和 JDK JDK(Sun JDK)：Sun 公司发布 OpenJDK：JDK 的开源版本，其实也是Sun公司发布的Java版本，Sun被Oracle收购之后也称为Oracle OpenJDK JDK 的一个“发行版”，Java SE 7 JSR 的一个开源实现 现在同 Oracle JDK 区别很小配置 JAVA123456789export JAVA_HOME=/opt/jdk # 安装是jdk，所以目录直接由jdk就好 # 或者保留原版本号，创建符号链接`java`执行原目录 # 可自定以部分export JRE_HOME=$JAVA_HOME/jreexport PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=$CLASSPATH:$JRE_HOME/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar # jar包是java文件的集合，可以/需要看作是文件夹 # java的`CLASSPATH`所以需要添加的是jar包 Scala12export SCALA_HOME=/opt/scalaexport PATH=$PATH:$SCALA_HOME/bin:$SCALA_HOME/sbin MAVEN","link":"/Java/config.html"},{"title":"Python安装配置","text":"PythonPython3包管理安装 CentOS7依赖缺失 zlib-devel bzip2-devel readline-devel openssl-devel sqlite(3)-devel 根据包用途、名称可以确认对应的应用，缺少就是相应 -devel(-dev) Python Implementation名称中flag体现该发行版中python特性 -d：with pydebug -m：with pymalloc -u：with wide unicode pymalloc是specialized object allocator 比系统自带的allocator快，且对python项目典型内存 分配模式有更少的开销 使用c的malloc函数获得更大的内存池 原文：Pymalloc, a specialized object allocator written by Vladimir Marangozov, was a feature added to Python2.1. Pymalloc is intended to be faster than the system malloc() and to have less memory overhead for allocation patterns typical of Python programs. The allocator uses C’s malloc() function to get large pools of memory and then fulfills smaller memory requests from these pools.J 注意：有时也有可能只是hard link Python配置Python相关环境变量 PYTHONPATH：python库查找路径 PYTHONSTARTUP：python自动执行脚本 自动补全123456789101112131415161718192021import readlineimport rlcompleter # 为自动补全`rlcompleter`不能省略import atexitreadline.parse_and_bind(&quot;tab:complete&quot;) # 绑定`&lt;tab&gt;`为自动补全try: readline.read_history(&quot;/path/to/python_history&quot;) # 读取上次存储的python历史except: passatexit.register( readline.write_history_file, &quot;/path/to/python_history&quot;) # 将函数注册为推出python环境时执行 # 将python历史输入存储在的自定以文件中 # 这部分存储、读取历史其实不必要del readline, rlcompleter 每次在python解释器中执行生效 保存为文件python_startup.py，将添加到环境变量 PYTHONSTARTUP中，每次开启python自动执行 123# .bashrcexport PYTHONSTARTUP=pythonstartup.py # 这个不能像*PATH一样添加多个文件，只能由一个文件 Pippython包、依赖管理工具 pip包都是源码包 需要在安装时编译，因此可能在安装时因为系统原因出错 现在有了wheels也可以安装二进制包 安装 编译安装python一般包括pip、setuptools 系统自带python无pip时，可用apt、yum等工具可以直接安装 虚拟python环境，无般法使用系统包管理工具安装pip，则只能 下载pip包使用setuptools安装 配置配置文件：~/.config/pip/pip.conf 12345[global]index-url = https:?//pypi.tuna.tsinghua.edu.cn/simple/ # pypi源地址format = columns # pip list输出格式（legacy，columns） 依赖管理pip通过纯文本文件（一般命名为requirements.txt）来记录、 管理python项目依赖 $ pip freeze：按照package_name=version的格式输出 已安装包 $ pip install -r：可按照指定文件（默认requirements.txt） 安装依赖 Virtualenv/Venv虚拟python环境管理器，使用pip直接安装 将多个项目的python依赖隔离开，避免多个项目的包依赖、 python版本冲突 包依赖可以安装在项目处，避免需要全局安装python包的权限 要求、影响 实现原理$ virtualenv venv-dir复制python至创建虚拟环境的文件夹中， $ source venv-dir/bin/activate即激活虚拟环境，修改系统环境 变量，把python、相关的python包指向当前虚拟环境夹 Virtualenv使用Pyenvpython版本管理器，包括各种python发行版 安装不需要事先安装python 从github获取pyenv：git://github.com/yyuu/pyenv.git 将以下配置写入用户配置文件（建议是.bashrc)，也可以在 shell里面直接执行以暂时使用 123export PYENV_ROOT=&quot;$HOME/pyenv路径&quot;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;eval &quot;$(pyenv init -)&quot; 以上配置可参见home_config/bashrc_addon，以项目详情为准 Pyenv安装Python发行版问题使用pyenv安装python时一般是从PYTHON_BUILD_MIRROR_URL表示 的地址下载安装文件（或者说整个系统都是从这个地址下载），缺省 是http://pypi.python.org，但国内很慢 #todo 设置这个环境变量为国内的镜像站，如 http://mirrors.sohu.com/python，但这个好像没用 在镜像站点下载安装包，放在pyenv/cache文件夹下（没有就 新建） pyenv安装python时和使用一般安装应用一样，只是安装prefix不是 /usr/bin/之类的地方，而是pyenv安装目录，因此pyenv编译安装 python也需要先安装依赖 实现原理修改$PATH环境变量 用户配置文件将PYENV_ROOT/bin放至$PATH首位 初始化pyenv时会将PYENV_ROOT/shims放至$PATH首位 shims、bin放在最前，优先使用pyenv中安装的命令 bin中包含的是pyenv自身命令（还有其他可执行文件，但是 无法直接执行?） shims则包含的是所有已经安装python组件 包括python、可以执行python包、无法直接执行的python包 这些组件是内容相同的脚本文件，仅名称是pyenv所有安装 的python包 用于截取python相关的命令 并根据设置python发行版做出相应的反应 因此命令行调用安装过的python包，pyenv会给提示 即使不是安装在当前python环境中 因此一般将命令放在.profile文件中，这样每次登陆都会设置好 pyenv放在.bashrc中会设置两次（没有太大关系） 使用指定Python发行版 $ pyenv local py-version指定是在文件夹下生成 .python-version文件，写明python版本 所有的python相关的命令都被shims中的脚本文件截取 pyenv应该是逐层向上查找.python-version文件，查找到文件则 按照相应的python发行版进行执行，否则按global版本 Conda通用包管理器 管理任何语言、类型的软件 conda默认可以从http://repo.continuum.io安装已经 编译好二进制包 conda包和pip包只是部分重合，有些已安装conda包 甚至无法被pip侦测到（非python脚本包） python本身也作为conda包被管理 创建、管理虚拟python环境（包括python版本） 安装 conda在Miniconda，Anaconda发行版中默认安装 Miniconda是只包括conda的发行版，没有Anaconda中默认 包含的包丰富 在其他的发行版中可以直接使用pip安装，但是这样安装的 conda功能不全，可能无法管理包 Miniconda、Anaconda安装可以自行设置安装位置，无需介怀 配置conda配置文件为$HOME/.condarc，其中可以设置包括源在内 配置 12345channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - defaultsshow_channel_urls: true 添加国内源conda源和pypi源不同（以下为清华源配置，当然可以直接修改 配置文件） 123$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/$ conda config --set show_channel_urls yes conda源不是pypi源，不能混用 Win平台设置 添加菜单项 123 # 可用于恢复菜单项$ cd /path/to/conda_root$ python .\\Lib\\_nsis.py mkmenus VSCode是通过查找、执行activate.bat激活虚拟环境 所以若虚拟环境中未安装conda（无activate.bat） 则虚拟环境无法自动激活 常用命令123456789101112131415161718192021222324252627$ conda create [--clone ori_env] -n env [packages[packages]] # 创建虚拟环境 # python也是conda包，可指定`python=x.x`$ conda remove -n env --all # 删除虚拟环境$ conda info -e$ conda env list # 列出虚拟环境$ conda info # 列出conda配置$ conda activate env # 激活env环境$ conda deactivate # 退出当前环境$ conda list -n env # 列出env环境/当前环境安装conda包$ conda search package # 搜索包$ conda install [-n env] packages # env环境/当前环境安装conda包$ conda update [-n env] packages # env环境/当前环境升级conda包$ conda remove [-n env] packages # env环境/当前环境移除包 使用conda而不是pip安装包更合适，方便管理 创建新环境时，默认不安装任何包，包括pip，此时切换到 虚拟环境后，pip等命令都是默认环境的命令 Pipenvpip、virtualenv、Pipfile（版本控制）功能的综合，事实上就 依赖于pip、virtualenv（功能封装） $ pipenv sync/install替代$ pip install $ pipenv shell替代$ activate $ pipenv run甚至可以不用激活虚拟环境运行某些命令 Pipfile控制dev、release包管理，Pipfile.lock锁定包依赖 安装 使用pip直接安装 系统安装源里有pipenv，也可以用系统包管理工具安装 实现原理Python版本pipenv和virtualenv一样指定python版本也需要已经安装该python 版本 $PATH中的路径无法寻找到相应的python版本就需要手动 指定 不是有版本转换，将当前已安装版本通过类似2to3的“中 间层”转换为目标版本 虚拟环境pipenv会在~/.local/share/virtualenv文件夹下为所有的虚拟 python环境生成文件夹 文件夹名字应该是“虚拟环境文件夹名称-文件夹全路径hash” 包括已安装的python包和python解释器 结构和virtualenv的内容类似，但virtualenv是放在项目目录下 $ python shell启动虚拟环境就是以上文件夹路径放在 $PATH最前 依赖管理pipenv通过Pipfile管理依赖（环境） 默认安装：$ pipenv install pkg 作为默认包依赖安装pkg，并记录于Pipfile文件 [packages]条目下 相应的$ pipenv install则会根据Pipfile文件 [packages]条目安装默认环境包依赖 开发环境安装：$ pipenv install --dev pkg 作为开发环境包依赖安装pkg，并记录于Pipfile 文件[dev-packages]条目下 相应的$ pipenv intall --dev则会根据Pipfile 文件中[dev-packages]安装开发环境包依赖 Pipfile和Pipfile.lock Pipfile中是包依赖可用（install时用户指定）版本 Pipfile.lock则是包依赖具体版本 是pipenv安装包依赖时具体安装的版本，由安装时包源的 决定 Pipfile.lock中甚至还有存储包的hash值保证版本一致 Pipfile是用户要求，Pipfile.lock是实际情况 因此 $ pipenv install/sync优先依照Pipfile.lock安装具体 版本包，即使有更新版本的包也满足Pipfile的要求 Pipfile和Pipfile.lock是同时更新、内容“相同”， 而不是手动锁定且手动更新Pipfile，再安装包时会默认更新 Pipfile.lock Pipenv用法详情https://docs.pipenv.org 创建新环境具体查看$pipenv --help，只是记住$pipenv --site-packages 表示虚拟环境可以共享系统python包 默认环境和开发环境切换pipenv没有像git那样的切换功能 默认环境“切换”为dev环境：$ pipenv install --dev dev环境“切换”为默认环境：$ pipenv uninstall --all-dev 同步$ pipenv sync 官方是说从Pipfile.lock读取包依赖安装，但是手动修改Pipfile 后$ pipenv sync也会先更新Pipfile.lock，然后安装包依赖， 感觉上和$ pipenv install差不多 Pipenv特性和Pyenv的配合pipenv可以找到pyenv已安装的python发行版，且不是通过$PATH 中shims获得实际路径 pipenv能够找到pyenv实际安装python发行版的路径versions， 而不是脚本目录shims pipenv能自行找到pyenv安装的python发行版，即使其当时没有 被设置为local或global pyenv已安装Anaconda3和3.6并指定local为3.6的情况下 $ pipenv --three生成的虚拟python使用Anaconda3 后系统全局安装python34，无local下pipenv --three 仍然是使用Aanconda3 后注释pyenv的初始化命令重新登陆，pipenv --three就 使用python34 目前还是无法确定pipenv如何选择python解释器，但是根据以上测试 和github上的feature介绍可以确定的是和pyenv命令有关 pipenv和pyenv一起使用可以出现一些很蠢的用法，比如：pyenv指定 的local发行版中安装pipenv，然后用这pipenv可以将目录设置为 另外版本虚拟python环境（已经系统安装或者是pyenv安装） 总结除了以上的包管理、配置工具，系统包管理工具也可以看作是python 的包管理工具 事实上conda就可以看作是pip和系统包管理工具的交集 系统python初始没有pip一般通过系统包管理工具安装 使用场景优先级：pip &gt; conda &gt; 系统包管理工具 纯python库优先使用pip安装，需要额外编译的库使用conda conda源和系统源都有的二进制包，优先conda，版本比较新 2018/04/06经验最后最合适的多版本管理是安装pipenv 系统一般自带python2.7，所以用系统包管理工具安装一个 python3 使用新安装的python3安装pipenv，因为系统自带的python2.7 安装的很多包版过低 最后如果对python版本要求非常严格 还可以再使用pyenv安装其他版本 然后仅手动启用pyenv用于指示pipenv使用目标python版本 2019/02/20经验直接全局（如/opt/miniconda）安装Miniconda也是很好的选择 由conda管理虚拟环境，虚拟环境创建在用户目录下，登陆时 激活","link":"/Python/config.html"},{"title":"Python注意事项","text":"Python原生数据结构list 方法 ==：list 的 == 是逐值比较 __contains__：方法中使用 == 比较元素 in 判断列表包含时也是逐值比较 迭代技巧 需要修改列表元素时尽量不直接迭代列表，考虑 新建列表存储元素值 迭代列表下标 迭代过程会更改列表元素数量时 使用 .pop 方法 确定迭代数量 运算注意 .append：直接修改原列表，不返回 .extend：直接修改原列表，不返回 __add__：返回新列表 参数 勿使用列表、字典等指针类型作为默认参数，否则函数重入结果很可能出现问题 原因：函数体中任何对参数的修改都会被保留 替代方式：None + 函数体内判断 迭代器 需要多次迭代时，应该将迭代器转换为可重复迭代数据结构，如：列表 迭代器值会被消耗","link":"/Python/Twists/twists.html"},{"title":"Git 基础","text":".gitingore.gitignore忽略规则 !开头：排除应被忽略 /结尾：忽略文件夹 /开头：git仓库根目录路径开始（可省略） 遵循一定的正则表达式 *：多个字符，不包括/，因此多层级目录需要一一指定 ?：单个字符 []：匹配其中候选字符 .gitignore配置方式 仓库根目录创建.gitignore文件，添加忽略规则 忽略规则针对当前项目 .gitignore文件默认随仓库分发，所有人共用忽略规则 （当然可以在.gitignore中配置忽略.gitignore） 设置全局忽略文件，对所有git项目适用 1git config --global core.excludesfile /path/to/.gitignore 修改.git/info/exclude文件，添加忽略规则 对单一项目有效 非所有人共用忽略规则 Git配置/config 配置文件、配置类型 --system：系统全局配置，配置文件/etc/gitconfig --global：用户全局配置，配置文件 $HOME/.gitconfig、$HOME/.config/git/config --local：局部repo配置，配置文件repo/.git/config 1234# 修改`section.key`值（缺省`--local`）$ git config [--system|--global|--local] &lt;section&gt;.&lt;key&gt; &lt;value&gt;# 删除配置项$ git config [--system|--global|--local] --unset &lt;section&gt;.&lt;key&gt; 配置文件常用123456789101112131415161718192021222324252627282930313233 # 核心修改[core] # 忽略文件权限修改 filemode = false editor = vim # 提交、检出时换行符设置 # `input`：提交时转换为`&lt;LF&gt;`、检出时不转换 # `false`：提交、检出均不转换 # `true`：提交时转换为`&lt;LF&gt;`、检出时转换为`&lt;CRLF&gt;` autocrlf = input # 是否允许文件混用换行符 # `true`：拒绝提交包含混合换行符文件 # `false`：允许提交包含混合换行符文件 # `warn`：提交包含混合换行符文件时警告 safecrlf = true[user] name = xyy15926 email = xyy15926@163.com # 设置别名[alias] st = status ci = commit br = branch lg = &quot;log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit&quot; d = difftool # 输出着色[color] # 打开所有默认终端着色 ui = true[diff] tool = vimdiff[difftool] prompt = false autocrlf在linux若设置为input，在add包含&lt;CRLF&gt; 文件会报fatal错 因为input在提交时会将&lt;CRLF&gt;转换为&lt;LF&gt;，但在 检出时无操作 所以导致即使add也不能保证repo当前状态和提交状态 一致 remote1234 # 查看远程仓库$ git remote -v # 设置远程仓库地址$ git remote set-url &lt;repo_name&gt; &lt;new_url&gt; 指定ssh key git依赖ssh进行存储库认证，无法直接告诉git使用哪个私钥 ~/.ssh/config中配置ssh host：git每次使用host代替原 服务器地址 1234host &lt;host&gt;HostName github.comIdentityFile $HOME/.ssh/id_rsa_github_privateUser git ssh host详见*linux/shell/config_files” GIT_SSH_COMMAND环境变量：指定ssh命令-i中参数 12345GIT_SSH_COMMAND=&quot;ssh -i ~/.ssh/id_rsa_github_private&quot; git clone ...// 可以`export`持久化export GIT_SSH_COMMAND = ...// 写入git配置git config core.sshCommand &quot;...&quot; 展示命令log12$ git log [&lt;file_name&gt;] # 查看文件提交历史 show12$ git show &lt;tag_no|commit_hash&gt; # 查看改动内容","link":"/Linux/Tool/git.html"},{"title":"Grub","text":"Grub/etc/sysconfig/grubGRUB配置文件，实际上是/etc/default/grub的软连接 系统日志/var/log bootstrap.log：系统引导相关信息 cron：系统调度执行信息 dmesg：内核启动时信息，包括硬件、文件系统 maillog：邮件服务器信息 message：系统运行过程相关信息，包括IO、网络 secure：系统安全信息","link":"/Linux/Tool/grub.html"},{"title":"Rust 程序设计笔记","text":"参数、环境变量 std::env::args()：返回所有参数的一个迭代器，第一参数 是可执行文件，包含任何无效unicode字符将panic!， args: Vec = std::env::args().collect() std::env::var(&quot;env_var&quot;)：获取设置的环境变量值，返回 一个Result 环境变量设置时返回包含其的Ok成员 未设置时返回Err成员 设置“环境变量”并执行程序：$&gt;ENV_NAME=val cargo run","link":"/Rust/command_line.html"},{"title":"Pandoc介绍","text":"PandocPandoc：将文本在不同标记语言之间相互转换的工具 Pandoc使用Haskell开发，最新版本Pandoc可以使用Haskell平台 包管理器cabal安装 123$ sudo apt install haskell-platform$ cabal update$ cabal install pandoc Pandoc支持的标记语言格式包括 （具体可通过--list-input-formats查看） Markdown ReStructuredText HTML LaTeX ePub MS Word Docx PDF Pandoc输入、输出文本 可从输入、输出的文件扩展名推测输入、输出格式 缺省输入格式为Markdown、缺省输出格式为html 若未指明输入、输出文件，则读取、写入标准输入、输出 文本默认为utf-8编码，否则可以用iconv转换文本 编码进行输入、输出 Pandoc相关选项基础选项 -f/-t：输入、输出格式 -o：输出文件 --number-sections/-N：为标题添加编号 --verbose：详细调试信息 其中会给出资源文件目录~/.pandoc，存放模板等 --log：日志信息 --file-scope：分别转换每个文件 指定多个输入文件时默认将多个文件拼接，空行分隔 信息选项 --list-input-formats/--list-output-formats：输入、 输出格式 --list-extensions[=FORMAT]：列出Markdown扩展支持情况 &lt;FORMAT&gt;-&lt;EXT&gt;可以增减格式中一个、多个扩展选项 --list-highlight-languages：语法高亮支持语言 --list-highlight-styles：语法高亮支持样式 模板选项 -standalone/-s：生成完整文件 （仅对可生成片段的某些格式：html、LaTeX） 默认生成文档片段 采用相应内值模板生成完整文件 --print-default-template=&lt;FORMAT&gt;/-D &lt;FORMAT&gt;：输出 对应格式的默认模板 --template=&lt;TPL&gt;：指定创建文档所需模板 --css=&lt;URL&gt;/-c &lt;URL&gt;：指定CSS样式表 自定义值传递 --variable=&lt;KEY[:&lt;VAL&gt;]&gt;/-V &lt;KEY[:&lt;VAL&gt;]&gt;：指定模板 变量取值 --metadata=&lt;KEY[:&lt;VAL&gt;]&gt;/-M &lt;KEY[:&lt;VAL&gt;]&gt;：指定 元数据字段取值 元数据字段影响模板变量取值，同时影响底层文档元数据 --metadata-file=&lt;FILE&gt;：从YAML格式文件中设置元数据字段 取值 PDF生成相关 --toc：生成目录 --template=&lt;TPL&gt;：编译使用的LaTeX模板，缺省为自带 --latex-engine=&lt;ENG&gt;：指定LaTeX引擎，需安装 默认pdflatex对中文支持缺失，建议使用xelatex --highlight-style=&lt;STY&gt;：代码块语法高亮 自带高亮样式可通过--list-highlight-styles查看 也可指定高亮样式文件 --listings：LeTeX文档中使用Listings包格式化代码块 --biblatex/--natbib：指定处理参考文献程序 --bibliography=&lt;FILE&gt;：设置文档元数据中参考文献信息 -f markdown-implicit_figures设置Markdown格式，指定 图像保持原始位置，避免pdf中错位 HTML生成相关 --self-contained：将css、图片等所有外部文件压缩进html 文件中 Markdown中使用html标记可以在转换为html后保留，可以据此 设置转换后的样式 DOCX生成相关 --reference-doc=&lt;FILE&gt;：指定格式参考文件 参考文件内容被忽略，就样式、文档属性被使用 --print-default-data-file=reference.docx：输出系统默认 模板 --extract-media=&lt;DIR&gt;：提取文档中多媒体文件至文件夹， 并在目标文件中设置对其引用 EPUB生成相关 --epub-cover-image=&lt;FILE&gt; --epub-metadata=&lt;FILE&gt; --epub-embed-font=&lt;FILE&gt; 数学公式渲染 --mathjax[=&lt;URL&gt;] --mathml --katex[=&lt;URL&gt;] Pandoc模板模板变量模板变量：Pandoc模板中可以包含变量用于自定义模板 1234567891011$title$ # 变量表示方法$if(var)$ # 变量条件语句X$else$Y$endif$$for(var)$ # 变量循环语句X$endfor$ 变量赋值方式 命令行参数提供 文档元数据中查找","link":"/Linux/Tool/pandoc.html"},{"title":"GCC","text":"G++g++：是gcc的特殊版本，链接时其将自动使用C++标准库而不是 C标准库 12$ gcc src.cpp -l stdc++ -o a.out // 用`gcc`编译cpp是可行的","link":"/Linux/Tool/gcc.html"},{"title":"Nginx 使用、配置","text":"配置 配置文件夹为/etc/nginx 基本配置nginx.confnginx.conf：Nginx主配置文件，包含“全部配置” 默认include modules-enabled/*.conf：已启用模块 mime.types：代理文件类型 conf.d/*.conf：服务器设置 sites-enabled/*：已启用站点 user表示启动nginx进程的用户 键值默认为www-data 可修改为其他用户，使nginx具有访问某些文件的权限 若是在nginx启动之后修改，需修改/var/log/nginx中 log文件的属主，否则无法正常log http服务器设置12345678910server{ listen 8080; server_name localhost; location / { root /home/xyy15926/Code; autoindex on; autoindex_exact_size off; autoindex_localtime on; }} root：需要nginx进程可访问，否则403 Forbidden autoindex：自动为文件生成目录 若目录设置index index.XXX，不设置autoindex访问 目录则会403 Forbidden https服务器12345678910111213141516server{ listen 443 ssl; server_name localhost; ssl_certificate /home/xyy15926/Code/home_config/nginx/localhost.crt; ssl_certificate_key /home/xyy15926/Code/home_config/nginx/localhost.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / { root /home/xyy15926/Code/statics; autoindex on; autoindex_exact_size off; autoindex_localtime on; }} ssl_certificate、ssl_certificate_key：SSL证书、私钥 123456# 个人签发https证书，个人一般不会是受信任机构，所以还需要# 将证书添加进受信任机构（但是windows下有些有问题）openssl req -x509 -out localhost.crt -keyout localhost.key \\ -newkey rsa:2048 -nodes -sha256 \\ -subj '/CN=localhost' -extensions EXT -config &lt;( \\ printf &quot;[dn]\\nCN=localhost\\n[req]\\ndistinguished_name = dn\\n[EXT]\\nsubjectAltName=DNS:localhost\\nkeyUsage=digitalSignature\\nextendedKeyUsage=serverAuth&quot;) 运行123 # Nginx启动、重启动$ /etc/init.d/nginx start$ /etc/init.d/nginx restart","link":"/Linux/Tool/nginx.html"},{"title":"Linux 远程工具","text":"远程连接服务器sshssh：ssh登陆服务器 12ssh &lt;user_name&gt;@&lt;host&gt; [-p &lt;port&gt;] [-i &lt;private_key&gt;] [-F &lt;config_file&gt;] 参数 -F：指定配置文件，简化命令，缺省~/.ssh/config 有时会覆盖其余配置，可以指定-F /dev/null避免 -p：指定端口 -i：指定使用的私钥 -T：测试连接 ssh-keygenssh-keygen：生成ssh密钥 1234 # 生成位长为4096的RSA密钥$ ssh-keygen -t rsa -b 4096 -C &quot;xyy15926@163.com&quot; # 更改现有私钥密钥$ ssh-keygen -p [-f keyfile] [-m format] [-N new_pwd] [-p old_pwd] 参数 -t [dsa|ecdsa|ecdsa-sk|ed25519|ed25519-sk|ras]： 生成密钥类型 -f &lt;output_keyfile&gt;：密钥保存文件 -b &lt;bits&gt;：密钥位数 -C &lt;comment&gt; -p：修改现有密钥密码 在生成密钥时可以设置密钥，避免计算机访问权限被获取后密钥 被用于访问其他系统 设置有密钥的私钥每次使用都需要输入密码 ssh-agent可以用于管理私钥密码，将私钥添加给 ssh-agent无需每次输入密码 ssh-addssh-add：管理ssh-agent代理密钥 12 # 缺省将`$HOME/.ssh/id_rsa`私钥添加至`ssh-agent`$ ssh-add &lt;keyfile&gt; 参数 -l：查看代理中私钥 -L：查看代理中私钥对应公钥 -d &lt;keyfile&gt;：移除指定私钥 -D：移除所有私钥 -x/-X：锁定/解锁ssh-agent（需要设置密码） -t &lt;seconds&gt;：密钥时限 ssh-agentssh-agent：控制和保存公钥验证所使用的私钥程序 参数 -k：关闭当前ssh-agent进程 启动方式 12345# 创建默认子shell，在子shell中运行`ssh-agent`# 会自动进入子shell中，退出子shell则`ssh-agent`关闭$ ssh-agent $SHELL# 启动后台`ssh-agent`进程，需手动关闭`ssh-agent`进程$ eval `ssh-agent` 说明 向ssh-agent添加私钥需要输入私钥密码 （无密码私钥无管理必要） ssh-agent不会默认启动，应是每次需要大量使用私钥 前启动、添加私钥，然后关闭 /etc/init.d/sshdsshd：ssh连接的服务器守护程序（进程） 1234$ sudo systemctl start sshd # 使用`systemctl`启动$ /etc/init.d/sshd restart # 直接启动进程 scpscp：secure cp，安全传输（cp）文件 本机到远程 1$ scp /path/to/file user_name@host:/path/to/dest 远程到本机 1$ scp user_name@host:/path/to/file /path/to/dest 这个命令应该在本机上使用，不是ssh环境下 ssh环境下使用命令表示在远程主机上操作 而本机host一般是未知的（不是localhost） 远程到远程 rsync实现本地主机、远程主机的文本双向同步 同步两种模式同步过程由两部分模式组成 决定哪些文件需要同步的检查模式 默认情况下，rsync使用quick check算法快速检查 源文件、目标文件大小、mtime是否一致，不一致则 需要传输 也可以通过指定选项改变检查模式 文件同步时的同步模式：文件确定被同步后，在同步发生 之前需要做哪些额外工作 是否删除目标主机上比源主机多的文件 是否要先备份已经存在的目标文件 是否追踪链接文件 工作方式 本地文件系统同步：本质是管道通信 1$ rsync [option..] src... [dest] 本地主机使用远程shell和远程主机通信 12$ rsync [option...] [user@]host:src... [dest]$ rsync [option...] src... [user@]host:dest 本质上是管道通信 本地主机通过socket连接远程主机的rsync 1234$ rsync [option...] rsync://[user@]host[:port]/src... dest$ rsync [option...] [user@]host::src... [dest]$ rsync [option...] src... rsync://[user@]host[:port]/dest$ rsync [option...] src... [user@]host::dest 需要远主机运行rsync服务监听端口，等待客户端连接 通过远程shell临时派生rsync daemon，仅用于临时读取daemon 配置文件，同步完成后守护进程结束 语法同shell远程主机通信，指定--rsh/-e选项 参数说明 可以有多个源文件路径，最后一个是目标文件路径 如果只有一个路径参数，则类似于ls -l列出目录 注意：如果原路径是目录 /结尾表示目录中文件，不包括目录本身 不以/结尾包括目录本身 常用选项同步模式选项 v/-vvvv：显示详细/更详细信息 p/--partial --progress：显示进度 -n/--dry-run：测传传输 -a/--archive：归档模式，递归传输并保持文件属性 -r/--recursive：递归至目录 -t/--times：保持mtime属性 建议任何时候都使用，否则目标文件mtime设置为系统时间 -o/--owner：保持属主 -g/--group：保持group -p/--perms：保持权限（不包括特殊权限） -D/--device --specials：拷贝设备文件、特殊文件 -l/--links：如果目标是软链接文，拷贝链接而不是文件 z：传输时压缩 w/--whole-file：使用全量传输 网络带宽高于磁盘带宽时，此选项更高效 R/--relative：使用相对路径，即在目标中创建源中指定 的相对路径 123$ rsync -R -r /var/./log/anaconda /tmp # 将会在目标创建`/tmp/log/anaconda` # `.`是将绝对路径转换为相对路径，其后的路径才会创建 --delete：以源为主，对DEST进行同步，多删、少补 -b/--backup：对目标上已经存在文件做备份的 备份文件名使用~做后缀 --backup-dir：指定备份文件保存路径，不指定为同一目录 --remove-source-file：删除源中已成功传输文件 连接 --port：连接daemon时端口号，默认873 --password-file：daemon模式时的密码文件 可以从中读取密码文件实现非交互式 是rsync模块认证密码，不是shell认证密码 -e：指定所需要的远程shell程序，默认ssh1$ rsync -e &quot;ssh -p 22 -o StrictHostKeyChecking=no&quot; /etc/fstab --rsh：使用rsync deamon进行同步 检查模式选项 --size-only：只检查文件大小，忽略mtime -u/--update：进源mtime比已存在文件mtime新才拷贝 -d/--dirs：以不递归方式拷贝目录本身（不目录中内容） --max-size：传输最大文件大小，可以使用单位后缀 --min-size：传输的最小文件大小 --exclude：指定派出规则排除不需要传输的文件 --existing：只更新目标端已存在文件，不存在不传输 --ignore-existing：只更新在目标段不存在文件 SSH/etc/ssh/sshd_config全局系统ssh配置 12345678RSAAuthentication # 去掉注释启用RSA认证PubkeyAuthentication yes # 启用公私钥配对认证方式AuthorizedKeyFile .ssh/authorized_keys # 设置被认证的公钥存放文件 # 默认为`~/.ssh/authorized_keys`中 # 将其他主机公钥写入其中，即可从其使用密钥认证免密访问 ~/.sshauthorized_keys在/etc/.ssh/sshd_config中默认的存储其他主机公钥的文件， 使用在其中的公钥可以使用公钥登陆，无需密码 必须设置只有root用户有更改权限有效，否则报错 1---pubkey--- id_rsa.pub生成公钥 configssh访问远程主机配置 每条配置对应一个ssh连接，配置后可以使用link_name直接 连接 1234567Host &lt;link_name&gt; HostName &lt;host&gt; User &lt;user_name&gt; Port &lt;port&gt; IdentityFile &lt;private_key&gt; IdentitiesOnly yes PreferredAuthentications publickey 默认私钥文件为：~/.ssh/id_rsa，可以指定特定私钥 此文件中配置是ssh协议参数封装，适合任何可以使用ssh协议 场合：ssh、git、scp","link":"/Linux/Tool/remote.html"},{"title":"Todo.txt","text":"Todo.txt格式 todo.txt格式使用纯文本存储、表示任务 存储任务的文本文件中每行表示一项task todo.txt类清单管理应用因此一般具备如下特点 待完成任务、已完成任务分为两个文件分别存储 可以自由修改任务存储文件以修改任务内容 基本要素 任务结构：各部分之间使用空格分隔 x：任务完成标识符 优先级：([A-Z]) 完成日期、创建日期：Y-m-d格式 任务描述：任务主体部分 任务描述部分可以包含各种类型的tag，tag格式上可以放在任务 任何部分，但习惯上放在末尾 project：+标识 context：@标识 [key]:[value]：metadata键值对，key表示键值对含义 （中间一般不用空格分隔，便于处理） 常用特殊metadata键值对 时间戳：t:Y-m-d 截至日期：due:Y-m-d Todo.txt工具todo.txt-clitodo.txt-cli：基于shell脚本管理todo.txt文件 只提供基本todo.txt功能，可以通过自行添加脚本插件方式扩展 插件文件即普通可执行脚本文件，todo.sh会将命令参数 传递给相应脚本文件 todo.sh [action]将直接调用相应action名称脚本 （可建立同名文件夹、文件管理，同名文件夹文件被调用） 使用两个文件分别存储待完成任务、已完成任务 待完成任务文件中可以自行x标记完成，然后使用命令 归档至已完成任务文件中 https://github.com/todotxt/todo.txt-cli topydotopydo：基本python脚本管理todo.txt文件 提供了cli、prompt、column三种模式 原生支持以下标签 due、start日期 管理任务之间依赖管理 重复任务","link":"/Linux/Tool/todotxt.html"},{"title":"Tmux","text":"Tmux Session：用户与计算计算机的交互 一般而言，temrinal窗口、Session进程绑定 打开窗口，Session开始 关闭窗口，Session结束 Tmux：终端复用软件，将terminal窗口、Session解绑 允许多个窗口接入、断开多个Session 新增多个Session 接入已有Session，共享Session 支持窗口竖直、水平拆分 https://man7.org/linux/man-pages/man1/tmux.1.html 命令行参数 -S &lt;socket-file&gt;：指定tmux使用socket文件（位置） Session管理 tmux new -s &lt;session-name&gt;：创建指定名称session 缺省数字命名 tmux detach：detach当前接入会话 tmux ls/list-session：列出session列表 tmux rename -t &lt;s1&gt; &lt;s2&gt;：重命名session tmux a [-t &lt;session-name&gt;]：attach指定session 缺省连接上个session tmux switch -t &lt;session-name&gt;：切换至指定session tmux kill-session [[-a] -t s1]：关闭session 缺省关闭上次session -a：关闭除指定session外其他session tmux kill-server：关闭所有session Tab（Windows）管理 tmux new-window [-n &lt;win-name&gt;]：创建新窗口 tmux switch-window -t &lt;win-name&gt;：切换到指定窗口 tmux rename-window &lt;win-name&gt;：重命名当前窗口 Pane管理 tmux split-window [-h]：竖直/水平划分窗口 tmux select-pane -U/-D/-L/-R：激活上、下、左、右侧Pane tmux swap-pange -U/-D/-L/-R：当前Pane上、下、左、右 移动 帮助 tmux list-key：列出所有绑定键 tmux list-command：列出所有命令 tmux info：列出当前所有Tmux会话信息 tmux source-file &lt;tmux-conf&gt;：重新加载Tmux配置文件 配置set 默认配置文件为~/.tmux.conf set[-option] [-g] [-a]：session选项 全局、追加标志 -g：全局设置 -a：追加设置，适合option需要字符串、样式值 default-terminal display-time escape-time history-limit base-index pane-base-index setw/set-window-option [-g] [-a]：window选项 全局、追加标志同set[-option] allow-rename mode-keys：快捷键模式，可以设置为vi synchronize-panes set[-option] -s：server选项 StatusBar设置 StatusBar主要由5部分组成 windows列表 windows-status-*：默认windows windows-status-current-*：当前windows windows-status-bell-*：后台有活动windows （需开启支持） 左侧显示区 右侧显示区 message显示条：占据整个status bar command输入条：占据整个status bar *-style bg=&lt;color&gt;,fg=&lt;color&gt;,&lt;ATTR&gt;指定样式 颜色可以用名称、colour[0-255]、#RGB方式指定 属性包括（前加no表关闭） bright dim underscore blink reverse hidden italics strikethrough *-format：设置格式 #{}中变量名称会被替换为相应值，支持alias缩写的变量 可以省略{} host：#H host_short：#h pane_id：#D pane_index：#P pane_title：#T session_name：#S window_flags：#F *：当前窗口 -：最后打开的窗口 z：Zoom窗口 window_index：#I window_name：#W #()会被作为shell命令执行并被替换 命令执行不会阻塞tmux，而是展示最近一次命令执行 结果 刷新频率由status-interval控制 这里介绍2.9之后配置风格 bind bind[-key] [-n] [-r] &lt;key&gt;：key mapping -n：无需prefix -r：此键可能重复 unbind &lt;key&gt;：解绑捕获 默认KeyMappings 快捷键前缀缺省为C-b &lt;prefix&gt;:：进入命令行 以下快捷键都是缺省值，可以解绑 Session s：列出session，可用于切换 $：重命名session d：detach当前session D：detach指定session Tab/Windows c：创建新tab &amp;：关闭当前tab ,：重命名当前tab .：修改当前tab索引编号 w：列出所有tab n/p/l：进入下个/上个/之前操作tab [tab-n]：切换到指定编号窗口 f：根据显示内容搜索tab tmux中window相当于tab Panes %：水平方向创建窗口 &quot;：竖直方向创建窗口 Up/Down/Left/Right：根据箭头访问切换窗口 q：显示窗口编号 o：顺时针切换窗口 }/{：与下个/上个窗口交换位置 space：在预置面板布局中循环切换 even-horizontal even-vertical main-horizontal main-vertical tiled !：将当前窗口置于新tab C-o/M-o：顺/逆时针旋转当前窗口，即所有窗口循环前/后 移动一个位次 t：在当前窗口显示时间 z：最大/恢复当前窗口 i：显示当前窗口信息 x：关闭当前窗口 q：显示当前窗口编号 [：进入自由复制模式，VI 模式下快捷键同 VI，且 &lt;space&gt;：从光标处开始选择（支持 V 选择行） &lt;enter&gt;：复制选择部分 ]：粘贴 tmux中pane相当于vim中windows 信息 ?：列出所有绑定键","link":"/Linux/Tool/tmux.html"},{"title":"常见分布","text":"离散连续P-stable Distributionsp_stable distribution：随机变量 $\\sum_i v_i X_i$ 、随机变量 $(\\sum_i |v_i|^p)^{1/p} X$ 具有相同的分布 $v_1, v_2, \\cdots, v_n$：任意实数 $X_1, X_2, \\cdots, X_n$：独立同分布$D$随机变量 $X$：服从分布$D$随机变量 $\\forall p \\in (0, 2]$，稳定分布存在，但仅$p=1,2$时，有解析解 $p=1$：柯西分布 c(x) = \\frac 1 \\pi \\frac 1 {1+x^2} $p=2$：高斯分布 g(x) = \\frac 1 {\\sqrt {2\\pi}} e^{-\\frac {x^2} 2} 可以从$[0,1]$上均匀分布获得稳定分布 但是概率分布、密度函数没有解析解 性质、用途 若向量 $a$ 中每个元素独立从 p-stable 分布中抽取，则 $|v|_p X = (\\sum_i |v_i|^p)^{1/p} X$ 和 $$ 同分布 可用较好计算的内积估计 $|v|_p$ 考虑到 $a(v_1 - v_2) = av_1 - av_2$，将内积和点之间 $L_p$ 范数距离 $|v_1 - v_2|_p$ 相联系 Exponential Family of Distributions单变量指数分布概率密度/分布 \\begin{align*} f_X(x|\\theta) &= h(x) e^{\\eta(\\theta) T(x) - A(\\theta)} \\\\ &= h(x) g(\\theta) e^{\\eta(\\theta) T(x)} \\\\ &= e^{\\eta(\\theta) T(x) - A(\\theta) + B(x)} \\end{align*} $\\eta(\\theta)$：nutural parameter，自然参数 $h(x)$：underlying measure，底层观测值 $T(x)$：sufficient statistic，随机变量X的充分统计量 $A(\\theta)$：log normalizer，对数规范化 $\\eta(\\theta), T(x)$：可以是向量，其内积仍为实数 $\\eta(\\theta) = \\theta$时，称分布族为canonical形式 总是能够定义$\\eta = \\eta(\\theta)$转为此形式 对数规范化$A(\\theta)$使得概率密度函数满足积分为1 \\begin{align*} f(x|\\theta) e^{A(\\theta)} & = h(x) e^{\\eta(\\theta)T(x)} \\\\ \\int e^{A(\\theta)} f(x|\\theta) dx & = \\int h(x) e^{\\eta(\\theta) T(x)} dx \\\\ e^{A(\\theta)} \\int f(x|\\theta) dx & = \\int h(x) e^{\\eta(\\theta) T(x)} dx \\\\ A(\\theta) & = ln \\int h(x) e^{\\eta(\\theta) T(x)} dx \\end{align*} https://zhuanlan.zhihu.com/p/148776108 性质 充分统计量$T(x)$可以使用固定几个值，从大量的独立同分布 数据中获取信息todo Bernoulli分布 $h(x) = 1$ $T(x) = x$ $\\eta = log \\frac \\theta {1 - \\theta}$ $A(\\theta) = ln(1+e^{\\theta})$ Possion $\\theta = \\lambda$ $h(x) = \\frac 1 {x!}$ $\\eta(\\theta) = ln\\lambda$ $T(x) = x$ $A(\\theta) = \\lambda$ Normal $h(x) = \\frac 1 {\\sqrt{2\\pi\\sigma^2}} e^{-\\frac {x^2} {2\\sigma^2}}$ $T(x) = \\frac x \\sigma$ $A(\\theta) = \\frac {\\mu^2} {2\\sigma^2}$ $\\eta(\\theta) = \\frac \\mu \\sigma$","link":"/Probability/distributions.html"},{"title":"统计推断","text":"Likelihood似然函数：表示统计模型参数中似然性的（参数的）函数 L(w|Y) = \\alpha P(Y|W=w) $Y$：观测所得结果，事件 $Y$ $W$：模型参数 $\\alpha$：正常量 似然函数可以理解为 条件概率的逆反 似然：在已知某些观测所得结果上，对有关事物性质的参数进行估计 似然性：某个参数为特定值的可能性 单独查看某个似然值无价值，要将各种似然值一起比较 概率：在已知某些参数上，预测之后观测所得到结果 形式上，似然函数也是条件概率函数，但关注统计模型中参数 似然函数不满足归一性，乘正常数仍然是似然函数 同一似然函数代表的模型中，某个参数具有多种可能，如果存在参数使得似然函数值最大，则该值为最合理的参数值 假设不同模型（经验得到），选择不同的统计模型 则有不同的概率密度（分布）函数，得到不同的似然函数 应用 最大似然估计：选取似然函数，整理之后求最大值点 实际中一般选取似然函数对数作为求解对象，结果同直接求似然函数最大值点 似然函数最大值点不一定唯一，也不一定存在 相较于矩估计 精度较高，信息损失少 计算量大 似然比检验：利用似然函数检测假设、限制是否有效 将加入某个限制的复杂某些的似然函数最大值和简单模型的似然函数最大值比较，检测某个参数限制是否正确 若参数限制正确，则不应造成似然函数最大值的大幅变动 尼曼-尼尔森引理 说明：似然比检验是所有具有同等显著性差异的检验中，最有统计效力的检验 条件概率分布似然函数\\begin{align*} L_P(W|X,Y) &= \\prod P(Y|X,W) \\\\ &= \\prod_{x,y} P(Y|X,W)^{N_{x,y}} \\\\ &= \\prod_{x,y} P(Y|X,W)^{N * \\tilde P(X,Y)} \\\\ log(L_P(W|X,Y)) &= N \\sum_{x,y} \\tilde P(X,Y) log(P(Y|X,W)) \\end{align*} $P$：（所选择）统计模型的概率分布函数 $\\tilde P$：$X,Y$ 的实际分布 $X,Y$：离散随机变量，$X$ 自变量观察值、$Y$ 因变量观察值 $W$：条件概率分布 $P$ 的参数 $N$，$N_{x,y}$：样本数量，取值为 $x,y$ 的样本数量 这里是条件概率分布的似然函数，用 $(X,Y)$ 联合分布同样 \\begin{align*} L_P &= \\prod P(X,Y|W) \\\\ &= \\prod P(Y|X,W) P(X|W) \\\\ &= \\prod P(Y|X,W) P(X) \\\\ &= \\prod P(Y|X,W) \\prod P(X) \\end{align*} 考虑 $W$ 是条件分布参数，与 $X$ 分布无关，有 $P(X|W) = P(X)$ 再考虑似然函数乘正常数不改变性质，则结果同上 对数似然函数中，样本量 $N$ 可省略","link":"/Probability/stat_inference.html"},{"title":"集合","text":"集合势 等势：若集合 $X, Y$ 之间存在双射 $\\phi: X \\rightarrow Y$，则称 $X, Y$ 等势 可数/可列集合：与自然数集合、其子集等势的集合称为可数集合，否则称为不可数集合 等势构成集合之间的等价关系 集合 $X$ 的等势类记为 $|X|$ 若存在单射 $\\phi: X \\rightarrow Y$，则记为 $|X| \\leq |Y|$ 一些基本结论 自然数集 $N = {0, 1, 2, 3, \\cdots}$ 和闭区间 $[0,1]$ 不等势 https://zhuanlan.zhihu.com/p/34097692 序 偏序集：若集合 $A$ 上有二元关系 $\\leq$ 满足以下性质，则称集合 $A$ 为偏序集，关系 $\\leq$ 称为偏序关系 反身性：$\\forall x \\in A, x \\leq x$ 传递性：$(x \\leq y) \\wedge (y \\leq z) \\Rightarrow x \\leq z$ 反称性：$(x \\leq y) \\wedge (y \\leq x) \\Rightarrow x = y$ 全序集：若 $\\leq$ 是集合上的偏序关系，若对每个$x, y \\in A$，必有 $x\\leq y$ 或 $y \\leq x$，则称集合 $A$ 为全序集，关系 $\\leq$ 为全序关系 良序集：若集合 $A$ 每个自己都有极小元，则称为良序集 特点 偏序指集合中只有部分成员之间可比较 全序指集合全体成员之间均可比较 良序集则是不存在无穷降链的全序集（可有无穷升链） 序数 序数：若集合 $A$ 中每个元素都是 $A$ 的子集，则称 $A$ 是传递的。而 $A$ 对于关系 $\\in$ 构成良序集，则称 $A$ 为序数 满足如下形式的集合即为序数 \\{\\phi, \\{\\phi\\}, \\{\\phi, \\{\\phi\\}\\}, \\{\\phi, \\{\\phi\\}, \\{\\phi, \\{\\phi\\}\\}\\} \\}, \\cdots 序数的性质（引理） 若 $\\alpha$ 为序数，$\\beta \\in \\alpha$，则 $\\beta$ 也是序数 对任意序数 $\\alpha, \\beta$，若 $\\alpha \\subset \\beta$，则 $\\alpha \\in \\beta$ 对任意序数 $\\alpha, \\beta$，必有 $\\alpha \\subseteq \\beta$ 或 $\\beta \\subseteq \\alpha$ 由以上，序数性质的解释 序数是唯一的，都满足上述形式 序数都是由自己之前的所有序数构造而来 对任意序数 $\\alpha$，有 $\\alpha = {\\beta: \\beta &lt; \\alpha }$ （$ &lt; $ 表示偏序关系） 将 $0, 1, 2, \\cdots$ 依次对应上述序数，即给出自然数和序数 0 := \\phi, 1 := \\{phi\\}, 2 := \\{\\phi, \\{phi\\}\\}, \\cdots https://zh.wikipedia.org/wiki/%E5%BA%8F%E6%95%B0 自然数可用于描述集合大小（势，基数）、序列中元素的位置（序，序数） 良序定理 Zermelo 良序定理：任何集合 $P$ 都能被赋予良序 Zermelo 良序定理和 ZFC 选择公理等价，可以由选择公理证明 由选择公理，可以一直从集合中选择元素，建立偏序关系 而集合有限，则集合和序数之间可以建立双射 基基数 基数：序数 $k$ 为基数，若对任意序数 $\\lambda &lt; k$，都有 $|\\lambda| &lt; |k|$ Counter 定理：设 $A$ 为集合，$P(A)$ 为 $A$ 的幂集，则有 $|A| \\leq |P(A)|$ 基数是集合势的标尺 数的集合的基数 自然数集合基数 $\\aleph_0$：最小的无限基数 实数集集合基数称为 continuum 连续统 连续统假设：不存在一个集合，基数在自然数集和连续统之间 哥德尔证明：连续统假设与公理化集合论体系 Zermelo-Fraenkel set theory with the axiom of choice 中不矛，即不能再 ZFC 中被证伪 科恩证明：连续统假设和 ZFC 彼此独立，不能在 ZFC 公理体系内证明、证伪 https://zh.wikipedia.org/wiki/%E5%9F%BA%E6%95%B0_(%E6%95%B0%E5%AD%A6)","link":"/Set/set_theory.html"},{"title":"常用等式","text":"常用定理Lucas 定理 C(n, m) \\% p = (C(n//p, m//p) * C(n\\%p, m\\%p)) \\% p $p &lt; 10^5$：必须为素数 Holder 定理$|x|^{*}_p = |x|_q$ $\\frac 1 p + \\frac 1 q = 1$","link":"/Math-Mixin/equality.html"},{"title":"概率不等式","text":"InequalityAzuma-Hoeffding InequalityAzuma-Hoeffding 不等式：设 ${Xi:i=0,1,2,\\cdots}$ 是鞅差序列，且 $|X_k - X{k-1}| &lt; c_k$，则 \\begin{align*} super-martingale: P(X_N - X_0 \\geq t) \\leq exp \\left ( \\frac {-t^2} {2\\sum^N_{k=1} c_k^2} \\right ) \\\\ sub-martingale: P(X_N - X_0 \\leq -t) \\leq exp \\left ( \\frac {-t^2} {2\\sum^N_{k=1} c_k^2} \\right ) \\\\ martingale: P(|X_N - X_0| \\geq t) \\leq exp \\left ( \\frac {-t^2} {2\\sum^N_{k=1} c_k^2} \\right ) \\end{align*}Hoeffding InequalityHoeffding 不等式：考虑随机变量序列 $X_1, X_2, \\cdots, X_N, X_i \\in [a_i, b_i]$ 对随机变量 $\\bar X = \\frac 1 N \\sum_{i=1}^N {X_i}$，对任意 $t&gt;0$ 满足 \\begin{align*} P(\\bar X - E \\bar X \\geq t) \\leq exp(\\frac {-2N^2t^2} {\\sum_{i=1}^N (b_i - a_i)^2} ) \\\\ P(E \\bar X - \\bar X \\geq t) \\leq exp(\\frac {-2N^2t^2} {\\sum_{i=1}^N (b_i - a_i)^2} ) \\\\ \\end{align*} 对随机变量 $SN = \\sum{i=1}^N X_i$，对任意 $t&gt;0$ 满足 \\begin{align*} P(S_N - E S_N \\geqslant t) & \\leqslant exp \\left ( \\frac {-2t^2} {\\sum_{i=1}^n (b_i - a_i)^2} \\right ) \\\\ P(E S_N - S_N \\geqslant t) & \\leqslant exp \\left ( \\frac {-2t^2} {\\sum_{i=1}^n (b_i - a_i)^2} \\right ) \\\\ \\end{align*} 两不等式可用绝对值合并，但将不够精确 Bretagnolle-Huber-Carol InequilityBretagnolle-Huber-Carol 不等式：${X_i: i=1,2,\\cdots,N} i.i.d. M(p1, p_2, \\cdots, p_k)$ 服从类别为 $k$ 的多项分布 p{\\sum_{i=1}^k |N_i - Np_i| \\geq \\epsilon} \\leq 2^k exp \\left ( \\frac {- n\\epsilon^2} 2 \\right ) $N_i$：第 $i$ 类实际个数","link":"/Probability/inequality.html"},{"title":"常用不等式","text":"Cauthy-Schwarz 不等式 https://zhuanlan.zhihu.com/p/22004031 https://zhuanlan.zhihu.com/p/129033407 https://zhuanlan.zhihu.com/p/70315155 https://zhuanlan.zhihu.com/p/85283405","link":"/Math-Mixin/inequality.html"},{"title":"未归类概念","text":"Radial Basis Function RBF 径向基函数：取值仅依赖到原点距离的实值函数，即 $\\phi(x) = \\phi(|x|)$ 也可以按照距离某中心点 $c$ 的距离定义，即 $\\phi(x) = \\phi(|x-c|)$ 其中距离一般为使用 $L_2$ 范数，即欧式距离 函数 $\\phi$ 一般与 $|x|$ 负相关 径向基函数最初用于解决多变量插值问题 即以各样本为中心创建多个径向基函数 多个径向基函数加权加和即得到拟合的函数曲线，可用于函数插值 常见径向基函数 定义 $r=|x-x_i|$ 高斯函数 \\phi(r) = e^{-(\\epsilon r)^2} Multiquadric 多二次函数： \\phi(r) = \\sqrt {1 + (\\epsilon r)^2} Inverse Quadric 逆二次函数： \\phi(r) = \\frac 1 {1 + (\\epsilon r)^2} Polyharmonic Spline 多重调和样条： \\begin{align*} \\phi(r) &= r^k, & k=1,3,5,\\cdots \\\\ \\phi(r) &= r^k (ln(r))^{}, & k=2,4,6,\\cdots \\\\ \\end{align*} Thin Plate Spline 薄板样条（多重调和样条特例）： \\phi(r) = r^2 ln(r)","link":"/Math-Mixin/uncharted_concepts.html"},{"title":"函数说明","text":"约定 I：示性/指示函数 满足条件时取1，否则取0 sign：符号函数 &gt;0：取1 &lt;0：取-1","link":"/Math-Mixin/README.html"},{"title":"距离函数","text":"距离 距离可认为是两个对象 $x,y$ 之间的 相似程度 距离和相似度是互补的 可以根据处理问题的情况，自定义距离 Bregman Divergence D(x, y) = \\Phi(x) - \\Phi(y) - $Phi(x)$：凸函数 布雷格曼散度：穷尽所有关于“正常距离”的定义 给定 $R^n * R^n \\rightarrow R$ 上的正常距离 $D(x,y)$，一定可以表示成布雷格曼散度形式 直观上：$x$处函数、函数过$y$点切线（线性近似）之差 可以视为是损失、失真函数：$x$由$y$失真、近似、添加噪声得到 特点 非对称：$D(x, y) = D(y, x)$ 不满足三角不等式：$D(x, z) \\leq D(x, y) + D(y, z)$ 对凸集作 Bregman Projection 唯一 即寻找凸集中与给定点Bregman散度最小点 一般的投影指欧式距离最小 Domain $\\Phi(x)$ $D_{\\Phi}(x,y)$ Divergence $R$ $x^2$ $(x-y)^2$ Squared Loss $R_{+}$ $xlogx$ $xlog(\\frac x y) - (x-y)$ $[0,1]$ $xlogx + (1-x)log(1-x)$ $xlog(\\frac x y) + (1-x)log(\\frac {1-x} {1-y})$ Logistic Loss $R_{++}$ $-logx$ $\\frac x y - log(\\frac x y) - 1$ Itakura-Saito Distance $R$ $e^x$ $e^x - e^y - (x-y)e^y$ $R^d$ $\\ x\\ $ $\\ x-y\\ $ Squared Euclidean Distance $R^d$ $x^TAx$ $(x-y)^T A (x-y)$ Mahalanobis Distance d-Simplex $\\sum_{j=1}^d x_j log_2 x_j$ $\\sum_{j=1}^d x_j log_2 log(\\frac {x_j} {y_j})$ KL-divergence $R_{+}^d$ $\\sum_{j=1}^d x_j log x_j$ $\\sum{j=1}^d x_j log(\\frac {x_j} {y_j}) - \\sum{j=1}^d (x_j - y_j)$ Genelized I-divergence 正常距离：对满足任意概率分布的点，点平均值点（期望点）应该是空间中距离所有点平均距离最小的点 布雷格曼散度对一般概率分布均成立，而其本身限定由凸函数生成 和 Jensen 不等式有关？凸函数隐含部分对期望的度量 http://www.jmlr.org/papers/volume6/banerjee05b/banerjee05b.pdf 单点距离Minkowski Distance闵科夫斯基距离：向量空间 $\\mathcal{L_p}$ 范数 d_{12} = \\sqrt [1/p] {\\sum_{k=1}^n |x_{1,k} - x_{2,k}|^p} 表示一组距离族 $p=1$：Manhattan Distance，曼哈顿距离 $p=2$：Euclidean Distance，欧式距离 $p \\rightarrow \\infty$：Chebychev Distance，切比雪夫距离 闵氏距离缺陷 将各个分量量纲视作相同 未考虑各个分量的分布 Mahalanobis Distance马氏距离：表示数据的协方差距离 d_{12} = \\sqrt {({x_1-\\mu}^T) \\Sigma^{-1} (x_2-\\mu)} $\\Sigma$：总体协方差矩阵 优点 马氏距离和原始数据量纲无关 考虑变量相关性 缺点 需要知道总体协方差矩阵，使用样本估计效果不好 LW Distance兰氏距离：Lance and Williams Distance，堪培拉距离 d_{12} = \\sum^{n}_{k=1} \\frac {|x_{1,k} - x_{2,k}|} {|x_{1,k} + x_{2,k}|} 特点 对接近0的值非常敏感 对量纲不敏感 未考虑变量直接相关性，认为变量之间相互独立 Hamming Distance汉明距离：差别 diff = \\frac 1 p \\sum_{i=1}^p (v^{(1)}_i - v^{(2)}_i)^k $v_i \\in {0, 1}$：虚拟变量 $p$：虚拟变量数量 可以衡量定性变量之间的距离 Embedding 找到所有点、所有维度坐标值中最大值 $C$ 对每个点 $P=(x_1, x_2, \\cdots, x_d)$ 将每维 $x_i$ 转换为长度为 $C$ 的 0、1 序列 其中前 $x_i$ 个值为 1，之后为 0 将 $d$ 个长度为 $C$ 的序列连接，形成长度为 $d * C$ 的序列 以上汉明距离空间嵌入对曼哈顿距离是保距的 Jaccard 系数Jaccard 系数：度量两个集合的相似度，值越大相似度越高 sim = \\frac {\\|S_1 \\hat S_2\\|} {\\|S_1 \\cup S_2\\|} $S_1, S_2$：待度量相似度的两个集合 Consine Similarity余弦相似度 similarity = cos(\\theta) = \\frac {x_1 x_2} {\\|x_1\\|\\|x_2\\|} $x_1, x_2$：向量 欧式距离点到平面 $T={(x_1,y_1),(x_2,y_2),\\cdots,(x_n,y_n)}$：样本点集 $wx + b = 0$：超平面 Functional Margin 函数间隔 \\hat{\\gamma_i} = y_i(wx_i + b) 函数间隔可以表示分类的正确性、确信度 正值表示正确 间隔越大确信度越高 点集与超平面的函数间隔取点间隔最小值 $\\hat{T} = \\min_{i=1,2,\\cdots,n} \\hat{\\gamma_i}$ 超平面参数 $w, b$ 成比例改变时，平面未变化，但是函数间隔成比例变化 Geometric Margin 几何间隔\\begin{align*} \\gamma_i & = \\frac {y_i} {\\|w\\|} (wx_i + b) \\\\ & = \\frac {\\hat \\gamma_i} {\\|w\\|} \\end{align*} 几何间隔一般是样本点到超平面的 signed distance 点正确分类时，几何间隔就是点到直线的距离 几何间隔相当于使用 $|w|$ 对函数间隔作规范化 $|w|=1$ 时，两者相等 几何间隔对确定超平面、样本点是确定的，不会因为超平面表示形式改变而改变 点集与超平面的几何间隔取点间隔最小值 $\\hat{T} = \\min_{i=1,2,\\cdots,n} \\hat{\\gamma_i}$ Levenshtein/Edit Distance（字符串）编辑距离：两个字符串转换需要进行插入、删除、替换操作的次数 lev_{A,B}(i, j) = \\left \\{ \\begin{array}{l} i, & j = 0 \\\\ j, & i = 0 \\\\ min \\left \\{ \\begin{array}{l} lev_{A,B}(i,j-1) + 1 \\\\ lev_{A,B}(i-1,j) + 1 \\\\ lev_{A,B}(i-1, j-1) + 1 \\end{array} \\right. & A[i] != B[j] \\\\ min \\left \\{ \\begin{array}{l} lev_{A,B}(i,j-1) + 1 \\\\ lev_{A,B}(i-1,j) + 1 \\\\ lev_{A,B}(i-1, j-1) \\end{array} \\right. & A[i] = B[j] \\\\ \\end{array} \\right.组间距离Single LinkageAverage LinkageComplete Linkage","link":"/Math-Mixin/func_distance.html"},{"title":"Kernel Function","text":"Kernel Function 对输入空间 $X$ （欧式空间 $R^n$ 的子集或离散集合）、特征空间 $H$ ，若存在从映射 $$ \\phi(x): X \\rightarrow H 使得对所有 $x, z \\in X$ ，函数 $K(x,z)$ 满足 K(x,z) = \\phi(x) \\phi(z) $$ 则称 $K(x,z)$ 为核函数、 $\\phi(x)$ 为映射函数，其中 $\\phi(x) \\phi(z)$ 表示内积 特征空间 $H$ 一般为无穷维 特征空间必须为希尔伯特空间（内积完备空间） 映射函数 $\\phi$ 映射函数 $\\phi$：输入空间 $R^n$ 到特征空间的映射 $H$ 的映射 对于给定的核 $K(x,z)$ ，映射函数取法不唯一，映射目标的特征空间可以不同，同一特征空间也可以取不同映射，如： 对核函数 $K(x, y) = (x y)^2$ ，输入空间为 $R^2$ ，有 \\begin{align*} (xy)^2 & = (x_1y_1 + x_2y_2)^2 \\\\ & = (x_1y_1)^2 + 2x_1y_1x_2y_2 + (x_2y_2)^2 \\end{align*} 若特征空间为$R^3$，取映射 \\phi(x) = (x_1^2, \\sqrt 2 x_1x_2, x_2^2)^T或取映射 \\phi(x) = \\frac 1 {\\sqrt 2} (x_1^2 - x_2^2, 2x_1x_2, x_1^2 + x_2^2)^T 若特征空间为$R^4$，取映射 \\phi(x) = (x_1^2, x_1x_2, x_1x_2, x_2^2)^T 核函数 $K(x,z)$ Kernel Trick 核技巧：利用核函数简化映射函数 $\\phi(x)$ 映射、内积的计算技巧 避免实际计算映射函数 避免高维向量空间向量的存储 核函数即在核技巧中应用的函数 实务中往往寻找到的合适的核函数即可，不关心对应的映射函数 单个核函数可以对应多个映射、特征空间 核技巧常被用于分类器中 根据 Cover’s 定理，核技巧可用于非线性分类问题，如在 SVM 中常用 核函数的作用范围：梯度变化较大的区域 梯度变化小的区域，核函数值变化不大，所以没有区分能力 Cover’s 定理可以简单表述为：非线性分类问题映射到高维空间后更有可能线性可分 正定核函数 设 $X \\subset R^n$，$K(x,z)$ 是定义在 $X X$的对称函数，若 $\\forall x_i \\in \\mathcal{X}, i=1,2,…,m$，$K(x,z)$ 对应的 Gram* 矩阵 $$ G = [K(x_i, x_j)]_{m*m} $$ 是半正定矩阵，则称 $K(x,z)$ 为正定核 可用于指导构造核函数 检验具体函数是否为正定核函数不容易 正定核具有优秀性质 SVM 中正定核能保证优化问题为凸二次规划，即二次规划中矩阵 $G$ 为正定矩阵 欧式空间核函数Linear Kernel线性核：最简单的核函数 k(x, y) = x^T y 特点 适用线性核的核算法通常同普通算法结果相同 KPCA 使用线性核等同于普通 PCA Polynomial Kernel多项式核：non-stational kernel K(x, y) = (\\alpha x^T y + c)^p 特点 适合正交归一化后的数据 参数较多，稳定todo 应用场合 SVM：p 次多项式分类器 f(x) = sgn(\\sum_{i=1}^{N_s} \\alpha_i^{*} y_i (x_i x + 1)^p + b^{*}) Gaussian Kernel高斯核：radial basis kernel，经典的稳健径向基核 K(x, y) = exp(-\\frac {\\|x - y\\|^2} {2\\sigma^2}) $\\sigma$：带通，取值关于核函数效果，影响高斯分布形状 高估：分布过于集中，靠近边缘非常平缓，表现类似像线性一样，非线性能力失效 低估：分布过于平缓，失去正则化能力，决策边界对噪声高度敏感 特点 对数据中噪声有较好的抗干扰能力 对应映射：省略分母 \\begin{align*} K(x, y) & = exp(-(x - y)^2) \\\\ & = exp(-(x^2 - 2 x y - y^2)) \\\\ & = exp(-x^2) exp(-y^2) exp(2xy) \\\\ & = exp(-x^2) exp(-y^2) \\sum_{i=0}^\\infty \\frac {(2xy)^i} {i!} \\\\ & = \\phi(x) \\phi(y) \\\\ \\phi(x) & = exp(-x^2)\\sum_{i=0}^\\infty \\sqrt {\\frac {2^i} {i!}} x^i \\end{align*}即高斯核能够把数据映射至无穷维 应用场合 SVM：高斯radial basis function分类器 f(x) = sgn(\\sum_{i=1}^{N_s} \\alpha_i^{*} y_i exp(-\\frac {\\|x - y\\|^2} {2\\sigma^2}) + b^{*}) Exponential Kernel指数核：高斯核变种，仅去掉范数的平方，也是径向基核 K(x, y) = exp(-\\frac {\\|x - y\\|} {2\\sigma^2}) 降低了对参数的依赖性 适用范围相对狭窄 Laplacian Kernel拉普拉斯核：完全等同于的指数核，只是对参数$\\sigma$改变敏感 性稍低，也是径向基核 K(x, y) = exp(-\\frac {\\|x - y\\|} {\\sigma^2})ANOVA Kernel方差核：径向基核 k(x,y) = \\sum_{k=1}^n exp(-\\sigma(x^k - y^k)^2)^d 在多维回归问题中效果很好 Hyperbolic Tangent/Sigmoid/Multilayer Perceptron KernelSigmoid核：来自神经网络领域，被用作人工神经元的激活函数 k(x, y) = tanh(\\alpha x^T y + c) 条件正定，但是实际应用中效果不错 参数 $\\alpha$：通常设置为$1/N$，N是数据维度 使用Sigmoid核的SVM等同于两层感知机神经网络 Ration Quadratic Kernel二次有理核：替代高斯核，计算耗时较小 k(x, y) = 1 - \\frac {\\|x - y\\|^2} {\\|x - y\\|^2 + c}Multiquadric Kernel多元二次核：适用范围同二次有理核，是非正定核 k(x, y) = \\sqrt {\\|x - y\\|^2 + c^2}Inverse Multiquadric Kernel逆多元二次核：和高斯核一样，产生满秩核矩阵，产生无穷维的 特征空间 k(x, y) = \\frac 1 {\\sqrt {\\|x - y\\|^2 + c^2}}Circular Kernel环形核：从统计角度考虑的核，各向同性稳定核，在$R^2$上正定 k(x, y) = \\frac 2 \\pi arccos(-\\frac {\\|x - y\\|} \\sigma) - \\frac 2 \\pi \\frac {\\|x - y\\|} \\sigma \\sqrt{1- \\frac {\\|x - y\\|^2} \\sigma}Spherical Kernel类似环形核，在$R^3$上正定 k(x, y) = 1 - \\frac 3 2 \\frac {\\|x - y\\|} \\sigma + \\frac 1 2 (\\frac {\\|x - y\\|} \\sigma)^3Wave Kernel波动核 k(x, y) = \\frac \\theta {\\|x - y\\|} sin(\\frac {\\|x - y\\|} \\theta) 适用于语音处理场景 Triangular/Power Kernel三角核/幂核：量纲不变核，条件正定 k(x, y) = - \\|x - y\\|^dLog Kernel对数核：在图像分隔上经常被使用，条件正定 k(x, y) = -log(1 + \\|x - y\\|^d)Spline Kernel样条核：以分段三次多项式形式给出 k(x, y) = 1 + x^t y + x^t y min(x, y) - \\frac {x + y} 2 min(x, y)^2 + \\frac 1 3 min(x, y)^2B-Spline KernelB-样条核：径向基核，通过递归形式给出 \\begin{align*} k(x, y) & = \\prod_{p=1}^d B_{2n+1}(x_p - y_p) \\\\ B_n(x) & = B_{n-1} \\otimes B_0 \\\\ & = \\frac 1 {n!} \\sum_{k=0}^{n+1} \\binom {n+1} {r} (-1)^k (x + \\frac {n+1} 2 - k)_{+}^n \\end{align*} $x_{+}^d$：截断幂函数x_{+}^d = \\left \\{ \\begin{array}{l} x^d, & if x > 0 \\\\ 0, & otherwise \\\\ \\end{array} \\right. Bessel KernelBessel核：在theory of function spaces of fractional smoothness 中非常有名 k(x, y) = \\frac {J_{v+1}(\\sigma\\|x - y\\|)} {\\|x - y\\|^{-n(v + 1)}} $J$：第一类Bessel函数 Cauchy Kernel柯西核：源自柯西分布，是长尾核，定义域广泛，可以用于原始维度 很高的数据 k(x, y) = \\frac 1 {1 + \\frac {\\|x - y\\|^2} {\\sigma}}Chi-Square Kernel卡方核：源自卡方分布 \\begin{align*} k(x, y) & = 1 - \\sum_{i=1}^d \\frac {(x_i - y_i)^2} {\\frac 1 2 (x_i + y_i)} \\\\ & \\frac {x^t y} {\\|x + y\\|} \\end{align*}Histogram Intersection/Min Kernel直方图交叉核：在图像分类中经常用到，适用于图像的直方图特征 k(x, y) = \\sum_{i=1}^d min(x_i, y_i)Generalized Histogram Intersection广义直方图交叉核：直方图交叉核的扩展，可以应用于更多领域 k(x, y) = \\sum_{i=1}^m min(|x_i|^\\alpha, |y_i|^\\beta)Bayesian Kernel贝叶斯核：取决于建模的问题 \\begin{align*} k(x, y) & = \\prod_{i=1}^d k_i (x_i, y_i) \\\\ k_i(a, b) & = \\sum_{c \\in \\{0, 1\\}} P(Y=c | X_i = a) P(Y=c | x_k = b) \\end{align*}Wavelet Kernel波核：源自波理论 k(x, y) = \\prod_{i=1}^d h(\\frac {x_i - c} a) h(\\frac {y_i - c} a) 参数 $c$：波的膨胀速率 $a$：波的转化速率 $h$：母波函数，可能的一个函数为 h(x) = cos(1.75 x) exp(-\\frac {x^2} 2) 转化不变版本如下 k(x, y) = \\prod_{i=1}^d h(\\frac {x_i - y_i} a) 离散数据核函数String Kernel字符串核函数：定义在字符串集合（离散数据集合）上的核函数 \\begin{align*} k_n(s, t) & = \\sum_{u \\in \\sum^n} [\\phi_n(s)]_u [\\phi_n(t)]_u \\\\ & = \\sum_{u \\in \\sum^n} \\sum_{(i,j): s(i) = t(j) = u} \\lambda^{l(i)} \\lambda^{l(j)} \\end{align*} $[\\phin(s)]_n = \\sum{i:s(i)=u} \\lambda^{l(i)}$：长度 大于等于n的字符串集合$S$到特征空间 $\\mathcal{H} = R^{\\sum^n}$的映射，目标特征空间每维对应 一个字符串$u \\in \\sum^n$ $\\sum$：有限字符表 $\\sum^n$：$\\sum$中元素构成，长度为n的字符串集合 $u = s(i) = s(i1)s(i_2)\\cdots s(i{|u|})$：字符串s的 子串u（其自身也可以用此方式表示） $i =(i1, i_2, \\cdots, i{|u|}), 1 \\leq i1 &lt; i_2 &lt; … &lt; i{|u|} \\leq |s|$：序列指标 $l(i) = i_{|u|} - i_1 + 1 \\geq |u|$：字符串长度，仅在 序列指标$i$连续时取等号（$j$同） $0 &lt; \\lambda \\leq 1$：衰减参数 两个字符串s、t上的字符串核函数，是基于映射$\\phi_n$的 特征空间中的内积 给出了字符串中长度为n的所有子串组成的特征向量的余弦 相似度 直观上，两字符串相同子串越多，其越相似，核函数值越大 核函数值可由动态规划快速计算（只需要计算两字符串公共 子序列即可） 应用场合 文本分类 信息检索 信物信息学","link":"/Math-Mixin/func_kernels.html"},{"title":"马恩的社会主义观","text":"生产资料：社会所有制、公有制 经济运行方式：消灭商品货币关系，实行有组织的计划生产 分配方式：实行按劳分配 阶级与国家：消灭了阶级和阶级差别，消灭了作为阶级统治工具的国家 对于斯大林和现实中国的社会主义观与马列的社会注意观之间的差异， 做出符合现实与逻辑的、一以贯之的解释 既是理论对我们提出的挑战， 也是社会建设的实践要求剋人 因此这个问题的回答，或者说正确解决这个矛盾，就具有重要的理论 意义和实践意义 在资本主义社会和共产主义社会之间，有一个从前者转变为后者 的个命转变时期，同这个时期相适应的也有一个政治上的过渡时期， 这个时期的国家，只能是国产阶级的革命专政 社会主义初级阶段 社会性质，已经是社会主义了 还处于社会主义社会初级阶段，还没有根本摆脱贫穷落后的不发达状态 实际上处于马克思讲的从资本主义社会向社会主义社会过渡时期， 是过渡时期中的一个比较初级的阶段 重新定位社会主义初级阶段的意义 可以消除现实与马列理论间的诸多矛盾，端正被扭曲的马克思主义 理论与社会主义形象 在实践中脚踏实地，从当代中国现实国情触发，探索具有中国特色 的通向社会主义的道路，更好的沿着社会主义方向前进 邓小平 社会主义初级阶段最根本任务就是发展生产力，社会主义的优越性 归根结底就是体现在他的生产力比资本主义发展得更快一些、更高 一些， 改革都是为了一个目的，就是扫除发展社会生产力障碍 对内搞活了经济，是活了社会主义，没有伤害社会主义的本质，因为 从政治上讲，我们的国家机器是社会主义性质得， 有能力保障 社会主义制度，从经济上讲，我国的社会主义经济在工业、农业、 商业和其他方面已经建立相当坚实的基础 社会主义的目的就是要全国人民共同富裕，不是两极分化。如果我们 的政策导致了两级分化，我们就失败了；如果产生了什么新的资产 阶级，那么我们就整的走了邪路了 公有制占主体，共同富裕，是我们必须坚持的社会主义根本原则 概括 要发展生产力 要坚持公有制和按劳分配为主体 走共同富裕道路，防止出现两极分化 坚持四项基本原则 市场与计划都是手段，利用资本主义发展社会主义 用三个有利于的标准衡量改革开放的成就 社会主义本质解放生产力，发展生产力，消灭剥削，消除两极分化，最终达到共同富裕 在高于特征的层次上，在目标和目的的层次上揭示了社会主义 的内在要求 突出生产力的基础地位，是对社会主义的具有时代特征的新认识 突出了社会主义的目的共同富裕 在动态中描述了社会主义的本质 社会主义的根本任务：发展生产力 理论上：发展生产力是马克思主义的基本原则 实践上：是解决社会主义初级阶段主要矛盾的要求 前途上：是巩固社会主义制度、增强社会主义吸引力， 向共产主义过渡的根本途径 生产力与社会主义关系 阶级斗争和社会革命并不同工业发达程度、生产力发展水平成正比， 经验的研究似乎是，它只在大工业的发展时期的一定阶段才有可能 共产主义个命将在一切文明国家里同时发生，就这些文明国家而言， 由于资本主义发展不均衡，生产力发展水平也是有区别的 革命的发生、完成要区别开来，受资本主义大生产和世界市场的 存在，发生革命的先后次序，并不单纯取决于一国的生产力发展水平 开始革命，走上社会主义道路，可以不经过资本主义充分发展的阶段， 但是完成革命，实现社会主义乃至共产主义，则非有生产力的巨大 发展不可 人类社会发展规律不可改变，资本主义虽然不能避免，但是资本 主义制度可以避免，可以缩短，过渡阶段就是对资本主义阶段的补课 ，对经济文化落后国家，问题是如何发展、利用、节制资本主义 毛思中的社会主义理论 在一个经济文化比较落后的国家，在新民主主义革命胜利后，如何 过渡到社会主义 在社会主义改造完成之后，如何进行社会主义建设 准备过渡—-&gt;开始过渡 已经开始执行社会主义革命的任务 没收官僚资本，建立社会主义性质的国营经济 只有没收了占比80%的官僚资本，才能对20%的民族资本 采取和平的方式，逐步进行社会主义改造 开始引导私人资本主义经济走国家资本主义的道路 赎买：为了便于过渡到社会主义，保持极大的生产 组织是很重要的 民族资产阶级有两面性，是内部矛盾 为什么接受 社会主义力量增长，政权在手中 社会主义性质经济基本控制了国家经济命脉，在国民 经济中处于领导地位和作用 制定了适宜的政策、方法 为什么愿意 政治上，民族资产阶级拥护国家、宪法、共同纲领 经济上，民族资产阶级原因接受国家资本主义、国家的 引导和监督，民族资本的存在对于加速国民经济的恢复 发展有重要作用 历史上，不愿看到同一战线破裂 可以让工人阶级学会如何管理工商业，经营、组织生产 引导个体农民走上了互助合作社的道路 新民主主义社会是一个具有过渡性质的社会 这个革命的性质是社会主义革命 革命的性质是由社会的主要矛盾决定的 过渡时期总路线 主体：国家工业化 主体？ 工业化时生产力发展水平的重要标致 近代中国的两大任务：民族独立和人民解放，国家繁荣富强 两翼：农业、手工业和资本主义工商业的改造 工业化和社会主义改造并举的路线 工业化道路 资本主义工业化道路走不通 民族资本主义脆弱 不满足条件 有大量人身自由，但丧失了生产资料的无产者存在 大量货币集中在少数人手里 社会主义 国营经济力量比较强大 民族资本主义经济弱小，不能成为主义依靠力量 对个体农业的社会主义改造，是实现国家工业化的必要条件 国际环境促使中国选择了社会主义 国家资本主义改造资本主义工商业的过渡形式，不是独立经济形态，性质随国家 性质而转移 资本主义制度：资产阶级政府直接产于国家经济生活，通过国有化 或国家预算建设新的企业等办法，使国民经济某些部门、企业转移到 国家手里 社会主义制度：能够加以限制、规定活动范围的资本主义，同国家 联系着 三种形式 初级：国营经济与资本主义经济在企业外部发生不固定联系 中极：国营经济和资本主义经济在企业外部发生固定联系 以上仍然资本主义性质，追逐理论最大化 但是和国营经济的密切联系，在一定程度上被纳入国家计划 轨道，限制了剥削 高级：国营经济和资本主义经济在企业内部联系合作、并居于领导 地位，即公私合营经济，包括单个企业和全行业 社会主义控制企业流通过程、生产过程 私人资本具有资本性质，但是已经失去了独立地位 农村社会主义农民工体经济：生产资料归农民私有，与个人劳动相结合的半自然经济 或小商品经济 生产资料私有—&gt;发展个体经济的积极性—&gt;自发的资本主倾向 以自身劳动去基础，不存在剥削—&gt;互助合作积极性—&gt; 被引导走向社会主义 农业合作化 限制生产力法渐 分散性、盲目性同国营经济、工业化目标冲突 小农经济不稳定，必然导致农村不稳定","link":"/Daily-Life/Maxism/marxism.html"},{"title":"Data Science","text":"名词Statistic - Frequentist and Bayesian统计：数学分支，概率论和优化的交集，是数据科学其他分支的理论基础 分析方法：验证式分析 统计建模：基于数据构建统计模型，并验证假设 模型预测：运用模型对数据进行预测、分析 理论依据：模型驱动，严格的数理支撑 理论体系 概率论、信息论、计算理论、最优化理论、计算机学科等多个领域的交叉学科 并在发展中形成独自的理论体系、方法论 基本假设：同类数据具有一定的统计规律性，可以用概率统计方法加以处理，推断总体特征，如 随机变量描述数据特征 概率分布描述数据统计规律 分析对象：以样本为分析对象 从数据出发，提取数据特征、抽象数据模型、发现数据知识，再回到对数据的分析与预测 数据多种多样，包括数字、文字、图像、音视频及其组合 假设数据独立同分布产生 训练数据集往往是人工给出的 Data Mining 从现有的信息中提取数据的 pattern、model，即精选最重要、可理解的、有价值的信息 核心目的在于找到 数据变量之间的关系 不是证明假说的方法，而是构建假说的方法 大数据 的发展，传统的数据分析方式无法处理大量“不相关”数据 常用技术 cluster analysis：聚类分析，揭示数据内在结构 classification：判别分析，数据预测 regression/decision trees：决策树，模型图形化展示 neural networks：神经网络 联系 本质上看起来像是 ML、AI 的基础 会使用大量机器学习算法，但是特定的环境、目的和ML不同 建模一般策略：类似机器学习 将数据视为高维空间中的点，在高维空间中找到分类面、回归面 Artificial Intelligence 研究如何创造智能 agent，并不一定涉及学习、归纳 但是大部分情况下，智能 需要从过去的经验中进行归纳，所以 AI 中很大一部分是 ML Machine Learning机器学习：从有限观测数据中学习一般性规律，并将规律应用到未观测样本中进行预测（最基本的就是在不确定中得出结论） 分析方法：归纳式、探索式分析 理论依据：数据驱动，从数据中中学习知识， 分析对象：对样本要求低，样本往往不具有随机样本的特征 机器学习建模：不假设，通过对高维空间的搜索，找到数据隐藏规律的恰当概括 Shallow Learning浅层学习：不涉及特征学习，特征抽取依靠人工经验、特征转换方法 传统机器学习可以视为浅层学习 步骤 数据预处理 特征提取 特征转换 预测 Deep Learning深度学习：将原始数据特征通过多步特征转换得到更高层次、抽象的特征表示，进一步输入到预测函数得到最终结果 主要目的是从数据中自动学习到有效的特征表示 替代人工设计的特征，避免“特征”工程 模型深度不断增加，特征表示能力越强，后续预测更容易 相较于浅层学习：需要解决的关键问题是贡献度分配问题 从某种意义上说，深度学习也可以视为强化学习 内部组件不能直接得到监督信息，需要通过整个模型的最终监督信息得到，有延时 目前深度学习模型主要是神经网络模型 神经网络可以使用反向传播算法，较好的解决贡献度分配问题 credit assignment problem：贡献度分配问题，系统中不同组件、参数对最终系统输出结果的贡献、影响 深度：原始数据进行非线性特征转换的次数，将深度学习系统看作有向图结构，深度可以看作是从输入节点到输出节点经过最长路径长度 Representing Learning表示学习：自动学习有效特征、提高最终机器学习模型性能的学习 好的学习标准 较强的表示能力：同样大小向量可以表示更多信息 简化后续学习任务：需要包含更高层次语义信息 具有一般性，是任务、领域独立的：期望学到的表示可以容易迁移到其他任务 要学习好的高层语义（分布式表示），需要从底层特征开始，经过多步非线程转换得到 深层结构的优点式可以增加特征重用性，指数级增加表示能力 所以表示学习的关键是构建具有一定深度、多层次特征表示 传统机器学习中也有关于特征学习的算法，如：主成分分析、线性判别分析、独立成分分析 通过认为设计准则，用于选取有效特征 特征学习、最终预测模型的学习是分开进行的，学习到的特征不一定可以用于提升最终模型分类性能 Semantic Gap：语义鸿沟，输入数据底层特征和高层语义信息之间不一致性、差异性 表示 Local Representation：局部表示，离散表示/符号表示 通常可以表示为 one-hot 向量形式 每个特征作为高维局部表示空间中轴上点 不足 one-hot 维数很高、不方便扩展 不同特征取值相似度无法衡量 Distributed Representation：分布式表示 通常可以表示为 低维、稠密 向量 分散在整个低维嵌入空间中中 表示能力强于局部表示 维数低 容易计算相似度 神经网络可以用于将高维局部空间 $R^{|V|}$ 映射到非常低维分布式表示空间 $R^d$ End-to-End Learning端到端学习/训练：学习过程中不进行分模块、分阶段训练，直接优化任务的总体目标 不需要给出不同模块、阶段功能，中间过程不需要认为干预 训练数据为“输入-输出”对形式，无需提供其他额外信息 和深度学习一样，都是要解决“贡献度分配”问题 大部分神经网络模型的深度学习可以看作是端到端学习 Learning ComponentsModel/Hypothesis/Opimizee/Learner/Learning Algorithm模型/假说/优化对象/学习器/学习算法：待学习的条件概率分布 $P(Y|X)$、决策函数 $Y=f(X)$ 概率模型：适合用条件概率分布 $P(Y|X)$ 表示的模型 非概率模型：用决策函数 $Y=f(x)$ 表示的模型 learner：某类模型的总称 hypothesis：训练好的模型实例，有时也被强调作为学习器应用在某个样本集（如训练集）上得到的结果 learning algorithm：模型、策略、算法三者的模型总体 Hypothesis Space假设空间：特征空间（输入空间）到输出空间的映射集合 假设空间可以定义为决策函数/条件概率的集合，通常是由参数向量 $\\theta$ 决定的函数/条件分布族 假设空间包含所有可能的条件概率分布或决策函数 假设空间的确定意味着学习范围的确定 概率模型假设空间可表示为：$F={P|P_{\\theta}(Y|X), \\theta \\in R^n}$ 非概率模型假设空间可表示为：$F={f|Y=f(x),\\Theta \\in R^n }$ 以下大部分情况使用决策函数，同时也可以代表概率分布 Strategy/Goal策略/目标：从假设空间中，根据 evaluation criterion 选择最优模型，使得其对已知训练数据、未知训练数据在给定评价准则下有最优预测 选择合适策略，监督学习问题变为经验风险、结构风险函数 最优化问题 在某些学习方法中，最优化问题目标函数也有可能不是风险函数，如：SVM，是和模型紧密相关的损失函数，但逻辑是一样的 Empirical Risk MinimiationERM：经验风险最小化策略认为，经验风险最小模型就是最优模型 按经验风险最小化求最优模型，等价于求最优化问题 \\min_{f \\in F} \\frac 1 N \\sum_{i=1}^N L(y_i, f(x_i)) 样本容量足够大时，经验风险最小化能保证有较好的学习效果，现实中也被广泛采用 Structural Risk MinimizationSRM：结构风险最小化，为防止过拟合提出的策略 结构化风险最小化策略认为结构风险最小的模型是最优模型，则求解最优模型等价于求解最优化问题 arg \\min_{f \\in F} \\frac 1 N \\sum_{i=1}^N L(y_i, f(x_i)) + \\lambda J(f) 结构风险小需要经验风险与模型复杂度同时小，此时模型往往对训练数据、未知的测试数据都有较好的预测 结构化风险最小策略符合 Occam’s Razor 原理 Occam’s Razor：奥卡姆剃刀原理，在所有可能选择的模型中，能够很好的解释已知数据并且十分简单才是最好的模型 Algorithm/Optimizer算法/优化器：学习模型（选择、求解最优模型）的具体计算方法 （求解最优化问题） 如果最优化问题有显式解析解，比较简单 但通常解析解不存在，需要用数值计算方法求解 保证找到全局最优解 高效求解 Supervised Learning监督学习：学习一个模型，使得模型能够对任意给定输入、输出，做出好的预测 从给定的、有限的、用于学习的 train data $T={(x_1,y_1), (x_2,y_2), \\cdots, (x_N, y_N)}$ 中学习 预测 “未知” test data $T={(x_1,y_1), (x_2,y_2), \\cdots, (x_N^{‘}, y_N^{‘})}$ 数据 input space：输入空间 $\\chi$，所有输入 $X$ 可能取值的集合 output space：输出空间 $\\gamma$，所有输出 $Y$ 可能取值集合 feature space：特征空间，表示输入实例 feature vector 存在的空间 特征空间每维对应一个特征 模型实际上是定义在特征空间上的 特征空间是输入空间的象集，有时等于输入空间 学习方法分类Generative Approach生成方法：由数据学习联合概率分布 $P(X, Y)$，然后求出条件概率分布 $P(Y|X)$ 作为 generative model 方法学习给定输入X产生输出Y的生成关系（联合概率分布） generative model：生成模型，由生成方法学习到的模型 $P(Y|X) = \\frac {P(X, Y)} {P(X}$ 朴素贝叶斯法 隐马尔可夫模型 特点 可以还原联合概率分布 $P(X, Y)$ 生成方法学习收敛速度快，样本容量增加时，学习到的模型可以快速收敛到真实模型 存在隐变量时，仍可以使用生成方法学习 Discriminative Approach判别方法：由数据直接学习决策函数 $f(x)$、条件概率分布 $P(Y|X)$ 作为 discriminative model 判别方法关心的是对给定输入 $X$，预测输出$Y$ discriminative model：判别模型 KNN 感知机 决策树 逻辑回归 最大熵模型 支持向量机 提升方法 条件随机场 特点 直接学习条件概率、决策函数 直面预测，学习准确率更高 可以对数据进行各种程度抽象、定义特征、使用特征，简化学习问题 问题分类 well-posed problem：好解问题，指问题解应该满足以下条件 解存在 解唯一 解行为随着初值连续变化 ill-posed problem：病态问题，解不满足以上三个条件 Classification分类问题：输出变量$Y$为有限个离散变量 学习过程：根据已知训练数据集，利用有效学习方法学习分类器 $P(Y|X))$、$Y=F(X)$ 分类过程：利用学习的分类器对新输入实例进行分类 可用学习方法 KNN 感知机 朴素贝叶斯 决策树 决策列表 逻辑回归 支持向量机 提升方法 贝叶斯网络 神经网络 不存在分类能力弱于随机预测的分类器（结论取反） Tagging标注问题：输入、输出 均为变量序列 可认为是分类问题的一个推广、更复杂 structure prediction 简单形式 学习过程：利用已知训练数据集构建条件概率分布模型 $P(Y^{(1)}, Y^{(2)}, \\cdots, Y^{(n)}|X^{(1)}, X^{(2)}, \\cdots, X^{(n)})$ $X^{(1)}, X^{(2)}, \\cdots, X^{(n)}$：每个输入序列 $Y^{(1)}, Y^{(2)}, \\cdots, Y^{(n)}$：所有可能标记 标注过程：按照学习到的条件概率分布，标记新的输入观测序列 可用模型 隐马尔可夫模型 条件随机场 Regression回归问题：输入（自变量）、输出（因变量）均为连续变量 回归模型的拟合等价于函数拟合：选择函数曲线很好的拟合已知数据，且很好的预测未知数据 学习过程：基于训练数据构架模型（函数）$Y=f(X)$ 最常用损失函数是平方损失函数，此时可以使用最小二乘求解 预测过程：根据学习到函数模型确定相应输出 Unsupervised Learning无监督学习：没有给定实现标记过的训练示例，自动对输入的数据进行分类 主要目标：预训练一般模型（称识别、编码）网络，供其他任务使用 目前为止，有监督模型一般比无监督的预训练模型表现得好 主要原因：有监督模型对数据的 特性编码 更好 问题分类Clustering 聚类 Hierarchy Clustering K-means Mixture Models DBSCAN OPTICS Algorithm Anomaly Detection 异常检测 Local Outlier Factor Neural Networks 神经网络 Auto-encoders Deep Belief Nets Hebbian Learning Generative Adversarial Networks Self-organizing Map 隐变量学习 Expectation-maximization Algorithm Methods of Moments bind signal separation techniques Principal Component analysis Independent Component analysis Non-negative matrix factorization Singular Value Decomposition Semi-Supervised Learning半监督学习：利用少量标注数据和大量无标注数据进行学习的方式 可以利用大量无标注数据提高监督学习的效果 Reinforcement Learning强化学习：从与环境交互中不断学习的问题、以及解决这类问题的方法 强化学习问题可以描述为：智能体从与环境的交互中不断学习以完成特定目标 强化学习的关键问题：贡献度分配问题 每个动作不能直接得到监督信息，需要通过整个模型的最终 监督信息得到，且具有时延性 给出的监督信息也非“正确”策略，而是策略的延迟回报，并通过调整策略以取得最大化期望回报","link":"/ML-Theory/machine_learning.html"},{"title":"存储格式","text":"数值存储 机器数：数在计算机中二进制表示形式，带符号 真值：考虑表示规则，机器数二进制表示的真实数值 大小端 big-little endian大小端：高位byte在低位byte前 更适合人理解 little-big endian小大端：低位byte在高位byte前 更适合计算机计算，大部分计算机架构 方便截断操作 符号（有符号数）：大部分（静态）语言使用最高位表示符号 0：正数 1：负数 动态语言如 python 的整形不对应定长数据类型，存储逻辑和 cpp/c 等语言相差较大 整形 模：衡量计数系统容量的参数，代表了计数系统能表示、存储的状态数 原码、反码、补码 sign and magnitude 原码：二进制位表示数值本身 需要额外符号位标识正负 ones’ complement 反码：二进制位为真值对计数系统最大值求补 one：表示有限位计数系统能表示的最大值，即二进制位全为 1 符号位不仅标识正负值，且可作为数值位参与运算 但不是对模求补 存在 +0/-0 问题 运算结果和实际结果相差 1 考虑到二进制位全 1 性质 正数：反码即为其原码 负数：反码为原码符号位不变，数值位取反（因此被称反码） twos’ complement 补码：二进制位为真值对计数系统模求补 two：表示有限位计数系统容量，即溢出 1、二进制位全为 0 符号位不仅标识正负值，且可作为数值位参与运算 考虑到是对模求补 -0 表最大负值，不存在 +0/-0 问题 运算结果和实际结果相同 将有限位计数系统视为加法封闭群 系统中各元素是有序的，为保证加法计算，则最大正值之后必然为最大负值 正、负值可视为是对群元素的人为划分 可以任意值作为划分，但二进制位计算真值复杂 考虑到二进制位全 0 性质 正数：补码即为其原码 负数：补码为反码 +1（原码也为补码数值位求反后 +1） 浮点型 遵循 IEEE 754 标准的系统必须支持单精度，最好支持双精度，对扩展精度则无要求 长度 符号位 指数/阶码 尾数 有效位数 指数偏移/偏阶 单精度 32bits 1bit 8bits 23bits 23bits 127（规格化）/126（非规格化） 双精度 64bits 1bit 11bits 52bits 53bits 1023（规格化）/1022（非规格化） 扩展精度 80bits 1bit 15bits 64bits 64bits 16383 \\begin{align*} N &= (-1)^F * 2^{E - 127} * (1 + F), & 规格化数 \\\\ N &= (-1)^F * 2^{-126} * F, & 非规格化数 \\\\ \\end{align*} 符号位：数值整体正负号 指数/阶码：数值小数点位置，也即数值放缩 阶码部分没有单独的符号位，为表示负值，则需要规定指数偏移，将 阶码减去偏移量得到实际指数值 指数偏移被设置为 $2^{E-1} - 1$ 好处 对称正负取值范围 首位即可判断浮点值和 1 关系 尾数：数值精确程度 根据 IEEE 754，规格化值尾数首位（整数位）必须为 1 规格化值的尾数值必然大于 1 单、双精度可以省略对首位的存储，有效位数比尾数长度多 1 扩展精度不区分是否为规格化值 （单、双精度）非规格化值首位为 0，同样省略 非规格化值允许尾数部分小于 1，扩展浮点数对小值的表示 所以，非规格化值阶数部分必然（规定）全为 0 非规格化值指数偏移量比规格化值小 1，可缩小最小规格化值与最大非规格化值间距 特殊浮点值 指数值全 1、尾数非 0：NaN 指数值全 1、尾数为 0：正、负无穷 事实上指数底数可以是任意值，但 IEEE 754 标准规定底数为 2","link":"/CS/Storage/storage.html"},{"title":"解释型语言","text":"Abstarct Syntax TreeAST：抽象语法树，源代码的抽象语法结构的树状表示形式 基本上语言中每种结构都与一种AST对象相对应 不同解释器会有独有的AST格式 AST定义了代码的结构，可以通过操纵AST，精准定位到各种语句 ，实现 代码分析、检查：语法、风格、错误提示 代码结构优化：代码格式化、高亮、自动补全 优化变更代码：改变代码结构","link":"/CS/Program-Design/interpreted_lang.html"},{"title":"函数设计","text":"Hook/Callback callback：回调函数，实现与调用者分离 在API中注册、用于在处理流中的合适时刻调用的函数 可以看作是hook的一种 hook：钩子函数 更广义的、用于修改对API调用的函数 callback、hook意义其实差不多，很多情况下名词混用 register：注册函数 提供参数作为hook的挂载点 register通过挂载点调用hook 优点 让用户实现hook然后注册，框架调用用户自定义的hook，提供 更好的泛用性 框架不再处理hook函数中涉及的问题，降低系统耦合程度 hook函数可以随时更换，提升框架的灵活性、扩展性 实现函数指针作为函数参数，API通过函数指针调用函数实现 定制API C实现12345678910111213141516171819202122232425262728 # include&lt;stdlib.h&gt; # include&lt;stdio.h&gt;void populate_array( int *array, size_t array_size, int (*get_next_value_hook)(void) // `get_next_value_hook`就是函数指针 // hook的“挂载点”){ for (size_t i=0; i&lt;array_size; i++){ array[i] = get_next_value(); }}int get_next_random_value(){ return rand();}int main(){ int array[10]; poppulate_array(array, 10, get_next_random_value); // 这里`get_next_random_value`就是钩子函数 for(int i=0; i&lt;10; i++){ printf(&quot;%d\\n&quot;, array[i]); } printf(&quot;\\n&quot;); return 0; Python实现python中虽然没有明确的C中的函数指针，但是实现原理仍然类似， 都是“函数指针”作为参数，由API负责调用实现定制API 123456789101112131415import randompopulate_array(l, len, func): # `func`就类似于`C`中的函数指针，hook的挂载点 for i in range(len): l[l] = func()get_next_random_value(): return random.random()def test(): l = [ ] populate_array(l, 10, get_next_random_value) # `get_next_random_value`就是钩子函数 print(l) Closure闭包：一个函数及与其相关的组合 将回调函数与数据封装成单独的单元 实现方式 允许在函数定义的同时，使用函数内部变量支持闭包，如： python 使用特定数据结构实现闭包，如：C++使用函数类实现 Cache 固定大小：存储空间有上限 快速获取：插入、查找操作必须快速，最好$\\in O(1)$ 达到存储空间上限时可以替换已有缓冲项 Least Recently Used CacheLRU Cache：优先排除least recently缓冲条目 hashmap存储键、节点地址：常数时间查找 双向链表存储数据：利用地址可常数时间插入、删除 缓冲条目每次被获取后，移至双向链表头 缓冲区满后，删除双向链表最后节点条目，新条目插入表头 https://medium.com/@krishankantsinghal/my-first-blog-on-medium-583159139237","link":"/CS/Program-Design/function_design.html"},{"title":"语言设计","text":"编程范型Functional Programming函数式编程：使用纯函数 程序使用紧密的函数调用表示，这些函数可以进行必要计算， 但是不会执行会改变程序状态（如：赋值）的操作 函数就是数据值，可以像对待其他数据值一样对其进行操作 纯函数纯函数：没有副作用、表达式对所有引用透明度表达式也是引用透明 的函数 执行过程中除了根据输入参数给出运算结果外没有其他影响 输入完全由输入决定，任何内部、外部过程的状态改变不会影响 函数执行结果 reference transparency：引用透明，表达式可以用其结果 取代而不改变程序含义 语言基础错误类型 trapped errors：导致程序终止执行错误 除0 Java中数组越界访问 untrapped errors：出错后程序继续执行，但行为不可预知， 可能出现任何行为 C缓冲区溢出、Jump到错误地址 程序行为 forbidden behaviours：语言设计时定义的一组行为，必须 包括untrapped errors，trapped errors可选 undefined behaviours：未定义为行为，C++标准没有做出 明确规定，由编译器自行决定 well behaved：程序执行不可能出现forbidden behaviors ill behaved：否则 语言类型 strongly typed：强类型，偏向于不能容忍隐式类型转换 weakly typed：弱类型，偏向于容忍隐式类型转换 statically typed：静态类型，编译时就知道每个变量类型， 因为类型错误而不能做的事情是语法错误 dynamically typed：动态类型，编译时不知道每个变量类型 ，因为类型错误而不能做的事情是运行时错误 静态类型语言不定需要声明变量类型 explicitly typed：显式静态类型，类型是语言语法的 一部分，如：C implicitly typed：隐式静态类型，类型由编译时推导 ，如：ML、OCaml、Haskell 类型绑定 强类型倾向于值类型，即类型和值绑定 弱类型倾向于变量类型，类型和变量绑定，因而偏向于 容忍隐式类型转换 polymorphism多态：能将相同代码应用到多种数据类型上方式 相同对象收到不同消息、不同对象收到相同消息产生不同动作 Ad hoc Polymorphism：ad hoc polymorphism：接口多态，为类型定义公用接口 函数重载：函数可以接受多种不同类型参数，根据参数类型有 不同的行为 ad hoc：for this, 表示专为某特定问题、任务设计的解决 方案，不考虑泛用、适配其他问题 Parametric Polymorphismparametric polymorphism：参数化多态，使用抽象符号代替具体 类型名 定义数据类型范型、函数范型 参数化多态能够让语言具有更强表达能力的同时，保证类型安全 例 C++：函数、类模板 Rust：trait bound 在函数式语言中广泛使用，被简称为polymorphism Subtypingsubtyping/inclsion polymorphism：子类多态，使用基类实例 表示派生类 子类多态可以用于限制多态适用范围 子类多态一般是动态解析的，即函数地址绑定时间 非多态：编译期间绑定 多态：运行时绑定 例 C++：父类指针 Rust：trait bound 变量设计Lvalue、Rvalue lvalue：location value，可寻址 rvalue：readable value，可读取 左值：引用内存中能够存储数据的内存单元的表达式 使用表达式在内存中位置 考虑其作为对象的身份 右值：非左值表达式 使用表达式的值 考虑其作为对象的内容 左值、右值最初源自C 左值：可以位于赋值运算符=左侧的表达式 右值：不可以位于赋值运算赋=左侧的表达式 左值 任何左值都存储在内存中，所以都有一个地址 左值声明后，地址不会改变，地址中存储的内容可能发生 改变 左值的地址是一个指针值，可以被存储在内存中的、像数据 一样被修改 特点 重要原则 多数情况下，需要右值处可使用左值替代 需要左值处不能用右值替代 重要特点 左值存在在变量中，有持久的状态 右值常为字面常量、表达式求职过程中创建的临时对象， 没有持久状态 一等对象一等对象：满足以下条件的程序实体 在运行时创建 能赋值给变量、数据结构中的元素 能作为参数传递给函数 能作为函数返回结果 高阶函数高阶函数：以其他函数作为参数、返回函数作为结果的函数 短路求值短路求值：布尔运算and/or中若结果已经确定，则不继续计算之后 表达式 x and y：首先对x求值 若x为假停止计算 否则继续对y求值再判断 x or y：首先对x求值 若x为真则停止计算 否则继续对y求值再判断 返回值取决于语言实现 确定返回布尔值：C/C++ 返回x、或y的求值结果：python","link":"/CS/Program-Design/language_design.html"},{"title":"继承、Mixin","text":"多重继承多重继承问题 结果复杂化：相较于单一继承明确的父类，多重继承父类和子类 之间的关系比较复杂 优先顺序模糊：子类同时继承父类和“祖先类”时，继承的方法 顺序不明确 功能冲突：多重继承的多个父类之间可能有冲突的方法 多重继承优点todo解决方案规格继承使用inteface、traits这些结构实现“多重继承” （普遍意义上的单一继承） 类只能单一继承父类 但是可以继承多个interface、traits，其中只能包含 方法，而没有具体实现 方案问题 即使继承interface也需要重新实现方法 只是通过规定解决多重继承的问题，但是也损失优点 弥补技巧delegatedelegate（代理） 对interface itf实现一个公用实现class impl 其他“继承”itf的类itf_cls声明一个itf类型的变量 itf_var 将公用实现的一个实例赋值给itf_var 这样itf_cls中interface itf方法的实现就可以直接使用 itf_var调用impl的方法 1234567891011121314151617181920interface itf{ pulic void itf_func()=0;}class itf_impl implements itf{ public void itf_func(){ }}class itf_cls implements itf, others{ itf itf_var; public itf_cls(String args[]){ itf_var = new itf_impl; } public void func(){ itf_var.func(); }} 实现继承方法+实现的集合，普遍意义上多重继承 类可以继承多个父类 多个父类没有要求其中不能包含方法的实现 方案问题即多重继承的普遍问题 弥补技巧mixinmixin（混入） 每个类只“逻辑上”继承一个类，其他只继承mixin类 mixin类单一职责 mixin对宿主类（子类）无要求 宿主类（子类）不会因为去掉mixin类而受到影响，不调用 超类方法避免引起MRO查找顺序问题 mixin思想同规则继承 均是将父类划分为 逻辑父类 逻辑特性族 但是规则继承是禁止（普遍意义）多重继承，而mixin 只是有效方案，并没有从规则上真正禁止“多重继承” mixin对开发者要求更严格，需要自查是否符合mixin原则 12345class MixinCls: passclass SubCls(SuperCls, MixinCls1, MixinCls2): pass","link":"/CS/Program-Design/inheritation.html"},{"title":"ISO9001标准","text":"OSI/RM物理层数据链路层网络层传输层会话层表示层应用层硬件高层设备物理上兼并底层设备功能，逻辑上只考虑其该部分功能 RP repeater中继器：连接网络线路的装置，信号放大器 最简单的网络互联设备 主要完成物理层功能 功能 双向转发两个网络节点的物理信号 在物理层上按位传递信息 完成信号的复制、调整、放大 延长网络的长度 Hub集线器：多口中继器 局域网中的星形连接点 实现多台机器之间的互联 功能 基本功能是分发，把一个端口接收到所有信号向所有端口分发 有些在分发前将弱信号重新生成 有些会整理信号的时序以提供所有的端口间的同步数据通信 Bridge网桥/桥接器：连接两个局域网的存储转发设备 工作在数据链路层 用于完成具有相同、相似体系结构、数量不多LAN的连接 功能 根据MAC地址转发帧 对所接收的信息帧只作少量包装，不做任何修改 可以采用另外一种协议转发信息 网桥有足够大的缓冲空间，以满足高峰期要求 具有寻址、路径选择能力 有效的连接两个LAN 限制本地通信在本网段内 转发相应信号至另一网段 Switch交换机：采用交换技术增加数据输入输出总和、安装介质的带宽 可以理解为高级的网桥，拥有网桥的功能，性能比网桥强 交换机转发延迟很小，能经济把网络分成小的冲突网域 功能Router路由器：网络层上的连接 路由器在网络上处于关键地位 路由器能够跨越不同的网络类型 在逻辑上将整个互联网分割成独立的网络单位 功能为每个数据帧寻找最佳传输路径，把数据（IP报文）传送到正确的 网络 IP数据报的转发，包括数据报的寻址、传送 子网隔离，抑制广播风暴 维护路由表，与其他路由器交换路由信息，这是IP报文转发基础 IP数据报的差错处理、简单的拥塞控制 对IP数据报的过滤、记账 Gateway网关：协议转换器，网络层上具有协议转换功能的设施 网关不一定是一台设备，可能在一台主机中实现网关功能 用于一下场合的异构网络互联 异构型局域网 局域网与广域网的互联 广域网与广域网的互联 局域网与主机相连（主机操作系统、网络操作系统不同时） 分类 协议网关：在使用不同协议的网络区域间做协议转换 应用网关：在使用不同数据格式的网络区域间翻译数据 安全网关：各种技术的融合，有重要且独特的保护作用，处理 范围从协议级过滤到应用级过滤","link":"/CS/Network/iso9001.html"},{"title":"RFC","text":"局域网协议Identification ProtocalIdent协议 如果客户端支持Ident协议，可以在TCP端口113上监听ident请求 基本每个类Unix操作系统都带有Ident协议 Ident在组织内部可以很好工作，但是在公共网络不能很好工作 很多PC客户端没有运行Ident识别协议守护进程 Ident协议会使HTTP事务处理产生严重时延 很多防火墙不允许Ident流量进入 Ident协议不安全，容易被伪造 Ident协议不支持虚拟IP地址 暴露客户端用户名涉及隐私问题 Ident协议不应用作认证、访问控制协议 Internet协议","link":"/CS/Network/rfc.html"},{"title":"转义序列","text":"C0、C1 控制字符集 C0、C1 控制字符 ISO/IEC 2022 定义的控制字符集 Unicode 中控制字符码位兼容 ISO/IEC 2022，但 仅对 U+001C - U+001F、U+0009 - U+000D、U+0085 限定语义 其余控制字符语义对 Unicode 透明，留给高层协议 https://zh.wikipedia.org/wiki/C0%E4%B8%8EC1%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6 C0 控制字符集 CO 控制字符集码位范围：0x00 - 0x1F ASCII 中定义控制字符标准 码位限定在 1byte 可以表示，避免终端机需要实现状态机处理多字节控制序列 现只有少数控制字符被使用 C0 控制字符码位范围之外，还有定义有两个具备控制符特点的字符 0x7F（delete） 0x20（space） C1 控制字符集 C1 控制字符集码位范围：0x80 - 0x9F 8bits ISO/IEC 8859 ASCII 扩展提出后 考虑到可打印字符的最高比特位去掉之后不应变成控制字符 以 C0 控制字符集作为低位、最高位置 1，得到 C1 控制字符集 C1 码位在经常被私有编码方案（Windows-1252、Mac Os Roman）用于提供额外的可打印字符 ISO/IEC 8859 ASCII 扩展标准中指定 为兼容 7bits 传输，所有 C1 控制字符使用 ESC 开头的 7bits 字符序列表示 标准 C 转义规则 非打印（包括控制）字符可以通过其 ASCII 码位 16 进制、8 进制表示 \\0[ooo]：八进制数 oo 码位字符 \\x[hh]：十六进制数 hh 码位字符 \\x0a：同 \\n 针对常用非打印字符，有如下简写方式 \\\\：反斜杠 \\ \\'：单引号 ' \\&quot;：双引号 &quot; \\a：BEL ASCII 响铃 \\b：BS ASCII退格 \\f：FF ASCII 进纸 \\n：LF/NL ASCII 换行，开启新行 \\r：CR ASCII 回车，“指针移至行首” \\t：TAB ASCII 制表符 \\v：VT 垂直制表符 ANSI Escape SequencesANSI：一种 In-band Signaling 的转义序列标准，用于控制终端上 光标位置、颜色、其他选项 在文本中嵌入的 ANSI 转义序列，终端会将 ANSI 转义序列解释为相应指令，而不是普通字符 ANSI 转义序列使用 ASCII 中字符传递所有信息 ANSI 转义序列有不同长度，但都 以 ASCII 字符 ESC（0x1b） 开头 8 进制表示：\\033 16 进制表示：\\x1b 第二字节则是 0x45 - 0x5F（ASCIIi @A-Z[\\]^_）范围内的字符 标准规定，在 8bits 环境中 ANSI 转义序列前两个字节的序列可以合并为 0x80 - 0x9F 范围内的单个字节（即 C1 控制字符） 但在现代设备上，C1 控制字符码位被用于其他目的，一般不被使用 UTF-8 编码对 x80 字符本就需要 2bytes Windows-1252 编码将 C1 控制字符码位挪作他用 C0 控制字符输出有时也会产生与 ANSI 转义序列相近效果，如：LF、ESC E都有换行效果 https://zh.wikipedia.org/wiki/ANSI%E8%BD%AC%E4%B9%89%E5%BA%8F%E5%88%97 https://www.gnu.org/software/screen/manual/html_node/Control-Sequences.html No-CSI - 非控制序列 序列（省略 ESC） 对应 C1 名称 效果 N 0x8E SS2 - Single Shift 2 从替代 G2 字符集中选择字符 O 0x8F SS3 - Single Shift 3 从替代 G3 字符集中选择字符 P 0x90 DCS - Device Control String 控制设备 D 仅换行，不重置光标至行首 E 换行并充值光标至行首，类似LF H 制表，类似TAB M 翻转换行，回到上一行 X 0x98 SOS - Start of String 引用由 ST 终止的一串文本参数 ^ 0x9E PM - Privacy Message 引用由 ST 终止的以穿文本参数 _ 0x9F APC - Application Program Command 引用由 ST 终止的一串文本参数 c - RIS - Reset to Initial State 类似clear命令 [ 0x9B CSI - Control String Sequence 控制序列导入器，某些终端中也可以使用0x9D \\ 0x9C ST - String Terminator 终止其他控件得字符串 ] 0x9D OCS - Operating System Command 启动操作系统使用的控制字符串 %G 选择 UTF8 作为字符集 #8 DEC 屏幕校准测试，使用E填充整个终端 Control Sequence Introducer控制序列导入器：ESC[ + 若干参数字节 + 若干中间字节 + 一个最终字节 常见序列只是把参数用作一系列分号分隔的数字，如：1;2;3 缺少的数字视为 0 某些序列（CUU）把 0 视为 1，以使缺少参数情况下有意义 一部分字符定义“私有”，方便终端制造商插入私有序列 参数字节 &lt;=&gt;? 的使用：ESC[?25h、ESC[?251 打开、关闭光标显示 最终字节 0x70 - 0x7F 组成部分 字符范围 ASCII字符 参数字节 0x30~0x3F 0-9:;&lt;=&gt;? 中间字节 0x20~0x2F 、!&quot;#$%&amp;'()*+,-./ 最终字节 0x40~0x7E @A-Z[]^_a-z{}~, ` 光标移动 序列内容 名称 效果 [n]A/[n]B/[n]C/[n]D CU[UDFB] - Cursor Up/Down/Forward/Back 光标移动[n]格，在屏幕边缘则无效 [n]E/[n]F Cursor Next Line/Previous Line 光标移动至下[n]行/上[n]行开头 [n]G Cursor Horizontal Absolute 光标移动到第[n]列 [n;m]H CUP - Cursor Position 光标绝对位置 [n;m]f Horizontal Vertical Position 同 CUP [n]J Erase in Display 清除屏幕部分区域：0 - 光标至末尾；1 - 开头至光标；2 - 整个屏幕 [n]K Erase in Line 清除行内部分区域 [n]S Scroll Up 整页向上滚动 [n] 行 [n]T Scroll Down 整页向下滚动 [n] 行 s Save Cursor Position 保存光标当前位置 u Restore Cursor Position 恢复光标位置 窗口 序列内容 名称 效果 5i - 打开辅助端口，通常用于本地串行打印机 4i - 关闭辅助端口，通常用于本地串行打印机 6n Device Status Report 以 ESC[n;m]R 报告光标位置 Select Graphic Rendition SGR 选择图形再现：ESC[[n]m [n]：多个参数用 ; 分隔，缺省为 0 m：结束字节 样式 设置值 显示效果 取消值 0 所有属性值重置为默认值，用于取消对后续输出影响 1 高亮或粗体 22 2 半亮 22 4 下划线 24 5 闪烁 25 7 反显，前景、背景色交换 27 8 隐藏，前景、背景色相同，可能不支持 28 9 删除线 29 53 上划线 55 11-19 选择替代字体 3/4位色 前景色值 背景色值 颜色 高亮前景色值 高亮背景色值 30 40 黑色 90 100 31 41 红色 91 101 32 42 绿色 92 102 33 43 黄色 93 103 34 44 蓝色 94 104 35 45 紫红色 95 105 36 46 青蓝色 96 106 37 47 白色 97 107 38 48 控制使用256位、RGB色 39 49 默认颜色 可通过反显 7 实现背景色、高亮 1 实现多高亮色 8bits 色 8bits 色设置格式 ESC[38;5;37m：设置256位前景色 ESC[48;5;37m：设置256位背景色 预定义 8bits 色情况 0-7：标准颜色，同 ESC[30-37m 8-15：高强度颜色，同 ESC[90-97m 16-231：16 + 36*r + 6*g + b（$0 leq r,g,b leq 5$ 得到 6 6 6 立方） 232-255：24阶灰阶 24bits 色 24bits 色设置格式 ESC[38;2;&lt;r&gt;;&lt;g&gt;;&lt;b&gt;m：选择 RGB 前景色 ESC[48;2;&lt;r&gt;;&lt;g&gt;;&lt;b&gt;m：选择 RGB 辈景色 字符内容体系结构有一个不太受支持的替代版本 ESC[38:2:&lt;Color-Space-ID&gt;:&lt;r&gt;:&lt;g&gt;:&lt;b&gt;:&lt;unused&gt;:&lt;CS tolerance&gt;:&lt;Color-Space: 0=&quot;CIELUV&quot;;1=&quot;CIELAB&quot;&gt;m：选择 RGB 前景色 ESC[48:2:&lt;Color-Space-ID&gt;:&lt;r&gt;:&lt;g&gt;:&lt;b&gt;:&lt;unused&gt;:&lt;CS tolerance&gt;:&lt;Color-Space: 0=&quot;CIELUV&quot;;1=&quot;CIELAB&quot;&gt;m：选择 RGB 背景色 支持 libvte 的终端上支持 ISO-8613-3 的 24bits 前景色、背景色设置，如 Xterm、Konsole 24bits 色的替代版本是 ISO/IEC 8613-6 采用的 ITU 的 T.416 信息技术","link":"/CS/Character/escape_sequences.html"},{"title":"编码问题","text":"Abstract Charater Repertoire抽象字符集：ACR 字符字母、数字、标点、表意文字（汉字）、符号或其他文本形式的 “原子” 抽象字符抽象的字符，包括空白、不可打印的字符 对于某些语言中，抽象字符应该还包括发音字符 如：印度语中单词“नमस्ते” 有6个字符[‘न’, ‘म’, ‘स’, ‘्’, ‘त’, ‘े’]， 其中4、6两个字符在单词不出现，是发音字符 Abstract Charater Repertoire抽象字符集：ACR，抽象字符的集合 集合表明无序性 有时也简称为字符集（charater set） 有开放（字符不会改变）和封闭之分（会扩张） Coded Character Set编码字符集：CCS Code Point码位：抽象字符集中与字符关联的数字编号 一般是非负整数 习惯上有16进制表示 Coded Character Set编码字符集：CCS，每个所属字符都分配了码位的抽象字符集 经常简称为字符集（charater set），同ACR弄混 字符与码位一一映射 可以更加方便的引用字符集中的某个元素 可以类比于dict 字符集（抽象、编码）举例US-ASCIIACSII字符集 128个抽象字符，封闭字符集 主要包括 控制字符：回车、退格、换行 可显示字符：英文大小写、阿拉伯数字、西文符号 一般字符集都是兼容ascii编码字符集，即相同字符的码位相同 ISO-8859-X扩展的ASCII字符集 涵盖了大多数西欧语言字符、希腊语 GBXXXX国标系列字符集：每个标准包含的字符数量不同、对应的编码方案 也不不完全相同 GB2312：信息交换用汉字编码字符集基本集 包含汉字覆盖99.75%的使用频率 人名、古汉语等罕用字不能处理 GBK：汉字内码扩展规范 包括21003个汉字 支持国际标准ISO/IEC10646-1和国家标准GB13000-1中 全部中日韩汉字 包含了BIG5编码中的所有汉字 兼容GB2312 GB18030：信息技术中文编码字符集 其中收入汉字70000余个 以汉字为主并包含多种我国少数民族文字（如藏、蒙古、 傣、彝、朝鲜、维吾尔文等）的超大型中文编码字符集 强制性标准 兼容GBK Big5Big5字符集：主要包含台湾、香港地区繁体字 Universal Character Set/Unicode/UCS统一字符集/Unicode字符集：ISO/IEC 10646定义的编码字符 开放字符集，码位无上限，容纳一切字符，包括emoji等 UCS中码位不是连续分配的 目前为止，分为0x0000~0x10FFFF共17个平面 其中0平面0x0000~0xFFFF称为 basic multilingual plane BMP中码位只有16bit长度，能够节约大量存储空间，有 战略意义 因此“常用”语言的常用字符放在BMP，其他不常用的字符 只能放在其他平面 unicode本身是指一系列用于计算机表示所有语言字符的标准 Character Encoding Form字符编码表：CEF，将码位映射为码元序列 fixed-length-encoding：定长编码，对每个码位（字符） 赋予长度同为m的码元（位串） 封闭字符集符号有限，可以直接确定一一对应编码表 variable-length-encoding：变长编码，允许对不同码位 赋予不同长度的码元 开放字符集包括符号无上限，无法定长码元表示码位， 必须有某种方式将码位一一映射为码元序列 封闭字符集出于节约成本考量，也可能使用变长编码 如：Huffman编码 码元：能用于处理或交换编码文本的最小比特组合（位串） Unicode定义的CEF本质思想：预留标记位值使码元序列的长度实现变长 UTF-8 码元为1B 对BMP中字符一般需要1~3B，BMP外需要4B 兼容ASCII编码表（方案） 不同于编码字符集兼容的意义，基本上编码字符集都 兼容ASCII编码字符集，即对应字符码位相同 兼容编码表指，“ASCII编码方案”可以使用UTF-8解码 方案直接解码 UTF-16 码元为2B 对BMP中字符一般需要2B，BMP外需要4B UTF-32 码元为4B Prefix-Free Code（自由）前缀码：所有代码码元都不是另一个字符码元的前缀 可以简单扫描位串直到得到一组有效码元，转换为相应字符 这样编码表可以很容易用一棵（编码）二叉树表示 树左向边标记为0、右向边标记为1 叶子节点表示字符，根节点到叶子节点路径为其码元 树中叶子节点到其他叶子节点的简单路径不存在，即码元 不可能为其他码元前缀 所以任何二叉树对应一套编码表 这种编码方案一般用于产生平均长度最短的位串 因此这类编码方案以bit为单位，而不是以byte为单位 Huffman Encoding哈夫曼编码：prefix-free code的一种 根据字符出现频率进行编码 需要事先知道字符出现概率 可以事先扫描给定文本，对文本中字符出现字符计数 将较短位串分配给高频字符、较长位串分配给低频字符 若字符独立出现，则哈夫曼编码是最优编码（最短长度编码） 需要把编码树信息包含在编码文本中才能正确解码 构造哈夫曼树的贪婪算法参见组合问题 Adaptive Huffman Encoding利用已经处理字符串动态更新编码 Lempel-ziv对字符串编码 Character Encoding Schema字符编码方案：CES，字符编码表+字节序列化方案，将码位 映射为字节流 大小端序问题：码元高位还是低位字节在前 字节序标记问题：不同程序之间端序交流 通常所说编码、解码就是指使用CES 应用场合 CES是真正的应用层面，需要给出具体存储方案实现， 前述都是理论上protocol 所有字符串存储介质中，磁盘、内存都采用某种具体CES 实现存储 Java、Python3这样的偏上层语言，字符串对象在内存中 通常采用UTF-16 C这样偏底层语言，基本上按照源文件的编码确定，即将 源文件中对应字符串对应字节，但现在C/C++中还有一种 宽字符w_char类型 以上仅对Unicode而言，对于ASCII来说没有区分必要 内存CSE说明 内存中如果不使用某种CES实现，直接使用码元，一样会出现 长度问题，所以显然会使用某种CES方案 虽然在内存中，字符仍然使用某种编码方案得到字节流存储，但 这个字节流并不是这个字符，码位才“是”这个字符 大部分提供Unicode处理语言会自动处理字符，不仅仅 是字节 在考虑字符串问题时，可以“抽象的”忽略具体存储方式， 认为存储的就是“码位”本身 Byte Order Mark字节序标：BOM，放置于编码字节开始处的特殊字节序列，表明 序列大小端序 0xFFFE：小端序，低位在前 0xFEFF：大端序，高位在前 Unicode族CES方案UTFunicode transfromation format：历史上是指CES，而UTF-X 现在可以同时指代CES和CEF，Unicode族标准CEF方案 UTF-8：utf-8编码表码元为1B，不存在字节序问题 指代CES和CEF没有什么区别，CEF只有一种 UTF-16：指代CES和CEF时有歧义，需要明确指明是 UTF-16 encoding form（码元序列）、 UTF-16 encoding schema（字节流） UTF-16-le：utf-16编码表小端版本 UTF-16-be：yutf-16编码表大端版本 UTF-16：utf-16编码表带BOM版本，大小端均可 UTF-16 CES表示BMP（包含大部分常用字符）只需要2B， 权衡了内存占用、处理便捷，适合作为内存中字符串的 编码方案 UTF-32 UTF-32le： UTF-32be UTF-32 UCSUnicode还有两种非标准CES UCS-2：使用2B定长序列化码位 可以视为UTF-16的子集 不支持BMP外的字符表示 UCS-4：使用4B定长序列化码位 可以视为UTF-32的子集 其他字符集CES方案US-ASCII、GBK都有自己的编码方案，只是编码方案太简单，以至于 CCS、CEF、CES三层合一 ASCII编码方案：1B的低7位表示一个字符 ISO-8895-1编码方案：1B表示一个字符 GB2312编码方案：2B表示一个汉字 第一个字节：区字节，高位字节 第二个字节：位字节，低位字节 GBK编码方案：2B表示一个汉字 兼容GB2312方案 编码范围：0x8140~0xFEFE，剔除0xxx7F GB18030编码方案：变长字节1B、2B、4B 兼容GBK方案 Big5编码方案：2B表示一个汉字 字节顺序类似GB2312 ANSI编码 各个国家、地区独立制定、兼容ASCII编码，但彼此之间不兼容 的编码方案，微软统称为ANSI编码 ANSI编码一般代表系统（仅win）默认编码方式，在不同系统中 指不同的编码方案 英文操作系统：ISO-8859-1 简体中文：GBxxxx编码 繁体中文：Big5编码 日文：Shift JIS编码 默认ANSI编码可以通过设置系统Locale更改 win下系统Locale决定代码页，用户Locale决定数字、 数字、货币、时间与日期格式 Transfer Encoding Syntax传输编码语法：TES，有时候需要对字节流再次编码以进行传输 如：某些字符不允许出现在传输流中 举例 base64编码：将字节流映射成64个安全字符集组成的字符流 输入、输出辨析输入所有的输入都是经过CES编码的字节流（包括数字） 文件输入流：文件编码方案决定 标准输入流（terminal）：terminal编码方案决定 管道传输流：由管道输入端的编码方案决定 处理这里应该有两种处理方式 将输入视为字节流，不做任何处理，直接按字节存储在 内存中 将输入字节流视为其自身编码方案字节流，直接储存 将输入视为字符串，尝试解码 若解码发现无法解释位串 strict：报错 replace：将违规字符替换为有效字符 替换为某种?：很多应用采用此方式，是乱码 发生的主要原因 有些也替换为Unicode码位 ignore：忽略该位串 而解码后字符串的在内存中的存储，取决于解释器、编译器 、系统等处理主体的编码方案 以上只是对真正有字符串类型的语言Python、Java有这样区分 对于没有字符串类型的语言C并没有真正意义上的字符串，只有 字节串，不涉及解码、自身字符串内存存储的问题，仅有换行符 转义问题（若处理换行符被视为解码） 输出所有输出都是编码后字节流（包括数字） 文件输出流：write 标准输出流（terminal）：print 管道传输流 需要注意的是，输出的字节流编码方案和处理主体在内存中编码 方案不一定相同，和编程实现、平台等因素都有关，比如很多 默认输出编码方案为utf-8 同样的，此输出流是对于其接收者而言仅仅是字节流，需要自行 决定如何处理字节流 此输出是指传递给直接输出外部的输出，有些语言在输出前 会隐式调用函数生成字符串 其他常见问题乱码乱码主要有以下3种可能 读取乱码：真正的乱码 读取时没有正确解码，内容被替换，打印输出 存储乱码：保存时已经是“乱码”，其实也不能算是乱码 读取时没有正确解码，内存中内容已经被错误，保存后内容 保持错误 内存中数据正确，但保存使用的编码方案不支持某些字符， 内容被替换 缺少字体库 乱码不是其实已经是将不能打印的字符剔除、替换，能看到的 乱码已经是程序认为“正确解码的字符串” 换行符处理 鉴于以下两种行为 win下换行需要两个字符\\r\\n标识，linux下只需要\\n 即可 编程语言往往类似Linux只需要\\n即标识换行 Vim中在内存中以&lt;CR&gt;标识换行 在win下很多语言以字符串模式：读取字节流时会自动将\\r\\n 替换为\\n、写出字节流时替换回\\r\\n Python这种原生支持字符串语言，这个特性可以看作字符串 解码的行为 C这种原生只支持字节串的语言，这个特性可能是二进制、 字符串读写的唯一区别 例子以UTF-8编码方案为例 输入的所有的内容都是由UTF-8编码方案编码的字节流 处理主体获取字节序列，根据指令处理字节序列 比如字节序列编码和处理主体编码不同，将其解码为 主体编码方案 比如按照约定将字节序列转变为不同类型的数据 输出则是将需要输出的内容（包括数字等）转换字节流传给底层 函数","link":"/CS/Character/char_encoding.html"},{"title":"字体杂记","text":"字体文件 TTF：Truetype Font 苹果公司创建，Mac 和 Win 上最常用的字体文件格式 由数学表达式定义、基于轮廓的字体文件 保证了屏幕、打印输出的一致性，同时也可以和向量字体一样随意缩放 TTC：TrueType Collection 微软开发的新一代字体文件，多个 TTF 文件合并而成 可以共用字体笔画文件，有效的节约空间 兼容性不如 TTF，有些应用无法识别 FON Win 上最小的字体文件格式 固定大小的位图格式，难以调整字体大小 字体分类西文字体分类 西文字体分类方法有很多种，但是太学术，不常用，常用分类的可以看计算机字体族 Thibaudeau 分类法 法国字体排印师 Francis Thibaudeau 于 1921 年提出 Vox-ATypl 分类法 Maximilien Vox 于1954年提出，是比较早、基础、业内有过影响力的分类法 Fontshop 自家的分类法 在已有的思路的基础上，基于字体开发的独特的分类法 适合网上搜索字体，网罗了超过 15 万字体 Linotype 提供的3种分类法 by category + by usage+ by theme 后 2 者是面向一般字体用户，重视字体的用途来合理分类 中文字体分类 中文字体则没有一个明确的分类体系，仅能大概分类 宋体（明体）：最能代表汉字风格的印刷字头 仿宋：相当于雕版时代的魏碑体 楷体：标准化的楷书，毛体书法的产物 黑体：汉字在西方现代印刷浪潮冲击下的产物 圆体：海外地区率先开发、使用 计算机字体分类 serif：有衬线字体 特点 笔画有修饰，末端向外展开、尖细或者有实际衬线 文字末端在小号字体下容易辨认，大号可能模糊或有锯齿 例 Times New Roman、MS Georgia、DejaVu Serif 宋体、仿宋 两种衍生字体 petit-serif：小衬字体，可以当作无衬线 slab-serif：雕版衬线，末端变化非常明显 san-serif：无衬线字体 特点 末端笔画清晰，带有一点或没有向外展开、交错笔画 与serif相比，字体较小时可能难以分辨、串行（阅读） 举例 MS Trebuchet、MS Arial、MS Verdana 黑体、圆体、隶书、楷体 monospace：等宽字体 特点 每个字形等宽，因此常作为终端所用字体 举例 Courier、MS Courier New、Prestige 多数中文字体（中文字体基本都等宽） cursive：手写字体 举例 Caflisch Script、Adobe Poetica xx手写体、xx行草 fantasy：梦幻字体（艺术字） 举例 WingDings、WingDings2、Symbol 各种奇怪名字的字体 serif、san-serif 是西文字体的两大分类 而后应该是计算机的出现带来的monospace的兴起 最后面两种在正式场合中不常用","link":"/CS/Character/fonts.html"},{"title":"通信、锁","text":"函数通信 简单通信方式：允许进程向其他进程发送简单信息 命令行参数 信号：受控于操作系统的非同步事件机制 shell环境变量 程序退出状态码 简单文件 匿名管道：允许共享文件描述符的线程、进程传递数据 仅在进程内部存在，通常和进程分支合用作为父进程、 子进程之间的通信手段、线程之间通信 依赖于类Unix下进程分支模型，可移植性差 具名管道FIFO：映射到系统的文件系统，允许不相关程序 进行交流 是真正的外部文件，通过标准文件接口实现 可以独立启动，局限于本地进程通信时可以替代套接字 相较于普通外部文件，操作系统同步化FIFO访问，使之 适合IPC 套接字socket：映射到系统级别端口号 允许远程联网机器程序之间交流 可移植性较好，几乎所有平台都支持 共享内存：消息保存在函数外部，不随着函数栈清除消失 全局变量 类中变量 锁 线程/进程调度本质上是不确定的 并行编程中错误使用锁机制可能会导致随机数据损坏、其他 异常行为，即竞争条件 最好在临界区（对临界资源进行操作的部分代码）使用锁 死锁、预防 线程/进程同时获取多个锁 避免、预防方案 尽可能保证每个线程/进程只能同时保持一个锁 为程序中每个锁分配唯一ID，然后只允许按照升序规则使用 多个锁 单纯按照对象ID递增顺序加锁不会产生循环依赖，而循环 依赖时死锁必要，从而避免进入死锁状态 可以数学上证明，这样能保证程序不会进入死锁状态 检测、恢复方案 引入看门狗计数器： 线程正常运行时每隔一段时间重置计数器 没有发生死锁时正常运行 一旦发生死锁，无法重置计数器导致计数器超时，程序通过 重启恢复自身状态","link":"/CS/Parallel/communication.html"},{"title":"并行计算简介","text":"并行计算模型PRAMParallel Random Access Machine：随机存取并行机器模型，也称 共享存储的SIMD模型，从串行的RAM模型直接发展起来 假定 容量无限大的共享存储器 有限个或无限个功能相同的处理器，具有简单的算术运算和逻辑 判断功能 任何时刻各处理器都可以通过共享存储单元相互交互数据 分类根据处理器对共享存储单元同时读、同时写的限制，PRAM模型可以 分为下面几种 PRAM-EREW：Exclusive-Read and Exclusive-Write，不允许同时 读、写 PRAM-CREW：Concurrent-Read and Exclusive-Write，允许同时 读、不允许同时写 PRAM-CRCW：Concurrent-Read and Concurrent-Write，允许 同时读和同时写，允许同时写是不现实的，进一步约定 CPRAM-CRCW：Common PRAM-CRCN，只允许所有的处理器同时 写相同的数 PPRAM-CRCW：Priority PRAM-CRCN，只允许最优先的处理器 先写 APRAM-CRCW：Aribitrary PRAM-CRCN，允许任意处理器 自由写 SPRAM-CRCW：Sum PRAM-CRCN，往存储器中写的实际内容是 所有处理器写的数的和 优点 适合于并行算法的表达、分析和比较 使用简单，很多关于并行计算机的底层细节，比如处理器间通信 、存储系统管理和进程同步都被隐含在模型中 易于设计算法和稍加修改便可以运行在不同的并行计算机系统上 缺点 模型中使用了全局、单一共享存储器、局存容量较小 不足以描述分布主存多处理机的性能瓶颈 共享单一存储器的假定，不适合分布存储结构的MIMD机器 PRAM模型是同步的 意味着所有的指令都按照锁步的方式操作 耗时长、不能反映现实中很多系统的异步性； 假设不现实 模型假设每个处理器可在单位时间访问共享存储器的任一 单元，要求处理机间通信无延迟、无限带宽和无开销，忽略 资源竞争和有限带宽 假设处理机有限或无限，对并行任务的增大无开销 BSP模型异步MIMD-DM（Distributed Memory）模型 BSP模型支持消息传递系统，块内异步并行，块间显式同步 模型基于一个master协调，所有worker同步(lock-step)执行， 数据从输入的队列中读取 模型描述模型可以用 p/s/g/i 4个参数进行描述 p：处理器的数目(带有存储器)。 s：处理器的计算速度。 g：选路器吞吐率 定义为：time_steps / packet time_steps：每秒本地完成的局部计算数目 packet：通信网络每秒传送的数据量 i：全局同步时间开销，Barrier synchronization time 同步和通信的开销都规格化为处理器的指定条数，p台处理器同时 传送h个字节信息，则gh就是通信的开销 模型结构BSP程序同时具有水平和垂直两个方面的结构 垂直上：BSP程序由一系列串行的超步(superstep)组成 从水平上看：在一个超步中，所有的进程并行执行局部计算 超步可分为三个阶段 本地计算阶段：每个处理器只对存储本地内存中的数据进行 本地计算 全局通信阶段：对任何非本地数据进行操作 栅栏同步阶段：等待所有通信行为的结束 特点 模型将计算划分为一个一个的超步(superstep)，有效避免死锁。 处理器和路由器分开，强调了计算任务和通信任务的分开，且 路由器仅仅完成点到点的消息传递，不提供组合、复制和广播等 功能，掩盖具体的互连网络拓扑、简化了通信协议 一般分布存储的MIMD模型的可编程性比较差，但BSP模型中，若 计算和通信可以合适的平衡（例如g=1），则它在可编程方面 呈现出主要的优点。 采用障碍同步的方式以硬件实现的全局同步是在可控的粗粒度级 ，从而提供了执行紧耦合同步式并行算法的有效方式，而程序员 并无过分的负担 BSP模型起到为软件和硬件之间架起一座类似于冯·诺伊曼机的 桥梁的作业，因此BSP模型也常叫做桥模型 BSP模型上曾直接实现了一些重要的算法（如矩阵乘、并行前序 运算、FFT和排序等），均避免自动存储管理的额外开销 为PRAM模型所设计的算法，都可以采用在每个BSP处理器上模拟 一些PRAM处理器的方法来实现。 不足 模型中，在超级步开始发送的消息，即使网络延迟时间比超级步 长度短，该消息也只能在下一个超级步才能被使用 全局障碍同步假定是用特殊的硬件支持的，但很多并行机中可能 没有相应的硬件 LogP模型分布存储、点到点的多处理机模型 模型描述通信网络由4个主要参数描述 L：Latency，源处理机与目的处理机进行消息通信所需要的 等待或延迟时间的上限，表示网络中消息的延迟 O：Overhead，处理机准备发送或接收每个消息的时间开销 包括操作系统核心开销和网络软件开销 在这段时间里处理不能执行其它操作 G：Gap，一台处理机连续两次发送或接收消息时的最小时间 间隔，其倒数即微处理机的通信带宽。 P：Processor，处理机/存储器模块个数 以处理器周期为时间单位，L、o、g可以表示成处理器周期 整数倍 特点 抓住了网络与处理机之间的性能瓶颈：带宽 g反映了通信带宽，单位时间内最多有L/g个消息能进行处理机间传送。 处理机之间异步工作，并通过处理机间的消息传送来完成同步 对多线程技术有一定反映。每个物理处理机可以模拟多个虚拟 处理机（VP） 某个VP有访问请求时，计算不会终止 VP的个数受限于通信带宽和上下文交换的开销、网络容量 至多有L/g个VP。 消息延迟不确定，但延迟不大于L 消息经历的等待时间是不可预测的 但在没有阻塞的情况下，最大不超过L。 可以预估算法的实际运行时间。 不足 对网络中的通信模式描述的不够深入，有些现象未描述、考虑 重发消息可能占满带宽 中间路由器缓存饱和等未加描述 主要适用于消息传递算法设计 对于共享存储模式，则简单地认为远地读操作相当于两次 消息传递 未考虑流水线预取技术、Cache引起的数据不一致性以及 Cache命中率对计算的影响 未考虑多线程技术的上下文开销 用点对点消息路由器进行通信，这增加了编程者考虑路由器上 相关通信操作的负担 背景 根据技术发展的趋势，20世纪90年代末和未来的并行计算机发展 的主流之一是巨量并行机，即MPC（Massively Parallel Computers）， 它由成千个功能强大的处理器/存储器节点，通过具有有限带宽 和相当大的延迟的互连网络构成。所以我们建立并行计算模型 应该充分考虑到这个情况，这样基于模型的并行算法才能在现有 和将来的并行计算机上有效的运行。 根据已有的编程经验，现有的共享存储、消息传递和数据并行 等编程方式都很流行，但还没有一个公认的和占支配地位的编程方式， 因此应该寻求一种与上面的编程方式无关的计算模型。而根据 现有的理论模型，共享存储PRAM模型和互连网络的SIMD模型对 开发并行算法还不够合适，因为它们既没有包含分布存储的情况， 也没有考虑通信和同步等实际因素，从而也不能精确的反映运行 在真实的并行计算机上的算法的行为，所以，1993年D.Culer等人 在分析了分布式存储计算机特点的基础上，提出了点对点通信 的多计算机模型，它充分说明了互联网络的性能特性，而不涉 及到具体的网络结构，也不假定算法一定要用现实的消息传递 操作进行描述 并行算法基本设计策略串改并发掘和利用现有串行算法中的并行性，直接将串行算法改造为并行 算法 最常用的设计思路但并不普适 好的串行算法一般无法并行化（数值串行算法可以） 全新设计从问题本身描述出发，不考虑相应的串行算法，设计全新并行算法 借用法找出求解问题和某个已解决问题之间的联系，改造或利用已知算法 应用到求解问题上 并行算法常用设计技术划分设计技术使用划分法把问题求解分成两步： 把给定问题划分成p个几乎等尺寸的子问题 用p台处理器并行求解子问题 分治设计技术 将复杂问题划分成较小规模特性相同的子问题 且子问题类型和原问题类型相同 通常用递归完成分治算法 平衡树设计技术 以树的叶结点为输入，中间结点为处理结点 由叶向根或由根向叶逐层进行并行处理 倍增设计技术 递归调用时，所要处理数据之间的距离逐步加倍 经过k步后即可完成距离为2^k的所有数据的计算 流水线技术 将算法路程分成p个前后衔接的任务片段，一个任务片段完成后 ，其后继任务片段可以立即开始 则可以引入流水线的思想来处理多条数据 并行计算机体系架构Shared Memory Distributed Memory Hybrid 并行编程模型 特征 数据并行 共享变量 消息传递 代表 HPF OpenMP MPI、PVM 可移植性 SMP、DSM、MPP SMP、DSM 所有流行并行计算机 并行力度 进程级细粒度 线程级细粒度 进程级粗粒度 并行操作方式 松散同步 异步 异步 数据存储 共享存储 共享存储 分布式存储 数据分配方式 半隐式 隐式 显示 难度 较简单 简单 难 可扩展性 一般 较差 好 数据并行模型相同操作同时作用于不同数据 共享变量模型用共享变量实现并行进程间通信 消息传递模型驻留在不同节点上的进程通过网络传递消息相互通信，实现进程之间 信息交换、协调步伐、控制执行等 ?","link":"/CS/Parallel/parallel_computing_intro.html"},{"title":"C++函数","text":"函数定义、声明函数：被组织成具有特定名称的独立单元的代码块 将某段操作代码组织起来，编写一次、多次使用，可以显著降低 程序规模，而且使程序更易于维护 将大型程序分解成多个易于管理的小部分 好的、独特的分解分解方法，会使得每个函数都是紧密的 单元，使得问题整体更加易于理解 top-down design：过程一般从主程序开始分解问题， 逐步求精 即使函数只在程序中使用一次，定义函数依然值得 123type name(parameters){ body} name：函数名 parameters：逗号分隔的函数形参列表 Parameters形参：调用函数时用以传递实参的占位符 类似局部变量，但是在调用时使用实参进行初始化 如果需要使用形参值，可以忽略其形参名，即使是在 函数实现中也可以忽略，如：++后缀重载 Default Parameter默认形参：具有默认值的形参，调用时可以不给其传递实参值 默认形参只能出现在函数声明中，不能出现在函数定义中 默认形参只能出现在形参列表末尾 默认形参在C++中有滥用的问题，更倾向使用函数重载完成默认 形参的功能 默认形参、函数重载同时使用可能导致编译器无法识别应该调用 何者而报错 Value Parameter值参数：函数调用时，被调函数中值形参将获得主调函数的实参的 值拷贝 被调函数中传入的实参变量值仅改变被调用函数局部形参 的值，对主调函数中实参变量的值没有影响 Reference Parameter引用参数&amp;：函数调用时，被调函数中引用形参获得主调函数中实参 引用 主调函数、被调函数共享实参变量的统一存储空间，不需要复制 实参变量中的值，有时更高效 对应引用形参的实参必须是可赋值的量，如：变量名 实参可以是指针，即参数可以同时有* &amp; 1int insertAVL(BSTNode * &amp; t, const string &amp; key); 常用于 需要保存函数对参数值的修改 函数需要返回多个值：并通过实参列表向函数传递、获取值 Constant Reference Parameter常量引用调用const &amp;：常量引用作为函数参数调用 传递对象时，常量引用调用通常优于传统引用调用、值调用， 提供了引用传递的高效性、值传递的安全性 需要注意参数中const关键字的位置 12345int strlen(const char * cptr); // `const`后是类型名，表明`cptr`是指向`const char`指针 // 不能改变`cptr`指向的支付串内容int strlen(char * const cptr); // `const`后是形参名，表明`cptr`常量，其值不能改变 使用常量引用需要参数类是constant correct，能够提供更多 的关于类中定义的方法的信息 Prototype函数原型/函数声明：函数定义的首行加上分号结尾组成 提供编译器大部分情况下仅仅需要的形参、返回值类型 函数原型中形参名可选，但是好的形参名有助于可读性 如果函数先定义后调用，可以不需要编写函数原型，但这种代码 风格和自顶向下的程序设计风格相悖 Signature函数签名：函数的形参模型 和函数原型相比，不包括返回值类型 Overloading函数名重载：使用相同名字的不同版本函数 函数名相同、函数参数列表不同是合法的，即函数签名不同即 合法（函数原型不同不一定合法，返回值类型不同） 形参数量 形参类型 编译器遇到调用函数的函数名指代不唯一时，编译器会检查所传 实参，选择最合适的函数版本 Calling使用函数名调用函数代码（块）的行为 函数被调用后将会获得函数argument提供的值，执行函数功能 返回函数调用点：记忆主调程序工作情况，以便程序 返回函数调用的确切位置是函数调用机制的主要特性之一 argument：实参，调用函数时的表达式，用于向函数传递信息 调用函数前必须对函数提供声明或定义，以使编译器可以判断 函数调用是否与其定义兼容 函数调用步骤 主调函数将实参与自己上下文中的若干局部变量绑定来 计算每个参数值 实参通常为表达式，计算其值时可能涉及操作符、其他函数 调用 新的函数开始执行前，主调函数会对传如的实参合法性进行 验证 系统为新函数所需的所有局部变量（包括形参）创建新的存储 空间 这些变量将被分配在内存中stack frame区域中 每个实参值将被传入到函数相应的形参变量中 对于包含多个形参的函数，实参对形参的值拷贝将按照 对应函数形参顺序执行 如有必要，编译器将像变量赋值一样，执行从实参到 形参的类型转换 对引用参数，栈帧会存储一个指针指向该值内存单元 执被调函数体中语句，直到遇到return语句或没有多余语句 如果函数有返回值，函数体内return语句表达式的值将被计算 ，作为返回值返回给主调函数 如有必要，编译器将执行数值的类型转换，确保返回值 符合被调函数值的类型要求（被调函数返回之前转换）12345678int rint(){ return 9.8; // 返回整形}int main(){ double j = rint(); // `j`被初始化为`9.8`} 删除为函数调用创建的栈帧，其中所有局部变量被系统清理 将函数返回值（若存在）代入到调用函数调用点的位置 Pointer to a Function函数指针：函数的第一条指令地址 1234double *g(double); // 返回double类型指针的函数gdouble (*fn)(double); // 返回double类型的函数指针fn 将函数作为数据值使用：使设计有效的接口变得容易，允许用户 像指定数据一样指定操作，即作为回调函数 12void mapAll(double (*fn)(double)); // 声明使用函数指针做参数 C++对函数指针自动解析引用 早期计算中，程序以代码、数据完全分开形式表示 现代计算机，内存同时存储的数据值、硬件执行的机器指令 von Neumann Architecture：冯诺伊曼体系结构，将指令存储 在内存地址中作为数据值使用，使得创建函数指针成为可能 ClosureC++需要使用创建必要数据结构实现闭包 需要将数据、代码封装在一个单独实体，即对象/类 为使得闭包函数一般化，最好的方法是使用function class 实现，直接将实例作为“函数” （当然可以随便实现一个函数，不影响） 函数类参见cppc/basics/class 闭包参见program/program_design/function_design 函数类作为参数 使用函数类作为参数时，没有任何明确方法声明类型，因为任何 重载()操作符都可以作为参数 C++使用模板函数实现，任何以函数对象作为参数的函数 12template &lt;typename FunctionClass&gt;void mapAll(FunctionClass fn); 传给模板函数mapAll值可以是任意类型 但当编译器展开其时，若参数类型不能获得期望参数， 编译器报错","link":"/C-C/func.html"},{"title":"库","text":"C++库结构定义C++库时，需要提供：interface、implementation 类库向用户提供了一组函数、数据类型，以实现 programming abstraction 类库像函数一样，提供了可用于降低复杂度的方法，但也需要 在建库时考虑更多细节，简化程度取决于接口设计的优劣 接口、实现 接口：允许库用户在不了解库实现细节的情况下使用库中库函数 典型接口可提供多种定义、声明，称为interface entry 函数声明 类型定义 常量定义 实现：说明库的底层实现细节 C++接口通常写在.h头文件中，实现在同名.cpp文件 接口设计原则 unified：统一性，接口必须按照统一主题来定义一致的抽象 simple：简单性，接口必须向用户隐藏实现的复杂性 sufficient：充分性，接口必须提供足够功能满足用户的需求 general：通用性，良好设计的接口必须有高度适用性 stable：稳定性，接口在函数底层实现改变时也要有不变的 结构、功能 使用12345$ g++ -o a.out src.cpp -L /path/to/library -l lib_name // 动态、静态链接库均可 // `-L`指定（额外）库文件搜索路径$ g++ -o a.out src.cpp liblib_name.a // 静态链接库可以类似于`.o`文件使用 编译时使用指定链接库名只需要指定lib_name，编译器自动 解析为lib[lib_name].so gcc/ld为可执行文件链接库文件时搜索路径 /lib、/usr/lib64、/usr/lib、/usr/lib64 LIBRARY_PATH中包含的路径 Static Link Library静态链接库.a/.lib：二进制.o中间目标文件的集合/压缩包 链接阶段被引用到静态链接库会和.o文件一起，链接打包到 可执行文件中 程序运行时不再依赖引用的静态链接库，移植方便、无需配置 依赖 相较于动态链接库浪费资源、空间 相较于.o二进制的文件，管理、查找、使用方便 生成静态链接库 linux下使用ar、windows下使用lib.exe，即可将目标文件 压缩得到静态链接库 库中会对二进制文件进行编号、索引，以便于查找、检索 123$ g++ -c src.cpp src.o$ ar -crv libsrc.a src.o // 生成静态库`libsrc.a` linux下静态库命名规范：lib[lib_name].a（必须遵守，因为 链接时按此规范反解析名称） Dynamic Link Library动态链接/共享库.so/.dll 动态链接库在程序链接时不会和二进制中间文件一起，被打包 进可执行文件中，而时在程序运行时才被 dynamic linker/loader载入 不同程序调用相同库，在内存中只需要该共享库一份实例，规避 空间浪费、实现资源共享 解决了静态库对程序更新、部署、发布的麻烦，可以通过仅仅 更新动态库实现增量更新 执行环境需要安装依赖、配置环境变量（或者是编译时指定依赖 搜索路径） 生成动态链接库 直接使用编译器即可创建动态库 12345$ g++ -f PIC -c src.cpp -o src.o # PIC: position independent code # 创建地址无关的二进制目标文件w$ g++ -shared -nosname libsrc.so -o libsrc.so.1 src.o # 生成动态链接库 动态链接库命名规则：lib[libname].so（必须按照此规则 命名，因为链接时按照此规则反解析库名称） dynamic linker/loader动态载入器：先于executable模块程序工作，并获得控制权 对于linux下elf格式可行程序，即为ld-linux.so* 按照一定顺序搜索需要动态链接库，定位、加载 搜索次序ld-linux.so*依次搜索以下，定位动态链接库文件、载入内存 elf文件的DT_RPATH段：链接/编译时指定的搜索 库文件的路径，存储在elf文件中 g++通过添加-Wl,rpath,、ld通过-rpath参数指定添加 的路径 若没有指定rpath，环境变量LD_RUN_PATH中路径将被添加 12345678$ objdump -x elf_exe # 查看elf文件的`DT_RPATH`$ g++ -Wl,-rpath,/path/to/lib # 在g++命令中直接给出链接参数 # 也可以使用链接器`ld`链接时给出$ g++ -Wl,--enable-new-tags,-rpath,'$ORIGIN/../lib' # 使用相对路径 # Makefile中使用时需要转义`$$ORIGIN/../lib` LD_LIBRARY_PATH环境变量 优先级较高，可能会覆盖默认库，应该避免使用，会影响 所有动态链接库的查找 不需要root权限，同时也是影响安全性 /etc/ld.so.cache文件列表（其中包括所有动态链接库 文件路径） /lib、/lib64、/usr/lib、/usr/lib64隐式 默认包含，优先级较低、且逐渐降低 其由ldconfig根据/etc/ld.so.conf生成，库文件添加 进已有库路径、添加路径至/et/ld.so.conf后，需要通过 ldconfig更新缓存才能被找到 ldconfig具体参见linux/shell/cmd_sysctl 因为LD_LIBRARY_PATH的缺点，建议使用LD_RUN_PATH，在 链接时就指定动态库搜索路径","link":"/C-C/lib.html"},{"title":"CPP 类","text":"","link":"/C-C/Cppref/class.html"},{"title":"CPP 概念","text":"","link":"/C-C/Cppref/concepts.html"},{"title":"CPP Exception","text":"","link":"/C-C/Cppref/exceptions.html"},{"title":"CPP 声明","text":"","link":"/C-C/Cppref/declaration.html"},{"title":"CPP 语句","text":"","link":"/C-C/Cppref/expressions.html"},{"title":"CPP 函数","text":"","link":"/C-C/Cppref/functions.html"},{"title":"CPP 初始化","text":"","link":"/C-C/Cppref/initiation.html"},{"title":"CPP 语句","text":"","link":"/C-C/Cppref/statements.html"},{"title":"CPP 预处理","text":"","link":"/C-C/Cppref/pretreatment.html"},{"title":"STL 本地化","text":"","link":"/C-C/STL/locale.html"},{"title":"STL Exception","text":"","link":"/C-C/STL/exceptions.html"},{"title":"STL 数值计算","text":"","link":"/C-C/STL/numeric.html"},{"title":"CPP 模板","text":"","link":"/C-C/Cppref/templates.html"},{"title":"IO","text":"C++中数据输入/输出操作是通过I/O流库实现 流：数据之间的传输操作 输出流：数据从内存中传送到某个载体、设备中 输入流：数据从某个载体、设备传送到内存缓冲区 C++中流类型 标准流I/O流：内存与标准输入、输出设备之间信息传递 文件I/O流：内存与外部文件之间信息传递 字符串I/O流：内存变量与表示字符串流的字符数组 之间信息传递 &lt;ios&gt;class iosios：流基类 所有流的父类 保存流状态、处理错误 方法 .fail()：判断流是否失效 尝试超出文件的结尾读取数据时 输入流中字符串无法被正确解析 .eof()：判断流是否处于文件末尾 基于C++流库语义，.eof方法只用在.fail调用之后， 用于判断错故障是否是由于到达文件结尾引起的 .clear()：重置与流相关状态位 故障发生后，任何时候重新使用新流都必须调用此函数 if(stream)：判断流是否有效 大部分情况下等同于if(!stream.fial()) .open(filename)：尝试打开文件filename并附加到流中 流方向由流类型决定：输入流对于输入打开、输出流对于 输出打开 可以调用.fail判断方法是否失败 .close()：关闭依附于流的文件 .[un]setf12UKNOWN setf(setflag, unsetfield);UKNOWN unsetf(unsetflag); 用途 .setf：设置某个流操纵符 .unsetf()：取消某个流操纵符 参数 setflag：需要设置的操纵符 unsetflag：取消设置的操纵符 unsetfield：需要清空的格式设置位组合 不能像&lt;&lt;、&gt;&gt;中省略操纵符ios::前缀 .rdbuf1234567891011121314template &lt;class Elem, class Traits&gt;class basic_ios: public ios_base{ basic_streambuf &lt;_Elem, _Traits&gt; *_Mystrbuf, _Mysb * rdbuf() const{ return (_Mystrbuf); } _Mysb * rdbuf(_Mysb * _Strbuf){ _Mysb * _Oldstrbuf = _Mystrbuf; _Mystrbuf = _Strbuf; return (_Oldstrbuf); }} 用途：获得输入、输出流对象中指向缓冲区类streambuf指针 &gt;&gt;、&lt;&lt;操作符对其有重载，可以方便读取、写入 class istreamistream：输入流基类 将流缓冲区中数据作格式化、非格式化之间的转换 输入 方法 .unget()：复制流的内部指针，以便最后读取的字符能再次 被下个get函数读取 .get123456int_type get();basic_istream&amp; get(E&amp; c);basic_istream&amp; get(E *s, streamsize n);basic_istream&amp; get(E *s, streamsize n, E delim);basic_istream&amp; get(basic_stream&lt;E, T&gt; &amp;sb);basci_istream&amp; get(basci_stream&lt;E, T&gt; &amp;sb, E delim); 用途：从输入流中获取字符、字符串 参数 delim：分隔符，缺省\\n n： （友元）函数getline123456789101112template&lt;class E, class T, class A&gt;basic_istream&lt;E, T&gt;&amp; getline( basic_istream&lt;E, T&gt;&amp; is, basic_string&lt;E, T, A&gt;&amp; str,);template&lt;class E, class T, class A&gt;basic_istream&lt;E, T&gt;&amp; getline( basic_istream&lt;E, T&gt;&amp; is, basic_string&lt;E, T, A&gt;&amp; str, E delim,); 用途：从流is读取以delim为界，到字符串中 保留开头空白字符、丢弃行尾分割符 读取字符直到分隔符，若首字符为分隔符则返回空字符串 参数 delim：分隔符，缺省为换行符\\n class ostreamostream：输出流基类 将流缓冲区中数据作格式化、非格式化之间的转换，输出 方法 .put(ch)：将字符ch写入输出流 class iostreamiosstream：多目的输入、输出流基类 OperatorInsertion Operator&lt;&lt;：插入操作符，将数据插入流中 左操作数是输出流 右操作数是需要插入流中的数据 基本类型：&lt;&lt;会将其自动转换为字符串形式 整形：默认10进制格式 [unsigned ]char类型：总是插入单个字符 streambuf类型指针：插入缓冲区对象中所有字符 Extraction Operator&gt;&gt;：提取操作符，从输入流中读取格式化数据 左操作数为输入流 右操作数存储从输入流中读取的数据 缺省 skipws：忽略开头所有空白字符 空白字符分隔：读取字符直到遇到空白字符 streambuf类型指针：把输入流对象中所有字符写入该 缓冲区 几乎不提供任何支持检测用户输入是否有效的功能 数据格式由变量类型控制 缓冲缓冲类型 ISO C要求 当且仅当不涉及交互设备时，标准输入、输出全缓存 标准错误绝不是全缓存 无缓冲：不缓冲字符 适用情况：标准错误 标准库不缓冲不意味着系统、设备驱动不缓冲 行缓冲：在输入、输出遇到换行符时才会执行I/O操作 适用情况：涉及交互设备，如标准输入、输出 全缓冲：I/O操作只会在缓冲区填满后才会进行 适用情况：大部分情况，如驻留在磁盘的文件 flush描述I/O缓冲写操作 标准I/O函数自动flush 手动调用对流调用死fflush函数 缓冲区一般是在第一次对流进行I/O操作时，由标准I/O函数调用 malloc函数分配得到 文件自定义缓冲区 文件必须已打开、未做任何操作 setbuf1void setbuf(FILE * restrict fp, char * restrict buf); 用途：打开或关闭缓冲区 打开：buf必须为大小为BUFSIZ的缓存 BUFSIZ：定义在stdio.h中，至少256 关闭：将buf设置为NULL setvbuf12int setvbuf(FILE * restrict fp, char * restrict buf, int mode, size_t size); 用途：设置缓冲区类型 流自定义缓冲区setbuf1virtual basic_streambuf * setbuf(E *s, streamsize n); Manipulator（流）操纵符：控制格式化输出的一种特定类型值 输出 短暂的：只影响下个插入流中的数据 持久的：直到被明确改变为止 双操纵符条目中，前者为默认 setw、setprecision、setfill还需要包含&lt;iomanip&gt; 组合格式 adjustfield：对齐格式位组合 basefield：进制位组合 floatfield：浮点表示方式位组合 位置 endl：将行结束序列插入输出流，确保输出字符被写入目的流 setw(n)：短暂的 setfill(ch)：持久的，指定填充字符，缺省空格 left：持久的，指定有效值靠左 right：持久的，指定有效值靠右 internal：持久的，指定填充字符位于符号、数值间 数值 showbase：为整数添加表示其进制的前缀 fixed：持久的，完整输出浮点数 scientific：持久的，科学计数法输出浮点数 setprecision(digits)：持久的，精度设置依赖于其他设置 fixed/scientific：指定小数点后数字位数 其他：有效数字位数 hex：持久的，16进制输出无符号整形 oct：持久的，8进制输出无符号整形 dec：持久的，10进制输出整形 noshowpoint/showpoint：持久的，否/是强制要求包含 小数点 noshowpos/showpos：持久的，要求正数前没有/有+ nouppercase/uppercase：持久的，控制作为数据转换部分 产生任意字符小/大写，如：科学计数法中的e noboolalpha/boolalpha：持久的，控制布尔值以数字/ 字符形式输出 控制 unitbuf：插入、提取操作之后清空缓冲 stdio：每次输出后清空stdout、stderr 输入 skipws/noskipws：持久的，读取之前是/否忽略空白字符 ws：从输入流中读取空白字符，直到不属于空白字符为止 &lt;iostream&gt; ifstream_withassign：标准输入流类 cin：标准文件stdin ofstream_withassign：标准输出、错误、log流 cout：标准文件stdout cerr：标准文件stderr clog：标准文件stderr &lt;fstream&gt; ifstream：文件输入流类 默认操作：ios::in ofstream：文件输出流类 默认操作：ios::out|ios::trunc fstream：文件流输入、输出类 例12345678910111213#include &lt;fstream&gt;int main(){ ifstream infile; ofstream outfile; // 声明指向某个文件的流变量 infile.open(filename) // 打开文件：在所声明变量和实际文件间建立关联 infile.close() // 关闭文件：切断流与所关联对象之间联系} 流操作复制文件 逐字符复制 1234567#include&lt;fstream&gt;std::ifstream input(&quot;in&quot;, ios::binary);std::ofstream output(&quot;out&quot;, ios::binary);char ch;while(input.get(ch)){ output &lt;&lt; ch;} 使用input &gt;&gt; ch默认会跳过空白符，需要使用 input.unsetf(ios::skipws)取消 逐行复制 12345#include&lt;string&gt;std::string line;while(getline(input, line)){ output &lt;&lt; line &lt;&lt; &quot;\\n&quot;;} 若文件最后没有换行符，则复制文件会末尾多\\n 迭代器复制 123456#include&lt;iterator&gt;#include&lt;algorithm&gt;input.unsetf(ios::skipws);copy(istream_iterator(input), istream_iterator(), ostream_iterator(output, &quot;&quot;)); 缓冲区复制 1output &lt;&lt; input.rdbuf(); 丢失\\n 标准输出文件内容 &lt;&lt;操作符 12345#include&lt;iostream&gt;#include&lt;fstream&gt;ifstream input(&quot;in&quot;);cout &lt;&lt; input.rdbuf(); .get方法 12345678910while(input.get(*cout.rdbuf()).eof()){ // 读取一行 if(input.fail()){ // `get`遇到空行无法提取字符，会设置失败标志 input.clear(); // 清除错误标志 } cout &lt;&lt; char(input.get()); // 提取换行符，转换为`char`类型输出} .get方法2 1input.get(*cout.rdbuf(), EOF); &lt;sstream&gt; 基于C类型字符串char *编写 istrstream：串输入流类 ostrstream：串输出流类 strstream：串输入、输出流类 基于std::string编写：推荐 istringstream：串输入流类 ostringstream：串输出流类 stringstream：串输入、输出流类 例1234567891011121314151617181920212223#include &lt;sstream&gt;int string_to_integer(string str){ instringstream istream(str) // 类似`ifstream`，使用流操作符从字符串中读取数据 int value; istream &gt;&gt; value &gt;&gt; ws; // `&gt;&gt;`忽略流开头空白字符，`ws`读取尾部空白 if(stream.fail() || !stream.eof()){ // 如果字符串不能作为整数解析，`.fail`返回`true` // `.eof`返回`false`，说明字符串包含其他字符 error(&quot;string to integer: illegal integer format&quot;); } return value;}string integer_to_string(int n){ ostringstream ostream; ostream &lt;&lt; n; return stream.str(); //}","link":"/C-C/STL/io.html"},{"title":"STL 其他","text":"","link":"/C-C/STL/others.html"},{"title":"STL 线代","text":"选择函数简单多态函数 max(x,y) min(x,y) swap(x,y) iter_swap(x,y) 迭代范围内操作 binary_search(begin, end, value)：若迭代返回内包含指定 value，返回true copy(begin, start, out)：将指定迭代范围内值拷贝给out 开始的迭代器 count(begin, end, value)：返回迭代范围内与指定value 值相等的数目 fill(begin, end, value)：将指定迭代范围内元素值置为 value find(begin, end, value)：返回指定范围内首个与value值 相同的元素的迭代器，不存在则结束 merge(begin_1, end_2, begin_2, end_2, out)：将两个有序 子序列合并为一个以out开始的完整有序序列 inplace_merge(begin, middle, end)：合并同一个集合内的 两个子序列 min_element(begin, end)：返回指向迭代范围中最小元素的 迭代器 max_element(begin, end)：返回指向迭代范围中最大元素的 迭代器 random_shuffle(begin, end)：随机重排迭代范围中的元素 replace(begin, end, old, new)：将迭代范围中的所有old 替换为new reverse(begin, end)：逆序指定迭代范围中元素 sort(begin, end)：将迭代范围中元素升序排列 包含函数参数 函数参数可以是函数对象、函数指针 for_each(begin, end, fn)：对迭代范围中每个元素调用fn count_if (begin, end, pred)：计算迭代范围内pred返回 true数目 replace_if(begin, end, pred)：将迭代范围内pred返回 true所有值替换为new partition(begin, end, pred)：将所有pred返回true 元素放在开头，返回指向边界的迭代器","link":"/C-C/STL/stl_alg.html"},{"title":"STL 内存分配","text":"","link":"/C-C/STL/stl_alloc.html"},{"title":"集合类","text":"VectorVector类提供了类似数组功能的机制，并对C++中数组做出了改进 数组参见cppc/mem_ctl API123456789101112131415Vector&lt;int&gt; vec; // 创建Vector对象Vector&lt;int&gt; vec(VEC_LEN); // 创建确定长度Vector对象长度，并将值初始化为0vec.add(10); // 在Vector对象里面添加新元素vec.insert(2, 30); // 向Vector对象中index=2插入元素vec.remove(0) // 删除Vector对象中index=0处元素vec.set(3, 70)vec[3] = 70 // 改变Vector对象中index=3处元素 // `[]`方法简短、和数组操作更相似，Vector被设计模仿 构造函数 Vector&lt;type&gt;() Vector&lt;type&gt;(n, value)：创建含有n个对象Vector元素， 每个元素都被初始化为value，缺省为相应类型默认值 方法 .size() .isEmpty() .get(index) .set(index, valu) .add(value) .insertAt(index, value) .removeAt(index) .clear() 操作符 [index] v1 + v2：连接两个Vector，返回包含所有元素的Vector v1 += e1：向Vector尾部添加元素 注意参数传递Vector对象123456789void print_vector(Vector&lt;int&gt; &amp; vec){ cout &lt;&lt; &quot;[&quot;; for (int i=0; i&lt;vec.size(); i++){ if (i&gt;0) count &lt;&lt; &quot;,&quot;; count &lt;&lt; vec[i]; } count &lt;&lt; &quot;]&quot; &lt;&lt; endl;} 二维结构12Vector&lt; Vector&lt;int&gt; &gt; sodok(9, Vector&lt;int&gt;(9)) // 内部`Vector&lt;int&gt;`两侧需要空格，否则`&gt;&gt;`被错误解析 StackAPI构造函数 Stack&lt;type&gt;() 方法 .size() .isEmpty() .push(value) .pop() .peek()：返回栈顶元素但不出栈 .clear() QueueAPI构造函数 Queue&lt;type&gt;() 方法 .size() .isEmpty() .enqueue(value)：将值添加到队尾 .dequeue()：删除队首元素，并返回给调用者 .peek()：返回队首元素但不将其熟队列中删除 .clear() MapAPI构造函数 Map&lt;key_type, value_type&gt;() 方法 .size() .isEmpty() .put(key, value) .get(key)：返回Map对象中当前与键key相关联的值 若该键没有定义，get创建新的键值对，设置值为默认值 .remove(key) .containsKey(key) .clear() 操作符 map[key]：同get方法 SetAPI构造函数 Set&lt;type&gt;() 方法 .size() .isEmpty() .add(value) .remove(value) .contains(value) .clear() .isSubsetof(set) .first() 操作符 s1 + s2：返回两集合并运算结果 s1 * s2：交 s1 - s2：差 s1 += s2 s1 -= s2 s1 *= s2","link":"/C-C/STL/stl_container.html"},{"title":"C++函数式编程","text":"&lt;functional&gt;基类 binary_function&lt;arg_type1, arg_type2, result_type&gt;： 两个指定类型参数、返回指定类型的函数类的父类 unary_function&lt;arg_type, result_type&gt;：指定类型参数、 返回指定类型的函数类的父类 实现算数操作符类 plus&lt;arg_type&gt;：+ minus&lt;arg_type&gt;：- multiples&lt;arg_type&gt;：* divides&lt;arg_type&gt;：/ modulus&lt;arg_type&gt;：% negate&lt;arg_type&gt;：-取反 实现比较操作 equal_to&lt;arg_type&gt;：== not_equal_to&lt;arg_type&gt;：!= less&lt;arg_type&gt;：&lt; less_equal&lt;arg_type&gt;：&lt;= greater&lt;arg_type&gt;：&gt; greater_equal&lt;arg_type&gt;：&gt;= 实现逻辑关系 logical_and&lt;arg_type&gt;：&amp;&amp; logical_or&lt;arg_type&gt;：|| logical_not&lt;arg_type&gt;：! 产生函数对象 bind1st(fn, value)：返回新一元函数对象，用与其绑定的 value作为首个参数调用二元函数对象fn bind2nd(fn, value)：返回新一元函数对象，用与其绑定的 value作为第二个参数调用二元函数对象fn not1(fn)：返回新函数对象，且该函数对象为一元函数对象 时返回true not2(fn)：返回新函数对象，且该函数对象为二元函数对象 时返回true ptr_fun(fnptr)：返回需要调用特定函数指针的新函数对象， 可能需要一个或两个同类型参数 返回具有相同效果的函数对象，可以使得函数指针、 函数对象概念一体化，避免代码重复 例12345678count_if(v.begin(), v.end(), bind2nd(less&lt;int&gt;(), 0)); // 返回元素类型为整形的矢量对象`v`中负数数量template&lt;typename FunctionClass&gt;void func_func(FunctionClass fn);void func_func(double (*fn)(double)){ // 函数重载+`ptr_fun`减少代码重复 func_func(ptr_func(fn));}","link":"/C-C/STL/stl_func.html"},{"title":"STL String","text":"字符串：理论上是指特定字符序列 声明string类型变量时，一般赋予字符串字面值作为初始值 字符串长短、索引类型默认是size_t类型，在&lt;string&gt;类库 中已经定义 &lt;string&gt;操作 + += == != &lt; &lt;= &gt; &gt;= 读字符串内容 .length() .at(k)：返回值可以用于赋值 .substr(pos, n) .compare(str) .find(pattern, pos) 修改接收方字符串内容 .erase(pos, n) .insert(pos, str) .replace(pos, n, str) C风格 string(carray) string(n, ch) .c_str()","link":"/C-C/STL/string.html"},{"title":"STL 迭代","text":"","link":"/C-C/STL/stl_iter.html"},{"title":"内存分配","text":"","link":"/C-C/Cstd/dyn_alloc.html"},{"title":"字符串、字符处理","text":"&lt;cctype&gt;检验字符类型 isalpha(ch) isupper(ch) islower(ch) isdigit(ch) isxdigit(ch) isalnum(ch) ispunct(ch) isspace(ch) isprint(ch) 大小写转换 toupper(ch) tolower(ch)","link":"/C-C/Cstd/char_str.html"},{"title":"C 标准库其他","text":"","link":"/C-C/Cstd/others.html"},{"title":"I&#x2F;O","text":"","link":"/C-C/Cstd/io.html"},{"title":"C 数学库","text":"","link":"/C-C/Cstd/math.html"},{"title":"时间、本地化","text":"","link":"/C-C/Cstd/time_date_local.html"},{"title":"C 标准库 String","text":"","link":"/C-C/Cstd/wstr.html"},{"title":"MPI","text":"总述Message Passing Interface：消息传递函数库的标准规范 标准、规范，不是特指其某个具体实现 库描述，包括上百个函数调用接口，支持Fortran、CppC 消息传递编程模型，并且是这种编程模型的代表、事实上的标准 说明 高移植性 在所有主流并行机上得到实现 使用MPI做消息传递的CppC、Fortran并行程序可以不加 改变移植 常用版本：所有版本遵循MPI标准，MPI程序可以不加修改的运行 MPICH：最流行的非专利实现，具有更好的可移植性 OpenMPI：LAMMPI的下代MPI实现 其他商用版本MPI：HP-MPI、MS-MPI 编译运行123$ mpicc -o hello hello.c$ mpirun np 4 hello # 指定进程数 概念通信组通信子：进程组集合，所有参与并行计算的进程可以组合为一个或 多个通信组 MPI通信操作函数中必要参数，用于限定参加通信的进程范围 MPI_COMM_WORLD：MPI_Init后，MPI程序的所有进程形成的 缺省组 MPI接口 头文件为mpi.h MPI函数均以MPI_为前缀，其后第一个字符大写 MPI函数返回出错代码或成功代码MPI_SUCCESS MPI数据类型 MPI(C Binding) C MPI(Fortran Binding) Fortran MPI_BYTE MPI_BYTE MPI_CHAR signed char MPI_CHARACTER CHARACTER(1) MPI_COMPLEX COMPLEX MPI_DOUBLE double MPI_DOUBLE_PRECISION DOUBLE_PRECISION MPI_FLOAT float MPI_REAL REAL MPI_INT int MPI_INTEGER INTEGER MPI_LOGICAL LOGICAL MPI_LONG long MPI_LONG_DOUBLE long double MPI_PACKED MPI_PACKED MPI_SHORT short MPI_UNSIGNED_CHAR unsigned char MPI_UNSIGNED unsigned int MPI_UNSIGNED_LONG unsigned long MPI_UNSIGNED_SHORT unsigned short 用途 异构计算：不同系统架构有不同数据表示格式，MPI预定义一些 基本数据类型，实现过程中以这些基本数据类型为桥梁进行转换 派生数据类型：允许消息来自不连续、类型不一致存储区域，如 数组散元、结构类型等 开始结束MPI_Init1int MPI_Init(int *argc, char **argv) MPI程序的第一个调用（除MPI_Initialize） 完成MPI程序的所有初始化工作 启动MPI环境 标志并行代码开始 main必须带参数运行 MPI_Finalize (void)1int MPI_Finalize(void) MPI程序的最后一个调用 结束MPI程序的运行 必须是MPI程序的最后一条可执行语句，否则程序运行结果 不可预知 标志并行代码结束，结束除主进程外其他进程 串行代码之后仍然可在主进程上运行 进程判断MPI_Common_size1int MPI_Common_size(MPI_Comm comm, int *size) 说明：获得进程个数p存储于size中 参数 comm：通信组 MPI_Common_rank1int MPI_Comm_rank(MPI_Comm comm, int *rank) 说明：获得0~p-1间进程rank值，相当于进程ID MPI_Get_processor_name1234int MPI_Get_processor_name( char *processor_name, int *namelen) 说明：获得进程名称 参数 processor_name：存储进程名称 namelen：存储进程名称长度 其他MPI_Get_count12345init MPI_Get_count( MPI_Status status, MPI_Datatype datatype, int *count) 说明：返回实际接收到的消息长度 参数 status：接收操作返回值 datatype：接收缓冲区中元素类型 count：OUT，接受区元素个数 P2P通信 一对一通信 注意 MPI_Send/Recv匹配，避免死锁 同步P2PMPI_Send12345678int MPI_Send( void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm) 说明：阻塞发送缓冲区中count个datatype数据类型 数据至目的进程 参数 buf：发送缓冲区起始地址 count：发送元素个数 datatype：发送信息元素类型 dest：目标进程rank值 阻塞式消息传递中不允许source == dest，即自身 作为接收者，会导致死锁 tag：消息标签 comm：通信组 缺省MPI_COMM_WORLD 消息传递必须限制在同一个消息组内 MPI_Recv123456789int MPI_Recv( void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Common comm, MPI_Status *status) 说明：阻塞从发送源进程获取count个datatype 数据类型至数据缓冲区buf 参数 buf：OUT，接收缓冲区起始地址 必须至少可以容纳count个datatype类型数据， 否则溢出、出错 count：最多可接收数据个数 datatype：接收数据类型，必须同MPI_Send匹配 有类型数据：发送、接收两者数据类型相同 无类型数据：使用MPI_BYTE数据类型 打包数据通信：使用MPI_PACKED source：接收数据源进程rank值 发送进程隐式确定，由进程rank值唯一标识 MPI_ANY_SOURCE：接收任意进程来源 tag：消息标签 MPI_ANY_TAG：匹配任意tag值 comm：通信组 缺省MPI_COMM_WORLD 消息传递必须限制在同一个消息组内 status：OUT，包含实际接收到消息的有关信息 status.MPI_SOURCE：MPI_ANY_SOURCE时，确定 消息来源 status.MPI_TAG：MPI_ANY_TAG时，确定消息tag 和MPI_Get_count获取接收到的消息长度 案例123456789101112131415161718192021222324#include&lt;stdio.h&gt;#include &quot;mpi.h&quot;void maini(int argc, char *argv[]){ int myid, numprocs, source; MPI_Status status; char message[100]; MPI_Init(&amp;argc, &amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;myid); MPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs); if (myid != 0){ sprintf(message, &quot;Hello! From process %d&quot;, myid); MPI_Send(message, strlen(message)+1, MPI_CHAR, 0, 99, MPI_COMM_WORLD); }else{ for (source = 1; source &lt; numproces; source++){ MPI_Recv(message, 100, MPI_CHAR, source, 99, MPI_COMM_WORLD, &amp;status); printf(&quot;%s\\n&quot;, message); } } MPI_Finalize() 异步P2PMPI_Isend123456789int MPI_Isend( void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm, MPI_Request *request) 说明：非阻塞发送缓冲区中count个datatype数据类型 数据至目的进程 参数 request：OUT，非阻塞通信完成对象（句柄、指针） MPI_Irecv123456789int MPI_Recv( void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Common comm, MPI_Request *request) 说明：非阻塞从发送源进程获取count个datatype 数据类型至数据缓冲区buf Collective Communication集合通信 通信空间中所有进程都参与通信操作 每个进程都需要调用操作函数 多对一或一对多、同步通信 数据移动 All-：结果到所有进程 -v：variety，被操作的对象、操作更灵活 通信元素块大小可变 发送、接收时数据位置可以不连续 MPI_Bcast1234567int MPI_Bcast( void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm) 说明：数据广播，一到多 参数 root：根进程 MPI_Gather12345678910int MPI_Gather( void *sendbuf, int sendcnt, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm) 说明：数据聚合，多到一 参数 sendbuf：发送缓冲区起始位置 sendcnt：发送数据元素个数 sendtype：发送数据类型 recvcount：接收元素个数 所有进程相同 仅对根进程有效 recvtype：接收数据类型 仅对根进程有效 root：接收进程rank值 comm：通信组 MPI_Gatherv1234567891011int MPI_Gatherv( void *sendbuf, int sendcnt, MPI_Datatype sendtype, void *recvbuf, int *recvcnts, int *displs, MPI Datatype recvtype, int root, MPI_Comm comm) 说明：MPI_Gather的一般形式 参数 recvcnts：从各进程分别要接受的元素个数数组 大小等于通信组大小 仅对根进程有效 displs：从各进程要接受存放位置相对于接收缓冲区 起始位置的偏移量 仅对根进程有效 MPI_Allgather 说明：MPI_Gather特殊形式 MPI_Allgatherv 说明：MPI_Allgather一般形式 MPI_Scatter12345678910int MPI_Scatter( void *sendbuf, int sendcnt, MPI_Datatype sendtype, void *recvbuf, int recvbuf, MPI_Datatype recvtype, int root, MPI_Comm comm) 说明：数据分散，一对多 MPI_Scatterv 说明：MPI_Scatter一般形式 MPI_Alltoall 说明：多对多，全交换置换数据 MPI_Alltoallv 说明：MPI_Alltoall一般形式 数据聚集 MPI_Reduce123456789int MPI_Reduce( void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm_ 说明：数据规约，多对一 MPI_Allreduce 说明：MPI_Allreduce特殊形式，结果在所有进程 MPI_Reduce_scatter 说明：结果分散到每个进程 MPI_Scan 说明：前缀操作 同步MPI_Barrier 说明：同步操作","link":"/C-C/MPI/mpi.html"},{"title":"Hadoop 计算模型","text":"分布式计算模型分布式系统，不像一般的数据库、文件系统，无法从上至下、从头 到尾进行求和等操作，需要由分散的节点不断向一个点聚拢计算过程 ，考虑将分布式计算模型可以考虑分为两部分 分布：操作原语 聚合：处理流程 MapReduceMapReduce计算模型主要描述是分布：操作原语部分， 但是此也包含了聚合：处理流程 操作原语 map：映射 以键值对二元组为主要处理对象 map过程相互独立、各mapper相互不通信的 所以mapper比较适合可独立计算任务 reduce：规约 直接处理map输出，reduce中二元组键位map过程中输出值 处理流程以hadoop中MapReduce为例 需要把任何计算任务转换为一系列MapReduce作业，然后依次 执行这些作业 计算过程的各个步骤之间，各个作业输出的中间结果需要存盘， 然后才能被下个步骤使用（因为各个步骤之间没有明确流程） 缺陷操作原语部分 提供原语少：需要用户处理更多逻辑，易用性差 所以抽象层次低：数据处理逻辑隐藏在用户代码中，可读性差 所以其表达能力有限： 复杂数据处理任务，如：机器学习算法、SQL连接查询很难 表示用MapReduce计算默认表达 处理流程部分 MapReduce需要通过把中间结果存盘实现同步，I/O延迟高 reduce任务需要等待map任务全部完成才能继续，同步Barrier 大 适合场景 One Pass Computation：只需要一遍扫描处理的计算任务 MapReduce计算模型非常有效 批数据处理 Multi Pass Computation：需要在数据上进行多遍扫描、处理 的计算任务，需要执行多个MapReduce作业计算任务，因为 多副本复制、磁盘存取，其效率不高 DAGDirected Acyclic Graph：只是表示数据处理流程的有向无环图 顶点：数据处理任务，反映一定的业务逻辑，即如何对数据进行 转换和分析 边：数据在不同的顶点间的传递 应用 DAG本身并不涉及如何处理数据，只是对数据数据流程的规划 所以DAG并不能改进MapReduce计算模型中原语部分的缺陷，只能 优化数据处理流程 减少MapReduce作业中间结果存盘，减少磁盘I/O 优化map、reduce任务执行，减少同步Barrier 这也正是Tez所做的事情 RDD","link":"/Database/Hadoop/computing_schema.html"},{"title":"HBase","text":"HBase简介HBase是高可靠、高性能、面向列、可伸缩的分布式数据库系统 利用HBase技术可以在廉价硬件上搭建大规模非结构化数据管理 集群 HBase借鉴Google Bigtable技术实现的开源软件 ||HBase|Bigtable| |——-|——-|——-| |存储系统|HDFS|GFS| |数据处理|Hadoop MapReduce|MapReduce| |协同服务|Zookeeper|Chubby| |RDBMS数据导入|Sqoop|-| HBase访问接口 Native Java API：常用、高效的访问方式 HBase Shell：HBase命令行工具，适合用于管理HBase Thrift Gateway：利用Thrift序列化技术，支持C++、PHP、 Python多种语言异构系统访问HBase表数据 REST Gateway：支持REST风格的Http API访问HBase Pig：支持Pig Latin语言操作HBase中数据 最终被转换为MapReduce Job处理HBase表数据 适合做数据统计 Hive：支持用户使用HiveQL访问HBase 可以在HBase系统上运行MapReduce作业，实现数据批处理 HBase数据结构 TableHBase的表格，类似关系型数据库中的表格，但有所不同 特殊TableHBase中有两张特殊的Table .META.：记录用户表Region信息，自身可以有多个region -ROOT-：记录.META.表Region信息的，自身只能有一个 region Row Key行键，Table行主键，Table记录按照此排序 Column、Column Family Table在水平方向由一个或多个列簇组成 一个列簇可以由任意多个Column组成 列簇支持动态扩展，无需预先定义列数量、类型 所有列均义二进制格式存储，用户需要自行进行类型转换 Timestamp时间戳：每次数据操作对应的时间戳，可视为是数据的版本号 RegionTable记录数不断增加而变大后，逐渐分裂出的多个split 每个region由[startkey, endkey)表示 不同region被Master分配给相应RegionServer进行管理（存储） HBase系统架构 Client HBase Client使用HBase RPC机制同HMaster、HRegionServer 进行通信 对于管理类操作，通过RPC机制访问HMaster 对于读写操作，通过RPC机制访问HRegionServer Zookeeper Zookeeper Quorum中记录-ROOT表的位置 客户端访问数据之前首先访问zookeeper 然访问-ROOT-表 然后访问.META.表 最后根据用户数据位置，访问具体数据 Zookeeper Quorum中存储有HMaster地址 HRegionServer把自己义Ephemeral方式注册到Zookeeper中， 使得HMaster可以随时感知各个HRegionServer健康状态 引入Zookeeper，避免了HMaster单点失败问题 HBase中可以启动多个HMaster 通过Zookeeper的Master Election机制保证总有一个Master 运行 HMasterHMaster在功能上主要负责Table、Region管理工作 管理用户对Table增、删、查、找操作？？？ 管理HRegionServer负载均衡，调整Region分布 在Region分裂后，负责新Region分配 在HRegionServer停机后，负责失效HRegionServer上region迁移 HRegionServerHRegionServer负责响应用户I/O请求，向HDFS文件系统写数据，是 HBase中最核心的模块 HRegionHRegionServer内部管理一系列HRegion对象 HRegion对象对应Table中一个Region HRegion由多个HStore组成 HStore每个HStore对应Table中一个列簇的存储，是HBase存储核心模块 由此可以看出列簇就是一个集中存储单元 因此最好将具备共同IO特性的列放在同一个列簇中，可以 提高IO效率 HStore由两部分构成 MemStore StoreFile：底层实现是HFile，是对HFile的轻量级包装 MemStoreSorted memory buffer，用户写入数据首先放入MemStore中，满了 后Flush成一个StoreFile StoreFile 文件数量增长到一定阈值时会触发Compact合并操作，将多个 StoreFile合并成一个StoreFile 合并过程中会进行版本合并、数据删除 即HBase其实只有增加数据，所有更新、删除操作都是后续 Compact过程中进行的 这使得用户写操作只要进入内存就可以立即返回，保证 HBase IO高性能 Compact操作会逐步形成越来越大的StoreFile，超过阈值之后 会触发Split操作 当前Region分裂成2个Region 父Region下线 新分裂出的2个子Region会被HMaster分配到相应的 HRegionServer上，实现负载均衡 HLog每个HRegionServer中都有一个HLog对象，避免因为分布式系统 中节点宕机导致的MemStore中内存数据丢失 HLog是实现WriteAheadLog的类 HLog作用 每次用户写入MemStore时，也会写入一份数据至HLog文件中 HLog定时删除已持久化到StoreFile中的数据 HRegion意外终止后，HMaster会通过zookeeper感知到 HMaster首先处理遗留的HLog文件，将其中不同Region的Log 数据进行拆分，分别放到相应Region目录下 然后将失效Region重新分配 领取到Region的HRegionServer在Load Region过程中，会 发现有历史HLog需要处理，会Replay HLog中的数据到 MemStore中，然后flush到StoreFile中，完成数据恢复 HBase存储HBase中所有数据存储在HDFS中 HFileHFile是Hadoop二进制格式文件，实现HBase中Key-Value数据存储 HFile是不定长的，长度固定的只有：Trailer、FileInfo Trailer含有指针指向其他数据块起点 FileInfo记录文件的一些元信息，如 AVG_KEY_LEN AVG_VALUE_LEN LAST_KEY COMPARATOR MAX_SEQ_ID_KEY Data Index记录每个Data块起始点 Meta Index记录每个Meta块起始点 Data BlockData Block是HBase IO基本单元 为了提高效率，HRegionServer中实现了基于LRU的Block Cache 机制 Data块大小可以在创建Table时通过参数指定 较大的块有利于顺序Scan 较小的块有利于随机查询 Data块除了开头的Magic信息外，就是一个个&lt;key, value&gt; 键值对拼接而成 Magic内容就是一些随机数字，防止数据损坏 每个键值对就是简单的byte array，但是包含很多项，且有固定 结构 开头是两个固定长度的数值，分别表示key、value长度 然后是key部分 固定长度数值表示RowKey长度 RowKey 固定长度数值表示Column Family的长度 Column Family Qualifier 固定长度数值表示：Timestamp、KeyType（Put/Delete） Value部分就是二进制数据 HLogFileHBase中Write Ahead Log存储格式，本质上是Hadoop Sequence File Sequence File的Key是HLogKey对象，记录了写入数据的归属信息 table region squecence number：起始值为0，或最近一次存入文件系统 中的squence number timestamp：写入时间 Squence File的Value是KeyValue对象，即对应HFile中KeyValue e","link":"/Database/Hadoop/hbase.html"},{"title":"Zookeeper","text":"Zookeeper是一个协调软件服务，用于构建可靠的、分布式群组 提供群组成员维护、领导人选举、工作流协同、分布式系统同步 、命名、配置信息维护等服务 提供广义的分布式数据结构：锁、队列、屏障、锁存器 Zookeeper促进户端间的松耦合，提供最终一致的、类似传统 文件系统中文件、目录的Znode视图，提供基本操作，如：创建 、删除、检查Znode是否存在 提供事件驱动模型，客户端能观察到Znode的变化 Zookeeper运行多个Zookeeper Ensemble以获得高可用性，每个 服务器上的Ensemble都持有分布式系统内存副本，为客户端读取 请求提供服务 FlumeFlume是分布式日志收集系统，收集日志、事件等数据资源，并集中 存储 Flume组件、结构 旧版本组件、结构 新版本组件、结构：每个Flume整体称为Agent 两个版本的组件功能、数据流结构都有区别 但是3大组件基本可以一一对应（功能略有差异） Agent是一组独立的JVM守护进程，从客户端、其他Agent接收 数据、迅速传递给下个目的节点 支持多路径流量、多管道接入流量、多管道接出流量、上下文 路由 Source（Agent）采集数据，是Flume产生数据流的地方 运行在数据发生器所在的服务器上，接收数据发生器接受数据， 将数据以event格式传递给一个或多个Channel 支持多种数据接收方式 Avro Source：支持Avro RPC协议，内置支持 Thrift Source：支持Thrift协议 Exec Source：支持Unix标准输出 JMS Source：从JMS（消息、主题）读取数据 Spooling Directory Source：监控指定目录内数据变更 Twitter 1% firehose Source：通过API持续下载Twitter 数据 Netcat Source：监控端口，将流经端口的每个文本行数据 作为Event输入 Sequence Generator Source：序列生成器数据源 HTTP Source：基于POST、GET方式数据源，支持JSON、BLOB 格式 收集数据模式 Push Source：外部系统主动将数据推送到Flume中，如 RPC、syslog Polling Source：Flume主动从外部系统获取数据，如 text、exec Channel （Collector）暂时的存储容器，缓存接收到的event格式的数据，直到被sink消费 在source、sink间起桥梁作用 Channel基于事务传递Event，保证数据在收发时的一致性 Channel可以和任意数量source、sink连接 主要Channel类型有 JDBC channel：数据持久化在数据库中，内置支持Derby File Channel：数据存储在磁盘文件中 Memory Channel：数据存储在内存中 Spillable Meemory Channel：优先存在内存中，内存队列 满则持久到磁盘中 Custom Channel：自定义Channel实现 Sink（Storage Tier）将从Channel接收数据存储到集中存储器中（HDFS、HBase） Flume EventFlume事件是内部数据传输最小基本单元、事务处理基本单位 由一个装载数据的byte array、可选header构成 数据对Flume是不透明的 header是容纳键值对字符串的无需集合，键在集合内唯一 header可以在上下文路由中使用扩展，如：数据清洗 Event将传输数据进行封装 Flume架构特性（旧版）ReliablityFlume提供了3种数据可靠性选项 End-to-End：使用磁盘日志、接受端Ack的方式，保证Flume接收 数据最终到导致目的地 Store on Failure：目的地不可用时，将数据保存在本地硬盘， 但进程如果出问题，可能丢失部分数据（发送后目的地不可用） Best Effort：不做任何QoS保证 Scalability易扩展性 Flume三大组件都是可伸缩的 Flume对事件的处理不需要带状态，Scalability容易实现 Avaliablity高可用性：Flume引入Zookeeper用于保存配置数据 Zookeeper本身可以保证配置数据一致性、高可用 在配置数据发生变化时，Zookeeper通知Flume Master节点 Flume Master节点通过gossip协议同步数据 Manageablity易管理性 多个Master，保证可以管理大量节点 Extensibility可开发性：可以基于Java为Flume添加各种新功能 实现Source子类，自定义数据接入方式 实现Sink子类，将数据写入特定目标 实现SinkDecorator子类，对数据进行一定的预处理 适合场景 高效率的从多个网站服务器收集日志信息存储在HDFS上 将从多个服务器获取的数据迅速移交给Hadoop 可以收集社交网络站点事件数据，如：facebook、amazon Kafka分布式、分区的、可复制的Message System（提交日志服务）， 得益于特有的设计，Kafka具有高性能、高可扩展的特点 完全分布式系统，易于横向扩展、处理极大规模数据 同时为发布、订阅提供极高吞吐能力 支持多订阅，出现失败状态时，可以自动平衡消费者 将消息持久化到磁盘，保证消息系统可靠性，可用于消息 批量消费应用（ETL系统）、实时应用 Kafka组件 Topic话题：特定类型的消息流 话题是消息的分类机制 消息产生器向Kafka发布消息必须指定话题 Kafka安照Topic维护接收到的消息 话题被划分为一系列分区 Kafka集群为每个Topic维护一个分区日志文件存储消息 消息是字节的Payload（有效载荷） Producer生产者：向Kafka发布消息的进程 生产者需要指定消息分配至哪个分区 采用Round-Robin方式方便均衡负载 根据应用的语义要求，设置专用Partition Function进行 消息分区 Broker代理：AMQP客户端，保存已经发布消息的服务器进程 AMQP：the Advanced Message Queuing Protocal，标准开放 的应用层消息中间件协议。AMQP定义了通过网络发送的字节流 的数据格式，兼容性非常好，任何实现AMQP协议的程序可以和 兼容AMQP协议兼容的其他应用程序交互，容易做到跨语言、 跨平台。 一组代理服务器构成Kafka集群 Kafka代理是无状态的，消费者需要自行维护已消费状态信息 因此Kafka无法知晓信息是否已经被消费、应该删除，因此 代理使用简单的、基于时间的Serice Level Agreement应用 于保留策略，消息在代理中超过一定时间自动删除 这种设计允许消费者可以重复消费已消费数据 虽然违反队列常见约定 但是实际应用中很多消费者有这种特征 消息代理将紧密耦合的系统设计解耦，可以对未及时处理的消息 进行缓存 提高了吞吐能力 提供了分区、复制、容错支持 Kafka代理通过Zookeeper与其他Kafka代理协同 系统中新增代理或代理故障失效时，Zookeeper通知生产者 、消费者 生产者、消费者据此开始同其他代理协同工作 Consumer消费者：向Kafka subscribe话题，以处理Kafka消息的进程 消费者可以订阅一个或多个话题，从代理拉取数据，消费已经 发布的消息 消费者获取消息系统一般采用两种模型 Queuing：队列模型，一组消费者从一个服务器读取信息， 每个消息仅可被其中一个消费者消费 Publish Subscribe：发布订阅模型，消息被广播给所有 消费者 Kafka采用一种抽象方法：消费者组Consumer Group提供对上述 两种消息系统模型的支持 给每个消费者打上属于某个消费者组的标签（这里组只是 表示同组内消费者只能有一个消费信息） 每个发布到话题的消息分发给消费者组的其中一个消费者 一般情况下每个话题下有多个消费者组，每个组中有多个 消费者实例，以达到扩展处理能力、容错 极端情况：如果所有消费者实例都隶属于同一个消费者组， Kafka工作模式类似于队列模型；所有消费者实例隶属于 不同的消费者组，Kafka工作模式类似于发布-订阅模型 消息分区、存储、分发分区日志每个分区是有序的、不可更改、可在末尾不断追加的 消息序列 分区优势 允许Kafka处理超过一台服务器容量的日志规模 分区作为并行处理基本单元，允许Kafka进行并行处理 通过保证每个分区仅仅由一个消费者消费，可以保证同一 分区内消息消费的有序 由于可以设置很多分区，仍然可以保证在不同消费者之间 实现负载均衡 分区内外保证消息有序、数据分区处理对大部分实际应用 已经足够 分区管理每个分区由单独的（一组）服务器处理，负责该分区数据管理、消息 请求，支持多个副本以支持容错 每个分区中有一台服务器作为leader、若干服务器作为follower 领导者负责分区读、写请求，跟随者以被动的方式领导者数据 进行复制 领导者失败，则追随者之一在Zookeeper协调下成为新领导者 为保证负载均衡，每个服务器担任部分分区领导者、其他分区 追随者 存储布局Kafka存储布局非常简单 分区存储 话题每个分区对应一个逻辑日志 每个日志为相同的大小的一组分段文件 生产者发布的消息被代理追加到对应分区最后一个段文件中 发布消息数量达到设定值、经过一段时间后，段文件真正写入 磁盘，然后公开给消费者 Offset分区中每个消息的Sequential ID Number（Offset），唯一标识 分区中消息，并没有明确的消息ID 偏移量是增量的但不连续，下个消息ID通过在其偏移量加上 消息长度得到 偏移量标识每个消费者目前处理到某分区消息队列的位置， 对分区消息队列处理依赖于其（消息通过日志偏移量公开） 偏移量由消费者控制，所以消费者可以以任何顺序消费消息 可以回推偏移量重复消费消息 设计消费者仅仅查看分区末尾若干消息，不改变消息， 其他消费者可以正常的消费 从消息分区机制、消费者基于偏移量消费机制，可以看出Kafka消息 消费机制不会对集群、其他消费者造成影响 适合场景 Messaging：消息传递，作为传递消息队列（ActiveMQ、 RabbitMQ等）替代品，提供高吞吐能力、高容错、低延迟 Website Activity Tracking：网站活动跟踪，要求系统必须 快速处理产生消息 Metric：度量，把分布式各个应用程序的运营数据集中，进行 汇总统计 Streaming Processing：流数据处理 Event Sourcing：事件溯源，把应用程序状态变化以时间顺序 存储，需要支持大量数据 Commit Log：日志提交，作为分布式系统提交日志的外部存储 服务 StormStorm是分布式、高容错的实时流数据处理的开源系统 Storm为流数据处理设计，具有很高的容错性 Storm保证每个消息只能得到一次完整处理，任务失败时会负责 从消息源重试消息，从而支持可靠的消息处理 可以通过实现Storm通讯协议，提供其他语言支持 Storm架构 主节点的运行Nimbus守护进程 分配代码 布置任务 故障检测 工作节点运行Supervisor守护进程 监听、开始、终止工作进程 Nimbus、Supervisor都是无状态的（不负责维护客户端两次调用 之间状态维护） 这使得两者十分健壮 两者之间的协调由Zookeeper完成 Storm在ZeorMQ内部传递消息 NimbusSupervisorWorkerStorm编程模型Stream数据流：没有边界的tuple序列 这些tuple以分布式的方式，并行的创建、处理 Topology计算拓扑：实时计算应用程序处理逻辑封装成的Topology对象 相当于Mapreduce作业，但是MapReduce作业最终会结束、而 Topology会一直运行直到被杀死 Topology由Spout、Bolt组成 Spout消息源：消息tuple生产者 消息源可以是可靠的、不可靠的 可靠的消息源可在tuple没有被storm成功处理时，可以重新发送 不可靠的消息源则在发送tuple之后彻底丢弃 Bolt消息处理者：封装所有的消息处理逻辑 Bolt可以做很多事情，包括过滤、聚集 Bolt一般数据处理流程 处理一个输入tuple，发送0个、多个tuple 调用ack接口，通知storm子集已经处理过了 Task、ExecutorTopology每个Spout、Bolt转换为若干个任务在整个集群里执行 默认情况下，每个Task对应一个线程Executor，线程用于执行 task 同一个Spout/Bolt里的Task共享一个物理线程 Stream Grouping数据分发策略：定义Spout、Bolt间Tasks的数据分发 Shuffle Grouping：洗牌式分组，上游Spout数据流tuples随机 分发到下游Bolt的Task Fields Grouping：按指定字段进行分组 All Grouping：Spout数据tuple分发给所有下Bolt Global Grouping：Spout数据tuple分发给最小id的task Non-Grouping：类似shuffle Grouping，把具有Non-Grouping 设置Bolt推到其订阅的上游Spout、Bolt Direct Grouping：tuple生产者决定接收tuple下游bolt中的task Local or Shuffle Grouping：如果目标bolt中由一个或多个 task工作在同一进程中，tuple分配给这些task，否则同洗牌式 分组 Partial Key Grouping：类似Fields Grouping，但是在下游 Bolt中做负载均衡，提高资源利用率 消息处理保证Storm追踪由每个SpoutTuple产生的Tuple树 每个从Spout发出tuple，可能会生成成千上万个tuple 根据血缘关系形成一棵tuple树 当tuple树中所有节点都被成功处理了，才说明tuple被完全 处理 每个Topology都有一个消息超时设置，如果Storm在时间内无法 检验tuple树是否完全执行，该tuple标记为执行失败，之后重发 重发","link":"/Database/Hadoop/hdp_tools.html"},{"title":"Hadoop概述","text":"Hadoop（核心）：HDFS和MapReduce/YARN Hadoop家族：建立在Hadoop基础上的一系列开源工具 HadoopHadoop时Apache的一个分布式计算、java语言实现的开源框架， 实现在大量计算机组成的集群中对海量数据进行分布式计算。相比于 依赖硬件的可靠性，Hadoop被设计为可以检测、处理应用层面的 failures，能够提供构建于电脑集群上的可靠服务。 Hadoop：Apache的分布式计算开源框架，提供分布式文件系统 HDFS、MapReduce/YARN分布式计算的软件架构 Hadoop Common支持其它Hadoop模块的公用组件 Hadoop Distributed File System(HDFS)虚拟文件系统，让整个系统表面上看起来是一个空间，实际上是很多 服务器的磁盘构成的 Hadoop YARNYet Another Resource Negotiator，通用任务、集群资源分配框架 ，面向Hadoop的编程模型 YARN将classic/MapReduce1中Jobtracker职能划分为多个独立 实体，改善了其面临的扩展瓶颈问题 YARN比MapReduce更具一般性，MapReduce只是YARN应用的一种 形式，可以运行Spark、Storm等其他通用计算框架 YARN精妙的设计可以让不同的YARN应用在同一个集群上共存， 如一个MapReduce应用可以同时作为MPI应用运行，提高可管理性 和集群利用率 Hadoop MapReduceYARN基础上的大数据集并行处理系统（框架） 包括两个阶段 Map：映射 Reduce：归一 在分布式系统上进行计算操作基本都是由Map、Reduce概念步骤 组成 分布式系统，不像一般的数据库、文件系统，无法从上至下 、从头到尾进行求和等操作 需要由分散的节点不断向一个点聚拢的计算过程 不适合实时性要求的应用，只适合大数据离线处理 Apache下Hadoop相关项目高频Ambari用于部署（供应）、管理、监控Hadoop集群的Web工具 支持HDFS、MapReduce、Hive、HCatalog、HBase、 Oozie、ZooKeeper、Pig、Sqoop 提供dashboard用于查看集群健康程度，如：热度图 能够直观的查看MapReduce、Pig、Hive应用特点，提供 易用的方式考察其执行情况 HBaseHadoop项目子项目，高可靠、高性能、面向列、可伸缩的分布式 存储系统 该技术源于Fay Chang撰写的Google论文《Bigtable：一个 结构化数据的分布式存储系统》，类似于Bigtable在Google 文件系统上提供的分布式数据存储一样，HBase在Hadoop的 基础上提供了类似于Bigtable的能力 适合非结构化数据存储 可用于在廉价PC Server上搭建大规模结构化存储集群，是 NoSQL数据库的两个首选项目（MongoDB） Hive基于Hadoop的数据仓库工具 在Hive中建立表，将表映射为结构化数据文件 可以通过类SQL语句直接查询数据实现简单的MapReduce统计， 而不必开发专门的MapReduce应用 Hive会将SQL语句转换为MapReduce任务查询Hadoop 速度很慢 适合数据仓库的统计分析 支持SQL语法有限 Pig基于Hadoop的大规模数据高层分析工具（类似于Hive） 提供SQL-Like语言PigLatin 其编译器会把类SQL的数据分析请求，转换为一系列经过 优化处理的MapReduce运算 是一种过程语言，和Hive中的类SQL语句相比，更适合写 脚本，而Hive的类SQL语句适合直接在命令行执行 ZookeeperHadoop正式子项目，针对大型分布式应用设计的分布式、开源协调 系统 提供功能：配置维护、名字服务、分布式同步、组服务 封装好复杂、易出错的关键服务，提供简单易用、功能稳定、 性能高效的接口（系统），解决分布式应用中经常遇到的数据 管理问题，简化分布式应用协调及管理难度，提供高性能分布式 服务 通常为HBase提供节点间的协调，部署HDFS的HA模式时是 必须的 Spark基于内存计算的开源集群计算系统，目的是让数据分析更加快速 低频Mahout基于Hadoop的机器学习、数据挖掘的分布式框架 使用MapReduce实现了部分数据挖掘算法，解决了并行挖掘问题 包括聚类、分类、推荐过滤、频繁子项挖掘 通过使用Hadoop库，Mahout可以有效扩展至云端 Cassandra开源分布式NoSQL数据库系统，最初由Facebook开发，用于存储 简单格式数据，集Google BigTable数据模型和Amazon Dynamo 的完全分布式架构于一身 Avro数据序列化系统，设计用于支持数据密集型、大批量数据交换应用， 是新的数据序列化格式、传输工具，将逐步取代Hadoop原有的 IPC机制 Chukwa用于监控大型分布式系统的开源数据收集系统，可以将各种类型的 数据收集成适合Hadoop处理的文件，保存在HDFS中供MapReduce 操作 Tez基于YARN的泛用数据流编程平台 提供强力、灵活的引擎用于执行任何DAG任务，为批处理和 交互用例处理数据 Tez正逐渐被Hive、Pig等Hadoop生态框架采用，甚至被一些 商业公司用于替代MapReduce作为底层执行引擎 其他Hadoop相关项目高频Sqoop用于将Hadoop和关系型数据库中数据相互转移的开源工具 可以将关系型数据库（MySQL、Oracle、Postgres）中 数据转移至Hadoop的HDFS中 也可以将HDFS的数据转移进关系型数据库中 Impala由Cloudera发布的实时查询开源项目 模仿Google Dremel 称比基于MapReduce的Hive SQL查询速度提升3~30倍，更加 灵活易用 Phoenixapache顶级项目，在HBase上构建了一层关系型数据库，可以用 SQL查询HBase数据库，且速度比Impala更快，还支持包括 二级索引在内的丰富特性，借鉴了很多关系型数据库优化查询方法 Oozie工作流引擎服务器，用于管理、协调运行在Hadoop平台 （HDFS、Pig、MapReduce）的任务 Cloudera Hue基于Web的监控、管理系统，实现对HDFS、MapReduce/YARN、 HBase、Hive、Pig的Web化操作和管理 低频Hama基于HDFS的BSP(Bulk Synchronous Parallel)并行 计算框架，可以用包括图、矩阵、网络算法在内的大规模、 大数据计算 Flume分布的、可靠的、高可用的海量日志聚合系统，可用于日志数据 收集、处理、传输 Giraph基于Hadoop的可伸缩的分布式迭代图处理系统，灵感来自于BSP和 Google Pregel Crunch基于Google FlumeJava库编写的Java库，用于创建MapReduce 流水线（程序） 类似于Hive、Pig，提供了用于实现如连接数据、执行聚合 、排序记录等常见任务的模式库 但是Crunch不强制所有输入遵循同一数据类型 其使用一种定制的类型系统，非常灵活，能直接处理复杂 数据类型，如：时间序列、HDF5文件、HBase、序列化 对象（protocol buffer、Avro记录） 尝试简化MapReduce的思考方式 MapReduce有很多优点，但是对很多问题，并不是合适的 抽象级别 出于性能考虑，需要将逻辑上独立的操作（数据过滤、投影 、变换）组合为一个物理上的MapReduce操作 Whirr运行于云服务的类库（包括Hadoop），提供高度互补性 相对中立 支持AmazonEC2和Rackspace的服务 Bigtop对Hadoop及其周边生态打包、分发、测试的工具 HCatalog基于Hadoop的数据表、存储管理，实现中央的元数据、模式管理， 跨越Hadoop和RDBMS，利用Pig、Hive提供关系视图 Llama让外部服务器从YARN获取资源的框架 非CDH组件Fuse让HDFS系统看起来像普通文件系统 Hadoop StreaminMapReduce代码其他语言支持，包括：C/C++、Perl、Python 、Bash等","link":"/Database/Hadoop/hdp_family.html"},{"title":"Hive","text":"Hive简介Hive是Hadoop平台上的数据仓库，面向结构化数据分析 将结构化数据文件映射为一张数据库表 提供完整的SQL查询功能，所用语言称为HiveQL Hive将HiveQL转换为MapReduce作业，在hadoop平台运行 Hive相当于一个在hadoop平台上的SQL Shell 方便用户使用HiveQL快速实现简单数据分析、统计，而不必 开发专用MapReduce程序，学习成本低 相较于传统关系数据库，Hive具有如下特点 ||Hive|传统关系型数据库| |———|———|———-| |数据存储|HDFS分布式文件系统|服务器本地文件系统| |查询处理|MapReduce计算模型|自行设计的查询处理模型| |应用场景|海量数据分析处理|高性能查询，实时性好| |数据更新|不支持对具体数据行修改，只能覆盖、追加|支持| |事务处理|不支持|支持| |索引支持|不支持，一般需要对数据进行全部扫描|支持，多种索引| |扩展能力|基于Hadoop平台，存储、计算强大的扩展能力|扩展性较差| |数据加载|Writing Time Schema：数据加载时无需进行模式检查，在读取数据时对数据以一定模式进行解释|Reading Time Schema：要求数据必须符合数据库表结构| Hive服务端组件Driver负责将用户的编写的HiveQL查询语句进行解析、编译、优化、生成 执行计划，然后调用底层MapReduce计算模型执行，包括 Compiler：编译器 Optimizer：优化器 Executor：执行器 MetaStore元信息管理器，对Hive正确运行举足轻重 MetaStore实际上就是Thrift服务 MetaStore客户端（hive、spark shell等）和服务端通过 thrift协议进行通信 客户端通过连接metastore服务，实现对元数据的存取 通过Thrift获取元数据，屏蔽了访问MetaStore Database 所需的驱动、url、用户名、密码等细节 负责存储元数据在关系型数据库（称为MetaStore Database） 元数据包括Hive创建的database、table等元信息 支持的关系型数据库 Derby：Apache旗下Java数据库 MySQL MetaStore服务可以独立运行，可以让多个客户端同时连接、 甚至安装到远程服务器集群，保持Hive运行的健壮性 Embedded Metastore Server(Database Derby)内嵌模式：使用内嵌的Derby数据库存储元数据 不需要额外起Metastore服务 一次只能一个客户端连接，使用做实验，不适合生产环境 Derby默认会在调用hive命令所在目录的metastore_db文件中 持久化元数据 Local Metastore Server本地元存储 采用外部数据库，支持 MySQL Postgres Orcale MSSQL 数据库独立于hive部署，hive服务使用JDBC访问元数据，多个 服务可以同时进行 本地元存储不需要单独起metastore服务，用的是跟hive在同一 进程metastore服务 Remote Metastore Server远程元存储 类似于本地元存储，只是需要单独启动metastore服务，和hive 运行在不同的进程（甚至主机）中 需要在每个客户端配置文件配置连接到该metastore服务 hive通过thrift访问metastore 此模式可以控制到数据库的连接 hiveserver2基于的Thrift RPC实现 远程客户端可以通过hiveserver2执行对hive的查询并返回结果 支持多客户端并发、身份验证 可以使用JDBC、ODBC、Thrift连接hiveserver2（Thrift Server 特性） hiveserver2也能访问元数据，不依赖于metastore服务 Hive客户端组件CLICommand Line Interface 允许用户交互式的使用Hive THrift Client/beeline基于Thrift的JDBC Client 包括JDBC/ODBC驱动程序 WEB GUI允许用户通过WEB GUI图形界面访问Hive 需要首先启动Hive Web Interface服务 Hive查询处理过程 用户提交HQL至Driver Driver把查询交给Compiler，Compiler使用MetaStore中元信息 检查、编译 查询经过Optimizer优化交由Executor Engine执行，转换为 MapReduce作业后调用MapReduce执行 MapReduce存取HDFS，对数据进行处理，查询结果返回Driver 数据类型 基础数据类型 Integer Float Double String 复杂数据类型：通过嵌套表达复杂类型 Map List Struct 还允许用户自定以类型、函数扩展系统 数据存储模型使用传统数据库：Table、Row、Column、Partition等概念，易于 理解 Database相当于关系型数据库中的Namespace 将不同用户数据隔离到不同的数据库、模式中 Table表格 逻辑上由存储的数据、描述数据格式的相关元数据组成 表格数据存放在分布式文件系统（HDFS）中 元数据存储在MetaStore服务指定关系型数据库中 创建表格、加载数据之前，表格在HDFS中就是一个目录， 表格分为两种类型 托管表：数据文件存放在Hive数据仓库中，即HDFS中的一个 目录，是Hive数据文件默认存放路径 外部表：数据文件可以存放在其他文件系统中 Partition根据“分区列”的值，对表格数据进行粗略划分的极值 存储上：是Hive中表格主目录的子目录，名字即为定义的分区列 名字 逻辑上：分区不是表中的实际字段，是虚拟列 根据虚拟列（可能包含多个实际字段）划分、存储表格数据 同一虚拟列中字段通常应该经常一起被查询，这样在需要 存取部分数据字段时，可以只扫描部分表 BucketTable、Partition都是目录级别的数据拆分，指定Bucket的表格， 数据文件将按照规律拆分成多个文件 每个桶就是table、partition目录中的文件 一般使用Hash函数实现数据分桶，创建表时，需要指定桶数量、 分桶操作依据的列 用户执行Sample查询时，Hive可以使用分桶信息，有效的Prune Data，如：对每个目录下单个桶文件进行查询","link":"/Database/Hadoop/hive.html"},{"title":"MapReduce YARN","text":"MapReduce1.0组件MapReduce1.0是指Hadoop1.0中组件，不是指MapReduce计算模型 优势 方便扩展：能够运行在普通服务器构成的超大规模集群上 IO瓶颈：通过将IO分散在大规模集群的各个节点上，可以提高 数据装载速度（大规模数据时只有部分数据可以状态在内存中） 局限 MapReduce计算模型问题（参见MapReduce计算模型） 数据处理延迟大 MapReduce作业在Map阶段、Reduce阶段执行过程中，需要 把中间结果存盘 在MR作业间也需要通过磁盘实现作业间的数据交换 资源利用率低 任务调度方法远未达到优化资源利用率的效果，给每个 TaskTracker分配任务的过程比较简单 资源分配 每个TaskTracker拥有一定数量的slots，每个活动的Map、 Reduce任务占用一个slot JobTracker把任务分配给最靠近数据、有slot空闲TT 不考虑Task运算量大小，所有Task视为相同，如果有某个TT 当前负载过高，会影响整体的执行 也可以通过Speculative Execution模式，在多个slave上 启动同一个任务，只要其中有一个任务完成即可 执行引擎MapReduce执行引擎运行在HDFS上 JobTracker：运行在NameNode上 分解客户端提交的job为数据处理tasks，分发给集群里相关 节点上的TaskTacker运行 发送任务原则：尽量把任务推送到离数据最近的节点上， 甚至推送到数据所在的节点上运行 TaskTracker：运行在DataNode上 在节点上执行数据处理map、reduce tasks 可能需要从其他DataNode中获取需要数据 MapRedudce2.0ShuffleShuffle：系统执行排序的过程 为了确保MapReduce的输入是按键排序的 Map端每个Map Task都有一个内存缓冲区用于存储map输出结果，缓冲区 快满时需要将缓冲区数据以临时文件方式存放到磁盘中，整个Task 结束后再对此Map Task产生所有临时作合并，生成最终正式输出文件 ，等待Reduce Task拉数据 YARNYet Another Resource Negotiator，通用任务、集群资源分配框架 ，面向Hadoop的编程模型 YARN优势扩展性 YARN将classic/MapReduce1中Jobtracker职能划分为多个独立 实体，改善了其面临的扩展瓶颈问题 MapReduce现在只是批数据处理框架，是YARN支持的数据处理 框架的一种，独立于资源管理层，单独演化、改进 YARN精妙的设计可以让不同的YARN应用在同一个集群上共存， 如一个MapReduce应用可以同时作为MPI应用运行，提高可管理性 、集群利用率 高效率 ResourceManager是单独的资源管理器 Job Scheduler指负责作业调度 根据资源预留要求、公平性、Service Level Agreement等标准 ，优化整个集群的资源利用 一般性YARN是通用资源管理框架，在其上可以搭建多种数据处理框架 批处理：MapReduce 交互式处理：Tez 迭代处理：Spark 实时流处理：Storm 图数据处理：GraphLab/Giraph YARN中实体ResourceManagerRM物理上对应主节点，逻辑上管理集群上的资源使用，其功能由 Scheduler、ApplicationManager协调完成 AppplicatonManager：接受、监控任务 接受客户端提交的job 判断启动该job的ApplicationMaster所需的资源 监控ApplicationMaster的状态，并在失败时重启其 Scheduler：分配资源、调度 Schedular计算启动ApplicationManager提交的job的AM所需 资源，将资源封装成Container 然后根据调度算法调度，在某个NM上启动job的AM 不提供失败重启、监控功能 Scheduler收到AM任务完成汇报之后，回收资源、向RM返回 执行结果 调度算法可自定以，YARN根据不同场景提供 FIFO Scheduler Capacity Scheduler Fair Scheduler NodeManagerNM物理上对应计算节点，逻辑上监控、管理当前节点资源 仅仅抽象本节点资源（cpu、内存、磁盘、网络等），并且定时 像RM的Scheduler汇报 接受并处理AM的tasks启动、停止等请求 ApplicationMasterAM管理集群上运行任务生命周期 每个job都有一个专用的AM AM启动后会计算job所需资源，并向Scheduler申请资源 AM运行在job运行期间，负责整个job执行过程的监控 NM分配完任务container后，AM开始监控这些containers 、tasks状态 任务失败则回收资源重新生成 成功则释放资源 任务执行完毕后回报Scheduler ContainersYARN为将来的资源隔离提出的框架，是一组资源的集合，每个task 对应一个container，只能在container中运行 容器有特定的内存分配范围 容器内存最小值即为内存分配单位，内存最大值也应该是 内存分配单位整数倍 根据任务所需资源多少分配给容器整数倍内存单位，但是 如果任务所需内存大于容器内存最大值，运行时可能会报错 由NM确保task使用的资源不会超过分配的资源 注意 AM并不运行于container中，真正的task才运行在container Job运行过程作业提交 从RM获取新的作业ID 作业客户端检查作业输出说明，计算输入分片（也可以配置 在集群中产生分片） 将作业资源复制到HDFS 调用RM上的submitApplication方法提交作业 作业初始化 RM收到调用submitApplication消息后，将请求传递给 内部scheduler，scheduler分配一个container NM在RM的管理下在容器中启动应用程序的master进程AM， 其对作业进行初始化 AM创建多个簿记对象用于接受任务进度、完成报告，保持 对作业进度的跟踪 AM接受来自共享文件系统的在客户端计算的输入分片，对 每个分片创建一个map对象，及由mapreduce.job.reduces 属性确定的多个reduce任务对象 AM根据任务大小决定如何运行job，如果在新容器中分配、 运行任务的开销大于并行运行时的开销，AM会在单个节点 上运行，这样的作业称为uberized AM在任何tasks执行之前通过job的setup方法设置job的 OutputCommiter，建立作业输出目录 任务分配 若作业不适合作为uber任务运行，AM为该作业中所有map 、reduce任务向RM请求容器 请求附着heart beat，包括每个map任务的数据本地化信息 ，特别是输入分片所在的主机、机架信息，scheduler据此 做调度决策 理想化情况下任务分配到数据本地化节点 否则优先使用机架本地化 请求同时指定了任务内存需求，YARN中的资源分为更细粒度 ，task可以请求最小到最大限制范围、任意最小值倍数的 内存容量 任务执行 当NM的scheduler为task分配了container，AM就可以通过 与NM通信启动容器 任务由YarnChild执行，在执行任务之前，需要将任务 所需资源本地化，包括作业的配置、JAR文件、所有来自 分布式缓存的文件，然后运行map、reduce任务 对于Streaming、Pipes程序，YarnChild启动Streaming、 Pipes进程，使用标准输入输出、socket与其通信（以 MapReduce1方式运行） 进度和状态更新 task每3s通过umbilical接口向AM汇报进度、状态（包括 计数器），作为job的aggregate view 客户端则默认没1s查询AM接受进度更新 作业完成 客户端每5s通过调用job的waitForCompletion检查作业 是否完成，也可以通过HTTP callback完成作业 作业完成后AM和task容器清理工作状态，OutputCommiter 作业清理方法被调用 todo：这里逻辑有问题，要删MapReduce计算模型 分布式系统，不像一般的数据库、文件系统，无法从上至下 、从头到尾进行求和等操作 需要由分散的节点不断向一个点聚拢的计算过程，即分布式系统 上计算模型基本都是由map、reduce步骤组成 MapReduceMapReduce每步数据处理流程包括两个阶段 Map：映射 map过程相互独立、各mapper见不通信，所以mapreduce 只适合处理独立计算的任务 Reduce：归一 reduce直接处理map的输出，reduce的键为map输出 值 数据处理过程 需要把任何计算任务转换为一系列MapReduce作业，然后依次 执行这些作业 计算过程的各个步骤之间，各个作业输出的中间结果需要存盘， 然后才能被下个步骤使用（因为各个步骤之间没有明确流程） One Pass Computation：只需要一遍扫描处理的计算任务 MapReduce计算模型非常有效 Multi Pass Computation：需要在数据上进行多遍扫描、处理 的计算任务，需要执行多个MapReduce作业计算任务，因为 多副本复制、磁盘存取，其效率不高 Mapred on DAGDirected Acyclic Graph；表示数据处理流程的有向无环图 顶点：数据处理任务，反映一定的业务逻辑，即如何对数据进行 转换和分析 边：数据在不同的顶点间的传递 比较 比较方面 MapReduce DAG 操作原语 map、reduce 较多 抽象层次 低 高 表达能力 差 强 易用性 要手动处理job之间依赖关系，易用性差 DAG本身体现数据处理流程 可读性 处理逻辑隐藏在代码中，没有整体逻辑 较好 正是MapReduce提供操作原语少、抽象层次低，所以其表达能力 差，同时需要用户处理更多的逻辑，易用性、可读性差 复杂数据处理任务，如：机器学习算法、SQL连接查询很难 表示用MapReduce计算默认表达 操作原语多并不是DAG本身的要求，DAG本身只是有向无环图， 只是使用DAG计算模型可以提供更多的操作原语 由于DAG的表达能力强于MapReduce，对某些处理逻辑，DAG 所需作业数目小于MapReduce，消除不必要的任务 DAG显著提高了数据处理效率，对小规模、低延迟和大规模、 高吞吐量的负载均有效 MapReduce需要通过把中间结果存盘实现同步，而DAG整合 部分MapReduce作业，减少磁盘I/O reduce任务需要等待map任务全部完成才能继续，DAG优化 数据处理流程，减少同步Barrier DAG部分计算模型也由map、reduce任务构成，只是不像传统 MapReduce计算模型中map、reduce必须成对出现 或者说DAG只有一次map任务（扫描数据时），其余都是 reduce任务？ 从MapReduce配置也可以看出，MapReduce可以选择基于 yarn或yarn-tez","link":"/Database/Hadoop/mapred_yarn.html"},{"title":"Tez","text":"Tez简介Tezm目标就是建立执行框架，支持大数据上DAG表达的作业处理 YARN将资源管理功能从数据处理模型中独立出来，使得在Hadoop 执行DAG表达的作业处理成为可能，Tez成为可扩展、高效的执行 引擎 Tez在YARN和Hive、Pig之间提供一种通用数据处理模型DAG Hive、Pig、Cascading作业在Tez上执行更快，提供交互式 查询响应 Tez把DAG的每个顶点建模为Input、Processer、Output模块的 组合 Input、Output决定数据格式、输入、输出 Processor包装了数据转换、处理逻辑 Processor通过Input从其他顶点、管道获取数据输入，通过 Output向其他顶点、管道传送生成数据 通过把不同的Input、Processor、Output模块组合成顶点， 建立DAG数据处理工作流，执行特定数据处理逻辑 Tez自动把DAG映射到物理资源，将其逻辑表示扩展为物理表示， 并执行其中的业务逻辑 Tez能为每个节点增加并行性，即使用多个任务执行节点 的计算任务 Tez能动态地优化DAG执行过程，能够根据执行过程中获得地 信息，如：数据采样，优化DAG执行计划，优化资源使用、 提高性能 去除了连续作业之间的写屏障 去除了工作流中多余的Map阶段 Tez执行过程 初始化例程，提供context/configuration信息给Tez runtime 对每个顶点的每个任务（任务数量根据并行度创建）进行初始化 执行任务Processor直到所有任务完成，则节点完成 Output把从Processor接收到的数据，通过管道传递给下游顶点 的Input 直到整个DAG所有节点任务执行完毕","link":"/Database/Hadoop/tez.html"},{"title":"Spark GraphX","text":"GraphXSpark GraphX：图数据的并行处理模块 GraphX扩展RDD为Resilient Distributed Property Graph， 边、顶点都有属性的有向图 可利用此模块对图数据进行ExploratoryAnalysis、Iterative Graph Computation GraphX提供了包括：子图、顶点连接、信息聚合等操作在内的 基础原语，并且对的Pregel API提供了优化变量的 GraphX包括了正在不断增加的一系列图算法、构建方法，用于 简化图形分析任务 提供了一系列操作 Sub Graph：子图 Join Vertices：顶点连接 Aggregate Message：消息聚集 Pregel API变种 经典图处理算法 PageRank","link":"/Database/Spark/spark_graphx.html"},{"title":"Spark Core","text":"Spark特性数据处理速度快得益于Spark的内存处理技术、DAG执行引擎 内存计算 Spark尽量把数据（中间结果等）驻留在内存中，必要时才写入 磁盘，避免I/O操作，提高处理效率 支持保存部分数据在内存中，剩下部分保存在磁盘中 数据完全驻留于内存时，数据处理达到hadoop系统的 几十~上百倍，数据存在磁盘上时，处理速度能够达到hadoop的 10倍左右 DAG执行引擎 Spark执行任务前，根据任务之间依赖关系生成DAG图，优化数据 处理流程（减少任务数量）、减少I/O操作 除了简单的map、reduce，Spark提供了超过80个数据处理的 Operator Primitives 对于数据查询操作，Spark采用Lazy Evaluation方式执行， 帮助优化器对整个数据处力工作流进行优化 易用性/API支持 Spark使用Scala编写，经过编译后在JVM上运行 支持各种编程语言，提供了简洁、一致的编程接口 Scala Java Python Clojure R 通用性 Spark是通用平台，支持以DAG（有向无环图）形式表达的复杂 数据处理流程，能够对数据进行复杂的处理操作，而不用将复杂 任务分解成一系列MapReduce作业 Spark生态圈DBAS（Berkely Data Analysis Stack）包含组件， 支持批处理、流数据处理、图数据处理、机器学习 兼容性 DataStorage 一般使用HDFS、Amazon S3等分布式系统存储数据 支持Hive、Hbase、Cassandra等数据源 支持Flume、Kafka、Twitter等流式数据 Resource Management 能以YARN、Mesos等分布式资源管理框架为资源管理器 也可以使用自身资源的管理器以Standalone Mode独立运行 使用支持 可以使用shell程序，交互式的对数据进行查询 支持流处理、批处理 数据类型、计算表达能力 Spark可以管理各种类型的数据集：文本 Spark架构核心组件 Spark Streaming、Spark SQL、Spark GraphX、 Spark MLLib为BDAS所包含的组件 Spark Streaming：提供对实时数据流高吞吐、高容错、可 扩展的流式处理系统 采用Micro Batch数据处理方式，实现更细粒度资源分配， 实现动态负载均衡 可以对多种数据源（Kafka、Flume、Twitter、ZeroMQ），进行 包括map、reduce、join等复杂操作 Spark SQL：结构化数据查询模块 通过JDBC API暴露Spark数据集，让客户程序可以在其上 直接执行SQL查询 可以连接传统的BI、可视化工具至数据集 前身Shark即为Hive on Spark，后出于维护、优化、 性能考虑放弃 Spark GraphX：图数据的并行处理模块 扩展RDD为Resilient Distributed Property Graph， 将属性赋予各个节点、边的有向图 可利用此模块对图数据进行ExploratoryAnalysis、Iterative Graph Computation Spark MLLib：可扩展的机器学习模块 大数据平台使得在全量数据上进行学习成为可能 实现包括以下算法 Classification Regression Clustering Collaborative Filtering Dimensionality Reduction 周围组件 BlinkDB：近似查询处理引擎 可以在大规模数据集上，交互式执行SQL查询 允许用户在查询精度、响应时间之间做出折中 用户可以指定查询响应时间、查询结果精度要求之一 BlinkDB在Data Sample上执行查询，获得近似结果 查询结果会给Error Bar标签，帮助决策 Tachyon：基于内存的分布式文件系统 支持不同处理框架 可在不同计算框架之间实现可靠的文件共享 支持不同的上层查询处理框架，可以以极高的速度对集群 内存中的文件进行访问 将workset文件缓存在内存中，避免对磁盘的存取，如果数据集 不断被扫描、处理，数据处理速度将极大提升 Spark实体 Spark Context：负责和CM的交互、协调应用 所有的Spark应用作为独立进程运行，由各自的SC协调 SC向CM申请在集群中worker创建executor执行应用 Driver：执行应用主函数、创建Spark Context的节点 Worker：数据处理的节点 Cluster Manager：为每个driver中的应用分配资源 以下3种资源管理器，在sceduling、security、monitoring 有所不同，根据需要选择不同的CM Standalone Mesos YARN CM对Spark是agnostic Spark Contextspark.SparkContext1234567891011class SparkConf{ // 设置Spark应用名 def setAppName(appName: String) // 设置集群地址：yarn master节点地址、&quot;local[4]&quot;本地standalone def setMaster(master: String)}class SparkContext(?conf: SparkConf){ // 将driver中节点分块 def parallelize(?val: ?AnyRef, ?numPartition: Int)} SparkContext是Spark应用执行环境封装，任何应用都需要、 也只能拥有一个活动实例，有些shell可能默认已经实例化 12345import org.apache.spark.{SparkConf, SparkContext}val conf = new SparkConf().setAppName(&quot;app name&quot;) .setMaster(&quot;local[4]&quot;)val sc = new SparkContext(conf) Share Variable共享变量：可以是一个值、也可以是一个数据集，Spark提供了两种 共享变量 Broadcast Variable广播变量：缓存在各个节点上，而不随着计算任务调度的发送变量 拷贝，可以避免大量的数据移动 12val broadcastVal = sc.breadcast(Array(1,2,3))println(broadcastVal.value) Accumulator收集变量/累加器：用于实现计数器、计算总和 集群上各个任务可以向变量执行增加操作，但是不能读取值， 只有Driver Program（客户程序）可以读取 累加符合结合律，所以集群对收集变量的累加没有顺序要求， 能够高效应用于并行环境 Spark原生支持数值类型累加器，可以自定义类型累加器 12345678910111213141516// 创建数值类型累加器val accum = sc.accumulator(0, &quot;accumulator&quot;)sc.parallelize(Array(1,2,3,4)).foreach(x =&gt; accum += x)println(accum.value)// 自定义向量累加器工具object VectorAccumulatorParam extends AccumulatorParam[Vector]{ def zero(initialValue: Vector): Vector = { Vector.zeros(initialValue.size) } def addInPlace(v1: Vector, v2: Vector){ v1 += v2 }}// 创建向量累加器val vecAccum = sc.accumulator(new Vector(1,2,3))(VectorAccumulator) 数据源1234567// 按行读取文本文件def sc.textFile(?fileName: String, ?slices: Int): RDD[String]// 读取包含多个小文件的目录def sc.wholeTextFile(?directoryName: String): Map[String, RDD[String]]// #tododef sc.SequenceFiles(fileName: String)def sc.hadoopRDD() slices：切片数目，缺省为每个文件块创建切片，不能设置 小于文件块数目的切片值 Spark基于文件的方法，原生支持 文件目录 压缩文件：gz 简单通配符 |通配符|含义| |——-|——-| |[]：范围| |[^]|范围补集| |?|单个字符| |*|0、多个字符| |{}|整体或选择| Spark SessionSparkSession：Spark2.0中新入口，封装有SparkConf、 SparkContext、SQLContext、HiveContext等接口 12345678val warehouseLocation = &quot;file:${system:user.dir}/spark-warehouse&quot;val spark = SparkSession .builder() .appName(&quot;App&quot;) .config(&quot;spark.sql.warehouse.dir&quot;, warehouseLocation) .enableHiveSupport() .getOrCreate()spark.conf.set(&quot;spark.executor.memory&quot;, &quot;2g&quot;)","link":"/Database/Spark/spark_core.html"},{"title":"SparkSQL2.4中启用CBO时JoinReorder分析","text":"背景Spark Join方式SparkSQL目前支持三种join方式 broadcast hash join：将小表广播分发到大表所在的结点上 ，并行在各节点上进行hash join 仅适合内表非常小的场合 shuffle hash join：按照join key分区，每个结点独立并行 进行hash join 类似分布式GHJ，不同块位于不同结点 sort merge join：按照join key分区，在各节点独立并行SMJ spark当前shuffle算法使用sort-based shuffle算法 理论上shuffle过后各分区数据已经排序完毕，无需再次 sort，效率很高 Join类型SparkSQL支持的Join类型可以分为以下两类 顺序结果无关Join inner join (full)outer join 顺序结果相关Join left(outer) join right(outer) join left semi join right semi join 考虑到JoinReorder的结果 仅支持连接重排序的连接类型只可能是inner join outer join 而outer join重排序虽然不影响结果，但是处理不方便，所以 联接重排序一般仅限于inner join？？？ 有些情况下RBO可以将外联接等价转换为内联接 SparkSQL2.4中支持的连接重排序仅限于内连接 Cost-Based Opitimization/OptimizerCBO：基于成本的优化（器） 根据SQL的执行成本制定、优化查询作业执行计划，生成可能 的执行计划中代价最小的计划 数据表统计数据 基/势 唯一值数量 空值数量 平均、最大长度 SQL执行路径I/O 网络资源 CPU使用情况 在SparkSQL Hash Join中可以用于 选择正确hash建表方 选择正确join类型：广播hash、全洗牌hash join reorder：调整多路join顺序 CBO本身需要耗费一定资源，需要平衡CBO和查询计划优化程度 数据表的数据统计资源耗费 优化查询计划即时资源耗费 CBO是相较于Rule-Based Optimization的概念 CBO中的独特概念 cardinality：集的势，结果集的行数 表示SQL执行成本值 SQL执行返回的结果集包含的行数越多，成本越大 selectivity：可选择率，施加指定谓语条件后返回结果集的 记录数占未施加任何谓语条件的原始结果记录数的比率 值越小，说明可选择性越好 值越大，说明可选择性越差，成本值越大 Join ReorderJoin Reorder：基于CBO的多表连接顺序重排 用统计信息预估的基修正join顺序 主要涉及到以下两个方面 查询代价估算 多表连接顺序搜索算法 查询代价估计代价模型 单个join操作成本 cost = weight * cardinality + (1 - weight)*size carinality：对应CPU成本 size：对应IO成本 join树的成本是所有中间join成本总和 Filter Selectivity估计过滤选择率：估计应用谓词表达式过滤的选择率 逻辑运算符 AND：左侧过滤条件选择率、右侧过滤条件选择率之积 fs(a AND b) = fs(a) * fs(b) OR：左侧、右侧过滤条件选择率之和，减去其乘积 fs(a OR b) = fs(a) + fs(b) - fs(a) * fs(b) NOT：1减去原始过滤条件选择率 fs(NOT a) = 1.0 - fs(a) 比较运算符 =：等于条件 若常数取值在当前列取值范围之外，则过滤选择率为0 否则根据柱状图、均匀分布得到过滤选择率 &lt;：小于条件 若常数取值小于当前列最小值，则过滤选择率为0 否则根据柱状图、均匀分数得到过滤选择率 Join Carinality估计联接基：估计联接操作结果的基 inner：其他基估计值可由inner join计算 num(A IJ B) = \\frac {num(A) * num(B)} {max(distinct(A.k), distinct(B.k))} num(A)：join操作前表A的有效记录数 distinct(A.k)：表A中列k唯一值数量 left-outer：取inner join、左表中基较大者 num(A LOJ B) = max(num(A IJ B), num(A)) right-outer：取inner join、右表中基较大者 num(A ROJ B) = max(num(A IJ B), num(B)) full-outer num(A FOJ B) = num(A ROJ B) + num(A ROJ B) - num(A IJ B) 多表连接顺序搜索算法SparkSQL2.4中使用动态规划算法对可能联接顺序进行搜索，从中 选择最优的联接顺序作为执行计划 最优子结构：一旦前k个表联接顺序确定，则联接前中间表和 第k+1个表方案和前k个表的联接顺序无关 动态规划表：从单表代价开始，逐层向上计算各层多表联接代价 ，直到求得所有表联接最小代价 减少搜索空间启发式想法：尽可能优先有谓词限制的内连接、 中间表 评价 优势：动态规划算法能够求得整个搜索空间中最优解 缺陷：当联接表数量增加时，算法需要搜索的空间增加的非常快 ，计算最优联接顺序代价很高 PostgreSQL代价模型Postgres的查询代价估计模型基于CPU开销、IO开销，另外还增加 了启动代价 总代价 = 启动代价 + IO代价 + CPU代价动态规划算法类似SparkSQL2.4多表连接算法（假设联接n个表） 构造第一层关系：每个关系的最优路径就是关系的最优单表扫描 方式 迭代依次构造之后n-1层关系联接最优解 左深联接树方式：将第k-1层每个关系同第1层关系联接 紧密树联接方式：将第m(m &gt; 2)层每个关系同第k-m层关系 联接 遗传算法遗传算法：模拟自然界生物进化过程，采用人工进化的方式对目标 空间进行搜索 本质是高效、并行、全局搜索方法 能在搜索过程中自动获取、积累有关搜索空间的知识，并自适应 的控制搜索过程以求的最佳解 思想 将问题域中可能解看作是染色体，将其编码为符号串的形式 对染色体群体反复进行基于遗传学的操作：选择、交叉、变异 根据预定目标适应度函数对每个个体进行评价，不断得到更优 群体，从中全局并行搜索得到优化群体中最优个体 MySQL代价模型 总代价 = IO代价 + CPU代价 因为多表联接顺序采用贪心算法，多个表已经按照一定规则排序 （可访问元组数量升序排序） 所以MySQL认为，找到每个表的最小花费就是最终联接最小代价 贪心算法贪心算法：认为每次连接表的连接方式都是最优的，即从未联接表中 选择使得下次联接代价最小者 多表排序一般为 常量表最前 其他表按可访问元组数量升序排序 贪心算法得到的联接方式都是最优的 则每次联接主要求解要联接表对象的最佳访问方式 即每次代价估计的重点在于单表扫描的代价 求解结束后，局部最优查询计划生成 得到左深树 最初始表位于最左下端叶子节点处 优化方案以下分别从查询代价估计、多表连接顺序搜索算法给出方案 查询代价估计 考虑在现有代价模型上增加网络通信开销 cost = \\alpha * cardinality + \\beta * size + \\gamma netcost 在现有直方图估计选择率基础上，增加选择率估计方法 Parametric Method：参数方法，使用预先估计分布函数 逼近真实分布 Curve Fitting：曲线拟合法，使用多项式函数、最小 标准差逼近属性值分布 多表连接顺序搜索算法考虑到动态规划算法随着联接表数量增加时，计算代价过于庞大， 可以考虑引入其他算法优化多表连接顺序 遗传算法 退火算法 贪心算法 遗传算法 退火算法 贪心算法","link":"/Database/Spark/spark_joinreorder.html"},{"title":"Spark MLLib","text":"MLLibSpark MLLib：Spark平台的机器学习库 能直接操作RDD数据集，可以和其他BDAS其他组件无缝集成， 使得在全量数据上进行学习成为可能 实现包括以下算法 Classification Regression Clustering Collaborative Filtering Dimensionality Reduction MLLib是MLBase中的一部分 MLLib MLI MLOptimizer MLRuntime 从Spark1.2起被分为两个模块 spark.mllib：包含基于RDD的原始算法API spark.ml：包含基于DataFrame的高层次API 可以用于构建机器学习PipLine ML PipLine API可以方便的进行数据处理、特征转换、 正则化、联合多个机器算法，构建单一完整的机器学习 流水线 MLLib算法代码可以在examples目录下找到，数据则在data 目录下 机器学习算法往往需要多次迭代到收敛为止，Spark内存计算、 DAG执行引擎象相较MapReduce更理想 由于Spark核心模块的高性能、通用性，Mahout已经放弃 MapReduce计算模型，选择Spark作为执行引擎 mllib.classificationClassificationLogistic Regression12345678910111213141516171819from pyspark.mllib.classification import \\ LogisticRegressionWithLBFGS, LogisticRegressionModelfrom pyspark.mllib.regression import LabledPointdef parse_point(line): value = [float(i) for i line.split(&quot;, \\r\\n\\t&quot;)data = sc.textFile(&quot;data/mllib/sample_svm_data.txt&quot;)parsed_data = data.map(parse_point) # map `parse_point` to all datamodel = LogisticRegressionWithLBFGS.train(parsed_data)labels_and_preds = parsed_data.map(lambda p: (p.label, model.predict(p.features)))train_err = labels_and_preds \\ .filter(lambda lp: lp[0] != lp[1]) \\ .count() / float(parsed_data.count())model.save(sc, &quot;model_path&quot;)same_model = LogisticRegressionModel.load(sc, &quot;model.path&quot;) Decision Tree Random Forest Gradient boosted tree Multilaye Perceptron Support Vector Machine One-vs-Rest Classifier Naive Bayes ClusteringK-means1234567891011121314151617181920import numpy as npfrom pyspark.mllib.clustering import KMeans, KMeansModeldata = sc.textFile(&quot;data/mllib/kmeans_data.txt&quot;)parsed_data = data.map(lambda line: np.array([float(i) for i in line.split()]))cluster_model = KMeans.train( parsed_data, maxIteration=10, initializationMode=&quot;random&quot;)def error(point): center = cluster_model.centers[cluster.predict(point)] return np.sqrt(sum([i**2 for i in (point - center)]))WSSSE = parsed_data \\ .map(lambda point.error(point)) \\ .reduce(lambd x, y: x + y)cluster_model.save(sc, &quot;model_path&quot;)same_model = KMeansModel.load(sc, &quot;model_path&quot;) Gaussian Mixture Model(GMM) 混合密度模型 有限混合模型：正态分布混合模型可以模拟所有分布 迪利克莱混合模型：类似于泊松过程 应用 聚类：检验聚类结果是否合适 预测：todo 123456789101112131415import numpy as npfrom pyspark.mllib.clustering import GussianMixture, \\ GussianMixtureModeldata = sc.textFile(&quot;data/mllib/gmm_data.txt&quot;)parsed_data = data.map(lambda line: np.array[float(i) for i in line.strip()]))gmm = GaussianMixture.train(parsed_data, 2)for w, g in zip(gmm.weights, gmm.gaussians): print(&quot;weight = &quot;, w, &quot;mu = &quot;, g.mu, &quot;sigma = &quot;, g.sigma.toArray())gmm.save(sc, &quot;model_path&quot;)same_model = GussainMixtureModel.load(sc, &quot;model_path&quot;) Latent Dirichlet Allocation(LDA)123456789101112131415161718from pyspark.mllib.clustering import LDA, LDAModelfrom pyspark.mllib.linalg import Vectorsdata = sc.textFile(&quot;data/mllib/sample_lda_data.txt&quot;)parsed_data = data.map(lambda line: Vector.dense([float(i) for i in line.strip()]))corpus = parsed_data.zipWithIndex() \\ .map(lambda x: [x[1], x[0]).cache()ldaModel = LDA.train(corpus, k=3)topics = ldaModel.topicsMatrix()for word in range(0, ldaModel.vocabSize()): for topic in word: print(topic)ldaModel.save(sc, &quot;model_path&quot;)same_model = LDAModel.load(&quot;model_path&quot;) Disecting K-means RegressionLinear Regression 耗时长、无法计算解析解（无意义） 使用MSE作为极小化目标函数，使用SGD算法求解 123456789101112131415161718192021222324from pyspark.mllib.regression import LabledPoint, \\ LinearRegressionWithSGD, LinearRegressionModeldef parse_point(line): value = [float(i) for i line.split(&quot;, \\r\\n\\t&quot;)data = sc.textFile(&quot;data/mllib/ridge-data/lpsa.data&quot;)parsed_data = data.map(parse_point) # map `parse_point` to all datamodel = LinearRegressionWithSGD.train( parsed_data, iteration=100, step=0.00000001)values_and_preds = parsed_data.map(lambda p:(p.label, model.predict(p.features)))MSE = values_and_preds \\ .map(lambda vp: (vp[0] - vp[1]) ** 2) \\ .reduce(lambda x, y: x + y) / values_and_preds.count()model.save(sc, &quot;model_path&quot;) # save modelsame_model = LinearRegressionModel.load(sc, &quot;model_path&quot;) # load saved model Generalized Linear Regression Decision Tree Regression Random Forest Regression Gradient-boosted Tree Regression Survival Regression Isotonic Regression Collaborative Filtering","link":"/Database/Spark/spark_mllib.html"},{"title":"Resilient Distributed Dataset","text":"RDDRDD：容错的、immutable、分布式、确定可重复计算的数据集 RDD可分配在集群中的多个节点中以支持并行处理 隶属于同一RDD数据，被划分为不同的Partition，以此为 单位分布到集群环境中各个节点上 RDD是无结构的数据表，可以存放任何数据类型 RDD immutable 对RDD进行转换，不会修改原RDD，只是返回新RDD 这也是基于Lineage容错机制的要求 是Spark软件系统的核心概念 RDD容错机制 RDD采用基于Lineage的容错机制 每个RDD记住确定性操作的lineage，即从其他RDD转换而来 的路径 若所有RDD的转换操作是确定的，则最终转换数据一致， 无论机器发生的错误 当某个RDD损坏时，Spark可以从上游RDD重新计算、创建 其数据 容错语义 输入源文件：Spark运行在HDFS、S3等容错文件系统上，从 任何容错数据而来的RDD都是容错的 receiver：可靠接收者告知可靠数据源，保证所有数据总是 会被恰好处理一次 输出：输出操作可能会使得数据被重复写出，但文件会被 之后写入覆盖 故障类型 worker节点故障：节点中内存数据丢失，其上接收者缓冲 数据丢失 driver节点故障：spark context丢失，所有执行算子丢失 RDD操作1import org.apache.spark.rdd.RDD Transformation转换：从已有数据集创建新数据集 返回新RDD，原RDD保持不变 转换操作Lazy 仅记录转换操作作用的基础数据集 仅当某个动作被Driver Program（客户操作）调用DAG 的动作操作时，动作操作的一系列proceeding转换操作才会 被启动 Transformation RDD DStream map(func) flatMap(func) filter(func) reduceByKey(func[, numTasks]) 包含(K, V)键值对，返回按键聚集键值对 groupByKey() aggregateByKey() pipe() coalesce() repartition(numPartitions) union(other) 无 XXXByKey：RDD中应为(K, V)键值对 绿色、黑色：单、多RDD窄依赖转换 紫色：KV shuffle转换 黄色：重分区转换 蓝色：特例转换 Action动作：在数据集上进行计算后返回值到驱动程序 施加于一个RDD，通过对RDD数据集的计算返回新的结果 默认RDD会在每次执行动作时重新计算，但可以使用 cache、persist持久化RDD至内存、硬盘中，加速下次 查询速度 Action RDD DStream count() 返回包含单元素RDD的DStream collect() 将RDD数据聚集至本地 countByValue() 返回(T, long)键值对 countByKey() first() 返回包含单元素RDDd的DStream reduce(func) 返回包含单元素RDD的DStream take(func) foreach(func) foreachPartition(func) join(other[, numTasks]) 包含(K,V)，与另一(K,W)连接 cogroup(other[, numTasks]) 包含(K,V)、输入(K,W)，返回(K, Seq(V), Seq(W) numTasks：默认使用Spark默认并发数目 DStream RDD123456789101112131415161718// RDD级`map`：`func`以RDD为参数，自定义转换操作def transform(func)// RDD级`foreach`def foreachRDD(func)// RDD级`reduce`def updateStateByKey[S: ClassTag]( // `K`、`Seq[V]`：当前RDD中键`K`对应值`V`集合 // `Option[S]`：上个RDD结束后键`K`对应状态 updateFunc: (Iterator[(K, Seq[V], Option[S])]) =&gt; Iterator[(K, S)], // 分区算法 partitioner: Partitioner, // 是否在接下来Streaming执行过程中产生的RDD使用相同分区算法 remmemberPartition: Boolean, // 键值对的初始状态 initRDD: RDD[(K,S)]) RDD分布在多个worker节点上，对不可序列化传递对象，需要在 每个worker节点独立创建 1234567891011dstream.foreachRDD(rdd =&gt; { rdd.foreachPartition(partitionOfRecords =&gt; { // 为每个partition创建不可序列化网络连接 // 为每个record创建成本过高 val connection = createNewConnnection() // 进一步可以维护静态连接对象池 // val connection = ConnectionPool.getConnection() partitionOfRecords.foreach(record =&gt; connection.send(record)) connection.close() })}) DStream Window Action Window Action DStream window(windowLength, slideInterval) 基于DStream产生的窗口化批数据产生DStream countByWindow(windowLenght, slideInterval) 返回滑动窗口数 reduceByWindow(func, windowLength, slideInterval) reduceByKeyAndWindow(func, windowLength, slidenInterval[, numTasks]) reduceByKeyAndWindow(func, invFunc, windowLength, slideInterval[, numTasks]) 须提供invFunc消除离开窗口RDD对reduce结果影响 countByValueAndWindow(windowLength, slideInterval[, numTasks]) windowLength：窗口长度 slideInterval：滑动间隔 以上操作默认会持久化RDD至内存，无需手动调用persist等方法 Output Output Operation RDD DStream print 打印前10条元素 每个RDD打印前10条元素 saveAsObjectFile(prefix[, suffix]) 保存为序列化文件 命名为&lt;prefix&gt;-TIME_IN_M.&lt;suffix&gt; saveAsTextFile(prefix[, suffix]) 保存为文本文件 saveAsHadoopFile(prefix[, suffix]) 保存为Hadoop文件 Persistence Persistence RDD DStream persist() cache() Directed Asycled GraphSpark中DAG：可以看作由RDD、转换操作、动作操作构成，用于表达 复杂计算 当需要执行某个操作时，将重新从上游RDD进行计算 也可以对RDD进行缓存、持久化，以便再次存取，获得更高查询 速度 In-mem Storage as Deserialized Java Objects In-mem Storage as Serialized Data On-Disk Storage DAG工作流示例 从HDFS装载数据至两个RDD中 对RDD（和中间生成的RDD）施加一系列转换操作 最后动作操作施加于最后的RDD生成最终结果、存盘 宽依赖、窄依赖 窄依赖：每个父RDD最多被一个子RDD分区使用 即单个父RDD分区经过转换操作生成子RDD分区 窄依赖可以在一台机器上处理，无需Data Shuffling， 在网络上进行数据传输 宽依赖：多个子RDD分区，依赖同一个父RDD分区 涉及宽依赖操作 groupByKey reduceByKey sortByKey 宽依赖一般涉及Data Shuffling DAG SchedulerDAG Scheduler：Stage-Oriented的DAG执行调度器 使用Job、Stage概念进行作业调度 作业：一个提交到DAG Scheduler的工作项目，表达成DAG， 以一个RDD结束 阶段：一组并行任务，每个任务对应RDD一个分区，是作业 的一部分、数据处理基本单元，负责计算部分结果， DAG Scheduler检查依赖类型 把一系列窄依赖RDD组织成一个阶段 所以说阶段中并行的每个任务对应RDD一个分区 宽依赖需要跨越连续阶段 因为宽依赖子RDD分区依赖多个父RDD分区，涉及 Data Shuffling，数据处理不能在单独节点并行执行 或者说阶段就是根据宽依赖进行划分 DAG Scheduler对整个DAG进行分析 为作业产生一系列阶段、其间依赖关系 确定需要持久化的RDD、阶段的输出 找到作业运行最小代价的执行调度方案、根据Cache Status 确定的运行每个task的优选位置，把信息提交给 Task Sheduler执行 容错处理 DAG Scheduler负责对shuffle output file丢失情况进行 处理，把已经执行过的阶段重新提交，以便重建丢失的数据 stage内其他失败情况由Task Scheduler本身进行处理， 将尝试执行任务一定次数、直到取消整个阶段 DataFrame DataFrame：类似关系型数据库中表，数据被组织到具名列中 相较于RDD是对分布式、结构化数据集的高层次抽象，提供 特定领域的专用API进行处理 静态类型安全：相较于SQL查询语句，在编译时即可发现 语法错误 Dataset：有明确类型数据、或无明确数据类型集合，相应API 也分为两类 相较于DataFrame，也可组织半结构化数据，同样提供方便 易用的结构化API 静态类型、运行时类型安全：相较于DataFrame，集合元素 有明确类型，在编译时即可发现分析错误 Spark2.0中二者API统一 DataFrame可视为无明确数据类型Dataset[Row]别名，每行是 无类型JVM对象 创建方式 .toDF 1234567891011121314151617val sqlContext = new org.apache.spark.sql.SQLContext(sc)import sqlContext.implicits._// `.toDF` + `Seq`创建val df = Seq( (1, &quot;F&quot;, java.sql.Date.valueOf(&quot;2019-08-02&quot;)), (2, &quot;G&quot;, java.sql.Date.valueOf(&quot;2019-08-01&quot;))).toDF(&quot;id&quot;, &quot;level&quot;, &quot;date&quot;)// 不指定列名，则默认为`_1`、`_2`等// `.toDF` + `case Class`创建case class Person(name: String, age: Int)val people = sc.textFile(&quot;people.txt&quot;) .map(_.split(&quot;,&quot;)) .map(p =&gt; Person(p(0),p(1).trim.toInt)) .toDF() .createDataFrame 1234567891011import org.apache.spark.sql.types._val schema = StrucType(List( StructField(&quot;id&quot;, IntegerType, nullable=False), StructField(&quot;level&quot;, StringType, nullable=False), StructField(&quot;date&quot;, DateType, nullable=False)))val rdd = sc.parallelize(Seq( (1, &quot;F&quot;, java.sql.Date.valueOf(&quot;2019-08-02&quot;)), (2, &quot;G&quot;, java.sql.Date.valueOf(&quot;2019-08-01&quot;))))val df = sqlContext.createDataFrame(rdd, schema) 读取文件创建 1234567val df = sqlContext.read.parquet(&quot;hdfs:/peopole.parq&quot;)val df = spark.read.json(&quot;people.json&quot;)// 读取csv仅2.0版本`SparkSession`后可val df = spark.read.format(&quot;com.databricks.spark.csv&quot;) .option(&quot;header&quot;, &quot;true&quot;) .option(&quot;mode&quot;, &quot;DROPMALFORMED&quot;) .load(&quot;people.csv&quot;) 三种数据集对比 空间、时间效率：DataFrame &gt;= Dataset &gt; RDD DataFrame、Dataset基于SparkSQL引擎构建，使用Catalyst 生成优化后的逻辑、物理查询计划；无类型DataFrame相较 有类型Dataset运行更快 Spark作为编译器可以理解Dataset类型JVM对象，会使用 编码器将其映射为Tungsten内存内部表示 RDD适合场景 对数据集进行最基本的转换、处理、控制 希望以函数式编程而不是以特定领域表达处理数据 数据为非结构化，如：流媒体、字符流 DataFrame、Dataset使用场景 需要语义丰富、高级抽象、通用平台、特定领域API 需要对半结构化数据进行高级处理，如：filter、SQL查询 需要编译时/运行时类型安全、Catalyst优化、内存优化","link":"/Database/Spark/spark_rdd.html"},{"title":"Spark SQL","text":"Spark SQLSpark SQL：结构化数据查询模块 内置JDBC服务器，通过JDBC API暴露Spark数据集，让客户程序 可以在其上直接执行SQL查询 通过ETL工具从不同格式数据源装载数据，并运行一些 Ad-Hoc Query 可以连接传统的BI、可视化工具至数据集 前身Shark即为Hive on Spark，后出于维护、优化、 性能考虑放弃 Extraction Transformation Loading：ETL sql.SQLContext123456789101112131415161718192021import org.apache.spark.sql.{SQLContext, HiveContext}class SQLContext{ // 缓存使用柱状格式的表 // Spark将仅仅浏览需要的列、自动压缩数据减少内存使用 def cacheTable(tableName: String) // 将普通RDD转换为SchemaRDD def implicit createSchemaRDD(rdd: RDD): SchemaRDD // 载入parquet格式文件 def parquetFile(fileName: String): SchemaRDD // 载入json格式文件 def jsonFile(fileName: String): SchemaRDD def jsonRDD(rdd: RDD[String]): SchemaRDD // 执行SQL query def sql(query: String): SchemeRDD} HiveContext支持SQLContext支持功能的超集，增加在 MetaStore发现表、利用HiveSQL写查询功能 sql.SchemaRDD1234567891011class SchemaRDD{ // 存储为parquet文件 def saveAsParquetFile(fileName: String) // 注册为临时表，然后可以使用SQL语句查询 def registerTempTable(tableName: String) // 打印表schema def printSchema()} 在数据存储层面对数据进行结构化描述的schema 由SchemaRDD（上个版本）发展而来，在其上增加schema层 ，以便对各个数据列命名、数据类型描述 可以通过DF API把过程性处理、Relational Processing （对表格的选择、投影、连接等操作）集成 DF API操作是Lazy的，使得Spark可以对关系操作、数据处理 工作流进行深入优化 结构化的DF可以通过调用DF API重新转换为无结构的RDD数据集 可以通过不同Data Source创建DF 已经存在的RDD数据集 结构化数据文件 JSON数据集 Hive表格 外部数据库表 Data Source数据源：通过DS API可以存取不同格式保存的结构化数据 Parquet JSON Apache Avro数据序列化格式 JDBC DS：可以通过JDBC读取关系型数据库 1234567891011121314151617181920212223242526272829303132333435363738394041import org.apache.spark.sql.{SQLContext, StructType, StructField, Row}import org.apache.spark.sql.HiveContextval sqlContext = new SQLContext(sc)import sqlContext.createSchemeRDDcase class Person(name: String, age: Int)// 通过反射推断包含特定对象类型的RDD的模式// 需要编写时已知模式// 代码更简洁、工作更好val people: RDD[Person] = sc.textFile(&quot;people.txt&quot;) .map(_.split(&quot;,&quot;)) .map(p =&gt; Person(p(0), p(1).trim.toInt))// 编程指定模式：构建模式，然后在已经存在的RDDs上使用// 运行在运行期前不知道列、列类型情况下构造SchemaRDDsval schemaString = &quot;name age&quot;val people = sc.textFile(&quot;people.txt&quot;)val schema = StructType(schemaString.split(&quot; &quot;) .map(fieldName =&gt; StructField(fieldName, StringType, true)))val rowRDD = people.map(_.split(&quot;,&quot;)) .map(p =&gt; Row(p(0), p(1).trim))val peopleSchemaRDD = sqlContext.applySchema(rowRDD, schema)peopleSchemaRDD.registerTempTable(&quot;people&quot;)// 查询语言集成val teenagers = people.where(&quot;age &gt;= 13&quot;).select(&quot;name&quot;)people.registerTempTable(&quot;people&quot;)val teenagers = sqlContext.sql(&quot;SELECT name FORM people WHERE age &gt;= 13&quot;)val apRDD = sc.parallelize( &quot;&quot;&quot;{&quot;name&quot;: &quot;Tom&quot;, &quot;address&quot;: { &quot;city&quot;: &quot;Columbus&quot;, &quot;state&quot;: &quot;Ohio&quot; }}&quot;&quot;&quot; :: Nil)val anotherPeople = sqlContext.jsonRDD(apRDD)","link":"/Database/Spark/spark_sql.html"},{"title":"Spark Streaming","text":"Spark StreamingSpark Streaming：提供对实时数据流高吞吐、高容错、可扩展的 流式处理系统 可以对多种数据源（Kafka、Flume、Twitter、ZeroMQ），进行 包括map、reduce、join等复杂操作 采用Micro Batch数据处理方式，实现更细粒度资源分配，实现 动态负载均衡 离散化数据流为为小的RDDs得到DStream交由Spark引擎处理 数据存储在内存实现数据流处理、批处理、交互式一体化 故障节点任务将均匀分散至集群中，实现更快的故障恢复 streaming.StreamingContext12345678910import org.apache.spark.streaming.StreamingContextclass StreamingContext(?conf: SparkConf, ?slices: Int){ // 开始接受、处理流式数据 def start() // 结束流式处理过程 def stop(?stop_spark_context=True) // 等待计算完成 def awaitTermination()} 123456import org.apache.spark.{SparkContext, SparkConf}import org.apache.spark.streaming.Secondsimport org.apache.spark.streaming.StreamingContext._val conf = new SparkConf().setAppName(&quot;app name&quot;).setMaster(master)val ssc = new StreamingContext(conf, Seconds(1)) Discreted StreamDStream：代表持续性的数据流，是Spark Streaming的基础抽象 可从外部输入源、已有DStream转换得到 可在流应用中并行创建多个输入DStream接收多个数据流 在内部实现 DStream由时间上连续的RDD表示，每个RDD包含特定时间 间隔内的数据流 对DStream中各种操作也是映射到内部RDD上分别进行 （部分如transform等则以RDD为基本单元） 转换操作仍然得到DStream 最终结果也是以批量方式生成的batch 对DStream操作参见tools/spark/spark_rdd （大部分）输入流DStream和一个Receiver对象相关联 Recevier对象作为长期任务运行，会占用独立计算核， 若分配核数量不够，系统将只能接收数据而不能处理 reliable receiver：可靠的receiver正确应答可靠源， 数据收到、且被正确复制至Spark unreliable receiver：不可靠recevier不支持应答 Basic Sources基本源：在StreamingContext中直接可用 套接字连接 Akka中Actor RDD队列数据流 12345678// 套接字连接TCP源获取数据def ssc.socketTextStream(?host: String, ?port: Int): DStream// 自定义actor流def ssc.actorStream(actorProps: ?, actorName: String): DStream// RDD队列流def ssc.queueStream(queueOfRDDs: Seq[RDD]) 文件系统1234// 文件流获取数据def ssc.fileStream[keyClass, valueClass, inputFormatClass] (dataDirectory: String): DStreamdef ssc.textFileStream(dataDirectory) 文件系统：StreamingContext将监控目标目录，处理目录下任何 文件（不包括嵌套目录） 文件须具有相同数据格式 文件需要直接位于目标目录下 已处理文件追加数据不被处理 文件流无需运行receiver Advanced Sources高级源：需要额外的依赖 Flume Kinesis Twitter Kafka123// 创建多个Kafka输入流val kafkaStreams = (1 to numStreams).map(_ =&gt; kafkaUtils.createStream())val unifiedStream = streamingContext.union(kafkaStreams) 性能调优 减少批数据处理时间 创建多个receiver接收输入流，提高数据接受并行水平 提高数据处理并行水平 减少输入数据序列化、RDD数据序列化成本 减少任务启动开支 设置正确的批容量，保证系统能正常、稳定处理数据 内存调优，调整内存使用、应用的垃圾回收行为 Checkpoint1234// 设置checkpoint存储信息目录def ssc.checkpoint(?checkpointDirectory: String)// 从checkpoint中恢复（若目录存在）、或创建新streaming上下文def StreamingContext.getOrCreate(?checkPointDirectory: String, ?functionToCreateContext: () =&gt; StreamingContext) 为保证流应用程序全天运行，需要checkpoint足够信息到容错 存储系统，使得系统能从程序逻辑无关错误中恢复 metadata checkpointing：流计算的定义信息，用于恢复 worker节点故障 configuration：streaming程序配置 DStream operation：streaming程序操作集合 imcomplete batches：操作队列中未完成批 data checkpointing：中间生成的RDD，在有状态的转换 操作中必须，避免RDD依赖链无限增长 需要开启checkpoint场合 使用有状态转换操作：updateStateByKey、 reduceByKeyAndWindow等 从程序的driver故障中恢复 1234567def functionToCreateContext(): StreamingContext = { val conf = new SparkConf() val ssc = new StreamingContext(conf) // other streaming setting ssc.checkpoint(&quot;checkpointDirectory&quot;) ssc}","link":"/Database/Spark/spark_streaming.html"},{"title":"Catalyst 优化器","text":"结构Catalyst优化器：利用Scala模式匹配和quasiquotes机制构建的 可扩展查询优化器 SparkSQL Pipeline的中间核心部分 Parser模块Parser模块：将SQL语句切分为token，根据一定语义规则解析为AST Spark1.x使用Scala原生Parser Combinator构建的词法、语法 分析器 Spark2.x使用采用第三方语法解析器工具ANTLR4 ANTLR4根据语法文件SqlBase.g4自动解析生成两个Java类 ，将sql语句解析成ParseTree的语法结构 SqlBaseLexer：词法解析器 SqlBaseParser：语法解析器 随后ParsePlan过程，使用AstBuilder.scala将ParseTree 转换为catalyst表达式逻辑计划Unresovled Logical Plan Unsolved Relation Unsolved Function Unsolved Attribute Analyzer模块Analyzer模块：使用Analysis Rules，借助数据元数据 （session catalog、hive metastore）将ULP解析为 Logical Plan ULP虽然具备基本骨架，但是系统对表的字段信息不清楚，需要 基本元数据信息表达ULP中token 遍历整个AST，对树上每个结点进行数据类型绑定、函数绑定， 得到LP Schema Catalog元数据信息：表的模式信息 表的基本定义：表名、列名、数据类型 表的数据格式：json、text、parquet、压缩格式 表的物理位置 Optimizer模块Optimizer模块：使用Optimization Rules对LP进行合并、列 裁剪、过滤器下推等优化工作，生成等价Optimized Logical Plan 分为RBO、CBO两种优化策略，是catalyst核心 Spark PlannerSpark Planner模块：将OLP转换为spark能够理解的 Physical Plan 将逻辑上可行的执行计划变为Spark真正可以执行的物理计划 物理计划实际上是逻辑计划中耗时最小的算法实现 JoinJoin类型SparkSQL目前支持三种join算符 shuffle hash join broadcast hash join sort merge join Broadcast Hash Joinbroadcast hash join：将小表广播分发到大表所在的结点上， 并行在各节点上进行hash join 适合小表很小，可以直接广播的场合 spark.sql.autoBroadcastJoinThreshold设置广播小表 大小上限 broadcast阶段：将所小表广播分发到大表所在的所有主机 driver分发 p2p分发 hash join结点：各结点独立并行hash join 小表构建hash表 各结点本地大表试探 Shuffle Hash Joinshuffle hash join：按照join key分区，在每个结点独立并行 进行hash join 类似分布式GHJ，不同块位于不同结点 shuffle阶段：将表按照join key分区，将具有相同join key 的记录重分布到同一结点 hash jon阶段：各结点使用本地数据独立并行hash join Sort Merge JoinSMJ：按照join key分区，在各节点独立并行SMJ shuffle阶段：将表按照join key分区，将具有相同join key 的记录重分布到同一结点 sort阶段：各节点并行对本地数据排序 spark当前shuffle算法使用sort-based shuffle算法 理论上shuffle过后各分区数据已经排序完毕，无需再次 sort，效率很高 merge阶段：各节点对排序好表数据执行join操作 Join Reorder 基于CBO的join重排序优化：用统计信息预估的基修正join顺序 使用动态规划算法，考虑所有可能组合，选择代价最小的方案 单个join操作成本，join树的成本是所有中间join成本总和 cost = weight * cardinality + (1 - weight)*size carinality：对应CPU成本 size：对应IO成本 没有任何join条件同时包含左、右子树时，修剪笛卡尔积 减少搜索范围 Statistics Collection FrameworkCBO依赖统计细节信息优化查询计划 CBO自下而上遍历LP，统计信息可以随之传播到上层算子 统计信息类型 Numeric、Date、Timestamp Distinct Count Max Min Null Count Average Length：定长 Max Length：定长 String、Binary Distinct Count Null Count Average Length Max Length 统计方式 扫描全表：简单、统计信息准确，代价大 抽样统计： 应用Filter Selectivity过滤选择率：估计应用谓词表达式过滤的选择率 逻辑运算符 AND：左侧过滤条件选择率、右侧过滤条件选择率之积 fs(a AND b) = fs(a) * fs(b) OR：左侧、右侧过滤条件选择率之和，减去其乘积 fs(a OR b) = fs(a) + fs(b) - fs(a) * fs(b) NOT：1减去原始过滤条件选择率 fs(NOT a) = 1.0 - fs(a) 比较运算符 =：等于条件 若常数取值在当前列取值范围之外，则过滤选择率为0 否则根据柱状图、均匀分布得到过滤选择率 &lt;：小于条件 若常数取值小于当前列最小值，则过滤选择率为0 否则根据柱状图、均匀分数得到过滤选择率 Join Carinality联接基：估计联接操作结果的基 inner：其他基估计值可由inner join计算 num(A IJ B) = \\frac {num(A) * num(B)} {max(distinct(A.k), distinct(B.k))} num(A)：join操作前表A的有效记录数 distinct(A.k)：表A中列k唯一值数量 left-outer：取inner join、左表中基较大者 num(A LOJ B) = max(num(A IJ B), num(A)) right-outer：取inner join、右表中基较大者 num(A ROJ B) = max(num(A IJ B), num(B)) full-outer num(A FOJ B) = num(A ROJ B) + num(A ROJ B) - num(A IJ B) B) $$","link":"/Database/Spark/sparksql_catalyst.html"},{"title":"数据库背景","text":"数据库术语数据库结构 数据源：多源数据继承 数据仓库继承工具：FTL工具、MapReduce 数据仓库服务器：列存储数据库引擎 数据即使：数据仓库的数据子集、聚集数据继 OLAP服务器：提供多维数据视图 前台数据分析工具 报表工具 多维分析工具 数据挖掘工具 数据库类型 传统关系型数据库 MPP大规模并行处理数据库 NoSQL数据库 图数据库 NewSQL数据库 GPU数据库 数据查询 Project Pushdown：投影下推 只读取、查询需要的列 减少每次查询的IO数据量 Predicate Pushdown：谓词下推 将过滤条件尽快执行，跳过不满足条件行 数据压缩算法 Run Length Encoding：重复数据 Delta Encoding：有序数据集 Dictionary Encoding：小规模数据集合 Prefix Encoding：字符串版Delta Encoding 数据库调优数据库调优：是数据库具有更高的吞吐量、更快响应 被调优对象是数据库整体 需要考虑很多资源、数据库配置 人工调优 依赖人工，效率低下 要求操作者理解查询原理，对应用、DBMS、操作系统、硬件有 一定理解 基于案例调优 总结典型应用案例情况中数据库参数推荐配置值、逻辑层设计等 情况，为用户调优工作提供参考、借鉴 忽略系统动态性、不同系统之间差异 自调优 为DBMS建立模型，根据“影响数据库性能效率的因素”，自动进行 参数配置 部分商业数据库实现了自调优技术 需求分析期应用情况估算 应用使用方式 将业务逻辑转换为读写分布逻辑，以读多写少、读写均衡 区分OLAP、OLTP 应用对数据库的并发情况、并发是否可池化 数据量 对数据库压力、峰值压力 系统选型策略 确定适合的数据库：开源、商业；集群、单机 操作系统、中间件、硬件、网络选型 项目设计期数据模型设计根据业务逻辑，从以下角度考虑表结构 E-R模型设计：遵循E-R模型设计原理，适当非规范化可以改善 系统查询性能 数据逻辑分布策略：减少数据请求中不必要的数据量 分区 利用E-R模型分表 数据物理存储策略：减少IO操作 启用压缩 分开存储索引、表数据 不同表数据分布在不同表空间 不同表空间分布在不同物理存储，尤其是读写量大的表空间 分布在不同物理存储上 日志、索引、数据分布在不同物理存储上 索引：在查询频繁的对象上建立恰当索引 开发期SQL设计 编写正确、查询效率高的SQL语句，依据“查询重写规则” 有意识地保障SQL能利用到索引 数据库功能启用 查询重用 数据库参数设计 测试、试运行、上线、维护模型系统预运行 在备用系统上模型实际运行环境，加大压力进行相似测试 系统监控分析 应用系统表示：收集用户使用意见、系统存在问题 OS环境监控：实时监控CPU、内存、IO等，对比历史正常情况 数据库内部状态监控：系统表、视图、工具、锁的情况 日志分析：在数据库的日志、操作系统日志中找出异常","link":"/Database/SQL-DB/db_intro.html"},{"title":"HiveSQL","text":"命令行参数 -d/--define &lt;key=value&gt;：替换脚本中shell形式变量 --hivevar &lt;key=value&gt;：替换脚本中shell形式变量 结合hive脚本中设置shell变量使用 -h &lt;hostname&gt;：hive服务器 -p &lt;port&gt;：hive服务器端口 -database &lt;database&gt;：连接数据库 -e &lt;quoted-query-string&gt;：从命令行获取、执行hive脚本 -f &lt;filename&gt;：从文件获取、执行hive脚本 -i &lt;filename&gt;：初始化hive脚本 --hiveconf &lt;property=value&gt;：设置hive参数 -S/--slient：安静模式启动交互hive shell -v/--verbose：详细模式 -H/--help：帮助 辅助语句结果输出 INSERT INTO/OVERWRITE：查询结果追加/覆盖在hive表中 INSERT INTO/OVERWRITE [LOCAL] DIRECTORY：查询结果追加/ 覆盖本地/HDFS目录 有分区情况下，仅覆盖当前分区 内置函数聚合函数 collect_set()：配合group by合并、消除重复字段，返回 array concat_ws()：连接字符串 if(&lt;condition&gt;, &lt;true_value&gt;, &lt;false_value&gt;)：判断条件 size()：返回array长度 length()：返回字符串大小 配置相关语句文本分隔符 记录分隔：\\n 字段分隔：\\001（八进制）ASCII码1字符 Array、Struct、Map等集合中元素分隔：\\002ASCII码1字符 Map中键值对分隔：\\003ASCII码1字符 1234line terminated by `\\n`row format delimited fields terminated by `\\001`collection items terminated by `\\002`map keys terminated by `\\003` 空值 hive中空值一般有两种存储方式 NULL：底层存储NULL，查询显示为NULL \\N：底层存储\\N，查询显示为NULL，查询输出为\\N 空值查询：&lt;field&gt; is NULL NULL：也可&lt;field&gt; = 'NULL' \\N：也可&lt;field&gt; = '\\\\N'（转义） 底层存储设置参见表存储 空字符串不是空值，需要用&lt;field&gt; = ''查询 表存储配置分区属性serdeproperties 设置空值存储方式 1alter &lt;table&gt; SET serdeproperites('serialization.null.format' = '\\N')","link":"/Database/SQL-DB/hivesql.html"},{"title":"MSSQL Puzzles","text":"访问其他数据库服务器SQL默认阻止对组件Ad Hoc Distributed Queries的STATEMENT OpenRowSet/OpenDatasource的访问，需要使用sp_configure 启用Ad Hoc Distributed Queries 开启Ad Hoc Distributed Queries 1234exec sp_configure 'show advanced options',1reconfigureexec sp_configure 'Ad Hoc Distributed Queries',1reconfigure 关闭 1234exec sp_configure 'Ad Hoc Distributed Queries',0reconfigureexec sp_configure 'show advanced options',0reconfigure 特殊语法数据导入 mssql中换行符设置为\\n表示的是\\r\\n，即永远无法单独 指定\\n或者\\r，尽量使用ASCII码0xXX表示 1&gt; bulk insert tbl_name from /path/to/file with (FILEDTERMINATOR=&quot;|&quot;, ROWTERMINATOR=&quot;0x0a&quot;);","link":"/Database/SQL-DB/mssql_puzzles.html"},{"title":"Mysql&#x2F;Mariadb安装配置","text":"安装Mysql大部分系统常用源中包含mysql，直接使用自带的包管理工具安装 即可，对于源中无法找到mysql的系统可以访问官网获取 安装方法 1$ sudo zypper install mysql-server mysql-client CentOS7CentOS7的常用源中即不含mysql，安装mysql则需要添加mysql源， 同样在官网中找到添加方式： 下载的是RPM源rpm包 $ sudo yum localintall安装后即添加源 使用yum直接安装mysql，需要注意的是默认情况下只有最新版本 mysql源是enabled，其他版本的需要--enablerepo指定或者 /etc/yum.repo.d下修改文件 Mariadbmariadb和mysql大部分兼容，添加了一些新的特性，是mysql的一个 开源分支，由mysql的作者维护，避免mysql在被Oracle收购后闭源。 大部分情况下，mariadb可以完全看作是mysql 甚至在某些系统中，mariadb服务有别名mysql mariadb控制台命令也是mysql 配置配置文件 /etc/mysql/my.cnf:mysql主配置文件 mysql的此配置文件内包含有具体的配置 mariadb此文件中则不包含具体配置，而是导入配置文件12!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mariadb.cond.d/ ~/.my.cnf 一般不存在，需要自行建文件，注意需要设置文件权限， 只能root用户可写，否则mysql会忽略此配置文件 mysqld服务启动需要root权限，因此~目录下的配置文件 基本不可能影响mysql-server状态，即[server]下的配置 基本是无效的 数据位置 数据库存放数据位置：/var/lib/mysql/db_name/ Mysql-Client登陆@todo 一个问题，我安装的mariadb，默认的root用户无法在一般用户账户 登陆，必须sudo才能正常登陆 参数登陆1$ mysql -h host -P port -u user -p mysql不带参数启动则是默认cur_user_name@localhost:3306， 表示使用当前用户名作为用户名登陆，如果该用户设置密码，-p 参数不能省略 文件1$ mysql --defaults-file=file_name 文件内容格式类似于配置文件 12345[client]host=user=password=database=（可选） 注意 mysql中默认存在一个用户名为空的账户，只要在本地，可以 不用账户、密码登陆mysql，因为这个账号存在，使用新建用户 无法通过密码登陆，需要在123$ use mysql;$ delete from user where User=&quot;&quot;;$ flush privileges; Mysql交互命令Show信息类 SHOW DATABASES：列出MySQLServer数据库。 SHOW TABLES [FROM db_name]：列出数据库数据表。 SHOW TABLE STATUS [FROM db_name]：列出数据表及表状态信息。 SHOW COLUMNS FROM tbl_name [FROM db_name]：列出资料表字段 DESC tbl_name：同 SHOW FIELDS FROM tbl_name [FROM db_name] DESCRIBE tbl_name [col_name] SHOW FULL COLUMNS FROM tbl_name [FROM db_name]：列出字段及详情 SHOW FULL FIELDS FROM tbl_name [FROM db_name]：列出字段完整属性 SHOW INDEX FROM tbl_name [FROM db_name]：列出表索引 SHOW STATUS：列出 DB Server 状态 SHOW VARIABLES [like pattern]：列出 MySQL 系统环境变量 SHOW PROCESSLIST：列出执行命令。 SHOW GRANTS FOR user：列出某用户权限 User CREATE USER 'USER_NAME'@'ADDRESS' IDENTIFIED BY 'PASSWORD' IDENTIFIED BY PASSWORD这个语法好像已经被丢弃了 SET PASSWORD FOR 'USER_NAME'@'ADDRESS' = PASSWORD('NEW_PWD') SET PASSWORD = PASSWORD('NEW_PWD')：修改当前用户密码 GRANT PRIVILEGES ON DB_NAME.TBL_NAME TO 'USER_NAME'@'ADDRESS' [WITH GRANT OPTION] WITH GRANT OPTION：允许用户授权 REVOKE PRIVILIEGES ON DB_NAME.TBL_NAME TO 'USER_NAME'@'ADDRES%' DROP 'USER_NAME'@'ADDRESS' 说明 revoke和grant中的权限需要一致才能取消相应授权 grant select不能通过revoke all取消select grant all也不能通过revoke select取消select 特殊符号 %：所有address，也可以是ip部分，如：111.111.111.% 这个其实在sql语句中可以表示任意长度字符串 *：所有数据库、表 Priviledges 名称 权限 alter alter table alter routine alter or drop routines create create table create routine create routine create temporary table create temporary table create user create, drop, rename users and revoke all privilieges create view create view delete delete drop drop table execute run stored routines file select info outfile and load data infile index create index and drop index insert insert lock tables lock tables on tables for which select is granted process show full processlist reload use flush replicati on client ask where slave or master server are replicati on slave select select show databases show databases show view show view shutdown use mysqladmin shutdown super change master, kill, purge master logs, set global sql statements, use mysqladmin debug command, create an extra connection even reach the maximum amount| |update|update| |usage|connect without any specific priviliege| 执行Sql脚本 shell内执行 1mysql -h host -D db_name -u user -p &lt; file_name.sql; mysql命令行执行 1source file_name.sql; 导入、导出数据导入数据 shell内 mysql命令行内 12345load data [local] infile '/path/to/file' into table tbl_namefields terminated by 'sep_char'optionally enclosed by 'closure_char'escaped by 'esc_char'lines terminated by `\\r\\n`; 若/path/to/file不是绝对路径，则被认为是相对于当前 数据库存储数据目录的相对路径，而不是当前目录 关键字local表示从客户端主机导入数据，否则从服务器 导入数据 导出数据 shell内 mysql命令行内 注意：远程登陆mysql时，两种方式导出数据不同，shell导出 数据可以导出至client，而mysql命令行内导出至server Mysql-Server数据库字符编码方式查看 只查看数据库编码方式 1show variables like &quot;character_set_database; 查看数据库相关的编码方式 1show variables like &quot;character%&quot;; |variable_name|value| |——-|——-| |character_set_client|latin1| |character_set_connection|latin1| |character_set_database|latin1| |character_set_filesystem|binary| |character_set_results|latin1| |character_set_server|latin1| |character_set_system|utf8| |character_sets_dir|/usr/share/mysql/charsets/| 另一种查询数据库编码方式 1show variables like &quot;collation%&quot;; |Variable_name|Value| |——-|——-| |collation_connection|utf8mb4_general_ci| |collation_database|utf8mb4_general_ci| |collation_server|utf8mb4_general_ci| 相关变量说明 character_set_client：客户端编码方式 character_set_connection：建立连接是所用编码 character_set_database：数据库编码 character_set_results：结果集编码 character_set_server：服务器编码 保证以上编码方式相同则不会出现乱码问题，还需要注意其他连接 数据库的方式不一定同此编码方式，可能需要额外指定 修改编码方式修改数据库默认编码方式修改mysql配置文件（/etc/mysql/my.cnf） #todo mysql配置文件的优先级 utf8mb4意义 12345[client]default-character-set=utf8mb4[mysqld]default-character-set=utf8mb4init_connect=&quot;SET NAMES utf8mb4&quot; 重启mysql即可 修改单个数据库 创建时1create database db_name character set utf8 collate utf8_general_ci; 1create database if not exists db_name defualt charater set utf8; 脚本、窗口1set names gbk; 只修改character_set_client、character_set_connection、 character_set_results编码方式，且只对当前窗口、脚本有效， 不影响数据库底层编码方式","link":"/Database/SQL-DB/mysql.html"},{"title":"Postgre SQL笔记","text":"安装 交互式客户端：postgresql 服务器：postgres-server 额外功能：postgresql-contrib 开发工具：postgresql-devel OpenSuSe12$ sudo zypper in postgresql postgresql-server \\ postgresql-contrib postgresql-devel CentOS12$ sudo yum install postgresql postgresql-server \\ postgresql-contrib postgresql-devel 其他版本 从中选择合适版本下载：Postgres Yum repositories 1$ wget https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm 安装下载的RPM（依赖EPEL repo） 1$ sudo yum install pgdg-centos96-9.6-3.noarch.rpm 更新Yum、安装指定PG版本 12$ sudo yum update$ sudo yum install postgresql96-sever postgresql96-contrib 安装的PG带有版本后缀，初始化、启动时注意 配置 postgres安装完成后，默认创建Linux用户 用户密码为空，要为其设置密码以切换到其12$ sudo passwd postgres$ su - postgres 用户目录默认是/var/lib/pgsql 很多命令可以切换到用户postgres直接执行 初始化数据库簇后，默认创建数据库角色postgres、数据库 postgres 初始化 创建新PostgreSQL数据库簇 123$ sudo postgresql-setup initdb # 或$ sudo inidb -D /var/lib/pgsql/data 默认数据库存储路径为/var/lib/pgsql/data 开启PG密码认证：修改host-based authentication设置 1234# /var/lib/pgsql/data/pg_hba.conf# TYPE DATABASE USER ADDRESS MEHTODhost all all 127.0.0.1/32 md5host all all ::1/128 md5 替换默认ident为md5开启密码认证 修改之后需要重启PG 修改postgres用户密码，以可以通过密码作为postgres连接 数据库 123$ su - postgres$ psql -d template1 -c &quot;ALTER USER postgres with password '&lt;passwd&gt;'&quot; # 也可以在数据库prompt中执行 启动数据库 作为服务：start、enablePG 12$ sudo systemctl start postgresql$ sudo systemctl enable postgresql 作为普通程序启动：pg_ctl 12$ su - postgres$ pg_ctl start -D /var/lib/pgsql/data RolesPG使用概念roles处理认证、权限问题 角色相较于区分明显的用户、组概念更加灵活 create user和create role几乎完全相同 create user：创建角色默认带LOGIN属性 create role：创建角色默认不带LOGIN属性 权限 SUPERUSER/NOSUPERUSER：数据库超级用户 CREATEDB/NOCREATEDB：创建数据库 CREATEUSER/NOCREATEUSER CREATEROLE/NOCREATEROLE：创建、删除普通用户角色 INHERIT/INHERIT：角色可以继承所属用户组权限 LOGIN/NONLOGIN：作连接数据库初始角色名 REPLICATION/NOREPLICATION：流复制时用到 CONNECTION LIMIT connlimit [ENCRYPTED/UNENCRYPTED]PASSWORD '&lt;passwd&gt;' VALID UNTIL '&lt;timestamp&gt;' IN ROLE &lt;role_name&gt;[, ...]：角色所属用户组 IN GROUP &lt;role_name&gt;[, ...] ROLE &lt;role_name&gt;[, ...] ADMIN &lt;role_name&gt;[, ...] USER &lt;role_name&gt;[, ...] SYSID uid 角色赋权12345psql&gt; create role/user &lt;name&gt; [[with] &lt;option&gt; [...]]; # 创建角色时直接赋权psql&gt; alter role/user &lt;name&gt; [[with] &lt;option&gt; [...]];psql&gt; grant connect on database &lt;db_name&gt; to &lt;name&gt;; # 修改已创建角色权限 组赋权 把多个角色归为组，通过给组赋权、撤销权限实现权限管理 PG中角色赋权是通过inherit方式实现的 1234567psql&gt; create role father login createdb createrole; # 创建组角色、赋权psql&gt; create role son1 inherit;psql&gt; grant father to son1; # 创建有`inherit`权限的用户、赋权psql&gt; create role son2 inherit in role father; # 创建用户时直接赋组权 认证方式Peer Authenticationpeer：从内核中获取操作系统中用户名，作为数据库角色名连接 默认连接同名数据库 信任Linux用户身份（认证），不询问密码 即使-W强制输入密码，也不会检查密码正确性 只有local连接支持此方法 Trust Authenticationtrust：允许任何数据库角色名的连接 信任任何连接、不询问密码 只应该在操作系统层面上能提供足够保护下情况下使用 文件系统权限：限制对Linux域套接字文件的访问 适合单用户、本地连接 数据库、用户权限限制仍然存在 Ident Authenticationident：从ident服务器中获取操作系统中用户名，用于连接数据库 仅在TCP/IP连接情况下支持 若被指定给local连接，将使用peer认证 数据库服务器向客户端ident服务器询问“连接数据库的”用户， 据此判断连 此流程依赖于客户端完整性，若客户端机器不可信，则 攻击者可以在113端口执行任何程序返回任何用户名 故此认证方法只适合封闭网络，所以客户端机器都被严格 控制 有些ident服务器开启非标准选项导致返回的加密用户名， 此选项应该关闭 基本每个类Unix操作系统都带有ident服务器，用于监听 113端口TCP 涉及配置 map：运行系统、数据库用户名之间映射 Password AuthenticationPassword认证：基于密码的认证方式 password：明文传输密码验证 md5：MD5-hashed传输密码o md5可以避免密码嗅探攻击 password总应该尽量避免使用 启用db_user_namespace特性时无法使用md5 SSL加密连接下password也能安全使用 每个数据库的密码存储在pg_authid系统表中 若用户没有设置密码，则存储的密码为null，密码验证 也总是失败 使用create user、alter role等SQL语句修改密码 GSSAPI AuthenticationGSSAPI：定义在RFC 2743中的安全认证产业界标准协议 GSSAPI为支持其的系统自动提供认证 认证本身是安全的，但是通过数据库连接的数据默认没有 加密，除非使用SSL PG中GSSAPI需要编译时启用支持 SSPI Authenticationnegotiate：windows的安全认证技术 PG将尽可能使用Kerberos，并自动回滚为NTLM 仅服务器、客户端均在windows下或GSSAPI可用的情况下才能 工作 使用Kerberos情况下，SSPI、GSSAPI工作方式相同 涉及配置 include_realm map krb_realm Kerberos AuthenticationKerberos：适合公共网络上分布式计算的产业界标准安全认证系统 Kerberos提供不加密的语句、数据安全认证，若需要加密则使用 SSL PG支持Kerberos第5版，需要在build时开启Kerberos支持 涉及配置 map include_realm krb_realm krb_server_hostname LDAP AuthenticationLDAP：类似password，只是使用LDAP作为密码认证方法 涉及配置 ldapserver ldapport ldaptls ldapprefix ldapsuffix ldapbasedn ldapbinddn ldapbindpasswd ldapsearchattribute RADIUS AuthenticationRADIUS：类似password，只是使用RADIUS作为密码认证方法 涉及配置 radiusserver radiussecret radiusport radiusidentifier Certificate AuthenticationCertificate：使用SSL客户多证书进行认证 所以只在SSL连接中可用 服务器要求客户端提供有效证书，不会向客户端传递密码prompt cn属性（common name）将回和目标数据库的用户名 比较 可通过名称映射允许cn属性和数据库用户名不同 涉及配置 map：允许系统、数据库用户名之间映射 PAM AuthenticationPAM：类似password，只是使用 PAM(Pluggable Anthentication Modules)作为密码认证机制 涉及配置 parmservice：PAM服务名 默认postgresql pg_ctlpg_ctl：用于控制PostgreSQL服务器的工具，此工具基本需要在 postgres用户下才能使用 查看状态：$ pg_ctl status -D /var/lib/pgsql/data psqlShell连接数据库1$ psql [-h &lt;host&gt;] [-p &lt;port&gt;] [-U &lt;user_name&gt;] [[-d] &lt;db_name&gt;] -h：缺省为local类型连接本地数据库 local、host连接类型对应不同认证方式 -h localhost和缺省对应不同hba.conf条目 -p：缺省端口5432 -U/--user_name=：缺省linux用户名 [-d]/--database=：当前linux用户名 -W：密码，peer、trust模式下无价值 Shell命令 postgres不仅仅提供psql交互环境作为shell命令，还提供可以 直接在shell中运行的数据库命令 当然前提是当前linux登陆用户在数据库中存在、有权限 1234$ createdb &lt;db_name&gt; [-O &lt;user_name&gt;] # 创建数据库，设置所有权为`user_name`$ dropdb &lt;db_name&gt; # 删除数据库 元命令元命令：反斜杠命令，\\开头，由psql自己处理 \\后：跟命令动词、参数，其间使用空白字符分割 冒号:：不在引号中的冒号开头的参数会被当作psql变量 反点号：参数内容被当作命令传给shell， 输出（除去换行符）作为参数值 单引号'：参数包含空白时需用单引号包o，其中包含的参数 的内容会进行类C的替换 \\n（换行）、\\digits（八进制） 包含单引号需要使用反斜杠转义 双引号\\”&lt;\\code&gt; 遵循SQL语法规则，双引号保护字符不被强制转换为 小写，且允许其中使用空白 双引号内的双引号使用双双引号&quot;&quot;转义 帮助 \\? [&lt;commands&gt;]：元命令帮助 &lt;options&gt;：psql命令行选项帮助 &lt;variables&gt;：特殊变量帮助 \\h [&lt;clauses&gt;]：SQL命令语法帮助（*表示全部） 展示信息 \\du：查看用户权限 \\c &lt;db_name&gt; &lt;name&gt;：以身份name访问数据库db_name \\l[ist]：查看数据库 \\dt：展示当前数据库中表 变量 \\set foo bar：设置变量 可以像php设置“变量 变量”：\\set :foo bar \\unset foo：重置变量 数据库变量内部变量特殊变量特殊变量：一些选项设置，在运行时可通过改变变量的值、应用的 表现状态改变其，不推荐改变这些变量的用途 AUTOCOMMIT：缺省为on，每个SQL命令完成后自行提交，此时 需要输出BEGIN、START TRANSACTION命令推迟提交 DBNAMW：当前所连接数据库 ENCODING：客户端字符集编码 详情查询手册 环境变量 PGDATA：指定数据库簇（存放数据）目录 1$export PGDATA=/var/lib/pgsql/data 默认/var/lib/pgsql/data -D命令行参数指定","link":"/Database/SQL-DB/psql.html"},{"title":"SQL语法","text":"基本操作12345678910111213141516SELECT &lt;field&gt;, DISTINCT &lt;field&gt;INTO &lt;new_tbl&gt; [IN &lt;other_db&gt;]FROM &lt;tbl&gt;WHERE &lt;field&gt; &lt;OP&gt; &lt;value&gt;/&lt;field&gt;ORDER BY &lt;field&gt; [ASC/DESC];INSERT INTO &lt;tbl&gt;[&lt;field&gt;]VALUES (&lt;value&gt;);UPDATE &lt;tbl&gt;SET &lt;field&gt; = &lt;value&gt;WHERE &lt;field&gt; &lt;OP&gt; &lt;value&gt;/&lt;field&gt;;DELETEFROM &lt;tbl&gt;WHERE &lt;field&gt; &lt;OP&gt; &lt;value&gt;/&lt;field&gt;; 数据库、表、索引、视图创建123456789101112131415161718!-- 创建数据库CREATE DATABASE &lt;db_name&gt;;!-- 创建表CREATE TABLE &lt;tbl&gt;( &lt;field&gt; &lt;dtype&gt;, &lt;field&gt; &lt;dtype&gt; &lt;CSTRT&gt;, !-- MSSQL、ORACLE &lt;CSTRT&gt; (&lt;field&gt;,), !-- MySQL CONSTRAINT [&lt;cstrt_name&gt;] &lt;cstrt&gt; (&lt;field&gt;,) !-- common)!-- 创建索引CREATE INDEX &lt;index_name&gt;ON &lt;tbl&gt; (&lt;field&gt;);!-- 创建视图CREATE VIEW &lt;view_name&gt; AS&lt;select_expr&gt;; 自增字段12345678910!-- MSSQL&lt;field&gt; &lt;dtype&gt; IDENTITY!-- MySQL&lt;field&gt; &lt;dtype&gt; AUTO_INCREMENT!-- ORACLE：创建自增序列，调用`.nextval`方法获取下个自增值CREATE SEQUENCE &lt;seq&gt;MINVALUE &lt;min&gt;START WITH &lt;value&gt;INCREMENT BY &lt;step&gt;CACHE &lt;cache&gt; !-- 提高性能 丢弃123456789101112131415161718!-- 丢弃索引!-- MSSQLDROP INDEX &lt;tbl&gt;.&lt;index_name&gt;;!-- ORACLEDROP INDEX &lt;index_name&gt;;!-- MySQLALTER TABLE &lt;tbl&gt;DROP INDEX &lt;index_name&gt;;!-- 丢弃表/数据DROP TABLE &lt;tbl&gt;;TRUNCATE TABLE &lt;tbl&gt;;!-- 丢弃数据库DROP DATABASE &lt;db_name&gt;;!-- 丢弃视图DROP VIEW &lt;view&gt;; 修改表1234567891011!-- 添加列ALTER TABLE &lt;tbl&gt;ADD &lt;field&gt; &lt;dtype&gt;;!-- 删除列ALTER TABLE &lt;tbl&gt;DROP COLUMN &lt;field&gt;;!-- 修改类型ALTER TABLE &lt;tbl&gt;ALTER COLUMN &lt;field&gt; &lt;dtype&gt;; 关键字TOP MSSQL：SELECT TOP &lt;num&gt;/&lt;num&gt; PERCENT * MYSQL：LIMIT &lt;num&gt; ORACLE：WHERE ROWNUM &lt;= &lt;num&gt; Alias AS：指定行、列别名 Join [INNER] JOIN LEFT JOIN RIGHT JOIN FULL JOIN Union UNION：合并SELECT结果集 要求结果集中列数量、类型必须相同 NULL IS [NOT] NULL：比较是否为NULL值 比较符无法测试NULL值 符号运算符 =：有些方言可以使用== &lt;&gt;：有些方言可以使用!= &gt; &lt; &gt;= &lt;= BETWEEN &lt;value&gt; AND &lt;value&gt; [NOT] IN (&lt;value&gt;) [NOT] LIKE &lt;pattern&gt; %：匹配0个、多个字符 _：匹配一个字符 [&lt;char&gt;]：字符列中任意字符 ^[&lt;char&gt;]/[!&lt;char&gt;]：非字符列中任意字符 逻辑运算 AND OR 符号 '：SQL中使用单引号包括文本值 大部分方言也支持&quot;双引号 数据类型MySQL TEXT类型 描述 CHAR([&lt;size&gt;]) VARCHAR([&lt;size&gt;]) TINYTEXT LONGTEXT MEDIUMITEXT BLOB MEDIUMBLOB LONGBLOB ENUM(&lt;val_list&gt;) SET NUMBER类型 描述 TINYINT([&lt;size&gt;]) SMALLINT([&lt;size&gt;]) MEDIUMINT([&lt;size&gt;]) INT([&lt;size&gt;]) BIGINT([&lt;size&gt;]) FLOAT([&lt;size&gt;]) DOUBLE([&lt;size&gt;]) DECIMAL([&lt;size&gt;]) DATE类型 描述 DATE() DATETIME() TIMSTAMP() TIME() YEAR() MSSQL ASCII类型 描述 CHAR([&lt;size&gt;]) VARCHAR([&lt;size&gt;]) TEXT UNICODE类型 描述 CHAR([&lt;size&gt;]) VARCHAR([&lt;size&gt;]) text BINARY类型 描述 bit binary([&lt;n&gt;]) varbinary([&lt;n&gt;]) image NUMBER类型 描述 TINYINT SMALLINT MEDIUMINT INT BIGINT DECIMAL(p, s) FLOAT([&lt;n&gt;]) REAL SMALLMONEY MONEY DATE类型 描述 DATETIME DATETIME2 SMALLDATETIME DATE TIME DATETIMEOFFSET TIMESTAMP 约束 建表时添加约束 MSSQL、ORACLE：可直接在字段声明后添加约束 MySQL：需独立指定约束 向已有表添加约束 可以添加匿名、具名约束 MSSQL、ORACLE：有COLUMN关键字 删除约束 MySQL：使用约束关键字指定 MSSQL、ORACLE：使用CONSTRAINT关键字指定 NOT NULL1&lt;field&gt; &lt;dtype&gt; NOT NULL DEFAULTDEFAULT 123456789101112131415161718!-- 建表&lt;field&gt; &lt;dtype&gt; DEFAULT &lt;value&gt;!-- 已有表添加!-- MySQLALTER TABLE &lt;tbl&gt;ALTER &lt;field&gt; SET DEFAULT &lt;value&gt;;!-- MSSQL、ORACLEALTER TABLE &lt;tbl&gt;ALTER COLUMN &lt;field&gt; SET DEFAULT &lt;value&gt;;!-- 删除!-- MySQLALTER TABLE &lt;tbl&gt;ALTER &lt;field&gt; DROP DEFAULT;!-- MSSQL、ORACLEALTER TABLE &lt;tbl&gt;ALTER COLUMN &lt;field&gt; DROP DEFAULT; UNIQUEUNIQUE 12345678910111213141516171819202122!-- 建表!-- MySQL、MSSQL、ORACLECONSTRAINT [&lt;cstrt_name&gt;] UNIQUE (&lt;field&gt;,)!-- MySQLUNIQUE [KEY] [&lt;cstrt_name&gt;] (&lt;field&gt;)!-- MSSQL、ORACLE&lt;field&gt; &lt;dtype&gt; UNIQUE!-- 已有表添加!-- MySQL、MSSQL、ORACLEALTER TABLE &lt;tbl&gt;ADD UNIQUE(&lt;field&gt;);ALTER TABLE &lt;tbl&gt;ADD CONSTRAINT &lt;cstrt_name&gt; UNIQUE(&lt;field&gt;,);!-- 删除!-- MySQLALTER TABLE &lt;tbl&gt;DROP INDEX &lt;cstrt_name&gt;;!-- MSSQL、ORACLEALTER TABlE &lt;tbl&gt;DROP CONSTRAINT &lt;cstrt_name&gt;; PRIMARY KEYPRIMARY KEY 1234567891011121314151617181920212223!-- 建表!-- MySQL、MSSQL、ORACLECONSTRAINT [&lt;cstrt_name&gt;] PRIMARY KEY (&lt;field&gt;,)!-- MYSQLPRIMARY KEY (&lt;field&gt;,)!-- MSSQL、ORACLE&lt;field&gt; &lt;dtype&gt; PRIMARY KEY!-- 已有表添加!-- MySQL、MSSQL、ORACLEALTER TABLE &lt;tbl&gt;ADD PRIMARY KEY (&lt;field&gt;,);ALTER TABLE &lt;tbl&gt;ADD CONSTRAINT &lt;cstrt_name&gt; PRIMARY KEY (&lt;field&gt;,);!-- 删除!-- MySQLALTER TABLE &lt;tbl&gt;DROP PRIMARY KEY;!-- MSSQL、ORACLEALTER TABLE &lt;tbl&gt;DROP CONSTRAINT &lt;cstrt_name&gt;; FOREIGN KEYFOREIGN KEY 12345678910111213141516171819202122232425262728!-- 建表!-- MySQL、MSSQL、ORACLECONSTRAINT [&lt;cstrt_name&gt;] FOREIGN KEY (&lt;field&gt;,)REFERENCES &lt;tbl&gt;(&lt;field&gt;,)!-- MYSQLFOREIGN KEY (&lt;field&gt;,)REFERENCES &lt;tbl&gt;(&lt;field&gt;,)!-- MSSQL、ORACLE&lt;field&gt; &lt;dtype&gt; FOREIGN KEYREFERENCES &lt;tbl&gt;(&lt;field&gt;,)!-- 已有表添加!-- MySQL、MSSQL、ORACLEALTER TABLE &lt;tbl&gt;ADD FOREIGN KEY (&lt;field&gt;,)REFERENCES &lt;tbl&gt;(&lt;field&gt;,);ALTER TABLE &lt;tbl&gt;ADD CONSTRAINT &lt;cstrt_name&gt; FOREIGN KEY (&lt;field&gt;,)REFERENCES &lt;tbl&gt;(&lt;field&gt;);!-- 删除!- MySQLALTER TABLE &lt;tbl&gt;DROP FOREIGN KEY &lt;cstrt_name&gt;;!-- MSSQL、ORACLEALTER TABLE &lt;tbl&gt;DROP CONSTRAINT &lt;cstrt_name&gt;; CHECKCHECK 12345678910111213141516171819202122!-- 建表!-- MySQL、MSSQL、ORACLECONSTRAINT [&lt;cstrt_name&gt;] CHECK(&lt;condition&gt;)!-- MySQLCHECK (condition)!-- MSSQL、ORACLE&lt;field&gt; &lt;dtype&gt; CHECK(&lt;condition&gt;)!-- 已有表添加!-- MySQL、MSSQL、ORACLEALTER TABLE &lt;tbl&gt;ADD CHECK (condition);ALTER TABLE &lt;tbl&gt;ADD CONSTRAINT &lt;cstrt_name&gt; CHECK (condition);!-- 删除!-- MySQLALTER TABLE &lt;tbl&gt;DROP CHECK &lt;cstrt_name&gt;;!-- MSSQL、ORACLEALTER TABLE &lt;tbl&gt;DROP CONSTRAINT &lt;cstrt_name&gt;; 内建函数Date MySQL NOW() CURDATE() CURTIME() DATE() EXTRACT() DATE_ADD() DATE_SUB() DATE_DIFF() DATE_FORMAT() MSSQL GETDATE() DATEPART() DATEADD() DATEDIFF() CONVERT() NULL MSSQL ISNULL(&lt;field&gt;, &lt;replacement&gt;) ORACLE NVL(&lt;field&gt;, &lt;repalcement&gt;) MySQL IFNULL(&lt;field&gt;, &lt;replacement&gt;) COALESCE(&lt;field&gt;, &lt;replacement&gt;) Aggregate聚集函数Scalar","link":"/Database/SQL-DB/sql_grammer.html"},{"title":"SQL数据库Puzzles","text":"数据迁移直接查询、插入同库12insert into dst_tb select * from src_tb;insert into dst_tb(field1, field2, ...) select (field_a, field_b, ...) from src_tb; 异库、同服务器123456insert into db1.dst_db select * from db2.src_db; # 插入已有表create table db1.dst_tb as select * from db2.src_tb; # 创建表并插入数据rename table src_db.src_tb to dst_db.dst_tb; # 重命名迁移完整表 异服务器文件中介、跨实例.sql12345$ mysqldump [-u user] -p --single-transaction [--where=&quot;&quot;] src_db src_tb &gt; src_db.src_tb.sql # 导入数据 # 加上`-d`仅导出表结构$ mysql [-u user] -p dst_db &lt; src_db.src_tb.sql # 导入数据 1source src_db.src_tb.sql; .csvsecure_file_privload data infile和into outfile需要mysql开启 secure_file_priv选项，可以通过查看 1show global variables like `%secure%`; mysql默认值NULL不允许执行，需要更改配置文件 12[mysqld]secure_file_priv='' 本机Server1234567891011121314select * from src_tb into outfile file_name.csv fields terminated by ',' optionally enclosed by '&quot;' escaped by '&quot;' lines terminated by '\\r\\n'; # 导出至`.csv`load data infile file_name.csv [replace] into table dst_tb(field1, field2, @dummy...) fields terminated by ',' optionally enclosed by '&quot;' escaped by '&quot;' lines terminated by '\\r\\n'; # 从`.csv`数据导入 # 表结构不同时可以设置对应字段，多余字段`@dummy`表示丢弃 异机Server1234$ mysql -h host -u user -p src_db -N -e &quot;select * from src_tb;&quot; &gt; file_name.csv # 只能通过*shell*查询并导出至文件 # 需要`file`权限 # `-N`：skip column names 12load data local infile filename.csv; # 指定`local`则从*client*读取文件，否则从*server*读取 大表分块迁移 容易分块的字段 自增id 时间 注意","link":"/Database/SQL-DB/sql_puzzles.html"},{"title":"Tabu Seach","text":"禁忌搜索","link":"/Algorithm/Heuristic/tabu_search.html"},{"title":"Envolutionary Algorithm","text":"进化算法进化算法： 后设启发式算法：适合多种最优化问题，但不保证找到全局最优 Genetic Algorithm遗传算法：模拟自然界生物进化过程，采用人工进化的方式对目标 空间进行搜索 本质是高效、并行、全局搜索方法 能在搜索过程中自动获取、积累有关搜索空间的知识，并自适应 的控制搜索过程以求的最佳解 思想 将问题域中可能解看作是染色体，将其编码为符号串的形式 对染色体群体反复进行基于遗传学的操作：选择、交叉、变异 根据预定目标适应度函数对每个个体进行评价，不断得到更优 群体，从中全局并行搜索得到优化群体中最优个体 实体 population：群体，GA的遗传搜索空间 individual：个体，搜索空间中可能解 chromosome：染色体，个体特征代表 由若干段基因组成 GA中基本操作对象 gene：基因 染色体片段 fitness：适应度，个体对环境的适应程度 基本操作 selection：选择，根据个体适应度在群体中按照一定概率 选择个体作为父本 适应度大个体被选择概率高 体现了适者生存、优胜劣汰的进化规则 crossover：交叉，将父本个体按照一定概率随机交换基因 形成新个体 mutate：变异，按照一定概率随机改变某个体基因值 串编码方式 把问题的各种参数用二进串进行编码构成子串 把子串拼接成染色体 串长度、编码方式对算法收敛影响极大 二进制编码方式二进制法：使用二进制染色体表示所有特征 优点 编码、解码操作简单 交叉、变异等遗传操作便于实现 符合最小字符集编码原则 利于模式定理对算法理论分析 缺点 连续函数离散化存在误差，染色体长度短时达不到精度 要求，较长时解码难度大、搜索空间增大 对连续函数优化问题，随机性使得其局部搜索能力较差， 接近最优值时不稳定 浮点编码浮点法：个体的每个基因值用某一范围内的一个浮点数表示 必须保证基因之在给定区间限制范围内 交叉、变异等遗传算子结果也必须在限制范围内 优点 适用于在遗传算法中表示范围较大的数 精度较高 便于较大空间的遗传搜索 改善了遗传算法的计算复杂性，提高了运算效率 便于遗传算法与经典优化方法的混合使用 便于设计针对问题的专门知识的知识型遗传算子 便于处理复杂的决策变量约束条件 符号编码法符号法：个体染色体编码串基因值取自无意义字符集 优点 符合有意义积木块编码原则 方便利用所求解问题的专门知识 访问GA和相关近似算法的混合使用 Fitness Function适应度/对象函数 一般可以把问题模型函数作为对象函数 过程 解码个体，得到个体表现型 由个体表现型计算个体目标函数值 根据最优化问题类型，由目标函数值按一定转换规则求出 个体适应度 操作选择函数 Roulette Wheel Selection：轮盘赌选择，个体进入下一代 概率为其适应度与整个种群适应度之比 放回式随机抽样 选择误差较大 Stochastic Tournament：随机竞争选择，每次按轮盘赌选择 一对个体，选择适应度较高者，重复直到选满 最佳保留选择：按轮盘赌选择方法执行遗传算法选择操作，然后 t将当前群体中适应度最高的个体结构完整地复制到下一代群体中 Excepted Value Selection：无回放随机选择，根据每个个体 在下一代群体中的生存期望来进行随机选择运算 计算群体中每个个体在下一代群体中的生存期望数目N 若体被选中参与交叉运算，则它在下一代中的生存期望数目 减去0.5，否则在下一代中的生存期望数目减去1.0 随着选择过程的进行，当个体的生存期望数目小于0时，则 该个体就不再有机会被选中。 确定式选择：按照一种确定的方式来进行选择操作 计算群体中各个体在下一代群体中的期望生存数目N 用N的整数部分确定个体在下一代群体中的生存数目 用N的小数部分对个体进行降序排列，顺序取前M个个体加入 到下一代群体 完全确定出下一代群体中Ｍ个个体 无回放余数随机选择 可确保适应度比平均适应度大的一些个体能够被遗传到 下一代群体中 选择误差比较小 均匀排序：对群体中的所有个体按期适应度大小进行排序，基于 这个排序来分配各个个体被选中的概率 最佳保存策略：当前群体中适应度最高的个体不参与交叉运算 和变异运算，而是用它来代替掉本代群体中经过交叉、变异等 操作后所产生的适应度最低的个体 随机联赛选择：每次选取几个个体中适应度最高个体遗传到 下一代群体中。 排挤选择：新生成的子代将代替或排挤相似的旧父代个体，提高 群体的多样性 Cross Over One-point Crossover：单点交叉，在个体编码串中只随机 设置一个交叉点，然后再该点相互交换两个配对个体的部分 染色体 Two-point Crossover：两点交叉，在个体编码串中随机设置 两个交叉点，然后再进行部分基因交换 Multi-point Crossover：多点交叉 Uniform Crossover：均匀交叉/一致交叉，两个配对个体的 每个基因座上的基因都以相同的交叉概率进行交换，从而形成 两个新个体 Arithmetic Crossover：算术交叉，由两个个体的线性组合 而产生出两个新的个体 操作对象一般是由浮点数编码表示的个体 Mutation Simple Mutation：基本位变异，对个体编码串中以变异概率 、随机指定的某一位或某几位仅因座上的值做变异运算 Uniform Mutation：均匀变异，用符合某一范围内均匀分布 的随机数，以较小的概率来替换个体编码串中各个基因座上原有 基因值 适用于在算法的初级运行阶段 Boundary Mutation：边界变异，随机的取基因座上的两个 对应边界基因值之一去替代原有基因值 适用于最优点位于或接近于可行解的边界时的一类问题 非均匀变异：对原有的基因值做一随机扰动，以扰动后的结果 作为变异后的新基因值 对每个基因值都以相同的概率进行变异运算之后，相当于 整个解向量在解空间中作了一次轻微的变动 高斯近似变异：进行变异操作时用符号均值为P、方差$P^2$的 正态分布的一个随机数来替换原有的基因值 GA超参设置 群体大小$n$：过小难以求出最优解，过大难收敛，一般取 $n = 30 ~ 160$ 交叉概率$P_c$：太小难以前向搜索，太大容易破坏高适应 值结构，一般取$P_c = 0.25 ~ 0.75$ 变异概率$P_m$：太小难以产生新结构，太大则变为单纯 随机搜索，一般取$P_m = 0.01 ~ 0.2$ 算法 随机初始化种群 估初始种群：为种群每个个体计算适应值、排序 若没有达到预定演化数，则继续，否则结束算法 选择父体 杂交：得到新个体 变异：对新个体变异 计算新个体适应值，把适应值排名插入种群，淘汰最后个体 重复3 Differential Evolution差分进化算法： Particle Swarm Optimization粒子群/微粒群算法：","link":"/Algorithm/Heuristic/envolutional_algorithms.html"},{"title":"Simulated Annealing Algorithm","text":"Simulated Annealing Algorithm模拟退火算法 来源于固体退火原理 将固体加热至充分高，固体内部粒子随之变为无序状，内能 增加 再让固体徐徐冷却，内部例子随之有序 到达常温状态时，内能减为最小 用固体退火模拟组合优化问题 目标函数值f视为内能E，控制参数t视为温度T 由初始解i、控制参数初值t开始，对当前解重复 产生新解-&gt;计算目标函数增量-&gt;接受或舍弃的迭代，并 逐步衰减t值 算法终止时，当前解即为所得近似最优解 退火过程由Cooling Schedule控制，包括控制参数初值t、衰减 因子$\\Delta t$、迭代次数L、停止条件S 算法 初始化：初始温度$t_0$（充分大）、初始解$i_0$、迭代次数L 产生新解$i_1$，计算目标函数增量$\\Delta f=f(i_1)-f(i)$ 若$\\Delta f&lt;0$则接受$i_1$作为新解，否则以概率 $\\exp^{\\Delta f/f(i_0)}$接受$i_1$作为新解 若满足终止条件则算法结束 若干次新解都不被接受：当前解“能量”低 迭代次数达到上限 否则减小温度为$t_1$继续迭代 说明 解生成器：应该可以通过简单变换即可产生新解，便于减少每次 迭代计算新解耗时 比如对新解全部、部分元素进行置换、互换等 需要注意的是，这决定了新解的领域结构，对冷却的进度表 选取有影响 新解是否被接受采用的是Metropolis准则 模拟退火算法性质 与初值无关 具有渐进收敛性 具有并行性 在理论上被证明是以概率1收敛于全局最优解的算法 能够跳出局部最优解 应用 VLSI：目前退火模拟算法的应用实例，几乎可以完成所有VLSI 设计工作 神经网络：模拟退火算法能够跳出局部最优解 图像处理：用于进行图像恢复工作 其他问题：还可以用于其他各种组合优化问题","link":"/Algorithm/Heuristic/simulated_anealing.html"},{"title":"图衍生","text":"度Laplacian矩阵$L=D-A$：Laplacian矩阵，其中 $A$：邻接矩阵 $D$：度矩阵（对角线为各个顶点度） 性质 若$c$为图中各个节点权重，则$c^T L C$为各个节点与其 邻接节点差值平方和 展开即可证明 边数量Multigraph多重图：含有平行边，即顶点之间边数大于1 允许顶点通过边和自己相连 边权欧几里得类型加权图欧几里得类型加权图：权重满足欧式几何条件 三角不等式：任意3点$i,j,k, d{ij} \\leqslant d{ik}+d{kj} 对称性：任意两个点$i,j, d_{ij}=d{ji}$ 连通性Transitive closure传递闭包：表示所有节点两两直接连通性的n阶布尔矩阵T $T={t{ij}}$，若节点i到节点j直接存在有效（长度&gt;0）有向 路径，则$t{ij}=1$，否则为0 Hamiltonian Circuit哈密顿回路：对图每个顶点只穿过一次的回路 可以理解为：n+1个相邻顶点的一个排列，其中首尾顶点相同， 而其余顶点互不相同 因为是回路，可以不失一般性的假定回路开始、结束于相同 顶点，这样不影响回路性质 Eular Circuit欧拉回路：将给定图每条边都只遍历一次的回路 无向图：当且仅当连通多重图的每个顶点连通度都为偶数时， 才具有欧拉回路 有向图：当且仅当图中所有顶点是否出度、入度相等时，才存在 欧拉回路 在$\\O(n^)$内解决问题 State-Space Graph状态空间图：把问题化简为标准图问题 顶点：表示问题可能状态 边：表示状态之间的可能转换 原问题转换为求初始状态到目标状态顶点路径问题","link":"/Algorithm/Data-Structure/graph_derived.html"},{"title":"有向图衍生","text":"Directed Acycline GraphDAG：有向无环图 描述含有公共子式的表达式的有效工具 可以实现对相同子式的共享，节省存储空间 描述一项工程、系统进行过程的有效工具 拓扑排序：工程能否顺利进行 关键活动：整个工程完成必须的最短时间 Dependence Analysis依赖性分析：由有向图判断、构造可行任务执行序列 Topological Sort 拓扑有序：由偏序得到的全序 拓扑排序：由偏序定义得到拓扑有序的操作 构造有向图中顶点的拓扑有序序列 得到可行任务执行顺序 判断有向图AOV-网中是否存在环，即是否为DAG 若图中所有顶点都在拓扑有序序列中，则有向图中不存在环 参见algorithm/problems/graph AOV网：activity on vertex network，顶点表示活动，弧 表示活动间优先关系的有向图 关键活动优化Critical Path关键路径：路径长度最长的路径 对整个AOE网，开始点到结束点的关键路径长度即为完成工程 的最短时间 对事件$v_i$，从起始点$v_1$到其的关键路径长度即为，以 $v_i$为尾的活动的最早开始时间 关键路径上的所有活动均为关键活动 分析关键路径目的就是找出关键活动 提高关键活动工效缩短工期 AOE网：activity on edge network，顶点表示事件，边表示 活动持续事件的带权有向无环图 一般网络中只有一个源点、汇点，表示工程开始、完成 以上假设AOE网中活动可以并行进行 关键活动 关键活动：记$ee{ij}$为活动$a{ij}$最早开始时间、 $el{ij}$为不推迟整个工程完成前提下$a{ij}$最迟开始时间 ，称$ee{ij} = el{ij}$称为关键活动 $el{ij} - ee{ij}$表示完成活动$a_{ij}$的时间余量 提前完成非关键活动不能加快工程进度 关键活动耗时一定范围变化影响工程整体完成时间 考虑如下事件和活动发生关系有 \\left \\{ \\begin{array}{l} ee_{ij} & = ve_{i} \\\\ el_{ij} & = vl_{j} - a_{ij} \\end{array} \\right. $ve_i, vl_i$：事件（顶点）i最早、最晚发生的时间 $a{ij}$：活动$a{ij}$需要持续时间 对$ve_i, vl_i$，存在如下递推关系 \\left \\{ \\begin{array}{l} ve_i = \\max\\{ve_m + a_{mi} \\}, & \\forall a_{mi} \\in E \\\\ vl_i = \\max\\{vl_n - a_{in} \\}, & \\forall a_{in} \\in E \\end{array} \\right.则依拓扑排序可计算得$ve_i$，逆拓扑排序可计算得$vl_i$ 参见algorithm/problems/graph 为求解AOE网中活动$e{ij}, l{ij}$，应该首先求出事件 Flow Network流量网络 包含一个源点：物质流唯一出发点 包含一个汇点：物质流唯一汇聚点 每条有向边权重为边capacity的正整数$u_{ij}$ 事实上，有理数总可以通过变换变为整数，所以只要容量为 有理数就可以 计算机无法真正处理无理数，无理数边权只具有理论意义 流量约束Capacity Constraits容量约束：通过边的流量不大于边容量$x{ij} \\leqslant u{ij}$ Flow-Conservation Requirement流量守恒要求：除源点、汇点外其余顶点只能改变流方向，进入、 流出物质总量不变，不能消耗、添加物质 \\sum_{i:(i,j) \\in E} x_{ij} = \\sum_{k:(j,k) \\in E} x_{jk} 其中$x_{ij}$表示通过边$(i,j)$的流量（传输量） 等式左右为进入、离开顶点i的输入、输出流总和 并且 \\sum_{j:(1,j) \\in E} x_{1j} = \\sum_{i:(i,n) \\in E} x_{in} 流的值 = 源点输出流 = 汇点输入流 可通过流量守恒要求推出 最大流最大流：分配流量网络中边权（实际流量），使得网络在满足流量 守恒、容量束情况下，最大的流的值（边容量都为正整数） \\max = \\sum_{j:(1,j)} x_{i,j} \\\\ s.t. 0 \\leqslant x_{ij} \\leqslant u_{ij} \\\\ \\sum_{j:(j,i) \\in E) x_{ji} - \\sum_{j:(i,j) \\in E} x_{ij} = 0cut割：$C(X,\\bar X)$=所有头在$X$、尾在$\\bar X$边集合 $X$；包含源点、不包含汇点的顶点V的子集 $\\bar X$：$X$的补集，包含汇点 删除割中所有边，则不存在从源点的汇点的路径 Augmenting-Path MethodAugmenting-Path流量增益路径：当前流情况下，可以传输更多流量、从源点到 汇点路径，考虑路径$i \\rightarrow j \\leftarrow k$中顶点j边 forward edge：前向边$(i, j)$，同流量网络中边$(i, j)$ 方向相同 具有正的未使用容量$r{ij} = u{ij} - x_{ij}$ 可以把该边流量增加最多$r_{ij}$ backward edge：后向边$(j, k)$，同流量网络中边$(k, j)$ 方向相反 具有正流量$x_{kj}$ 可以把该边流量减少最多$x_{kj}$ 增益路径法 寻找网络中增益路径，设$r$为路径中各前向边未使用容量 $r{ij}$、后向边流量$x{jk}$最小值 每条前向边流量加r、后向边流量减r，可以得到新的可行流量， 且流量值增加r，不断迭代 基于边容量、流量都为正整数假设 r也为正整数，每次迭代流量值至少增加1 流量最大值有上界为源点为起点边容量和，则增益路径法 在有限步迭代后会停止 联合最大流-最小割定律可以证明 最终流量一定是最大化的，等于最小割容量 和增量路径选择无关 最后一步迭代中 所有已标记顶点和未标记顶点之间边就构成最小割 这样边流量要么满（标记到未标记）、要么空（反） 增益路径法具体实现参见graph 算法主要问题在于如何寻找增益路径，生成路径的顺序对算法 有巨大影响 Max-Flow Min-Cut Theorem最大流-最小割定理：网络中最大流量值等于其最小割容量 Theorem1网络中最大流量值小于任意割容量 设可行流量x值为v，割$C(X, \\bar_X)$容量为c 通过该割的流量为：$X$到$\\bar_X$的流量之和与 $\\bar_X$到$X$的流量之和的差值（可由流量守恒推导） v = \\sum_{i \\in X, j \\in \\bar_X} x_{ij} - \\sum{j \\in \\bar_X, i \\in X} x_{ji} 由流量非负可得 v \\leqslant \\sum_{i \\in X, j \\in \\bar_X} x_{ij} \\leqslant \\sum_{i \\in X, j \\in \\bar_x} u_{ij}即网络上任何可行流值不能超过网络上任意割容量 v \\leqslant c Theorem2网络中最大流量等于最小割容量，可以使用增益路径法证明 设$v^{}$为通过路径增益法得到的最终流$x^{}$的值 对增益路径法最终流量情况下，考虑顶点集合$X^{*}$ 包含源点 其他顶点可由源点出发，经未使用的容量大于0的前向边、 流量大于0的后向边组成路径到达 则汇点不属于$X^{*}$，否则存在一条流量增益路径，不是流量 增益法最终流情况 考虑割$C(X^{}, \\bar_{X^{}})$ $X^{}, \\bar_{X^{}}$之间任意边$(i,j)$： $x{ij} = u{ij}$，没有未使用容量 $\\bar{X^{}}, X^{}$之间任意边$(j,i)$：$x{ji}=0$， 没有流量 否则顶点j$\\in X^{*}$ 则有 \\begin{align}{c} v* & = \\sum_{i \\in X^{*}, j \\in \\bar_{X^{*}} x_{ij} - \\sum{j \\in \\bar_{X^{*}, i \\in X^{*}} x_{ji} \\\\ & = \\sum_{i \\in X^{*}, j \\in \\bar_{X^{*}}} u_{ij} - 0 \\\\ & = C(X^{*}, \\bar_{X^{*}}) \\end{align}即存在某个割容量等于流量增益法得到最终流量值","link":"/Algorithm/Data-Structure/graphdi_specials.html"},{"title":"Hashing","text":"Hashing Table 哈希表/散列表：可根据哈希值直接访问的数据结构 原理：以哈希值做为地址，缩小搜索空间、提高查找效率 使用哈希函数为每个键计算哈希值，得到位于 $0, \\cdots, m-1$之间整数 按照哈希值把键分布在$H[0, \\cdots, m-1]$哈希表中 查找匹配键时，以查找键哈希值作为起点在哈希表中 搜索 应选择合适的哈希函数、哈希表长度，尽量把键尽量均分在 哈希表中 哈希函数$hash$：参见math_algebra/#todo 对闭散列：减少冲突 对开散列：避免数据集中 散列表长度$m$：常为质数（方便双散列） Load Factor负载因子：$\\alpha = \\frac {noempty} {m}$ $m$：哈希表中slots数量（长度）（哈希桶数量） $noempty$：非空数量 闭散列：负载因子反映哈希表冲突可能性、查找效率 负载因子过小：冲突可能性小，查找效率高，但浪费空间 负载因子过大：冲突可能性大，查找效率低，空间利用率高 负载因子取值最大为1 应适当平衡负载因子，负载因子接近1时重散列，避免冲突 过多影响查找效率 Java中HashMap初始负载值为0.75 开散列：负载因子反映查找效率 但应该无法反映冲突可能性（也无必要） 开散列往往被用于应对大规模数据，冲突总是存在 查找效率更多取决于数据（哈希值）偏倚程度 负载因子可以大于1 应用 字典/映射实现：cs_algorithm/data_structure/set Open Addressing闭散列/开放寻址：所有键存储在散列表本身中，不扩展存储空间 哈希表$m$至少要和哈希键数量$n$一样大 冲突问题解决：根据一定规则计算下个地址 cluster：聚合，散列表接近满时，一序列连续单元格被占据 线性探查性能恶化，操作效率降低 聚合越来的越大时，新元素插入聚类可能性增加 聚合可能被新插入元素连接，导致更大程度聚合 增量类型增量类型：碰撞发生后，根据一定规则对原哈希值修正 H_i = (hash(key) + d_i) mod m, i=1,2,\\cdots $d_i = i$：linear probing，线性探查 $d_i = i^2, -i^2$：quadratic probing，二次探查 $d_i = 伪随机数$：伪随机探查 $d_i = i hash_2(K), i=0,1,2,\\cdots$：double hashing* ，再散列法 再散列法说明：为保证哈希表中每个位置被探查，增量$s(K)$ 必须互质 $m$为质数时自动满足 文献推荐：$s(K) = m - 2 - K mod (m-2)$ 对较小散列：$s(K) = 8 - (K mod 8)$ 对较大散列：$s(K) = K mod 97 + 1$ 操作 插入：依次检查哈希值$h(K)$、探查目标序列，直至找到空 单元格放置键 查找：给定查找键K，计算哈希值$h(K)$、探查目标序列，比较 K和单元格中键值 若查找到匹配键，查找成功 遇到空单元格，查找失败 删除：延迟删除，用特殊符号标记曾经被占用过、现被删除 的位置 不能直接删除，否则的中间出现空单元格，影响查找正确性 算法效率 成功查找访问次数： $S \\approx \\frac 1 2 (1+\\frac 1 {(1-\\alpha)})$ 失败查找访问次数： $U \\approx \\frac 1 2 [1+\\frac 1 {(1-\\alpha)^2}]$ 简化版本近似结论（散列规模越大，近似结论越正确） 无法避免散列表趋满时性能恶化 再哈希法数学分析困难，经验表明优秀的散列函数（两个）， 性能较线性探查好 Multi Hashing多重哈希：使用一组哈希函数$h_0,\\cdots,h_n$依次计算哈希值， 确定插入、查找地址 类似增量类型方法，仅各次地址独立使用哈希函数计算 增大空间Rehashing重散列：扫描当前表，将所有键重新放置在更大的表中 散列表趋满时唯一解决办法 Overflow Area建立公共溢出区：将哈希表分为基本表、溢出表两部分 将发生冲突的元素都放入溢出区 基本表中可以考虑为为每个哈希值设置多个slots 即基本表直接存储哈希桶 Chaining开散列/分离链：哈希表作为目录，使用额外数据空间组织哈希键 拉链法/分桶法拉链法/分桶法：哈希表作为目录项存储指向hash桶的指针，hash桶 中存储哈希键 目录项表：顺序表，连续存储空间 可以通过hash值在常数时间内定位：一般其索引位置就是 hash值 目录项越多，数据分布相对越稀疏、碰撞概率越小、效率 越高 hash桶：存储具有相同哈希值元素的顺序表 目录项存储chain为顺序表：每个链即为hash桶 目录项存储chain为顺序表链：链中每个顺序表为hash桶 即每个目录项对应多个hash值，链接多个hash桶 操作 查找 对查找键K，使用同样散列函数计算键散的函数值$h(K)$ 遍历相应单元格附着链表，查找是否存在键K 插入：计算键对应桶，在链表尾部添加键即可 删除：查找需要删除的键，从链表中移除即可 算法效率 效率取决于链表长度，而链表长度取决于字典、散列表长度 和散列函数质量 成功查找需要检查指针次数$S = 1 + \\alpha / 2$ 不成功查找需要检查指针次数$U = \\alpha$ 计算散列函数值是常数时间操作 若n和m大致相等，平均情况下$\\in \\Theta(1)$ 算法查找的高效是以额外空间为代价的 Perfect Hashing完美哈希：采用两级全域哈希，目录项链接独立哈希表的拉链哈希表 二级哈希表开头部分存储哈希表元信息 $m = n^2$：哈希表槽数，$n$为映射至该槽元素数量 （此时由全域哈希性质：冲突次数期望小于0.5） $a, b$：全域哈希参数 复杂度 时间复杂度：最坏情况下查找为$O(1)$ 空间复杂度：期望空间为线性 $E(\\sum_{i=1}^{m-1} \\theta(n_i^2) = \\theta(n)$ 完美哈希没有冲突的概率至少为0.5 全域哈希参见math_algebra/hash_funcs Dynamic Hashing动态hash：在hash表中元素增加同时，动态调整hash桶数目 在原hash表基础上进行动态桶扩展 不需要遍历表元素重复执行插入操作 开散列法在大规模、在线数据的扩展 多hash表多hash表：通过建立多个hash表的方式扩展原hash表 思想、实现简单 占用空间大，数据分布偏斜程度较大时，桶利用率不高 实现操作时需要考虑多个hash表 插入 若存在hash相应桶中存在空闲区域，直接插入 否则分裂，新建hash表，插入元素至空闲区域 查找：需要查找所有hash表相应桶才能确定 当表中元素较多时，可以考虑并行执行查找操作 删除操作：若删除元素导致某hash表空，可考虑删除该表 可扩展动态hash可扩展动态hash：只分裂将要溢出的桶，使用目录项作为索引 多个目录项可能指向同一个桶 分裂时代价较小 翻倍目录项替代翻倍整个hash表 每次只分裂将要溢出桶 只需要进行局部重散列，重分布需要分裂的桶 目录指数级增长 数据分布不均时，会使得目录项很大 插入 D：全局位深度，hash值截断长度，为局部桶深度最大值 L_i：桶局部深度，等于指向其目录项数目 若对应桶存在空闲位，则直接插入 否则分裂桶：分裂后两桶局部深度加1 若分裂桶局部深度不大于全局位深度 创建新桶 重散列原始桶中数据 更新目录项中对应指针：分别指向分裂后桶 若分类桶局部深度大于全局位深度 更新全局位深度 目录项翻倍 创建新桶 重散列原始桶中数据 更新目录项中对应指针 （新增）无关目录项仍然指向对应桶 相关目录项指向分别指向分裂后桶 查找 计算原始hash值 按照全局位深度截断 寻找相应目录项，找到对应桶，在桶中进行比较、查找 删除 计算原始hash值 按照全局位深度截断 寻找相应目录项，找到对应桶，在桶中进行比较、删除 若删除后发现桶为空，考虑与其兄弟桶合并，并使局部深度 减1 线性散列线性散列：按次序分裂桶，保证整个建表过程类似完全二叉树 整个哈希表建表过程始终保持为完全二叉树 每次分裂的桶是完全二叉树编号最小的叶子节点 分裂前后桶间均为有序 相较于可扩展散列 无需存放数据桶指针的专门目录项，节省空间 能更自然的处理数据桶满的情况 允许更灵活的选择桶分裂时机 但若数据散列后分布不均，则问题可能比可扩散散列严重 实现相较而言更复杂 桶分裂 N：hash表中初始桶数目，应为2的幂次 d = log_2N：表示桶数目需要位数 level：分裂轮数，初始值为0，则每轮初始桶数为 $N * 2^{level}$ Next：下次要发生分裂的桶编号 每次同分裂条件可以灵活选择 设置桶填充因子，桶中记录数达到该值时进行分裂 桶满时发生分裂 每次发生的分裂的桶总是由Next决定 与当前被插入的桶溢出无关，可引入溢出页处理桶溢出 每次只分裂Next指向的桶，桶分裂后Next += 1 后续产生映像桶总是位于上次产生映像桶之后 “轮转分裂进化”：各桶轮流进行分裂，一轮分裂完成后进入下轮 分裂 查找 根据N、level计算当前d值，截取原始hash值 若hash值位于Next、N之间，说明该轮对应桶还未分裂， 直接在桶中查找 若hash值小于Next，说明该轮对应桶已经分裂，hash值向前 多取一位，在对应桶中查找 删除 删除操作是插入操作的逆操作 若删除元素后溢出块为空，可直接释放 若删除元素后某个桶元素为空，Next -= 1 当Next减少到0，且最后桶也是空时，Next = N/2 - 1 ，同时level -= 1 1`","link":"/Algorithm/Data-Structure/hash_table.html"},{"title":"无向图衍生","text":"Bipartite Graph二分图：所有顶点可以分为两个不相交集合U、V，两个集合大小不定 相等，但每条边都连接两个集合中各一顶点 可以证明：当且仅当图中不存在奇数长度回路时，为二分图 二分图中顶点可以可以染成两种颜色，使得每条边两头顶点颜色 不同 矩阵存储二分图时，因为U、V内部节点之间无边，大部分场景 只需要$|V| * |U|$的矩阵（对有序、加权适用） 性质 二分图匹配意义：同类型（集合内部）之间没有连接 Augmenting-Path（二分图）增益路径：对合法匹配M，简单路径两端连接V、U中 的自由顶点，路径中边交替出现在$E-M, M$中，称M的增益路径 增益路径长度总为奇数，为M中匹配两倍+1 则路径中奇数边组成新的匹配，比M多一条边 增益路径-最大匹配证明当且仅当G中不存在M增益路径时，M为G最大匹配 必要性 若M存在增益路径，则可以扩展M得到更多匹配，M不是最大匹配 充分性 若存在M无增益路径，但不为最大匹配，设$M{}$是G中的最大 匹配，则$M{}$中边至少比M中边数量大1，有 $|M^{}| &gt; |M|, |M^{} - M| &gt; |M - M^{*}|$ 则两者对称差集为 $M \\bigoplus M^{} = (M - M^{}) \\cup (M^{*} - M)$ 设$G^{‘} \\subseteq G$为二者差集中所有边、点，根据匹配 定义，$G^{‘}$中任何单个点和$M, M^{*}$相连接不会超过 一条边 则$G^{‘}$中顶点连通度不大于2，其中连通分量为 偶数长度回路，其中边交替属于 $|M^{} - M|, |M - M^{}|$，在两者中数量相同 若不交替，则说明连续两条边在同个匹配中，有交点， 和匹配定义冲突 若不为偶数长度，同样的首、尾两条边在同一匹配中， 和匹配定义冲突 交替路径（无环） 因为$|M^{} - M| &gt; |M - M^{}|$，所以$G^{*}$中 不可能仅有回路 所以至少存在一条具有交替边路径，起点终点都是 $M^{*} - M$同一条边（如单边路径），M具有增益路径 ，矛盾 最大匹配求解匈牙利算法实现详见graph Konig TheoremKonig定理：二分图中最大匹配数|M| = 最小点覆盖数|C| 已经通过匈牙利算法求出最大匹配M 从集合V中每个未被匹配点开始，走一条类似增益路径 的交替路径，标记路径中的所有点 只是因为已经找到了最大匹配，所以路径另外一端不可能 是自由顶点 允许重复走过同一条边 路径中V到U的均为非匹配边、U到V均为匹配边 当然也可以从U的所有未匹配顶点开始 记集合V中中未被访问、U集合中已被访问的已匹配顶点点集为C，则 $顶点数目|C| = 最大匹配数 = 最小点覆盖数$ 因为每个点都是M中某边端点，且V中已标记同U中未标记、V中 未标记顶点同U中已标记一一对应，为匹配边两端点，所以 顶点数 = V中未被访问 + U中已访问 = \\\\ V中未访问 + V中已访问 = （最大）匹配数 在最大匹配情况下，所有边至少有一个端点为已匹配点 对于匹配边，肯定被C中顶点覆盖 若非匹配顶点在V中，则一定在某个路径中被访问，则被U 中某个已访问匹配顶点覆盖 若非匹配顶点在U中，则被V中未访问顶点覆盖的 或者说不存在这样的边：其左端点没有标记、而右端点有 标记 匹配边肯定不是起点，不可能 非匹配边，右端有标记则能直接访问左端，标记左端 （通样广度优先搜索遍历所有邻接有顶点点） 而要覆盖匹配边需要至少$|M|$个点，所以$|M|$是最小覆盖点数 推论 1二分图中：最小边覆盖|W| = 图中顶点数|V| - 最小点覆盖数|C| |W| = |V| - |M| = |V| - |C|Ordered Bipartite Graph有序二分图：以同一顶点作为端点的边的有优先级（独立于其他点） 即：V中顶点对U中顶点都有优先级排序，U中顶点对V中顶点也有 优先级排序 Marriage Matching婚姻匹配问题可以使用特殊的完全有序二分图代表 集合V（男士集合）、U（女士集合）大小相同为n 任意男士、女士都有之间都有边连接，即任意男士、女士都需要 给出所有女士、男士优先级 存储、表示方法 优先列表：各男士、女士按照异性优先级排序列表，共2n个 对实现匹配算法而言效率更高 等级矩阵：男士、女士为分别作为矩阵行、列，矩阵元素$P_ij$ 为男士$m_i$对女士$w_j$优先级排序、女士$w_j$对男士$m_i$ 优先级排序元组 更容易看出集合元素匹配 只需要$n * n$阶方阵 Stable Marriage Matching对包含n个对的婚姻匹配M Block Pair：受阻对，满足$m \\in V, w \\in U$，而$(m, w)$ 更倾向于对方，而不是匹配M中对象 Stable Marriage Matching：稳定婚姻匹配，不存在受阻对的 婚姻匹配 稳定婚姻存在性V中存在自由男士时，任选求婚、回应之一执行，直至不存在 自由男士 求婚：自由男士m向女士w求婚，w为其优先级最大、之前未拒绝 过其女士（可以是已匹配） 回应：若女士w自由则接受男士m求婚，与之配对；女士w不自由 则把m同当前配偶匹配，选择其中优先级较高者 当不存在自由男士时，得到匹配M就是稳定匹配 若M是不稳定的，设存在受阻对$(m, w)$ 因为m按照降序求婚，所以m必然在某次迭代向w求过婚，则w当前 对偶必然比m拥有更高优先级，和受阻对假设矛盾 稳定婚姻问题求解算法参见graph Weighted Bipartite Graph加权二分图；每条边都有权重的二分图 Distribution Problem分配问题可以使用特殊的完全加权二分图代表 集合V（人员集合）、U（任务集合）大小相同为n 任意人员、任务有边相连，人员、任务内部之间无边 存储方法 使用$n * n$阶成本矩阵C存储，其元素$c_{ij}$表示人员$i$ 完成任务$j$的成本 则问题转化为：从成本矩阵中每行分别选择元素，且元素不属于 同一行，使得和最小 （最小成本）分配问题算法参见graph Biconnected Graph articulation point：关节点，删除顶点v、与v相连的各边 之后，将图一个连通分量分割成 两个、两个以上连通分量，则 称顶点v为图的一个关节点 biconnected graph：重连通图，没有关节点的连通图 重连通图中任意一对结点之间至少存在两条路径 若在重连通图中至少删除k个顶点才能破坏图的连通性，则称图 的连通度为k 求解关节点利用DFS可以求出图的关节点，判断图是否是重连通的，对DFS生成树 生成树有两棵及以上子树，则根节点为关节点 因为不同子树之间不存在连通不同子树顶点的边 非叶子顶点v某棵子树中没有指向v前驱的回边，则v为关节点 算法参见algorithm/problems/graph","link":"/Algorithm/Data-Structure/graphundi_specials.html"},{"title":"Linear List","text":"线性表综述线性表：n个数据元素的有限序列 元素个数n定义为线性表长度，n=0时称为空表 非空表中每个元素都有确定的位置 顺序存储结构顺序存储结构/映像：使用一组地址连续的存储单元依次存储数据 元素 具体参见algorithm/data_structure_intro 顺序表顺序表：顺序存储结构的线性表 12345typedef struct{ ElemType *elem; int length; int listsize;}SqList; 以元素在计算机内物理位置相邻表示线性表中数据元素之间 的逻辑关系 每个数据元素存储位置和线性表起始位置，相差和其在线性表中 位序成正比常数，所以顺序表时一种随机存取存储结构 高级程序语言中数组类型也有随机存取特点，因此通常 用数组描述 时间效率 插入/删除：$O(n)$ 主要时间耗费在移动元素上 求表长：$O(1)$ 取第n个元素：$O(1)$ 链式存储结构链式/非顺序存储结构/映像：用一组任意存储单元存储线性表 中数据元素，还需存储一个指示其直接后继的信息 具体参见algorithm/data_structure_intro （线性/单）链表线性链表：n个节点链接而成 1234typedef struct LNode{ ElemType data; struct LNode * next;}LNode, *LinkList; 链表中每个节点只包含一个指针域 数据元素之间的逻辑关系由节点中指针指示，即指针为数据 元素之间的逻辑关系映像 整个链表存取必须从头指针开始 单链表中任何两个元素存储位置之间没有固定联系，是非随机 存取存储结构 头指针：指示链表中第一个节点的存储位置 头节点：在单链表第一个节点之前附设的节点，其数据域可以 不存储信息，也可以存储线性表长度、尾指针等附加信息 时间效率 插入、删除：$O(n)$ 已知插入、删除元素确切位置的情况下，仅需修改指针， 而不需要移动元素 取第n个元素：$O(n)$ 访问时间依赖元素在列表中位置 说明 在很多场合下，链表是线性表的首选结构 链表不需要事先分配任何存储空间，空间利用合理 插入、删除效率高，只需要重连相关指针 但是存在一些实现问题 求线性表长不如顺序存储结构 链表中结点关系使用指针表示，数据元素在线性表中“位序” 概念淡化，被“位置”代替 因此重新定义带头结点的线性链表 12345678typedef struct LNode{ ElemType data; struct LNode * next;}*Link, * Position;typedef struct { Link head, tail; int len;} 单链表注意事项 头结点/头指针：处理链表非常方便的技巧 头指针指向链表首个结点：便于调整首个节点位置时，仍然 记住链表 头指针不包含链表信息，本质不属于链表：有些情况下方便 统一代码，不需要特殊考虑链表首个节点 对链表进行可能改变链表的遍历操作：一般使用两个标记 结点/指针 头结点/指针lstart：记住链表 遍历标记指针cur：标记处理结点 交换节点：标记指针需要指向当前处理节点的前一个结点 单链表中只有指向下个节点的指针，若标记指针指向当前 节点，则无法方便将链表同当前节点断开、重连 注意待交换两个节点为同一节点的情况：不同于值交换 ，这种情况可能导致链表错误连接成环 无指针、纯引用对象语言（python）中：只能使用节点对象 遍历链表 变量为链表中节点引用：使用类似普通指针，需要注意 别修改引用节点数据 变量为额外节点引用：内存类似普通指针，使用时注意 解析引用次数 静态链表静态链表：使用数组描述的链表 1234typedef struct{ ElemType data; int cur;}component, SLinkList[MAXSIZE]; 数组分量表示节点 使用游标cur作为指针域指示节点在链表中的逻辑位置 第0个分量表示头节点，其指针域cur指向链表第一个节点 方便在无指针高级语言中使用链式结构 为确定未使用的数组分量，可以将未被使用的、删除的分量用 游标链成备用边表 Circular Linked List循环链表：表中最后一个节点指针域指向头节点，整个链表形成环 循环链表和线性链表操作基本一致 仅循环条件不再是指针域为空，而是是否等于头指针 Double Linked List双向链表：链表中有两个指针域，分别指向直接后继、直接前驱 12345typedef struct DuLNode{ ElemType data; Struct DulNode * prior; Struct DulNode * next;}DuLNode, * DuLinkList; 双向链表克服线性链表寻找直接前驱时间$O(n)$的缺点 双向链表大部分操作和线性链表相同，指示有些操作需要同时 修改两个指针 字符串：数组实现的一种数据结构 字符串常见操作不同于其他数组 计算字符串长度 按照字典序确定字符串排序时位置 连接字符串构","link":"/Algorithm/Data-Structure/linear_list.html"},{"title":"数组和广义表","text":"综述 数组、广义表可以看作是线性表的扩展：线性表中数据元素本身 也是抽象数据结构 Array对各维界分别为$b_i$的n维数组 数组中含有$\\prod_{i=1}^n b_i$个数据元素，每个元素都受n个 关系约束 每个关系中，元素都有直接后继 就单个关系而言，这个n个关系仍然是线性关系 n维数组可看作是线性表的推广，n=1时，数组退化为定长线性表 和线性表一样，所有数据元素必须为同一数据类型 数组一旦被定义，其维数、维界就不再改变 除了初始化、销毁之外，数组只有存储、修改元素值的操作 采用顺序存储结构表示数组是自然的 几乎所有程序设计语言都把数组类型设定为固有类型 顺序存储表示 存储单元是一维结构，数组是多维结构，所有使用连续存储单元 存储数组的数据元素需要约定次序 BASIC、PL/1、COBOL、PASCAL、C语言中，以行序作主序 FORTRAN中，以列序作主序 数组元素存储地址 \\begin{align*} LOC(j_1, j_2, \\cdots, j_n) & = LOC(0, 0, \\cdots, 0) + (\\sum_{i=1}^{n-1} j_i (\\prod_{k=i+1}^n b_k + j_n))L & = LOC(0, 0, \\cdots, 0) + \\sum_{i=1}^n c_i_i \\end{align} $cn=L, c{i-1} = b_ic_i$ 123456789typedef struct{ Elemtype * base; int dim; // 数组维数 int * bounds; // 数组各维界（各维度长度） int * constants; // 数组各维度单位含有的数组元素数量，由`bounds`累乘} 矩阵压缩压缩存储：为多个值相同元只分配一个存储空间，对0元不分配空间 特殊矩阵特殊矩阵：值相同元素、0元素在矩阵的分布有一定规律，将其压缩 至一维数组中，并找到每个非零元在一维数组中的对应关系 对称矩阵：为每对对称元分配一个存储空间 一般以行序为主序存储其下三角（包括对角线）中的元 上/下三角矩阵：类似对称矩阵只存储上/下三角中的元，附加 存储下/三角常数 对角矩阵：同样可以按照行、列、对角线优先压缩存储 稀疏矩阵稀疏矩阵：稀疏因子$\\sigma = \\frac t {mn} \\leq 0.05$的矩阵 使用三元组（非零元值、其所属的行列位置）表示非零元 三元组顺序表三元组顺序表/有序双下标法：以顺序结构表示三元组表 123456789typedef struct{ int i, j; ElemType e;}Triple;typedef struct{ Triple data[MAXSIZE+1]; int mu, nu, tu; // 行、列、非零元数}TSMatrix; data域中非零元的三元组以行序为主序顺序排列，有利于进行 依行顺序处理的矩阵运算 行逻辑链接的顺序表行逻辑链接的顺序表：带行链接信息的三元组表 123456typedef struct{ Triple data[MAXSIZE+1]; int rpos[MAXRC+1]; // 各行首个非零元的位置表 int mu, nu, tu;}RLSMatrix; 为了便于随机存取任意行非零元，需要知道每行首个去非零元 在三元组表中的位置，即rpos 十字链表十字链表：采用链式存储结构表示三元组的线性表 123456789101112typedef struct OLNode{ int i,j; // 该非零元行、列下标 ElemType e; struct OLNode, *right, *down; // 该非零元所在行表、列表的后继链域}OLNode, *OLink;typedef struct{ OLink *rhead, *chead; // 行、列链表表头指针向量基址 int mu, nu, tu;}CrossList; 同一行非零元通过right域链接成一个线性链表 同一列非零元通过down域链接成一个线性链表 适合矩阵非零元个数、位置在操作过程中变化较大的情况 Lists广义表/列表：线性表的推广 LS = (\\alpha_1, \\alpha_2, \\cdots, \\alpha_n) $\\alpha_i$：可以时单个元素，也可以是广义表，分别称为LS 的原子、子表 head：表头，LS非空时的首个元素$\\alpha$ tail：表尾，LS除表头外的其余元素组成的表，必然是列表 列表是一个多层次结构：列表的元素可以是子表，子表元素 也可以是子表 列表可以为其他列表所共享 列表可以是一个递归的表：即列表自身作为其本身子表 广义表长度：广义表中元素个数 广义表深度：广义表中最大括弧重数 链式存储结构广义表中数据元素可以具有不同结构，难以用顺序存储结构表示， 通常采用链式存储结构 头尾链表 数据元素可能是原子、列表，因此需要两种结构的结点 表节点：表示列表，包括：标志域、指示表头的指针域、 指示表尾的指针域 原子节点：表示原子，包括：标志域，值域 123456789101112131415typedef enum{ATOM, LIST} ElemTag;typedef struct GLNode{ ElemTag tag; // 标志域，公用 union{ // 原子节点、表节点联合部分 AtomType atom; // 值域，原子节点 struct{ struct GLNode *hp, *tp; // 两个指针域，表节点 }ptr; };}*GList; 除空表的表头指针为空外，任何非空列表的表头指针均指向 表节点，且该表节点 hp指针域指向列表表头 tp指针域指向列表表尾，除非表尾为空，否则指向表节点 容易分清列表中原子、子表所属层次 最高层的表节点个数即为列表长度 扩展线性链表12345678910typedef enum {ATOM, LIST} ElemTag;typedef struct GLNode{ ElemTag tag; union{ AtomType atom; struct GLNode *hp; }; struct GLNode *tp;}*GList;","link":"/Algorithm/Data-Structure/linear_general.html"},{"title":"无向图","text":"点集点覆盖集 Vertex Covering Set：点覆盖（集），顶点子集$S \\subseteq V$ ，满足每条边至少有一个顶点在集合中 Minimum Vertex Covering Set：最小顶点覆盖集，最少顶点的 点覆盖集 点支配集 Vertex Dominating Set：点支配集，顶点子集$D \\subseteq V$ ，满足$\\forall u \\in V-D, \\exists v \\in D, (u, v) \\in E$ 即V中顶点要么是D中元素，要么同D中一个顶点相邻 Minimum Vertext Dominating Set：最小支配集，顶点数目 最小支配集 极小支配集：真子集都不是支配集的支配集 点独立集 Vertext Independent Set：（点）独立集，顶点子集 $I \\subseteq V$，满足I中任意两顶点不相邻 Maximum Vertext Independent Set：最大独立点集，顶点数 最多的独立点集 极大点独立集：超集都不是独立集的独立集 性质Thoerem 1若无向图$G(V, E)$中无孤立顶点，则G的极大点独立集都是G的极小 支配集（反之不成立） Thoerem 2一个独立集是极大独立集，当前且仅当其为支配集 Thoerem 3若无向图$G=(V, E)$中无孤立点，顶点集$C \\subseteq V$为G点覆盖 ，当且仅当$V - C$是G的点独立集 边集边覆盖 Edge Covering Set：边覆盖（集），边子集$W \\subseteq E$， 满足$\\forall v \\in V, \\exists e \\in W$，使得v是e端点 即G中所有点都是便覆盖W的邻接顶点 Minimum Edge Covering Set：边数最少的边覆盖集 极小边覆盖集：任意真子集都不是边覆盖集的边覆盖 边独立集 Matching/Edge Indepdent Set：匹配（边独立集），边子集 $I \\subseteq E$，满足I中所有边没有公共顶点 Maximum (Cardinality) Matching：最大（基数）匹配，包含 最多边的匹配 极大匹配：任意超集都不是匹配的匹配 Perfect Matching：完美匹配，匹配所有点的最大匹配 Mate：对偶，匹配中相互连接的一对顶点 性质Thoerem 1M为G一个最大匹配，对G中每个M未覆盖点v，选取一条与v关联边组成 集合N，则边集$W = M \\cup N$为G中最小边覆盖 Thoerem 2若W为G最小边覆盖，其中每存在相邻边就移去其中一条，设移去边集 为N，则边集$M = W - N$为G中一个最大匹配 Thoerem 3最大匹配、最小边覆盖满足：$|M| + |W|= |V|$","link":"/Algorithm/Data-Structure/graph_set.html"},{"title":"Stack&amp;Queue","text":"从数据结构来看，栈和队列也是线性表，但其基本操作是线性表 操作的子集 从数据类型来看，栈和队列是和线性表不同的抽象数据类型 Stack栈：限定在表尾/栈顶进行插入和删除、操作受限的线性表 top：栈顶，表尾端 bottom：栈底，表头端 栈的修改是按照LIFO的方式运转，又称后进先出的线性表 入栈：插入元素 出栈：删除栈顶元素 last in first out/栈应用广泛，对实现递归操作必不可少 顺序存储结构顺序栈顺序栈：顺序映像存储栈底到栈顶的数据元素，同时附设指针指示 栈顶元素在顺序栈帧中的位置 12345typedef struct{ SElemType * base; SElemType *top; int stacksize;}SqStack; base永远指向栈底，top指向栈顶元素下个位置 base==NULL：栈不存在 top==base：表示空栈 栈在使用过程中所需最大空间难以估计，因此一般初始化设空栈 时不应限定栈的最大容量，应分配基本容量，逐渐增加 链式存储结构Queue队列：限定在表尾/队尾进行插入、在表头/队头进行删除的 受限线性表 rear：队尾，允许插入的一端 front：队头，允许删除的一端 队列是一种FIFO的线性表 队列在程序设计中经常出现 操作系统作业排队 图的广度优先遍历 链式存储结构链队列链队列：使用链表表示的队列 12345678typedef struct QNode{ QElemType data; struct QNode * next;}QNode, *QueuePtr;typedef struct{ QueuePtr front; QueuePtr rear;}LinkQueue; front：头指针 rear：尾指针 为方便同样给链队列添加头结点，令头指针指向头结点，此时 空队列判断条件为头、尾指针均指向头结点 链队列的操作即为单链表插入、删除操作的特殊情况的，需要 同时修改头、尾指针 顺序存储结构循环队列循环队列：使用顺序结构存储队列元素，附设两个指针分别指示对头 、队尾的位置 为充分利用数组空间，将数组视为环状空间 12345typedef struct{ QElemType * base; int front; int rear;} front：头指针 rear：尾指针 循环队列时，无法通过rear==front判断队列空、满，可以在 环上、环外设置标志位判断 C语言中无法用动态分配的一维数组实现循环队列，必须设置 最大队列长度，如果无法确定，应该使用链队列 Deque双端队列：限定删除、插入操作在表两端进行的线性表 输出受限双端队列：一个端点允许删除、插入，另一个端点只 允许插入 输入受限双端队列：一个端点允许删除、插入，另一个端点只 允许删除 栈底邻接的两个栈：限定某个端点插入元素只能从该端点删除 看起了灵活，但是实际应用不多 Priority Queue优先队列 用于从一个动态改变的候选集合中选择一个优先级高的元素 主要操作 查找、删除最大元素 插入元素 实现 可以基于数组、有序数组实现 基于heap的优先队列实现更好","link":"/Algorithm/Data-Structure/linear_queue_stack.html"},{"title":"String","text":"综述串/字符串：零个或多个字符组成的有限序列 文本串：字母、数字、特殊符号构成 位串：0、1构成 基因序列：可以使用字符串模型表示，其字母表只包括4个 字母{A, C, G, T} s = 'a_1a_2\\cdots\\a_n' $s$：串名，其后单引号括起是串的值 $a_i$：字母、数字等字符 $n$：串中字符的数目，串长度，零个字符的串称为空串 串的逻辑结构和线性表相似，只是串的数据对象约束为字符集 串的基本操作和线性表有很大差别 线性表基本操作大多以“单个元素”作为操作对象 串的基本操作通常以“串的整体”作为操作对象 串的存储表示 串只作为输入、输出常量出现，则只需要存储串的串值字符序列 在非数值处理中，串也以变量形式出现 定长顺序存储 类似线性表的顺序存储结构 按照预定义大小，为每个定义的串变量分配固定长度的存储区， 存储字符序列 1typedef unsigned char SString[MAXSTRLEN+1] 串实际长度在预定义范围内随意，超过预定义长度的串值则被 舍去（截断） 串实际长度存储方式 以下标为0的数组分量存放：Pascal 在串值后面加入不计串长的结束标记字符：C以\\0标记， 此时串长为隐含值，不利于某些操作 串操作的原操作为“字符序列的复制”，操作的时间复杂度基于 复制的字符序列长度 堆分配存储 仍然以地址连续的存储单元存储串字符序列，但存储空间是在 程序执行过程中动态分配得到 1234typdef struct{ char *ch; int length;} length：串长 既有顺序存储结构的特点，处理方便，对串长又没有任何限制 此存储结构的串操作仍是基于“字符序列的复制”进行 块链存储 使用链表的方式存储串值 但是串结构特殊的，需要设置节点大小 12345678typedef struct Chunk{ char ch[CHUNKSIZE]; struct CHUNK * next;}Chunk;typedef struct{ Chunk *head, *tail; int curlen;} CHUNKSIZE：节点大小，每个节点中最大存储字符数量 curlen：当前串长度 节点大小不为1时，链表最后一个节点不一定全被串值占满， 此时通常补上非串值字符 一般情况下，对串进行操作时，只需要从头到尾扫描即可 对串值不必简历双向链表 设尾指针是为了方便进行联结操作（联结操作需要注意 串尾无效字符） 节点大小选择影响串处理效率 存储效率 = 串值所占存储位/实际分配存储位 存储密度小，运算处理方便，存储量占用大 块链结构对某些串操作有一定方便，但是总的来说不如另外两种 存储结构灵活，存储量大、操作复杂 串的模式匹配模式匹配：子串定位操作","link":"/Algorithm/Data-Structure/linear_string.html"},{"title":"二叉树衍生","text":"Huffman Tree哈夫曼树/最优树：带权路径长度WPL最短的树 哈夫曼树中没有度为1的结点，又称为严格的（正则的）二叉树 树带权路径长度：树中所有叶子结点的带权路径长度之和 $WPL = \\sum_{k=1}^n w_k l_k$ 哈夫曼算法哈夫曼算法：构建最小加权路径二叉树 输入：给定的n个权值${w_1, w_2, \\cdots, w_n}$ 初始化n个单节点二叉树集合$F={T_1, T_2, \\cdots, T_n}$ 合并权重最小的两棵树，将其权重之和作为新树权重记录于新树 根节点中 重复，直至生成单独一棵树 特点 贪婪算法 Huffman算法构建的最优二叉树是只有叶子节点有权值，若所有 节点都有权值的最优二叉查找树，需要使用动态规划算法， 参见cs_algorithm/data_structure/tree_search 哈夫曼编码 哈夫曼编码：编码总长度最短的二进制前缀编码 前缀编码：任意编码都不是其他编码的前缀，此时编码可以 前缀编码可以使用二叉树设计，叶子结点代表字符，根节点到 叶子结点路径上分支代表的二进制串即为其二进制编码 对给定出现频率$P[1..n]$的字符集$C[1..n]$，生成哈夫曼树 即可得到哈夫曼编码 链式存储哈夫曼树1234typedef struct HTNode{ unsigned int weight; struct HTNode *parent, *lchild, *rchild;}HTNode, *HuffmanTree; 选拔树优胜树优胜树：非叶结点取值是两个孩子中较小者的完全二叉树 根据定义，根节点的取值是整个树的最小值 从叶节点构建/重构优胜树的过程中 每对兄弟结点捉对比赛，胜利者晋升为父亲结点 胜者逐级向上直到根节点为止 调整优胜树的时间效率$\\in \\Theta(logk)$ 顺序存储结构1typedef SqBiTree SqVictTree; 数组实现的二叉树可以通过完全二叉树性质迅速计算父节点、 孩子节点位置 淘汰树淘汰树：非叶结点值是两个孩子结点中较大者，即指向失败者的 选拔树 可以简化选拔树重构过程 需要额外结点记录/指向胜者 用途归并多路有序序列 问题：k路有序（降序）序列，要将其归并为一组有序序列， 归并过程每轮输出一个最小关键字记录 （显然只能是当前k路序列中第一个记录） 以k路序列首k个元素建立k个叶节点的选拔树 构建选拔树，输出最小元素值 用其所属序列下个元素替换其所在叶节点值，重构选拔 重复n轮：所有k轮归并总时间为$\\in \\Theta(nlogk)$ )$","link":"/Algorithm/Data-Structure/tree_derived.html"},{"title":"Set","text":"集合集合：互不相同项的无序组合 要么指出集合的特殊属性，只有集合中元素才满足的特性 要么显式列出集合的所有成员 存储映像位向量存储表示位串表示法 每个集合S使用一个位串表示，位串中每位代表全集U的一个元素 当且仅当全集$U$中第i个元素被包含在子集$S$中时，位向量 第i个元素为1 1typedef int BitSet[MAX_SET_SIZE/sizeof(int)]; 可以实现快速的标准集合运算 以使用大量存储空间为代价的 线性表存储表示线性表表示法 每个集合使用一个线性表表示，线性表中存储集合元素 1234typedef SqList SLSet; // 顺序表表示集合typedef LinkList LLSet; // 链表表示集合 集合不能包含相同元素，列表可以 可以引入multiset、bag绕过对唯一性的要求 多重集和包是可重复项的无序组合 集合是元素的组合，而列表是集合的有序组合 用线性表表示集合时，不必维护线性表的有序排列 集合运算 检查元素是否属于集合 集合的并集 集合的交集 Disjoint Set/Union Find不相交集/并查集：由某个有限集的一系列不相交子集，及相应 操作构成 通常假设集合中元素为整数，或可以映射为整数 主要包括find、union操作 存储映像 实现应该对find、union有特殊优化 按秩合并：将包含较少结点的集合合并到含有较多结点集合 路径压缩：将每个结点都直接指向根节点 大多数实现会使用集合某个元素作为该集合代表 有些对代表没有特殊约定 有的要求代表为子集中最小元素等 树双亲表存储表示双亲表示法 使用树的双亲表示法作存储结构 1typedef PTree MFSet; 以集合中某个元素作为树根、集合名，其余所有结点都作为根 的孩子结点 每个结点只能有一个双亲结点，即只能属于一个集合，适合存储 不相交集 应用 生成不相交集 求解无向图中连通分量数量 求解等价问题：两两等价元素作为一类，求解每类元素 集合归并 生成迷宫：连通入口、出口连通分量 Map/Dictionary映射/字典：能查找给定元素、增加新元素、删除元素的集合 需要处理的是动态内容的查找，因此需要在查找效率和其他两种 操作中达到平衡 数组、散列法、平衡查找树都可以实现字典 ||散列表|平衡查找树| |——-|——-|———| |渐进时间效率|平均$\\in \\Theta(1)；最坏$\\in \\Theta(n)$|$\\in \\Theta(logn)| |有序性保留|不假定键有序，不保证，不适合按序遍历、按范围查询|保证| 应用 Extendible Hashing：可扩充散列，用于存储磁盘上大型字典 查找时先计算可能包含查找键K的存储段磁盘地址 然后从磁盘中读取段中所有键，从中查找K 因为存取主存开销较磁盘小很多，宁可多次存取主存","link":"/Algorithm/Data-Structure/set.html"},{"title":"图","text":"分类图$G=$：由一些称为顶点的点构成的集合，其中某些顶点由 称为边的线段相连 有限集合V：元素为顶点vertex 有限集合E：元素为顶点二元组，称为边edge/弧arc 边方向Undigraph/Undirected Graph 无向图：所有边都是无向边的图 无向边：若有序对$(u, v) \\in E$，必有$(v, u) \\in E$， 即E是对称的，顶点对$(u, v)$等同于$(v, u)$，没有顺序 对无向边$(u, v)$ 则顶点u、v相互adjcent 其通过undirected edge$(u, v)$相连接 顶点u、v称为边$(u, v)$的endpoint u、v和该边incident（相依附） Digraph 有向图：所有边都是有向边的图 有向边：若有序对对$(u, v) \\in E$无法得到$(v, u) \\in E$， 即两者不等同，有顺序 对有向边$(u, v)$ 边$(u, v)$的方向是从顶点u到顶点v u称为tail，v称为head 边权重Ordered Graph有序图：各边地位有序 Weighted Graph/Network加权图/网络：给边赋值的图 值称为weight或cost 有大量的现实应用 边数量 complete graph：任意两个顶点直接都有的边相连的图 使用$K_{|v|}$表示有|V|个顶点的完全图 dense graph：图中所缺的边数量相对较少 sparse：图中边相对顶点数量较少 特点 不考虑loop（顶点连接自身边），则含有|V|个顶点无向图 包含边的数量|E|满足： $ 0 \\leq |E| \\leq \\frac {|V|(|V| - 1)} {2} $ 对于稀疏图、稠密图可能会影响图的表示方法，影响设计、使用 算法的运行时间 图表示方法（存储结构）Adjacency Matrix邻接矩阵：两个数组分别存储数据元素（顶点）信息、数据元素之间 关系（边）的信息 n个顶点的图对应n * n的bool矩阵 图中每个顶点使用一行和一列表示 i、j节点间有边，则矩阵第i行、j列元素为1，否则为0 无向图邻接矩阵一定是对称的，有向图邻接矩阵不一定 123456789101112131415typedef enum{DG, DN&lt; UDG, UDN} GraphKind;typedef struct ArcCell{ VRType adj; // 顶点关系类型：无权图0、1是否相邻，加权图权值类型 InfoType * info; // 弧相关信息}ArcCell, AdjMatrix[MAX_VERTEX_NUM][MAX_VERTEX_NUM];typedef struct{ VertexType vexs[MAX_VERTEX_NUM]; // 顶点向量 AdjMatrix arcs; int vexnum, arcnum; // 图当前顶点弧数 GraphKind kind;} Adjacency List邻接表：n条单链表代替邻接矩阵的n行，对应图G的n个顶点 每个顶点用一个邻接表表示 线性表的header表示对应的顶点 链表中结点表示依附于顶点的边 无向图一条边在邻接链表中对应两条链，有向图对应一条 有向图出度计算简单 计算入度则比较复杂，如果需要频繁计算入度，可以再存储 一个反向邻接表 12345678910111213141516171819typedef struct ArcNode{ int adjvex; // 弧指向顶点信息 struct ArcNode *nextarc; // 指向下条弧指针 InfoType * info; // 弧相关信息}ArcNode;typedef struct VNode{ VertexType data; // 顶点信息 ArcNode * firstarc; // 首条依附该顶点的弧指针}VNode, AdjList[MAX_VERTEX_NUM];typedef struct{ AdjList vertices; int vexnum, arcnum; int kind;} Orthogonal List十字链表：将有向图的邻接表、逆邻接表结合起来 有向图中每条弧、每个顶点对应一个结点 弧结点所在链表为非循环链表， 结点之间相对位置自然形成，不一定按照顶点序号有序 表头结点即顶点结点，顺序存储 12345678910111213141516171819typedef struct ArcBox{ int tailvex, headvex; // 头、尾顶点链域 struct ArcBox *hlink, *tlink; // 头相同、尾相同弧链域 InfoType *info; // 弧相关信息}ArcBox;typedef struct VexNode{ VertexType data; // 顶点信息 ArcBox *firstin, *firstout; // 顶点第一条出、入弧}VexNode;typedef struct{ VexNode xlist[MAX_VERTEX _NUM]; // 表头 int vexnum, arcnum;}OLGraph; Adjacency Multilist邻接多重表：无向图的另一种存储形式 一条边对应唯一结点 所有依附于同一顶点的串联在同一链表中 每个边界点同时链接在两个链表中 避免无向图邻接表中一条边两次出现 类似十字链表，仅无需区分头尾结点 12345678910111213141516171819typedef struct EBox{ VisitIf mark; // 访问标记 int ivex, jvex; // 边依附的两个顶点 struct EBox *ilink, *jlink; // 依附两个顶点的下条边 InfoType *info; // 边信息指针}EBox;typedef struct VexBox{ VertexType data; EBox *firstedge; // 第一条依附该顶点的边}VexBox;typedef struct{ VexBox adjmulist[MAX_VERTEX_NUM]; int vexnum, edgenum;}AMLGraph; 说明 稀疏图：尽管链表指针会占用额外存储器，但是相对于邻接矩阵 占用空间依然较少 稠密图：邻接矩阵占用空间较少 邻接矩阵、邻接链表都可以方便的表示加权图 邻接矩阵元素A[i, j]设置为有限值表示存在的边的权重， 设置为$\\infty$表示不存在边，此时矩阵也称 weighted matrix或cost matrix 邻接链表在节点中型跨同时包含节点名称和相应边权重 任何可以存储顶点、边的数据结构（如集合）都可以表示图， 只是存储效率低、无法高效操作 概念路径有向图 directed path：有向图中顶点的一个序列，序列中每对连续 顶点都被边连接，边方向为一个顶点指向下一个顶点 directed cycle：有向图中节点序列，起点、终点相同，每个 节点和其直接前趋之间，都有一条从前趋指向后继的边 directed acyclic graph：DAG，有向无环图 无向图 path：（无向）图G中始于u而止于v的邻接顶点序列，即为顶点u 到顶点v的路径 simple path：路径上所有点互不相同 cycle：特殊的path 起点、终点都是同一顶点 长度大于0 不包含同一条边两次 acyclic：不包含回路的图 长度 length：路径中代表顶点序列中的顶点数目减1，等于路径中 包含的边数目 distance：顶点间距离，顶点之间最短路径长度 连通性无向图 connected：顶点u、v连通，当且仅当存在u到v的路径 connected graph：连通图，对图中的每对顶点$(u, v)$， 都有从u到v的路径 connected component：连通分量，给定图的极大连通子图， 即没有可以添加的连通子图用于扩充 非连通图中包含的几个自我连通的部分 articulation point：关节点，如果从连通图$G$中删除顶点 $v$、极其邻接边各点之后的的图$G^{‘}$至少有两个连通分量， 则称顶点$v$为关节点 biconnected graph：重连通图，没有关节点的连通图 biconnected component：重连通分量，连通图的最大重连通 子图，即不是其他重连通分量的真子图 两个重连通分量不可能共享一个以上节点，即图的一条边 不可能同时出现在两个重连通分量中 （否则两个“重连通分量”可以合并） 所以可以说重连通分量是对原图的边的划分 有向图 强连通图：对所有不同顶点u、v，都存在u到v、v到u的路径 strongly connected component：强连通分量，有向图的 极大连通子图 源点、汇点 soruce：源，没有输入边的顶点 sink：汇点，没有输出边顶点 图遍历遍历图：实质是对每个顶点查找其邻接顶点的过程 具体算法参见algorithm/problem/graph 遍历方式 BFS：Breadth First Search：广度优先搜索，类似树的先序 遍历 DFS：Depth First Search：深度优先搜索，类似树的按层次 遍历 具体算法参见algorithm/problem/graph 结点处理顺序 post-order：后序，先处理子节点，再处理当前结点 pre-order：前序，先处理当前结点，再处理子节点 搜索森林中仅有一棵树时 前序、后序均满足处理顺序（后序为逆处理顺序） 前序、后序处理仅是处理顺序刚好相反 搜索森林中有多棵树时，将每棵树视为一个结点考虑 每个树内前序、后序顶点处理顺序相反 不同树整体前序、后序处理顺序相反 此时前序不再满足处理顺序，后序仍为逆处理顺序，所以 前序不常用 节点处理记录方式 栈：出栈顺序同记录反向 队列：出队列顺序同记录顺序 总结 Pre-Order：正前序，先当前顶点、后子顶点，队列存储 Reverse Pre-Order：逆前序，先子顶点、后当前顶点， 栈存储 Post-Order：正后序，先当前顶点、后子顶点，队列存储 Reversed Post-Order：逆后序，先子顶点、后当前顶点， 栈存储，也称为伪拓扑排序 可以用于得到DAG的拓扑有序序列 也可以用于得到有环有向图的伪拓扑序列 强连通分量整体看作结点，组成DAG 各强连通分量必然可以选出某个顶点，满足在伪拓扑 序列中次序先于DAG中先驱强连通分量所有顶点 用途最广 有向图拓扑排序 Kosaraju算法中用到 BFS、DFS森林广度优先、深度优先生成森林 遍历的初始顶点可以作为森林中树的根 遇到新未访问的顶点，将其附加为直接前趋子女 其实仅有树向边才是符合森林定义（其他边都只是搜索过程 中遇到） DFS森林中边是从左到右逐渐生成 BFS森林中边是从上到下逐渐生成 边类型 tree edge：树向边，连接父母、子女的边 back edge：回边，连接非直接前驱的边 对有向图包括连接父母的边 对无向图不存在连接父母边 cross edge：交叉边，连接非前驱、后继的边 forward edge：前向边，连接非直接后代的边 边存在性 无向图 DFS森林：只可能有回边 BFS森林：只可能有交叉边 有向图 DFS森林：可以都有 BFS森林：只可能有回边、交叉边 Spanning Tree生成树/极小连通子图：包含图中所有顶点的连通无环子图（树） n个顶点的生成树有且仅有n-1条边，反之不成立 在生成树添加一条边必定构成一个环，因为其实使得其依附的 两个顶点之间生成了第二条路径 Minimum Cost Spanning Tree最小生成树：图的一棵权重最小的生成树（权重指所有边权重之和） MST性质 若$N=(V, {E})$是连通网，U是顶点集V的非空子集，若 $(u, v), u \\in U, v \\in V-U$是一条具有最小权值（代价）边 ，则图中存在最小生成树包含该边 假设网N中最小生成树T不包含边$(u, v)$，将其加入T中 因为T为生成树，所以必存在边 $(u^{‘}, v^{‘}), u^{‘} \\in U, v^{‘} \\in V-U$，且 $u, u^{‘}$、$v, v^{‘}$之间均有路径连通 则删除$(u^{‘}, v^{‘})$可以消去上述回路，得到新生成树 $T^{‘}$，且代价不大于$T$，矛盾 存在是考虑到存在其他同权值边，若权值严格最小，则所有 最小生成树必然包含 依此性质生成算法参见algorithm/problems/graph 连通性 对图进行遍历是判断图连通性、求解连通分量的好方法 有向图 连通图：从图中任意顶点出发，进行深度、广度优先搜索即可 访问到图中所有顶点 利用DFS生成树可以找出图的重连通分量 非连通图：需要从多个顶点起始进行搜索 每次从新的起始点出发进行搜索过程中得到顶点访问 序列就是各个连通分量的顶点集 无向图 深度优先搜索是求有向图强连通分量的有效方法 具体算法参见algorithm/problem/graph","link":"/Algorithm/Data-Structure/graph.html"},{"title":"Tree","text":"树&amp;森林Free tree自由树：连通、无回路图，具有一些其他图不具有的重要 特性 边数总比顶点数少一：$|E|=|V|-1$ 这个是图为一棵树的必要条件，但不充分 若图是连通的，则是充分条件 任意两个顶点之间总是存在简单路径 (Rooted)Tree（有根）树：存在根节点的自由树 Tree = (root, F) $root$：根节点数据元素 $F=(T_1, T_2, \\cdots, T_m)$：森林 $T_i=(r_i, F_i)$：根root的第i棵子树 在任意一棵非空树中 有且仅有一个特定称为根的节点 节点数n&gt;1时，其余节点可以分为m个互不相交的有限集 ，每个集合本身又是一棵树，称为根的子树 树中任何两个节点间总存在简单路径，所以可以任选自由树 中某节点，作为有根树的根 有根树远远比自由树重要，所以也简称为树 根一般放在树的顶层，第0层 之后节点根据和根的距离放在相应层数 Forest森林：无回路但不一定连通的图 其每个连通分量是一棵树 对树中每个节点，其子树集合即为森林 Ordered Tree有序树：所有顶点的所有子女都是有序（不能交换次序）的有根树 应用 常用于描述层次关系 文件目录 企业的组织结构 字典的实现 超大型的数据集合的高效存储 数据编码 用于分析递归算法 state-space tree：状态空间树，强调了两种算法设计 技术：回溯、分支界限 结构 ancestor：从根到该顶点上的简单路径上的所有顶点 proper ancestor：除自身外的所有祖先顶点 parent：从根到顶点简单路径中，最后一条边的另一端节点 parental：至少有一个子女的顶点 child： sibling：具有相同父母的顶点 leaf：没有子女的顶点 descendent：所有以该顶点为祖先的顶点 proper descendent：不包括顶点自身的子孙 subtree：顶点的所有子孙、连接子孙的边构成以该顶点为根的 子树 depth：根到该顶点的简单路径的长度 height：根到叶节点的最长简单路径的长度 链式存储结构 链表结点代表树中一个顶点，其中至少包含：数据域、指向子女 的指针域 链表头指针指向二叉树根节点 双亲表存储双亲表示法 利用除根节点外，每个结点只有一个双亲，给所有结点添加一个 指向双亲的指针域 12345678typedef struct PTNode{ TElemType data; int parent;}PTNode;typedef struct{ PTNode nodes[MAX_TREE_SIZE]; int r, n;}PTree; 求结点双亲时是常数时间 求结点孩子时需要遍历整个结构 孩子链表存储孩子表示法 把每个结点的孩子结点排列起来，视为线性表，以单链表作为 存储结构 否则结点同构则浪费空间，不同构时操作不方便 123456789101112131415161718typedef struct CTNode{ // 逻辑意义的结点，存储兄弟关系 int child; // 结点位置，`nodes`中序号 struct CTNode *next; // 指示下个兄弟结点}*ChildPtr;typedef struct{ // 实际存储信息的结点 TElemType data; ChildPtr firstchild; // 孩子链表头指针}CTBox;typedef struct{ CTBox nodes[MAX_TREE_SIZE]; int n, r; // 节点数，根节点位置}CTree; 二叉链表存储First Child-next Silbling Representaion：孩子兄弟/二叉链表 /二叉树表示法 每个节点只包含两个指针，左指针指向第一个子女，右指针指向 节点的下一个兄弟 节点的所有兄弟通过节点右指针被单独的链表连接 1234typedef struct CSNode{ ElemType data; struct CSNode *firstchild, *nextsibling;}CSNode, *CSTree; 可高效的将有序树改造成一棵二叉树，称为关联二叉树 易于实现某些操作 寻找孩子结点 森林与二叉树转换 给定一棵树，可以以二叉链表为媒介导出树与二叉树之间的对应 关系，即可以找到唯一一棵二叉树和与之对应 任何一棵树对应的二叉树，其右子树必然为空 将森林中各棵树的根节点看作兄弟结点，则可以得到森林和 二叉树的对应关系 森林转换为二叉树森林$F={T_1, T_2, \\cdots, T_M}$转换为二叉树的 $B=(root, LB, RB)$ 若F为空，即m=0，则B为空树 若F非空 root即为森林中第一个树的根$ROOT(T_1)$ LB是从$T_1$中根节点的子树森林转换而成的二叉树 RB是从森林$F^{‘}$转换而来的二叉树 二叉树转换为森林二叉树的$B=(root, LB, RB)$转换为森林 $F={T_1, T_2, \\cdots, T_M}$ 若B为空，即m=0，则F为空树 若B非空 F中第一棵树根$ROOT(T_1)$即为二叉树根root $T_1$中根节点的子树森林$F_1$是由B的左子树LB转换来的 子树森林 F中除$T_1$外的其余树组成的森林$F^{‘}$是由B的右子树 RB转换而来的子树森林 树、森林遍历 以二叉链表作树、森林的存储结构式，树、森林的先（根）序 遍历、后（根）序遍历对应二叉树先序、后序遍历 Binary Tree二叉树：所有顶点子女个数不超过2个，每个子女不是父母的 left child就是right child的有序树 二叉树的根是另一棵二叉树顶点的左（右）子女 左右子树也是二叉树，所以二叉树可以递归定义 涉及二叉树的问题可以用递归算法解决 特点 二叉树第i层之多有$2^{i-1}$个节点 深度为k的二叉树最多有$2^k-1$节点 对任何二叉树$T$，如果其终端节点数$n_0$，度为2的节点数为 $n_2$，则$n_0=n_2+1$ \\left. \\begin{array}{r} 考虑节点数：n = n_0 + n_1 + n_2 \\\\ 考虑分支数：n = n_1 + 2n_2 + 1 \\end{array} \\right \\} \\rightarrow n_0 = n_2 + 1 $n, n_0, n_1, n_2$：总结点数、终端节点数、度1节点数 、度2节点数 顺序存储结构完全二叉树顺序存储结构：顺序存储完全二叉树结点元素 12typedef TElemType SqBiTree[MAX_TREE_SIZE];SqBiTree bt; 将完全二叉树编号为i的结点存储在一维数组中下标为i-1分量中 一般二叉树则将每个结点与完全二叉树结点相对照，存储在相应 分量中，并标记不存在的结点 对某些二叉树空间利用效率极低 所以顺序存储结构只适合完全二叉树 链式存储结构 二叉树的链表节点中至少包含3个域：数据域、左右指针域 链表头指针指向二叉树根节点 为方便，也可以添加一个头结点，其lchild指针域指向 根结点 二叉链表1234typedef struct BiTNode{ TElemType data; struct BiTNode *lchild, *rchild;}BiTNode, *BiTree; 含有n个结点的二叉链表中有n+1个空链域 三叉链表1234typedef struct BiTriNode{ TElemType data; struct BiTriNode *parent, *lchild, *rchild;}BiTriNode, *BiTriTree; 在二叉链表基础上增加指向双亲结点的指针域 二叉线索链表Threaded Binary Tree：线索二叉树/线索化树 使用二叉链表中的n+1个空链域存放二叉树遍历的前驱、后继 信息 附设标记域区分指针域存放子孙结点、前驱/后继 适合经常需要遍历的二叉树、查找遍历所得线性序列中前驱、 后继 时间复杂度常数系数小 无需设栈 123456typedef enum PointerTag{Link, Thread};typedef struct BiThrNode{ TElemType data; struct BitThrNode *lchild, *rchild; PointerTag LTag, RTag;}BiThrNode, *BiThrTree; 后序线索化树找后继时需要知道双亲，应该使用带标志域的 三叉链表 Complete Binary Tree 满二叉树：深度为k且有$2^k-1$节点的二叉树，每层上的节点数 都是最大节点数 完全二叉树：essentially complete，树的每层都是满的，除 最后一层最右边的元素（一个或多个）可能有缺位 特点 只存在一棵n个节点完全二叉树，高度为 $\\lfloor log_2 n \\rfloor$ 深度为k、节点数为n的完全二叉树同深度为k的满二叉树中 1-n号节点一一对应 叶子节点只可能在层次最大的两层上出现 对任一节点，其左分支只能和右分支深度相同或大1 从上到下、从左到右对结点编号，即使用数组H存储完全二叉树 （从1开始编号，数组H[0]不存储节点值，或存放限位器） 父母节点键会位于数组前$\\lfloor n/2 \\rfloor$个位置中 ，叶子节点位于后$\\lceil n/2 \\rceil$ 对位于父母位置i的键，其子女位于2i、2i+1，相应的对于 子女位置i的键，父母位于$\\lfloor i/2 \\rfloor$ 应用 堆 二叉树高度 将空树高度定义为-1 算法12345678Height(T): // 递归计算二叉树的高度 // 输入：二叉树T // 输出：T的高度 if T = null_set return -1 else return max{Height(T_left), Height(T_right)} + 1 特点 检查树是否为空是这个算法中最频繁的操作 算法时间效率 树的节点数为n，则根据加法操作次数满足递推式 $A(n(T))=A(n(T{left})) + A(n(T{right})) + 1$， 得到$A(n(T)) = n$ 考虑为树中每个节点的空子树添加外部节点得到 扩展树，则外部节点数量x满足$x=n+1$ 检查树是否为空次数即为扩展树节点数目 $C(n(T))=n+x=2x+1$ 二叉树遍历 不是所有关于二叉树的算法都需要遍历两棵子树，如：查找、 插入、删除只需要遍历两颗子树中的一棵，所以这些操作属于 减可变规模（减治法） 先序、中序、后序遍历都需要用到栈 中序遍历得到的序列称为中序置换/中序序列，先序、后序类似 递归版本 Preorder Traversal：先序 123456PreOrder(T): visit(T) if T_left not null: PreOrder(T_left) if T_right not null: PreOrder(T_right) Inorder Traversal：中序 123456InOrder(T): if T_left not null: InOrder(T_left) visit(T) if T_right not null: InOrder(T_right) Postorder Traversal：后序 123456PostOrder(T): if T_left not null: PostOrder(T_left) visit(T) if T_right not null: PostOrder(T_right) 栈非递归 先序遍历 深度优先入栈：左子树优先入栈 节点先访问后入栈，栈内存已访问节点 1234567891011121314151617181920212223PreOrder(T): s = InitStack() cur = T while s.not_empty() or cur: while cur: visit(cur) s.push_back(cur) cur = cur.left cur = s.pop() cur = cur.right// 等价写法，仅使用`if`利用外层循环PreOrder(T): s = InitStack() cur = T while s.not_empty() or cur: if cur: visit(cur) s.push_back(cur) cur = cur.left else: cur = s.pop() cur = cur.right 基于对遍历性质的考虑 扩展性较好，可以扩展到中序、后序遍历 广度优先入栈：同层右、左节点先后入栈 12345678910PreOrder(T): s = InitStack() s.push_back(T) while s.not_empty(): cur = s.pop() if cur.right: s.push_back(cur.right) if cur.left: s.push_back(cur.left) visit(cur) 中序遍历 深度优先入栈 节点先入栈后访问，栈内存未访问节点 1234567891011121314151617181920212223InOrder(T): s = InitStack() cur = T while s.not_empty() or cur: while cur: s.push_back(cur) cur = cur.left cur = s.pop() visit(cur) cur = cur.right// 等价写法，仅使用`if`利用外层循环InOrder(T): s = InitStack() cur = T while s.not_empty() or cur: if cur: s.push_back(cur) cur = cur.left else: cur = s.pop() visit(cur) cur = cur.right 后序：需要标记当前节点左、右子树是否被访问 深度优先入栈 节点先入栈后访问，栈内存未访问节点 记录最后一次访问节点，判断右子树是否被访问 （若右子树被访问，右子节点必然是上个被访问节点） 1234567891011121314151617PostOrder(T): s = InitStack() cur = T last = NULL while s.not_empty() or cur: while cur: s.push_back(cur) cur = cur.left cur = s.top() // 检查右子树是否被访问过 if cur.right == NULL or cur.right == last: visit(cur) last = s.pop() // 此时再弹出`cur` cur = NULL // 置`cur`为`NULL`，否则 // 再次访问左子树，死循环 else: cur = cur.right 或者为每个节点附设标志位 层次遍历 队列实现 1234567891011121314151617181920212223242526# 判断节点是否存在、再填充至队列LevelTraversal(T): q = InitQueue() cur = T while q.not_empty() or cur: if cur.left: q.push_back(cur.left) if cur.right:d q.push_back(cur.right) visit(cur) cur = q.pop_first()# 先填充、再判断节点是否为`None`# 填充可保证、适合节点位置和满二叉树对应LevelTraversal(T): q = InitQueue() q.push(T) # 层次遍历使用队列实现，所以无需像栈一样使用 # 两个判断条件`q.not_empty or cur` while q.not_empty(): cur = q.pop_first() # 弹出时判断节点是否有效 if cur: visit(cur) q.push_back(cur.left) q.push_back(cur.right) 严格分层遍历：记录队列长度、遍历固定长度 12345678910111213LevelTraversal(T): q = InitQueue() q.push(T) while q.not_empty(): # 记录当前开始时队列长度 # 每轮遍历该长度数目元素，严格分层遍历节点 for i=0 to len(q): cur_node = q.pop_left() visit(cur_node) if cur.left: q.push_back(cur.left) if cur.right: q.push_back(cur.right) 树的计数 二叉树相似：二者为空树或二者均不为空树，且其左右子树分别 相似 二叉树等价：二者不仅相似，而且所有对应结点上的数据元素 均相同 二叉树的计数：n个结点、互不相似的二叉树数量$b_n$ 树和一棵没有右子树的二叉树一一对应，所以具有n个结点不同 形态的树的数目，等于具有n-1个结点互不相似的二叉树数目 数学推导二叉树可以看作是根节点、i个结点的左子树、n-i-1个结点的右子树 组成，所有有如下递推 \\left \\{ \\begin{array}{l} b_0 & = 1 \\\\ b_n & = \\sum_{i=0}^{n-1} b_i b_{n-i-1}, & n \\geq 1 \\end{array} \\right.求解得 b_n = \\frac 1 {n+1} \\frac {(2n)!} {n!n!} = \\frac 1 {n+1} C_{2n}^n遍历性质 给定结点的前序序列、中序序列，可以唯一确定一棵二叉树 n个结点，不同形态二叉树数目恰是前序序列为$1 \\cdots n$ 二叉树能得到的中序序列数目 中序遍历过程实质是结点进栈、出栈的过程，序列$1 \\cdots n$ 按不同顺序进栈、出栈能得到排列的数目即为中序置换数目 $C{2n}^n - C{2n}^{n-1} = \\frac 1 {n+1} C_{2n}^n$","link":"/Algorithm/Data-Structure/tree.html"},{"title":"Heap","text":"Heap堆/大根堆：每个节点包含一个键、且大于等于其子女键、基本完备 的二叉树 认为非叶子节点自动满足大于其子女键值 根到某个叶子节点路径上，键值序列递减（允许键值相等则是 非递增） 键值之间没有从左到右的次序，即树的同一层节点间没有任何 关系，或者说左右子树之间没有任何关系 堆特性 完全二叉树特性参见完全二叉树 堆的根总是包含了堆的最大元素 堆的节点及该节点子孙也是一个堆 堆这种数据结构经常被用于实现优先队列 最小堆min-heap：（最大）堆的镜像 堆的主要特性最小堆也满足，但 最小堆根节点包含最小元素 可通过给元素取反构造（最大）堆得到最小堆 堆算法Bottom-Up Heap Construction自底向上堆构造：先利用所有元素构造二叉树，从倒数第二层开始 修改使得整棵树满足堆要求 算法 将给定线性表对应为（初始化）一棵完全二叉树 对二叉树进行堆化，从最后父母节点开始、到根为止，算法检查 节点键是否满足大于等于其子女键 若不满足，交换节点键K和其子女最大键值 在新位置上检查是否满足大于子女键值，直到满足为止 对以当前节点为根的子树满足堆化条件后，算法对节点直接前趋 进行检查，直到树根满足堆化 123456789101112131415161718192021222324252627282930HeapAdjust(H[0..n-1], cur): // 左右子树已经为堆，仅根节点元素不一定满足 // 输入：待调整堆H、根节点cur，cur左右子树已经为堆 // 输入：调整后堆 while 2*cur+2 &lt; n: // 获取左右子女中最大者 if 2*cur+2 &lt; n: _tmp = argmax(H[2*cur+1], H[2*cur+2]) else: _tmp = 2*cur+1 // 交换自身和最大子女 if H[_tmp] &gt; H[cur]: swap(H[cur], H[_tmp]) cur = _tmp else: // 从底向上建堆，左、右子树均为堆 // 则此时已经满足堆性质 break return HHeapBottomUp(H[0..n-1]): // 用自底向上算法，从给定数组元素中构造一个堆 // 输入：可排序数组H[0..n-1] // 输出：堆H[0..n-1] for i=floor((n-1)/2) to 0: HeapAdjust(H, i) return H 算法特点 算法效率 时间效率：最差情况，每个位于树第i层节点会移到叶子层 h中，每次移动比较两次，则总键值比较次数 $C_{worst}=2(n-log_2(n+1))$ （将各层叶子节点可能交换次数加总即差比数列求和） Top-Down Heap Construction自顶向下堆构造算法：先利用部分元素构建堆顶，把新键连续插入 已经构造好的堆末尾，修改使之满足堆要求 算法 把包含键K的新节点附加在当前堆最后一个叶子节点 将K与其父母进行比较 若后者大于K，算法停止 否则交换这两个键，并比较K和其新父母，直到K不大于其 父母或是达到了树根 算法特点 算法效率 操作所需键值比较次数小于堆高度$h \\approx log_2 n$， 则总比较次数$\\in \\Theta(nlogn)$ 删除堆根节点算法 根键和堆中最后一个键K交换 堆规模减1（删除原根键） 按照自底向上堆构造算法，把K沿着树向下筛选使得新树满足 堆化 算法特点 算法效率 效率取决于树堆化所需比较次数，不可能超过树高度两倍， 即$\\in O(logn)$ 堆排序算法算法 为给定数组构造堆 删除最大键，即对堆应用n-1此根删除操作 算法特点 算法效率 根删除阶段算法所需比较次数 \\begin{align} C(n) & \\leq 2\\sum_{i=1}^{n-1} \\lfloor log_2i \\rfloor \\\\ & \\leq 2 \\sum_{i=1}^{n-1} log_2(n-1) \\\\ & = 2(n-1)log_2(n-1) \\end{align} 两阶段总效率$\\in O(nlogn)$ 详细分析证明，无论最差情况、平均情况下，时间效率 $\\in \\Theta(nlogn)$ 堆排序时间效率和归并排序、快排时间效率属于同一类，但是 堆排序是在位的（不需要额外存储空间） 随机实验表明：堆排序比快排慢、和归并排序相比有竞争力","link":"/Algorithm/Data-Structure/tree_heap.html"},{"title":"高维检索树","text":"K-dimentional TreeKd树：循环遍历各维度，按该维度取值二分数据 对高维数据进行快速搜索二叉树 超平面都垂直于轴的BSPTree Kd树对样本点的组织表示对k维空间的划分 每个节点对应k维空间中超矩形区域 构造kd树相当于用垂直于坐标轴超平面不断划分k维空间， 得到一系列超矩形区域 Kd树构建目标 树应该尽量平衡，即分割应尽量均匀 最大化邻域搜索的剪枝 建树 输入：数据点$X_i, i=1,2,\\cdots,N$ 确定划分维度（轴） 选择方差最大的轴，使得数据尽量分散 按次序循环遍历所有轴：方便查找时定位轴 选择该维度上数值中位数作为划分点 中位数查找方法 各维度统一全体排序、记录 抽样，使用样本中位数 小于中位数的数据点划分至左子树，否则划分至右子树 递归建立左、右子树直至无法继续划分 节点中包含数据项数量小于阈值 查找K近邻 输入：Kd树、目标点x 在Kd树中找出包含目标点x的叶节点，以之为近邻点 从根节点出发，与节点比较对应坐标值，递归访问至叶节点 为止 目标点在训练样本中不存在，必然能够访问到叶节点 沿树回溯，检查节点是否距离目标点更近，尝试更新 检查该节点另一子区域是否可能具有更近距离的点 即考察以目标点为圆心、当前近邻距离为半径圆，同划分轴 是否相交 则只需比较目标点同相应切分平面距离、近邻距离 若目标点同该对应切分平面距离小于近邻距离 则将目标节点视为属于该子区域中的点 从节点未访问子树开始重复以上步骤，进行近邻搜索 否则继续回退 退回到根节点时，搜索结束，近邻点 回溯过程中需要盘对子域是否访问过，可以通过标记、比较相应 轴坐标等方式判断 k&gt;1的情况类似，不过检测时使用最远近邻，新近邻需要和所有 原近邻依次比较 其他操作插入新节点 从根节点出发，根据待插入节点、当前节点在对应维度取值确定 插入左、右子树 遍历直至叶子节点，插入 删除节点 简单方法：将待删除节点子节点组成新集合，对其重新构建， 将新子树挂载在原被删节点位置 分类讨论：设删除节点T对应划分维度为D 节点无子树：直接删除 节点有右子树 在右子树寻找维度D取值最小节点P，替换被删除节点T 在右子树递归处理删除节点P 节点无右子树有左子树 在左子树寻找维度D取值最小节点P，替换被删除节点T 将T的左子树作为P的右子树 在右子树递归处理删除节点P 查找维度D最小点 若当前结点切分维度为D：只需查找左子树 否则需要对左、右子树分别递归搜索 Vantage Point TreeVP树：任选样本点，按照数据点与该点距离二分数据 对高维数据进行快速搜索二叉树 VP树对样本点的组织表示对k维空间的划分 每个节点对应k维空间中一个球形划分 构造kd树相当于用以给定样本点为球心不断划分k维空间， 得到一系列球内、球外区域 建树 输入：数据$X_i, i=1,2,\\cdots,n$ 选择某数据点$X_v$作为划分球心 计算其他数据点距离$D_i = d(X_i, X_v)$ 求出$D_i$中位数$M$ 与$X_v$距离$D_i \\leq M$的数据点$D_i$划分至左子树 与$X_v$距离$D_i \\gt M$的数据点$D_i$划分至右子树 Rectangle TreeR树：将空间划分为有重叠的 B树高维推广 类似B树将一维区间划分为多个不重叠的子区间 同样是平衡树，所有叶子位于同一层上 R树退化至1维有分割区间重叠问题，效果不如B树 性质 $M$：节点中最大键数量 $m \\leq \\frac M 2$：节点中条目最小数量 非根叶节点包含$m-M$索引记录：$I$表示可在空间中完全覆盖 节点中条目点的MBR 非根、非叶节点包含$m-m$个子节点：$I$表示可在空间中完全 覆盖节点中条目矩形的MBR 根节点条目数$[2, m]$，除非为叶子节点 minimal bounding rectangle：MBR，最小边界矩形 节点结构 叶子节点结构：$(I, tuple-ids)$ $I((s_1, e_1), (s_2, e_2), \\cdots, (s_n, e_n))$： n维空间中矩形 $tuple-ids$：节点包含的记录 非叶节点：$(I, child-pointer)$ 操作建树矩形搜索1234567891011121314151617181920SearchRect(T, S, ret): // 利用R树搜索矩形范围中包含的记录点 // 输入：R树根节点T、待搜索矩形S // 输出：矩形S覆盖的条目 if T.I join S == NULL: return // 若T不是叶子节点，检查其每个条目E if not T.is_leaf(): for E in T.entries: // 对与S相交E.I对应条目E，递归调用搜索 if T.I join S != NULL: SearchRect(E, S, ret) // 若T是叶子节点且T.I与S相交，检查其每个记录点 elif T.I join S != NULL: for E in T.entries: if E in S: ret.add(E) 选择所属叶子12345678910111213ChooseLeaf(T, E): // 在R树中寻找新索引条目所属叶子节点 // 输入：R树根节点T、索引条目E // 输出：E所属R树中叶子节点 if T.is_leaf(): Assert(E.is_subset(T)) return T else: for T_E in T.entries: if E.is_subset(T_E) return ChooseLeaf(T_E, E) or T_E 插入新条目123456789101112Insert(T, E): // 向R树中插入新条目 // 输出：R树根T、新条目E L = ChooseLeaf(T, E) if L.has_slot(): L.add(E) else: LL = L.split() L.add(E) P = L.get_parent() 调整树1234567891011121314AdjustTree(T, L): // 从不满足节点开始调整R树至满足要求 // 输入：R树根T、不满足要求节点L // 输出： if L.is_root(): return P = L.get_parent_node() if L.splitted(): NN = L.get_split_node() if P. // 调整节点L在父节点中矩形框I大小 addjust_I(P.L.I) R*-treeX-treeSS-treeSR-TreeMetric-tree","link":"/Algorithm/Data-Structure/tree_high_dimension.html"},{"title":"线性最长问题","text":"最长公共子串求两个字符串s1、s2（长度分别为m、n）最长公共子串长度 矩阵比较 将两个字符串分别以行、列组成矩阵M 对矩阵中每个元素$M[i, j]$，若对应行、列字符相同 元素置为1，否则置0 置元素$M[i,j] = M[i-1, j-1] + 1$，否则置0 则矩阵中最长的非0斜序列对应子串即为最长公共子串 算法特点 时间效率$\\in \\Theta(mn)$ 输入增强 最长公共子序列求两个序列X、Y的最长公共子序列 子序列：去掉给定序列中部分元素，子序列中元素在原始序列中 不必相邻 最长公共子序列可能有很多 动态规划 先使用动态规划确认最长子序列长度，构造动态规划表 C[i,j] = \\left \\{ \\begin{array}{l} 0 & i=0 或 j=0 \\\\ C[i-1, j-1] & i,j > 0 且 X[i] == Y[j] \\\\ max\\{C[i-1, j], C[i, j-1]\\} & i,j > 0 且 X[i] != Y[j] \\\\ \\end{array} \\right. $C[i,j]$：序列X前i个元素子序列、序列Y前j个元素子序列 最大子序列长度 根据动态规划表找出最长公共子序列 从动态规划表中首个格子开始，沿着某条格子路径达到 表中最后一个元素 路径中值改变格子对应序列中元素即为最长公共子序列中 元素 不同格子路径可能找到不同的最长公共子序列 算法特点 时间效率 动态规划部分$\\in \\Theta(|X||Y|)$ 生成公共子序列部分$\\in Theta(|X|+|Y|)$ 动态规划 最长升/降序序列寻找长度为N的序列L中最长单调自增子序列 最长公共子序列法 将原序列升序排序后得到$L^{ * }$ 原问题转换为求$L, L^{ * }$最长公共子序列 算法特点 时间效率：$\\in \\Theta(|L|^2)$ 动态规划法 使用动态规划法求出以$L[i]$结尾的最长升序子序列长度， 得到动态规划表 C[i] = \\left \\{ \\begin{array}{l} max\\{C[j]\\} + 1, j=1,\\cdots,i-1, L[j]","link":"/Algorithm/Issue/longest_xx.html"},{"title":"组合问题","text":"总述 寻找（明确地、隐含地）寻找一个组合对象 排列 组合（整数规划） 子集 这些对象能满足特定条件并具有想要的属性 价值最大化 成本最小化 特点无论从理论角度、实践角度而言，组合问题是计算领域最难的问题 随着问题规模增大，组合对象数量增长极快 没有一种已知算法，能在可接受的时间范围内，精确的解决 大部分组合问题，且被普遍认为不存在（未被证实） 有些组合问题有高效求解算法，是幸运的例外 从更抽象的角度看，旅行商问题、图填色问题也是组合问题的特例 思路 exhaustive search：（穷举搜索）是简单的蛮力方法 生成问题域每个元素 选出满足问题约束的元素 最后寻找期望元素 因为可能性太多，基本可能从动态规划方向着手 背包问题给定n个重量为$w_1, w_2, \\cdots, w_n$价值为$v_1, v_2, …, vn$ 的物品和承重为$W$的背包，求能够装进背包的最有价值物品子集 蛮力算法算法 考虑所有n个物品的子集 计算每个子集重量，找出可行子集 找到可行子集中价值最大子集 经典自底向上动态规划依次求解所有子问题、记录 算法设$F(i, j)$为由前i个物品、承重量为j的背包得到最优解 不包括第i个物品的子集中，最优子集价值为$F(i-1, j)$ 包括第i个物品的子集中，最优子集是由该物品和前i-1个物品 中能够放进承重量为$j-w_i$的背包的最优子集组成，总价值为 $v_i + F(i-1, j-w_i)$ 则递推式为 F(i, j) = \\left \\{ \\begin{array}{l} max\\{F(i-1, j), v_i + F(i-1, j-w_i)\\} & j-w_i \\geqslant 0 \\\\ F(i-1, j) & j-w_i \\leqslant 0 \\\\ 0 & i=0 or j=0 (i, j \\geqslant 0) \\end{array} \\right.123456789101112131415Knapsack(Ws[1..n], Vs[1..n], W) // 动态规划求解背包问题 // 输入：Ws[1..n]物品重量、Vs[1..n]物品价值，W背包承重 // 输出：背包能够装载的最大价值 for i = 0 to n do F[i, 0] = 0 for j = 0 to W do F[0, j] = 0 for i = 1 to n do if j &gt;= Ws[i]: F[i, j] = max(F[i-1, j], Vs[i] + F[i-1, j-Ws[i]) // 这里用于比较的F值，在之前的循环中已经确定 else F[i, j] = F[i-1, j] return F[n, W] 算法特点 算法效率 时间效率$\\in \\Theta(nW)$ 空间效率$\\in \\Theta(nW)$ 回溯求最优解组成效率$\\in O(n)$ 自顶向下动态规划算法1234567891011121314151617MFKnapsack(i, j) // 背包问题的记忆功能方法 // 输入：i考虑的物品数量，j背包承重 // 输出：前i个物品的最优可行子集 // Ws[1..n]、Vs[1..n]、F[0..n, 0..W]作为全局变量 for i = 0 to n do F[i, 0] = 0 for j = 0 to W do F[0, j] = 0 if F[i, j] &lt; 0 if j &lt; Ws[i] value = MFKnapsack(i-1, j) else value = max(MFKnapsack(i-1, j), Vs[i] + MFKnapsack(i-1, j - Ws[i])) F[i, j] = value return F[i, j] 算法特点 算法效率 相较于经典自底向上算法，时间效率提升常数因子，但是 效率仍然$\\in \\Theta(nW)$ 相较于自底向上算法空间优化版版本而言，空间效率较低 分支界限法 不失一般性认为，物品按照价值重量比$v_i / w_i$降序排列， 可以简化问题 第i层节点上界可取$ub = v + (W - w)(v{i+1} / w{i+1})$ $v$：已选物品价值 $W - w$：背包剩余承重量 $v{i+1}/w{i+1}$：剩余物品单位单位最大价值 更紧密、复杂的上界 $ub = v + \\sum{k=i+1}^K v_k + (W - \\sum{k=1}^K w_k)v_K / w_K$ 算法特点 分支界限法求解背包问题中，每个中间节点都是给定物品的子集 ，是背包问题的可行解 背包问题近似算法贪婪算法算法 对物品按照价值重量比$r_i = v_i / w_i, i=1,2,\\cdots,n$ 降序排列 重复以下直到有序列表中不留下物品 如果列表中当前物品可以装入，则放入背包并处理下个物品 否则忽略，直接处理下个物品 特点 原始的贪婪算法解的精确率没有上界 考虑：承重量为$W$背包，如下物品 |物品|重量|价值|价值/重量| |——-|——-|——-|——-| |1|1|2|2| |2|w|w|1| 则近似解精确率$r(s_a) = W/2$无上界 增强版贪婪算法：取贪婪算法解、能装载的价值最大单个物品 价值中较大者 此改进的性能比可以降到2 近似方案背包问题的存在多项式时间的系列算法，可以调节算法中参数$k$ 得到满足任意预定义精确率的近似解$s_a^{(k)}$ \\frac {f(s^{*})} {f(s_a^{(k)}} \\leqslant 1 + 1/k, k=1,2,\\cdots, n-1Sahni方案 生成所有小于k个物品的子集 向贪婪算法一样，向每个能装入背包的子集添加剩余物品中 价值重量比最大者 得到最有价值的修改后子集作为结果返回 Fully Polynomial Scheme完全多项式方案 特点 Sahni方案理论意义远大于实用价值 其效率$\\in O(kn^{k+1})$是n的多项式函数 但是是k的指数函数 完全多项式方案更加复杂，但没有效率为参数k指数的缺陷 Bin-Packing Problem装箱问题：给定n个问题，大小都是不超过1的有理数，将其装进数量 最少的大小为1的箱子中 Graph-Coloring Problem图着色问题：对给定图，求使得任何两个相邻顶点颜色都不同时， 需要分配给图顶点的颜色数量 划分问题给定n个正整数${a_i, i=1,2,\\cdots}，判定能够将其划分为和相等 的两个子集 Subset-Sum Problem给定n个正整数${a_i, i=1,2,\\cdots}$，求子集$S$和为正整数d 回溯算法约束 s + a_{i+1} > d \\\\ s + \\sum_{j=i+1}^n a_j < d 其中$s$为考虑考虑第i+1元素时，前i个元素选情况下的和 算法 假设集合元素按升序排列 根节点为未选择任何元素 依次考虑将元素$a_i$添加进子集S中 若满足约束条件、下个元素未考虑，继续考虑 否则回溯，重新考虑父母节点 直到找到子集满足和为d，或第二次回溯到根节点 特点币值最大化给定一排n个硬币，币值为正整数$c_i, i=1, 2, \\cdots, n$（币值 不唯一），在原始位置不相邻的情况下，使得所选硬币总金额最大 动态规划算法记最大可选金额为$F(n)$将可行规划分为两组 包含最后一枚硬币，最大金额为$c_n + F(n-2)$ 不包含最后一枚硬币，最大金额为$F(n-1)$ 则递推方程为 F(n) = max\\{c_n + F(n-2), F(n-1)\\}, n>1 \\\\ F(0) = 0, F(1) = c_1123456789CoinRow(C[1..n]) // 在所选硬币不相邻，从一排硬币中选择最大金额 // 输入：C[1..n]保存n个硬币面值 // 输出：可选硬币最大金额 F[0] = 1 F[1] = C[1] for i = 2 to n do F[i] = max(C[i] + F[i-2], F[i-1]) return F[n] 算法特点 时间效率$\\in \\Theta(n)$ 空间效率$\\in \\Theta(n)$ 找零问题需找零金额为n，最少需要多少面值为$d_1 &lt; d_2 &lt; \\cdots &lt; d_n$ 的硬币，考虑$d_1 = 1$的一般情况 动态规划算法记$F(n)$为总金额为n的数量最少的硬币数目，定义$F(0)=0$ 得到n的途径只能是在$n-d_j$上加入面值为$d_j$的硬币，其中 $j=1, 2, \\cdots, m$，且$n \\geqslant d_j$ 考虑所有满足条件$d_j$，选择使得且$F(n - d_j)$最小者 则递推式有 F(n) = \\left \\{ \\begin{array}{l} min \\{ j: n \\geqslant d_j \\} \\{ F(n - d_j) \\} + 1 & n > 0 \\\\ 0 & n = 0 \\end{array} \\right.12345678910111213ChangeMaking(D[1..m], n) // 动态规划法求解找零问题，d_1 = 1 // 输入：正整数n，币值数组D[1..m] // 输出：总金额为n的最少硬币数目 F[0] = 0 for i = 1 to n do tmp = \\infty j = 1 while j &lt;= m and i &gt;= D[j] do tmp = min(F[i-D[j], tmp) j += 1 F[i] = tmp + 1 return F[n] 硬币收集问题在n * m格木板中存放有硬币，每格硬币最多一个，寻找左上角(1,1) 到右下角(n, m)路径，使得能够收集尽可能多硬币，每次只能向下、 向右移动 动态规划算法记$F(i, j)$为截止到第i行、第j列单元格$(i, j)$能够收集到最大 硬币数 单元格$(i, j)$只能经由$(i-1, j)$、$(i, j-1)$达到 初值1：假定$F(0, j)=0, F(i, 0)=0$ 初值2；递推求解$F[1, j], F[i, 1]$ 则递推方程为 F(i, j) = \\left \\{ \\begin{array}{l} max \\{F(i-1 ,j), F(i, j-1)\\} + c_{ij} & 1","link":"/Algorithm/Problem/combination.html"},{"title":"几何问题","text":"总述处理类似于点、线、多面体这样的几何对象 最近对问题给定平面上的n个点中，距离最近的两个点 点数量n不大3时，可以通过蛮力算法求解的 假设集合中每个点均不相同、点按其x坐标升序排列 另外使用算法得到点按照y坐标升序排列的列表Q 蛮力算法算法123456789BruteForceClosestPoints(p) // 蛮力算法求平面中距离最近的点 // 输入：n个点的列表p；p_i = (x_i, y_i) // 输出：两个最近点的距离 d = \\infty for i = 1 to n -1 do for j = i+1 to n do d = min(d, sqrt((x_i - x_j)^2 + (y_i - y_j)^2)) return d 改进 忽略平方根函数，只比较平方 分治法 在点集在x轴方向中位数m作垂线，将点集分成大小为 $\\lceiling n/2 \\rceiling, \\lfloor n/2 \\rfloor$两个子集 $P_l, P_r$，然后递归求解子问题$P_l, P_r$得到最近点问题解 定义$d=min{d_l, d_r}$ d不一定是所有点对最小距离 最小距离点对可能分别位于分界线两侧，在合并子问题的 解时需要考虑 只需要考虑关于m对称的2d垂直带中的点，记S为来自Q、位于 分隔带中的点列表 S同样升序排列 扫描S，遇到距离更近的点对时更新最小距离$d_{min}=d$ 对于S中点P，只需考虑在其后、y坐标差小于$d_min$ 的矩形范围内点（因为S有序，P前的点已经考虑过） 该矩形范围内点数目不超过6个（包括P），所以考虑下个点 前，至多考虑5个点 123456789101112131415161718192021222324252627EfficientClosestPair(P, Q) // 分治法解决最近点问题 // 输入：P存储平面上n个点，按x轴坐标升序排列 Q存储和P相同的n个点，按y坐标升序排列 /// 输出：最近点直接欧几里得距离 if n &lt;= 3 return 蛮力法最小距离 else 将P前ceiling(n/2)个点复制到P_l 将Q相应的ceiling(n/2)点复制到Q_l 将P余下floor(n/2)个点复制到P_r 将Q余下floor(n/2)个点复制到Q_r d_l = EfficientClosestPair(P_l, Q_l) d_r = EfficientClosestPair(P_r, Q_r) d = min{d_l, d_r} m = P[ceiling(n/2) - 1].x 将Q中所有|x-m|&lt;d的点复制到数组S[0..num-1] dminsq = d^2 for i=0 to num-2 do k = i+1 while k &lt;= num-1 and (S[k].y - S[i].y)^2 &lt; dminsq dminsq = min((S[k].x - S[i].x)^2 + (S[k].y - S[i].y)^2, dminsq) k = k+1 return sqrt(dminsq) 算法特点 算法时间效率 将问题划分为规模相同子问题、合并子问题解，算法都只 需要线性时间 运行时间递推式$T(n) = 2T(n/2) + f(n)$，其中 $f(n) \\in \\Theta(n)$，则$T(n) \\in \\Theta(nlogn)$ 已经证明在对算法可以执行的操作没有特殊假设情况下， 这是可能得到的最好效率 应用 聚类分析 凸包问题寻找能把给定集合中所有点都包含在里面的最小凸多边形 设集合S中点按照x坐标升序排列，存储在列表P中 （x坐标相同，按y坐标升序） 蛮力算法算法 对于n个点集中两个点$p_i$、$p_j$，当且仅当集合中其他点 都位于穿过这两点的直线同侧时，其连线是该集合凸包边界 一部分 检验每对点，满足条件的点即构成凸包边界 特点 算法时间效率为$O(n^3)$ 快包算法（分治法）算法 $p_1、$p_n$显然是凸包顶点，且$\\overrightarrow{p_1p_n}$ 将点集分为左右两部分$S_1$、$S_2$ 其上的点不是凸包顶点，之后不必考虑 S的凸包也被划分为upper hull、lower hull，可以使用 相同的方法构造 若$S1$为空，则上包就是线段$p_1p_n$；否则寻找距离 $p_1p_n$最大点$p{max}$，若有多个，则选择使得夹角 $\\angle p_{max}p_1p_n$最大点 $p_max$是上包顶点 包含在$\\triangle p1p{max}p_2$中的点不是上包顶点， 之后不必考虑 不存在同时位于$\\overrightarrow{p1p{max}}$、 $\\overrightarrow{p_{max}p_n}$左侧的点 对$\\overrightarrow{p1p{max}}$及其左侧点构成的集合 $S{1,1}$、$\\overrightarrow{p{max}pn}$及其左侧的点构成 集合$S{1,2}$，重复以上即可继续得到上包顶点 类似的可以对$S_2$寻找下包顶点 向量左侧、距离计算参考线代 算法特点快包和快排很类似 最差效率$\\Theta(n)$，平均效率好得多 也一般会把问题平均的分成两个较小子问题，提高效率 对于均匀分布在某些凸区域（园、矩形）的点，快包平均效率 可以达到线性 应用 计算机动画中使用凸包替换物体本身，加快碰撞检测速度 车辆路径规划 地理信息系统中根据卫星图像计算accessibility map 数理统计中用于进行异常值检测 计算点集直径的高效算法中需要用到 欧几里得最小生成树问题给定平面上n个点，构造顶点为这n个点的总长度最小的树 参考二维散点Convex Hull凸包：包含点集S的最小凸集合 离散点集：包含所有点的最小凸多边形 最小：凸包一定是所有包含S的凸集合的子集 凸包能方便地提供目标形状或给定数据集地一个近似 Extreme Point极点：对于任何以集合中点为端点的线段，不是线段中点的点 极点有一些特性是凸集中其他点不具备的性质 单纯形法：如果存在极值，则一定可以在极点处取到 找到极点、极点排序方向即可解决凸包问题 举例 三角形中3个顶点 圆周上所有点","link":"/Algorithm/Problem/geometry.html"},{"title":"数值问题","text":"总述涉及连续性数学问题 解方程、方程组，计算定积分，函数求值 和离散数学中：图、树、排序、组合相对 特点 大部分此类问题只能近似求解 泰勒展开求解$e^x$ Composite Trapezoidal rule：组合梯形法则，计算 定积分 此类问题大部分要操作实数，而实数在计算机内部只能近似表示 ，大量对近近似数的算术操作可能会叠加误差，输出错误结果 整数乘法俄式乘法两个正整数n、m相乘的非主流算法 算法 反复应用以下公式，简化每步的计算 n为奇数：n * m = \\frac n 2 * 2m + m \\\\ n为偶数：n * m = \\frac n 2 * 2m 以$1 * m$作为算法终止条件 特点 n为奇数步骤中的m，可以最后累加即可 算法中只有折半、加倍、相加操作 手动计算非常简便 计算机硬件对折半、加倍只需要移位就可 减常因子法 大整数乘法算法考虑a、b两个n位整数，n为偶数 从中间把数字分段，得到$a_1, a_0, b_1, b_0$ 则有 \\begin{align} c & = a * b = (a_1 10^{n/2} + a_0) * (b_1 10^{n/2} + b_0) \\\\ & = (a_1 * b_1)10^n + (a_1 * b_0 + a_0 * b_1) 10^{n/2} + (a_0 + b_0) \\\\ & = c_2 10^n + c_1 10^{n/2} + c_0 \\end{align} $c_2 = a_1 * b_1$ $c_0 = a_0 * b_0$ $c_1 = (a_1 + a_0) * (b_1 + b_0) - (c_2 + c_0) 若n/2也是偶数，可以使用相同的方法计算得到三个乘法表达式 若n为2的幂次，就可以得到计算n位数积的递归乘法 n迭代到足够小时，递归就可以停止 特点 算法效率 乘法次数递推式：$M(n)=3M(n/2), M(1)=1$，则 $M(n) = n^(log_2 3) \\approx n^{1.585}$ 加法次数递推式：$A(n)=3A(n/2) + cn, A(1)=1$，则 $A(n) \\in \\Theta(n^{log_2 3})$ 算法有渐进效率优势，实际性能依赖于计算机系统、算法实现 质量，在某些情况下 计算8位乘法时，分治算法速度快于传统方法 计算超过100位时，速度是传统算法2倍 分治法 欧几里得算法计算最大公约数、最大公倍数 最大公约数gcd(m, n) = gcd(n, m mod n) n为0，返回m作为结果结束 将m处以n的余数赋给r 将n付给m，r赋给n，返回第一步 123456Euclid(m, n) while n != 0 do r = m mod n m = n n = r return m 最大公倍数lcm(m, n) = \\frac {m * n} {gcd(m, n)} 利用最大公约数计算最小公倍数 特点 变治法（+减可变规模） 特定点求值霍纳法则（计算多项式）霍纳法则：不断将x作为公因子提取出来，合并降次后的项，然后 计算多项式在特定点的值 算法12345678Horner(P[0..n], x) // 用霍纳法则求多项式在给定点的值 // 输入：多项式系数数组P[0..n]、数字x // 输出：多项式在x点的值 p = P[n] for i = n-1 downto 0 do p = x*p + P[i] return p 特点 算法效率 效率始终为n，只相当于直接计算中$a_n x^n$的乘法数量 变治法 二进制（计算）幂将幂次转换为二进制位串，利用二进制位串简化计算 从左至右二进制幂 对位串应用霍纳法则 12345678910LeftRightBinaryExponentiation(a, B[0..n-1]) // 从左至右二进制幂算法计算a^n // 输入：数字a、表示幂次的二级制位串B[0..n-1] // 输出：a^n的值 product = a for i = n-1 downto 0 do product = product * product if B[i] == 1: prduct = product * a return product 从右至左二进制幂 累次计算二进制位串中为1部分值，将其累乘 12345678910111213141516RightLeftBinaryExponentiation(a, B[0..n-1]) // 从右至左二进制幂算法 // 输入：数字a、表示幂次的二级制位串B[0..n-1] // 输出：a^n的值 term = a if B[0] == 1 product = a else product = 1 // 保存累乘值 for i = i to n do term *= 2 // 保存二进制位为1部分值 if B[i] = 1 product = product * term return product 特点 算法效率 两个算法效率取决于位串长度，是对数级的 变治法 应用 在密码技术中，需要对超过100位十进制整数进行乘法运算，而 计算机往往不能直接运算 矩阵乘法Strassen矩阵乘法\\begin{align} \\begin{bmatrix} C_{00} & C_{01} \\\\ C_{10} & C_{11} \\end{bmatrix} & = \\begin{bmatrix} A_{00} & A_{01} \\\\ A_{10} & A_{11} \\end{bmatrix} \\begin{bmatrix} B_{00} & B_{01} \\\\ B_{10} & B_{11} \\end{bmatrix} \\\\ & = \\begin{bmatrix} M_1+M_2-M_5+M_7 & M_3+M_5 \\\\ M_2+M_4 & M_1+M_3-M_2+M_6 \\end{bmatrix} \\\\ M_1 & = (A_{00} + A_{11}) · (B_{00} + B_{11}) \\\\ M_2 & = (A_{10} + A_{11}) · B_{00} \\\\ M_3 & = A_{00} · (B_{01} - B_{11}) \\\\ M_4 & = A_{11} · (B_{10} - B_{00}) \\\\ M_5 & = (A_{00} + A_{01}) · B_{11} \\\\ M_6 & = (A_{10} - A_{00}) · (B_{00} + B_{01}) \\\\ M_7 & = (A_{01} + A_{11}) · (B_{10} + B_{11}) \\\\ \\end{align}算法若A、B是两个n阶方阵（若n不是2幂次，考虑填充0） 将A、B、C均分块为4个n/2子矩阵 递归使用Strassen方程中定义的矩阵M进行计算计算C各个子阵 算法特点 对2 * 2分块计算，Strassen算法执行了7次乘法、18次加减法， 蛮力算法需要执行8次乘法、4次加法 算法效率 乘法次数递推式：$M(n) = 7M(n/2), M(1) = 1$，则 $M(n) = 7^{log2 n} = n^{log_2 7} \\approx n{2.807}$ 加法次数递推式：$A(n) = 7A(n/2) + 18(n/2)^2, A(1)=0$ ，则$A(n) \\in \\Theta(n^{log_2 7})$ 矩阵趋于无穷大时，算法表现出的渐进效率卓越 还有一些算法能运行时间$\\in \\Theta(n^\\alpha)$，最小能达到 2.376，但是这些算法乘法常量很大、算法复杂，没有实用价值 矩阵乘法效率下界为$n^2$，目前得到的最优效率和其还有很大 距离 分治法 线性方程组 假设方程组系数矩阵为n阶方阵，且解唯一 主要思想都是高斯消元法（变治法），只是出于效率、误差有 不同实现方式 前向消去法算法1234567891011ForwardElimination(A[1..n, 1..n], b[1..n]) // 对方程组扩展矩阵[A|b]使用高斯消元法 // 输入：矩阵A[1..n, 1..n]，向量b[1..n] // 输出：扩展的上三角矩阵 for i = 1 to n do A[i, n+1] = b[i] // 得到扩展矩阵 for i = 1 to n-1 do for j = i+1 to n do for k = n+1 downto i do A[j, k] = A[j, k] - A[i, k]*A[j, i] / A[i, i] 算法特点 前向消去法不一定正确 如果A[i, i]==0，不能以其作为除数，此时需要交换行 （解唯一时总是存在非0行） A[i, i]非常小，导致比例因子A[j, i] / A[i, i]非常大， 产生大的舍入误差 最内层循环效率低 部分选主元法算法1234567891011121314151617181920BetterForwardElimination(A[1..n, 1..n], b[1..n]) // 用部分选主元法实现高斯消去 // 输入：矩阵A[1..n, 1..n]，向量b[1..n] // 输出：扩展的上三角矩阵 for i = 1 to n do A[i, n+1] = b[i] for i = 1 to n-1 do pivotrow = i for j = i+1 to n do if |A[j, i]| &gt; A[pivot, i] pivotrow = j // 选择第i列系数最大的行作为第i次迭代基点 // 保证比例因子绝对值不会大于1 for k = i to n+1 do swap(A[i, k], A[pivot, k]) for j = j+1 to n do temp = A[j, i] / A[i, i] // 这样只需要计算依次比例因子 for k = i to n+1 do A[j, k] = A[j, k] - A[i, k] * temp 特点 部分选主元法克服了前向消去法弊端 最内层乘法（加法）执行次数为 $\\frac {n(n-1)(2n+5) 6 \\approx \\frac n^3 3 \\in \\Theta(n^3)$ 始终能保证比例因子绝对值不大于1 反向替换法在得到上三角系数矩阵中 从最后一个方程中可以立刻求出$x_n$ 将$xn$带入倒数第二个方程求出$x{n-1}$ 逐次递推得到所以解 特点 算法时间效率$\\in \\Theta(n^2)$ 高斯消去法应用 矩阵（可逆矩阵）中应用 LU分解（Doolittle分解） Cholesky分解（要求矩阵正定） 求逆 求行列式 高斯消元法整个算法效率取决于消去部分，是立方级 事实上此方法在计算机上求解大规模方程组很难，因为舍入 误差在计算过程中会不断累积 非线性方程求解 5次及以上多项式没有只包含多项式系数、算术操作、开根号 的通用求根公式 方程的代数解并不具有很大的意义，充其量只是为方程的根设置 一个符号，然后再说方程有一个根等于这个符号（高斯） 平分法基于连续函数界值定理，类似于连续版折半查找 算法在区间[a, b]的端点上，$f(x)$符号取反 计算$f(x{mid}), x{mid}= \\frac {a+b} 2$的值 若$f(x_{mid})=0$，则求得一个 否则选择使得$f(x)$能在端点上取得相反值区间$[a, x{mid}$ 、$[x{mid}, b]$ 当包含根得区间小于预定义得$\\epsilon &gt; 0$时，就可以停止 算法 1234567891011121314151617181920Bisection(f(x), a, b, eps, N) // 评分法求f(x) = 0的一个根 // 输入：f(a)f(b) &lt; 0，eps绝对误差上界，N迭代次数上界 // 输出：(a, b)上的一个根近似（精确）值，或包含根的区间 n = 1 // 迭代计数 while n &lt;= N do x = (a + b)/2 if x - a &lt; eps return x fval = f(x) if fval = 0 return x if fval*f(a) &lt; 0: b = x else a = x n += 1 return a, b // 达到迭代限制，返回包含根的区间 特点 求解精度 理论上迭代次数足够$x_n$可以任意接近真实根$x^{*}$ 实际上，机器使用0表示非常小的值，$\\epsilon$小于特定 机器阈值时，算法不会停止，也无法得到满足条件的解 d对目标函数求值时可能会发生舍入误差 缺点 相较于其他已经算法，收敛速度较慢 并且无法扩展到更加一般的方程、方程组领域 优点 区间特性容易检验 Method of False Position试位法：类似于连续版差值查找 算法 类似平分法每次也使用某个区间$[a_n, b_n]$括住连续函数的 根，函数在端点取值符号相反 使用穿过$(a_n, f(a_n)), (b_n, f(b_n))$的直线在x轴截距 $x=\\frac {a_nf(b_n) - b_nf(a_n)} {f(b_n) - f(a_n)}$作为 分割点 特点 对许多实例，试位法收敛速度较平分法更快 牛顿法Newton-Raphon Method 算法 方法产生近似解序列：函数切线在x轴截距 $x_{n+1} = x_n - \\frac {f(x_n)} {f^{‘}(x_n)},n=0,1,\\cdots$ 特点 大多数情况下，若初值$x_0$足够接近根，牛顿法能够保证序列 收敛与根；对远离根的初值，无法保证一定会收敛 优点 牛顿法相较于平分法、试位法收敛速度更快，选定合适的 初值能够快速收敛 能够应用于更一般类型的方程、方程组 方法每次都迭代需要重新求函数、导数值 导数值等于0，则牛顿法失效 导数绝对值越大，牛顿法越有效 牛顿法不会把根括起来","link":"/Algorithm/Problem/numeric_analysis.html"},{"title":"博弈论","text":"总述约瑟夫斯问题n个人围成圈编号{0..n-1}，从1号开始每次消去第m个人直到最后一个 人，计算最后人编号$J(n)$。 减1法考虑每次消去1人后剩余人的编号情况 还剩k人时，消去1人后，以下个人编号为0开始，将剩余人重新 编号，得到每个人在剩k-1人时的编号 相较于剩k人时，剩k-1人时每个人编号都减少m，即每个人在剩 k人时编号满足 J_k = (J_{k-1} + m) \\% k 考虑只剩1人时，其编号为0，则可以递推求解 算法1234567Joseph_1(n, m): // 减1法求解Joseph问题 // 输入：人数n、消去间隔m // 输出：最后留下者编号 j_n = 0 for k from 2 to n: j_n = (j_n + m) % k 特点 算法效率 时间效率$\\in O(n)$ 减常因子剩余人数$k &gt;= m$时考虑所有人都报数一次后剩余人的编号变化情况 还剩k人时，报数一圈后消去k//m人，以最后被消去人的下个人 编号为0开始，将剩余人重新编号，得到剩k-k/m人时的编号 相较于剩k人时，剩k-k//m人时每个人编号满足 \\begin{align*} J_k & = \\left \\{ \\begin{array}{l} J_{k - d} + d * m, & J_{k - d} < n\\%m \\\\ J_{k - d} // (m-1) * m + (J_{k - d} - n\\%m) \\% (m - 1), & J_{k - d} > n\\%m \\end{array} \\right. \\\\ & = \\left \\{ \\begin{array}{l} s + n, & s < 0 \\\\ s + s // (m-1), & s >= 0 \\end{array} \\right. \\end{align*} $d = k // m$ $s = J_{k - d} - n\\%m$ $k &lt; m$时，使用减1法计算 m很大时，以$k &lt; m$作为调用减1法很容易使得递归超出 最大值 另外$m &lt; k &lt;= d * m$时，每轮也不过消去$d$个人，而 递推式复杂许多、需要递归调用 所以具体代码实现中应该选择较大的$d$值，如5 算法12345678910111213141516Joseph_factor(n, m): // 减常因子法求解Joseph问题 // 输入：人数n、消去间隔m // 输出：最后留下者编号 if n &lt; 5 * m: j_n = 0 for k from 2 to n j_n = (j_n + m) % k return j_n s = Joseph(n-n/m, m) - k % m if s &lt; 0: retrun s + n else: return s + s // (m-1) return j_n 特点 算法效率 时间效率$\\in O(log n) + m$ 特别的，对$m=2$时 $n=2k$为偶数时，$J(2k)=2J(k)-1$ $n=2k+1$为奇数时，$J(2k+1)=2J(k)+1$ 任意第k个 考虑报数不重置，则第k个被消去的人报数为$k * m - 1$ 对报数为$p = k * m + a, 0 \\leq a &lt; m$的人 此时已经有k个人被消去，剩余n-k个人 则经过$n - k$个剩余人报数之后，该人才继续报数，则 其下次报数为$q = p + n - k = n + k*(m-1) + a$ 若该人报数$p$时未被消去，则$a \\neq m-1$，则可以得到 $p = (q - n) // (m-1) * m + (q-n) \\% (m-1)$ 算法12345678Joseph_k(n, m, k): // 计算Joseph问题中第k个被消去人编号 // 输入：人数n、间隔m、被消去次序k // 输出：第k个被消去人编号 j_k = k*m - 1 while j_k &gt;= n: j_k = (j_k-n) // (m-1) * m - (j_k-n)%(m-1) return j_k 算法特点 算法效率 时间效率$\\in O(log n)$ 特别的，m=2时对n做一次向左循环移位就是最后者编号 双人游戏 双人游戏中往往涉及两个概念 state：状态，当前游戏状态、数据 move：走子，游戏中所有可能发生的状态改变 状态、走子彼此之间相互“调用” 状态调用走子转化为下个状态 走子调用状态评价当前状态 12345678910111213make_move(state, move): switch move: case move_1: state = move_1(state) evaluate_state(state) ...other cases...evaluate_state(state): switch state: case state_1: make_move(state, move_1) ...other cases... end game 拈游戏同样局面，每个玩家都有同样可选走法，每种步数有限的走法都能 形成游戏的一个较小实例，最后能移动的玩家就是胜者。 拈游戏（单堆版）：只有一堆棋子n个，两个玩家轮流拿走最少 1个，最多m个棋子 拈游戏（多堆版）：有I堆棋子，每堆棋子个数分别为 ${n_1,\\cdots,n_I}$，可以从任意一堆棋子中拿走任意允许数量 棋子，甚至拿走全部一堆 减可变规模算法算法（单堆）从较小的n开始考虑胜负（标准流程） n=0：下个人失败 1&lt;=n&lt;=m：下个人胜利（可以拿走全部） n=m+1：下个人失败（无论拿走几个，对方符合1&lt;=n&lt;=m 胜利条件） 数学归纳法可以证明：n=k(m+1)时为败局，其余为胜局 12345678910111213141516171819// 两个函数轮流递归调用find_good_move(coins): // 判断当前是否有成功步骤 // 输入：棋子数目 // 输出：成功策略或没有成功策略 for taken=1 to limit do if(is_bad_position(coins-taken)) // 对手没有成功策略 return taken return NO_GOOD_MOVEis_bad_position(coins): // 判断当前是否是good position // 输入：棋子数量 // 输出：是否有成功策略 if (coins == 0) return true return find_good_move(coins) == NO_GOOD_MOVE // 没有成功策略 特点 堆为2时，需要对两堆是否相同分别考虑 对更一般的I堆时 对每堆数量的位串计算二进制数位和 结果中包含至少一个1则对下个人为胜局，全为0则为负局 则玩家下步要拿走的棋子数量要使得位串二进制数位和全0 ，则对方陷入负局 todo又是二进制？？？和约瑟夫斯问题一样了 但是这里没有涉及最多能拿几个啊，不一定能够成功拿到 使拈和全为0啊 二进制数位和（拈和）：每位求和并忽略进位（奇或）","link":"/Algorithm/Problem/game_theory.html"},{"title":"架构相关算法","text":"无符号整形二进制1数量 目标：统计 unsinged 二进制表示中 1 数量 思路方向 移位遍历 分治统计 仅遍历112345678int population(unsigned int bits){ int result = 0; while (bits != 0){ bits &amp;= bits - 1; ++result; } return result;} 遍历减少：仅仅遍历无符号整形二进制表示中 1 次数 bits &amp;= bits - 1 将末尾 1 消除 分治+查表12345678910111213int * initialization(){ int * table = new int[256]; for (int i = 1; i &lt; 256; i++){ table[i] = (i &amp; 0x1) + table[i &gt;&gt; 1]; } return table;}int population(int bits, int * table){ return table[bits &amp; 0xff] + table[(bit &gt;&gt; 8) &amp; 0xff] + table[(bit &gt;&gt; 16) &amp; 0xff] + table[(bit &gt;&gt; 24) &amp; 0xff]} 思路 建表：为 8bits 数建立 256 长度的 1 数量表 递推建立：f(n) = f(n &gt;&gt; 1) + last_bit(n) 分治：将无符号整型分4块查表、加和结果 分治123456789int population(unsigned int bits){ // 分组计算 bits = (bits &amp; 0x55555555) + ((bits &gt;&gt; 1) &amp; 0x55555555); bits = (bits &amp; 0x33333333) + ((bits &gt;&gt; 2) &amp; 0x33333333); bits = (bits &amp; 0x0f0f0f0f) + ((bits &gt;&gt; 4) &amp; 0x0f0f0f0f); bits = (bits &amp; 0x00ff00ff) + ((bits &gt;&gt; 8) &amp; 0x00ff00ff); bits = (bits &amp; 0x0000ffff) + ((bits &gt;&gt; 16) &amp; 0x0000ffff); return bits;} 分治统计：依次将相邻 2bits、 4bits 分组，计算组内 1数量 移位、求并：将组内无效 bits 置 0、并对齐 +：计算组内 1 数量 0x0 + 0x0 = 0x0 0x0 + 0x1 = 0x1 0x1 + 0x1 = 0x10：进位，符合逻辑 改进方式：考虑避免不必要的 &amp; 根据进位特性替换 2bits 组对应语句 考虑组内空位是否可容纳 + 后结果 8bits 组：有效半组 4bits 足够存储中的最大 1 数量 8，但 无法存储 16 或更大， 需要及时置空无效bit 16bits 组及之后：有效半组足够存储最大 1 数量 32，可以 计算完之后再取值 1234567891011int population(unsigned int bits){ // 等于上述首行 bits = bits - ((bits &gt;&gt; 1) &amp; 0x55555555); bits = (bits &amp; 0x33333333) + ((bits &gt;&gt; 2) &amp; 0x33333333); // 4bits 足够存储组内 8bits 中 `1` 最大数量 8 bits = (bits + (bits &gt;&gt; 4)) &amp; 0x0f0f0f0f; // 8bits 足够存储全部 32bits 中 `1` 最大数量 32 bits = bits + (bits &gt;&gt; 8); bits = bits + (bits &gt;&gt; 16); return bits &amp; 0x3f} 奇偶性 目标：判断 unsigned 二进制表示中 1 数量奇偶性 思路方向 移位遍历，注意语言特性 逻辑移位和算术移位 求余结果 分治统计 分治统计123456789101112// 原始版本unsigned char parity(unsigned int i){ // 相邻2bit一组异或确定奇偶 i = i ^ (i &gt;&gt; 1); // 相邻4bit一组，依赖以上结果确定奇偶 i = i ^ (i &gt;&gt; 2); i = i ^ (i &gt;&gt; 4); i = i ^ (i &gt;&gt; 8); i = i ^ (i &gt;&gt; 16); // 奇偶性保存在最后1bit，取出 return i &amp; 0x1;} 分治统计：依次将相邻 2bits、 4bits 分组，统计组内奇偶性 分组方式顺序调换仅影响中间结果中存放奇偶性统计结果 bits 位置 奇偶性统计结果存放在组内最后 bit 其中每次分组统计事实上都是统计 2bits 的奇偶性 改进方式 调整分组顺序，将存储奇偶性 bits 位置移至最后 计算奇偶性 bits 对应奇偶性表，查表得到结果 一般可以设置长度为 0x0f 长度的数组，其中取值为索引奇偶性 0x6996 即为对应奇偶性表，其中各位序 bit 取值为位序值对应 的奇偶性 123456789// 改进版本unsigned char parity_k(unsigned int i){ // 将存储奇偶性 bits 移至最后 i = i ^ (i &gt;&gt; 4); i = i ^ (i &gt;&gt; 8); i = i ^ (i &gt;&gt; 16); // 查表得到结果 return (0x6996 &gt;&gt; (i &amp; 0x0f )) &amp; 0x01;} 奇偶性填充 目标：将 unsigned char 中最高位作为校验位，保证整体的二进制标表示的奇偶性 思路方向 求1数量并设置标志位 按位乘积后取模 取模123456unsigned char even(unsigned char i){ return ((i * 0x10204081) &amp; 0x888888ff) % 1920;}unsigned char odd(unsigned char i){ return ((i * 0x00204081) | 0x3DB6DB00) % 1152;} 各数字二进制含义（设 i 的二进制表示为 abcdefg） 0x10204081 * i 得到 i 二进制重复 5 次（溢出被截断） 0x888888ff &amp; 抽取所需 bits d000a000e000b000f000c000gabcdefg 1920 = 15 * 128：对其取模即得到[X]abcdefg （将被除数表示为 16 进制分块可证） 位元反序 目标：返回 6bits 长二进制的反序 123unsigned char revert(unsigned char i){ return ((i * 0x00082082) &amp; 0x01122408) % 255;} 各数字二进制含义（设 i 的二进制表示为 abcdef） 0x00082082 * i 得到 i 二进制重复 4 次 0x01122408 &amp; 抽取所需 bits 0000000a000e00b000f00c000000d000 对 255 取模即得到反序*（将被除数表示为 256 进制分块可证） 前导 0 目标：获取 unsigned 的二进制表示中前导 0 数量 思路方向 移位遍历 区间映射：将原始 unsigned 映射为较小范围的取值 区间映射1234567891011121314151617unsigned char nlz(unsigned int i){ static unsigned char table[64] = { 32, 31, 'u', 16, 'u', 30, 3, 'u', 15, 'u', 'u', 'u', 29, 10, 2, 'u', 'u', 'u', 12, 14, 21, 'u', 19, 'u', 'u', 28, 'u', 25, 'u', 9, 1, 'u', 17, 'u', 4, 'u', 'u', 'u', 11, 'u', 13, 22, 20, 'u', 26, 'u', 'u', 18, 5, 'u', 'u', 23, 'u', 27, 'u', 6, 'u', 24, 7, 'u', 8, 'u', 0, 'u' } i = i | (i &gt;&gt; 1); i = i | (i &gt;&gt; 2); i = i | (i &gt;&gt; 4); i = i | (i &gt;&gt; 8); i = i | (i &gt;&gt; 16); i = i * 0x06eb14f9; return table[i &gt;&gt; 26];} 区间映射 移位取或：将最高位 1 传播至所有低位，原始值映射至 33 种取值 0x06eb14f9：将 33 种值映射为低 6 位取值均不同值 此类数的共同特点是因子均为 $2^k \\pm 1$ （此类数乘法容易通过移位操作实现） 最小的此性质的数为 0x45bced1 = 17 * 65 * 129 * 513 速算无符号整形除法 目标：大部分计算机架构中除法耗时，寻找方法将特定除数的除法转换为 其他指令 思路：除数为常数时，用移位、乘法、加法替代除法运算 常数除法（有符号或无符号）基本都有对应的乘法版本 注意类型溢出 除数为312345unsigned div3(unsigned int i){ // 在更高级别优化过程实际就会转化为类似指令 // 但此语句可能会导致类型溢出 return (i * 2863311531) &gt;&gt; 33;} \\begin{align*} 2863311531 &= \\frac {2^{33} + 1} 3 \\\\ i/3 &= \\lfloor i * \\frac {2^{33} + 1} 3 * \\frac 1 {2^{33}} \\rfloor \\\\ &= \\lfloor \\frac i 3 + \\frac i {3 * 2^{33}} \\rfloor = \\frac i 3 \\end{align*}快速求平方根倒数12345678910111213141516float i_sqrt(float a){ union { int ii; float i; }; i = a; float ihalf = 0.5f * i; // 得到较好的初始估算值 ii = 0x5f000000 - (ii &gt;&gt; 1); // 牛顿法迭代，可以重复以下语句多次提高精度 i = i * (1.5f - ihalf * i * i); return i;} 移位获取初始值 考虑（规格化）单精度浮点数 $a$ 的二进制表示 \\begin{align*} a &= 2^{E-127} * (1+F) \\\\ \\frac 1 {\\sqrt a} &= 2^{\\frac {127 - E} 2 + 127} * (1+F)^{-\\frac 1 2} \\\\ &= 2^{190.5 - \\frac E 2} * (1+F)^{-\\frac 1 2} \\end{align*} 则 0x5f000000 - (ii &gt;&gt; 1) 可以满足指数部分得到近似结果 $190 - \\frac E 2$ 其他细节使得存在比 0x5f000000 实践更优值，如：0x5f375a86 规格化值的底数接近 1 移位运算指数最后位部分移至尾数 减法运算尾数部分向指数借位 牛顿法：$x{n+1} = xn - \\frac {f(x_n)} {f^{‘}(x__n)}$ 求 $\\frac 1 {\\sqrt x}$，即求 $f(x) = x^{-2} - a$ 零点 则迭代为 $x{n+1} = xn(1.5 - 0.5 a x__n^2)$ http://www.lomont.org/papers/2003/InvSqrt.pdf https://zhuanlan.zhihu.com/p/33543750","link":"/Algorithm/Specification/hardware_arch.html"},{"title":"高维数据检索方法","text":"相似性检索相似性检索：从指定目标集合中检索出与给定样本相似的目标 range searches：范围检索，给定查询点、检索距离阈值 K-neighbor searches：K近邻检索，给定查询点、检索结果 数量 待检索目标、样本：以指定feature space中的高维数据点 表示 相似性检索则在相应metric space中搜索样本点最近邻作为 检索结果 关键：对待检索的目标建立有效的相似性索引 对待检索目标进行预划分，在对给定样本进行检索时，只需 对比相似索引中给出的可能相似的目标 减少相似性检索的对比次数、I/O，让相似性检索在大规模 数据集中应用成为可能 Tree-Based Index基于树结构的索引 向量维度大于20之后，仍然需要扫描整个向量集合的大部分， 与线性扫描没有太大差别 包括 kd-tree R-tree R*-tree X-tree SS-tree SR-tree VP-tree metric-trees Hasing-Based Index基于哈希的索引技术：利用LSH函数简化搜索 locality sensitive hashing：LSH，局部敏感哈希，特征 向量越接近，哈希后值越可能相同 局部敏感哈希值能够代表代替原始数据比较相似性 支持对原始特征向量进行非精确匹配 hash技术能从两个方面简化高维数据搜索 提取特征、减小特征维度 在损失信息较小的情况下对数据进行降维 hash函数（特征提取方法）选择依赖于对问题认识 一般都归于特征提取范畴 划分特征空间（哈希桶）、缩小搜索空间 将高维特征映射到1维先进行近似搜索得到候选集， 然后在候选集中进行精确搜索 hash函数的选择取决于原始特征表示、度量空间 一般LSH都是指此类哈希技术 提取特征 average hashing：aHash，平均哈希 perceptual hashing：pHash，感知哈希 differantiate hashing：dHash，差异哈希 划分空间 MinHashing：最小值哈希，基于Jaccard系数 基于汉明距离的LSH 基于曼哈顿距离的LSH Exact Euclidean LSH：E2LSH，基于欧式距离 Visual Words Based Inverted Index向量化方法：将向量映射为标量，为（图像）特征建立 visual vocabulary 基于K-means聚类（层级K-means、近似K-means） 在图像检索实际问题中取得了一定成功 K-means聚类算法的复杂度与图像特征数量、聚类数量有关 图像规模打达到百万级时，索引、匹配时间复杂度依然较高 visual vocabulary：视觉词库，代表聚类类别整体 visual word：视觉单词，每个代表一个聚类类别","link":"/Algorithm/Specification/searching_high_dimensional.html"},{"title":"Infomation Security","text":"Hash/摘要方法文件校验MD4 附加填充bits：在末尾对消息填充，使得消息$M$长度满足 $len(M) mod 512 = 448$ 填充最高位位为1、其余为0 分块：将填充后消息512bits分块为$M_1,M_2,\\cdots,M_K$ 初始化MD4缓存值 MD4使用128bits缓存存储哈希函数中间、最终摘要 将其视为4个32bits寄存器初始化为 A = 0x67452301 B = 0xefcbab89 C = 0x98badcfe D = 0x10325476 使用压缩函数迭代计算K个消息分块、上次计算结果 $H_{i+1} = C(H_i, M_i)$ 最终$H_K$即为MD4摘要值 MD5SHA数字签名鉴权协议","link":"/Algorithm/Specification/info_security.html"},{"title":"Random","text":"线性同余法线性同余法：产生伪随机数最常用方法 \\left \\{ \\begin{array}{l} a_0 = & d \\\\ a_n = & (ba_{n-1} + c) % m, & n=1,2,\\cdots \\end{array} \\right. $d \\leq m$：随机序列种子 $b \\geq 0, c \\geq 0, m \\geq 0$：关系到产生随机序列的随机性能 $m$：应该取得充分大 $gcd(m ,b)=1$：可以取b为素数","link":"/Algorithm/Specification/random_numbers.html"},{"title":"NPM 总述","text":"npm npm 的三个独立组成部分 网站：查找包、设置参数、管理 npm 使用体验的主要途径 注册表：存储包信息 CLI：终端应用 npm 包管理 npm 包可以分为是否全局安装 全局安装：适合安装命令行工具包 位于 /user/local 或 Node.js 安装目录 局部安装（缺省）：适合安装包依赖，且包通过 Node.js 的 require 加载 位于当前目录 node_modules 目录下 全局安装和局部安装互相独立 若同时需要命令行、包依赖，则应分别安装或使用 npm 链接 为避免污染全局环境，以下方式可以用于局部安装命令行 npx 包（命令）：查找 noode_modules 中局部安装包 alias 设置别名：添加 PATH=&lt;bin-dir&gt;:$PATH &lt;cmd&gt; 别名，即每次为命令执行设置环境变量 https://docs.npmjs.com/cli/v7/commands/npm https://www.npmjs.cn/cli/npm/ 输入命令 install：安装 -g：全局安装 --save：维护 package.json 中依赖项 --save-dev：维护 package.json 中开发依赖项 uninstall：卸载 -g：卸载全局安装包 --save：维护 package.json 中依赖项 --save-dev：维护 package.json 中开发依赖项 update：更新 -g：更新全局安装包 outdated：检查版本 -g：检查全局安装包 --depth=&lt;num&gt;：检查深度 输出命令 whoami： publish：发布包 npm 配置 config：更新、修改用户或全局 npmrc 文件 npm 配置文件npm 用户配置文件.npmrc1234repository=&lt;repo-URL&gt;init.author.email=init.author.name=init.license= .npmrc：npm 用户配置文件，缺省为 ~/.npmrc 指定 npm 本身配置：包仓库地址、用户信息 https://www.npmjs.cn/files/npmrc/ .npm-init.js12345678// 直接设置键值对module.exports = { &quot;&lt;custom-field&gt;&quot;: &quot;&lt;field-value&gt;&quot;, &quot;&lt;custom-field&gt;&quot;: &quot;&lt;field-value&gt;&quot;,}// 通过 `prompts` 函数交互式设置键值对module.exports = prompts(&quot;&lt;Question 1&gt;, &quot;&lt;Field&gt;&quot;)) .npm-init.js：用户包初始化配置文件，缺省为 ~/.npm-init.js 设置 package.json 生成内容 环境变量 NPM_CONFIG_PREFIX：全局包安装地址 npm 包配置文件包配置文件package.json1234567891011121314151617181920212223242526272829{ &quot;name&quot;: &quot;&lt;package-name&gt;&quot;, &quot;version&quot;: &quot;&lt;semantic-version&gt;&quot;, &quot;description&quot;：&quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;tests&quot;: &quot;echo \\&quot;Error:\\&quot; &amp;&amp; exit 1&quot; }, &quot;repository&quot;: { &quot;type&quot;: &quot;git&quot;, &quot;url&quot;: &quot;&lt;URL&gt;&quot; }, &quot;keywords&quot;: [ ], &quot;author&quot;: &quot;&lt;author-name&gt;&quot;, &quot;license&quot;: &quot;&lt;license-name&gt;&quot;, &quot;bugs&quot;: { &quot;url&quot;: &quot;&lt;URL&gt;&quot; }, &quot;homepage&quot;: &quot;&lt;URL&gt;&quot; // 以上为 `npm init` 默认生成内容 &quot;dependencies&quot;: { &quot;&lt;dep-named&gt;&quot;: &quot;&lt;dep-version&gt;&quot;, &quot;&lt;dep-named&gt;&quot;: &quot;&lt;dep-version&gt;&quot; }, &quot;devDependecies&quot;: { &quot;&lt;dev-only-dep-named&gt;&quot;: &quot;&lt;dep-version&gt;&quot;, &quot;&lt;dev-only-dep-named&gt;&quot;: &quot;&lt;dep-version&gt;&quot; }} package.json：局部包管理文件，位于当前包目录 列出包依赖 语义化 管理包版本 方便迁移 创建：npm init [--yes] 初始化包即默认生成 package.json 包含字段可通过 .npm-init.js 设置 字段值大部分为空，除非可从 npm 用户配置文件 init 字段中获取 字段说明 name：可用 @&lt;scope&gt;/ 为包设置域名，方便组织相关包 version：应遵守语义化版本规则 dependencies：包依赖，安装、卸载时 --save 标志会自动维护 devDependencies：开发时包依赖，安装、卸载时 --save-dev 标志会自动维护","link":"/Web/NPM/config.html"},{"title":"CSS","text":"CSS属性 display：元素展示 inline：默认，内联元素 flex：弹性容器 none：不显示 block：块级元素，元素前后有换行符 inline-block：行内块元素 list-item：列表元素 run-in：根据上下文作为块级元素或内联元素 table：表格元素&lt;table&gt;，前后有换行符 inline-table：内联表格元素，前后无换行符 table-row-group table-row table-header-group table-footer-group table-column-group table-column table-cell table-caption inherit 弹性容器Flexflex弹性容器内元素空间分配 flex-grow flex-shrink flex-basis简写，只给出一个值时 相当于flex-grow auto：同1 1 auto none：同0 0 auto initial：初始值，同0 0 auto inherit： flex-grow（弹性容器内）元素相对于其他元素项目扩展的量 auto inherit {num}：相对于其他元素的扩展量，默认为0，应该是按照比例分 flex-shrink（弹性容器内）元素相对于其他元素收缩的量 flex-basis（弹性容器内）元素基础长度 auto inherit 具体长度（%, px, em为单位） flex-flow flex-direction flex-wrap initial inherit flex-direction弹性容器内元素方向 row：默认，灵活元素水平排列 row-reverse：灵活元素水平反向排列 column：灵活元素竖直排列 column-reverse：灵活元素竖直反向排列 initial inherit flex-wrap弹性容器内元素是否拆行/列 nowrap：默认，灵活项目不拆行/列 wrap：灵活项目必要时拆行/列 wrap-reverse：灵活项目必要时反向拆行/列 initial inherit 弹性容器Alignalign-items弹性容器内侧轴（竖直方向）对齐各项元素，适合含有单行元素 stretch：默认，元素拉伸对齐，元素大小确定时同 flex-start效果 center：元素堆叠在容器中心 flex-start：元素堆叠向容器开头 flex-end：元素堆叠向容器结尾 baseline：元素位于容器基线上 initial：初始值 inherit：从父类继承 align-content和align-items有相同的功能，适合多行元素 （这个好像作用单位是弹性容器的行） stretch：默认，元素拉伸对齐，元素大小确定时同 flex-start效果 center：元素堆叠在容器中心 flex-start：元素堆叠向容器开头 flex-end：元素堆叠向容器结尾 space-between：元素向容器两端堆叠，元素间保持间距 space-around：类似space-between，但元素于容器 边界直接也有间距 initial：初始值 inherit：从父类继承 align-self设置弹性容器内元素本身侧轴方向上的对齐方式 auto：默认，继承父容器align-items属性，没有 父容器则为stretch stretch：元素拉伸对齐，元素大小确定时同 flex-start效果 center：元素堆叠在容器中心 flex-start：元素堆叠向容器开头 flex-end：元素堆叠向容器结尾 baseline：元素位于容器基线上 initial：初始值 inherit：从父类继承 justify弹性容器内水平排列各项元素 flex-start：默认，元素位于容器开头 flex-end：元素堆叠向容器结尾 center：元素堆叠在容器中心 space-between：元素向容器两端堆叠，元素间保持间距 space-around：类似space-between，但元素于容器 边界直接也有间距 initial：初始值 inherit：从父类继承","link":"/Web/CSS/css.html"},{"title":"随机算法","text":"数值随机化算法数值化随机算法：常用于数值问题求解，往往得到的是近似解 近似解的精度随计算时间、采样数量增加不断提高 很多情况下计算问题的精确解不可能、无必要，数值化随机算法 可以得到较好的解 随机投点法随机投点法：在给定范围内生成均匀分布随机数模拟随机投点 计算$\\pi$值：在正方形、内切圆中随机撒点，计算圆内、 正方形内点数量之比 计算黎曼积分：在包括积分区域单位矩形内随机投点，计算 积分区域、矩形区域点数量之比 平均值法平均值法：结合随机数分布、目标问题构造统计量，估计目标问题 计算黎曼积分 假设独立同分布随机变量${\\eta_i}$在$[a, b]$中服从分布 $f(x)$、待积函数为$g(x)$ 记$g^{*}(x) = \\frac {g(x)} {f(x)}$，则有 \\begin{align*} E(g^{*}(\\eta)) & = \\int_a^b g^{*}f(x) dx \\\\ & = \\int_a^b g(x) dx = I \\end{align*} 由强大数定理 P_r(\\lim_{x \\rightarrow \\infty} \\frac 1 n \\sum_{i=1}^n g^{*}(\\eta_i) = I) = 1选择$\\bar I = \\frac 1 n \\sum_{i=1}^n g^{*}(\\eta_i)$， 则$\\bar I$依概率收敛为$I$ 选择抽样方法简单的概率密度函数$f(x)$满足 \\left \\{ \\begin{array}{l} f(x) \\neq 0, & g(x) \\neq 0, a \\leq x \\leq b \\\\ \\int_a^b f(x) dx = 1 \\end{array} \\right.可以取$f(x)$为均匀分布 f(x) = \\left \\{ \\begin{array}{l} \\frac 1 {b-a}, & a \\leq x \\leq b \\\\ 0, & x < a, x > b \\end{array} \\right. 则积分 I = \\int_a^b g(x)dx = (b-a) \\int_a^b g(x) \\frac 1 {b-a}dx取均值 \\bar I = \\frac {b-a} n \\sum_{i=1}^n g(x_i)可作为求分I的近似值 解非线性方程组\\left \\{ \\begin{array}{l} f_1(x) & = f_1(x_1, x_2, \\cdots, x_n) & = 0 \\\\ f_2(x) & = f_2(x_1, x_2, \\cdots, x_n) & = 0 \\\\ \\vdots \\\\ f_n(x) & = f_n(x_1, x_2, \\cdots, x_n) & = 0 \\end{array} \\right. 线性化方法、求函数极小值方法有时会遇到麻烦，甚至使方法 失效而不能获得近似解 随机化方法相较而言要耗费较多时间，但设计简单、易于实现 对于精度要求较高的问题，随机化方法可以提供一个较好的初值 步骤 构造目标函数 \\Phi(x) = \\sum f_i^2(x)则目标函数的极小值点即为所求非线性方程组的一组解 随机选择点$x_0$作为出发点，不断随机生成搜索方向， 迭代为使得目标函数值下降的搜索点 一般以目标函数变化幅度、迭代轮数作为终止条件 搜索方向为随机生成，迭代步长比例每轮缩小指定幅度 真正的随机次梯度下降 Monte Carol Method蒙特卡洛算法：一定能给出问题解，但未必正确 要求在有限时间、采样内必须给出解，解未必正确 求得正确解的概率依赖于算法所用时间，算法所用时间越多， 得到正确解概率越高 无法有效判断得到的解是否肯定正确 Las Vegas Method拉斯维加斯算法：找到的解一定是正确解，但是可能找不到解 找到正确解的概率随着计算所用时间增加而提高 用同一拉斯维加斯算法反复对实例求解多次，可使得求解失效 概率任意小 Sherwood Method舍伍德算法：能求得问题的一个解，所求得得解总是正确的 确定性算法在最好情况、平均情况下计算复杂度有较大差别， 在确定性算法中引入随机性将其改造成舍伍德算法，消除、减少 问题的好坏实例间差别 精髓不是改进算法在最坏情形下的行为，而是设法消除最坏情形 与特定问题实例的关联性 思想 问题输入规模为n时，算法A所需的平均时间为 \\bar t_A(n) = \\sum_{x \\in X_n} t_A(x) / |X_n| $X_n$：算法A输入规模为n的实例全体 $t_A(x)$：输入实例为x时所需的计算时间 显然存在$x \\in X_n, t_A(x) &gt;&gt; \\bar t_A(x)$ 希望获得随机化算法B，使得对问题的输入规模为n的每个实例 $x \\in X_n$均有$t_B(x) = \\bar t_A(x) + s(n)$ 对具体实例，存在$x \\in X_n$，算法B需要时间超过 $\\bar t_A(x) + s(n)$，但这是由于算法所做的概率引起， 与具体实例无关 算法B关于规模为n的随机实例平均时间为 \\begin{align*} \\bar t_B(n) & = \\sum_{x \\in X_n} t_B(x) / (X_n) \\\\ & = \\bar t_A(n) + s(n) \\end{align*}K 当$s(n)$与$\\bar t_A(n)$相比可以忽略时，舍伍德算法 可以获得较好平均性能 todo","link":"/Algorithm/Specification/random_strategies.html"},{"title":"Hexo 建站","text":"Hexo 安装、配置 安装 Hexo、并建站 1234567 # 安装 Hexonpm install -g hexo-cli # 初始化 Hexohexo init &lt;folder&gt;cd &lt;folder&gt; # 安装 Hexo 依赖npm install 启动站点：https://hexo.io/zh-cn/docs/server 1234# 安装独立的服务器模块（也可以不注册依赖）npm install hexo-server --save# 启动服务器hexo server [-p &lt;port&gt;] Hexo 站点结构 _config.yml：配置信息 package.json：Hexo 模块 npm 配置文件 scaffolds：模板文件 新建文章时，尝试根据布局参数寻找相应模板建立文章 source：资源 _posts：文章 _drafts：草稿文章，默认会被忽略 https://hexo.io/zh-cn/docs/writing#%E8%8D%89%E7%A8%BF _data：其中 YAML、JSON 文件可以作为全站数据引用 https://hexo.io/zh-cn/docs/data-files 其余 _ 开头文件、文件夹和隐藏文件将被忽略 其中 Markdown、HTML 文件被解析放到 public 文件夹下 public： themes：主题文件夹，一个文件夹即一个主题 https://hexo.io/zh-cn/docs/configuration Hexo 主题结构 _config.yml：主题配置文件 修改后会自动更新 languages：语言文件夹 layout：布局文件夹，存放主题模板文件 Hexo 内建 Swig 模板引擎，可另外安装 EJS、Haml、Jade、Pug 插件支持 Hexo 根据模板文件扩展名决定模板引擎 scripts：脚本文件夹 启动时，Hexo 会载入其中 JS 文件 source：资源文件夹 除模板外的资源，如：CSS、JS 均位于此处 _ 开头文件、文件夹和隐藏文件被忽略 若文件可被渲染，则会被解析存储到 public 文件夹，否则直接拷贝 Hexo 命令12345678910hexo init [folder]hexo new [layout] &lt;title&gt; # 新建hexo generate # 生成静态文件hexo publish [layout] &lt;filename&gt; # 发布草稿hexo deploy [-g] # 部署hexo render &lt;file1&gt; [file2] [-o &lt;output&gt;] # 渲染文件hexo migrate &lt;type&gt; # 从其他博客系统迁移hexo clean # 清楚缓存、静态文件hexo list &lt;type&gt; # 列出站点资料hexo version https://hexo.io/zh-cn/docs/commands 更新配置、安装依赖（如：修改渲染引擎）之后，尝试清空缓存使生效 $ hexo clean 删除 db.json 文件 Hexo 模块 Markdown 渲染 hexo-renderer-mark：建议立刻删除，渲染能力极差 hexo-renderer-markdonw-it：不好用 hexo-renderer-markdonw-it-plus：也不好用 hexo-renderer-pandoc：太重，需要 pandoc 支持 hexo-renderer-kramed：快用，快用","link":"/Web/NPM/hexo_config.html"},{"title":"标准库","text":"Scala PackageAny123456class Any{ // 判断对象是否是否为类型`T`实例 def isInstanceOf[T] // 将对象强转为类型`T`实例 def asInstanceOf[T]} 12341.asInstanceOf[String] // 报错，未定义隐式转换函数1.isInstanceOf[String] // `false`List(1),isInstanceOf[List[String]] // `true`，泛型类型擦除List(1).asInstanceOf[List[String]] // 成功，泛型类型擦除 Option12345678class Option[T]{ // `Some`实例：返回被被包裹值 // `None`实例：返回参数（默认值） def getOrElse(default?: T)}class Some[T](s?: T) extends Option[T]object None extends Option[_] ??? 推荐使用Option类型表示可选值，明示该值可能为None Option类型可以被迭代 Some(s)：唯一迭代s None：空 12val a = Some(&quot;hello&quot;)a.foreach(x =&gt; println(x.length)) Predef1234object Predef extends LowPriorityImplicits{ // 返回运行过程中类型，具体实现由编译器填补 def classOf[T]: Class[T] = null} ListcollectionmutableMap1234val a=Map((3,4), 5-&gt;6)// 两种创建`Map`、二元组形式等价a.map{case (a, b) =&gt; println(a, b)}// `{case...}`为偏函数（或`Function1`） immutablereflectruntimeuniverse universe：提供一套完整的反射操作，可以反思性的检查 类型关系，如：成员资格、子类型 12// 返回类型`T`“类型值”，可以用于比较typeOf[T] TypeTag TypeTag：提供编译时具体类型的信息 能获取准确的类型信息，包括更高的泛型类型 但无法获取运行时值的类型信息 1234567891011121314import scala.reflect.runtime.universe.{TypeTag, TypeRef, typeTag}// 声明隐式参数列表def recognize[T](x: T)(implicit tag: TypeTag[T]): String = tag.tpe match { case TypeRef(utype, usymbol, args) =&gt; List(utype, usymbol, args).mkString(&quot;\\n&quot;) }val list: List[Int] = List(1,2)val ret = recognize(list)// 显式实例化`TypeTag`val tag = typeTag[List[String]] WeakTypeTag：提供编译时包括抽象类型的信息 WeakTypeTag可以视为TypeTag的超集 若有类型标签可用于抽象类型，WeakTypeTag将使用该标记 123456789101112131415161718import scala.reflect.runtime.universe.{WeakTypeTag, TypeRef, weakTypeRef}// 声明隐式参数列表def recognize[T](x: T)(implicit tag: WeakTypeTag[T]): String = tag.tpe match { case TypeRef(utype, usymbol, args) =&gt; List(utype, usymbol, args).mkString(&quot;\\n&quot;) }abstract class SAClass[T]{ // 抽象类型 val list: List[T] val result = Recognizer.recognize(list) println(result)}new SAClass[Int] { val list = List(2,3)}// 显式实例化`WeakTypeTag`val tag = weakTypeTag[List[String]] 当需要TypeTag[T]、WeakTypeTag[T]类型的隐式值tag时， 编译器会自动创建，也可以显式实例化 以上类型探测通过反射实现，编译器根据传递实参推断泛型 参数T，由此确定特定类型标签隐式值 ClassTagClassTag：提供关于值的运行时信息 不能在更高层次上区分，如：无法区分List[Int]、 List[String] 是经典的老式类，为每个类型捆绑了单独实现，是标准的 类型模式 1234567891011121314151617import scala.reflect.{ClassTag, classTag}// def extract[T: ClassTag](list: List[Any]) =def extract[T](list: List[Any])(implicit ct: ClassTag[T]) = list.flatMap{ case element: T =&gt; Some(element) // 以上被翻译为如下，告诉编译器`T`的类型信息 // case element @ ct(_: T) =&gt; // 否则泛型`T`被删除，编译不会中断，但是无法正确工作 case _ =&gt; None }val list: List[Any] = List(1, &quot;string1&quot;, List(), &quot;string2&quot;)val rets = extract[String](list)// 显式实例化`ClassTag[String]`val ct = classTag[String] 当需要ClassTag[T]类型的隐式值ct时，编译器会自动创建 也可以使用classTag显式实例化 ClassTag[T]类型值ct存在时，编译器将自动 包装(_:T)类型模式为ct(_:T) 将模式匹配中未经检查的类型测试模式转换为已检查类型 utilmatchingRegex123456789101112131415161718192021222324252627import scala.util.matching.{Regex, Match}class Regex(?pattern: String, ?group: String*){ def findAllIn(source: CharSequence): MatchIterator def findAllMatchIn(source: CharSequence): Iterator[Match] def findFirstIn(source: CharSequence): Option[String] def findFirstMatchIn(source: CharSequence): Option[Match] def replaceAllIn(target: CharSequence, replacer: (Match) =&gt; String): String def replaceAllIn(target: CharSequence, replacement: String): String def replaceFirstIn(target: CharSequence, replacement: String): String // 此`unapplySeq`就应该是定义在类中 def unapplySeq(target: Any): Option[List[String]] = target match{ case s: CharSequence =&gt; { val m = pattern matcher s if (runMatcher(m)) Some((1 to m.groupCount).toList map m.group) else None } // 等价于重载 case m: Match =&gt; unapplySeq(m.matched) case _ =&gt; None }}class Match{ def group(?key: Int): String def group(?key: String): String} 12345678910val keyValPattern: Regex = &quot;([0-9a-zA-Z-#() ]+): ([0-9a-zA-Z-#() ]+)&quot;.r// `String.r`可使任意字符串变成正则表达式// 使用括号同时匹配多组正则表达式val input: String =&quot;&quot;&quot;backgroud-color: #A03300l |background-image: url(img/header100.png);&quot;&quot;&quot;.stripMarginfor(patternMatch(attr, value) &lt;- keyValPattern.findAllMatchIn(input)) println(s&quot;key: ${attr}, value: ${value}&quot;)","link":"/Java/Scala/stdlib.html"},{"title":"SBT","text":"综述SBT：simple build tools，Scala世界的Maven 下载、解压、将SBT_HOME/bin添加进$PATH即可 SBT中包含的Scala可通过$ scala console交互式启动解释器 参数命令 clean：删除所有构建文件 compile：编译源文件：src/main/scala、src/main/java test：编译运行所有测试 console：进入包含所有编译文件、依赖的classpath的scala 解释器 :q[uit]：退出 run &lt;args&gt;：在和SBT所处同一虚拟机上执行项目main class package：将src/main/resources、src/main/scala、 src/main/java中编译出class打包为jar help &lt;cmd&gt;：帮助 reload：重新加载构建定义：build.sbt、project.scala 、project.sbt inspect &lt;key&gt;：查看key描述 show &lt;key[:subkey]&gt;：查看key对应value执行结果 例：show compile:dependencyClasspath 以上命令可以在shell中作参数、在SBT命令行作命令 SBT命令行中历史记录查找同shell ~前缀执行命令表示监视变化，源文件改变时自动执行该命令 项目结构 src：src中其他目录将被忽略 main：主源码目录 scala java resources：存储资源，会被打进jar包 分布式执行则每个节点可以访问全体资源，相当于 broadcast 访问时resources作为根目录，直接/列出相对 resource路径 test：测试源码目录 scala java resources project：可以包含.scala文件，和.sbt文件共同构成 完整构建定义 Build.scala plugins.sbt：添加sbt插件 target：包含构建出的文件：classes、jar、托管文件、 caches、文档 lib：存放非托管依赖 其中jar被添加进CLASSPATH环境变量 build.sbt：包含构建定义 其中隐式导入有 sbt.Keys._：包含内建key sbt._ SBT配置12345678910111213 # ~/.sbt/repositories # 默认依赖仓库设置[repositories] local &lt;maven_repo_name&gt;: &lt;repo_address&gt; &lt;ivy_repo_naem&gt;: &lt;repo_address&gt;, &lt;address_formation&gt; # 地址格式可能如下[orgnanization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext] # ali Maven2 repoaliyun: https://maven.aliyun.com/nexus/content/groups/public/ 需要添加sbt启动参数-Dsbt.override.build.repos=true使 覆盖默认生效 Build Definition构建定义：定义在build.sbt中、包含项目构建信息 多工程.sbt构建定义：可为代码中定义多个子项目，结构灵活 bare .sbt构建定义 构建定义可以包含位于project目录下的.scala下的文件， 用于定义常用函数、值 多工程.sbt构建定义12345678910111213// 自定义`TaskKey`lazy val hello = taskKey[Unit](&quot;example task&quot;)// 定义库IDval derby = &quot;org.apache.derby&quot; % &quot;derby&quot; % &quot;10.4.1.3&quot;// 创建名为`root`、位于当前目录的子项目lazy val root = (project in file(&quot;.&quot;)) // 在`.settings`方法中设置*setting expression*键值对 .settings( name := &quot;hello&quot;, hello := {prinln(&quot;hello&quot;)}, libraryDependencies += derby ) 构建定义拥有不可变的Setting[T]类型映射描述项目属性， 是会影响sbt保存键值对的map的转换 T：映射表中值类型 Setting描述.settings是对映射表的转换，增加新键值、 追加至已有值，转换后的映射成为sbt新映射 build.sbt文件中除设置外，可以包含val、def定义 所有定义都在设置之前被计算，无论在文件中所处位置 一般使用lazy val避免初始化顺序问题 Bare.sbt构建定义1234name := &quot;hello&quot;version := &quot;1.0&quot;scalaVersion := &quot;2.12.8&quot;library.Dependencies += &quot;org.apache.derby&quot; % &quot;derby&quot; % &quot;10.4.1.3&quot; bare .sbt构建定义由Setting[_]表达式列表组成 Keys SettingKey[T]：值仅在子项目载入时计算一次 TaskKey[T]：值每次都需要被计算，可能有副作用 InputKey[T]：值以命令行参数作为输入的任务 可以通过各自创建方法创建自定义key 12// 给定value（返回）类型、键值对描述lazy val hello = taskKey[Unit](&quot;task key demo&quot;) 在sbt交互模式下，可以输入key名称获取、执行value setting key：获取、显示value task key：执行value，但不会显示执行结果，需要 show &lt;task&gt;才会打印执行结果 Key可以视为为项目定义的属性、trigger taskiness（每次执行）可以视为task key的属性 sbt.Keys内建Key 内建Key中泛型参数已经确定，定制需要满足类型要求 项目属性 name：项目名称，默认为项目变量名 baseDirectory：项目根目录 sourceDirectories：源码目录 compile:_：编译时设置 sourceDirectory：源码上层目录？ 依赖相关 unmanageBase：指定非托管依赖目录 unmanagedJars：列举unmanagedBase目录下所有jar 的task key dependencyClasspath：非托管依赖classpath compile:_：编译时设置 runtime:_：运行时设置 libraryDependecies：指定依赖、设置classpath 直接列出 Maven POM文件 Ivy配置文件 resolvers：指定额外解析器，Ivy搜索服务器指示 externalResolvers：组合resolvers、默认仓库的task key 定制其以覆盖默认仓库 运行相关 package：打包系列Task 类型：TaskKey[File]的task key 返回值：生成的jar文件 compile：编译系列Task .sbt特殊方法 常用类型String等的方法仅在.sbt中可用 方法的具体行为、返回值略有差异 XXXXKey[T]： :=：给Setting[T]赋值、计算，并返回Setting[T] SettingKey[T].:=返回Setting[T] TaskKey[T].:=返回Setting[Task[T]] in：获取其他Key的子Key 1sourceDirectories in Compile += Seq(file(&quot;1&quot;), file(&quot;2&quot;)) SettingKey[T]： +=：追加单个元素至列表 ++=：连接两个列表 String %：从字符串构造Ivy ModuleID对象 %%：sbt会在actifact中加上项目的scala版本号 也可手动添加版本号替代 很多依赖会被编译给多个Scala版本，可以确保兼容性 at：创建Resolver对象 依赖非托管依赖非托管依赖：lib/目录下的jar文件 其中jar被添加进classpath 对compile、test、run、console都成立 可通过dependencyClasspath改变设置[某个]classpath 相关Key使用1234567// 定制非托管依赖目录dependencyClasspath in Compile += &lt;path&gt;dependencyClasspath in Runtime += &lt;path&gt;// 定制非托管目录unmanagedBase := baseDirectory.value / &quot;custom_lib&quot;// 清空`compile`设置列表unmanagedJars in Compile := Seq.empty[sbt.Attributed[java.io.File]] 托管依赖托管依赖：由sbt根据build.sbt中设置自动维护依赖 使用Apache Ivy实现托管依赖 默认使用Maven2仓库 格式123dep_exp ::= &lt;groupID&gt; % &lt;artifactID&gt; % &lt;revision&gt;[% &lt;configuraion&gt;] [% &quot;test&quot; | % Test] [% &quot;provided&quot;]resolver_exp ::= &lt;name&gt; at &lt;location&gt; groupID： acrtifactID：工件名称 revision：版本号，无需是固定版本号 &quot;latest.integration&quot; &quot;2.9.+&quot; [1.0,) 可选选项 &quot;test&quot;|Test：仅在Test配置的classpath中出现 &quot;provided&quot;：由环境提供，assembly打包时将不打包该 依赖 name：指定Maven仓库名称 location：服务器地址 依赖添加1234567891011// `sbt.Keys`中依赖声明val libraryDependencies = settingKey[Seq[ModuleID]](&quot;Delares managed dependencies&quot;)// 添加单个依赖libraryDependencies += dep_exp// 添加多个依赖libraryDependencies ++= Seq( dep_exp, dep_exp, &lt;groupID&gt; %% &lt;artifactID&gt; % &lt;revision&gt;) 解析器添加123456789101112// `sbt.Keys`中解析器声明val resolvers += settingKeys[Seq[Resolver]](&quot;extra resolvers&quot;)// 添加本地Maven仓库resolvers += resolver_expresolvers += Resolver.mavenLocalresolvers += &quot;Loal Maven Repo&quot; at &quot;file://&quot; + Path.userHome.absolutePath+&quot;/.m2/repository&quot;// 将自定义解析器至于默认`externalResolvers`前externalResolvers := Seq( resolver_exp) ++ externalResolvers.values externalResolvers中包含默认解析器，sbt会将此列表值拼接 至resolvers之前，即仅修改resolvers仍然会有限使用默认 解析器 其他配置project/plugins.sbt123// assembly插件// `assembly`：将依赖加入jar包，修改jar包配置文件addSbtPlugin(&quot;com.eed3si9n&quot; % &quot;sbt-assembly&quot; % &quot;0.14.6&quot;)","link":"/Java/Scala/sbt.html"},{"title":"PAC（Proxy Auto-Config）","text":"pac事实上是一个js脚本，定义如何根据浏览器器访问url不同， 自动选取适当proxy 主函数str = function FindProxyForUrl(url, host){ } 参数 url：浏览器访问的完整url地址，如： http://bing.com host：url中的host部分bing.com 返回值：字符串变量，表示应该使用何种”代理“，可以是 以下元素，或者是使用;分隔的多个组合，此时浏览器依次 尝试 （“据说”每隔30min，浏览器就会尝试之前失败的“代理元素”） DIRECT：不使用代理，直接连接 PORXY host:post：使用指定http代理@host:post SOCKS host:post：使用指定socks代理 SOCKS5 host:post：使用指定的socks5代理 浏览器在访问每个url时都会调用该函数 可用预定义JS函数host、domain、url相关js函数 bool = isPlainHostName(host)：host不包含域名返回 true true = isPlainHostName(“www”) false = isPlainHostName(“baidu.com”) bool = dnsDomainIs(host, domain)：host和domain相 匹配返回true true = dnsDomain(“www.google.com”, “.google.com”) false = dnsDomain(“www.apple.com”, “.google.com”) bool = localHostOrDomainIs(host,domain) ：host和 domain匹配、host不包含domain返回true（按照函数名 理解） true = localHostOrDomainIs(“www.google.com”, “www.google.com”) true = localHostOrDomainIs(“www”, “www.google.com”) false = localHostOrDomainIs(“www.apple.com”, “www.google.com”) bool = isResolvable(host)：成功解析host返回true bool = isInNet(host, pattern, mask)：host处于 pattern指定网段/地址返回true， host如果不是ip 形式，将解析成ip地址后处理；mask指定匹配部分，mask 就是和子网掩码类似 isinnet(“192.168.3.4”, “192.168.0.0”, “255.255.0.0”) -&gt; true isinnet(“192.168.3.4”, “192.168.0.0”, “255.255.255.255”) -&gt; false str = myipaddress()：字符串形式返回本机地址 int = dnsdomainlevels(host)：返回host中域名层级数 0 = dnsdomainlevels(“www”) 2 = dnsdomainlevels(“www.google.com”) bool = shexpmatch(str, shexp)：str符合shexp 正则表达式返回true shexpmatch(“www.apple.com/downloads/macosx/index.html”, “/macosx/“) -&gt; true. shexpmatch(“www.apple.com/downloads/support/index.html”, “/macosx/“) -&gt; false. 时间相关JS函数 bool = weekdayrange(wd1, wd2, gmt)：时间处于指定时间段 返回true weekdayrange(“mon”, “fri”) 星期一到星期五(当地时区)为true weekdayrange(“mon”, “fri”, “gmt”) 从格林威治标准时间星期一到星期五为true weekdayrange(“sat”) 当地时间星期六为true weekdayrange(“sat”, “gmt”) 格林威治标准时间星期六为true weekdayrange(“fri”, “mon”) 从星期五到下星期一为true(顺序很重要) bool = daterange(..)：时间处于指定时间段返回true （包括首尾日期） daterange(1) 当地时区每月第一天为true daterange(1, “gmt”) gmt时间每月的第一天为true daterange(1, 15) 当地时区每月1号到15号为true daterange(24, “dec”) 在当地时区每年12月24号为true daterange(24, “dec”, 1995) 在当地时区1995年12月24号为true daterange(“jan”, “mar”) 当地时区每年第一季度(1月到3月)为true daterange(1, “jun”, 15, “aug”) 当地时区每年6月1号到8月15号为true daterange(1, “jun”, 15, 1995, “aug”, 1995) 当地时区1995年6月1号到8月15号为true daterange(“oct”, 1995, “mar”, 1996) 当地时区1995年10月到1996年3月为true daterange(1995) 当地时区1995年为true daterange(1995, 1997) 当地时区1995年初到1997年底为true bool = timerange(..)：时间处于指定时间段返回true timerange(12)中午12点到下午1点之间为true timerange(12, 13)同上例 timerange(12, “gmt”)在gmt时间中午12点到下午1点之间为true timerange(9, 17)上午9点到下午5点之间为true timerange(8, 30, 17, 00)上午8点30分到下午5点之间为true. timerange(0, 0, 0, 0, 0, 30)午夜0点到其后的30秒内为true","link":"/Web/Proxy/pac.html"},{"title":"Web 代理","text":"代理 正向代理：模拟client的代理 反向代理：模拟server的代理，通常带有负载均衡，通常不处理 用户数据，也有可能处理静态数据（图片，静态页面等），典型 就是nginx服务器","link":"/Web/Proxy/web_proxy.html"},{"title":"Thrift简介","text":"Thrift架构 Thrift是跨语言、C/S模式、服务器部署框架 使用Interface Definition Language（IDL）定义RPC接口 、数据类型 然后通过Thrift编译器生成不同语言的代码，并由生成 代码负责RPC协议层、传输层实现 支持服务器端和客户端编译生成代码为不同语言 客户端、服务端代码调用生成代码搭建C/S Thrift支持动态（执行）、静态（编译） Thrift网络栈 TTransport传输层，定义数据传输方式 可以是TPC/IP、共享内存、共享文件等，作为运行时库 提供了一个简单的网络读写抽象层，使Thrift底层TTransport 从系统其他部分（如：序列化、反序列化）解耦 接口方法包括 open close read write listen accept flush 传输协议 TSocket：阻塞式socket TFramedTransport：frame为单位进行传输，非阻塞式 TFileTransport：文件形式传输 TMemoryTransport：直接对内存进行I/O Java实现时使用了简单的ByteArrayOutputStream TZlibTransport：使用zlib进行压缩，同其他方式联合使用 目前无java实现 TProtocol协议层，定义数据传输格式 定义了一种将内存的数据结构映射成可传输格式的机制，即定义 数据类型在TTransport和自身间进行解、编码 需要实现编码机制，负责对数据进行序列化、反序列化 数据格式 TBinaryProtocal：二进制格式 TCompactProtocal：压缩格式 TJSONProtocol：JSON格式 TSimpleJSONProtocal：提供JSON只写协议，生成文件容易 通过脚本语言解析 TDebugProtocol：简单易懂的可读文本格式，便于debug TProcessor封装了从输入数据流中读取、向输出数据流中写的操作 读写数据流用TProtocol对象表示 和服务相关的TProcessor由Thrift编译器产生 工作流程 使用输入TProtocol从连接中读取数据 将处理授权给用户实现的handler 使用输出TProtocol向连接中写入数据 服务模型 创建TTransport对象 为TTransport对象创建输入、输出TProtocol对象 基于输入、输出TProtocol对象创建TProcessor对象 等待连接请求，交由TProcessor处理 支持的服务模型 TSimpleServer：简单单线程服务模型 TThreadPoolServer：多线程服务模型，使用标准阻塞式I/O TNonblockingServer：多线程服务模型，使用非阻塞式I/O 需使用TFrameTransport传输方式 Thrift语法句法 支持shell的#注释、C/C++的////**/注释 struct等复杂类型定义中 类型名和{之间必须有空格 各字段之间,分割（末尾不能有,） 方法可以使用;、,结尾 函数参数 可以是基本类型、结构体 参数是常量const，不能作为返回值 返回值 可以是基本类型、结构体 数据类型基本类型不支持无符号整形 bool byte i16 i32 i64 double string binary：字节数组 泛型（容器）容器中元素类型可以是除了service以外的任何类型（包括结构体、 异常） map&lt;t1, t2&gt;：字典 list&lt;t1&gt;：列表 set&lt;t1&gt;：集合 结构体Thrift结构体概念上同C结构体：将相关数据封装 123456struct Work { 1: i32 num1=0, 2: i32 num2, 3: Operation op, 4: optional string comment,} 编译为面向对象语言时：将被转换为类 结构体中，每个字段包含 整数ID 数据类型 字段名 可选的默认值 字段可选：规范的struct定义中，每个域都使用optional 、required关键字标识 optional：字段未设置时，序列化输出时不被包括 required：字段未设置时，Thrift给与提示 不支持继承 Exception1234exception InvalidOperation { 1: i32 what, 2: string why} 异常在语法、功能上类似于结构体，使用exception声明，但 语义不同 ServiceThrift编译器根据选择的目标语言为server产生服务接口代码，为 client产生桩代码 函数、参数列表定义方式同struct 支持继承：extends 123456service Twitter { # Twitter和`{`中需要有空格 void ping(), bool postTweet(1: Tweet tweet); TweetSearchResult searchTweets(1: string query); oneway void zip(); enum枚举类型 枚举常量必须时32位正整数 123456enum TweetType { TWEET, RETWEET = 2, DM = 0xa, REPLY} const常量 复杂类型、结构体可以使用JSON标识 12const i32 INT_CONST = 1234const map&lt;string, string&gt; MAP_CONST = {&quot;hello&quot;: &quot;world&quot;, &quot;1&quot;: &quot;2&quot;} typedef1typedef i32 new_type namespaceThrift命名空间同C++中namespace类似 均提供组织（隔离）代码的方式 因为不同的语言有不同的命名空间定义方式（如：python中 module），Thrift允许针对特定语言定义namespace 12namespace cpp com.example.projectnamespace java com.example.project","link":"/Web/Thrift/thrift_intro.html"},{"title":"Keras Readme","text":"常用参数说明 函数书写声明同Python全局说明 以下常用参数如不特殊注明，按照此解释 Common seed=None/int 含义：随机数种子 padding=&quot;valid&quot;/&quot;same&quot;/&quot;causal&quot; 含义：补0策略 “valid”：只进行有效有效卷积，忽略边缘数据，输入 数据比输出数据shape减小 “same”：保留边界处卷积结果，输入数据和数据shape 相同 “causal”：产生膨胀（因果卷积），即output[t] 不依赖input[t+1:]，对不能违反时间顺序的时序 信号建模时有用 默认：valid Layers input_shape=None/(int,...) 含义：输入数据shape Layers只有首层需要传递该参数，之后层可自行推断 传递tuple中None表示改维度边长 默认：None，由Layers自行推断 data_format=None/&quot;channels_last&quot;/&quot;channels_first&quot; 含义：通道轴位置 类似于dim_ordering，但是是Layer参数 默认 大部分：None由配置文件（默认”channels_last”） 、环境变量决定 Conv1DXX：”channels_last” 其实也不一定，最好每次手动指定 dim_ordering=None/&quot;th&quot;/&quot;tf&quot; 含义：中指定channals轴位置(thbatch后首、tf尾） 默认：None以Keras配置为准 注意：Deprecated，Keras1.x中使用 Conv Layers filters(int) 含义：输出维度 对于卷积层，就是卷积核数目，因为卷积共享卷积核 对于局部连接层，是卷积核组数，不共享卷积核 ，实际上对每组有很多不同权重 kernel_size(int/(int)/[int]) 含义：卷积核形状，单值则各方向等长 strides(int/(int)/[int]) 含义：卷积步长，单值则各方向相同 默认：1移动一个步长 dilation_rate(int/(int)/[int]) 含义：膨胀比例 即核元素之间距离 dilation_rate、strides最多只能有一者为1， 即核膨胀、移动扩张最多只能出现一种 默认：1不膨胀，核中个元素相距1 use_bias=True/False 含义：是否使用偏置项 默认：True使用偏置项 activation=str/func 含义：该层激活函数 str：预定义激活函数字符串 func：自定义element-wise激活函数 默认：None不做处理（即线性激活函数） kernel_initializer=str/func 含义：权值初始化方法 str：预定义初始化方法名字符串 （参考Keras Initializer） func：初始化权重的初始化器 默认：glorot_uniform初始化为平均值 bias_initializer=str/func 含义：偏置初始化方法 str：预定义初始化方法名字符串 func：初始化权重的初始化器 默认：zeros初始化为全0 kernel_regularizer=None/obj 含义：施加在权重上的正则项 （参考Keras Regularizer对象） 默认：None不使用正则化项 bias_regularizer=None/obj 含义：施加在偏置上的正则项 （参考Keras Regularizer对象） 默认：None不使用正则化项 activity_regularizer=None/obj 含义：施加在输出上的正则项 （参考Keras Regularizer对象） 默认：None不使用正则化项 kernel_constraint=None/obj 含义：施加在权重上的约束项 （参考Keras Constraints） 默认：None不使用约束项 bias_constraint=None 含义：施加在偏置上的约束项 （参考Keras Constraints） 默认：None不使用约束项","link":"/Python/Keras/README.html"},{"title":"激活函数","text":"通过设置单独的激活层实现 1234from keras.layers import Activation, Densemodel.add(Dense(64))model.add(Activation('tanh')) 也可以在构造层对象时通过传递activation参数实现 1model.add(Dense(64, activation='tanh')) 可以通过传递一个逐元素运算的Theano/TensorFlow/CNTK函数 来作为激活函数 1234from keras import backend as Kmodel.add(Dense(64, activation=K.tanh))model.add(Activation(K.tanh)) softmax 1234softmax( x(tensor), axis=-1/int) Softmax激活函数 参数 x：张量 axis：整数，代表softmax所作用的维度 返回值：softmax变换后的张量。 异常： ValueError： In case dim(x) == 1 elu1234elu( x, alpha=1.0/num) 指数线性单元 参数 alpha：一个标量，表示负数部分的斜率。 返回值：线性指数激活 如果 x &gt; 0，返回值为 x 如果 x &lt; 0 返回值为 alpha * (exp(x)-1) 参考文献 Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) selu1selu(x) 可伸缩的指数线性单元（SELU）。 参数 x: 一个用来用于计算激活函数的张量或变量。 返回值：可伸缩线性指数激活 可伸缩的指数线性激活：scale * elu(x, alpha) （scale, alpha应该是预定义常数？） 注意 与「lecun_normal」初始化方法一起使用。 与 dropout 的变种「AlphaDropout」一起使用。 只要正确初始化权重（参见 lecun_normal 初始化方法） 并且输入的数量「足够大」（参见参考文献获得更多信息） ，选择合适的alpha和scale的值，就可以在两个连续层 之间保留输入的均值和方差 参考文献 Self-Normalizing Neural Networks softplus1softplus(x) Softplus 激活函数 返回值：$log(exp(x) + 1)$ softsign1softsign(x) Softsign 激活函数 返回值：$x / (abs(x) + 1)$ relu12345relu( x, alpha=0.0, max_value=None) 线性修正单元。 参数 alpha：负数部分的斜率。默认为 0。 max_value：输出的最大值 返回值：线性修正单元激活 x &gt; 0：返回值为 x x &lt; 0：返回值为 alpha * x 如果定义了max_value，则结果将截断为此值 tanh1tanh(x) 双曲正切激活函数 sigmoid1sigmoid(x) Sigmoid 激活函数 hard_sigmoid1hard_sigmoid(x) Hard sigmoid 激活函数。 说明 计算速度比 sigmoid 激活函数更快。 返回值：Hard sigmoid 激活： x &lt; -2.5：返回 0 x &gt; 2.5：返回 1 -2.5 &lt;= x &lt;= 2.5：返回 0.2 * x + 0.5 linear1linear(x) 线性激活函数（即不做任何改变）","link":"/Python/Keras/acitivation.html"},{"title":"Keras 安装配置","text":"Keras配置文件$HOME/.keras/keras.json12345678910{ &quot;image_data_format&quot;: &quot;channel_last&quot;, # 指定Keras将要使用数据维度顺序 &quot;epsilon&quot;: 1e-07, # 防止除0错误数字 &quot;flaotx&quot;: &quot;float32&quot;, # 浮点数精度 &quot;backend&quot;: &quot;tensorflow&quot; # 指定Keras所使用后端}","link":"/Python/Keras/config.html"},{"title":"Matplotlib约定","text":"函数书写声明 函数书写声明同Python全局 以下常用参数如不特殊注明，按照此解释 Pyplot data=dict/pd.DataFrame 其他 属于kwargs中参数 传参时，相应键值对替代对应参数","link":"/Python/README.html"},{"title":"Matplotlib 配置","text":"配置文件matplotlibrc配置文件路径 /current/dir/matplotplibrc $MATPLOTLIBRC/matplotlibrc ~/.config/matplotlib/matplotlibrc(~/.matplotlib/matplotlibrc) /path/to/matlabplot/mpl-data/matplotlibrc 查看实际路径1$ python -c 'import matplotlib as mpl; print(mpl.matplotlib_fname())' 中文问题字符编码问题 python2中默认字符编码方案是ascii，需要更改为utf-8 123import sysreload(sys)sys.setdefaultencoding(&quot;utf8&quot;) python3则默认为utf-8编码，无需其他操作 字体文件缺失 mpl不兼容ttc文件，只能识别ttf文件 mpl默认使用/path/to/matplotlib/mpl-data/fonts中的字体 文件 ttc和ttf格式参见cs_program/character 管理单个图表 通过mpl字体管理器管理单个图表元素字体 对每个需要使用该字体的图表元素，都需要传递相应的参数 无需字体都不需要安装 12ch=mpl.font_manager.FontProperties(fname=/path/to/font.ttf)ax.set_title(name, fontproperties=ch) 运行时配置MPL默认字体1234567 # 必须在`plt.plot()`类似的绘图语句执行之前执行 # `font-name`为已安装字体名称而不是字体文件名mpl.rcParams['font.default-font-family'].insert(0, font-name) # 查看当前默认font-familympl.font_manager.FontProperties().get_family() # 一般默认字体族是&quot;sans-serif&quot;，所以应该将字体名称插入其首位mpl.rcParams['font.sans-serif'].insert(0, font-name) 运行时指定“已安装”字体给当前执行mpl配置中默认字体 系统中已安装ttf字体，即fc-查找目录 /usr/share/fonts/ $HOME/.local/share/fonts/ $HOME/.fonts/ /path/to/matplotlib/mpl-data/fonts/中字体文件对应 字体 已安装字体指mpl.font_manager.FontManager能找到字体，但 不是所有系统已安装字体，mpl均可找到、使用 12# 获取mpl所有可用字体并排序sorted([i.name for i in mpl.font_manager.FontManger().ttflist]) 字体文件问题：mpl不兼容ttc字体文件 缓存问题：mpl可能在~/.cache/matplotlib/下有cache 文件，mpl会直接从中获取可用字体列表，新字体可能需 删除才能在mpl中生效 12# 获取mpl缓存文件夹mpl.get_cachedir() 修改MPL配置文件 修改配置文件更改全局默认字体 将字体名称添加在默认字体族首位，作为最优先候选字体 1font.sans-serif : font-name, 同样要求mpl能够找到、使用相应的字体文件 图片显示X11依赖 mpl一般在常用于包含有X11的图形化界面中，所以若X11不可用 则需修改mpl配置 对生成pdf、png、svg等，可以修改后端为Agg 运行时修改 1234import matplotlib as mpl# 须在导入`pyplot`前执行mpl.use(&quot;Agg&quot;)from matplotlib import pyplot as plt 修改配置文件 1backend: TkAgg By default, matplotlib ships configured to work with a graphical user interface which may require an X11 connection. Since many barebones application servers don’t have X11 enabled, you may get errors if you don’t configure matplotlib for use in these environments. Most importantly, you need to decide what kinds of images you want to generate(PNG, PDF, SVG) and configure the appropriate default backend. For 99% of users, this will be the Agg backend, which uses the C++ antigrain rendering engine to make nice PNGs","link":"/Python/Matplotlib/config.html"},{"title":"Matplotlib.plot笔记","text":"图像元素Figure整个窗口（句柄） 12fig=plt.figure(num=None, figsize=None, dpi=None,facecolor=None, edgecolor=None, frameon=True) Axes图像（子图）（句柄） 12345678910111213None=plt.subplot(*arg, **karg) // 创建并激活axesNone=plt.subplot(num=int(row-col-index)None=plt.subplot(row, col, index)fig, axs=plt.subplots(rows=int, cols=int)fig.add_subplot(rows=int, cols=int, index=int)ax=fig.add_axes(rect=[left,buttom,width,height], projection='aitoff'/'hammer'...) // 指定地点、大小子图 // `rect`参数是百分比 Axies轴 说明 这三个图像元素都是以句柄形式操作，可以理解为每次操作 都是在一个“容器”中操作，容器由plt管理，每次 plt.show()将图像全部展示之后，容器被回收，创建新容器 因此plt.show()之后，之前容器中的元素更改无法影响到新容器 plt可以当作当前激活状态的axes元素的句柄使用 绘图线图1234567891011121314151617181920None=ax(*args, **kwargs) # `args` # [x]=range(len(y))/list # y=list # [fmt]=str # `kwargs` # data：类似df、dict的indexable对象，传递时x、y可用 标签代替 # linewidth # markersize # color # marker # linestyle# examplesNone=ax([x], y, [fmt], [x2], y2, [fmt2], **kwargs）None=ax('xlabel', 'ylabel', data=indexable_obj)None=ax(2d-array[0], 2d-array[1:]) 柱状图123456789101112131415list=ax.bar(*args, **kwargs) # `args` # x=list # height=num/list # [width]=num/list # [bottom]=num/list # `kwargs` # align='center'/'edge' # agg_filter=func # alpha=None/float # capstyle='butt'/'round'/'projecting'#todo 饼图1234567list=ax.pie(x, explode=None/list(%), labels=None/list, colors=None/list(color), autopct=None/str/func, pctdistance=0.6, shadow=False, labeldistance=1.1, startangle=None, radius=None/float, counterclock=True, textprops=None, center=(0,0), frame=False, rotatelables=False, hold=None, data=None/dict(param_above)) 箱线图12list=ax.boxplot(x, notch=False, sym=None/str, vert=True, whis=1.5/str/list)","link":"/Python/Matplotlib/plt.html"},{"title":"Jupyter 常用基础","text":"配置文件生成配置文件12$ jupyter notebook --generate-config # 生成配置文件，默认为`~/jupyter/jupyter-notebook-config.py` 修改配置文件1234567891011121314c.NotebookApp.password = u'sha1:xxxxxxxx' # 配置sha1格式密文，需要自己手动生成c.NotebookApp.ip = &quot;*&quot; # 配置运行访问ip地址c.NotebookApp.open_brower = False # 默认启动时不开启浏览器c.NotebookApp.port = 8888 # 监听端口，默认c.NotebookAPp.notebook_dir = u&quot;/path/to/dir&quot; # jupyter默认显示羡慕路径c.NotebookApp.certfile = u&quot;/path/to/ssl_cert_file&quot;c.NotebookAppp.keyfile = u&quot;/path/to/ssl_keyfile&quot; # jupyter使用ssl证书文件 # 一般只有使用自己生成证书 生成密文123from notebook.auth import passwdpasswd() # 输入密码两次，然后就会返回对应密文，写入配置文件 远程访问jupyter必须使用https登陆、访问 因此服务端必须有ssl证书， 自己生成的证书默认浏览器不认可，浏览器访问会高危， 高级进入即可1openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout key_name.key -out cert_name.pem 访问时也必须加上https://前缀，一般默认http://前缀 会报服务器无响应（没配置重定向，应该是）","link":"/Python/Jupyter/config.html"},{"title":"Numpy Readme","text":"常用参数说明 函数书写说明同Python全局 以下常用参数如不特殊注明，按照此解释 NDArray常用参数基本数组参数 size=None(1)/int/Tuple[int] shape=None/int/Tuple[int] 含义：NDArray形状 int：1维时可直接用整数表示shape tuple：高维至低维指定哥维度大小 -1：由整个size、其余维度推断该维度大小 默认：None、1 dtype=None/str/list/dict/np.dtype/... 含义：指定输出数组数据类型 None：保证精度情况下自动选择数据类型 str、list、dict：可转换为数据类型 np.dtype：np.dtype实例 默认值：None，有内部操作，选择合适、不影响精度类型 order=&quot;K&quot;/&quot;C&quot;/&quot;F&quot;/&quot;A&quot; 含义：指定数组对象（输出）内存布局、迭代顺序 &quot;C&quot;：C-contiguous风格，行优先 &quot;F&quot;：Fortran-contiguous风格，列优先 &quot;A&quot;：除非所有参数数组均为Fortran风格，否则 为C风格 &quot;K&quot;：尽量贴近已有内存布局，原为”C”/“F”方式则 保持不变，否则选择较接近的风格 默认值：”C”/“K” casting=&quot;same_kind&quot;,&quot;no&quot;,&quot;equiv&quot;,&quot;safe&quot;,&quot;unsafe&quot; 含义：类型转换规则 no：不允许任何类型转换 equiv：仅允许字节顺序改变 safe：仅允许可保证数据精度的类型转换 same_kind：只能允许safe或同类别类型转换 unsafe：允许所有类型转换 numpy 1.10及以上版本，缺省为&quot;same_kind&quot; 结果参数 out=None/Tuple[Array]/Array 含义：保存结果的变量 None：由函数自行分配空间 tuple：需要存储多个输出结果的变量元组 Array：仅需要保存单个输出结果的变量元组 默认：None 函数自行分配空间不会初始化，即若其中某些元素未被设置 值，则其值不可预测，如 where非True时，False对应元素 keepdims=False/True 含义：是否维持原维数 True：保留本应被缩减的维度，并设置维度长为1 保证结果和输入操作数广播兼容 False：不保持维数不变 默认：False subok=True/False 含义：是否允许数组子类作为输出 True：允许 False：不允许 默认：True 标记参数 where=True/False/Array[bool] 含义：指示符合条件、需执行操作的bool map True：广播为全True，所有元素 False：广播为全False，所有元素都不 Array[bool]：True表示对应位置的元素满足条件 （需要和输入操作数广播兼容） weekmask=&quot;1111100&quot;/str/list 含义：指示一周内工作日 字符串 1、0按顺序表示周一到周日为、非工作日 空白符、驼峰分割周一至周日全称或缩写 列表：0、1按顺序表示周一到周日为、非工作日 condition=Array[bool,int] 含义：指示符合条件、需要执行操作的bool map Array[bool]：True表示对应位置的元素满足条件 Array[int]：根据是否为0转换为bool数组","link":"/Python/Numpy/README.html"},{"title":"NDArray","text":"NDArray1class ndarray(shape[,dtype,buffer,offset]) ndarray：具有相同类型、大小（固定大小）项目的多维容器 ndarray由计算中内存连续的一维段组成，并与将N个整数 映射到块中项的位置的索引方案相结合 可以共享相同数据段，即可以是其他数据区的视图 另一个ndarray 实现buffer的对象 属性 shape：指定尺寸、项目数量 dtype（data-type object）：指定项目类型 strides：存储各维度步幅，用于计算连续数据段中偏移 https://www.numpy.org.cn/reference/arrays/ndarray.html/https://www.numpy.org.cn/reference/arrays/ndarray.html Broadcast 广播规则Broadcasting：4条广播规则用于处理不同shape的数组 非维数最大者在shape前用1补足 输出的shape中各维度是各输入对应维度最大值 各输入的维度同输出对应维度相同、或为1 输入中维度为1者，对应的（首个）数据被用于沿该轴的 所有计算 （即对应的stride为0，ufunc不step along该维度） 12345shape(3, 2, 2, 1) + shape(1, 3) -&gt; shape(3, 2, 2, 1) + shape(1, 1, 1, 3) -&gt; shape(3, 2, 2, 3) + shape(1, 1, 2, 3) -&gt; shape(3, 2, 2, 3) + shape(1, 2, 2, 3) -&gt; shape(3, 2, 2, 3) + shape(3, 2, 2, 3) 数组属性内存布局 属性 描述 ndarray.flags 有关数组内存布局的信息 ndarray.shape 数组维度（元组） ndarray.strides 遍历数组时每个维度中的字节数量（元组） ndarray.ndim 数组维数 ndarray.data Python缓冲区对象指向数组的数据的开头 ndarray.size 数组中的元素数 ndarray.itemsize 数组元素的长度，以字节为单位 ndarray.nbytes 数组元素消耗的总字节数 ndarray.base 如果内存来自其他对象，则为基础对象 数据类型 属性 描述 ndarray.dtype 元素数据类型 其他属性 属性 描述 ndarray.T 转置 ndarray.real 实数部分 ndarray.imag 虚数部分 ndarray.flat 数组的一维迭代器 数组接口 属性 描述 __array_interface__ 数组接口python端 __array_struct__ 数组接口C语言端 ctypes外部函数接口 属性 描述 ndarray.ctypes 简化数组和ctypes模块交互的对象 np.nditer ndarray对象的默认迭代器是序列类型的默认迭代器 即以对象本身作为迭代器时，默认行为类似 12for i in range(X.shape[0]): pass Routine Function Version Method Version nditer(op[,flags,op_flags,...]) 高性能迭代器 无 nested_iters(op,axes[,flags,op_flags,...]) 在多组轴上嵌套创建nditer迭代器 无 ndenumerate(arr) (idx,val)迭代器 无 lib.Arrayterator(var[,buf_size]) 适合大数组的缓冲迭代 flat 无 返回np.flatiter迭代器 ndindex(*shape) 迭代shape对应数组的索引 无 np.nditer1234567891011class np.nditer( op, flags=None, op_flags=None, op_dtypes=None, order='K'/'C'/'F'/'A', casting='safe', op_axes=None, itershape=None, buffersize=0) 迭代方式 通过标准python接口迭代数组中各数组标量元素 显式使用迭代器本身，访问其属性、方法 np.nditer[0]访问当前迭代的结果 np.iternext()获取下个迭代对象 包含特殊属性、方法获取额外信息（可能需设置迭代标志） 跟踪索引：获取索引np.nditer.index、 np.nditer.multi_index 手动迭代np.nditer.iternext()得到下个 np.nditer对象 获取操作数np.nditer.operands：迭代器关闭之后 将无法访问，需要在关闭前获得引用 https://www.numpy.org.cn/reference/arrays/nditer.html 参数 flags：迭代器标志 buffered：允许缓冲 增大迭代器提供给循环内部的数据块 减少开销、提升性能 c_index：track C顺序索引 f_index：track C顺序索引 multi_index：track 多维索引 common_dtype：将所有操作数转换为公共类型 需设置copying或buffered copy_if_overlap：迭代器决定是否读操作数覆盖写 操作数，还是使用临时副本避免覆盖 delay_bufalloc：延迟缓冲区设置直至reset()函数 调用 允许allocate操作数在其值被复制到缓冲区前初始化 external_loop：迭代一维数组而不是零维数组标量 利于矢量化操作 返回的循环块与迭代顺序相关 grow_inner：允许迭代数组大小大于缓冲区大小 buffered、external_loop均设置情况下 ranged： refs_ok：允许迭代引用类型，如object数组 reduce_ok：允许迭代广播后的readwrite操作数 （也即reduction操作数） zerosize_ok：允许迭代大小为0 op_flags readonly：操作数只能被读取 readwrite：操作数能被读写 writeonly：操作只能被写入 no_broadcast：禁止操作数被广播 contig：强制操作数数据连续 aligned：强制操作数数据对齐 nbo：强值操作数数据按原生字节序 copy：允许临时只读拷贝 updateifcopy：允许临时读写拷贝 allocate：允许数组分配若op中包含None 迭代器为None分配空间，不会为非空操作数分配 空间，即使是广播后赋值空间不足 操作数中op中None对应op_flags缺省为 [&quot;allocate&quot;, &quot;writeonly&quot;] no_subtype：阻止allocate操作数使用子类型 arraymask：表明对应操作数为mask数组 用于从设置有writemasked标志的操作数中选择写回 部分 writemasked：只有arraymask操作数选择的元素被写回 overlap_assume_elementwise：标记操作数只能按照迭代 顺序获取 允许在copy_if_overlap设置的场合，更保守的拷贝 op_dtypes：操作数需求的数据类型 在循环内对单个值进行数据类型转换效率低 迭代器以缓冲、复制整体进行类型转换提高效率 需要同时设置&quot;copy&quot;或&quot;buffered&quot;，否则因无法复制、 缓冲报错（类型不同时） （类型转换不修改原数组值，需要额外空间存储转换后值） order：迭代顺序 C/F：C风格、Fortran风格 A：若所有数组均为Fortran风格则为Fortran风格，否则 为C风格 K：尽量贴近内存布局 allocate操作数的内存布局会兼容此参数设置 casting：指明在拷贝、缓冲时允许的数据类型转换规则 （包括读取、写回数组时可能的类型转换） no：不允许任何类型转换 equiv：仅允许字节顺序改变 safe：仅允许可保证数据精度的类型转换 same_kind：只能允许safe或同类别类型转换 unsafe：允许所有类型转换 op_axes：设置迭代器维度到操作数维度的映射 需为每个操作数设置维度映射 itershape：设置迭代器的shape buffersize：设置缓冲区大小 buffered设置的情况下 0表示默认大小 使用说明 控制迭代顺序 设置order参数 缺省按照内存布局迭代 提高效率 适合不关心迭代顺序场合 123456# 二者迭代顺序完全相同np.nditer(X, order=&quot;K&quot;)np.nditer(X.T)# 指定按C或Fortran顺序np.nditer(X, order=&quot;C&quot;)np.nditer(X, order=&quot;F&quot;) 修改数组值 设置writeonly、readwrite 生成可写的缓冲区数组，并在迭代完成后复制回原始 数组 发出迭代结束信号，将缓冲区数据复制回原始数组 支持with语句上下文管理 迭代完成后手动.close() 可设置allocate标志支持为空操作数分配空间 对None参数op，其op_flags缺省设置为 [&quot;allocate&quot;, &quot;readwrite&quot;] 123with np.nditer(X, op_flags=[&quot;readwrite&quot;]) as it: for x in it: x[...] = 0 迭代一维数组而不是数组标量 缺省返回最低维维度长的一维数组 可以通过设置buffered扩大返回的数组长度 buffersize设置buffered大小，可用此参数决定 返回的数组长度 返回数组长度完全由buffersize决定，与数组shape 无关123a = np.arange(30).reshape(5,6)for x in np.nditer(a, flags=[&quot;external_loop&quot;, &quot;buffered&quot;], buffersize=11): print(x, type(x)) 跟踪、获取索引 1234it = np.nditer(a, flags=[&quot;multi_index&quot;])while not it.finished: print(it[0], it.multi_index) it.iternext() 以特定数据类型迭代 op_dtypes参数设置迭代返回的数据类型 需同时设置&quot;copy&quot;或&quot;buffered&quot;字段 12for x in np.nditer(a, op_dtypes=[&quot;complex128&quot;]): print(np.sqrt(x), end=&quot; &quot;) 迭代器分配空间 allocate标志表示允许为操作数分配空间，即允许空 操作数 若分配空间初值被使用，注意迭代前初始化 （如reduction迭代场合） 1234567def square(a, ret=None): with np.nditer([a, ret], op_flags=[[&quot;readonly&quot;], [&quot;writeonly&quot;, &quot;allocate&quot;]] ) as it: for x, y in it: y[...] = x**2 return ret 外积（笛卡尔积）迭代 设置op_axes参数指定各操作数op各维度位置、顺序 迭代器负责将迭代器维度映射回各操作数维度 类似于手动自由广播 12345678# 指定维度位置、顺序it = np.nditer([a,b,None], flags=[&quot;external_loop&quot;], op_axes=[[0,-1,-1], [-1,0,1],None])# 迭代得到外积with it: for x,y,z in it: z[...] = x*y result = it.operands[2] Reduction迭代 触发条件：可写的操作数中元素数量小于迭代空间 &quot;reduce_ok&quot;需被设置 &quot;readwrite&quot;而不是&quot;writeonly&quot;被设置，即使循环 内部未读 暗含&quot;no_broadcast&quot;必然不被设置 123456789101112131415ret = np.array([0])with np.nditer([a,b], flags=[&quot;reduce_ok&quot;, &quot;external_loop&quot;], op_flags=[[&quot;readonly&quot;], [&quot;readwrite&quot;]]) as it: for x,y in it: y[...] += x# 或者同样设置`allocate`标志，并且在迭代器内设置初始值np.nditer([a, None], flags=[&quot;reduce_ok&quot;, &quot;external_loop&quot;], op_flags=[[&quot;readonly&quot;], [&quot;readwrite&quot;, &quot;allocate&quot;]], op_axes=[None, [0,1,-1]])with it: # 设置初始值 it.operands[1][...] = 0 for x, y in it: y[...] += x result = it.operands[1] nested_iters nested_iters：按维度嵌套nditer 迭代参数类似nditer 12345i, j = np.nested_iters(X, flags=[&quot;multi_index&quot;])for x in i: print(i.multi_index) for y in j: print(&quot;&quot;, j.multi_index, y) flat迭代器 X.flat：返回C-contiguous风格迭代器np.flatiter 支持切片、高级索引 实质上是数组的一维视图 np.ndenumerate np.ndenumerate：多维索引迭代器，返回多维索引、值元组 12for multi_idx, val in np.ndenumerate(X): pass np.broadcast np.broadcast：返回（多个）数组广播结果元组的迭代器 类似广播后zip，即先将数组广播，然后将广播后元素 组合成元组作为迭代器中元素 12for item in np.broadcast([[1,2],[3,4]], [5,6]): pass","link":"/Python/Numpy/ndarray.html"},{"title":"NDArray子类","text":"子类相关钩子属性、方法__array__方法 class.__array_ufunc__(ufunc, method, *inputs, **kwargs) 功能：供自定义以覆盖numpy中ufunc行为 返回操作结果，或NotImplemented （将此方法置None） 参数 ufunc：被调用的ufunc对象 method：字符串，指示调用的ufunc对象的方法 inputs：ufunc顺序参数元组 kwargs：ufunc关键字参数字典 Ufunc、与__array_ufunc__关系参见ufunc部分 class.__array_function__(func,types,args,kwargs) 参数 func：任意callable，以func(*args, **kwargs) 形式调用 types：来自实现` args、kwargs：原始调用的参数 class.__array__finalize(obj) 功能：构造之后更改self的属性 在为obj类型数组分配空间时调用 参数 obj：ndarray子类 class.__array_prepare__(array,context=None) 功能：在ufunc计算前，将ouput数组转换为子类实例、 更新元数据 调用任何ufunc前，在最高优先级的input数组，或指定 的output数组上调用，返回结果传递给ufunc 默认实现：保持原样 class.__array_wrap__(array,context=None) 功能：在将结果返回给用户前，将output数组转换为子类 实例、更新元信息 ufunc计算结果返回给用户前，在最高优先级的output 数组、或指定output对象上调用 默认实现：将数组转换为新 class.__array__([dtype]) 功能：若output对象有该方法，ufunc结果将被写入其 返回值中 若ufunc中所有__array_ufunc__返回NotImplemented，那么 raise TypeError __array__属性 class.__array_priority__ 功能：决定返回对象的数据类型（有多种可能性时） 默认值：0.0 Matrixnp.matrixMatrix对象：继承自ndarray，具有ndarray的属性、方法 Matrix对象的特殊行为 维数始终为2 .ravel()仍然二维 item selection返回二维对象 数学操作 覆盖乘法为矩阵乘法 覆盖幂次为矩阵幂次 属性 默认__array_priority__为10.0 Matrix类被设计用于与scipy.sparse交互，建议不使用 np.mat是np.matrix别名 Matrix对象property属性 Property Desc matrix.T 转置 matrix.H 复数共轭 matrix.I 逆矩阵 matrix.A 返回ndarray Matrix创建 Routine Desc np.mat(data[,dtype]) 创建矩阵 np.matrix(data[,dtype,copy]) 不建议使用 np.asmatrix(data[,dtype]) 将数据转换为矩阵 np.bmat(obj[,ldict,gdict]) 从字符串、嵌套序列、数组中构建 mp.bmat：可使用Matlab样式字符串表示法创建Matrix 空格分割列 ;分割行 np.matlib numpy.matlib模块中包含numpy命名空间下所有函数 返回matrix而不是ndarray matrix被限制为小于2维，会改变形状的函数可能无法 得到预期结果 np.matlib是为了方便矩阵运算的模块 np.charnp.chararray np.chararray类：string_、unicode_数据类型的增强型 数组，继承自ndarray 继承由Numarray引入的特性：项检索和比较操作中，数组 元素末尾空格被忽略 定义有基于元素的+、*、%的操作 具有所有标准string、unicode方法，可以逐元素执行 Routine Function Version char.array(obj[,itemsize,...]) char.asarray(obj[,itemsize,...]) 转换输入为chararray，必要时复制数据 chararray(shape[,itemsize,unicode,...]) 不应直接使用此构造函数 np.chararray类是为了后向兼容Numarray，建议使用 object_、string_、unicode_类型的数组替代，并利用 numpy.char模块的自由函数用于字符串快速向量化操作 NDArray Char Routine np.char/np.core.defchararray模块为np.string_、 np.unicode_类型的数组提供向量化的字符串操作 基于标准库中string、unicode的方法 字符串操作 Routine Function Version char.add(x1,x2) char.multiply(a,i) char.mod(a,values) %格式化（str.__mod__为%调用方法） char.capialize(a) 首字符大写 char.title(a) 单词首字符大写 char.center(a,width[,fillchar]) a居中、fillchar填充字符串 char.ljust(a,width(,fillchar)) a靠左 char.rjust(a,width(,fillchar)) a靠左 char.zfill(a,width) 0填充左侧 char.char.decode(a[,encoding,errors]) char.char.encode(a[,encoding,errors]) char.char.expandtabs(a[,tabsize]) 替换tab为空格 char.join(sep, seq) char.lower(a) char.upper(a) char.swapcase(a) char.strip(a[,chars]) char.lstrip(a[,chars]) char.rstrip(a[,chars]) char.partition(a,sep) 从左至右切分一次，返回三元组 char.rpartition(a,sep) 从右至左切分一次 char.split(a[,sep,maxsplit]) 从左至右切分maxsplit次，返回列表 char.rsplit(a[,sep,maxsplit]) char.splitlines(a[,keepends]) 切分行，即\\n为切分点 char.replace(a,old,new[,count]) Camparison Function Desc equal(x1,x2) greater(x1,x2) less(x1,x2) not_equal(x1,x2) greater_equal(x1,x2) less_equal(x1,x2) compare_chararrays(a,b,com_op,rstrip) com_op指定比较方法 字符串信息 Function Desc count(a,sub[,start,end]) 统计不重叠sub出现次数 startwith(a,prefix[,start,end]) endswith(a,suffix[,start,end]) find(a,sub[,start,end]) 返回首个sub位置，不存在返回-1 rfind(a,sub[,start,end]) 从右至左find index(a,sub[,start,end]) 同find，不存在ValueError rindex(a,sub[,start,end]) 从右至左index isalpha(a) iaalnum(a) isdecimal(a) isdigit(a) islower(a) isnumeric(a) isspace(a) istitle(a) 是否各单词首字符大写 isupper(a) str_len(a) np.rec np.rec/np.core.records np.recarray np.recarray类：允许将结构化数组的字段作为属性访问 Routine Function Version np.recarray 创建允许属性访问字段的ndarray np.record 允许使用属性查找字段的数据类型标量 Record Arrays Routine Function Version core.records.array(obj[,dtype,shape,...]) 从多类型对象中创建 core.records.fromarrays(arrayList[,dtype,...]) 从数组列表中创建 core.records.fromrecords(recList[,dtype]) 从文本格式的records列表创建 core.records.fromstring(datastring[,dtype,...]) 从二进制数据字符串中创建只读 core.records.fromfile(fd[,dtype,shape,...]) 从二进制文件中创建 np.mama.MaskedArray ma.MaskedArray：掩码数组，是np.ma核心，ndarray子类 ma.MaskedArray由标准np.ndarray和掩码组成 掩码数组.mask 掩码可以被设置为hardmask、softmask，由只读属性 hardmask指定 hardmask：无法修改被遮蔽值 softmask：可修改被遮蔽值，并恢复被遮蔽状态 .mask可以被设置 为bool数组，指示各位置元素是否被遮蔽 ma.maskded/ma.unmask/True/False，设置掩码数组 整体是被遮蔽 ma.nomask是np.bool_类型的False，ma.masked是特殊 常数 ma.MaskType是np.bool_别名 https://www.numpy.org.cn/reference/arrays/maskedarray.html https://www.numpy.org.cn/reference/routines/ma.html 属性 Attr Desc .hardmask 硬掩码标志 .data 值数组 .mask 掩码数组、ma.unmask、ma.masked .recordmask 项目中命名字段全遮蔽则遮蔽 创建掩码数组 Routine Function Version Method Version ma.MaskedArray(data[,mask,dtype,...]) 类 无 ma.masked_array(data[,mask,dtype,...]) MaskedArray别名 无 ma.array(data[,dtype,copy,...]) 构造函数 无 ma.frombuffer(buffer[,dtype,count,offset]) 无 ma.fromfunction(function,shape,dtype) 无 ma.fromflex(fxarray) 从有_data、_mask字段的结构化fxarray中创建 无 copy(a[,order]) Ones and Zeros Routine Function Version ma.empty(shape[,dtype,order]) 无初始化 ma.empty_like(prototype[,dtype,order,subok,...]) shape、类型同prototype ma.ones(shape[,dtype,order]) ma.zeros(shape[,dtype,order]) ma.masked_all(shape[,dtype]) 所有元素被屏蔽 ma.masked_all_like(shape[,dtype]) MaskedArray Routine np.ma模块下的函数、ma.MaskedArray方法和ndarray 类似，但行为可能不同 np命名空间下部分函数（hstack等）应用在 MaskedArray上 操作时忽略mask（即会操作被遮罩元素） 返回结果中mask被置为False 这里仅记录ma模块中额外、或需额外说明部分 数组检查 Routine Function Version Method Version ma.all(a[,axis,out,keepdims]) 全遮蔽时返回ma.masked ma.any(a[,axis,out,keepdims]) 存在遮蔽时返回ma.masked ma.count(arr,[axis,keepdims]) 沿给定轴统计未被遮罩元素数量 ma.count_masked(arr,[axis]) 沿给定轴统计被遮罩元素数量 ma.nonzero(a) 非0、未屏蔽元素索引 ma.is_mask(m) 是否为标准掩码数组 无 ma.is_masked(x) 是否包含遮蔽元素 获取、创建、修改掩码 Routine Function Version Method Version ma.getmask(a) 返回掩码、或ma.nomask、ma.masked .mask属性 ma.getmaskarray(arr) 返回掩码、或完整False数组 无 ma.make_mask(m[,copy,shrink,dtype]) 从数组创建掩码 无 ma.make_mask_none(newshape[,dtype]) 创建给定形状掩码 无 ma.make_mask_descr(ndtype) 为给定类型的创建掩码类型 无 ma.mask_rowcols(a[,axis]) 遮蔽包含遮蔽元素的axis方向分量 无 ma.mask_rows(a[,axis]) 缺省为0的mask_rowcols() 无 ma.mask_cols(a[,axis]) 缺省为1的mask_rowcols() 无 ma.mask_mask_or(m1,m2[,copy,shrink]) 掩码或 无 ma.harden_mask(a) ma.soften_mask(a) .shrink_mask() 无 尽可能缩小掩码 .share_mask() 无 复制掩码，并设置sharedmask=False 获取、创建索引 索引非结构化掩码数组 mask为False：返回数组标量 mask为True：返回ma.masked 索引结构化掩码数组 所有字段mask均为False：返回np.void对象 存在字段mask为True：返回零维掩码数组 切片 .data属性：原始数据视图 .mask属性：ma.nomask或者原始mask视图 Routine Function Version Method Version ma.nonzero(a) 未屏蔽、非0元素索引 ma.mr_[] 沿第1轴concate切片、数组、标量，类np.r_[] 无 ma.flatnotmasked_contiguous(a) 展平后未遮蔽切片 无 ma.flatnotmasked_edges(a) 展平后首个、末个未遮蔽位置 无 ma.notmasked_contiguous(a[,axis]) 沿给定轴，未遮蔽切片 无 ma.notmasked_edges(a[,axis]) 沿给定轴，首个、末个未遮蔽位置 无 ma.clump_masked(a) 展平后遮蔽切片 无 ma.clump_unmasked(a) 展位后未遮蔽切片 无 ma.mr_[]类似np.r_[]，但np.r_[]返回结果掩码被置为 False，而ma.mr_[]同时也操作掩码 获取、修改值 仅访问有效数据 对掩码mask取反作为索引~X.mask 使用.compressed方法得到一维ndarray 12print(X[~X.mask])print(X.compressed()) 访问数据 通过.data属性：可能是ndarray或其子类的视图 等同于直接在掩码数组上创建ndarray或其子类视图 __array__方法：ndarray 使用ma.getdata函数 Routine Function Version Method Version ma.getdata(a[,subok]) 返回掩码数组数据 .data属性 ma.fix_valid(a[,mask,copy,fill_value]) 替换a中无效值，并遮盖 无 ma.masked_equal(x,value[,copy]) 无 ma.masked_greater(x,value[,copy]) 无 ma.masked_greater_equal(x,value[,copy]) 无 ma.masked_inside(x,v1,v2[,copy]) 无 ma.masked_outside(x,v1,v2[,copy]) 无 ma.masked_invalid(x[,copy]) 无 ma.masked_less(x,value[,copy]) 无 ma.masked_less_equal(x,value[,copy]) 无 ma.masked_not_equal(x,value[,copy]) 无 ma.masked_values(x,value[,rtol,atol,...]) 无 ma.masked_object(x,value[,copy,shrink]) 类masked_values，适合值类型为object时 无 ma.masked_where(condition,a[,copy]) 按condition遮蔽指定值 无 其他属性、方法 Routine Function Version Method Version ma.common_fill_value(a,b) 若a,b填充值相同则返回，否则返回None 无 ma.default_fill_value(obj) 默认填充值 无 ma.maximum_fill_value(obj) 对象类型决定的最大值 无 ma.minimum_fill_value(obj) 无 ma.sef_fill_value(a,fill_value) .get_fill_value()/.fill_value 无 ma.allequal(a,b[,fill_value]) 若a,b元素均相等，则使用fill_value填充 np.ma运算 掩码数组支持代数、比较运算 被遮蔽元素不参与运算，元素在运算前后保持不变 掩码数组支持标准的ufunc，返回掩码数组 运算中任意元素被遮蔽，则结果中相应元素被遮蔽 若ufunc返回可选的上下文输出，则上下文会被处理， 且无定义结果被遮蔽 np.ma模块中对大部分ufunc有特别实现 对于定义域有限制的一元、二元运算，无定义的结果会 自动mask 1ma.log([-1, 0, 1, 2]) Routine Function Version Method Version ma.anom(a[,axis,dtype]) 沿给定轴计算与算数均值的偏差 np.memmap np.memmap：内存映射文件数组，使用内存映射文件作为数组 数据缓冲区 对大文件，使用内存映射可以节省大量资源 方法 |Method|Desc| |——-|——-| |np.memmap(filename[,dtype,mode,shape])|创建存储在磁盘文件的内存映射数组| |np.flush()|flush内存数据至磁盘| 标准容器类 np.lib.user_array.container 为向后兼容、作为标准容器类而引入 其中self.array属性是ndarray 比ndarray本身更方便多继承 类、方法、函数 |Method|Desc| |——-|——-| |np.lib.user_array.container(data[,...])|简化多继承的标准容器类|","link":"/Python/Numpy/ndarray_derived.html"},{"title":"Numpy 索引","text":"索引、切片基本切片、索引 基本切片[Slice]start:stop:step（基本同原生类型切片） start、stop负值时，按维度长取正模 step&gt;0时，start缺省为0、stop缺省为维度长N step&lt;0时，start缺省为N-1、stop缺省为-N-1 stop、start可以超过维度长N Ellipsis/...：放在切片中表示选择所有 ...存在的场合，结果总是数组而不是数组标量，即使其 没有大小 np.newaxis/None：为切片生成数组在所在位置添加长度为 1的维度 切片可以用于设置数组中的值 基本切片可认为是依次对各维度切片，若靠前维度为索引，则 可以把靠前维度独立出来 基本切片生成的所有数组始终是原始数组的视图，也因此存在 切片引用的数组内存不会被释放 注意：基本索引可用于改变数组的值，但是返回值不是对数组 中对应值的引用 高级索引 选择对象为以下类型时会触发高级索引 非元组序列 ndarray（整形或boolean类型） 包含至少一个序列、ndarray（整型或boolean类型）的 元组 高级索引总是返回数据的副本 高级索引结果不能保证任何内存布局 整数索引 整数索引X[obj]允许根据其各维度索引选择数组X任意元素 各整数索引（数组）表示对应维度的索引 各维度索引迭代、连接得到各元素位置：zip(obj*) 索引维数小于数组维数时，以子数组作为元素 （可以理解为索引和数组高维对齐后广播） 整数索引结果shape由obj中各维度索引shape决定 整数索引obj中各维度索引数组会被广播 各维度索引shape可能不同 为保证各维度索引能正常迭代选取元素，各维度索引 shape需要能被广播、符合广播要求 则高级索引出现场合 “普通索引（标量值）”不存在，必然被广播 切片能够共存 切片（包括np.newaxis）和高级索引共存时 高级索引特点导致其结果维度不可割 “标量索引”本应削减该维度 而高级索引整体（广播后）决定唯一shape 高级索引结果维度应整体参与结果构建 高级索引被切片分割：高级索引结果维度整体提前 高级索引相邻：高级索引结果维度填充至该处 高级索引操作结果中无元素，但单个维度索引越界的错误未定义 高级索引结果内存布局对每个索引操作有优化，不能假设特定 内存顺序 12345678X = np.array([[0,1,2],[3,4,5],[6,7,8],[9,10,11]])rows = [0, 3]cols = [0, 2] # 整数索引X[np.ix_(rows, cols)] # 整数索引数组X[[[1,2],[2,1]],:]X.take([[1,2],[2,1]], axis=0) Boolean索引 Boolean索引obj选择其中True处位置对应元素 索引obj维数较数组X小，直接抽取子数组作为元素 （可以理解为索引和数组高维对齐后广播） 索引obj在超出数组X.shape范围处有True值，会引发 索引错误 索引obj在X.shape内未填充处等同于填充False Boolean索引通过.nonezero方法转换为高级整数索引实现 Boolean索引等价于True数量长的1维整数索引 X[..,bool_obj,..]等价于 X[..,bool_obj.nonzero(),..] Boolean索引总是削减对应索引，展开为1维 Boolean索引、高级整数索引共同存在场合行为诡异 Boolean索引转换为等价的整数索引 整数索引需要广播兼容转换后整数索引 整数索引、转换后整数索引整体得到结果 索引obj和数组X形状相同计算速度更快 字段名称形式访问 ndarray中元素为结构化数据类型时，可以使用字符串索引 访问 字段元素非子数组时 其shape同原数组 仅包含该字段数据 数据类型为该字段数据类型 字段元素为子数组时 子数组shape会同原数组shape合并 支持字符串列表形式访问 返回数组视图而不是副本（Numpy1.6后）","link":"/Python/Numpy/ndarray_index.html"},{"title":"NDArray标量","text":"NDArray标量类型 numpy中定义了24种新python类型（NDArray标量类型） 类型描述符主要基于CPython中C语言可用的类型 标量具有和ndarray相同的属性和方法 数组标量不可变，故属性不可设置 内置标量类型 Routine Desc iinfo(int_type) 整数类型的取值范围等信息 finfo(float_type) 浮点类型的取值范围等信息 Python关联 NumPy类型 Python类型 64位NumPy定长类型 Desc int_ 继承自int（Python2） int64 float_ 继承自float float64 complex_ 继承自complex complex128 bytes_ 继承自bytes S#&quot;/&quot;a#&quot; Python字节串 unicode_ 继承自str &quot;U#&quot; Python字符串 void &quot;V#&quot; Python缓冲类型 object_ 继承自object（Python3） &quot;O&quot; Python对象引用 np.bool_类似Python中bool类型，但不继承它 Python中bool类型不允许被继承 np.bool_大小和bool类型大小不同 np.int_不继承自int，因为后者宽度不再固定 NumPy中数组没有真正np.int类型，因为宽度不再固定， 各产品 bytes_、unicode_、void是可灵活配置宽度的类型 在指定长度后不能更改，赋长于指定长度的值会被截断 unicode_：强调内容为字符串 bytes_：强调内容为字节串 void：类型强调内容为二进制内容，但不是字节串 object_存储的是python对象的引用而不对象本身 其中引用不必是相同的python类型 兜底类型 Python基本类型等在NumPy命名空间下都有同名别名，如： np.unicode == np.str == str NumPy数组中数据类型无法被真正设置为int类型，为保证数组 中元素宽度一致性，必然无法被设置为非定长类型 C类型关联 NumPy支持的原始类型和C中原始类型紧密相关 NumPy类型 C类型 64位定长别名 Desc 单字符代码 定长字符串代码 bool_ bool bool8 存储为字节的bool值 &quot;?&quot; 无 byte signed char int8 &quot;b&quot; &quot;i1&quot; short short int16 &quot;h&quot; &quot;i2&quot; intc int int32 &quot;i&quot; &quot;i4&quot; int_ long int64 &quot;l&quot; &quot;i8&quot; longlong long long 无 &quot;q&quot; 无 ubyte unsigned char uint8 &quot;B&quot; &quot;u1&quot; ushort unsigned short uint16 &quot;H&quot; &quot;u2&quot; uintc unsigned int uint32 &quot;I&quot; &quot;u4&quot; uint usigned long uint64 &quot;L&quot; &quot;u8&quot; ulonglong unsigned long long 无 &quot;Q&quot; 无 half 无 float16 半精度浮点：1+5+10 &quot;e&quot; &quot;f2&quot; single float float32 单精度浮点，通常为：1+8+23 &quot;f4&quot; double double float64 双精度浮点，通常为：1+11+52 &quot;d&quot; &quot;f8&quot; longdouble/longfloat long double float128 平台定义的扩展精度浮点 &quot;g&quot; &quot;f16&quot; csingle float complex complex64 两个单精度浮点 &quot;F&quot; &quot;c8&quot; cdouble/cfloat double complex complex128 两个双精度浮点 &quot;D&quot; &quot;c16&quot; clongdouble/clongfloat long duoble complex complex256 两个扩展精度浮点 &quot;G&quot; &quot;c32&quot; float complex、double complex类型定义在complex.h中 C中的定长类型别名定义在stdint.h中 其他类型 Python类型 Desc 单字符代码 定长字符串代码 timedelta64 时间增量 &quot;m&quot; &quot;m8&quot; datetime64 日期时间 &quot;M&quot; &quot;M8&quot; 属性、索引、方法 数组标量属性基本同ndarray 数组标量类似0维数组一样支持索引 X[()]返回副本 X[...]返回0维数组 X[&lt;field-name&gt;]返回对应字段的数组标量 数组标量与ndarray有完全相同的方法 默认行为是在内部将标量转换维等效0维数组，并调用相应 数组方法 定义数组标量类型 从内置类型组合结构化类型 子类化ndarray 部分内部行为会由数组类型替代 完全自定义数据类型，在numpy中注册 只能使用numpy C-API在C中定义 数据类型相关函数数据类型信息 Function Desc finfo(dtype) 机器对浮点类型限制 iinfo(type) 机器对整型限制 MachAr([float_conv,int_conv]) 诊断机器参数 typename(char) 对给定数据类型字符代码的说明 数据类型测试 Function Desc can_cast(from_,to[,casting]) 是否可以类型转换 issctype(rep) rep（不能为可转换字符串）是否表示标量数据类型 issubdtype(arg1,arg2) arg1在数据类型层次中较低（即dtype的issubclass） issubsctype(arg1,arg2) 同issubdtype，但支持包含dtype属性对象作为参数 issubclass_(arg1,arg2) 同内置issubclass，但参数非类时仅返回False，而不是raise TypeError np.int64、np.int32在层次体系中不同、且层级一致，所以 会出现issubdtype(np.int64, int) -&gt; True，其他情况为 False 通过np.can_cast函数确定safely类型转换 1234567891011def print_casting(ntypes): print(&quot;X&quot;) for char in ntypes: print(char, end=&quot; &quot;) print(&quot;&quot;) for row in ntypes: print(row, end=&quot; &quot;) for col in ntypes: print(int(np.can_cast(row, col)), end=&quot; &quot;) print(&quot;&quot;)print_casting(np.typecodes[&quot;All&quot;]) 数据类型确定 Function Params ReturnType ReturnDesc min_scalar_type(a) 标量值 dtype实例 满足要求最小类型 promote_types(type1,type2) dtype等 dtype实例 可安全转换的最小类型 result_type(*array_and_dtypes) dtype等、标量值、数组 dtype实例 应用promotion rules得到类型 find_common_type(array_types,scalar_types) dtype等列表 dtype实例 综合考虑标量类型、数组类型 common_type(*arrays) 数值型数组（有dtype属性） 预定义类型 满足要求类型中、最高精度类型 maximum_sctype(t) dtype等、标量值、数组 预定义类型 满足要求类型中、最高精度类型 obj2sctype(rep[,default]) dtype等、标量值、数组 预定义类型 对象类型 sctype2char(sctype) dtype等、标量值、数组 类型字符代码 满足要求的最小类型 mintypecode(typechars[,typeset,default]) dtype等、标量值、数组 类型字符代码 typeset中选择 除非标量和数组为不同体系内数据类型，否则标量不能up_cast 数组数据类型 https://numpy.org/devdocs/reference/generated/numpy.issubdtype.html#numpy.issubdtype https://numpy.org/devdocs/reference/generated/numpy.issubsctype.html#numpy.issubsctype https://numpy.org/devdocs/reference/generated/numpy.find_common_type.html#numpy.find_common_type https://numpy.org/devdocs/reference/generated/numpy.result_type.html#numpy.result_type https://numpy.org/devdocs/reference/generated/numpy.common_type.html#numpy.common_type 数据类型类np.dtype1class dtype(obj[,align,copy]) numpy.dtype类描述如何解释数组项对应内存块中字节 数据大小 数据内存顺序：little-endian、big-endian 数据类型 结构化数据 各字段名称 各字段数据类型 字段占用的内存数据块 子数组 形状 数据类型 需numpy.dtype实例作为参数的场合，大部分场景可用等价、 可转换为dtype实例的其他值代替 python、numpy中预定义的标量类型、泛型类型 创建dtype实例类型的字符串、字典、列表 包含dtype属性的类、实例 数据类型元素类型类 NumPy内置类型 24中内置数组标量类型 泛型类型 |Generic类型|转换后类型| |——-|——-| |number,inexact,floating|float_| |complexfloating|complex_| |integer,signedinteger|int_| |unsignedinteger|uint| |character|string| |generic,flexible|void| python内置类型，等效于相应数组标量 转换规则同NumPy内置数组标量类型 None：缺省值，转换为float_ |Python内置类型|转换后类型| |——-|——-| |int|int_| |bool|bool_| |float|float_| |complex|complex_| |bytes|bytes_| |str|unicode_| |unicode|unicode_| |buffer|void| |Others|object_| 带有.dtype属性的类型：直接访问、使用该属性 该属性需返回可转换为dtype对象的内容 可转换类型的字符串 numpy.sctypeDict.keys()中字符串 Array-protocal类型字符串，详细参见NumPy数组标量类型 首个字符指定数据类型 支持指定字节数的字符可在之后指定项目占用字节数 定长类型只能指定满足平台要求的字节数 非定长类型可以指定任意字节数 |代码|类型| |——-|——-| |'?'|boolean| |'b'|(signed) byte，等价于'i1'| |'B'|unsigned byte，等价于'u1'| |'i'|(signed) integer| |'u'|unsigned integer| |'f'|floating-point| |'c'|complex-floating point| |'m'|timedelta| |'M'|datetime| |'O'|(Python) objects| |'S'/'a'|zero-terminated bytes (not recommended)| |'U'|Unicode string| |'V'|raw data (void)| 结构化数据类型 Function Desc format_parser(formats,names,titles[,aligned,byteorder]) 创建数据类型 dtype(obj[,align,copy]) 结构化数据类型 包含一个或多个数据类型字段，每个字段有可用于访问的 名称 父数据类型应有足够大小包含所有字段 父数据类型几乎总是基于void类型 仅包含不具名、单个基本类型时，数组结构会穿透 字段不会被隐式分配名称 子数组shape会被添加至数组shape 参数格式 可转换数据类型的字符串指定类型、shape 依次包含四个部分 字段shape 字节序描述符：&lt;、&gt;、| 基本类型描述符 数据类型占用字节数 对非变长数据类型，需按特定类型设置 对变长数据类型，指字段包含的数量 逗号作为分隔符，分隔多个字段 各字段名称只能为默认字段名称 对变长类型，仅设置shape时，会将其视为bytes长度 1dt = np.dtype(&quot;i4, (2,3)f8, f4&quot;) 元组指定字段类型、shape 元组中各元素指定各字段名、数据类型、shape： (&lt;field_name&gt;, &lt;dtype&gt;, &lt;shape&gt;) 若名称为''空字符串，则分配标准字段名称 可在列表中多个元组指定多个字段 [(&lt;field_name&gt;, &lt;dtype&gt;, &lt;shape&gt;),...] 数据类型dtype可以嵌套其他数据类型 可转换类型字符串 元组/列表 123dt = np.dtype((&quot;U10&quot;, (2,2)))dt = np.dtype((&quot;i4, (2,3)f8, f4&quot;, (2,3))dt = np.dtype([(&quot;big&quot;, &quot;&gt;i4&quot;), (&quot;little&quot;, &quot;&lt;i4&quot;)]) 字典元素为名称、类型、shape列表 类似format_parser函数，字典各键值对分别指定名称 列表、类型列表等： {&quot;names&quot;:...,&quot;formats&quot;:...,&quot;offsets&quot;:...,&quot;titles&quot;:...,&quot;itemsize&quot;:...} &quot;name&quot;、&quot;formats&quot;为必须 &quot;itemsize&quot;指定总大小，必须足够大 分别指定各字段：&quot;field_1&quot;:..., &quot;field_2&quot;:... 不鼓励，容易与上一种方法冲突 1234dt = np.dtype({ &quot;names&quot;: ['r', 'g', 'b', 'a'], &quot;formats&quot;: [&quot;u1&quot;, &quot;u1&quot;, &quot;u1&quot;, &quot;u1&quot;]}) 解释基数据类型为结构化数据类型： (&lt;base_dtype&gt;, &lt;new_dtype&gt;) 此方式使得union成为可能 1dt = np.dtype((&quot;i4&quot;, [(&quot;r&quot;, &quot;I1&quot;), (&quot;g&quot;, &quot;I1&quot;), (&quot;b&quot;, &quot;I1&quot;), (&quot;a&quot;, &quot;I1&quot;)])) 属性 描述数据类型 |属性|描述| |——-|——-| |.type|用于实例化此数据类型的数组标量类型| |.kind|内置类型字符码| |.char|内置类型字符码| |.num|内置类型唯一编号| |.str|类型标识字符串| 数据大小 |属性|描述| |——-|——-| |.name|数据类型位宽名称| |.itemsize|元素大小| 字节顺序 |属性|描述| |——-|——-| |.byteorder|指示字节顺序| 字段描述 |属性|描述| |——-|——-| |.fields|命名字段字典| |.names|字典名称列表| 数组类型（非结构化）描述 |属性|描述| |——-|——-| |.subtype|(item_dtype,shape)| |.shape|| 附加信息 |属性|描述| |——-|——-| |.hasobject|是否包含任何引用计数对象| |.flags|数据类型解释标志| |.isbuiltin|与内置数据类型相关| |.isnative|字节顺序是否为平台原生| |.descr|__array_interface__数据类型说明| |.alignment|数据类型需要对齐的字节（编译器决定）| |.base|基本元素的dtype| 方法 更改字节顺序 |方法|描述| |——-|——-| |.newbyteorder([new_order])|创建不同字节顺序数据类型| Pickle协议实现 |方法|描述| |——-|——-| |.reduce()|pickle化| |.setstate()|| Datetime Numpy种时间相关数据类型 支持大量时间单位 基于POSIX时间存储日期时间 使用64位整形存储值，也由此决定了时间跨度 https://www.numpy.org.cn/reference/arrays/datetime.html np.datetime64 np.datetime64表示单个时刻 若两个日期时间具有不同单位，可能仍然代表相同时刻 从较大单位转换为较小单位是安全的投射 创建 创建规则 内部存储单元自动从字符串形式中选择单位 接受&quot;NAT&quot;字符串，表示“非时间”值 可以强制使用特定单位 基本方法：ISO 8601格式的字符串 12np.datetime64(&quot;2020-05-23T14:23&quot;)np.datetime64(&quot;2020-05-23T14:23&quot;, &quot;D&quot;) 从字符串创建日期时间数组 123np.array([&quot;2020-01-23&quot;, &quot;2020-04-23&quot;], dtype=&quot;datetime64&quot;)np.array([&quot;2020-01-23&quot;, &quot;2020-04-23&quot;], dtype=&quot;datetime64[D]&quot;)np.arange(&quot;2020-01-01&quot;, &quot;2020-05-03&quot;, dtype=&quot;datetime64[D]&quot;) np.datetime64为向后兼容，仍然支持解析时区 np.timedelta64 np.timedelta64：时间增量 np.timedelta64是对np.datetime64的补充，弥补Numpy对 物理量的支持 创建 创建规则 接受&quot;NAT&quot;字符串，表示“非时间”值数字 可以强制使用特定单位 直接从数字创建 1np.timedelta64(100, &quot;D&quot;) 从已有np.timedelta64创建，指定单位 注意，不能将月份及以上转换为日，因为不同时点进制不同 1np.timedelta(a, &quot;M&quot;) 运算 np.datetime64可以和np.timedelta64联合使用 12np.datetime64(&quot;2020-05-14&quot;) - np.datetime64(&quot;2020-01-12&quot;)np.datetime64(&quot;2020-05-14&quot;) + np.timedelta64(2, &quot;D&quot;) 相关方法 Function Desc np.busdaycalendar(weekmask,holidays) 返回存储有效工作日对象 np.busday_offset(date,offset[,roll,weekmask,holidays,busdaycal,out]) 工作日offset np.is_busday(date[,weekmask,holidays,busdaycal,out]) 判断是否是工作日 np.busday_count(begindates,enddates[,weekmask,holidays,busdaycal,out]) 指定天数 np.datetime_as_string(arr[,unit,timezone,...]) 转换为字符串数组 np.datetime_date(dtype,/) 获取日期、时间类型步长信息 np.busday_offset中 roll缺省为&quot;raise&quot;，要求date本身为工作日","link":"/Python/Numpy/ndarray_scalars.html"},{"title":"NDArray开发","text":"NDArray Interface/Protocol 数组接口（规范）：为重用数据缓冲区设计的规范 接口描述内容 获取ndarray内容的方式 数组需为同质数组，即其中各元素数据类型相同 接口包含C和Python两个部分 Python-API：对象应包含属性__array_interface__字典 C-API：结构体__array_struct__ https://www.numpy.org.cn/en/reference/arrays/interface.html#python-side Python API __array_interface__：由3个必须字段和5个可选字段构成 shape：各维度长度（使用时注意取值范围） typestr：指明同质数组数据类型的字符串 格式、含义基本同Array-Protocol，但有部分字符 含义不同 但不同于自定义数据类型字符串，不指定结构化数据、 shape，非基本类型就是void，具体含义由descr 给出 |代码|类型| |——-|——-| |'t'|bit| |'b'|boolean| |'B'|unsigned byte| |'i'|(signed) integer| |'u'|unsigned integer| |'f'|floating-point| |'c'|complex-floating point| |'m'|timedelta| |'M'|datetime| |'O'|(Python) objects| |'S'/'a'|zero-terminated bytes (not recommended)| |'U'|Unicode string| |'V'|raw data (void)| descr：给出同质数组中各元素中内存布局的详细描述的 列表 各元素为包含2、3个元素的元组 名称：字符串、或(&lt;fullname&gt;,&lt;basicname&gt;) 形式的元组 类型：描述基础类型字符串、或嵌套列表 shape：该结构的重复次数，若没有给出则表示无 重复 一般此属性在typestr为取值为V[0-9]+时使用， 要求表示的内存字节数相同 缺省为[(''), typestr] data：给出数据位置的2元素元组或暴露有缓冲接口 的对象 元组首个元素：表示存储数组内容的数据区域，指向 数据中首个元素（即offset被忽略） 元素第二个元素：只读标记 缺省为None，表示内存共享通过缓冲接口自身实现， 此时offset用于指示缓冲的开始 strides：存储各维度跃迁的strides的元组 元组各元素为各维度跃迁字节数整形值，注意取值范围 缺省为None，C-contiguous风格 mask：指示数据是否有效的暴露有缓冲接口的对象 其shape需要同原始数据shape广播兼容 缺省为None，表示所有数据均有效 offset：指示数组数据区域offset的整形值 仅在数据为None或为buffer对象时使用 缺省为0 version：指示接口版本 C API __array_struct__：ctype的PyCObject，其中voidptr 指向PyArrayInterface PyCObject内存空间动态分配 PyArrayInterface有相应的析构，访问其之后需要在其上 调用Py_DECREF 12345678910111213141516171819typedef struct{ int two; // 值为2，sanity check int nd; // 维数 char typekind; // 数组中数据类型 int itemsize; // 数据类型size int flags; // 指示如何解释数据的标志 // 5bits指示数据解释的5个标志位 // `CONTIGUOUS` 0x01 // `FROTRAN` 0x02 // `ALIGNED` 0x100 // `NOTSWAPPED` 0x200 // `WRITABLE` 0X400 // 1bit指示接口解释（是否包含有效`descr`字段） // `ARR_HAS_DESCR` 0x800 Py_intptr_t *shape; // shape Py_intptr_t *strides; // strides void *data; // 指向数组中首个元素 PyObject *descr; // NULL或数据描述（需设置`flags`中的`ARR_HAS_DESCR`，否则被忽略）} PyArrayInterface;","link":"/Python/Numpy/ndarray_interface.html"},{"title":"NDArray 科学计算","text":"NumPy Numeric矩阵、向量乘积 Function Desc dot(a,b[,out]) a最后轴与b倒数第二轴的点积，即shape满足线代要求 inner(a,b[,out]) a最后轴与b最后轴的点积 vdot(a,b) 向量点积，多维将被展平 outer(a,b[,out]) 向量外积，多维将被展平 matmul(x1,x2,/[,out,casting,order,...]) 矩阵乘积 tensordot(a,b[,axes]) 沿指定轴计算张量积 einsum(subscripts,*operands[,out,dtype,...]) Einstein求和约定 einsum_path(subscripts,*operands[,optimize]) 考虑中间数组情况下评估计算表达式最小代价 linalg.matrix_power(a,n) 方阵幂 kron(a,b) Kronecker积（矩阵外积，分块） trace(a[,offset,axis1,axis2,dtype,out]) 迹 Einstein求和约定：简化求和式中的求和符号 12345678910111213a = np.arange(0,15).reshape(3,5)b = np.arange(1,16).reshape(3,5)# Transposenp.einsum(&quot;ij-&gt;ji&quot;, a)# Sum allnp.einsum(&quot;ij-&gt;&quot;, a)# Sum along given axisnp.einsum(&quot;ij-&gt;i&quot;, a)np.einsum(&quot;ij-&gt;j&quot;, a)# Multiplynp.einsum(&quot;ij,ij-&gt;&quot;,a,b)# Inner productnp.einsum(&quot;ik,jk-&gt;&quot;,a,b) np.tensordot：张量积，类似普通内积，仅有结构 axes为整形 axes&gt;0：a末尾axes维度、b开头axes维度 内积 axes=0：Kronecker积 axes为2-Tuple：分别指定a、b内积的轴 其他|Function|Desc| |np.i0(X)|第1类修改的Bessel函数，0阶| np.linalg NumPy的线代基于BLAS、LAPACK提供高效的标准底层实现 依赖库可以是NumPy提供的C版本子集 也可是针对特定平台优化的库（更好） OpenBLAS MKL ATLAS np.linalg Function Desc multi_dot(arrays) 自动选择最快的计算顺序计算内积 cholesky(a) cholesky分解 det(a) 行列式 eig(a) 特征值、特征向量（右乘） eigh(a[,UPLO]) Hermitian（共轭对称）或实对称矩阵特征值、特征向量 eigvals(a) 特征值 eigvalsh(a[,UPLO]) Hermitian（共轭对称）或实对称矩阵特征值 inv(a) 矩阵逆 lstsq(a,b[,rcond]) 最小二乘解 norm(x[,ord,axis,keepdims]) 矩阵、向量范数 pinv(a[,rcond,hermitian]) Moore-Penrose伪逆 solve(a,b) 线程方程组求解 tensorsolve(a,b[,axes]) 张量方程组求解 tensorrinv(a[,ind]) 张量逆 svd(a[,full_matrices,compute_uv,hermitian]) 奇异值分解 qr(a[,mode]) QR分解 matrix_rank(M[,tol,hermitian]) 使用SVD方法计算矩阵秩 slogdet(a) 行列式的符号、自然对数 部分线代函数支持传入高维数组、数组序列，同时计算结果 对高维数组，要求数组最后2、1维度满足计算要求 （快速）傅里叶变换np.fftStandard FFTs Function Desc fft(a[,n,axis,norm]) 1维离散傅里叶变换 fft2(a[,n,axes,norm]) 2维离散FFT fftn(a[,n,axes,norm]) N维离散FFT ifft(a[,n,axis,norm]) 1维离散逆FFT ifft2(a[,n,axes,norm]) 2维离散逆FFT ifftn(a[,n,axes,norm]) N维离散逆FFT Real FFTs Function Desc rfft(a[,n,axis,norm]) 1维离散傅里叶变换 rfft2(a[,n,axes,norm]) 2维离散FFT rfftn(a[,n,axes,norm]) N维离散FFT irfft(a[,n,axis,norm]) 1维逆离散FFT irfft2(a[,n,axes,norm]) 2维离散逆FFT irfftn(a[,n,axes,norm]) N维离散逆FFT Hermitian FFTs Function Desc hfft(a[,n,axis,norm]) Hermitian对称（实谱）的信号的FFT ihfft(a[,n,axis,norm]) Hermitian对称（实谱）的信号的逆FFT 其他 Function Desc fftfreq(n[,d]) 离散FFT样本频率 rfftfreq(n[,d]) fftshift(x[,axes]) 平移0频成分到频谱中间 ifftshift(x[,axes]) np.lib.scimath np.lib.scimath中包含一些顶层命名空间的同名函数 相较于顶层空间，其定义域被扩展，相应其值域也扩展到 复数域 1np.emath.log(-np.e) == 1 + np.pi * 1j np.emath是np.lib.scimath模块的推荐别名","link":"/Python/Numpy/ndarray_sci.html"},{"title":"Numpy 性能","text":"Miscellaneous性能调优 Function Desc setbufsize(size) 设置ufunc使用的缓冲区大小 getbufsize() shares_memory(a,b[,max_work]) may_share_memory(a,b[,max_work]) byte_bounds(a) 返回指向数组结尾的指针 Array Mixin Function Desc lib.mixins.NDArrayOperatorsMixin 定义了所有使用array_ufunc特殊方法 lib.NumpyVersion(vstring) 解析、比较NumPy版本 get_include() 返回头文件目录 deprecate(*args,**kwargs) 废弃警告 deprecate_with_doc(msg) who([vardict]) 在指定字典中打印数组 disp(mesg[,device,linefee]) 展示信息 浮点错误处理 错误处理 设置硬件平台上注册的错误处理，如：除零错误 基于线程设置 Function Desc seterr([all,divide,over,under,invalid]) 设置浮点错误处理 seterrcall(func) 设置浮点错误回调或log geterr() 获取当前处理浮点错误的方法 geterrcall() 获取当前处理浮点错误回调函数 errstate(**kwargs) 浮点错误处理上下文 seterrobj(errobj) 设置定义浮点错误处理的对象 geterrobj() 获取定义浮点错误处理的对象 NumPy帮助 Function Desc lookfor(what[,module,import_modules]) 在文档中搜索关键词 info([object,maxwidth,output,toplevel]) 获取帮助信息 source(object[,output]) 获取源码","link":"/Python/Numpy/numpy_efficience.html"},{"title":"Numpy 附加库","text":"财金 Function Desc fv(rate,nper,pmt,pv[,when]) 未来值 pv(rate,nper,pmt[,fv,when]) 现值 npv(rate,values) 净现值 pmt(rate,nper,pv[,fv,when]) 等额本息，每期付款 ppmt(rate,per,nper,pv[,fv,when]) 等额本息中第per期本金 ipmt(rate,per,nper,pv[,fv,when]) 等额本息中第per期利息 irr(values) 内部收益率 mirr(values,finance_rate,reinvest_rate) 考虑期内再融资成本finance_rate、收益再投资收益reinvest_rate nper(rate,pmt,pv[,fv,when]) 每期付款 rate(nper,pmt,pv,fv[,when,guess,tol,...]) 每期间的利率 参数说明 pv：现值 fv：未来值 when：期初或期末付款 0/end 1/begin pmt：Payment，每期付款 ppmt：Principle of Payment，每期付款中本金 ipmt：Interest of Payment，每期付款中利息 值说明 正值：收入 负值：支出 Histogram Function Desc histogram(a[,bins,range,normed,weights,...]) histogram2d(x,y[,bins,range,normed,weights,...]) histogramdd(sample[,bins,range,normed,weights,...]) bincount(x[,weights,minlength]) histogram_bin_edges(a[,bin,range,weights]) digitize(x,bins[,right]) SetOperation Routine Function Version in1d(ar1,ar2[,assume_unique,invert]) 是否包含，始终返回1维数组 isin(element,test_element[,...]) 保持elementshape返回 intersect1d(ar1,ar2[,assume_unique,...]) 交集 union1d(ar1,ar2[,assume_unique,...]) 并集 setdiff1d(ar1,ar2[,assume_unique,...]) ar1-ar2 setxor1d(ar1,ar2[,assume_unique,...]) 差集 Unique Routine Function Version unique(ar[,return_index,return_inverse,return_counts,axis]) 返回唯一值","link":"/Python/Numpy/numpy_libs.html"},{"title":"Universal Functions","text":"Universal Functions UFunc：在数组上执行逐元素运算函数 支持广播、类型映射等 可视为是函数的向量化包装 基本ufunc在标量上执行操作，更泛化的ufunc也可以 在以子数组为基本元素进行操作 numpy中的ufunc是np.ufunc的实例 许多内建的ufunc是通过C编译实现的 可以通过np.frompyfunc工厂方法自定义ufunc实例 numpy中包含超过60种ufunc 部分ufunc在相关运算标记调用时，会被自动调用 内部缓冲 Internal Buffers 用于数据非对齐、数据交换、数据类型转换场合 .setbufsize(size)：基于线程设置内部缓冲，缺省为 10,000元素 类型转换规则 各ufunc内部维护列表，给出适用的输入类型（组合）、 相应的输出类型 （可通过.types属性查看） 当ufunc内部列表中没有给定的输入类型组合时，则需要 进行safely类型转换 （可通过np.can_cast函数判断） &quot;S&quot;, &quot;U&quot;, &quot;V&quot;类型不能支持ufunc运算 标量-数组操作使用不同类型转换规则确保标量不会降低 数组精度，除非标量和数组属于同一类型体系 UFunc维度说明 core dimension：核心维度，ufunc执行操作所在的维度 核心维度一般使用元组表示 对一般ufunc：核心维度为空元组 对广义ufunc：核心维度为非空元组、空元组 signature：签名，包含ufunc涉及的输出操作数和输出 操作数的核心维度字符串，如：(i,),(j,)-&gt;() 签名中各输入操作数的对应核心维度大小必须相同，移除后 剩余的循环维度共同广播，加上输出操作数的核心维度得到 输出结果shape loop dimension：循环维度，除核心维度之外的维度 这些术语来自Perl Vector Library https://numpy.org/doc/1.17/reference/c-api.generalized-ufuncs.html UFunc原型12345678910NDA = def numpy.&lt;ufunc&gt;( x1 [,x2], /, [out1, out2,], out, *, where=True, casting=&quot;same_kind&quot;, order=&quot;K&quot;, dtype=None, subok=True, [signature, extobj]) where=True/False/Array[bool] 此参数不用于对子数组做操作的广义ufunc keepdims=False/True 对广义ufunc，只在输入操作数上有相同数量核心维度、 输出操作数没有核心维度（即返回标量）时使用 axes=tuple/int 含义：广义ufunc执行操作、存储结果所在的轴序号 [tuple]：各元组为各输入操作数应被执行操作、 输出操作数存储结果的轴的序号 [int]：广义ufunc在1维向量上执行操作时，可以 直接使用整形 若广义ufunc的输出操作数均为标量，可省略其对应元组 axis=int 含义：广义ufunc执行操作所在的single轴序号 int：广义ufunc在相同的轴axis上执行操作， 等价于axes=[(axis,),(axis,),...] signature=np.dtype/tuple[np.dtype]/str 含义：指示ufunc的输入、输出的数据类型， 对于底层计算1维loop，是通过比较输入的数据类型，找到 让所有输入都能安全转换的数据类型 此参数允许绕过查找，直接指定loop 可通过ufunc.types属性查看可用的signature列表 extobj=list 含义：指定ufunc的缓冲大小、错误模式整数、错误处理 回调函数 list：长度为1、或2、或3的列表 默认这些值会在对应线程字典中查找，此参数可以通过更 底层的控制 可优化在小数组上大量ufunc的调用 部分参数含义通用，参见README UFunc属性 Attr Desc ufunc.nin 输入数量 ufunc.nout 输出数量 ufunc.nargs 参数数量 ufunc.ntypes 类型数量 ufunc.types input-&gt;output列表 ufunc.identity 标志值 ufunc.signature 广义ufunc执行操作所在的核心元素的定义 UFunc方法 Method Desc ufunc.reduce(a[,axis,dtype,out,...]) 通过沿轴应用ufunc缩减维度 ufunc.accumulate(array[,axis,dtype,out]) 累加所有元素的计算结果 ufunc.reduceat(a,indice[,axis,dtype,out]) 在single轴指定切片上执行reduce ufunc.outer(A,B,**kwargs) 在分属A,B的元素对上应用ufunc ufunc.at(a,indices[,b]) 在indices处在位无缓冲执行操作 所有ufunc都有4个方法，但是这些方法只在标量ufunc、 包含2输入参数、1输出参数里有价值，否则导致ValueError UFunc相关函数 Function Desc apply_along_axis(func1d,axis,arr,*args,...) 沿给定轴应用函数 apply_over_axes(func,a,axes) 依次沿给定轴应用函数func(a,axis) frompyfunc(func,nin,nout[,identity]) 创建ufunc，指定输入、输出数量 vertorize(pyfunc[,otypes,doc,excluded,cache,signature]) 创建ufunc，较frompyfunc提供更多特性 piecewise(x,condlist,funclist,*args,**kw) 按照condlist中索引，对应应用funclist中函数","link":"/Python/Numpy/numpy_ufunc.html"},{"title":"Pandas Readme","text":"常用参数说明 函数书写声明同Python全局 以下常用参数如不特殊注明，按此解释 DataFrame axis=0/1/&quot;index&quot;/&quot;columns&quot; 含义：作用方向（轴） 默认：0/&quot;index&quot;，一般表示row-wise（行变动）方向 inplace=False/True 含义：是否直接在原对象更改 默认：False，不更改，返回新DF对象（为True时无返回值） 其他 大部分df1.func()类型函数都有这个参数 level=0/1/level_name... 含义：用索引层级 默认：部分默认为0（顶层级）（也有默认为底层级）， 所以有时会如下给出默认值 t（top）：顶层级0（仅表意） b（bottom）：底层级-1（仅表意） 默认值为None表示所有层级 Pandas非必须依赖包文件相关 Excel xlrd/xlwt：xls格式读写，速度较快 openpyxl：xlsx格式读写，速度较慢 Pandas版本 0.22.x flaot类型可作为Categorical Index成员，不能被用于 loc获取值 l.1.1 astype方法不支持pd.Timestamp类型，只能用 &quot;datetime64&quot;替代 ALL Category Series作为groupby聚集键时，类别元素都会 出现在聚集结果中，即使其没有出现在seris值中 set、frozenset被认为是list-like的indexer，所以 在索引中的frozenset无法用一般方法获取 1df.iloc[list(df.index).index(fronzenset)]","link":"/Python/Pandas/README.html"},{"title":"Pandas数据结构","text":"DataFrame可以看作包含两个Index类（index、columns）、一个二维ndarray类 （values） 二维values + 结构化index + 结构化columns values自己还有两根只能使用integer indice的轴 结构同数据库表相似：列为属性，行为个体 123456789DF = pd.DataFrame( data=ndarray/{col_name: val}/DF/array-like, index=Index/array-like, columns=Index/array-like, dtype=None/dtype, copy=False) # `data=dict`：可以通过`columns`仅使用部分键值对创建 # `copy`：仅影响`data`为DF/ndarray时，默认不使用拷贝 DF行列逻辑可以通过DF = df1.T作转制更改行列逻辑 获取数据列优先12345678910111213141516171819202122232425262728Ser = df1[col_name]Ser = df1.col_name # 取列Ser = df1[col_level_0, col_level_1,...]Ser = df1[(col_level_0, col_level_1,...)]Ser = df1.col_level_0.col_level_1 # 对层级索引取列Val = df1[col_name][index_name]Val = df1.col_name.index_name # 取具体值 # 属性方式，要求`*_name`为字符串 # `.`、`[]`应该是覆盖过Val = df1[col_level_0, col_level_1,...]\\ [index_level_0, index_level_1,...]Val = df1[(col_level_0, col_level_1,...)]\\ [index_level_0, index_level_1,...]Val = df1.col_level_0.col_level_1....\\ .index_level_0.index_level_1... # 对层级索引取值DF = df1[cond1 &amp; cond2 &amp;...]DF = df1[cond1][cond2]... # `condX`为Ser(bool) # 两种讲道理应该没差 行优先.loc[]行优先,逻辑和df1[]列优先类似 123456789101112131415161718Ser = df.loc[index_name] # 取行Ser = df.loc[index_level_0, index_level_1,...]Ser = df.loc[(index_level_0, index_level_1,...)] # 层级索引取行Ser/DFVal = df1.loc[index_name, column_name] # 还可以这样的取值 # 不建议使用，容易照成混淆 # Val = df1.loc.index_name` # 不可Val = df1.loc[index_level_0, index_level_1,...]\\ [col_level_0, col_level_1,...] # 层级索引时，index、col不能混在一起Val = df1.loc[(index_level_0, index_level_1,...)]\\ [(col_level_0, col_level_1,...)] .iloc[]indices locate，应视为对value（ndarray）进行操作，index和 columns的结构对其没有任何影响 在层级索引情况下，仍然返回Ser 1234Ser = df1.iloc[indice] # 返回values第indice行Ser对象Val = df1.iloc[index_indice, col_indice] # 取得values第index_indice行、第col_indice列元素 .ix[].loc、.iloc的封装，不建议使用 优先使用.loc，除非参数为int、且Index不是int类型 1Ser = df1.ix[index] 行优先快速版本只能、必须取一个值 不能用于获取切片 对于多重索引必须将Index、Columns所有level全部指定 .iat 1Val = df1.iat[index_indice, col_indice] .at 1234Val = df1.at[index_name, col_name] # 单索引Val = df1.at[(index_level_0, index_level_1,...), (col_level_0, col_level_1,...)] # 多重索引必须指定全部level保证只取到一个值 切片Values切片切片对象是values 12345DF = df1.iloc[irow_start: irow_end, icol_start: icol_end] # 对values的切片，参数都是indices # 这个应该就是ndarray切片操作，不包括上限 # 如果只对行切片，可以省略`.iloc`，但不建议，因为这个 # 同时也可以表示Index切片（优先） Index切片切片对象是index，包括上限 全切片1234DF = df1.loc[ (index_0, index_1,...): (index_0, index_1,...), (col_0, col_1,...): (col_0, col_1,...)] # `.loc`可以替换为`.ix`，但不能删除，不建议使用 行切片1234DF = df1.loc[[(index_0, index_1,...),...]]DF = df1.loc[(index_0, index_1,...): (index_0, index_1,...)] # index_level可以不用指定到最低level， # 同样的，`.loc`可以替换为`.ix`，但不建议使用 列切片1234DF = df1[[col_name,...]]DF = df1.loc[:, (col_0,...): (col_0,...)] # `.loc`可以替换为`.ix`，但是不能删除，不建议使用 # 列切片没有`:`语法，只能通过设置行切片为`:`得到 DF数据共享逻辑DF数据（values）共享的逻辑 一般尽量共享数据，直至无法处理（数据同时增加/删除行、列） 有些方法会有copy参数，可以显式控制是否拷贝副本 如.reindex默认拷贝副本 123456789df1_T = df1.T # 两个此时共享数据，对任一的更改会反映在另一者df1_T[&quot;new_col_1&quot;] = [ ] # 添加新列后，两者仍然共享公共部分数据，只是`df1`中无法 # 访问新列df1[&quot;new_col_2&quot;] = [ ] # 此时两者数据均独立 # 类似的`del`删除列也是如此逻辑 Index 索引使用integer作为index时注意df1.ix[]的逻辑 MultiIndex 层级索引层级索引允许以低维度形式表示高纬度数据 层级索引可以使用tuple形式表示：(level_0, level_1,...) 需要注意区分和tuple本身作为index 打印时可以tuple有括号，而层级索引没有 层级索引有时可以省略括号 from_arrays1234567891011Index = pd.MultiIndex.from_arrays( arrays([[],[]]), sortorder=None/int, names=None/[])Index = [ level_0_list, level_1_list,...] # 隐式构建层级索引，各list长度相同，其按顺序组合 # 可以在：DF构造参数、给DF对象Index赋值等使用 # 应该是可以看作pandas使用`from_arrays`处理 说明：将arrays转换为MultiIndex 参数 arrays：包含多个list作为各个level索引 各list按照传递顺序决定level 不会自动合并不连续labels（否则需要交换数据位置） sortorder：sortedness级别？ names：level名 from_tuples1234Index = pd.MultiIndex.from_tuples( tuples=[tuple-like], sortorder=None/int, names=None) 说明：将tuples转换为MultiIndex 参数 tuples：每个tuple为一个index，按照tuple中元素顺序 决定各元素level from_product1234Index = pd.MultiIndex.from_product( iterables([[]]/[iterables]), sortorder=None/int, names) 说明：对iterables元素作product（积）作为MultiIndex Series：可以看作是包含一个Index类（index，存放标签）、一个一维ndarray类（values，存放数据） a. ser=pd.Series(data=np.darray/dict, index=list) b. Series对象可以处理标签不一致的数据，但是只有标签的交集才能得到有意义的结果，其余为NaN c. 其余性质类似于DataFrame对象 Index属性#todo a. index属性 df1.columns=[]：更改列名称，index同 df1.columns.names=[]：更改列名，index同 pandas库中的其他一些问题 a. 数据类型转换：Series对象和DF对象在运算过程中dtype类型可能发生”无意义”的转换 dtype=i8的对象之间的+、-结果为dtype=f8类型的对象（当然这个可能是保持和\\的一致性） SeriesObj.reindex(new_index)会”可能”会改变原有数据类型（由i8-&gt;f8）（有增加新index时）","link":"/Python/Pandas/data_structure.html"},{"title":"类","text":"综述Custom Classes用户定义类：通过类定义创建 每个类通过字典对象__dict__实现独立的命名空间 类属性引用被转化为在此字典中查找 其中未发现属性名时，继续在基类中查找 基类查找使用C3方法解析顺序，即MRO列表 也存在一些钩子对象允许其他定位属性的方式 当类属性引用yield类方法对象时，其将转化为__self__ 属性为当前类对象的实例方法对象 当类属性引用yield静态方法对象时，其将转换为静态方法 对象所封装的对象 类属性复制会更新类字典，不会更新基类字典 类对象可被调用产生类实例 特殊属性 __bases__：包含基类的元组，依在基类列表中出现的顺序 Class Instances类实例：通过调用类对象创建 每个类实例都有一个通过字典对象__dict__实现的独立命名 空间 属性引用首先在此字典中查找 其中未发现属性名时，继续在对应类属性中查找 用户定义函数对象：其会被转化为实例方法对象 __self__属性即为该实例 静态方法、类方法对象：同样会被转化 描述器属性有特殊处理，实际存放在类__dict__中 对象不同 若未找到类属性，对象对应类具有__getattr__()方法， 将调用该方法 属性赋值、删除会更新实例字典，不会更新对应类字典 若类具有__setattr__、__delattr__方法，将调用方法 而不是直接更更新对应实例字典 特殊属性 __class__：实例对应类 Classes类：类对象通常作为“工厂”创建自身实例 __doc__：类的文档字符串 类定义第一条语句、且须为字符串字面值 没有则为None 不会被子类继承 Class Instances类实例：在所属类中定义__call__()方法即成为可调用对象 属性属性访问. A.attr被解释为type(A)中__getattribute__(A, attr) .的行为由python解释器定义 type(A)中__getattribute__的中用于强调不会再从 type(type(A))继续获取调用__getattibute__ 则定义在类命名空间中函数是为实例定义 要为类定义方法应该自定义元类 测试代码 123456789class Meta(type): def __getattribute__(self, attr): print(&quot;--Meta--&quot;, attr) return super().attrclass D(metaclass=Meta): def __getattribute__(self, attr): print(&quot;--Class--&quot;, attr) return super().attr __getattribute__函数说明参见 cs_python/py3ref/special_methods 属性访问控制 python没有没有属性访问控制，不依赖语言特性封装数据，而是 遵循一定属性、方法命名规约达到效果 __开头属性：属性名称会被修改 防止被派生类继承，此类属性无法通过继承覆盖 即若清楚代码会涉及子类，且应该在子类中隐藏起来，考虑 使用双下划线开头 通常是在属性名称前添加类名标记_cls 但同时以__结尾属性名称不会被修改 单_开头属性：应被视为私有属性，不应被外部访问 python无法真正防止访问内部名称，但是这样会导致脆弱的 代码 此约定同样适用于模块名、模块级别函数 默认情况下，通配符*不会导入模块私有属性，除非 在配置有__all__属性 导入参见cs_python/py3ref/simple_stmt#todo 单_结尾：避免定义的变量和保留关键字冲突 特殊属性 __dict__：命名空间包含的属性 __doc__：文档字符串 第一条语句、且须为字符串字面值 没有则为None 不会被子类继承 __name__：名称 __qualname__：qualified name，完整限定名称 以点号分隔的名称 显示模块全局作用域到模块中某个定义类、函数、方法的 路径 __module__：所属模块名称 没有则为None 描述器属性 描述器协议参见cs_python/py3ref/special_methods 实例/类/静态方法：参见cs_python/py3ref/dm_gfuncs @property@property装饰器：为类的属性增加处理逻辑，如：类型检查、 合法性验证 property属性和普通属性实现迥异，但使用类似 property属性就是绑定有这些处理逻辑函数的类实例 访问、赋值、解除绑定时会自动触发getter、setter、 deleter处理逻辑 property属性（或者说有效描述器）为类属性 一般需要通过在实例、或描述器命名空间 instance.__dict__中存储数据，以实现对实例操作逻辑 独立 也可以实时计算属性值，此时无需为实例分别存储数据 初始化时，不应该直接设置底层数据属性，会绕过setter 的参数检查 过度使用@property时会降低代码可读性、效率，使用 get/set方法可能有更好的兼容性 代码实现 代码是C实现，这里是python模拟，和help结果不同 1234567891011121314151617181920212223242526272829303132333435363738class Property(object): &quot;Emulate PyProperty_Type() in Objects/descrobject.c&quot; def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.fget = fget self.fset = fset self.fdel = fdel if doc is None and fget is not None: doc = fget.__doc__ self.__doc__ = doc def __get__(self, obj, objtype=None): if obj is None: return self if self.fget is None: raise AttributeError(&quot;unreadable attribute&quot;) return self.fget(obj) def __set__(self, obj, value): if self.fset is None: raise AttributeError(&quot;can't set attribute&quot;) self.fset(obj, value) def __delete__(self, obj): if self.fdel is None: raise AttributeError(&quot;can't delete attribute&quot;) self.fdel(obj) def getter(self, fget): return type(self)(fget, self.fset, self.fdel, self.__doc__) # 返回描述器，可省略 def setter(self, fset): return type(self)(self.fget, fset, self.fdel, self.__doc__) # 返回更新`fset`的描述器，同名所以覆盖前者 def deleter(self, fdel): return type(self)(self.fget, self.fset, fdel, self.__doc__) @property是描述器类，接受方法返回同名资料描述器 创建property属性 @property[.getter]装饰getter-like方法得到同名资料 描述器 返回描述器包含.setter()、.deleter()方法/装饰器进一步 完善描述器 @method.setter：为描述器完善赋值处理逻辑 @method.deleter：为描述器完善del处理逻辑 可以直接使用已有类中函数创建property类实例，得到 property属性（描述器） 派生类中property属性覆盖 派生类中直接使用@property创建同名属性会覆盖基类 中property属性 只有显式声明的处理逻辑被设置 基类中逻辑位于基类相应同名property属性，不会 被“隐式继承” @&lt;basecls&gt;.&lt;method&gt;.getter/setter/deleter单独覆盖 property属性方法 但是basecls是硬编码方式，必须知道定义 property属性的具体类（或其子类） 描述器协议、实现参见cs_python/py3ref/special_methods 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Student(object): def __init__(self, value): self.birth = value # 使用`self.birth`而不是`self._birth`，保证即使 # 实在初始化时仍然进行参数检查 @property # 将一个getter-like方法变为属性 # `@property`同时会创建装饰器`@method.setter` def birth(self): return self._birth @birth.setter # `@property`对应，将setter-like方法变为属性 def birth(self, value): if not instance(value, int): raise ValueError(&quot;birth must be an integer&quot;) if value &lt; 1900 or value &gt; 2020: raise ValueError(&quot;birth must between 1900 ~ 2020&quot;) self._birth = value @birth.deleter # 同`@property`对应，在`del`时调用 def birth(self): del(self._age) del(self._birth) @property # 只设置`@property`而没有设置对应`@birth.setter` # 这样`birth`就成了只读属性 def age(self): return 2018 - self._birth def get_first_name(self): return self._first_name def set_first_name(self): if not instance(value, str): raise TypeError(&quot;expected a string&quot;) self._first_name = value def del_first_name(self): raise AttributeError(&quot;can't delete attribute&quot;) name = property(get_first_name, set_first_name, del_first_name) # 在已有getter-like、setter-like方法上创建property # 注意：这里就是应该定义类属性，本身使用`@property` # 装饰器也是相当于创建类属性 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Person: def __init__(self, name): self.name = name @property def name(self): return self._name @name.setter def name(self, value): if not instance(value, str): raise TypeError(&quot;expected a string&quot;) self._name = value @name.deleter def name(self): raise AttributeError(&quot;can't delete attribute&quot;)class SubPersonAll(Person): # 这个类继承、扩展了`name`属性的所有功能 @property def name(self): print(&quot;getting name&quot;) return super().name @name.setter def name(self, value): print(&quot;Setting name to&quot;, value) super(SubPerson, SubPerson).name.__set__(self, value) # 使用`super(SubPerson, SubPerson)`调用父类实现 # 将控制权传递给`.name.__set__`方法，委托给父类 # 中定义的setter方法 @name.deleter def name(self): print(&quot;deleting name&quot;) super(SubPerson, SubPerson).name.__delete__(self)class SubPersonPart(Person): # 仅修改`name`属性的某个方法 # 需要知道定义`name`属性的基类，否则重新定义property属性 # 的所有方法，并使用`super`将控制权转移给父类 @Person.name.getter # 使用硬编码的`Person`类名，这样会把之前已经定义的 # property属性方法复制过来，而对应的`getter`、 # `setter`、`deleter`方法被替换 # 这里如果直接使用`@property`装饰，那么`setter`、 # `deleter`方法将会消失 def name(self): print(&quot;getting name&quot;) return super().name 类继承 类继承会获得基类的所有方法 类里面的方法其实真的不是给类使用的，而是给实例使用 类自身使用的方法是元类中的方法 Method Resolution OrderMRO/方法解析顺序列表：包含当前类所有超类的线性顺序表 MRO列表顺序通过C3线性化算法实现，对每个类按以下规则合并 所有父类的MRO列表 子类先于父类检查 多个父类根据其在列表中的顺序被检查 若对下一个类存在多个合法的选择，选择第一个父类 为了实现继承，python会在MRO列表上从左到右开始查找超类， 直到第一个匹配这个属性的类为止 可以通过类__mro__、mro()访问 super1234567891011121314151617181920class super: super() # 等同于：`super(__class__, &lt;first_argument&gt;)` # `&lt;first_argument&gt;`常常就是`self` super(type) # 返回：未绑定super对象，需要`__get__`绑定 super(type, obj) # 返回：已绑定super对象，要求`isinstance(obj,type)` super(type, type2) # 返回：已绑定super对象，要求`issubclass(type2, type)` # 此时调用方法返回是函数，不是绑定方法，不会默认传入 # `type2`作为首个参数 def __get__(self, obj, type=None): def super(cls, inst/subcls): mro = inst.__class__.mro() mro = subcls.mro() return mro[mro.index(cls) + 1] 参数 第一个参数：在MRO列表中定位类搜索起点（不包括） 第二个参数：提供MRO列表 类：直接传递MRO列表 实例：传递所属类的MRO列表 返回：封装有两个参数的super实例 类似于返回MRO列表中某个类的实例，取决于访问的属性 用途：依次遍历MRO列表（指定位置开始）中类，查找指定属性 可以使用指定超类创建super实例，跳过对部分类搜索 只有MRO列表中每个类中的方法都super()调用，才能保证 列表中所有类的该方法都被链式调用 说明 需要注意super(cls, inst).__getattribute__(&quot;meth&quot;)中 共有两段属性访问，两次访问调用不同__getattribute__ super(cls, inst).__getattribute__首先调用 super.__getattribute__在type(inst).mro()中寻找 some_cls.__getattribute__ 然后调用some_cls.__getattrbibute__(&quot;meth&quot;)访问 meth属性 应使用super访问基类属性，而不是直接使用基类名称，避免 多继承中出现问题 继承链super保证方法只按找MRO列表顺序调用一次 多继承中硬编码基类名称调用方法可能导致方法被调用多次 super访问的属性路线不够明确，所以需要遵循以下原则 继承体系中，所有相同名字的方法拥有可兼容的参数名， 比如：相同参数个数、名称 最好确保最顶层类提供这个方法的实现，这样保证MRO上的 查找链肯定可以找到该方法 抽象类接口、抽象类 抽象类无法直接实例化 目的就是让别的类继承它并实现特定的抽象方法 也可以通过注册方式让某类实现抽象基类 用途 通过执行类型检查，确保实现为特定类型、实现特定接口 类型检查很方便，但是不应该过度使用，因为动态语言目的就是 灵活性，强制类型检查让代码更复杂 使用abc模块方便定义抽象类 MixinsMixins：把一些有用的方法包装成Mixin类，用于扩展其他类的 功能，而这些类往往又没有继承关系 Mixin不能直接实例化使用 Mixin没有自己的状态信息，即没有定义__init__方法， 没有实例属性，因此Mixin中往往会定义__slots__ = () Mixins讨论参见cs_program/program_design/inheritation 例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class LoggedMappingMixin: __slots__ = () def __getitem__(self, key): print(&quot;getting:&quot;, str(key)) return super9).__getimte__(key) def __setitem__(self, key, value): print(&quot;setting {} = {!r}&quot;.format(key, value)) return super().__setitem__(key, value) def __delitem__(self, key): print(&quot;deleting&quot;, str(key)) return super().__delitem__(key)class SetOnceMappingMixin: __slots__ = () def __setitem__(self, key, value): if key in self: raise KeyError(str(key), &quot;alreay set&quot;) return super().__setitem__(key, value)class StringKeysMappingMixin: __slots__ = () def __setitem__(self, key, value): if not isinstance(key, str): raise TypeError(&quot;keys must be strings&quot;) return super().__setitem__(key, value) # 单独的Mixin类使用没有意义，也无法实例化class LoggedDict(LoggedMappingMixin, dict): # 把混入类和其他已存在的类结合起来使用 passfrom collections import defaultdictclass SetOnceDefaultDict(SetOnceMappingMixin, defaultdict): passdef test(): d = LoggedDict() d[&quot;x&quot;] = 23 print(d[&quot;x&quot;]) del d[&quot;x&quot;] d = setOnceDefaultDict(list) d[&quot;x&quot;].append(2)","link":"/Python/Py3Ref/cls_basics.html"},{"title":"Compound Statements","text":"复合语句复合语句：包含其他语句（语句组）的语句 复合语句由一个、多个子句组成，子句包含句头、句体 子句头 都处于相同的缩进层级 以作为唯一标识的关键字开始、冒号结束 子句体 在子句头冒号后、与其同处一行的一条或多条分号分隔 的多条简单语句 或者是在其之后缩进的一行、多行语句，此形式才能 包含嵌套的复合语句 其会以某种方式影响、控制所包含的其他语句执行 12345678910111213compound_stmt ::= if_stmt | while_stmt | for_stmt | try_stmt | with_stmt | funcdef | classdef | async_with_stmt | async_for_stmt | async_funcdefsuite ::= stmt_list NEWLINE | NEWLINE INDENT statement+ DEDENTstatement ::= stmt_list NEWLINE | compound_stmtstmt_list ::= simple_stmt (&quot;;&quot; simple_stmt)* [&quot;;&quot;] 语句总以NEWLINE结束，之后可能跟随DEDENT 可选的后续子句总是以不能作为语句开头的关键字作为开头， 不会产生歧义 关键字ifif语句：有条件的执行 123if_stmt ::= &quot;if&quot; expression &quot;:&quot; suite (&quot;elif&quot; expression &quot;:&quot; suite)* [&quot;else&quot; &quot;:&quot; suite] 对表达式逐个求值直至找到真值，在子句体中选择唯一匹配者 执行 若所有表达式均为假值，则else子句体如果存在被执行 whilewhile语句：在表达式保持为真的情况下重复执行 12while_stmt ::= &quot;while&quot; expression &quot;:&quot; suite [&quot;else&quot; &quot;:&quot; suite] 重复检验表达式 若为真，则执行第1个子句体 若为假，则else子句体存在就被执行并终止循环 第1个子句体中break语句执行将终止循环，且不执行else 子句体 第1个子句体中continue语句执行将跳过子句体中剩余部分， 直接检验表达式 forfor语句：对序列（字符串、元组、列表）或其他可迭代对象中元素 进行迭代 12for_stmt ::= &quot;for&quot; target_list &quot;in&quot; expression_list &quot;:&quot; suite [&quot;else&quot; : suite] 表达式列表被求值一次 应该产生可迭代对象 python将为其结果创建可迭代对象创建迭代器 迭代器每项会按照标准赋值规则被依次赋值给目标列表 为迭代器每项执行依次子句体 所有项被耗尽raise StopIteration时，else子句体 存在则会被执行 目标列表中名称在循环结束后不会被删除 但若序列为空，其不会被赋值 序列在循环子句体中被修改可能导致问题 序列的__iter__方法默认实现依赖内部计数器和序列长度 的比较 若在子句体中增、删元素会使得内部计数器“错误工作” 可以对整个序列使用切片创建临时副本避免此问题 第1个子句体中break语句执行将终止循环，且不执行else 子句体 第1个子句体中continue语句执行将跳过子句体中剩余部分， 转至下个迭代项执行 trytry语句：为一组语句指定异常处理器、清理代码 1234567try_stmt ::= try1_stmt | try2_stmttry1_stmt ::= &quot;try&quot; &quot;:&quot; suite (&quot;except&quot; [expression [&quot;as&quot; identifier]] &quot;:&quot; suite)+ [&quot;else&quot; &quot;:&quot; suite] [&quot;finally&quot; &quot;:&quot; suite]try2_stmt ::= &quot;try&quot; &quot;:&quot; suite &quot;finally&quot; &quot;:&quot; suite except子句except子句：指定一个、多个异常处理器 try子句中没有异常时，没有异常处理器执行 否则，依次检查except子句直至找到和异常匹配的子句 无表达式子句必须是最后一个，将匹配任何异常 有表达式子句中表达式被求值，求值结果同异常兼容则匹配 成功 若在表达式求值引发异常，则对原异常处理器搜索取消 其被视为整个try语句引发异常，将在周边代码、 主调栈中为新异常启动搜索 若无法找到匹配的异常子句，则在周边代码、主调栈中继续 搜索异常处理器 兼容：是异常对象所属类、基类，或包含兼容异常对象元组 当找到匹配except子句时 异常将被赋值给as子句后目标，若存在as子句 对应子句体被执行（所有except子句都需要子句体） as后目标在except子句结束后被清除 12345678except E as N: foo # 被转写为except E as N: try: foo finally: del N 避免因异常附加回溯信息而形成栈帧的循环引用，使得 所有局部变量存活直至下次垃圾回收 则异常必须赋值给其他名称才能在except子句后继续 引用 except子句体执行前，有关异常信息存放在sys模块中， 参见cs_python/py3std/os_sys.md else子句else子句：在以下情况将被执行，若存在 控制流离开try子句体没有引发异常 没有执行return、continue、break语句 finally子句finally子句：指定清理处理器，子句体在任何情况下都被执行 执行期间程序不能获取任何异常信息 在try、except、else子句中引发的任何未处理异常 将被临时保存，执行完finally子句后被重新引发 但若finally子句中执行return、break语句，则临时 保存异常被丢弃 若finally子句引发新的异常，临时保存异常作为新异常 上下文被串联 显式异常串联参见cs_python/py3ref/simple_stmt try子句中执行return、break、continue语句时， finally子句在控制流离开try语句前被执行 函数返回值由最后被执行的return语句决定，而 finally子句总是最后被执行 12345678def foo(): try: return &quot;try&quot; finally: return &quot;finally&quot;foo() # 返回&quot;finally&quot; withwith语句：包装上下文管理器定义方法中代码块的执行 12with_stmt ::= &quot;with&quot; with_item (&quot;,&quot; with_item)* &quot;:&quot; suitewith_item ::= expression [&quot;as&quot; target] with句头中有多个项目，被视为多个with语句嵌套处理多个 上下文管理器 123456with A() as a, B() as b: suite # 等价于with A() as a: wiht B() as b: suite 执行流程 对表达式求值获得上下文管理器 载入上下文管理器__exit__以便后续使用 调用上下文管理器__enter__方法 若包含as子句，__enter__返回值将被赋值给其后目标 with语句保证若__enter__方法返回时未发生错误， __exit__总会被执行 若在对目标列表赋值期间发生错误，视为在语句体内部发生 错误 执行with语句体 调用上下文关管理器__exit__方法 若语句体退出由异常导致 其类型、值、回溯信息将被作为参数传递给__exit__ 方法；否则提供三个None作为参数 若__exit__返回值为假，该异常被重新引发；否则 异常被抑制，继续执行with之后语句 若语句体由于异常以外任何原因退出 __exit__返回值被忽略 Function函数定义：对用户自定义函数的定义 123456789101112funcdef ::= [decorators] &quot;def&quot; funcname &quot;(&quot; [parameter_list] &quot;)&quot; [&quot;-&gt;&quot; expression] &quot;:&quot; suitedecorators ::= decorator+decorator ::= &quot;@&quot; dotted_name [&quot;(&quot; [argument_list [&quot;,&quot;]] &quot;)&quot;] NEWLINEdotted_name ::= identifier (&quot;.&quot; identifier)*parameter_list ::= defparameter (&quot;,&quot; defparameter)* [&quot;,&quot; [parameter_list_starargs]] | parameter_list_starargsparameter_list_starargs ::= &quot;*&quot; [parameter] (&quot;,&quot; defparameter)* [&quot;,&quot; [&quot;**&quot; parameter [&quot;,&quot;]]] | &quot;**&quot; parameter [&quot;,&quot;]parameter ::= identifier [&quot;:&quot; expression]defparameter ::= parameter [&quot;=&quot; expression]funcname ::= identifier 函数定义是可执行语句 在当前局部命名空间中将函数名称绑定至函数对象（函数 可执行代码包装器） 函数对象包含对当前全局命名空间的引用以便调用时使用 函数定义不执行函数体，仅函数被调用时才会被执行 Decorators装饰器：函数定义可以被一个、多个装饰器表达式包装 函数被定义时将在包含该函数定义作用域中对装饰器表达式求值 ，求值结果须为可调用对象 其将以该函数对象作为唯一参数被调用；返回值将被绑定至函数 名称 多个装饰器会以嵌套方式被应用 12345678@f1(arg)@f2def func(): pass # 大致等价，仅以上不会临时绑定函数对象至名称def func(): passfunc = f1(arg)(f2(func)) Parameter Types形参类型 POSITIONAL_OR_KEYWORD：之前没有VAR_POSITIONAL类型的 参数 可以通过位置、关键字传值 KEYWORD_ONLY：之前存在VAR_POSITION类型、或*的参数 只能通过关键字传值 VAR_POSITIONAL：*args形式参数 只能通过位置传值 隐式默认值为() VAR_KEYWORD：**kwargs形式参数 只能通过关键字传值 隐式默认值为{} POSITIONAL_ONLY：只能通过位置传值的参数 某些实现可能提供的函数包含没有名称的位置参数 唯一不能使用关键字传参参数类型 CPython：C编写、PyArg_ParseTuple()解析参数的函数 Default Parameters Values默认参数值：具有parameter = expression形式的形参 具有默认值的形参，对应argument可以在调用中可被省略 默认形参值将在执行函数定义时按从左至右的顺序被求值 即函数定义时的预计算值将在每次调用时被使用 则被作为默认值的列表、字典等可变对象将被所有未指定该 参数调用共享，应该避免 可以设置默认值为None，并在函数体中显式测试 POSITION_OR_KEYWORD、有默认值形参必须位于无默认值者后 ，即若形参具有默认值，后续所有在*前形参必须具有默认值 KEYWORD_ONLY、有默认值形参可位于无默认值者前 Annotations 形参标注：param:expression 函数返回标注：-&gt; expression 标注不会改变函数语义 标注可以是任何有效python表达式 默认在执行函数定义时被求值 使用future表达式from __future__ import annotations ，则标注在运行时被保存为字符串以启用延迟求值特性 标注默认存储在函数对象__annotation__属性字典中 可以通过对应参数名称、&quot;return&quot;访问 Class类定义：对类的定义 123classdef ::= [decorators] &quot;class&quot; classname [inheritance] &quot;:&quot; suiteinheritance ::= &quot;(&quot; [argument_list] &quot;)&quot;classname ::= identifier 类定义为可执行语句 继承列表inheritance通常给出基类列表、元类 基类列表中每项都应当被求值为运行派生子类的类 没有继承类列表的类默认继承自基类object 类定义语句执行过程 类体将在新的执行帧中被执行 使用新创建的局部命名空间和原有的全局命名空间 类体执行完毕之后 丢弃执行帧 保留局部命名空间 创建类对象 给定继承列表作为基类 保留的局部命名空间作为属性字典__dict__ 类名称将在原有的全局命名空间中绑定至该类对象 类可以类似函数一样被装饰 装饰器表达式求值规则同函数装饰器 结果被绑定至类名称 类中属性、方法参见#todo 类属性可以作为实例属性的默认值，但注意使用可变类型值可能 导致未预期结果 Coroutine协程函数 12async_funcdef ::= [decorators] &quot;async&quot; &quot;def&quot; funcname &quot;(&quot; [parameter_list] &quot;)&quot; [&quot;-&gt;&quot; expression] &quot;:&quot; suite 协程函数可以在多个位置上挂起（保存局部状态）、恢复执行 协程函数体内部 await、async是保留关键字 await表达式、async for、async with只能在协程 函数体内部使用 使用yield from表达式将raise SyntaxError async for语句1async_for_stmt ::= &quot;async&quot; for_stmt async for语句允许方便的对异步迭代器进行迭代 1234async for TARGET in ITER: ...BLOCK1...else: ...BLOCK2... 在语义上等价于 123456789101112iter = (ITER)iter = type(iter).__aiter__(iter)running = Truewhile running: try: TARGET = await type(iter).__anext__(iter) except StopAsyncIteration: running = False else: BLOCK1else: BLOCK2 async with语句1async_with_stmt ::= &quot;async&quot; with_stmt async with语句允许方便使用异步上下文管理器 12async with EXPR as VAR: BLOCK 语义上等价于 123456789101112mgf = (EXPR)aexit = type(mgr).__aexit__aenter = type(mgr).__aenter__(mgr)VAR = await aentertry: BLOCKexcept: if not await aexit(mgr, *sys.exc_info()): raiseelse: await aexit(mgr, None, None, None)","link":"/Python/Py3Ref/compound_stmts.html"},{"title":"数据模型--执行相关","text":"以下类型为内部类型，由解释器内部使用、但被暴露给用户， 其定义可能随着未来解释器版本更新而变化 代码对象 帧对象 回溯对象 切片对象：参见cs_python/py3ref/dm_basics 静态方法对象：参见cs_python/py3ref/#todo 类方法对象：参见cs_python/py3ref/#todo Module模块：python代码的基本组织单元 导入系统创建 import语句 importlibd.import_module()、__import__()函数 模块对象具有由字典__dict__实现的命名空间 属性引用：被转换为该字典中查找m.__dict__['x'] 属性赋值：更新模块命名字典空间 不包含用于初始化模块的代码对象 模块中定义函数__globals__属性引用其 元属性 __name__：模块名称 __doc__：模块文档字符串 __annotaion__：包含变量标注的字典 在模块体执行时获取 __file__：模块对应的被加载文件的路径名 若加载自一个文件，某些类型模块可能没有 C模块静态链接至解释器内部 从共享库动态加载的扩展模块，该属性为共享库文件路径名 __dict__：以字典对象表示的模块命名空间 CPython：由于CPython清理模块字典的设定，模块离开作用域时 模块字典将被清理，即使字典还有活动引用，可以复制该字典、 保持模块状态以直接使用其字典 Code Object代码对象：“伪编译”为字节的可执行python代码，也称bytecode 代码对象和函数对象区别 代码对象不包含上下文；函数对象包含对函数全局对象 （函数所属模块）的显式引用 默认参数值存放于函数对象而不是代码对象 代码对象不可变，也不包含对可变对象的应用 代码对象由内置compile()函数返回 可以通过函数对象__code__属性从中提取 可以作为参数传给exec()、eval()函数执行 特殊属性 co_name：函数名称 co_argcount：位置参数数量 co_nlocals：函数使用的本地变量数量（包括参数） co_varnames：包含本地变量名称的元组 co_freevars：包含自由变量的元组 co_code：表示字节码指令序列的字符串 co_consts：包含字节码所使用的字面值元组 若代码对象表示一个函数，第一项为函数文档字符，没有 则为None co_names：包含字节码所使用的名称的元组 co_filenames：被编译代码所在文件名 co_firstlineno：函数首行行号 co_lnotab：以编码表示的字节码偏移量到行号映射的字符串 co_stacksize：要求栈大小（包括本地变量） co_flags：以编码表示的多个解释器所用标志的整形数 0x04位：函数使用*arguments接受任意数量位置参数 0x08位：函数使用**keywords接受任意数量关键字参数 0x20位：函数是生成器 0x2000位：函数编译时使用启用未来除法特性 其他位被保留为内部使用 Frame Objects栈帧对象：执行帧 可能出现在回溯对象中，还会被传递给注册跟踪函数 特殊只读属性 f_back：前一帧对象，指向主调函数 最底层堆栈帧则为None f_code：此栈帧中所执行的代码对象 f_locals：查找本地变量的字典 f_globals：查找全局变量 f_builtins：查找内置名称 f_lasti：精确指令，代码对象字节码字符串的索引 特殊可写属性 f_trace：None，或代码执行期间调用各类事件的函数 通常每行新源码触发一个事件 f_trace_lines：设置是否每行新源码触发一个事件 f_trace_opcodes：设置是否允许按操作码请求事件 f_lineno：帧当前行号 可以通过写入f_lineno实现Jump命令 方法 .clear()：清楚该帧持有的全部对本地变量的引用 若该栈帧为属于生成器，生成器被完成 有助于打破包含帧对象的循环引用 若帧当前正在执行则会raise RuntimeError Traceback Objects回溯对象：表示异常的栈跟踪记录 异常被印发时会自动创建回溯对象，并将其关联到异常的可写 __traceback__属性 查找异常句柄使得执行栈展开时，会在每个展开层级的当前 回溯之前插入回溯对象 进入异常句柄时，栈跟踪将对程序启用 获取：sys.exc_info()返回的元组第三项、异常的 __traceback__属性 程序没有合适的处理句柄时，栈跟踪将写入标准错误 可通过types.TracebackType显式创建 由回溯对象创建者决定如何链接tb_next属性构成完整 栈追踪 特殊只读属性 tb_frame：执行当前层级的执行栈帧 tb_lineno：给出发生异常所在行号 tb_lasti：最后具体指令 若异常出现在没有匹配的except子句、没有finally子句 的try中，回溯对象中的行号、最后指令可能于相应帧对象中 行号不同 特殊可写属性 tb_next：栈跟踪中下一层级（通往发生异常的帧），没有 下一层级则为None I/O对象/文件对象文件对象：表示打开的文件 创建文件对象 open()内置函数 os.popen()、os.fdopen() socket.makefile() sys.stdin、sys.stdout、sys.stderr会初始化为对应于 解释器的标准输入、输出、错误流对象 均以文本模式打开 遵循io.TextIOBase抽象类所定义接口","link":"/Python/Py3Ref/dm_executions.html"},{"title":"Python执行模型","text":"综述Code Blocks代码块：作为一个单元执行的一段python文本，代码块构成python 程序 模块、函数体、类定义 交互式输入的每条命令 作为标准输入、命令行参数发送给解释器的脚本文件 脚本命令 传递给eval()、exec()的字符串参数 代码块在执行帧中执行，执行帧包含某些用于调试的管理信息 并决定代码块执行完成后操作 Naming、BindingBinding of Names 名称：用于指代对象，通过名称绑定操作引入 名称绑定方法 传递参数 import语句 from ... import *会绑定被导入模块中定义的所有 公有名称（仅在模块层级上被使用） 类、函数定义 以标识符为目标的赋值 for循环开头、with和except子句的as之后 del语句的目标也被视为绑定，虽然实际语义为解除名称 绑定 变量类型 局部变量：绑定在代码块中的名称，且未声明为nonlocal 、或global 全局变量：绑定在模块层级的名称 模块代码块中变量既为全局变量、也是局部变量 自由变量：在代码块中使用但未在其中定义的变量 自由变量不同于闭包变量，函数闭包变量__closure__要求 自由变量来自于父函数作用域 Scope作用域：定义了代码块中名称的可见性 名称的作用域包含 定义该变量代码块 定义变量代码块所包含的代码块 （除非被包含代码块中引入对该名称不同绑定） 名称作用域虽然包括定义变量代码块所包含的代码块 可以直接访问变量 但修改变量必须使用global、local等声明 在代码块内任何位置进行名称绑定，则代码块内所有对该名称 的使用被认为是对代码块的引用 python没有声明语法，则代码块中局部变量可通过，在整个 代码块文本中扫描名称绑定来确定 模块作用域在模块第一次被导入时创建 Resolution of Names 若名称在代码块中被使用，会由包含它的最近作用域来解析 若名称完全无法找到将raise NameError 若当前作用域为函数作用域，且名称指向局部变量，若名称被 绑定值前被被使用将raise UnboundLocalError （UnboundLocalError是NameError子类） （代码块）环境：对代码块可见的所作用域集合 global 对global指定名称的使用是对最高层级命名空间中该名称 绑定的引用 全局命名空间：包含代码块的模块命名空间 内置命名空间：builtins模块的命名空间 global语句与同一代码块中名称绑定具有相同作用域 若自由变量最近包含作用域中有global语句，其也会被 当作全局变量 global语句须在名称使用之前声明 nonlocal nonlocal使得相应名称指向最近包含函数作用域的中绑定的 变量 指定名称不存在于任何包含函数作用域则raise SyntaxError 内置命名空间 与代码块执行相关联的内置命名空间实际上是通过其在全局命名 空间中搜索名称__builtins__找到，一般是字典、模块 （此时使用模块的命名空间字典） 默认情况下 __main__模块中：__builtins__为内置模块builtins 非__main__模块中：__buitlins__是builtins模块 自身的字典别名 动态特性 自由变量的名称解析 123456i = 0def f(): print(i)i = 42f() # 打印`42` 发生在运行时，而不是编译时 在全局命名空间中，而不是最近包含命名空间中 eval()、exec() eval()、exec()没有对完整环境的访问权限来解析名称 有可选参数用于重载全局、局部命名空间 若只指定一个命名空间，则会同时作用于两者 类 类中名称解析遵守大部分情况下同普通规则，但 未绑定局部变将在全局命名空间中搜索 类定义的命名空间__dict__会成为类的属性字典 类代码块中定义的名称的作用域会被限制在类代码块中，不会 扩展到方法代码块中，包括推导式、生成器表达式 123class A: a = 42 b = list(a + i for i in range(10)) Exception异常：中断代码块的正常控制流程以便处理错误、其他异常条件的 方式 在错误被检测到的位置引发 解释器检测到运行时错误时错误 raise语句显式引发 可被当前包围代码块、任何直接或间接主调代码块捕获、处理 try...except指定错误处理，finally子句清理代码 异常通过实例标识、根据器类型选择执行except子句 错误处理采用“终止”模型 异常处理器可以找出发生的问题，在外层继续执行 但不能修复错误的根源，并重试失败操作 异常完全未被处理时，解释器会终止程序执行、或返回交互 模式循环，并打印栈回溯信息，除非为SystemExit异常 异常实例可以携带关于异常状态的额外信息 异常信息不是python API一部分，内容可能在不同python 版本间不经警告的改变","link":"/Python/Py3Ref/execution_model.html"},{"title":"Lexical Analysis","text":"python将读取的程序问题转换为Unicode码点 源文件的文本编码可由编码声明指定 默认UTF-8 词法分析器将文件拆分为token 解释器以词法分析器生成的token流作为输入 行结构逻辑行逻辑行：逻辑行的结束以NEWLINE token表示 语句不能跨越逻辑行边集，除非其语法允许包含NEWLINE （如复合语句包含多个子语句） 逻辑行可由一个、多个物理行按照明确、隐含行拼接规则 构成 python程序可以分为很多逻辑行 物理行物理行：以行终止序列结束的字符序列 源文件、字符串中可以使用任何标准平台上行终止序列 Unix：\\n换行符LF Win：\\r\\n回车加换行CR LF Macintosh：\\r回车CR 输入结束会被作为最后物理行的隐含终止标志 嵌入Python源码字符串应使用标准C传统换行符\\n 显式行拼接显式行拼接：两个、多个物理行使用\\拼接为一个逻辑行 物理行以不在字符串、注释内的反斜杠结尾时，将与下行 拼接构成一个单独逻辑行 反斜杠、其后换行符将被删除 以反斜杠结束的行不能带有注释 反斜杠不能用于 拼接注释 拼接字符串外token 不允许原文字符串以外反斜杠存在于物理行其他位置 隐式行拼接隐式行拼接 圆括号、方括号、花括号内表达式允许被分为多个物理行，无需 使用反斜杠 拼接行可以带有注释 后续行缩进不影响程序结构、允许为空白行 拼接行之间不会有NEWLINE token 三引号&quot;&quot;&quot;/'''字符串允许被分为多个物理行 拼接行中不允许带有注释 空白行空白行：只包含空格符、制表符、进纸符、注释的逻辑行会被忽略， 不生成NEWLINE token 交互式输入语句时，对空白行处理可能因为读取-求值-打印循环 的具体实现而存在差异 标准交互模式解释器中：完全空白逻辑行将会结束一条多行 复合语句 注释注释：一不包含在字符串内的#开头，在物理行末尾结束 注释标志逻辑行的结束，除非存在隐含行拼接规则 注释在语法分析中被忽略，不属于token 编码声明编码声明：位于python脚本第一、第二行，匹配正则表达式 coding[=:]\\s*([-\\w.]+)的注释将被作为编码声明处理 1# -*- coding: &lt;encoding-name&gt; -*- 表达式第一组指定了源码文件编码 编码声明指定编码名称必须是python所认可的编码 词法分析将使用此编码：语义字符串、注释、标识符 编码声明须独占一行，若在第二行，则第一行也必须为注释 没有编码声明，默认编码为UTF-8 若文件首字节为UTF-8字节顺序标志b\\xef\\xbb\\xbf， 文件编码也声明为UTF-8 缩进缩进：逻辑行开头的空白（空格符、制表符）被用于计算该行 的缩进等级，决定语句段落组织结构 首个非空白字符之前的空格总数确定该行的缩进层次 缩进不能使用反斜杠进行拼接，首个反斜杠之前空格将确定 缩进层次 制表符被替换为1-8个空白，使得缩进的空格总数为8倍数 源文件若混合使用制表符、空格符缩进，并使得确定缩进 层次需要依赖于制表符对应空格数量设置，将引发 TabError 由于非Unix平台上文本编辑器本身特性，源文件中混合使用 制表符、空格符是不明智的 进纸符 在行首时：在缩进层级计算中被忽略 行首空格内其他位置：效果未定义，可能导致空格计数重置 为0 不同平台可能会显式限制最大缩进层级 INDENT/DEDENT token 读取文件第一行前，向堆栈中压入零值，不再弹出 被压入栈的层级数值从底至顶持续增加 每个逻辑行开头的行缩进层级将和栈顶进行比较 相同：不做处理 新行层级较高：压入栈中，生成INDENT token 新行层级较低：应为栈中层级数值之一 栈中高于该层级所有数值被弹出 每弹出一级数值生成一个DEDENT token 文件末尾，栈中剩余每个大于0数值生成一个DEDENT token Tokens型符 空白字符不属于token 除逻辑行开头、字符串内，空格符、制表符、进纸符等 空白符均可分隔token 否则彼此相连的token会被解析为一个不同的token 若存在二义性，将从左至右尽可能长读取合法字符串组成token Indentifiers标识符/名称：python标识符语法基于Unicode标准附件UAX-31，有 修改 ASCII字符集内可用于标识符与py2一致 大、小写字母 下划线_ 数字0-9 py3中引入ASCII字符集以外的额外字符 其分类使用包含于unicodedata模块中Unicode字符数据库 版本 标识符没有长度限制、大小写敏感 12345identifier ::= xid_start xid_continue*id_start ::= &lt;all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property&gt;id_continue ::= &lt;all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property&gt;xid_start ::= &lt;all characters in id_start whose NFKC normalization is in &quot;id_start xid_continue*&quot;&gt;xid_continue ::= &lt;all characters in id_continue whose NFKC normalization is in &quot;id_continue*&quot;&gt; Lu：大写字母 Ll：小写字母 Lt：词首大写字母 Lm：修饰字母 Lo：其他字母 Nl：字母数字 Mn：非空白标识 Mc：含空白标识 Nd：十进制数字 Pc：连接标点 Other_ID_Start：由PropList.txt定义的显式字符列表， 用来支持向后兼容 Other_ID_Continue：同上 Keywords关键字：以下标识符作为语言的保留字、关键字，不能用作普通 标识符 1234567False await else import passNone break except in raiseTrue class finally is returnand continue for lambda tryas def from nonlocal whileassert del global not withasync elif if or yield 保留标识符类以下划线字符开头、结尾的标识符类：具有特殊函数 _*：不会被from module import *导入 特殊标识符_：交互式解释器中用于存放最近一次求值 结果，不处于交互模式时无特殊含义、无预定义 __*__：系统定义名称 由解释器极其实现（包括标准库）定义 任何不遵循文档指定方式使用__*__行为可能导致无警告 出错 __*：类私有名称 在类定义中使用 会以混合形式重写避免基类、派生类私有属性之间出现 名称冲突 字面值字面值：表示一些内置类型常量 字符串、字节串字面值12345678910stringliteral ::= [stringprefix](shortstring | longstring)stringprefix ::= &quot;r&quot; | &quot;u&quot; | &quot;R&quot; | &quot;U&quot; | &quot;f&quot; | &quot;F&quot; | &quot;fr&quot; | &quot;Fr&quot; | &quot;fR&quot; | &quot;FR&quot; | &quot;rf&quot; | &quot;rF&quot; | &quot;Rf&quot; | &quot;RF&quot;shortstring ::= &quot;'&quot; shortstringitem* &quot;'&quot; | '&quot;' shortstringitem* '&quot;'longstring ::= &quot;'''&quot; longstringitem* &quot;'''&quot; | '&quot;&quot;&quot;' longstringitem* '&quot;&quot;&quot;'shortstringitem ::= shortstringchar | stringescapeseqlongstringitem ::= longstringchar | stringescapeseqshortstringchar ::= &lt;any source character except &quot;\\&quot; or newline or the quote&gt;longstringchar ::= &lt;any source character except &quot;\\&quot;&gt;stringescapeseq ::= &quot;\\&quot; &lt;any source character&gt; 123456789bytesliteral ::= bytesprefix(shortbytes | longbytes)bytesprefix ::= &quot;b&quot; | &quot;B&quot; | &quot;br&quot; | &quot;Br&quot; | &quot;bR&quot; | &quot;BR&quot; | &quot;rb&quot; | &quot;rB&quot; | &quot;Rb&quot; | &quot;RB&quot;shortbytes ::= &quot;'&quot; shortbytesitem* &quot;'&quot; | '&quot;' shortbytesitem* '&quot;'longbytes ::= &quot;'''&quot; longbytesitem* &quot;'''&quot; | '&quot;&quot;&quot;' longbytesitem* '&quot;&quot;&quot;'shortbytesitem ::= shortbyteschar | bytesescapeseqlongbytesitem ::= longbyteschar | bytesescapeseqshortbyteschar ::= &lt;any ASCII character except &quot;\\&quot; or newline or the quote&gt;longbyteschar ::= &lt;any ASCII character except &quot;\\&quot;&gt;bytesescapeseq ::= &quot;\\&quot; &lt;any ASCII character&gt; stringprefix、bytesprefix与字面值剩余部分之间不允许 由空白符 源字符集由编码声明定义 字节串字面值只允许ASCII字符（但允许存储不大于256） 两种字面值都可以使用成对（连续三个）单引号、双引号标示 首尾 单引号''：允许包含双引号&quot;&quot; 双引号&quot;&quot;：允许包含单引号'' 三重引号'''、&quot;&quot;&quot; 原样保留：未经转义的换行、（非三联）引号、空白符 反斜杠\\用于对特殊含义字符进行转义 字符串前缀 b/B前缀：字节串字面值 创建bytes类型而非str类型实例 只能包含ASCII字符 字节对应数值大于128必须以转义形式表示 r/R：原始字符串/字节串 其中反斜杠\\被当作其本身字面字符处理 转换序列不在有效 原始字面值不能以单个\\结束，会转义之后引号字符 f/F：格式化字符串字面值 转义规则 字符串、字节串字面值中转义序列基本类似标准C转义规则 \\xhh：必须接受2个16进制数码 以下转义序列仅在字符串字面值中可用 \\N{name}：Unicode数据库中名称为name的字符 \\uxxxx：必须接受4个16进制数码 \\Uxxxxxxxx：必须接受8个16进制数码 无法识别的转义序列 py3.6之前将原样保留在字符串中 py3.6开始，将引发DeprecationWarning，未来可能会 引发SyntaxError 字符串字面值拼接 多个相邻字符串、字符串字面值（空白符分隔），含义等同于 全部拼接为一体 所用引号可以彼此不同（三引号风格也可用） 每部分字符串可以分别加注释 可以包括格式化字符串字面值 此特性是在句法层面定义，在编译时实现 在运行时拼接字符串表达式必须使用+运算符 格式化字符串字面值格式化字符串字面值：带有f/F前缀的字符串字面值 包含可替换字段，即以{}标示的格式表达式 字符串{}以外部分按字面值处理 双重花括号{ { } }被替换为相应单个花括号 格式表达式被当作正常的包含在圆括号中python表达式处理 ，在运行时从左至右被求值 不允许空表达式 lambda空表达式必须显式加上圆括号 可以包含换行：如三引号字符串 不能包含注释 不能\\反斜杠，考虑创建临时变量 格式化字符串字面值可以拼接，但是一个替换字段不能拆分到 多个字面值中 格式化字符串不能用作文档字符串，即使其中没有包含表达式 12345678f_string ::= (literal_char | &quot;{{&quot; | &quot;}}&quot; | replacement_field)*replacement_field ::= &quot;{&quot; f_expression [&quot;!&quot; conversion] [&quot;:&quot; format_spec] &quot;}&quot;f_expression ::= (conditional_expression | &quot;*&quot; or_expr) (&quot;,&quot; conditional_expression | &quot;,&quot; &quot;*&quot; or_expr)* [&quot;,&quot;] | yield_expressionconversion ::= &quot;s&quot; | &quot;r&quot; | &quot;a&quot;format_spec ::= (literal_char | NULL | replacement_field)*literal_char ::= &lt;any code point except &quot;{&quot;, &quot;}&quot; or NULL&gt; !：标识转换字段 !s：对结果调用str() !r：调用repr() !a：调用ascii() 1234name = &quot;Fred&quot;print(f&quot;he said his name is {name!r}&quot;)print(&quot;he said his name is {repr(name)}&quot;) # 二者等价 :：标识格式说明符，结果使用format()协议格式化 格式说明符被传入表达式或转换结果的.__format__() 方法 省略格式说明符则传入空字符串 123456789width, precision = 4, 10value = decimal.Deciaml(&quot;12.345&quot;)print(f&quot;result: {value: {width}.{precision}}&quot;)today = datetime(yeat=2017, month=1, day=27)print(f&quot;{today: %B %d, %Y}&quot;)number = 1024print(f&quot;{number: #0x}&quot;) 顶层格式说明符可以包含嵌套替换字段 嵌套字段可以包含有自身的转换字段、格式说明符，但不能 包含更深层嵌套替换字段 数字字面值 数字字面值不包括正负号 负数实际上是由单目运算符-和字面值组合而成 没有专门复数字面值 复数以一对浮点数表示 取值范围同浮点数 数字字面值可以使用下划线_将数码分组提高可读性 确定数字大小时，字面值之间的下滑线被忽略 下划线可以放在数码之间、基数说明符0x等之后 浮点数中不能直接放在.后 整形数字字面值 整形数字字面值没有长度限制，只受限于内存 12345678910integer ::= decinteger | bininteger | octinteger | hexintegerdecinteger ::= nonzerodigit ([&quot;_&quot;] digit)* | &quot;0&quot;+ ([&quot;_&quot;] &quot;0&quot;)*bininteger ::= &quot;0&quot; (&quot;b&quot; | &quot;B&quot;) ([&quot;_&quot;] bindigit)+octinteger ::= &quot;0&quot; (&quot;o&quot; | &quot;O&quot;) ([&quot;_&quot;] octdigit)+hexinteger ::= &quot;0&quot; (&quot;x&quot; | &quot;X&quot;) ([&quot;_&quot;] hexdigit)+nonzerodigit ::= &quot;1&quot;...&quot;9&quot;digit ::= &quot;0&quot;...&quot;9&quot;bindigit ::= &quot;0&quot; | &quot;1&quot;octdigit ::= &quot;0&quot;...&quot;7&quot;hexdigit ::= digit | &quot;a&quot;...&quot;f&quot; | &quot;A&quot;...&quot;F&quot; 浮点数字字面值 整形数部分、指数部分解析时总以10为计数 浮点数字面值允许范围依赖于具体实现 123456floatnumber ::= pointfloat | exponentfloatpointfloat ::= [digitpart] fraction | digitpart &quot;.&quot;exponentfloat ::= (digitpart | pointfloat) exponentdigitpart ::= digit ([&quot;_&quot;] digit)*fraction ::= &quot;.&quot; digitpartexponent ::= (&quot;e&quot; | &quot;E&quot;) [&quot;+&quot; | &quot;-&quot;] digitpart 虚数字面值 序数字面值将生成实部为0.0的复数 1imagnumber ::= (floatnumber | digitpart) (&quot;j&quot; | &quot;J&quot;) 运算符123+ - * ** / // % @&lt;&lt; &gt;&gt; &amp; | ^ ~&lt; &gt; &lt;= &gt;= == != 分隔符1234( ) [ ] { }, : . ; @ = -&gt;+= -= *= /= //= %= @=&amp;= |= ^= &gt;&gt;= &lt;&lt;= **= 以上列表中后半部分为增强赋值操作符 在词法中作为分隔符，同时起运算作用 1' &quot; # \\ 以上可打印ASCII字符 作为其他token组成部分时有特殊意义 或对词法分析器有特殊意义 1$ ? 以上可打印ASCII字符不再Python词法中使用 出现在字符串字面值、注释之外将无条件引发错误","link":"/Python/Py3Ref/lexical_analysis.html"},{"title":"Python概述","text":"综述 语言的具体实现可能发生改变、其他实现可能使用不同方式 在语言的参考文档中加入过多细节实现很危险 Python实现python只是一种语言，其具体解释器实现有很多种 CPython：C语言实现，最原始版本 通常就被称为Python，其他实现区分时才强调为CPython 新语言特性通常较早出现 Jython：Java实现 将Python代码编译为Java字节码 可以左线Java应用的脚本语言、创建需要Java类库支持的 应用 在JVM上运行 Python for .NET：实际上使用CPython实现，但是属于.NET 托管应用，可以引入.NET类库 IronPython：.NET实现 生成IL的完全Python实现，将Python代码直接编译为.NET 程序集 PyPy：RPython（Python语言子集）实现 JIT编译器，执行效率高于CPython 非栈式支持 允许方便修改解释器，鼓励对语言本身进行实验 CPython是解释器实现版本，cython是将Python代码翻译为 C插件的项目/包 Notation说明标注：词法、句法解析的描述使用修改过的BNF语法标注 12name ::= lc_letter(lc_letter | &quot;_&quot;)*lc_letter ::= &quot;a&quot;...&quot;z&quot; ::=：声明规则，左侧为规则名称 |：分隔可选项 *：前一项的零次、多次重复 +：前一项的一次、多次重复 []：括起内容可选，即出现零次、一次 ()：分组 &quot;&quot;：固定字符串包含在引号内 ：空格仅用于分隔token ...：三个点分割的本义字符表示在指定区间范围内的任意 单个字符 &lt;&gt;：对所定义符号的非常描述，在必要时用于说明“控制字符” 意图 每条规则通常为一行，多个可选项规则可用|为界分为多行 词法定义：作用域输入源中的单独字符 句法定义：作用于词法分析生成的token stream 约定 实例方法：定义在类命名空间中、未因访问而绑定函数 绑定方法：已绑定实例方法 静态方法 类方法 [类]实例：类实例化所得对象 对象：泛指所有python对象，包括类、实例 Global Intepretor Lock全局内存锁：GIL，任何python字节码执行前必须获得的解释器锁 在任何时刻，只能有一个线程处于工作状态 避免多个线程同时操作变量导致内存泄漏、错误释放 优势 GIL实现简单，只需要管理一把解释器锁就能保证线程内存安全 当然GIL只能保证引用计数正确，避免由此导致内存问题 还需要原子操作、对象锁避免并发更新问题 GIL单线程情况下性能更好、稳定，若通过给所有对象引用计数 加锁来实现线程安全 容易出现死锁 性能下降很多 方便兼容C遗留库，这也是python得以发展的原因 很多python需要的C库扩展要求线程安全的内存管理 影响 Python线程是真正的操作系统线程 在准备好之后必须获得一把共享锁才能运行 每个线程都会在执行一定机器指令和后切换到无锁状态， 暂停运行 事实上程序在开始时已经在运行“主线程” 解释器检查线程切换频率sys.getcheckinterval() Python线程无法在多核CPU间分配，对CPU-Bound程序基本没有 提升效果，对于IO-Bound的程序性能仍然有巨大帮助 解决方案 多进程 进程分支：os.fork 派生进程：multiprocessing.Process、 concurrent.futures C语言库封装线程：ctypes、cython C扩展形式实现任务线程可在python虚拟机作用域外运行 可以并行运行任意数量线程 在运行时释放GIL、结束后继续运行python代码时重新获取 GIL，真正实现独立运行 使用其他版本Python解释器：只有原始Python版本CPython使用 GIL实现 Jython IronPython PyPy Python最高层级组件完整的Python程序 完整的python程序会在最小初始化环境中被执行 所有内置、标准模块均可用，但均处于未初始化状态 只有sys、builtins、__main__已经初始化 __main__模块为完整程序的执行提供局部、全局命名空间 完整程序可通过三种形式传递给解释器 -c命令行选项传递字符串 文件作为第一个命令行参数 标准输入 若文件、标准输入是tty设备，解释器进入交互模式，否则 将文件当作完整程序执行 解释器也可以通过交互模式被发起调用 每次读取执行一条语句，语句会在__main__命名空间中 被执行 初始环境同完整程序 输入类型文件输入文件输入：从非交互式文件读取的输入，具有相同形式 1file_input ::= (NEWLINE|statement)* 适合以下几种情况 解析完整的python程序（从文件、字符串） 解析模块 解析传递给exec()函数的字符串 交互式输入交互式输入：从tty设备读取输入 1interactive_input ::= [stmt_list] NEWLINE | compound_stmt NEWLINE 注意 交互模式中（最高层级）复合语句后必须带有空行，帮助 解释器确定输入的结束 表达式输入表达式输入 1eval_input ::= expression_list NEWLINE* eval被用于表达式输入 忽略开头空白","link":"/Python/Py3Ref/py3ref_abstract.html"},{"title":"Python C 扩展","text":"","link":"/Python/Cookbook/c_extensions.html"},{"title":"Py3std Readme","text":"常用参数说明 函数书写声明同Python全局说明 以下常用参数如不特殊注明，按照此解释 CommonStream mode=&quot;r&quot;/&quot;w&quot;/&quot;a&quot;/&quot;+&quot;/&quot;t&quot;/&quot;b&quot; 含义：文件/管道打开模式 t：文本，可省略 b：二进制 r：读，默认 w：写 a：追加，大部分支持 +：更新模式，同时允许读写 r+：文件已存在，读、写 w+：清除之前内容，读、写 a+：读、追加写 默认：rt/r buffering/bufsize = -1/0/1/int 含义：缓冲模式 0：不缓冲，只在二进制模式中被运行 1：逐行缓冲，只在文本模式中有效 其他正整数：指定固定大小chunk缓冲的大小 -1：全缓冲 普通二进制、文本，缓冲chunks大小启发式确定， io.DEFAULT_BUFFER_SIZE查询 终端交互流（.isatty()），逐行缓冲 默认：-1 encoding(str) 含义：文件编码 utf-8 utf-16 utf-16-le utf-16-be utf-32 gbxxxx 待续 缺省：使用locale.getpreferedencoding()返回值 Threading/Processing block/blocking = True/False 含义：是否阻塞 默认：大部分为True（阻塞） 其他 对返回值不是bool类型的函数，非阻塞时若无法进行 操作，往往会raise Exception timeout = None/num 含义：延迟时间，单位一般是秒 默认：None，无限时间 其他 block=False时，一般timeout参数设置无效 fn/func/callable(callable) 含义：可调用对象 默认：一般默认值 其他 实参可以是任何可调用对象 函数 方法 可调用对象 args = ()/None/tuple/list/*args(arg_1, ...) 含义：函数位置参数 默认：()/None，无参数 kwrags/kwds = {}/None/dict/**kwargs(kwarg_1=v1, ...) 含义：函数关键字参数 默认：{}/None，无参数 callback=callable 含义：回调函数 异步线程、进程调用才会有该参数 回调函数接收进程/线程返回值作为参数 回调函数最好有返回值，否则会阻塞进程、线程池 默认：None，无参数 chunksize=None/1/int 含义：一次传递给子进程的迭代器元素数量 常在进程池迭代调度函数中，较大的chunksize 能减少进程间通信消耗，但会降低灵活性 线程调度相关函数该参数被忽略 默认：None/1，一次传递一个元素 daemon=False/None/True 含义：是否为守护进程/线程 默认情况下，主进程（线程）会等待子进程、线程退出 后退出 主进程（线程）不等待守护进程、线程退出后再退出 注意：主进程退出之前，守护进程、线程会自动终止 Python命令行参数 -c：解释执行语句 -u：强制输入、输出流无缓冲，直接输入，默认全缓冲","link":"/Python/Py3std/README.html"},{"title":"Python 元编程","text":"Decorator装饰器装饰器就是函数，接受函数作为参数并返回新的函数 装饰器不会修改原始函数签名、返回值，但是大部分返回的 新函数不是原始函数，看起来像是函数元信息发生改变 新函数也可能是单纯的修改原函数的元信息、然后返回 装饰器设计保留函数元信息装饰器作用在函数上时，原函数的重要元信息会丢失 名字：func.__name__ 文档字符串：func.__doc__ 注解： 参数签名：func.__annotations__ 12345678910111213141516171819202122import timefrom functools import wrapsdef timethis(func): @wraps(func) def wrapper(*args, **kargs): start = time.time() result = func(*args, **kwargs) end = time.time() print(func.__name__, end - start) return result return wrapper@timethisdef countdown(n): while n &gt; 0: n -= 1def countdown(n): passcountdown = timethis(countdown) # 这个和上面装饰器写法效果一致 @wraps能够复制原始函数的元信息，并赋给装饰器返回的函数 ，即被@wraps装饰的函数 装饰后函数拥有__wrapped__属性 直接用于访问被包装函数，即解除装饰器 有多个包装器__wrapped__的行为是不可预知的， 可能会因为python版本有差，应该避免 让装饰器函数正确暴露底层参数签名信息 123countdown.__wrapped__(10000)from inspect import signatureprint(signature(countdown)) 自定义属性在装饰器中引入访问函数，访问函数中使用nolocal修改内部 变量t 访问函数可在多层装饰器间传播，如果所有的装饰中的wrapper 都使用了@functools.wraps注解（装饰） 可以使用lambda匿名函数，修改访问函数属性改变其行为 123456789101112131415161718192021222324252627282930313233343536373839404142from functools import wrapsimport loggingdef logged(level, name=None, message=None): def decorator(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) @attach_wrapper(wrapper) # attach setter function def set_level(newlevel): nonlocal level level = newlevel @attach_wrapper(wrapper) def set_message(newmsg): nonlocal logmsg logmsg = newmsg return wrapper return decorator@logged(logging.DEBUG)def add(x, y): return x + y@logged(logging.CRITICAL, &quot;example&quot;)def spam(): print(&quot;Spam&quot;)@timethis@logged(logging.DEBUG) # 使用多层装饰器，访问函数可以在多层装饰器间传播def countdown(n): while n &gt; 0: n -= 1 带参装饰器带参装饰器就是接受参数、处理，再返回一个第一个参数为函数 的函数（内部装饰器） 三层函数 最外层套一层接受参数的函数 内部装饰器函数可以访问这些参数，并在“存储”在内部， 相当于一个闭包 返回使用参数处理后的装饰器函数，再装饰函数 12345678910111213141516171819202122232425262728293031323334353637from functools import wrapsimport loggingdef logged(level, name=None, message=None): r&quot;&quot;&quot;Decorator that allows logging :param level: logging level :param name: logger name, default function's module :param message: log message, default function's name :return :decorator &quot;&quot;&quot; def decorator(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper return decorator@logged(logging.DEBUG)def add(x, y): return x + y@logged(loggin.CRITICAL, &quot;example&quot;)def spam(): print(&quot;spam&quot;)def spam(): passspam = logged(logging.CRITICAL, &quot;example&quot;)(spam) # 这样调用和之前的装饰器语句效果相同 functools.partialpartial接受一个函数作参数，并返回设置了部分参数默认值的 函数，而最外层函数就只是用于“获取”参数，因此可以使用此技巧 减少一层函数嵌套 123456789101112131415from functools import partialdef attach_wrapper(obj, func=None): r&quot;&quot;&quot;Decorator to attach function to obj as an attr :param obj: wapper to be attached to :param func: function to be attached as attr :return: wrapper &quot;&quot;&quot; if func is None: return partial(attach_wrapper, obj) setattr(obj, func.__name__, func) return func 参数可选三层函数这种形式的带可选参数的装饰器，即使不传递参数，也必须使用 调用形式装饰 12345678910111213141516171819202122232425262728293031323334353637from functools import wrapsimport loggingdef logged(level=logging.DEBUG, name=None, message=None): r&quot;&quot;&quot;Decorator that allows logging :param level: logging level :param name: logger name, default function's module :param message: log message, default function's name :return :decorator &quot;&quot;&quot; def decorator(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper return decorator@logged() # 这种方式实现的默认参数装饰器必须使用`@logged()`调用的 # 形式，从装饰器形式就可以看出，必须调用一次才能返回内部 # 装饰器 # 这种形式的装饰器不符合用户习惯，不用传参也必须使用的 # 调用形式def add(x, y): return x + y@logged(level=logging.CRITICAL, name=&quot;example&quot;)def add(x, y): return x + y partial这种形式的装饰器，不传参时可以像无参数装饰器一样使用 12345678910111213141516171819202122232425262728293031from functools import wraps, partialimport loggingdef logged( func=None, *, level=logging.DEBUG, name=None, message=None): if func is None: return partial(logged, level=level, name=name, message=message) logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper@logged # 使用`partial`函数形式的带默认参数的装饰器，可以不用 # 调用形式def add(x, y): return x + y@logged(level=logging.CRITICAL, name=&quot;example&quot;)def spam(): print(&quot;spam&quot;) 用途示例强制检查参数类型123456789101112131415161718192021222324252627282930def typeasssert(*ty_args, **ty_kwargs): r&quot;&quot;&quot;Decorator that assert the parameters type :param *ty_args: parameters type indicated with position :param **ty_kwargs: parameters type indicated with keywords :return: wrapper &quot;&quot;&quot; def decorator(func): # if in optimized mode, disable type checking if not __debug__: return func sig = signature(func) # map function argument names to asserted types bound_types = sig.bind_partial(*ty_args, **ty_kwargs).arguments @wraps(func) def wrapper(*args, **kwargs): # map function argument names to paraments bound_values = sig.bind(*args, **kwargs).argument for name, val in bound_values.items(): if name in bound_types: if not isinstance(value, bound_types[name]): raise TypeError( &quot;Argument {} must be {}.&quot;.format(name, bound_types[name]) return func(*args, **kwargs) return wrapper return decorator 装饰器类为了定义类装饰器，类需要实现__call__、__get__方法，然后 就可以当作普通的的装饰器函数使用 12345678910111213141516171819import typesfrom functools improt wrapsclass Profiled: def __init__(self, func): wraps(func)(self) # 获取`func`的元信息赋给实例 self.ncalls = 0 def __call__(self, *args, **kwargs): self.nacalls += 1 return self.__wrapped__(*args, **kwargs) # 解除装饰器 def __get__(self, instance, cls): if intance is None: return self else: return types.MethodType(self, instance) 装饰器方法在类中定义装饰器方法，可以将多个装饰器关联于同一个类的实例， 方便在装饰器中记录、绑定、共享信息 @property装饰器类：可以将类方法method_atrr“转变”为 属性 设置完成之后，会创建2个以方法名开头的装饰器 method_attr.setter、method_attr.deleter用于装饰 同名的方法 分别对应其中包含setter、deleter、getter （@property自身）三个方法 详情查看clsobj 装饰类、静态方法装饰器必须放在@staticmethod、@classmethod装饰器之前 （内层），因为这两个装饰器实际上并不创建callable对象，而是 创建特殊的描述器对象 添加参数为原函数“添加”KEYWORD_ONLY参数，这种做法不常见，有时能避免 重复代码 KEYWORD_ONLY参数容易被添加进*args、**kwargs中 KEYWORD_ONLY会被作为特殊情况挑选出来，并且不会用于调用 原函数 但是需要注意，被添加的函数名称不能与原函数冲突 1234567891011121314from functools import wrapsimport inspectdef optional_debug(func): if &quot;debug&quot; in inspect.getargspect(func).args: raise TypeError(&quot;Debug argument already defined&quot;) # 防止原函数参数中参数与新增`debug`冲突 @wraps(func) def wrapper(*args, debug=False, **kwargs): # 给原函数“增加”了参数 if debug: print(&quot;calling&quot;, func.__name__) return func(*args, **kwargs) return wrapper 装饰器扩充类功能可以通过装饰器修改类某个方法、属性，修改其行为 可以作为其他高级技术：mixin、metaclass的简洁替代方案 更加直观 不会引入新的继承体系 不依赖super函数，速度更快 注意：和装饰函数不同，装饰类不会返回新的类，而是修改原类， 因此装饰器的顺序尤为重要 12345678910111213141516def log_getattribute(cls): orig_getattribute = cls.__getattribute__ def new_getattribute(self, name): print(&quot;getting:&quot;, name) return orig_getattribute(self, name) cls.__getattribute = new_getattribute return cls@log_getattributeclass A: def __init__(self, x): self.x = x def spam(self): pass Metaclass元类用途示例单例模式123456789101112131415class Singleton(type): def __init__(self, *args, **kwargs): self.__intance = None super().__init__(*args, **kwargs) def __call__(self, *args, **kwargs): if self.__instance is None: self.__instance = super().__call__(*args, **kwargs) return self.__instance else: return self.__instanceclass Spam(metaclass=Singleton): def __init__(self): print(&quot;Creating Spam&quot;) 缓存实例123456789101112131415161718import weakrefclass Cached(type): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.__cache = weakref.WeakValueDictionar() def __call__(self, *args): if args in self.__cache: return self.__cache[args] else: obj = super().__call__(*args) self.__cache[args] = obj return objclass Spam(metaclass=Cached): def __init__(self, name): print(&quot;creating spam({!r})&quot;.format(name)) self.name = name","link":"/Python/Cookbook/decorator.html"},{"title":"Python Datetime","text":"","link":"/Python/Cookbook/date_time.html"},{"title":"Python 函数式编程","text":"functoolstotal_orderingtotal_ordering：允许类只定义__eq__和其他中的一个，其他 富比较方法由装饰器自动填充 12345678910111213141516171819202122232425262728293031323334from functools import total_orderingclass Room: def __init__(self, name, length, width): self.name = name self.length = length self.width = width self.square_feet = self.length * self.width@total_orderingclass House: def __init__(self, name, style): self.name = name self.style = style self.rooms = list() @property def living_space_footage(self): return sum(r.square_feet for r in self.rooms) def add_room(self, room): self.rooms.append(room) def __str__(str): return &quot;{}: {} squre foot {}&quot;.format( self.name, self.living_space_footage, self.style) def __eq__(self, other): return self.living_space_footage == other.living_space_footage def __lt__(self, other): return self.living_space_footage &lt; other.living_space_footage","link":"/Python/Cookbook/funcs.html"},{"title":"Python 测试","text":"","link":"/Python/Cookbook/excption_testing.html"},{"title":"Python IO、持久化","text":"DBMDBM文件是python库中数据库管理的标准工具之一 实现了数据的随机访问 可以使用键访问存储的文本字符串 DBM文件有多个实现 python标准库中dbm/dbm.py 使用 使用DBM文件和使用内存字典类型非常相似 支持通过键抓取、测试、删除对象 pickle 将内存中的python对象转换为序列化的字节流，可以写入任何 输出流中 根据序列化的字节流重新构建原来内存中的对象 感觉上比较像XML的表示方式，但是是python专用 1234567import pickledbfile = open(&quot;people.pkl&quot;, &quot;wb&quot;)pickle.dump(db, dbfile)dbfile.close()dbfile = open(&quot;people.pkl&quot;, &quot;rb&quot;)db = pickle.load(dbfile)dbfile.close() 不支持pickle序列化的数据类型 套接字 shelves 就像能必须打开着的、存储持久化对象的词典 自动处理内容、文件之间的映射 在程序退出时进行持久化，自动分隔存储记录，只获取、 更新被访问、修改的记录 使用像一堆只存储一条记录的pickle文件 会自动在当前目录下创建许多文件 123456import shelvesdb = shelves.open(&quot;people-shelves&quot;, writeback=True) // `writeback`：载入所有数据进内存缓存，关闭时再写回， // 能避免手动写回，但会消耗内存，关闭变慢db[&quot;bob&quot;] = &quot;Bob&quot;db.close() SQLiteSQLAlchemy","link":"/Python/Cookbook/io_serial.html"},{"title":"Python类说明","text":"元类说明typetype：元类，python中所有类都由type创建 12345class = type( name=cls_name, bases=(pls_name,..), dict={attr1: val1,...}) 参数 cls_name：类名称 bases：父类元组 dict：类方法、属性 返回值：类的别名 元类作用 拦截类创建-&gt;修改类-&gt;返回修改后的类（创建类对象） 元类的作用和函数相似 python并不关心类对象是否是由真正的元类创建 可以指定元类为一个函数，而非继承自type的元类 但仍应尽量将元类指定为继承自type的对象 元类应用场景一般比较复杂，使用类可以更好的管理代码 默认元类是type类，类继承保持一致性意图比较明显，且 可以使用type中的方法 元类可以使用一些类中特有的方法：__new__，__init__ 等 如果不确定是否需要用元类，就不应该使用 自定义元类123456789101112131415class UpperAttrMeta(type): def __new__(cls, cls_name, bases, attrs): upper_attrs=dict((name.upper(), val) for name,val in attrs.items() if not name.startswith('__') ); return super(UpperAttrMeta,cls).__new__( cls, cls_name, bases, upper_attrs); // 使用元类创建新类class Foo(metaclass=UpperAttrMeta): b=1; 使用自定义元类UppAttrMeta创建的类Foo中定义的__init__、 __new__等函数无意义，因为该类不仅是通过元类创建，也是 通过元类初始化 类Foo通过UpperAttrMeta创建，而UppAttrMeta本身没有 实现自定义__init__，默认继承于object 因此Foo类的创建就有object的init完成 segmentfault.com/q/1010000004438156 这个是原话，不明白什么意思了 但是如果元类仅仅是pass，如下： 12class MetaCls(type): pass; 使用此自定义元类，类定义中的__init__、__new__有效 类创建py2自定义元类python创建类对象步骤 __metaclass__指定创建类使用的元类 按照优先级：类定义内 &gt; 祖先类内 &gt; 模块内 &gt; type， 查找__metaclass__，并使用其创建类对象，若前三者 均未定义__metaclass__，则使用type创建 自定义元类就是为__metaclass__指定自定义值 python只是将创建类的参数传递给__metaclass__，并不 关心__metaclass__是否是一个类 cls()返回一个类对象，是相当于调用cls.__new__ 所以可以指定__metaclass__为一个函数 1234567891011121314151617181920212223242526272829303132333435 def upper_attr(cls_name, bases, attrs): upper_attrs=dict((name.upper(), val) for name,val in attrs.items()); return type(cls_name, bases, upper_attrs);class Foo(): bar=1; __metaclass__=upper_attr; # 函数版本class UpperAttrMeta(type): def __new__(clsf, cls_name, bases, attrs): upper_attrs=dict((name.upper(), val) for name,val in attrs.items()); return type(cls_name, bases, upper_attrs); class Foo(): bar=1; __metaclass__=UpperAttrMeta; # 类版本1class UpperAttrMeta(type): def __new__(cls, cls_name, bases, attrs): upper_attrs=dict((name.upper(), val) for name,val in attrs.items()); return type.__new__(cls, cls_name, bases, upper_attrs); # 类版本2class UpperAttrMeta(type): def __new__(cls, cls_name, bases, attrs): upper_attrs=dict((name.upper(), val) for name,val in attrs.items()); return super(UpperAttrMeta,cls).__new__(cls, cls_name, bases, upper_attrs); # 类版本3 元类示例缓存实例12345678910111213141516171819import weakrefclass Cached(type): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.__cache = weakref.WeakValueDictionary() def __call__(self, *args): if args in self.__cache: return self.__cache[args] else: obj = super().__call__(*args) self.__cache[args] = obj return objclass Spam(metaclass=Cached): def __init__(self, name): print(&quot;Creating Spam({!r})&quot;.format(name)) self.name = name 捕获类属性定义顺序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from collection import OrderedDictclass Typed: _expected_type = type(None) def __init__(self, name=None): self._name = name def __set__(self, instance, value): if not instance(value, self_expected_type): raise TypeError(&quot;expected&quot; + str(self._expected_type)) instance.__dict__[self._name] = valueclass Integer(Typed): _expected_type = intclass Float(Typed): _expected_type = floatclass String(Typed): _expected_type = strclass OrderedMate(type): def __new__(cls, clsname, bases, clsdict): d = dict(clsdict) order = [ ] for name, value in clsdict.items(): if isinstance(value, Typed): value._name = name order.append(name) d[&quot;_order&quot;] = order return type.__new__(cls, clsname, bases, d) @classmethod def __prepare__(cls, clsname, bases): # 此方法会在开始定义类、其父类时执行 # 必须返回一个映射对象，以便在类定义体中使用 return OrderedDict()class Structure(metaclass=OrderedMeta): def as_csv(self): return &quot;,&quot;.join(str(getattr(self, name)) for name in self._order)class Stock(Structure): name = String() shares = Integer() price = Float() def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price 有可选参数元类为了使元类支持关键字参数，必须在__prepare__、__new__、 __init__方法中使用KEYWORDS_ONLY关键字参数 12345678910111213class MyMeta(type): @classmethod def __prepare__(cls, name, bases, *, debug=False, synchronize=False): pass return super().__prepare(naeme, bases) def __new__(cls, name, bases, *, debug=False, synchronize=False): pass return super().__new__(cls, name, bases, ns) def __init__(self, name, bases, ns, *, debug=False, synchronize=False): pass super().__init__(name, base, ns)","link":"/Python/Cookbook/metaclass.html"},{"title":"Python系统编程","text":"综述主要标准模块 os：与Python所在底层操作系统相对应变量、函数 sys：与Python解释器本身相关的组件 文件、目录 glob：文件名扩展 stat：文件信息 并行开发 threading、_thread、queue：运行、同步并发线程 subprocess、multiprocessing：启动、控制并行进程 socket：网络连接、进程间通信 系统 time、timeit：获取系统时间等相关细节 signal、select、shutil、tempfile：多种系统 相关任务 说明 Python中大部分系统级接口都集中在模块sys、os中 以上模块之间具体实现不总是遵循规则 标准输入、输出流位于sys中，但可以将视为与操作系统 模式相关 一些内建函数实际上也是系统接口 open Sys模块平台、版本123456789101112import syssys.platform # 操作系统名称sys.maxsize # 当前计算机最大容纳“原生”整型 # 一般就是字长sys.version # python解释器版本号sys.byteorder # 平台字节序sys.hash_info # 数值类型hash信息 sys.xxxcheckinterval1234sys.getcheckinterval() # 查看解释器检查线程切换、信号处理器等的频率sys.setcheckinterval(N) # 设置解释器检查线程切换、信号处理器等的频率 参数 N：线程切换前执行指令的数量 对大多数程序无需更改此设置，但是可以用于调试线程性能 较大值表示切换频率较低，切换线程开销降低，但是对事件 的应答能力变弱 较小值表示切换频率较高，切换线程开销增加，对事件应答 能力提升 sys.hash_info12sys.hash_info.width # `hash()`函数截取hash值长度 模块搜索路径1sys.path 返回值：目录名称字符串组成的列表 每个目录名称代表正在运行python解释器的运行时模块 搜索路径 可以类似普通列表在运行时被修改、生效 sys.path初始化顺序 脚本主目录指示器：空字符串 脚本主目录是指脚本所在目录，不是os.getcwd() 获取的当前工作目录 PYTHONPATH环境变量 12# .bashrcexport PYTHONPATH=$PYTHONPATH:/path/to/fold/contains/module 标准库目录 .pth路径文件：在扫描以上目录过程中，遇到.pth文件会 将其中路径加入sys.path中 12# extras.pth/path/to/fold/contains/module 导入模块顺序导入模块时，python解释器 搜索内置模块，即内置模块优先级最高 从左至右扫描sys.path列表，在列表目录下搜索模块文件 嵌入解释器的钩子123456sys.modules # 已加载模块字典sys.builtin_module_names # 可执行程序的内置模块sys.getrefcount() # 查看对象引用次数 异常1sys.exc_info() 返回值：(type, value, trackback) 最近异常的类型、值、追踪对象元组 处理该异常的except执行之后，sys.exc_info被恢复 为原始值 追踪对象可以使用traceback模块处理 命令行参数1sys.argv 返回值：命令行参数列表 首项始终为执行脚本名称，交互式python时为空字符串 参数可以自行解析，也可以使用以下标准库中模块 getopt：类似Unix/C同名工具 optparse：功能更加强大 标准流123456sys.stdin # 标准输入流sys.stdout # 标准输出流sys.stderr # 标准错误流 标准流是预先打开的python文件对象 在python启动时自动链接到程序上、绑定至终端 shell会将相应流链接到指定数据源：用户标准输入、文件 重定向 可以将sys.stdin、sys.stdout重置到文件类的对象，实现 python内部的、普遍的重定向方式 外部：cmd输入输出重定向 局部：指定print参数 任何方法上与文件类似的对象都可以充当标准流，与对象类型 无关，只取决于接口 任何提供了类似文件read方法的对象可以指定给 sys.stdin，以从该对象read读取输入 任何提供了类似文件write方法的对象可以指定给 sys.write，将所有标准输出发送至该对象方法上 标准库io提供可以用于重定向的类StringIO、ByteIO 重定向之后print、input方法将应用在重定向之后的流 stdin12345678stdin.read() # 从标准输入流引用对象读取数据input(&quot;input a word&quot;)sys.stdin.readlines()[-1] # 以上两行语句类似stdin.isatty() # 判断stdin是否连接到终端（是否被重定向） 在stdin被重定向时，若需要接受用户终端输入，需要使用 特殊接口从键盘直接读取用户输入 win：msvcrt模块 linux：读取/dev/tty设备文件 退出1sys.exit(N) 用途：当前线程以状态N退出 实际上只是抛出一个内建的SystemExit异常，可以被正常 捕获 等价于显式raise SystemExit 进程退出参见os._exit() sys.exitfuncs1sys.exitfuncs 编码12345sys.getdefaulencoding() # 文件内容编码，平台默认值 # 默认输入解码、输出编码方案sys.getfilesystemencoding() # 文件名编码，平台默认体系 win10中二者都是utf-8，win7中文件名编码是mbcs os模块 os模块提供了POSIX工具 操作系统调用的跨平台移至标准 不依赖平台的目录处理工具 os.path 包含在C程序、shell脚本中经常用到的所有操作系统调用，涉及 目录、进程、shell变量 实践中，os基本可以作为计算机系统调用的可移植接口 使用 只要技术上可行，os模块都能跨平台 但在某些平台，os提供专属该平台的工具 Shell变量12345os.environ # 获取、设置shell环境变量，类似字典os.putenv() # 修改进程对应shell环境变量os.getenv() os.environos.environ可以向普通字典一样键索引、赋值 默认继承系统所有环境变量、命令行临时环境变量 在最新的python中，对os.environ的键值修改将自动导出 到应用的其他部分 os.environ对象 进程对应shell环境变量：通过后台调用os.putenv生效， 反之不会更新os.environ python进程、链入C模块、该进程派生子进程都可以获取新的 赋值 子进程一般会继承父进程的环境变量设定 可以作为传递信息的方式 os.putenv os.putenv同时会调用C库中的putenv（若在系统中可用） 导出设置到python链接的C库 底层C库没有putenv则可将os.environ作为参数传递 管理工具123456os.getpid() # 调用函数的进程idos.getcwd() # 当前工作目录CWDos.chdir(r&quot;C:\\Users&quot;) # 更改当前工作目录CWD 移植工具123456789101112131415os.sep # python底层运行平台采用的**目录组**分隔符号 # linux: `/`、win：`\\`、某些mac：`:`os.pathsep # 目录列表（字符串形式）中分隔目录的字符 # posix机：`:`、win：`;`os.curdir # 当前目录代表 # linux：`.`os.pardir # 父目录代表 # linux：`..`os.linesep # 换行符 # linux：`\\n` ||Linux|Win|Unix| |———|——————|———|———| |sep|/|\\|/（某些MAC:）| |pathsep|:|;|| |curdir|.||| |pardir|..||| |linesep|\\n|\\r\\n|| 借助这些变量可以系统相关字符串操作的跨平台 win下目录组分隔符是\\，大部分情况下看到\\\\是作为\\ 转义字符，防止\\和之后字符转义 确认不会转义时，直接使用\\也是可以的 使用r''表示不转义也可以直接使用\\ 路径名工具判断存在12345os.path.isdir(r&quot;C:\\Users&quot;)os.path.isfile(r&quot;C:\\Users&quot;) # 判断路径名是简单文件、目录os.path.exists(r&quot;C:\\Users&quot;) # 判断路径名是否存在 os.stat配合stat模块有更丰富的功能 路径操作123456789101112131415161718pfile = os.path.join(r&quot;C:\\temp&quot;, &quot;output.txt&quot;) # 连接文件名、目录os.path.split(pfile) # 分离文件名、目录os.path.dirname(pfile) # 返回路径中目录os.path.basename(pfile) # 返回路径中os.path.splitext(pfile) # 返回文件扩展名os.path.normpath(r&quot;C:\\temp/index.html&quot;) # 调整路径为当前平台标准，尤其是分隔符混用时os.path.abspath(&quot;index.html&quot;) # 返回文件的**完整绝对路径名** # 扩展`.`、`..`等语法 os.sep配合字符串.join、.split方法可以实现基本相同 效果 目录、文件操作123456789101112os.mkdir(dirname)os.rename(ori_name, dest_name)os.remove(filename)os.unlink(filename) # unix下文件删除，同`os.remove`os.chmod(filename, previlideges)info = os.stat(filename) # 命名元组表示的文件底层信息 # 可使用`stat`模块处理、解释信息os.listdir(dirpath)os.walk(rootdir, topdown=True/False) # 遍历根目录下的整个目录树 os.listdir 返回值：包含目录中所有条目名称的列表 名称不带目录路径前缀 需要注意的是：文件名同样有编码 若参数为字节串，返回文件名列表也是字节串 参数为字符串，返回文件名列表也是字符串 open函数也可以类似使用字节串确定需要打开的文件 glob.glob，os.walk内部都是通过调用os.listdir 实现，行为相同 glob模块也有遍历目录的能力 os.walk 返回值：返回迭代器 每个元素为(dirname, subdirs, subfile) 参数 topdown：默认True，自顶向下返回 文件描述符、文件锁123456789101112131415descriptor = os.open(path, flags, mode) # 打开文件并返回底层描述符os.read(descriptor, N) # 最多读取N个字节，返回一个字节串os.write(descriptor, string) # 将字节串写入文件os.lseek(descriptor, position, how) # 移动文件游标位置descriptor.flush() # 强制刷出缓冲new_fd = os.dup(fd) # 创建文件描述符副本os.dup2(fd_src, fd_dest) # 将文件描述符`fd_src`复制至`fd_dest` os通过调用文件的描述符来处理文件 基于文件描述符的文件以字节流形式处理 没有字符解码、编码、换行符转换 除了缓冲等额外性能，基于描述符的文件和二进制文件模式 对象类似 文件流对象、工具仅仅是在基于描述符的文件的封装 可以通过.fileno()获得文件流对象对应文件描述符， sys.stdin、sys.stdout、sys.stderr对应文件 描述符是：0、1、2 12os.write(1, b&quot;hello world\\n&quot;)sys.stdout.write(&quot;hello world\\n&quot;) 可以通过os.fdopen把文件描述符封装进文件流对象 123fdfile = os.open(&quot;filename&quot;, (os.O_RDWR|os.O_BINARY))filstream = os.fdopen(fdfile, &quot;r&quot;, encoding=&quot;utf-8&quot;, closefd=False) os.open12345def os.open(path, flags, mode=511, *, dir_fd=None) 参数 mode：需要模式标识符进行二进制操作以得到需要的模式 os.O_RDWR os.O_RDONLY os.O_WRONLY os.O_BINARY os.O_EXCL：唯一访问权，是python在并发、进程 同步情况下锁定文件最便捷的方法 os.O_NONBLOCK：非阻塞访问 其他模式选项参见os模块 返回值：文件描述符 整数代码、句柄，代表操作系统的中文件 退出进程12os._exit(0) # 调用进程立即退出，不输出流缓冲、不运行清理处理器 异常信息trackback模块12345678import traceback, systry: ...except: exc_info = sys.exec_info() print(exec_info[0], exec_info[1]) traceback.print_tb(exec_info[2]) 参数处理getopt模块optparse模块文件、目录stat模块 包含os.stat信息相关常量、函数以便跨平台使用 12345678import statinfo = os.stat(filename)info[stat.ST_MODE] # `stat.ST_MODE`就是字符串 # 只是这样封装易于跨平台stat.S_ISDIR(info.st_mode) # 通过整数`info.st_mode`判断是否是目录 os.path中包含常用部分相同功能函数 glob模块glob.glob123import globdef glob.glob(pathname,*,recursive=False) 参数 pathname：文件名模式 接受shell常用文件名模式语法 ?：单个字符 *：任意字符 []：字符选集 .开头路径不被以上?、*匹配 recursive False：默认 True：**将递归匹配所有子目录、文件 返回值：匹配文件名列表 目录前缀层次同参数 glob.glob是利用glob.fnmatch模块匹配名称模式 struct模块struct模块：用于打包、解压二进制数据的调用 类似于C语言中struct声明，需要指定二进制中数据类型 可以使用任何一种字节序（大、小端）进行组合、分解 12345678910111213141516import structdata = struct.pack(&quot;&gt;i4shf&quot;, 2, &quot;spam&quot;, 3, 1.234) # `&gt;`：高位字节优先，大端 # `i`：整形数据 # `4s`：4字符字符串 # `h`：半整数 # `f`：浮点数file = open(&quot;data.bin&quot;, &quot;wb&quot;)file.write(data) # 二进制写入字节串file.close()file = open(&quot;data.bin&quot;, &quot;rb&quot;)bytes = file.read()values = struct.unpack(&quot;&gt;i4shf&quot;, data) # 需要给出字节串存储格式 shutil模块shutil模块：包含文件操作相关 todo系统、信息locale模块1234import localelocale.getpreferredencoding() # 获取平台默认编码方案 dis模块12def dis.dis(func) # 打印可拆解函数语句对应机器指令 atexit模块atexit：主要用于在程序结束前执行代码 类似于析构，主要做资源清理工作 atexit.register12345def register( func, *arg, **kwargs) 用途：注册回调函数 在程序退出之前，按照注册顺序反向调用已注册回调函数 如果程序非正常crash、通过os._exit()退出，注册回调 函数不会被调用 1234567891011121314import atexitdf func1(): print(&quot;atexit func 1, last out&quot;)def func2(name, age): print(&quot;atexit func 2&quot;)atexit.register(func1)atexit.register(func2, &quot;john&quot;, 20)@atexit.registerdef func3(): print(&quot;atexit func 3, first out&quot;) 实现atexit内部是通过sys.exitfunc实现的 将注册函数放到列表中，当程序退出时按照先进后出方式 调用注册的回调函数， 若回调函数执行过程中抛出异常，atexit捕获异常然后继续 执行之后回调函数，知道所有回调函数执行完毕再抛出异常 二者同时使用，通过atexit.register注册回调函数可能不会 被正常调用 signal模块信号模块","link":"/Python/Cookbook/os_sys.html"},{"title":"Python 脚本","text":"","link":"/Python/Cookbook/scripts.html"},{"title":"Python","text":"contextlibcontextlib.contextmanager 用途：上下文实现装饰器 实现try...finally...语句的生成器上下文管理器语法 try部分：生成器部分，with语句进入时执行 finally部分：清理部分，with语句退出时执行 用法 定义 1234567@contextmanagerdef some_generator(&lt;parameters&gt;): &lt;setup&gt; try: yield &lt;value&gt; finally: &lt;cleanup&gt; 用法 12with some_generator(&lt;argrument&gt;) as &lt;variable&gt;: &lt;body&gt; 等价于 123456&lt;setup&gt;try: &lt;variable&gt; = &lt;value&gt; &lt;body&gt;finally: &lt;cleanup&gt;","link":"/Python/Cookbook/others.html"},{"title":"Python 字符串处理","text":"","link":"/Python/Cookbook/str_text.html"},{"title":"Python 网络","text":"","link":"/Python/Cookbook/web.html"},{"title":"Pywin32 应用模块","text":"win32comwin32com.clientwin32com.client.DispatchWord.Application 创建、打开文档 12345678910# 应用对象：word应用app = win32com.client.Dispatch(&quot;Word.Application&quot;)# 文档对象doc = app.Documents.add()doc = app.Documents.Open(&quot;/path/to/file&quot;)# 窗口对象：文档可以在多个窗口中展示（`View`栏中可找到）（不是打开两次文档）window = app.windows(winNo)window = doc.windows(winNo)# 视图对象：窗口的视图属性（全部显示，域底纹，表格虚框）view = window.view Selection 对象：选区，文档中高亮的选择区域、插入点 每个窗口有自身的 Selection 窗口和相应的 Selection 同时只有一个被激活 12345678910111213141516171819202122# 当前激活窗口的选区s = app.Selection()# 1窗口的选区s1 = app.Windows(1).Selection# 替换选区内容，选区变为输入文本整体s.Text = &quot;Hello, world!&quot;# 输入内容，选区变为文本后插入点s.TypeText(&quot;hello, world!&quot;)# 拷贝选区s.Copy()# 粘贴内容至选区s.Paste()# 变换选区s.Start = 0s.End = 1# 删除s.Delete()# 全选s.WholeStory()# 移动选区：&lt;wdunits&gt;：移动单位：1-字符，s.MoveLeft(&lt;wdunits&gt;, &lt;nums&gt;)s.MoveRight() Range 对象：连续区域，由 &lt;start&gt;、&lt;end&gt; 位置定义 区分文档不同部分 Range 独立于 Selection 可以定义多个 Range 属性、方法类似 Selection 12r = doc.Range(&lt;start&gt;, &lt;end&gt;)r = s.Range() Font 对象：字体属性（名称、字号、颜色等） 1234font = s.Fontfont = r.Fontfont.name = &quot;仿宋&quot;font.size = 16 ParagraphFormat 对象：段落格式（对齐、缩进、行距、边框底纹等） 12345678pf = s.ParagraphFormatpf = r.ParagraphFormat# 对齐方式：0-左对齐，1-居中对齐，2-右对齐pf.Alignment = 0# 行间距：0-单倍，1-1.5倍，2-双倍pf.LineSpacingRule = 0# 左缩进：单位：磅pf.LeftIndent = 21 PageSetup 对象：页面设置（左边距、右边距、纸张大小） 1234567891011121314ps = doc.PageSetupps = s.PageSetupps = r.PageSetup# 上边距：单位：磅（1cm = 28.35磅）cm2pound = 28.35ps.TopMargin = 79# 页面大小：6-A3，7-A4ps.PageSize = 7# 布局模式ps.LayoutMode = 1# 行字符数ps.CharsLine = 28# 行数：自动设计行间距ps.LinesPage = 22 样式集：文档中内置、用户定义的样式 12345styles = doc.Styles# 获取样式：-1-正文，-2-标题1，-3-标题2，-4-标题3，-32-页眉，-63-标题normal = styles(-1)normal.Font.Namenormal.Font.Size = 16 参考资料 宏录制：查看大致方法 Word -&gt; 宏编辑器 -&gt; 对象浏览器：查询各组件方法、属性 ![.NET 文档]https://docs.microsoft.com/zh-cn/dotnet/api/microsoft.office.interop.word：查询语法 https://zhuanlan.zhihu.com/p/67543981","link":"/Python/Pywin32/win32app.html"},{"title":"Pywin32 设备","text":"win32print http://timgolden.me.uk/pywin32-docs/win32print.html https://blog.csdn.net/sdfdsdfdf/article/details/106406291 参数 level：返回信息类型 1：列表，无值含义说明 2-5：内容逐渐省略的字典，键值对表示值含义、值 hPrinter：win32print.OpenPrinter 返回的打印机句柄 hdc：win32gui.CreateDC 返回打印机设备上下文句柄 pPrinter：win32print.GetPrinter 返回的 PRINTER_INFO_* 字典 打印机 win32print.OpenPrinter(printer, Defaults)：获取指定打印机的句柄 win32print.GetPrinter(hPrinter, Level)：获取打印机相关信息 Level：信息展示格式，一般设置为 2 以字典形式返回 win32print.GetDevicesCaps(hdc, Index)：获取设备上下文相关的参数、设置 Index 参数代号，可以通过 win32con. 获取 将打印机句柄作为 hdc 传递时，正常执行但返回结果始终为 0 win32print.SetPrinter(hPrinter, Level, pPrinter, Command)：改变打印机配置、状态 Command：发送给打印机的命令，可以通过 win32print.PRINTER_CONTROL_* 查看 win32print.EnumPrinters(flags, name, level)：枚举打印机 flags：指定打印机类型，可以通过 win32print.PRINTER_ENUM_&lt;type&gt; 获取相关类型枚举值 可设置为 6 以枚举 local、connections 类型设备 win32print.GetDefaultPrinter/win32print.GetDefaultPrinterW win32print.SetDefaultPrinter/win32print.SetDefaultPrinterW 打印机属性设置 打印机属性设置方式 123456// 获取打印相关属性properties = win32print.GetPrinter(hPrinter, 2)devmode = properties[&quot;pDevMode&quot;]// 修改属性设置properties[&quot;pDevMode&quot;] = devmodewin32print.SetPrinter(hPrinter, 2, properties, 0) 打印机属性常用设置 devmode.Color：彩印 可通过 win32con.DMCOLOR_&lt;XXX&gt; 查看枚举值 devmode.PaperSize：纸张尺寸 可以通过 win32con.DMPAPER_&lt;XXXX&gt; 查看枚举值 指定此属性时，devmode.PaperLength、devmode.PaperWidth 不生效 devmode.PaperLength：纸张长，单位毫米 devmode.PaperWidth：纸张宽，单位毫米 devmode.Duplex：单双面（双面分为 flip over 、flip up） 可通过 win32con.DMDUP_&lt;XXXX&gt; 查看枚举值 devmode.Orientation：打印方向，即横向、纵向 可通过 win32con.DMORIENT_&lt;XXXX&gt; 查看枚举值 真实打印时影响不大，打印至 pdf 文件时、双面打印时有影响 devmode.MediaType：纸张类型 devmode.DefaultSource：纸张来源 http://timgolden.me.uk/pywin32-docs/PyDEVMODE.html 打印无 GDI 打印 win32print.StartDocPrinter(hPrinter, level, tuple)：通知打印 spool 将有文件加入 hPrinter：wi32print.OpenPrinter 返回的打印机句柄 level：文档信息结构，此处仅支持 1 （元组） tuple：按 level 指定格式设置的文档信息 docName：文档名 outputFile：输出文件名 dataType：文档数据类型 win32print.EndDocPrinter(hPrinter)：结束打印机的打印任务 在 win32print.WriterPrinter 调用后使用 win32printer.AbortPrinter(hPrinter)：删除打印机的 spool 文件 win32print.StartPagePrinter(hPrinter)：通知打印 spool 一页将被打印 win32print.EndPagePrinter(hPrinter)：结束打印 job 中的一页 win32print.WritePrinter(hPrinter, buf)：将 buf 复制到打印机 适合复制 raw Postscripts、HPGL 文件 GDI 打印 win32print.StartDoc(hdc, docinfo)：在打印机设备上下文上开始 spooling 打印任务 hdc：win32gui.CreateDC 返回的设备上下文句柄 docinfo：指定打印任务参数，四元组 DocName：文档名 Output：输出文件名，仅在输出至文件时需要，正常打印时可设置为 None DataType：数据类型，如：RAW、EMF、TEXT，None` 使用默认 Type：操作模式，可选值 DI_APPBANDING、DI_ROPS_READ_DESTINATION、0 win32print.EndDoc(hdc, docinfo)：在打印机设备上下文上结束 spooling 打印任务 win32print.AbortDoc(hdc)：取消打印 job win32print.StartPage(hdc)：在打印机设备上下文上开始一页 win32print.EndPage(hdc)：在打印机设备上下文上结束一页 打印任务 win32print.EnumJobs(hPrinter, FirstJob, NoJobs, Level)：枚举打印机上的打印 job win32print.GetJob(hPrinter, JobID, Level)：获取打印 job 的信息 win32print.SetJob(hPrinter, JobID, Level, JobInfo, Command)：暂停、取消、恢复、设置优先级 Command：指定设置的内容，可以通过查询 win32print.JOB_CONTROL_&lt;XXXX&gt; 查看枚举值 打印示例图片打印 直接使用 win32gui.CreateDC 12345678910111213# 创建打印机上下文hdc = win32gui.CreateDC(&quot;WINSPOOL&quot;, printer_name, None)# 打开图像文件，并创建位图bmp = Image.Open(filename)dib = ImageWin.Dib(bmp)# 在上下文上打开文件、文件页win32print.StartDoc(hdc, 1, (&quot;&quot;, None, None, 0))win32print.StartPage(hdc)# 绘制位图dib.draw(hdc, (x1, y1, x2, y2))win32print.EndPage(hdc)win32print.EndDoc(hdc)win32gui.DeleteDC(hdc) 使用 win32ui.CreateDC 12345678910111213# 创建未初始化设备上下文hdc = win32ui.CreateDC()# 初始化上下文hdc.CreatePrinterDC(printer_name)hdc.StartDoc(filename)hdc.StartPage()bmp = Image.Open(filename)dib = ImageWin.Dib(bmp)# 获取句柄，并绘制dib.draw(hdc.GetHandleOutput(), (x1, y1, x2, y2))hdc.EndPage()hdc.EndDoc()hdc.DeleteDC() 结合 win32gui.CreateDC、win32ui.CreateDC 1234# 可以设置 `PDEVMODE`g_hdc = win32gui.CreateDC(&quot;WINSPOOL&quot;, printer_name, dev_mode)hdc = win32gui.CreateDCFromHandle(g_hdc)# 之后同上 可通过 GetDeviceCaps 方法、函数获取设备上下文属性，用于确定、设置打印位置、方向等 https://stackoverflow.com/questions/54522120/python3-print-landscape-image-file-with-specified-printer https://www.cnblogs.com/onsunsl/p/python_call_win32print_print_unicode.html","link":"/Python/Pywin32/win32device.html"},{"title":"Pywin32 接口","text":"说明 http://timgolden.me.uk/pywin32-docs/win32_modules.html pywin32 包是对 windows 提供接口的封装，和 C/CPP 接口内容相近 win32apiShell win32api.ShellExecute(hwnd, op, file, params, dir, bShow) hwnd：父窗口句柄 op：操作，&quot;open&quot;、&quot;print&quot; file：需要执行操作的文件 params：待执行操作的文件为可执行文件时，需要传递的参数 dir：应用执行的初始文件夹 bShow：应用打开时是否展示 Keyboard win32api.keybd_event(bVk, bScan, dwFlags, dwExtraInfo) ) bVk：虚拟键码，可通过 win32con.VK_&lt;KEY&gt; 获取 bScan：硬件扫描码，一般设置为 0 dwFlags：一般设置为 0，表示按键按下 win32con.KEYEVENTF_EXTENDEDKEY win32con.KEYEVENTF_KEYUP：按键释放 dwExtraInfo：与击键相关的附加的32位值，一般设置为 0","link":"/Python/Pywin32/win32api.html"},{"title":"Pywin32 图形化模块","text":"win32gui win32gui 提供对原生 win32 GUI API 的接口 Device Context win32gui.CreateDC(Driver, Device, InitData)：为打印机、显示器创建设备上下文 Driver：显示器、打印机供应商名称 Device：设备名，如打印机名称 InitData：PyDEVMODE 指定打印参数 win32gui.CreateCompatibleDC(hdc)：创建兼容指定设备的内存设备上下文 hdc：上下文句柄 win32gui.SetMapMode(hdc, MapMode)：设置逻辑（页空间）单位至设备（空间）单位的映射方式 MapMode：映射方式，可通过 win32con.MM_&lt;XXXX&gt; 查看枚举值 win32gui.SetViewportExtEx(hdc,XExtent,YExtent)：设置 DC 可视区域的 extent XExtent/YExtent：X/Y 方向逻辑长度 win32gui.SetWindowExtEx(hdc,XExtent,YExtent)：设置 DC 窗口的长度 win32gui.SetWindowOrg(hdc,X,Y)：设置 DC 可视区域起始位置 X/Y：X/Y 方向的逻辑坐标 设置逻辑长度即将 DC 的可视区域空间进行线性变换（映射），而避免对需展示信息进行线性变换 viewport 是整个可视区域，window 是可是区域中用于展示信息的部分，windowOrg 则是 window 在信息中的偏移 窗口 win32gui.EnumWindows(callback, ctx)：遍历所有窗口 123456def winEnumHandler(hwnd, ctx): if win32gui.IsWindow(hwnd) and win32gui.IsWindowsEnabled(hwnd) and wind32gui.IsWindowVisible(hwnd): print(hwnd, win32gui.GetWindowText(hwnd)) ctx.append(hwnd)hwnd_list = []win32gui.EnumWindows(winEnumHandler, hwnd_list) win32gui.EnumChildWindows(parent_hwnd, callback, ctx)：遍历窗口的子窗口 win32gui.ShowWindow(hwnd, status)：根据status设置窗口状态 |常量|大小|显示状态|激活状态| |——-|——-|——-|——-| |win32con.SW_HIDE|不变|隐藏|不变| |win32con.SW_MAXSIZE|最大化|不变|不变| |win32con.SW_MINISIZE|最小化|不变|不变| |win32con.SW_RESTORE|恢复正常|不变|不变| |win32con.SW_SHOW|不变|显示|激活| |win32con.SW_SHOWMAXIMIZED|最大化|显示|激活| |win32con.SW_SHOWMINIMIZED|最小化|显示|激活| |win32con.SW_SHOWNORMAL|恢复正常|显示|激活| |win32con.SW_SHOWMINNOACTIVE|最小化|显示|不变| |win32con.SW_SHOWNA|不变|显示|不变| |win32con.SW_SHOWNOACTIVE|恢复正常|显示|不变| win32gui.SetForegroundWindow(hwnd)： win32ui win32ui、win32gui 差别 win32gui 是对微软底层接口的直接封装 win32ui 则是对 win32gui Device Context win32ui.CreateDC()：创建未初始化的设备上下文 win32ui.CreateDCFromHandle(handle)：从句柄中创建上下文 https://newcenturycomputers.net/projects/pythonicwindowsprinting.html","link":"/Python/Pywin32/win32gui.html"},{"title":"Python并行","text":"threding_thread_dummy_threaddummy_threadingmultiprocessingconcurrentconcurrent.futuressubprocessschedqueue","link":"/Python/Py3std/concurrent_exec.html"},{"title":"Python标准库","text":"综述 内置类型相关参见cs_python/py3ref/dm_basics 常用参数说明Functional Programming key=None/callable 含义：key函数，接受一个参数，返回用于排序的值 默认：None，不处理 iterable=iterable 含义：可迭代对象","link":"/Python/Py3std/README.html"},{"title":"数据持久化","text":"DBMDBM文件：python库中数据库管理的标准工具之一 实现了数据的随机访问 可以使用键访问存储的文本字符串 DBM文件有多个实现 python标准库中dbm/dbm.py 使用 使用DBM文件和使用内存字典类型非常相似 支持通过键抓取、测试、删除对象 pickle 将内存中的python对象转换为序列化的字节流，可以写入任何 输出流中 根据序列化的字节流重新构建原来内存中的对象 感觉上比较像XML的表示方式，但是是python专用 1234567import pickledbfile = open(&quot;people.pkl&quot;, &quot;wb&quot;)pickle.dump(db, dbfile)dbfile.close()dbfile = open(&quot;people.pkl&quot;, &quot;rb&quot;)db = pickle.load(dbfile)dbfile.close() 不支持pickle序列化的数据类型 套接字 shelves 就像能必须打开着的、存储持久化对象的词典 自动处理内容、文件之间的映射 在程序退出时进行持久化，自动分隔存储记录，只获取、 更新被访问、修改的记录 使用像一堆只存储一条记录的pickle文件 会自动在当前目录下创建许多文件 123456import shelvesdb = shelves.open(&quot;people-shelves&quot;, writeback=True) // `writeback`：载入所有数据进内存缓存，关闭时再写回， // 能避免手动写回，但会消耗内存，关闭变慢db[&quot;bob&quot;] = &quot;Bob&quot;db.close() copyregmarshalsqlite3","link":"/Python/Py3std/data_persistence.html"},{"title":"Python数据类型","text":"collectionsarrayheadqbisectweakrefdatetimecalendertypescopypprintreprlibenum","link":"/Python/Py3std/data_types.html"},{"title":"二进制数据服务","text":"structstruct模块：用于打包、拆包Cstruct格式二进制数据 使用python字节串存储Cstruct数据 需要给出格式声明，指定二进制中存储格式 格式说明字节序、对齐 格式符 字节序（大、小端） 类型大小 字段对齐方式 @（缺省值） 原生字节序 原生大小 原生对齐 = 原生字节序 标准大小 标准对齐 &lt; lb-endian 标准大小 标准对齐 &gt; bl-endian 标准大小 标准对齐 ! 同&gt; 原生对齐：C对齐方式，字段起始位置须为其长度整数倍 标准对齐：按字节对齐，无需使用0补齐 类型 Format C Type Python Bytes x pad byte no value 1 ? _Bool bool 1 h short integer 2 H unsigned short integer 2 i int integer 4 I unsigned int integer 4 l long integer 4 L unsigned long long 4 q long long long 8 Q unsigned long long long 8 f float float 4 d double float 4 c char str of length1 1 b signed char bytes of length1 1 B unsigned char bytes of length1 1 s char[] str 1 p pascal string，带长度 str NA n ssize_t integer NA N size_t integer NA P void * 足够容纳指针的整形 NA 在类型符前添加数字可以指定类型重复次数 字符、字符串类型实参须以字节串形式给出 字符：必须以长度为1字节串形式给出，重复须对应多参数 字符串：可以是任意长度字节串，重复对应单个字符串 长于格式指定长度被截断 短于格式指定长度用\\0x00补齐 python按以上长度封装各类型，但C各类型长度取决于平台， 以上近视64位机器最可能对应C类型 非64位机器long long类型大部分为4bytes 用途 封装、解压数据 reinterpret_cast类型转换 Struct123class Struct: def __init__(self, fmt): pass 用途：根据指定格式fmt编译Sturct对象 Sturct对象可以调用以下方法，无需再次指定fmt Pack1234def struct.pack(fmt, v1, v2,...) -&gt; bytes: passdef struct.pack_into(fmt, buffer, offset , v1, v2, ...): pass pack：按照指定格式fmt封装数据为字节串 pack_into：将字节串写入buffer指定偏移offset处 Unpack123456def struct.unpack(fmt, buffer) -&gt; (v1, v2,...): passdef struct.unpack(fmt, buffer, offset=0) -&gt; (v1, v2, ...): passdef struct.iter_unpack(fmt, buffer) -&gt; iterator(v1, v2,...): pass unpack：按照指定格式fmt拆包字节串buffer unpack_from：从偏移offset处开始拆包 iter_unpack：迭代解压包含多个fmt的buffer calsize12def struct.calsize(fmt) -&gt; integer: pass 用途：计算封装指定格式fmt所需字节数 codecs","link":"/Python/Py3std/binary_data.html"},{"title":"内置异常","text":"基类具体警告警告异常层次服务","link":"/Python/Py3std/builtin_exceptions.html"},{"title":"文件、目录访问","text":"pathlibos.path判断存在12345os.path.isdir(r&quot;C:\\Users&quot;)os.path.isfile(r&quot;C:\\Users&quot;) # 判断路径名是简单文件、目录os.path.exists(r&quot;C:\\Users&quot;) # 判断路径名是否存在 os.stat配合stat模块有更丰富的功能 路径操作123456789101112131415161718pfile = os.path.join(r&quot;C:\\temp&quot;, &quot;output.txt&quot;) # 连接文件名、目录os.path.split(pfile) # 分离文件名、目录os.path.dirname(pfile) # 返回路径中目录os.path.basename(pfile) # 返回路径中os.path.splitext(pfile) # 返回文件扩展名os.path.normpath(r&quot;C:\\temp/index.html&quot;) # 调整路径为当前平台标准，尤其是分隔符混用时os.path.abspath(&quot;index.html&quot;) # 返回文件的**完整绝对路径名** # 扩展`.`、`..`等语法 os.sep配合字符串.join、.split方法可以实现基本相同 效果 fileinputstatstat：包含os.stat信息相关常量、函数以便跨平台使用 12345678import statinfo = os.stat(filename)info[stat.ST_MODE] # `stat.ST_MODE`就是字符串 # 只是这样封装易于跨平台stat.S_ISDIR(info.st_mode) # 通过整数`info.st_mode`判断是否是目录 os.path中包含常用部分相同功能函数 globglob.glob123import globdef glob.glob(pathname,*,recursive=False) 参数 pathname：文件名模式 接受shell常用文件名模式语法 ?：单个字符 *：任意字符 []：字符选集 .开头路径不被以上?、*匹配 recursive False：默认 True：**将递归匹配所有子目录、文件 返回值：匹配文件名列表 目录前缀层次同参数 glob.glob是利用glob.fnmatch模块匹配名称模式 shutilshutil模块：包含文件操作相关 fnmatchlinecachemacpathfilecmptempfile","link":"/Python/Py3std/file_dir_access.html"},{"title":"国际化","text":"locale1234import localelocale.getpreferredencoding() # 获取平台默认编码方案 gettext","link":"/Python/Py3std/i18n.html"},{"title":"通用操作系统服务","text":"osos：与Python所在底层操作系统相对应变量、函数 os模块提供了POSIX工具 操作系统调用的跨平台移至标准 不依赖平台的目录处理工具 os.path 包含在C程序、shell脚本中经常用到的所有操作系统调用，涉及 目录、进程、shell变量 实践中，os基本可以作为计算机系统调用的可移植接口 使用 只要技术上可行，os模块都能跨平台 但在某些平台，os提供专属该平台的工具 Shell变量12345os.environ # 获取、设置shell环境变量，类似字典os.putenv() # 修改进程对应shell环境变量os.getenv() os.environos.environ可以向普通字典一样键索引、赋值 默认继承系统所有环境变量、命令行临时环境变量 在最新的python中，对os.environ的键值修改将自动导出 到应用的其他部分 os.environ对象 进程对应shell环境变量：通过后台调用os.putenv生效， 反之不会更新os.environ python进程、链入C模块、该进程派生子进程都可以获取新的 赋值 子进程一般会继承父进程的环境变量设定 可以作为传递信息的方式 os.putenv os.putenv同时会调用C库中的putenv（若在系统中可用） 导出设置到python链接的C库 底层C库没有putenv则可将os.environ作为参数传递 管理工具123456os.getpid() # 调用函数的进程idos.getcwd() # 当前工作目录CWDos.chdir(r&quot;C:\\Users&quot;) # 更改当前工作目录CWD 移植工具123456789101112131415os.sep # python底层运行平台采用的**目录组**分隔符号 # linux: `/`、win：`\\`、某些mac：`:`os.pathsep # 目录列表（字符串形式）中分隔目录的字符 # posix机：`:`、win：`;`os.curdir # 当前目录代表 # linux：`.`os.pardir # 父目录代表 # linux：`..`os.linesep # 换行符 # linux：`\\n` ||Linux|Win|Unix| |———|——————|———|———| |sep|/|\\|/（某些MAC:）| |pathsep|:|;|| |curdir|.||| |pardir|..||| |linesep|\\n|\\r\\n|| 借助这些变量可以系统相关字符串操作的跨平台 win下目录组分隔符是\\，大部分情况下看到\\\\是作为\\ 转义字符，防止\\和之后字符转义 确认不会转义时，直接使用\\也是可以的 使用r''表示不转义也可以直接使用\\ 目录、文件操作123456789101112os.mkdir(dirname)os.rename(ori_name, dest_name)os.remove(filename)os.unlink(filename) # unix下文件删除，同`os.remove`os.chmod(filename, previlideges)info = os.stat(filename) # 命名元组表示的文件底层信息 # 可使用`stat`模块处理、解释信息os.listdir(dirpath)os.walk(rootdir, topdown=True/False) # 遍历根目录下的整个目录树 os.listdir 返回值：包含目录中所有条目名称的列表 名称不带目录路径前缀 需要注意的是：文件名同样有编码 若参数为字节串，返回文件名列表也是字节串 参数为字符串，返回文件名列表也是字符串 open函数也可以类似使用字节串确定需要打开的文件 glob.glob，os.walk内部都是通过调用os.listdir 实现，行为相同 glob模块也有遍历目录的能力 os.walk 返回值：返回迭代器 每个元素为(dirname, subdirs, subfile) 参数 topdown：默认True，自顶向下返回 文件描述符、文件锁123456789101112131415descriptor = os.open(path, flags, mode) # 打开文件并返回底层描述符os.read(descriptor, N) # 最多读取N个字节，返回一个字节串os.write(descriptor, string) # 将字节串写入文件os.lseek(descriptor, position, how) # 移动文件游标位置descriptor.flush() # 强制刷出缓冲new_fd = os.dup(fd) # 创建文件描述符副本os.dup2(fd_src, fd_dest) # 将文件描述符`fd_src`复制至`fd_dest` os通过调用文件的描述符来处理文件 基于文件描述符的文件以字节流形式处理 没有字符解码、编码、换行符转换 除了缓冲等额外性能，基于描述符的文件和二进制文件模式 对象类似 文件流对象、工具仅仅是在基于描述符的文件的封装 可以通过.fileno()获得文件流对象对应文件描述符， sys.stdin、sys.stdout、sys.stderr对应文件 描述符是：0、1、2 12os.write(1, b&quot;hello world\\n&quot;)sys.stdout.write(&quot;hello world\\n&quot;) 可以通过os.fdopen把文件描述符封装进文件流对象 123fdfile = os.open(&quot;filename&quot;, (os.O_RDWR|os.O_BINARY))filstream = os.fdopen(fdfile, &quot;r&quot;, encoding=&quot;utf-8&quot;, closefd=False) os.open12345def os.open(path, flags, mode=511, *, dir_fd=None) 参数 mode：需要模式标识符进行二进制操作以得到需要的模式 os.O_RDWR os.O_RDONLY os.O_WRONLY os.O_BINARY os.O_EXCL：唯一访问权，是python在并发、进程 同步情况下锁定文件最便捷的方法 os.O_NONBLOCK：非阻塞访问 其他模式选项参见os模块 返回值：文件描述符 整数代码、句柄，代表操作系统的中文件 退出进程12os._exit(0) # 调用进程立即退出，不输出流缓冲、不运行清理处理器 iotimeargparseargparse：编写用户友好的命令行接口 https://docs.python.org/zh-cn/3/library/argparse.html argparse.ArgumentParser12345678910111213141516171819202122232425262728293031323334class argparse.ArgumentParser: def __init__(self, prog=None, # 程序名，可用`$(prog)s`引用 usage=None, # 用法字符串 description=None, # 程序描述 epilog=None, # 程序尾描述 parents=[], # 父解析器，共用当前参数 formatter_class=argparse.HelpFormatter, prefix_chars=&quot;-&quot;/str, # 参数前缀（可包含多个可选） fromfile_prefix_chars=None, # 指定其后参数为存储参数文件名 argument_default=None, conflict_handler=&quot;error&quot;/&quot;resolve&quot; # 默认不允许相同选项字符串 # 有不同行为，可设置为 # &quot;resolve&quot;表示允许覆盖 add_help=True, # 符解释器中应禁止 allow_abbrev=True, # 允许前缀匹配（若不存在重复前缀） ): pass # 打印、输出信息至标准输出 def print_usage(self, file=None/IO) -&gt; None: pass def print_help(self, file=None/IO) -&gt; None: pass def format_usage(self) -&gt; str: pass def format_help(self) -&gt; str: pass # 退出 def exit(self, exit=0, message=None): pass def error(self, message): pass 添加参数12345678910111213141516171819202122232425262728293031323334353637383940414243 # 添加参数def add_argument(self, ?*name_or_flag=*[str], # 选项名（无前缀表示位置参数） action=&quot;store&quot;/&quot;store_const&quot;/ # 参数动作 &quot;store_true&quot;/&quot;store_false&quot;/ &quot;append&quot;/&quot;append_const&quot;/ &quot;count&quot;/&quot;help&quot;/&quot;version&quot;, nargs=None/int/&quot;?&quot;/&quot;*&quot;/&quot;+&quot; const=None, # `action`、`nargs`所需常数 default=None, # 未指定参数默认值 type=str/type, # 参数被转换类型、内建函数 choices=None, # 参数类型 required=None, # 选项候选集 help=None, # 选项描述 metavar=None, # 参数值示例 dest=None, # `parse_args()`返回的参数属性名): pass # 添加参数组，参数选项将可以注册至此def add_argument_group(self, title=None, description=None) -&gt; argparse._ArgumentGroup: pass # 添加互斥参数组，互斥组内仅有一个参数可用def add_mutally_exclusive_group(self, rquired=False # 互斥组中至少有一个参数) -&gt; argparse._MutaullyExclusiveGroup: pass # 设置默认值，优先级高于选项中默认值def set_defaults(self, **kwargs: {参数属性名: 默认值}): pass # 获取默认值def get_default(self, **kwargs: {参数属性名: 默认值}): pass 参数 action：关联命令行参数、动作，除以下预定义行为， 还可以传递argparse.Action子类、相同接口类 store：存储值，默认行为 store_const：存储const指定值，通常用于在 选项中指定标志 store_true/&quot;store_false&quot;：类上 append：存储列表，适合多次使用选项 append_const：将const参数值追加至列表， 适合多个选项需要在同一列表中存储常数 （即多个dest参数相同） count：计算选项出现次数 help：打印完整帮助信息 version：打印version参数值 - `nargs`：参数消耗数目，指定后`pare_args`返回列表， 否则参数消耗由`action`决定 - `int`：消耗参数数目，`nargs=1`产生单元素列表， 和默认不同 - `?/*/+`：类似普通正则，`+`会在没有至少一个参数时 报错 - `argparse.REMAINDER`：所有剩余参数，适合用于从 命令行传递参数至另一命令行 - `const`：保存不从命令行读取、被各种动作需求的常数 - `action=&quot;store_const&quot;/&quot;append_const&quot;`：必须给出 - `nargs=?`：气候选项没有参数时，使用`const`替代 - `type`：允许任何类型检查、类型转换，一般内建类型、 函数可以直接使用 - `argparse.FiltType(&quot;w&quot;)`：为文件读写方便，预定义 类型转换 - `dest`：`parse_args()`返回的参数属性名 - 位置选项：缺省为首个选项名 - 关键字选项：优秀首个`--`开头长选项名，选项目中间 `-`被替换为`_` 参数解析12345678910111213141516171819202122232425 # 解析参数，无法解析则报错def parse_args(self, args=None/list, # 需要解析参数列表，默认`sys.argv` namespace=None # 存放属性的`Namespace`对象，缺省创建新空对象) -&gt; argparse.Namespace: pass # 解析部分参数，无法解析则返回def parse_known_args(self, args=None/list, namespace=None) -&gt; (argparse.Namespace, [ ]): pass # 允许混合位置参数、关键字参数def parse_intermixed_args(self, args=None, namespace=None) -&gt; argparse.Namespace: passdef parse_known_intermixed_args(self, args=None, namespace=None) -&gt; argparse.Namespace: pass 说明 仅不包含类似负数的选项名，参数才会被尝试解释为负数 位置参数 前缀无歧义时，可以前缀匹配 添加子命令12345678910111213def add_subparsers(self, title, description, prog, parser_class, action, option_string, dest, required, help, metavar): pass 辅助类动作类123456class argparse.Action: def __init__(self, option_string, dest, nargs=None, **kwargs): pass def __call__(self, parser, namespace, values, option_string=None): pass 格式化类1234567class argparse.ArgumentDefaultHelpFormatter # 认为两程序描述已被正确格式化，保留原样输出class argparse.RawDescriptionHelpFormatter # 保留所有种类文字的空格，包括参数描述class argparse.RawTextHelpFormatter # 为每个参数使用`type`参数名作为其显示名，而不是`dest`class argparse.MetavarTypeHelpFormatter 其他类123456789101112 # 容纳属性的类class argparse.Namespace: pass # IO接口简化类class argparse.FileType: def __init__(self, mode=&quot;r&quot;/&quot;w&quot;, bufsize=-1, encoding=None, errors=None ): pass getoptoptparselogginglogging.configlogging.handlersgetpasscursescurses.textpadcurses.asciicurses.panelplatformerrnoctypes","link":"/Python/Py3std/generic_os.html"},{"title":"互联网数据","text":"emailjson json 模块一般只能序列化 list、dict，及其衍生类型 py37 前 dict 序列化不保证顺序，除非显式使用 collections.OrderedDict mailcapmailboxmimetypesbase64binhexbinasciiquopriuu","link":"/Python/Py3std/internet_data.html"},{"title":"文件打包","text":"zlibgzipbz2lzmazipfiletarfile","link":"/Python/Py3std/file_formats.html"},{"title":"数字、数学","text":"numbersmathcmathdecimalfractionsrandomstatics","link":"/Python/Py3std/numeric_math.html"},{"title":"网络、进程间通信","text":"asyncio协程与任务 https://docs.python.org/zh-cn/3.10/library/asyncio-task.html 协程包含两层概念 协程函数：定义形式为async def的函数 协程对象：调用协程函数返回的对象 可等待对象：可在await语句种使用的对象 协程对象 asyncio.Future：异步调用结果的占位符 以便通过async/await使用基于回调的代码 通过情况下无需在应用层级代码中显式创建Future 对象 asyncio.Task：Future子类，包装coroutine的future 运行协程（对象）的三种方式 await阻塞式等待协程执行完毕 只能在async def函数中使用 await同样是在事件循环中阻塞执行 将协程对象包装为可并发运行的asyncio.Task，并在事件 循环中并发执行 asyncio.create_task asyncio.run()创建、管理事件循环的高层API 启动事件循环执行是真正运行协程对象的开始 asyncio.run1def asyncio.run(coro, *, debug=False); 功能：创建新的事件循环并在结束时关闭 执行传入的协程，并返回结果 管理asyncio事件循环、终结异步生成器、关闭线程池 应当被用作asyncio程序的主入口点，理想情况下只被调用一次 同一线程中只能有一个asyncio事件循环运行，若同线程中有 其他事件循环运行，此函数不能被调用 Task1234567891011121314151617class asyncio.Task(Future): def __init__(coro,*,loop=None,name=None); # 1、此方法仅在下轮事件循环中`raise asyncio.CancelledError` # 给被封包协程，协程自行选择是否取消 # 2、协程等待的`Future`对象同样会被取消 def cancel(msg=None); bool cancelled(); bool done(); def result(); def exception(); def add_done_callback(callback, *, context=None); def remove_done_callback(callback); def get_stack(*, limit=None); def print_stack(*, limit=None, file=None); def get_coro(); def get_name(); def set_name(value); Task：用于在事件循环中运行协程，非线程安全 若协程在等待Future对象，Task对象会挂起该协程执行 并等待该Future对象完成再执行 事件循环使用协同日程调度，事件循环每次运行一个Task 对象，Task对象会等待Future对象完成，事件循环会 运行其他Task、回调、执行IO操作 不建议手动实例化Task对象，可以使用高层级的 asyncio.create_task()，或低层级的 loop.create_task()、ensure_future()创建 asyncio.Task从Future继承了除Future.set_result()、 Future.set_exception()外的所有API create_task1def asyncio.create_task(coro, *, name=None); 功能：将协程打包为task，排入日程准备执行 任务会在get_running_loop()返回的循环中执行 若线程中没有在运行的循环则引发RuntimeError python3.7加入，之前版本可以使用asyncio.ensure_future() gather1awaitable asyncio.gather(*aws, return_exception=False) 功能：并发运行aws序列中的可等待对象 若aws中的某个可等待对象为协程对象，则会自动作为 任务加入日程 若所有等待对象都成功完成，结果将是所有返回值列表， 结果顺序同aws中对象顺序 若gather被取消，被提交的可等待对象也被取消 若aws中task、future被取消，将被当作引发 CancelledError处理，gather也不会被取消 参数说明 return_exception False：首个异常被传播给等待gather()的任务 True：异常和成功结果一样处理并被聚合至结果列表 shield1awaitable asyncio.shield(aw); 功能：保护可等待对象防止其被取消 若aw是协程，则将自动作为任务加入日程 包含shield的协程被取消，aw中的任务不会被取消， 但若aw的调用者被取消，await表达式仍然会 raise CancelledError 若通过其他方式取消aw，则shield也会被取消 希望完全忽略取消操作则需要配合try/except 1234try: res = await shield(aw)except CancelledError: res = None 其他 Task内省 1234 # 返回当前运行Task实例，没有则返回`None`Task = asyncio.current_task(loop=None) # 返回`loop`事件循环未完成Task对象Set(Task) = asyncio.current_task(loop=None) Sleep 1coroutine asyncio.sleep(delay, result=None, *, loop=None) 等待超时wait_for1coroutine asyncio.wait_for(aw, timeout); 功能：等待aw可等待对象完成 发生超时则取消任务并raise asyncio.TimeoutError 函数会等待直到aw实际被取消，则总等待时间可能会超过 timeout 可以通过shield避免任务被取消 若等待被取消，则aw也被取消 wait12(done, pending) asyncio.wait(aws, *, timeout=None, return_when=ALL_COMPELTED); 功能：并发运行aws并阻塞线程直到满足return_when指定 的条件 超时不会raise asyncio.TimeoutError，而会在返回未 完成的Future、Task 参数 return_when FIRST_COMPLETED：任意可等待对象结束、取消时 返回 ALL_COMPLETED：所有可等待对象结束、取消时返回 FIRST_EXCEPTION：任意可等待对象引发异常结束时 返回，否则同ALL_COMPLETED as_completed1iterator asyncio.as_completed(aws, timeout=None); 功能：并发运行aws中可等待对象，返回协程迭代器，返回的 每个协程可被等待以从剩余可等待对象集合中获得最早下个结果 超时则raise asyncio.TimeoutError 12for coro in asyncio.as_completed(aws): earliest_result = await coro 其他线程中执行to_thread1coroutine asyncio.to_thread(func, *args, **kwargs); 功能：在不同线程中异步运行函数func args、kwargs会被直接传给func 当前contextvars.Context被传播，允许在不同线程中 访问来自事件循环的上下文变量 主要用于执行可能会阻塞事件循环的函数 对于CPython实现，由于GIL存在，此函数一般只能将 IO密集型函数变为非阻塞 对于会释放GIL的扩展模块、无此限制的替代性python 实现，此函数也可以被用于CPU密集型函数 run_coroutine_threadsafe1concurrent.futures.Future asyncio.run_coroutine_threadsafe(coro, loop) 功能：向事件循环loop提交协程coro 线程安全 此函数应该从另一个系统线程中调用 socketsslselectselectorsasyncoreasynchatsignalmmap","link":"/Python/Py3std/interproc_com.html"},{"title":"Funtioncal Programming Tools","text":"builtins filter(iterable, func)：过滤func返回布尔否值元素 enumerate(iterable)：添加索引迭代 zip(*iterables)：打包迭代元素 map(func, *iterables)：func接受各迭代器中元素作为 参数调用（类似zip） iter：两种产生迭代器的模式 iter(iterable)：返回迭代器 iter(callable, sentinel)：调用callable直到返回 sentinel停止迭代（不包括） 可用于替代while循环 itertoolsitertools：包含为高效循环而创建迭代器的函数 参考https://docs.python.org/zh-cn/3/library/itertools.html 无穷迭代器 count(start, step=1)：步长累加 cycle(p)：循环p中元素 repeat(elem, n=None)：重复elem 迭代元素处理 accumulate(p, func=None)：累加p中元素 chain(*iters)：链接迭代器 chain.from_iterable(iterable)：链接可迭代对象中迭代器 compress(data, selelctors)：根据selectors选取data dropwhile(pred, seq)：保留首个满足pred之后所有元素 takewhile(pred, seq)：保留首个不满足pred之前元素 filterfalse(pred, seq)：反filter groupby(iterable, key=None)：根据key(v)值分组迭代器 islice(seq, start=0, stop=None, step=1)：切片 starmap(func, seq)：迭代对seq中执行func(*elem) tee(iterable, n=2)：复制迭代器，默认2个 zip_longes(*iters, fillvalue)：依最长迭代器zip，较短 循环填充或fillvalue填充 排列组合 product(*iters, repeat=1)：笛卡尔积 permutations(p, r=None)：r长度的排列，缺省全排列 combinations(p, r)：r长度组合 combinations_with_replacement(p,r)：可重复组合 functoolsfunctools：包含高阶函数，即参数、返回值为其他函数的函数 参见https://docs.python.org/zh-cn/3/library/functools.html 函数转换 cmp_to_key(func)：将旧式比较函数转换新式key function 常用在以下函数key参数中转换旧式比较函数 sorted min max heapq.nlargest heapq.nsmallest itertools.groupby key function：接收参数，返回可以用于排序的值 partial(func, *args, **kwargs)：返回partial对象，其 调用时类似使用args、kwargs调用func partial.method(func, *args, **kwargs)：适合类命名空间 中函数、描述器 update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, udpated=WRAPPER_UPDATES)： 更新wrapper函数信息为wrapped函数信息 函数应用 reduce(func, iterable[, initializer])：使用func接受 两个参数，reduce处理iterable 函数装饰器 @lru_cache(maxsize=128, typed=False)：缓存函数执行结果 字典存储缓存：函数固定参数、关键字参数必须可哈希 不同参数调用模式（如仅参数顺序不同）可能被视为不同 ，从而产生多个缓存项 可以用于方便实现动态规划 @singledispatch：转换函数为单分派范型函数，实现python 的重载（接口多态） single dispatch：单分派，基于单个参数类型分派的 范型函数分派形式 @wraps(wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES)： 等价于partial(update_wrapper, wrapped, assigned, updated) 类装饰器 @total_ordering：根据类中已定义比较方法实现剩余方法 类必须实现__eq__、其他富比较方法中任意一种 operatoroperator：提供与python内置运算符对应的高效率函数 为向后兼容，保留双下划线版本函数名（同特殊方法名） 比较运算 lt(a,b)/__lt__(a,b) le(a,b) eq(a,b) ne(a,b) ge(a,b) gt(a,b) 逻辑运算 not(obj) truth(obj)：等价于使用bool构造器 is_(a,b) is_not(a,b) 数值运算 add(a,b) sub(a,b) mul(a,b) div(a,b) pow(a,b) mod(a,b) floordiv(a,b) truediv(a,b) matmul(a,b) abs(obj) neg(obj) pos(obj) 在位赋值 在位运算对可变数据类型才会更新参数，否则只返回结果 iadd(a,b)：等价于a += b isub(a,b) imul(a,b) idiv(a,b) ipow(a,b) imod(a,b) ifloordiv(a,b) itruediv(a,b) imatmul(a,b) 位运算 and_(a,b) or_(a,b) xor(a,b) inv(obj)/invert(obj) lshift(a,b) shift(a,b) 在位运算 iand(a,b) ior(a,b) ixor(a,b) 索引 index(a) 序列运算 concat(a,b) contains(a,b) countOf(a,b) delitem(a,b) getitem(a,b) indexOf(a,b) setitem(a,b,c) length_hint(obj, default=0) 访问函数 attrgetter(attr)/attrgetter(*attrs)：返回函数，函数 返回值为参数属性attr itemgetter(item)/itemgetter(*items)：类似 methodcaller(name[, args...])：类似","link":"/Python/Py3std/func_programming.html"},{"title":"Python 运行时服务","text":"syssys：与Python解释器本身相关的组件 平台、版本123456789101112import syssys.platform # 操作系统名称sys.maxsize # 当前计算机最大容纳“原生”整型 # 一般就是字长sys.version # python解释器版本号sys.byteorder # 平台字节序sys.hash_info # 数值类型hash信息 sys.xxxcheckinterval1234sys.getcheckinterval() # 查看解释器检查线程切换、信号处理器等的频率sys.setcheckinterval(N) # 设置解释器检查线程切换、信号处理器等的频率 参数 N：线程切换前执行指令的数量 对大多数程序无需更改此设置，但是可以用于调试线程性能 较大值表示切换频率较低，切换线程开销降低，但是对事件 的应答能力变弱 较小值表示切换频率较高，切换线程开销增加，对事件应答 能力提升 sys.hash_info12sys.hash_info.width # `hash()`函数截取hash值长度 模块搜索路径1sys.path 返回值：目录名称字符串组成的列表 每个目录名称代表正在运行python解释器的运行时模块 搜索路径 可以类似普通列表在运行时被修改、生效 sys.path初始化顺序 脚本主目录指示器：空字符串 脚本主目录是指脚本所在目录，不是os.getcwd() 获取的当前工作目录 PYTHONPATH环境变量 12# .bashrcexport PYTHONPATH=$PYTHONPATH:/path/to/fold/contains/module 标准库目录 .pth路径文件：在扫描以上目录过程中，遇到.pth文件会 将其中路径加入sys.path中 12# extras.pth/path/to/fold/contains/module 导入模块顺序导入模块时，python解释器 搜索内置模块，即内置模块优先级最高 从左至右扫描sys.path列表，在列表目录下搜索模块文件 嵌入解释器的钩子123456sys.modules # 已加载模块字典sys.builtin_module_names # 可执行程序的内置模块sys.getrefcount() # 查看对象引用次数 异常1sys.exc_info() 返回值：(type, value, trackback) 最近异常的类型、值、追踪对象元组 处理该异常的except执行之后，sys.exc_info被恢复 为原始值 追踪对象可以使用traceback模块处理 命令行参数1sys.argv 返回值：命令行参数列表 首项始终为执行脚本名称，交互式python时为空字符串 参数可以自行解析，也可以使用以下标准库中模块 getopt：类似Unix/C同名工具 optparse：功能更加强大 标准流123456sys.stdin # 标准输入流sys.stdout # 标准输出流sys.stderr # 标准错误流 标准流是预先打开的python文件对象 在python启动时自动链接到程序上、绑定至终端 shell会将相应流链接到指定数据源：用户标准输入、文件 重定向 可以将sys.stdin、sys.stdout重置到文件类的对象，实现 python内部的、普遍的重定向方式 外部：cmd输入输出重定向 局部：指定print参数 任何方法上与文件类似的对象都可以充当标准流，与对象类型 无关，只取决于接口 任何提供了类似文件read方法的对象可以指定给 sys.stdin，以从该对象read读取输入 任何提供了类似文件write方法的对象可以指定给 sys.write，将所有标准输出发送至该对象方法上 标准库io提供可以用于重定向的类StringIO、ByteIO 重定向之后print、input方法将应用在重定向之后的流 stdin12345678stdin.read() # 从标准输入流引用对象读取数据input(&quot;input a word&quot;)sys.stdin.readlines()[-1] # 以上两行语句类似stdin.isatty() # 判断stdin是否连接到终端（是否被重定向） 在stdin被重定向时，若需要接受用户终端输入，需要使用 特殊接口从键盘直接读取用户输入 win：msvcrt模块 linux：读取/dev/tty设备文件 退出1sys.exit(N) 用途：当前线程以状态N退出 实际上只是抛出一个内建的SystemExit异常，可以被正常 捕获 等价于显式raise SystemExit 进程退出参见os._exit() sys.exitfuncs1sys.exitfuncs 编码12345sys.getdefaulencoding() # 文件内容编码，平台默认值 # 默认输入解码、输出编码方案sys.getfilesystemencoding() # 文件名编码，平台默认体系 win10中二者都是utf-8，win7中文件名编码是mbcs sysconfigbuiltins__main__warningsdataclassatexitatexit：主要用于在程序结束前执行代码 类似于析构，主要做资源清理工作 atexit.register12345def register( func, *arg, **kwargs) 用途：注册回调函数 在程序退出之前，按照注册顺序反向调用已注册回调函数 如果程序非正常crash、通过os._exit()退出，注册回调 函数不会被调用 1234567891011121314import atexitdf func1(): print(&quot;atexit func 1, last out&quot;)def func2(name, age): print(&quot;atexit func 2&quot;)atexit.register(func1)atexit.register(func2, &quot;john&quot;, 20)@atexit.registerdef func3(): print(&quot;atexit func 3, first out&quot;) 实现atexit内部是通过sys.exitfunc实现的 将注册函数放到列表中，当程序退出时按照先进后出方式 调用注册的回调函数， 若回调函数执行过程中抛出异常，atexit捕获异常然后继续 执行之后回调函数，知道所有回调函数执行完毕再抛出异常 二者同时使用，通过atexit.register注册回调函数可能不会 被正常调用 tracebacktraceback.print_tb12345678import traceback, systry: ...except: exc_info = sys.exec_info() print(exec_info[0], exec_info[1]) traceback.print_tb(exec_info[2]) __future__gcinspectsiteabcABCMeta123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from abc import ABCMeta, abstractmethodclass IStream(metaclass=ABCMeta): @abstractmethod def read(self, maxbytes=-1): pass @abstractmethod def write(self, data): passclass SocketStream(IStream): # 抽象类目的就是让别的类继承并实现特定抽象方法 def read(self, maxbytes=-1): pass def write(self, data): passdef serialize(obj, stream): if not isinstance(stream, IStream): # 抽象基类的主要用途之一：检查某些类是否为特定类型、 # 实现特定接口 raise TypeError(&quot;expect an IStream&quot;) passclass A(metaclass=ABCMeta): @property @abstract def name(self): pass @name.setter @abstractmethod def name(self, value): pass @classmethod @abstractmethod def method1(cls): pass @staticmethod @abstractmethod def method2(): pass # `@abstract`还能注解静态方法、类方法、`@property` # 但是需要保证这个方法**紧靠**函数定义 用途标准库中有很多用到抽象基类的地方 collections模块定义了很多和容器、迭代器（序列、映射、 集合）有关的抽象基类 123456import collections as cltclt.Sequenceclt.Iterableclt.Sizedclt.Mapping numbers库定义了跟数据对象：整数、浮点数、有理数有关的 基类 IO库定义了很多跟IO操作相关的基类","link":"/Python/Py3std/runtime_service.html"},{"title":"Python语言服务","text":"parserastsymtabletokenkeywordtokenizetabnannypyclbrpy_compilecompilealldisdis.dis12def dis.dis(func) # 打印可拆解函数语句对应机器指令 将多条语句包装为函数，方便查看对应指令 pickletools","link":"/Python/Py3std/python_lang.html"},{"title":"文本处理服务","text":"stringredifflibtextwrapunicodedatastringrepreadlinerlcompleter","link":"/Python/Py3std/text_processing.html"},{"title":"TensorFlow Readme","text":"常用参数说明 函数书写声明同Python全局 以下常用参数如不特殊注明，按照此解释 Session target = &quot;&quot;/str 含义：执行引擎 graph = None/tf.Graph 含义：Session中加载的图 默认：缺省为当前默认图 config = None/tf.ConfigProto 含义：包含Session配置的Protocal Buffer 默认：None，默认配置 fetches = tf.OPs/[tf.OPs] 含义：需要获得/计算的OPs值列表 默认：无 feed_dict = None/dict 含义：替换/赋值Graph中feedable OPs的tensor字典 默认：无 说明 键为图中节点名称、值为向其赋的值 可向所有可赋值OPs传递值 常配合tf.placeholder（强制要求） Operators name = None/str 含义：Operations名 默认：None/OP类型，后加上顺序后缀 说明 重名时TF自动加上_[num]后缀 axis = None/0/int 含义：指定张量轴 默认 None：大部分，表示在整个张量上运算 0：有些运算难以推广到整个张量，表示在首轴（维） keepdims=False/True 含义：是否保持维度数目 默认：False不保持 dtype=tf.int32/tf.float32/... 含义：数据类型 默认：根据其他参数、函数名推断 shape/dims=(int)/[int] 含义：各轴维数 默认：None/1??? 说明 -1表示该轴维数由TF计算得到 有些情况下，此参数可省略，由TF隐式计算得到， 但显式指明方便debug start=int 含义：起始位置 默认：0 stop=int 含义：终点位置 默认：一般无 TensorFlow基本概念 TensorFlow将计算的定义、执行分开 流程组合计算图 为输入、标签创建placeholder 创建weigth、bias 指定模型 指定损失函数 创建Opitmizer 在会话中执行图中操作 初始化Variable 运行优化器 使用FileWriter记录log 查看TensorBoard PyTF 模块tf.nntf.nn：神经网络功能支持模块 rnn_cell：构建循环神经网络子模块 tf.contribtf.contrib：包含易于变动、实验性质的功能 bayesflow：包含贝叶斯计算 cloud：云操作 cluster_resolver：集群求解 compiler：控制TF/XLA JIT编译器 copy_graph：在不同计算图之间复制元素 crf：条件随机场 cudnn_rnn：Cudnn层面循环神经网络 data：构造输入数据流水线 decision_trees：决策树相关模块 deprecated：已经、将被替换的summary函数 distributions：统计分布相关操作 estimator：自定义标签、预测的对错度量方式 factorization：聚类、因子分解 ffmpeg：使用FFmpeg处理声音文件 framework：框架类工具，包含变量操作、命令空间、 checkpoint操作 gan：对抗生成相关 graph_editor：计算图操作 grid_rnn：GridRNN相关 image：图像操作 input_pipeline：输入流水线 integrate：求解常微分方程 keras：Keras相关API kernel_methods：核映射相关方法 kfac：KFAC优化器 labeled_tensor：有标签的Tensor layers：类似nn里面的函数，经典CNN方法重构 learn：类似ski-learn的高级API legacy_seq2seq：经典seq2seq模型 linalg：线性代数 linear_optimizer：训练线性模型、线性优化器 lookup：构建快速查找表 losses：loss相关 memory_stats：设备内存使用情况 meta_graph_transform：计算图转换 metrics：各种度量模型表现的方法 nccl：收集结果的操作 ndlstm：ndlstm相关 nn：tf.nn某些方法的其他版本 opt：某些优化器的其他版本 predictor：构建预测器 reduce_slice_ops：切片规约 remote_fused_graph resampler：重抽样 rnn：某些循环神经网络其他版本 saved_model：更加易用的模型保存、继续训练、模型转换 seq2seq：seq2seq相关模型 session_bundle signal：信号处理相关 slim：contrib主模块交互方式、主要入口 solvers：贝叶斯计算 sparsemax：稀疏概率激活函数、相关loss specs staging：分段输入 stat_summarizer：查看运行状态 statless：伪随机数 tensor_forest：可视化工具 testing：单元测试工具 tfprof：查看模型细节工具 timeseries：时间序列工具 tpu：TPU配置 training：训练及输入相关工具 util：Tensors处理相关工具 tf.traintf.train：训练模型支持 优化器 AdadeltaOptimizer：Adadelta优化器 AdamOptimizer：Adam优化器 GradientDescentOptimizer：SGD优化器 MomentumOptimizer：动量优化器 RMSPropOptimizer：RMSProp优化器 数据处理 Coordinator：线程管理器 QueueRunner：管理读写队列线程 NanTensorHook：loss是否为NaN的捕获器 create_global_step：创建global step match_filenames_once：寻找符合规则文件名称 start_queue_runners：启动计算图中所有队列 tfrecord数据 Example：tfrecord生成模板 batch：生成tensor batch shuffle_batch：创建随机tensor batch 模型保存、读取 Saver：保存模型、变量类 NewCheckpointReader：checkpoint文件读取 get_checkpoint_state：从checkpoint文件返回模型状态 init_from_checkpoint：从checkpoint文件初始化变量 latest_checkpoint：寻找最后checkpoint文件 list_variable：返回checkpoint文件变量为列表 load_variable：返回checkpoint文件某个变量值 tf.summarytf.summary：配合tensorboard展示模型信息 FileWriter：文件生成类 Summary get_summary_description：获取计算节点信息 histogram：展示变量分布信息 image：展示图片信息 merge：合并某个summary信息 merge_all：合并所有summary信息至默认计算图 scalar：展示标量值 text：展示文本信息","link":"/Python/TensorFlow/README.html"},{"title":"TensorFlow 安装配置","text":"安装CUDA、CUDNN、CUDAtookit、NVCC CUDA：compute unified device architecture，通用并行计算 平台和编程模型，方便使用GPU进行通用计算 cuDNN：深度学习加速库，计算设计的库、中间件 C++STL的thrust的实现 cublas：GPU版本blas cuSparse：稀疏矩阵运算 cuFFT：快速傅里叶变换 cuDNN：深度学习网络加速 CUDA Toolkit：包括以下组件 编译器nvcc：CUDA-C、CUDA-C++编译器，依赖nvvm 优化器 （nvvm本身依赖llvm编译器） ·debuggers、profiler等工具 科学库、实用程序库 cudart cudadevrt cupti nvml nvrtc cublas cublas_device 示例 驱动： TensorBoardTensorBoard是包括在TensorFlow中可视化组件 运行启动了TB的TF项目时，操作都会输出为事件日志文件 TB能够把这些日志文件以可视化的方式展示出来 模型图 运行时行为、状态 1$ tensorboard --logdir=/path/to/logdir --port XXXX 问题指令集 Your CPU supports instructions that this TensorFlow binary was not cmpiled to use: SSE1.4, SSE4.2, AVX AVX2 FMA 没从源代码安装以获取这些指令集的支持 从源代码编译安装 或者设置log级别123import osos.environ[&quot;TF_CPP_MIN_LOG_LEVEL&quot;] = &quot;2&quot;import tensorflow as tf","link":"/Python/TensorFlow/tf_config.html"},{"title":"TensorFlow操作符","text":"Tensor张量：n-dimensional array，类型化的多维数组 TF使用Tensor表示所有的数据 Tensor包含一个静态类型rank、一个shape TF会将python原生类型转换为相应的Tensor 0-d tensor：scalar 1-d tensor：vector，1d-array 2-d tensor：matrix，2d-array Data Type TF被设计为和numpy可以无缝结合 TF的变量类型基于numpy变量类型：tf.int32==np.int32 bool、numeric等大部分类型可以不加转换的使用TF、np 变量类型 TF、np中string类型不完全一样，但TF仍然可以从numpy 中导入string数组，但是不能在numpy中指定类型 但尽量使用TF变量类型 python原生类型：没有细分类型，TF需要推断类型 numpy类型：numpy不兼容GPU，也不能自动计算衍生类型 数据类型 说明 tf.float16 16-bit half-precision floating-point tf.float32 32-bit single-presicion floating-point tf.float64 64-bit double-presicion floating-point tf.bfloat16 16-bit truncated floating-point tf.complex64 64-bit single-presicion complex tf.complex128 128-bit double-presicion complex tf.int8 8-bit signed integer tf.uint8 8-bit unsigned integer tf.int16 tf.uint16 tf.int32 tf.int64 tf.bool tf.string tf.qint8 quantized 8-bit signed integer tf.quint8 tf.qint16 tf.quint16 tf.qint32 tf.resource handle to a mutable resource Constant OPstf.constant1234567def constant( value, dtype=none, shape=none, name=&quot;Const&quot;, verify_shape=False) 同值常量OPs zeros：类似np中相应函数 1234567891011121314# `np.zeros`def tf.zeros( shape, dtype=tf.float32, name=None)# `np.zores_like`def tf.zeros_like( input_tensor, dtype=None, name=None, optimizeTrue) 若没有指明dtype，根据input_tensor确定其中值 对数值型为0.0 对bool型为False 对字符串为b'' ones：类似np中相应函数 1234567891011121314# `np.ones`def tf.ones( shape, dtype=tf.float32, name=None)# `np.ones_like`def tf.ones_like( input_tensor, dtype=None, name=None, optimize=True) - 若没有指明`dtype`，根据`input_tensor`确定 - 对数值型为`0.0` - 对bool型为`True` - 对字符串报错 fill：以value填充dims给定形状 123456# `np.fill`def tf.fill( dims, value, name=None) 列表常量OPs tensor列表不能直接for语句等迭代 tf.lin_space：start、stop直接均分为num部分 1234567# `np.linspace`def lin_space( start, stop, num, name=None) tf.range：start、stop间等间隔delta取值 12345678# `np.arange`def tf.range( start, limit=None, delta=1, dtype=None, name=&quot;range&quot;) 随机常量OPs seed：设置随机数种子 123# np.random.seeddef tf.set_random_seed(seed): pass random：随机生成函数 123456789101112131415161718192021222324def tf.random_normal()def tf.truncated_normal( ?avg=0/int/(int), stddev=1.0/float, seed=None/int, name=None): passdef tf.random_uniform( shape(1d-arr), minval=0, maxval=None, dtype=tf.float32, seed=None/int, name=None/str): passdef tf.random_crop()def tf.multinomial()def tf.random_gamma() shuffle 1def tf.random_shuffle() 运算OPs元素OPs四则运算123456789101112131415161718192021222324def add(x, y, name=None)def subtract(x, y, name=None)def sub(x, y, name=None)def multiply(x, y, name=None)def mul(x, y, name=None) # 加、减、乘def floordiv(x, y, name=None)def floor_div(x, y, name=None)def div(x, y, name=None)def truncatediv(x, y, name=None) # 地板除def divide(x, y, name=None)def truediv(x, y, name=None) # 浮点除def realdiv(x, y, name=None) # 实数除法，只能用于实数？def add_n(input, name=None) # `input`：list-like，元素shape、type相同 # 累加`input`中元素的值 逻辑运算123def greater()def less()def equal() 数学函数1234567891011def exp()def log()def square()def round()def sqrt()def rsqrt()def pow()def abs()def negative()def sign()def reciprocal() # 倒数 列表运算OPs123456def tf.Concat()def tf.Slice()def tf.Split()def tf.Rank()def tf.Shape()def tf.Shuffle() 矩阵OPs1234def tf.MatMul()def tf.MatrixInverse()def tf.MatrixDeterminant()def tf.tensordot() # 矩阵点乘 梯度OPs12345678910111213141516171819202122def tf.gradients( # 求`y`对`[xs]`个元素偏导 ys: tf.OPs, xs: tf.OPs/[tf.OPs], grad_ys=None, name=None)def tf.stop_gradient( input, name=None)def clip_by_value( t, clip_value_min, clip_value_max, name=None)def tf.clip_by_norm( t, clip_norm, axes=None, name=None) Variable123456789101112131415161718192021222324252627282930313233343536373839class Variable: def __init__(self, init_value=None, trainable=True, collections=None, validata_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, expected_shape=None, import_scope=None, constraint=None ) # 初始化变量 # `sess.run`其即初始化变量 def intializer(self): pass # 读取变量值 def value(self): pass # 获取变量初始化值，其他变量调用、声明依赖该变量 def initilized_value(self): pass # 计算、获取变量值，类似`sess.run(OP)` def eval(self): pass # 给变量赋值 # `assgin`内部有初始化Variable，所以有时可以不用初始化 def assign(self): pass #`assgin_add`等依赖于原始值，不会初始化变量 def assign_add(self, ?dec) def assign_divide(self, ?dec) Variable是包含很多方法的类 其中方法OPs和一般的OP一样，也需要在Session中执行 才能生效 Variable必须在会话中初始化后，才能使用 会话维护自身独立Variable副本，不相互影响 Variable和图分开存储，甚至是存储在独立参数服务器上 存储大量数据也不会拖慢图载入速度 通常用于存储训练过程中weight、bias、维护图执行过程 中状态信息 constants是常数OPs 存储在图中：每次载入图会同时被载入，过大的constants 会使得载入图非常慢 所以最好只对原生类型使用constants Variable创建tf.get_variable123456789101112131415def get_variable( name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None) 此封装工厂方法相较于直接通过tf.Variable更好 若变量已设置，可通过变量名获取变量，方便变量共享 可以提供更多的参数定制变量值 1234567891011 # `tf.Variable`创建变量s = tf.Variable(2, name=&quot;scalar&quot;)m = tf.Variable([[0,1], [2,3]], name=&quot;matrix&quot;)w = tf.Variable(tf.zeros([784, 10])) # `tf.get_variable`创建、获取变量s = tf.get_variable(&quot;scalar&quot;, initializer=tf.constant(2))m = tf.get_variable(&quot;matrix&quot;, initializer=tf.constant([[0,1], [2,3]])W = tf.get_variable(&quot;big_matrix&quot;, shape=(784, 10), initializer=tf.zeros_initializer()) Variable初始化1234567with tf.Session() as sess: # 初始化所有Variables sess.run(tf.global_variable_initialier()) # 初始化变量子集 sess.run(tf.variable_initializer([s, m]) # 初始化指定单个变量 sess.run(s.initializer) 若某Variable依赖其他Variable，需要使用 initialized_value指明依赖，确保依赖线性初始化 123W = tr.Variable(tf.truncated_normal([700, 100])# 指明依赖，保证依赖线性初始化U = tf.Variable(W.initialized_value() * 2)","link":"/Python/TensorFlow/tf_operators.html"},{"title":"TensorFlow 持久化","text":"Session Checkpoint12345678910111213141516171819class tf.train.Saver: def __init__(self, var_list=None/list/dict, reshape=False, sharded=False, max_to_keep=5, keep_checkpoint_every_n_hours=10000.0, name=None, restore_sequentially=False, saver_def=None, builder=None, defer_build=False, allow_empty=False, write_version=tf.train.SaverDef.V2, pad_step_number=False, save_relative_paths=False, filename=None ): self.last_checkpoints 用途：保存Session中变量（张量值），将变量名映射至张量值 参数 var_list：待保存、恢复变量，缺省所有 变量需在tf.train.Saver实例化前创建 reshape：允许恢复并重新设定张量形状 sharded：碎片化保存至多个设备 max_to_keep：最多保存checkpoint数目 keep_checkpoint_every_n_hours：checkpoint有效时间 restore_sequentially：各设备中顺序恢复变量，可以 减少内存消耗 成员 last_checkpoints：最近保存checkpoints 保存Session12345678910def Saver.save(self, sess, save_path, global_step=None/str, latest_filename=None(&quot;checkpoint&quot;)/str, meta_graph_suffix=&quot;meta&quot;, write_meta_graph=True, write_state=True) -&gt; str(path): pass 用途：保存Session，要求变量已初始化 参数 global_step：添加至save_path以区别不同步骤 latest_filename：checkpoint文件名 meta_graph_suffix：MetaGraphDef文件名后缀 恢复Session12def Saver.restore(sess, save_path(str)): pass 用途：从save_path指明的路径中恢复模型 模型路径可以通过Saver.last_checkpoints属性、 tf.train.get_checkpoint_state()函数获得 tf.train.get_checkpoint_state12345def tf.train.get_checkpoint_state( checkpoint_dir(str), latest_filename=None): pass 用途：获取指定checkpoint目录下checkpoint状态 需要图结构已经建好、Session开启 恢复模型得到的变量无需初始化 123ckpt = tf.train.get_checkpoint_state(checkpoint_dir)saver.restore(ckpt.model_checkpoint_path)saver.restore(ckpt.all_model_checkpoint_paths[-1]) Graph Savertf.train.write_graph123456def tf.train.write_graph( graph_or_graph_def: tf.Graph, logdir: str, name: str, as_text=True) 用途：存储图至文件中 参数 as_text：以ASCII方式写入文件 Summary Savertf.summary.FileWriter12345678910111213141516class tf.summary.FileWriter: def __init__(self, ?path=str, graph=tf.Graph ) # 添加summary记录 def add_summary(self, summary: OP, global_step ): pass # 关闭`log`记录 def close(self): pass 用途：创建FileWriter对象用于记录log 存储图到文件夹中，文件名由TF自行生成 可通过TensorBoard组件查看生成的event log文件 说明 一般在图定义完成后、Session执行前创建FileWriter 对象，Session结束后关闭 实例12345678910111213141516171819202122232425262728 # 创建自定义summarywith tf.name_scope(&quot;summaries&quot;): tf.summary.scalar(&quot;loss&quot;, self.loss) tf.summary.scalar(&quot;accuracy&quot;, self.accuracy) tf.summary.histogram(&quot;histogram loss&quot;, self.loss) summary_op = tf.summary.merge_all()saver = tf.train.Saver()with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # 从checkpoint中恢复Session ckpt = tf.train.get_check_state(os.path.dirname(&quot;checkpoint_dir&quot;)) if ckpt and ckpt.model_check_path: saver.restore(sess, ckpt.mode_checkpoint_path) # summary存储图 writer = tf.summary.FileWriter(&quot;./graphs&quot;, sess.graph) for index in range(10000): loas_batch, _, summary = session.run([loss, optimizer, summary_op]) writer.add_summary(summary, global_step=index) if (index + 1) % 1000 = 0: saver.save(sess, &quot;checkpoint_dir&quot;, index) # 关闭`FileWriter`，生成event log文件write.close()","link":"/Python/TensorFlow/tf_persistence.html"},{"title":"TensorFlow Python IO接口","text":"TFRecordTFRecord格式：序列化的tf.train.Example protbuf对象 1234567891011121314151617181920212223242526272829303132class tf.python_io.TFRecordWriter: def __init__(self, ?fileanme: str, options: tf.python_io.TFRecordOptions, name=None ): passclass tf.python_io.TFRecordReader: def __init__(self, options: tf.python_io.TFRecordOptions, name=None ): pass def read(self): pass### Feature/Features```pythonclass tf.train.Features: def __init__(self, feature: {str: tf.train.Feature} ): passclass tf.train.Feature: def __init__(self, int64_list: tf.train.Int64List, float64_list: tf.train.Float64List, ) 示例 转换、写入TFRecord 12345678910111213141516# 创建写入文件writer = tf.python_io.TFRecord(out_file)shape, binary_image = get_image_binary(image_file)# 创建Features对象featurs = tf.train.Features( feature = { &quot;label&quot;: tf.train.Feature(int64_list=tf.train.Int64List(label)), &quot;shape&quot;: tf.train.Feature(bytes_list=tf.train.BytesList(shape)), &quot;image&quot;: tf.train.Feature(bytes_list=tf.train.BytesList(binary_image)) })# 创建包含以上特征的示例对象sample = tf.train.Example(features=Features)# 写入文件writer.write(sample.SerializeToString())writer.close() 读取TFRecord 1234567891011dataset = tf.data.TFRecordDataset(tfrecord_files)dataset = dataset.map(_parse_function)def _parse_function(tf_record_serialized): features = { &quot;labels&quot;: tf.FixedLenFeature([], tf.int64), &quot;shape&quot;: tf.FixedLenFeature([], tf.string), &quot;image&quot;: tf.FixedLenFeature([], tf.string) } parsed_features = tf.parse_single_example(tfrecord_serialized, features) return parsed_features[&quot;label&quot;], parsed_features[&quot;shape&quot;], parsed_features[&quot;image&quot;] 其他函数","link":"/Python/TensorFlow/tf_pythonio.html"},{"title":"TensorFlow控制算符","text":"控制OPsNeural Network Building Blockstf.softmaxtf.Sigmodtf.ReLUtf.Convolution2Dtf.MaxPoolCheckpointingtf.Savetf.RestoreQueue and Synchronizationtf.Enqueuetf.Dequeuetf.MutexAcquiretf.MutexReleaseControl Flowtf.count_up_totf.condpred为True，执行true_fn，否则执行false_fn 12345tf.cond( pred, true_fn=None, false_fn =None,) tf.casetf.while_looptf.grouptf.Mergetf.Switchtf.Entertf.Leavetf.NextIteration","link":"/Python/TensorFlow/tf_flow_control.html"},{"title":"TensorFlow执行","text":"SessionSession：TF中OPs对象执行、Tensor对象计算的封装环境 Session管理图、OPs 所有图必须Session中执行 将图中OPs、其执行方法分发到CPU、GPU、TPU等设备上 为当前变量值分配内存 Session只执行Data/Tensor Flow中OPs，忽略不相关节点 即通往fetches的flow中的OPs构成子图才会被计算 各Session中各值独立维护，不会相互影响 1234567891011121314151617181920212223242526272829class Session: def __init__(self, target=str, graph=None/tf.Graph, config=None/tf.ConfigProto) # 获取Session中载入图 self.graph # 关闭会话，释放资源 def close(self): pass # 支持上下文语法 def __enter__(self): pass def __exit__(self): pass # 执行TensorFlow中节点，获取`fetches`中节点值 # 返回值若为Tensor # python中：以`np.ndarray`返回 # C++/C中：以`tensorflow:Tensor`返回 # 可直接调用`.eval()`获得单个OP值 def run(self, fetches=tf.OPs/[tf.OPs], feed_dict=None/dict, options=None, run_metadata=None) tf.InteractiveSessiontf.InteractiveSession：开启交互式会话 1234567891011 # 开启交互式Sessionsess = tf.InteractiveSession()a = tf.constant(5.0)b = tf.constant(6.0)c = a * bx = tf.Variable([1.0, 2.0]) # 无需显式在`sess.run`中执行 # 直接调用`OPs.eval/run()`方法得到结果x.initializer.run()print(c.eval())sess.close() Session执行 Fetch机制：sess.run()执行图时，传入需取回的结果， 取回操作输出内容 Feed机制：通过feed_dict参数，使用自定义tensor值替代图 中任意feeable OPs的输出 tf.placeholder()表示创建占位符，执行Graph时必须 使用tensor替代 feed_dict只是函数参数，只在调用它的方法内有效， 方法执行完毕则消失 可以通过feed_dict feed所有feedable tensor，placeholder 只是指明必须给某些提供值 1234a = tf.add(2, 5)b = tf.multiply(a, 3)with tf.Session() as sess: sess.run(b, feed_dict={a: 15}) # 45 config参数选项 log_device_placement：打印每个操作所用设备 allow_soft_placement：允许不在GPU上执行操作自动迁移到 CPU上执行 gpu_options allow_growth：按需分配显存 per_process_gpu_memory_fraction：指定每个GPU进程 使用显存比例（无法对单个GPU分别设置） 具体配置参见tf.ConfigProto GraphGraph：表示TF中计算任务， operation/node：Graph中节点，包括：operator、 variable、constant 获取一个、多个Tensor执行计算、产生、返回tensor 不能无法对其值直接进行访问、比较、操作 图中节点可以命名，TF会自动给未命名节点命名 tensor：Graph中边，n维数组 TF中所有对象都是Operators tensor是OPs执行结果，在图中传递/流动 图计算模型优势 优化能力强、节省计算资源 缓冲自动重用 常量折叠，只计算取得目标值过程中必须计算的值 方便并行化 自动权衡计算、存储效率 易于部署 可被割成子图（即极大连通分量），便于自动区分 子图可以分发到不同的设备上分布式执行，即模型并行 许多通用ML模型是通过有向图教学、可视化的 图计算模型劣势 难以debug 图定义之后执行才会报错 无法通过pdb、打印状态debug 语法繁复 构建图123456789101112131415161718192021222324class Graph: def __init__(self): pass # 将当前图作为默认图 # 支持上下文语法 def as_default(self): pass # 强制OPs依赖关系（图中未反映），即优先执行指定OPs # 支持上下文语法 def as_default(self): def control_dependencies(self, ?ops=[tf.OPs]) pass # 以ProtoBuf格式展示Graph def as_graph_def(self): pass # 判断图中节点是否可以被feed def is_feedable(self, ?op=tf.OPs): pass 可以通过tf.Graph创建新图，但最好在是在一张图中使用多个 不相连的子图，而不是多张图 充分性：Session执行图时忽略不必要的OPs 必要性 多张图需要多个会话，每张图执行时默认尝试使用所有 可能资源 不能通过python/numpy在图间传递数据（分布式系统） 初始化即包含默认图，OP构造器默认为其增加节点 通过tf.get_default_graph()获取 图相关方法 获取TF初始化的默认图 12def tf.get_default_graph(): pass 命名空间12345678 # 均支持、利用上下文语法，将OPs定义于其下def tf.name_scope(name(str)): passdef tf.variable_scope( name(str), reuse=tf.AUTO_REUSE): pass tf.name_scope：将变量分组 只是将变量打包，不影响变量的重用、可见性等 方便管理、查看graph tf.variable_scope： 对变量有控制能力 可设置变量重用性 变量可见性局限于该variable scope内，即不同 variable scope间可以有完全同名变量 （未被TF添加顺序后缀） 会隐式创建name scope 大部分情况是用于实现变量共享 123456789101112131415161718def fully_connected(x, output_dim, scope): # 设置variable scope中变量自动重用 # 或者调用`scope.reuse_variables()`声明变量可重用 with tf.variable_scope(scope, reuse=tf.AUTO_REUSE) as scope: # 在当前variable scope中获取、创建变量 w = tf.get_variable(&quot;weights&quot;, [x.shape[1]], output_dim, initializer=tf.random_normal_initializer()) b = tf.get_variable(&quot;biases&quot;, [output_dim], initializer=tf.constant_initizer(0.0)) return tf.matmul(x, w) + bdef two_hidden_layers(x): h1 = fully_connected(x, 50, &quot;h1&quot;) h2 =-fully_connected(h1, 10, &quot;h2&quot;)with tf.variable_scope(&quot;two_layers&quot;) as scope: logits1 = two_hidden_layers(x1) logits2 = two_hidden_layers(x2) Lazy LoadingLazy Loading：推迟声明/初始化OP对象至载入图时 （不是指TF的延迟计算，是个人代码结构问题，虽然是TF延迟图计算 模型的结果） 延迟加载容易导致向图中添加大量重复节点，影响图的载入、 传递 1234567891011x = tf.Variable(10, name='x')y = tf.Variable(20, name='y')with tf.Session() as sess: sess.run(tf.global_variables_initializer()) writer = tf.summary.FileWriter('graphs/lazy_loading', sess.graph) for _ in range(10): # 延迟加载节点，每次执行都会添加`tf.add`OP sess.run(tf.add(x, y)) print(tf.get_default_graph().as_graph_def()) writer.close() 解决方案 总是把（图的搭建）OPs的定义、执行分开 python利用@property装饰器，使用单例模式函数 封装变量控制，保证仅首次调用函数时才创建OP Eager Execution1234import tensorflow as tfimport tensorflow.contrib.eager as tfe # 启用TF eager executiontfe.enable_eager_execution() 优势 支持python debug工具 提供实时报错 支持python数据结构 支持pythonic的控制流 123i = tf.constant(0)whlile i &lt; 1000: i = tf.add(i, 1) eager execution开启后 tensors行为类似np.ndarray 大部分API和未开启同样工作，倾向于使用 tfe.Variable tf.contrib.summary tfe.Iterator tfe.py_func 面向对象的layers 需要自行管理变量存储 eager execution和graph大部分兼容 checkpoint兼容 代码可以同时用于python过程、构建图 可使用@tfe.function将计算编译为图 示例 placeholder、sessions 123456789# 普通TFx = tf.placholder(tf.float32, shape=[1, 1])m = tf.matmul(x, x)with tf.Session() as sess: m_out = sess.run(m, feed_dict={x: [[2.]]})# Eager Executionx = [[2.]]m = tf.matmul(x, x) Lazy loading 12345x = tf.random_uniform([2, 2])for i in range(x.shape[0]): for j in range(x.shape[1]): # 不会添加多个节点 print(x[i, j]) Device设备标识 设备标识：设备使用字符串进行标识 /cpu:0：所有CPU都以此作为名称 /gpu:0：第一个GPU，如果有 /gpu:1：第二个GPU 123456# 为计算指定硬件资源with tf.device(&quot;/gpu:2&quot;): a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0], name=&quot;a&quot;) b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0], name=&quot;b&quot;) c = tf.multiply(a, b) # creates a graph 环境变量：python中既可以修改os.environ，也可以直接设置 中设置环境变量 CUDA_VISIBLE_DEVICES：可被使用的GPU id 设备执行设备执行：TF将图形定义转换成分布式执行的操作以充分利用计算 资源 TF默认自动检测硬件配置，尽可能使用找到首个GPU执行操作 TF会默认占用所有GPU及每个GPU的所有显存（可配置） 但只有一个GPU参与计算，其他GPU默认不参与计算（显存 仍然被占用），需要明确将OPs指派给其执行 指派GPU数量需通过设置环境变量实现 控制显存占用需设置Session config参数 注意：有些操作不能再GPU上完成，手动指派计算设备需要注意 tf.ConfigProto Session参数配置 12345 # `tf.ConfigProto`配置方法conf = tf.ConfigProto(log_device_placement=True)conf.gpu_options.allow_growth=Truesess = tf.Session(config=conf)sess.close()","link":"/Python/TensorFlow/tf_execution.html"},{"title":"TensorFlow训练","text":"Optimizer1234567891011class tf.train.GradientDescentOptimizer:class tf.train.AdagradOptimizer:class tf.train.MomentumOptimizer:class tf.train.AdamOptimizer:class tf.train.FtrlOptimizer:class tf.train.RMSPropOptmizer:","link":"/Python/TensorFlow/tf_train.html"},{"title":"TensorFlow资源管理","text":"Resourcestf.placeholderplaceholder：占位符，执行时通过feed_dict参数设置值 12345tf.placeholder( dtype, shape=None, name=None) shape：并不必须，但最好设置参数方便debug 需要导入数据给placeholder，可能影响程序速度 方便用户替换图中值 tf.data.DataSet123456789101112131415161718192021222324252627282930313233343536373839class tf.data.DataSet: def __init__(self) # 从tensor slice创建`Dataset` def from_tensor_slices(self, ?data=(?features, ?labels) ): pass # 从生成器创建`Dataset` def from_generator(self, gen, output_types, output_shapes ): pass # 迭代数据集一次，无需初始化 def make_one_shot_iterator(self): pass # 迭代数据集任意次，每轮迭代需要初始化 def make_initializable_iterator(self): pass # shuffle数据集 def shuffle(self, ?seed:int): pass # 重复复制数据集 def repeat(self, ?times:int): pass # 将数据集划分为batch def batch(self, batch_size:int): pass def map(self, func:callable): pass 创建只能迭代一轮的迭代器 123456789iterator = dataset.make_one_shot_iterator()# 这里`X`、`Y`也是OPs，在执行时候才返回TensorX, Y = iterator.get_next()with tf.Session() as sess: print(sess.run([X, Y])) print(sess.run([X, Y])) print(sess.run([X, Y])) # 每次不同的值 创建可以多次初始化的迭代器 123456789101112iterator = data.make_initializable_iterator()with tf.Session() as sess: for _ in range(100): # 每轮重新初始化迭代器，重新使用 sess.run(iterator.initializer) total_loss = 0 try: while True: sess.run([optimizer]) # 手动处理迭代器消耗完毕 except tf.error.OutOfRangeError: pass tf.data和tf.placeholder适合场景对比 tf.data速度更快、适合处理多数据源 tf.placeholder更pythonic、原型开发迭代速度快 读取文件数据可以从多个文件中读取数据 123456 # 文件每行为一个entryclass tf.data.TextLineDataset(filenames): # 文件中entry定长class tf.data.FixedLengthRecordDataset(filenames): # 文件为tfrecord格式class tf.data.TFRecordDataset(filenames): tf.data.Iterator123456789101112131415161718class tf.data.Iterator: # 获取下组迭代数据 def get_next(): pass # 根据dtype、shape创建迭代器 @classmethod def from_structure(self, ?dtype: type, ?shape: [int]/(int) ): pass # 从数据中初始化迭代器 def make_initializer(self, ?dataset: tf.data.Dataset ): pass","link":"/Python/TensorFlow/tf_resources.html"},{"title":"Vector","text":"向量 线性组合 向量空间 空间的基：向量空间的一组基是张成该空间的一个线性无关向量集 线性相关 向量点积 向量点积性质 向量的数乘等比例影响点积，则可为每个向量找到共线单位向量满足 $u \\cdot u=1$ 点积等同于向量 $b$ 左乘矩阵 $a^T$，即把向量 $b$ 压缩（线性变换）至向量 $a$ 方向上 点积 $a \\cdot b$ 与投影关系（假设向量 $a$ 为单位向量） 投影，即将向量 $b$ 线性变换 至 $a$ 方向上的标量 则投影可以用 $1 * n$ 矩阵表示 投影代表的矩阵则可通过利用基向量的变换结果求解 向量 $a$ 本身作为单位向量 坐标轴上单位向量与 $a$ 的内积即为 $a$ 该方向分量，也即 $a$ 在该轴上投影 由对称性显然，坐标轴在 $a$ 方向投影等于 $a$ 在轴方向投影 则投影到向量 $a$ 代表的线性变换矩阵即为 $a^T$ 扩展到一般情况 考虑标量乘法对点积影响，坐标轴上向量与任意向量 $a$ 内积等价于投影 投影是线性变换，则对空间一组基的变换可以推导到空间中任意向量 $b$ 高维空间到标量的线性变换与空间中一个向量对应，即应用线性变换等价于同该向量点积 点积用途 向量证明基本都是都转换到点积上 正定：行列式恒&gt;0 下降方向：内积&lt;0 方向（趋于）垂直：内积趋于0 求和、积分、点积、卷积 连续（函数） 离散（向量） 单元累计 积分：按值出现频率加权求和 求和：向量视为分段函数积分 二元累计 卷积：连续卷积 点积：离散卷积的特殊情况，即仅向量对应位置分量乘积有定义 卷积：累计中各点的值变为需累计的值，即二次累计 向量叉积 向量叉积意义 向量叉积即寻找向量（到标量的线性变换），满足与其点积结果为张成的体积 考虑点积性质，则向量叉积的方向与向量构成超平面垂直、模为超平面大小 一些规定 正交方向：向量空间 $R^n$ 中 $k, k \\leq n$ 个向量 $q^{(1)}, \\cdots, q^{(k)}$ 两两正交，则称其为 $k$ 个正交方向，若满足所有向量非 0，则称为 $k$ 个非 0 正交方向 向量左右 左侧：向量逆时针旋转 $[0, \\pi]$ 内 右侧：反左侧 矩阵 矩阵（乘法）：对向量的变换 对 $m * n$ 矩阵，即将 $n$ 维空间映射至 $m$ 维空间 矩阵相关概念 （矩阵）秩：空间维数 （矩阵）零空间/核：变换（左乘矩阵）后落在原点的向量的集合 线性变换：保持空间中坐标轴仍为直线且原点保持不变的变换 此处若无特殊说明，向量均以列向量作为基础 特殊矩阵 其中正交矩阵、三角阵、对角阵也被成为因子矩阵 Orthogonal Matrix 正交矩阵：和其转置乘积为单位阵的方阵 左乘正交矩阵几何意义：等价于旋转 酉矩阵/幺正矩阵：$n$ 个列向量是 $U$ 空间标准正交基的 $n$ 阶复方阵，是正交矩阵往复数域上的推广 Diagonal Matrix 对角阵：仅对角线非0的矩阵 左乘对角阵矩阵几何意义：等价于对坐标轴缩放 Triangular Matrix 上/下三角矩阵：左下/右上角全为0的方阵 三角阵是高斯消元法的中间产物，方便进行化简、逐层迭代求解线性方程组 左乘上三角阵几何意义：等价于进行右上切变（水平斜拉） 左乘下三角阵几何意义：等价于进行左下切变（竖直斜拉） Transposation Matrix 置换矩阵：系数只由 0、1 组成，每行、列恰好有一个 1 的方阵 矩阵常用公式Sherman-Morrison 公式 设A是n阶可逆矩阵，$u, v$均为n为向量，若 $1 + v^T A^{-1} u \\neq 0$，则扰动后矩阵$A + u v^T$可逆 (A + u v^T)^{-1} = A^{-1} - \\frac {A^{-1} u v^T A^{-1}} {1 + v^T A^{-1} u} 矩阵乘法 矩阵乘法 向量左乘矩阵：即是对向量进行变换 矩阵乘积：复合变换 矩阵乘法应按照从右往左阅读，右侧矩阵为输入、左侧矩阵为变换（向量默认为列向量时） Affline Transformation仿射变换：对向量空间进行线性变换、平移得到另一个向量空间 \\begin{align*} y &= Ax + b \\\\ y &= (A|b^T) \\begin {bmatrix} x \\\\ 1 \\end {bmatrix} \\end{align*} $y \\in R^n, x \\in R^n$ $A \\in R^{n * n}$：可视为产生旋转、放缩 $b \\in R^n$：可视为产生平移 仿射变换可以理解为：放缩、旋转、平移 从仿射变换的角度，对向量空间进行仿射变换 $n+1$ 对变换前、变换后向量坐标即可以求解仿射变换的全部参数 变换后的向量之间仍然保留某种相关性，所以 $n+1$ 对向量坐标可以完全确定仿射变换 从仿射变换几何含义，将向量空间中向量统一变换 $n+1$ 个不共线 $n$ 维向量即唯一确定n维空间 若所有向量变换均遵循同一“线性”变换规则，即进行相同放缩、旋转、平移，则这样的变换可以使用仿射变换表示 说明 $n$ 变换前、变换后向量坐标可以求解 $A$（不考虑 $b$），但第 $n+1$ 对向量坐标未必满足 $A$ 变换 若 $n+2$ 对向量坐标不满足 $(A|b)$ 的解，则表示不是进行仿射变换 Perspective Transformation透视变换：将向量空间映射到更高维度，再降维到另一向量空间 \\begin{align*} y &= P \\begin {bmatrix} x \\\\ 1 \\end {bmatrix} \\\\ y &= \\begin {bmatrix} A & b \\\\ c & p_{n+1,n+1} \\end {bmatrix} \\begin {bmatrix} x \\\\ 1 \\end {bmatrix} \\end{align*} $P \\in R^{(n+1) (n+1)}, A \\in R^{n n}$ $x \\in R^n, y \\in R^{n+1}$：这里默认$x$第$n+1$维为1 $c$：可视为产生透视，若其为0向量，则退化为仿射变换 $p_{n+1,n+1}$：可视为决定透视放缩，所以若是已确定新向量空间的“位置”，此参数无效，即 $n+2$ 对向量坐标即可求解变换 透视变换虽然是向量空间变换至另一向量空间，但仍然存在一个透视“灭点”，作为所有透视线的交点 对平面成像而言，“灭点”是成像平面、视角决定 变换后 $y$ 维数增加，一般会再次投影、缩放回原维度空间，如原向量空间 $(R^n,1)$ 仿射变换可以视为是新的向量空间和原始空间“平行”的透视变换特例 变换矩阵求解\\begin{align*} \\begin {bmatrix} P & b \\\\ c & p_{n+1,n+1} \\end {bmatrix} \\begin {bmatrix} x \\\\ 1 \\end {bmatrix} &= \\gamma \\begin {bmatrix} x^{'} \\\\ 1 \\end {bmatrix} \\\\ \\Rightarrow Px + b &= \\gamma x^{'} \\\\ c^Tx + p_{n+1,n+1} &= \\gamma \\\\ \\Rightarrow Px + b &= (c^Tx + p_{n+1,n+1}) x^{'} \\end{align*} 考虑变换后再次缩放回更低维 $(R^n,1)$ 向量空间 $\\gamma$：变换后向量缩放比例 可解性 共 $n+2$ 对变换前、后向量坐标，即 $n*(n+2)$ 组方程 对每对向量，其中 $n$ 组方程如上可以看出是齐次方程组，不包含常数项 则对 $P \\in R^{(n+1) * (n+1)}$ 中除 $p_{n+1,n+1}$ 其他项均可被其比例表示（不含常数项） 当然 $p_{n+1,n+1}$ 可以置 1 参加运算，不影响结果 Determinant 矩阵行列式几何意义：线性变换对空间的拉伸比例 行列式绝对值：拉伸的比例的绝对大小 行列式为 0 时则表示空间降维 则显然应有 $det(M_1 * M_2) = det(M_1) det(M_2)$ 行列式正负号：拉伸的方向 矩阵行列式的用途 行列式为 0 意味着矩阵表示降维变换，则对应线性方程组仅在方程组右侧在矩阵张成空间内，即扩展矩阵秩不增时有解 特别的 $2 * 2$ 矩阵 $\\begin{vmatrix} a &amp; b \\ c &amp; d \\end{vmatrix} = ad - bc$ $a, d$ 分别表示 $(1,0)$、$(0,1)$ 正向放缩比例 而 $b, c$ 则相应的为逆向放缩比例 二维三点：行列式绝对值为三点构成三角形面积两倍 \\begin{vmatrix} x_1 & y_1 & 1 \\\\ x_2 & y_2 & 1 \\\\ x_3 & y_3 & 1 \\\\ \\end{vmatrix} = x_1y_2 + x_3y_1 + x_2y_3 - x_3y_2 - x_2y_1 - x_1y_3 $q_3$ 位于 $\\overrightarrow{q_1q_2}$ 左侧：行列式大于0 $q_3q_1q_2$ 共线：行列式值为 0 三维三点：行列式为三个向量张成的平行六面体体积 Eigen Value、Eigen Vector 矩阵（变换）特征向量、特征值几何意义 特征向量：在线性变换后仍然在自身生成空间中，即保持方向不变，仅是模变化的向量 特征值：对应特征向量模变化的比例 特殊变换中的特征向量、特征值情况 旋转变换：特征值为 $\\pm i$，没有特征向量，即特征值为复数表示某种旋转 剪切变换（$\\begin{vmatrix} A^{‘} &amp; 0 \\ 0 &amp; 1 \\end{vmatrix}$$：必然有特征值为 1，且对应特征向量在坐标轴上 伸缩变换（$\\lambda E$）：所有向量都是特征向量 矩阵对角化 矩阵对角化：即寻找一组基，使得线性变换对该组基向量仅引起伸缩变换 定理：当且仅当 $n$ 阶矩阵 $A$ 有 $n$ 个线性无关的特征向量时，其可以对角化 即变换后有 $n$ 个线性无关向量在自身生成空间中 也即矩阵对应变换为线性变换 线性方程组Gaussian Elimination高斯消元法：初等变换n个线性方程组为等价方程组，新方程组系数矩阵为上三角矩阵 三角系数矩阵可以方便的递推求解 初等变换可将系数矩阵变换为上三角矩阵，而不影响方程解 参考资料 https://www.bilibili.com/video/av6731067/ https://charlesliuyx.github.io/2017/10/06/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9A%84%E6%9C%AC%E8%B4%A8/","link":"/Math-Algebra/Linear-Algebra/vector_matrix.html"},{"title":"Matrix Derivative&#x2F;Matrix Differential","text":"矩阵求导/矩阵微分Layout Conventions矩阵求导：在矩阵空间的多元微积分 numerator layout：分子布局，微分分子的维数决定微分结果 的高维度结构（行优先，如：微分矩阵行数等于分子维数） denominator layout：分母布局，微分分母的维数为微分结果 的高维度结构（行优先） 两种布局方式相差转置 与微分分子、分母为行、或列向量无关 （即当微分分子、分母为向量时，行、列向量结果相同，只与 维度有关） 此布局模式仅讨论简单单因子微分时布局模式，复合多因子 应使用维度分析考虑 （即若严格按照计算规则，结果应该满足布局） 数分中Jaccobi行列式采用分子布局，以下默认为分子布局 维度分析维度分析：对求导结果的维度进行分析，得到矩阵微分结果 维度一般化：将向量、矩阵维度置不同值，便于考虑转置 拆分有关因子：利用求导乘法公式（一般标量求导）拆分 因子，分别考虑各因子微分结果 变换微分因子、剩余因子（可能有左右两组），以满足矩阵运算 维度要求 微分因子：按布局模式考虑维度、不转置 剩余因子：为满足最终结果符合维度布局，考虑转置 若维度一般化也无法唯一确定剩余因子形式，再考虑行、列 內积对应关系 考虑到矩阵乘法定义（左乘矩阵行数为乘法结果行数），则在 分子布局（分子行优先），简单微分中若微分因子为右乘矩阵、 剩余因子为左乘矩阵，则类似标量系数在前求微分，否则 结果需转置 例 考虑$\\frac {\\partial x^T A x} {\\partial x}$，其中 $A \\in R^{n*n}, x \\in R^n$ 维度一般化：$\\frac {\\partial u^T A v} {\\partial x}$， 其中$A \\in R^{a * b}, x \\in R^n$ 拆分有关因子，变换微分、剩余因子 \\begin{align*} \\frac {\\partial (u^T A) v} {\\partial x} & = u^T A \\frac {\\partial v} {\\partial x} \\\\ \\frac {\\partial u^T (A v)} {\\partial x} & = v^T A^T \\frac {\\partial u} {\\partial x} \\end{align*} 则有 \\frac {\\partial x^T A x} {\\partial x} = x^T (A^T + A) 关于标量导数标量对标量标量$y$对标量$x$求导：$\\frac {\\partial y} {\\partial x}$ 向量对标量向量$Y$关于标量$x$求导（$Y$为行、列向量均如此） \\frac {\\partial Y} {\\partial x} = \\begin{bmatrix} \\frac {\\partial y_1} {\\partial x} \\\\ \\frac {\\partial y_2} {\\partial x} \\\\ \\vdots \\\\ \\frac {\\partial y_n} {\\partial x} \\end{bmatrix}矩阵对标量矩阵$Y$关于标量$x$求导 \\frac {\\partial Y} {\\partial x} = \\begin{bmatrix} \\frac {\\partial y_{11}} {\\partial x} & \\frac {\\partial y_{12}} {\\partial x} & \\cdots & \\frac {\\partial y_{1n}} {\\partial x} \\\\ \\frac {\\partial y_{21}} {\\partial x} & \\frac {\\partial y_{22}} {\\partial x} & \\cdots & \\frac {\\partial y_{2n}} {\\partial x} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac {\\partial y_{n1}} {\\partial x} & \\frac {\\partial y_{n2}} {\\partial x} & \\cdots & \\frac {\\partial y_{nn}} {\\partial x} \\\\ \\end{bmatrix}关于向量导数标量对向量标量$y$关于向量$X$求导 \\frac {\\partial y} {\\partial X} = [\\frac {\\partial y} {\\partial x_1}, \\frac {\\partial y} {\\partial x_1}, \\cdots, \\frac {\\partial y} {\\partial x_n}]向量对向量向量$Y$关于向量$X$求导 \\frac {\\partial Y} {\\partial X} = \\begin{bmatrix} \\frac {\\partial y_1} {\\partial x_1} & \\frac {\\partial y_1} {\\partial x_2} & \\cdots & \\frac {\\partial y_1} {\\partial x_n} \\\\ \\frac {\\partial y_2} {\\partial x_1} & \\frac {\\partial y_2} {\\partial x_2} & \\cdots & \\frac {\\partial y_2} {\\partial x_n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac {\\partial y_m} {\\partial x_1} & \\frac {\\partial y_m} {\\partial x_2} & \\cdots & \\frac {\\partial y_m} {\\partial x_n} \\end{bmatrix} $Y$、$X$为行、列向量均如此 关于矩阵导数标量对矩阵求导 微分微分形式 导数、微分转换","link":"/Math-Algebra/Linear-Algebra/matrix_derivative.html"},{"title":"Matrix Decomposition","text":"矩阵分解 矩阵加法分解：将矩阵分解为三角阵、对角阵之和 常用于迭代求解线性方程组 矩阵乘法分解：将矩阵分解为三角镇、对角阵、正交阵之积 以下分解均在实数域上，扩展至复数域需同样将相应因子矩阵 扩充至复数域上定义 矩阵加法分解Jacobi分解Jacobi分解：将矩阵分解为对角阵、非对角阵 Gauss-Seidel分解Gauss-Seidel分解：将矩阵分解为上、下三角矩阵 Successive Over RelaxationSOR：逐次超松弛迭代法，分解为对角、上三角、上三角矩阵，同时 增加权重$w$调整分解后比例 利用内在等式应用的平衡性、不动点收敛理论可以快速迭代 $x$拆分到等式左右两侧，可以视为$y=x$和另外函数交点 根据不动点收敛理论可以进行迭代求解 LU系列分解LU DecompositionLU分解：将方阵分解为lower triangualr matrix、 upper triangluar matrix \\begin{align*} A & = L U \\\\ \\begin{bmatrix} a_{1,1} & a_{1,2} & \\cdots & a_{1,m} \\\\ a_{2,1} & a_{2,2} & \\cdots & a_{2,m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m,1} & a_{m,2} & \\cdots & a_{m,m} \\end{bmatrix} & = \\begin{bmatrix} l_{1,1} & 0 & \\cdots & 0 \\\\ l_{2,1} & l_{2,2} & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ l_{m,1} & l_{m,2} & \\cdots & l_{m,m} \\end{bmatrix} \\begin{bmatrix} u_{1,1} & u_{1,2} & \\cdots & u_{1,m} \\\\ 0 & u_{2,2} & \\cdots & u_{2,m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & u_{m,m} \\end{bmatrix} \\end{align*} $L$：下三角矩阵 $U$：上三角矩阵 特别的可以要求某个矩阵对角线元素为1 几何意义：由单位阵出发，经过竖直、水平切变 特点 LU分解实际上不需要额外存储空间，矩阵L、U可以合并存储 LU分解可以快速求解线性方程组，可以视为高斯消元法的矩阵 形式 得到矩阵LU分解后，对任意向量b，可使用已有LU分解 求解 L为消元过程中的行系数和对角线全为1的下三角矩阵 （负系数在矩阵中为正值） U为消元结果上三角矩阵 则解方程组$Ax=b$等价于$LUx=b$ 先求解$Ly=b$ 再求解$Ux=x$ LDU DecompositionLDU分解：将矩阵分解为下三角、上三角、对角矩阵 \\begin{align*} A & = L D U \\\\ \\begin{bmatrix} a_{1,1} & a_{1,2} & \\cdots & a_{1,m} \\\\ a_{2,1} & a_{2,2} & \\cdots & a_{2,m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m,1} & a_{m,2} & \\cdots & a_{m,m} \\end{bmatrix} & = \\begin{bmatrix} 1 & 0 & \\cdots & 0 \\\\ l_{2,1} & 1 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ l_{m,1} & l_{m,2} & \\cdots & 1 \\end{bmatrix} \\begin{bmatrix} u_{1,1} & 0 & \\cdots & 0\\\\ 0 & 0 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & u_{m,m} \\end{bmatrix} \\begin{bmatrix} 1 & u_{1,2}/u_{1,1} & \\cdots & u_{1,m}/u_{1,1} \\\\ 0 & 1 & \\cdots & u_{2,m}/u_{2,2} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & 1 \\end{bmatrix} \\end{align*} LU分解可以方便的得到LDU分解：提取对角阵、然后对应矩阵 元素等比缩放 PLU[Q] Decomposition PLU分解：将方阵分解为置换矩阵、下三角、上三角矩阵 PLUQ分解：将方阵分解为置换矩阵、下三角、上三角、置换矩阵 考虑$P^{-1}A=LU$，交换$A$行即可作普通LU分解，PLUQ分解 类似 PLU分解数值稳定性好、实用工具 LL/Cholesky DecompositionLL分解：将对称阵分解为下三角、转置 \\begin{align*} A & = L L^T \\\\ \\begin{bmatrix} a_{1,1} & a_{1,2} & \\cdots & a_{1,m} \\\\ a_{2,1} & a_{2,2} & \\cdots & a_{2,m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m,1} & a_{m,2} & \\cdots & a_{m,m} \\end{bmatrix} & = \\begin{bmatrix} l_{1,1} & 0 & \\cdots & 0 \\\\ l_{2,1} & l_{2,2} & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ l_{m,1} & l_{m,2} & \\cdots & l_{m,m} \\end{bmatrix} \\begin{bmatrix} l_{1,1} & l_{2,1} & \\cdots & l_{m,1} \\\\ 0 & l_{2,2} & \\cdots & l_{m,2} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & l_{m,m} \\end{bmatrix} \\end{align*} Cholesky分解常用于分解$A^TA$ 常用于相关分析，分解相关系数阵、协方差阵 相较于一般LU分解，Cholesky分解速度更快、数值稳定性更好 类似的有LDL分解，同时提取对角线元素即可 Singular Value DecompositionSVD奇异值分解：将矩阵分解为正交矩阵、对角矩阵、正交矩阵 M_{m*n} = U_{m*r} \\Sigma_{r*r} V_{n*r}^T 特征值分解在任意矩阵上推广：相应的特征值、特征向量 被称为奇异值、奇异向量 几何意义：由单位阵出发，经旋转、缩放、再旋转 特点 $\\Sigma$对角线元素为$M^T M$、$M M^T$的奇异值 可视为在输入输出间进行标量的放缩控制 同$U$、$V$的列向量相对应 $U$的列向量称为左奇异向量 $M M^T$的特征向量 与$M$正交的“输入”或“分析”基向量 $V$的列向量成为右奇异向量 $M^T M$的特征向量 与$M$正交的“输出”基向量 低阶近似 对$m * n$阶原始矩阵$M$ 设其秩为$K \\leq min(m, n)$，奇异值为 $d_1 \\geq d_2 \\geq \\cdots \\geq d_K &gt; 0$ 不失一般性可以设其均值为0 根据Eckart and Young的结果 \\forall r \\leq K, \\sum_{k=1}^r d_k u_k v_k^T = \\arg\\min_{\\bar M \\in M(r)} \\| M - \\bar M \\|_F^2 $u_k, v_k$：$U, V$的第$k$列向量 $|M|_F$：矩阵的Frobenius范数 QR DecompositionQR分解：将矩阵分解为正交矩阵、上三角矩阵 \\begin{align*} A = Q R \\end{align*} 几何意义：由单位阵出发，经旋转、切变 特点 正交矩阵逆为其转置，同样可以方便求解线性方程组","link":"/Math-Algebra/Linear-Algebra/matrix_decomposition.html"},{"title":"Hilbert空间","text":"Reproducing Kernel Hilbert Space Hilbert space：假设 $K(x,z)$ 是定义在 $\\mathcal{X X}$ 上的对称函数，并且对任意 $x_1, x_2, \\cdots, x_m \\in \\mathcal{X}$，$K(x,z)$ 关于其的 Gram* 矩阵半正定，则可以根据函数 $K(x,z)$ 构成一个希尔伯特空间 构造步骤定义映射构成向量空间 定义映射 \\phi: x \\rightarrow K(·, x) 根据此映射，对任意 $x_i \\in \\mathcal{X}, \\alpha_i \\in R, i = 1,2,\\cdots,m$ 定义线性组合 f(·) = \\sum_{i=1}^m \\alpha_i K(·, x_i) 由以上线性组合为元素的集合 $S$ 对加法、数乘运算是封闭的，所以 $S$ 构成一个向量空间 定义内积构成内积空间 在 $S$ 上定义运算 $ * $：对任意 $f,g \\in S$ \\begin{align*} f(·) = \\sum_{i=1}^m \\alpha_i K(·, x_i) \\\\ g(·) = \\sum_{j=1}^n \\beta_j K(·, z_j) \\end{align*}定义运算 $ * $ f * g = \\sum_{i=1}^m \\sum_{j=1}^n \\alpha_i \\beta_j K(x_i, z_j) 为证明运算 $ * $ 是空间 $S$ 的内积 需要证明： $(cf) g = c(f g), c \\in R$ $(f + g) h = f h + g * h, h \\in S$ $f g = g f$ $f f \\geq 0, f f = 0 \\Leftrightarrow f = 0$ 其中前3条由 $S$ 元素定义、$K(x,z)$ 对称性容易得到 由 $ * $ 运算规则可得 f * f = \\sum_{i,j=1}^m \\alpha_i \\alpha_j K(x_i, x_j)由 Gram 矩阵非负可知上式右端非负，即 $f * f \\geq 0$ 为证明 $f * f \\Leftrightarrow f = 0$ 首先证明 |f * g|^2 \\leq (f * f)(g * g) 设$f, g \\in S$，则有$f + \\lambda g \\in S$，则有 \\begin{align*} (f + \\lambda g) * (f + \\lambda g) & \\geq 0 \\\\ f*f + 2\\lambda (f * g) + \\lambda^2 (g*g) & \\geq 0 \\end{align*} 则上述关于$\\lambda$的判别式非负，即 (f*g)^2 - (f*f)(g*g) \\leq 0 $\\forall x \\in \\mathcal{x}$，有 K(·, x) * f = \\sum_{i=1}^m \\alpha_i K(x, x_i) = f(x)则有 |f(x)|^2 = |K(·, x) * f|^2 又 |K(·, x) * f|^2 \\leq (K(·, x) * K(·, x))(f * f) = K(x, x)(f*f)则有 |f(x)|^2 \\leq K(x, x) (f * f)即$f * f = 0$时，对任意$x$都有$|f(x)| = 0$ 因为 $ * $ 为向量空间 $S$ 的内积，可以继续用 $ · $ 表示 f·g = \\sum_{i=1}^m \\sum_{j=1}^n \\alpha_i \\alpha_j K(x_i,z_J) 完备化构成Hilbert空间 根据内积定义可以得到范数 \\|f\\| = \\sqrt {f · f}所以 $S$ 是一个赋范向量空间，根据泛函分析理论，对于不完备的赋范空间 $S$ ，一定可以使之完备化得到希尔伯特空间 $\\mathcal{H}$ 此希尔伯特空间 $\\mathcal{H}$ ，称为 reproducing kernel Hilber Space ，因为核 $K$ 具有再生性 \\begin{align*} K(·, x) · f & = f(x) \\\\ K(·, x) · K(·, Z) & = K(x, z) \\end{align*} Positive Definite Kernel Function 设 $K: \\mathcal{X X} \\leftarrow R$ 是对称函数，则 $K(x,z)$ 为正定核函数的充要条件是 $\\forall x_i \\in \\mathcal{X}, i=1,2,…,m$，$K(x,z)$ 对应的 Gram 矩阵 $K = [K(xi, x_j)]{mm} $ 是半正定矩阵 必要性 由于 $K(x,z)$ 是 $\\mathcal{X X}$ 上的正定核，所以存在从 $\\mathcal{X}$ 到 Hilbert* 空间 $\\mathcal{H}$ 的映射，使得 K(x,z) = \\phi(x) \\phi(z) 则对任意 $x_1, x_2, \\cdots, x_m$，构造 $K(x,z)$ 关于其的 Gram 矩阵 [K_{ij}]_{m*m} = [K(x_i, x_i)]_{m*m} 对任意 $c_1, c_2, \\cdots, c_m \\in R$，有 \\begin{align*} \\sum_{i,j=1}^m c_i c_j K(x_i, x_j) & = \\sum_{i,j=1}^m c_i c_j (\\phi(x_i) \\phi(x_j)) \\\\ & = (\\sum_i c_i \\phi(x_i))(\\sum_j c_j \\phi(x_j)) \\\\ & = \\| \\sum_i c_i \\phi(x_i) \\|^2 \\geq 0 \\end{align*}所以 $K(x,z)$ 关于 $x_1, x_2, \\cdots, x_m$ 的 Gram 矩阵半正定 充分性 对给定的 $K(x,z)$，可以构造从 $\\mathcal{x}$ 到某个希尔伯特空间的映射 \\phi: x \\leftarrow K(·, x) 且有 K(x,z) = \\phi(x) · \\phi(z)所以 $K(x,z)$ 是 $\\mathcal{X * X}$ 上的核函数","link":"/Math-Algebra/Universal-Algebra/hilbert.html"},{"title":"Crate、Mod、可见性、文件结构","text":"文件结构规则拆分文件Rust一般库中文件名/文件夹都表示mod （测试文件规则比较特殊） modfoo在其父modbar中声明 如果modfoo没有子mod，将其实现放在foo.rs文件中 若modfoo有子mod，创建文件夹foo，将其实现放在 foo/mod.rs中 以上是文件拆分规则，也可以不拆分文件 库Crate库crate中lib.rs相当于该crate顶层mod（根mod） 所有的mod直接或间接（祖先mod）声明于此，否则不能识别 从引用库crate的外部crate角度来看，其名称和库crate同名 extern crate crate_name;的同时就use crate_name;， 此时可将引用其的mod视为根mod的父mod 库、二进制Cratecrate中可以同时有lib.rs和main.rs，此时库crate和二进制 crate应该看作相互独立 在两处都使用mod关键字声明定义mod（不能在main.rs 中使用use声明使用mod） 在main.rs中使用extern crate crate_name引入 “外部”库crate 可见性规则Mod默认私有 默认仅crate内部可见 父mod处直接可用 兄弟mod、子mod可以通过“回溯“声明使用 pub声明为公用后，对外部crate也可见 Fn默认私有 默认仅mod“内部”可见（包括后代mod） 当前mod内直接可用 子mod可以通过“回溯”声明可用 pub声明为公用后，对外部mod也可见 说明 项（mod、fn）的声明使用路径都是相对于当前项，即默认调用 其后代项（mod、fn），通过以下“回溯”方式调用非直接后代项 super直接父mod路径起始：super::child_mod ::根mod起始：::child_mod fn和mod的可见规则相似的，只是注意：fn是否可见只与mod有关 ，mod是否可见只有crate有关。从这个意义上说，crate不能 看作是“大号“的mod 相关关键字好像都是单一用途（意义），罕见 extern：引入外部crate（同时包含use crate_name;） crate：标记外部crate mod/fn：声明定义（注册）mod/fn（同crate内仅一次 ，位于其父mod处） use：声明使用项（mod、fn），用于缩略代码","link":"/Rust/crate_mod.html"},{"title":"Rust 错误（Panic）处理规范","text":"panic!与不可预期（不可恢复）错误panic!时程序默认开始展开（unwinding）、回溯栈并清理函数据 如果希望二进制文件尽量小，可以选择“终止（abort）”，此时 程序内存由操作系统进行清理，在Cargo.toml中添加 [profile] panic='abort' [profile.release] panic='abort' 前者是配置debug时，后者配置release版本 Result与潜在（可预期、可恢复）错误Result枚举类型Result&lt;T, E&gt;{ Ok&lt;T&gt;, Err&lt;E&gt;, } T：成功时Ok成员中的数据类型 E：失败时Err成员中返回的数据类型 直接处理 对Result值进行模式匹配，分别处理 let f = File::open(“hello.txt”); let mut f = match f { Ok(file) =&gt; file, Err(error) =&gt; panic!(“error:{:?}”, error), } 使用Result上定义的方法（类似以上） Result.unwrap() T = Ok&lt;T&gt;.unwrap() Err&lt;E&gt;.unwrap()使用默认信息调用panic Result.expect(&amp;str) T = Ok&lt;T&gt;.expect(&amp;str) Err&lt;E&gt;.expect(&amp;str)使用&amp;str调用!panic Result.unwrap_or_else Result.unwrap_or_else(|err|{ clojure... }) T = Ok&lt;T&gt;.unwrap_or_else() Err&lt;E&gt;.unwrap_or_else()将E作为闭包参数调用 闭包 Result.is_err() False = Ok&lt;T&gt;.is_err() True = Err&lt;E&gt;.is_err() 传播错误（Propagating）对Result对象进行匹配，提前返回Err&lt;E&gt;，需要注意返回值 类型问题，尤其是在可能存在多处潜在错误需要返回 let f = File:open(&quot;hello.txt&quot;); let mut f match f { Ok(file) =&gt; file, Err(error) =&gt; return Err(error), } ?简略写法（效果同上） let mut f = File::open(&quot;hello.txt&quot;)? ?会把Err(error)传递给from函数（定义在标准库From trait中），将错误从转换为函数返回值中的类型，潜在 错误类型都实现了from函数 ?只能用于返回值为Result类型的函数内，因为其”返回值” 就是Err(E)（如果有）","link":"/Rust/error_handling.html"},{"title":"Rust 所有权、引用、生命周期","text":"变量、值、所有权变量、值 变量：用来代表值进行操作、没有对应内存空间的字符串， 如：a，b 值：在内存中有对应的空间，如：5，”asdf” 变量默认不可变 var变量绑定的值1不能更改，对应的内存数据不能改变 不允许赋值操作，但是变量的声明和绑定可以分开，即使 声明不可变变量，也可以之后绑定值，注意区分 12345678fn ret_int() -&gt; i32{ 5 }// 以下代码可编译，且正确let num = &amp;mut ret_int();*num += 1;// 以下不可let num;num = &amp;mut ret_int();*num += 1; todo 不允许获取可变引用、所有权转移给可变变量（对函数 即限制参数类型，类似于默认const) 若其中包含（或就是）引用，引用值是可以更改的 12let ref = &amp;mut ori;*ref += 1; 但是变量var可以重新绑定为其他的值 虽然值1不能更改，但是var变量可以绑定其他值 12let var = 3;let var = 2; 此时虽然值1虽然无法被访问、使用，但是离开作用域 之前不会被丢弃，只是被“隐藏” 所有权规则 每个值（内存）都有一个称为所有者（owner）的变量 值（内存）有且只有一个所有者 如果多个变量拥有某值（内存）所有权，有可能会多次释放 同一内存，造成内存二次污染 rust中只有一个变量拥有所有权避免内存污染问题 所有者（变量）离开作用域，值将被丢弃（内存被回收） （rust为其调用drop函数） 在生命周期结束时释放资源的方法在C++称为RAII （Resource Aquistion Is Initialization），这里的 initialization是指对资源跟踪、管理初始化，RAII就是 将对象（变量）同资源生命周期相关联，在C++中体现为 析构函数 rust的所有权管理是编译是进行检查，没有runtime性能损失 相较于gc（垃圾回收）性能影响较小 相较于手动分配、释放内存不容易代码疏忽导致的内存问题 所有权转移Drop和Copytrait Drop：值离开作用域时rust自动调用 Copy：赋值时调用，赋值之后原变量仍然可以继续使用 需要分配内存、本身就是某种资源形式不会实现Copy trait，实现 Copy trait类型有 存储在stack上的类型，值拷贝速度快，定长 整型、bool型、浮点型这样（标量）原生数据类型 所有元素都copy的tuple rust不允许任何类型同时同时实现Drop和Copytrait 所有权转移对于没有实现Copytrait的类型：赋值（包括函数传参、返回值） 操作会将原变量所有权转移（move）给新变量，之后不允许使用 原变量，编译时即报错，这样就避免了同时释放同一内存造成 二次污染 有些情况下所有权不允许转移，如vec中元素 实现了Copytrait的类型，赋值（包括函数传参）操作将按照 Copytrait复制一个新值，将新值（包括所有权）赋给新变量， 如此原变量可以之后继续使用，没有违反rust的所有权规则，因为 实际上两个值（内存） Reference（引用）引用（references，&amp;，获取引用作为函数参数称为借用） 单一所有权情况下，仅仅想使用值而不获取所有权，尤其是函数 传参，虽然可以获取所有权之后再将所有权转移，但是操作麻烦， 而且函数返回值可能有其他用途 引用特点 引用允许变量使用值但是不获取所有权 引用离开作用域时不会丢弃其指向的值，不会内存二次污染 分为可变引用、不可变引用，类似于变量绑定 引用规则 任意时间内，特定作用域、特定变量只允许 一个可变引用 任意数量不可变引用 引用必须总是有效的 注意：获取可变引用和引用赋值给可变变量的区别 123456let m = 5;let mut n = &amp;m; //将引用赋值给可变变量let n = &amp;mut m; //获取可变引用赋值给变量，这里会报错，因为`m`是不可变 //变量，不允许通过其获取可变引用 规则1第一条规则避免以下情况导致的数据竞争 多个指针可以访问同一数据 至少有一个指针可以写入数据 没有有效的同步数据访问机制 这条规则在显式的赋值、声明易发现、遵守，需要注意的是 函数调用创建可变引用 自运算符创建可变引用（+=、*=） 规则2rust会在编译时检查引用是否有效，即引用是否是悬垂指针 悬垂指针：指向的内存已经被分配给其他所有者或值被丢弃， 常见于函数中返回局部变量 对于rust中的“变量（有所有权）”而言则不存此问题 赋值操作要么转移所有权，值不会被丢弃 要么实现copytrait，返回新值 解引用rust中引用更像c中的指针 引用有对应的解引用（dereferance），且“多层次”引用也需要 ”多层次“解引用 教程上的引用附图也是引用“指向”原“变量”，不是“值（内存）” 自动引用和解引用 方法中self +自己实现了解引用（不知道是否算自动解引用）12impl&lt;'a&gt; Add&lt;&amp;'a i32&gt; for i32{}impl Add&lt;i32&gt; for i32{} todo 生命周期 rust每个引用都有生命周期，即引用保持有效的作用域 （避免悬垂引用） 大部分情况下，生命周期是隐含、可推断的 （类似于类型可推断） 借用检查器（编译器一部分）可以分析函数代码得到引用的 生命周期，通过作用域确保借用有效 但是函数被调用、被函数之外的代码引用时，每次生命周期 都不一样，rust无法分析 有时也会出现引用生命周期以一些不同的方式相关联，此时需要 使用泛型生命周期参数标注关系 生命周期注解语法 生命周期参数必须以”’“开头（和一般泛型参数区别） 参数名称通常小写 位于引用”&amp;“之后，”mut“（如果存在）之前 函数生命周期注解只存在于函数签名中 1234567fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str{ if x.len() &gt; y.len(){ x }else{ y }} 生命周期注解并不改变参数、返回值的生命周期，只是在 函数签名中增加了生命周期“协议” 函数体中返回值不遵守“协议”，函数体编译错误 传参、返回值接收变量不遵守“协议”，调用处编译错误 生命周期注解是用于联系函数不同参数和返回值的生命 周期，一旦形成某种联系，编译器就能获取足够信息判断 引用是否有效（是否内存安全、产生悬垂指针） 生命周期注解是为了保证函数返回值引用有效，同函数 用途有关，因此以下签名也可以通过编译 123fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;str) -&gt; &amp;a' str{ x} 生命周期注解省略规则 每个是引用的参数都有自己的输入生命周期参数 如果只有一个输入生命周期参数，会被赋予所有输出生命周期 参数 若方法存在多个输入生命周期参数，且首个参数self 为引用（&amp;self、&amp;mut self），将其生命周期参数赋给 所有输出生命周期参数 编译器检查完以上三条规则之后，所有引用均有生命周期参数，则 无需额外生命周期注解，但是若函数体返回值不遵守“协议”，仍 无法编译通过 1234567impl&lt;'a&gt; stct&lt;'a&gt;{ fn other_str(&amp;self, &amp;str1) -&gt; &amp;str{ str1 }}// 检查完规则之后，所有引用均有注解，但是// 函数体中的生命周期和签名中不一致 这个例子说明生命周期注解不只是“注解”，是真的需要例子考虑 返回值的生命周期 结构体生命周期注解在结构体成员为引用时需要增加生命周期注解 123struct ImportantExcerpt&lt;'a&gt;{ part: &amp;'a str,} 此类结构体在实现方法时不能省略生命周期注解，方法签名可根据 规则省略注解 1234impl&lt;'a&gt; ImportantExcerpt&lt;'a&gt;{ fn (&amp;self){ }} 泛型结构体（枚举）作为函数参数、返回值类型时，替换泛型参数 为引用时也需要添加生命周期注解 12fn new(args: &amp;[String]) -&gt; Result&lt;Config, &amp;'a str&gt;{}fn search&lt;'a&gt;(query: &amp;str, contents: &amp;'a str) -&gt; Vec&lt;&amp;'a str&gt;{} 静态生命周期（'static） 存活于整个程序生命期间 所有的&amp;str（字符串字面值）都拥有'static生命周期 可以用于指定引用的生命周期，但是使用之前三思，应先考虑 悬垂引用、生命周期不匹配的问题 高级生命周期Lifetime Subtyping生命周期子类型：确保某个生命周期长于另一个生命周期 1234567891011121314151617181920212223242526struct Context&lt;'s&gt;(&amp;'s str);struct Parser&lt;'c, 's: 'c&gt;{ //`'s: 'c`声明一个不短于`'c`的生命周期`'s` context: &amp;'c Context&lt;'s&gt;;}impl&lt;'c, 's: 'c&gt; Parser&lt;'c, 's: 'c&gt;{ fn parse(&amp;self) -&gt; Result&lt;(), &amp;'s str&gt;{ //根据生命周期省略规则，若`'s`省略，则赋予`&amp;self`的 //生命周期 //使用生命周期子类型语法，指定（要求）`&amp;str`生命周期 //长于`&amp;Context` Err(&amp;self.context.0[1..] //这里没有考虑字符串切片的有效性，如果这个切片不是 //有效的unicode字符串（utf8字节序列），会panic }}fn parse_context(context: Context) -&gt; Result&lt;(), &amp;str&gt;{ //方法获取`context`的所有权 Parser{ context: &amp;Context }.parse() //`&amp;Context`的生命周期只有整个函数内 //函数体中的返回值是`context.0[1..]`，为保证返回值有效， //其生命周期必须长于整个函数 //返回值中的`&amp;str`类型的生命周期是`'s`，长于context`'c` //满足返回值的生命周期长于函数的要求，能编译通过} Lifetime Bounds生命周期bounds：帮助Rust验证泛型引用不会比其引用的数据存在 更久 12345struct Ref&lt;'a, T: 'a&gt; { &amp;'a T }; //为`T`增加生命周期bound，指定`T`引用的生命周期不短于 //`'a`，保证结构体成员有效struct StaticRef&lt;T: 'static&gt; { &amp;'static T }; //限制`T`为只拥有`'static`生命周期的引用或没有引用的类型 trait对象生命周期推断123456789trait Red {}struct Ball&lt;'a&gt; { diameter: &amp;'a i32,}impl&lt;'a&gt; Red for Ball&lt;'a&gt; {}fn main(){ let num = 5; let obj = Box::new(Ball {diameter: &amp;num}) as Box&lt;Red&gt;;} 以上代码能编译通过，因为生命周期和trait对象必须遵守： trait对象默认的生命周期为'static 若有&amp;'a X或&amp;'a mut x，则默认生命周期为'a 如有T: 'a从句，则默认生命周期为'a 若有多个类似T: 'a从句，则需明确指定trait对象生命周期， Box&lt;Red + 'a&gt;或Box&lt;Red + 'static&gt;todo 正如其他bound，任何Redtrait的实现内部包含引用，必须拥有和 trait对象bound中所指定的相同的生命周期","link":"/Rust/ownership.html"},{"title":"Rust 测试","text":"测试常用宏、属性注解宏 assert!(exp,...) assert_eq!(val1, val2,...) assert_ne!(val1, val2,...) 以上宏均可以传入自定义信息，所有的...中参数都将传递给 format!宏 属性注解 #[test]：$&gt;cargo test时将测试此函数 #[ignore]：除非指定，否则$&gt;cargo test默认不测试此 函数（仍需和#[test]注解） #[should_panic(expected=&amp;str)]：测试中出现panic测试 通过，可以传递expected参数，当参数为panic信息的起始 子串才通过 cargo test命令命令行参数和可执行文件参数用“—”分隔 1$&gt;cargo test cargo_params -- bin_params 可执行文件常用参数 控制测试线程数目1$&gt;cargo test -- --test-thread=1（不使用任何并行机制） 禁止捕获输出（测试函数中的标准输出）1$&gt;cargo test -- --nocapture 测试#[ignore]标注的测试函数1$&gt;cargo test -- --ignore 命令行常用参数 指定部分测试函数1$&gt;cargo test function_name（cargo匹配以此开头的函数） 指定部分集成测试文件1$&gt;cargo test --test test_filename 单元测试、集成测试单元测试在隔离环境中一次测试一个模块，可以测试私有接口，常用做法是 在每个文件中创建包含测试函数的tests模块，并使用 #[cfg(test)]标注，告诉rust仅在cargo test时才编译该mod 集成测试相当于外部库，和用户使用代码的方式相同，只能测试公有接口， 可以同时测试多个模块 新建/project/tests目录（和src同级），cargo自动寻找此目录 中集成测试文件 cargo将每个文件当作单独的crate编译（模仿用户） 其中的文件也不能共享相同的行为（fn、mod） 需要像外部用户一样extern crate引入外部文件，因此 如果二进制库没有lib.rs文件，无法集成测试，推荐 采用main.rs调用lib.rs的逻辑结构 不需要添加任何#[cfg(test)]注解，cargo会自动将 tests中文件只在cargo test时编译 即使文件中不存在任何#[test]注解的测试函数，仍然会 对其进行测试，只是结果永远是通过 而文件夹则不会当作测试crate编译 cargo test不会将文件夹视为测试crate，而是看作 一个mod 所以可以创建tests/common/mod.rs，并在测试文件中 通过mod common;声明定义common mod共享行为 （相当于所有的测试crate = 测试文件 + common mod）","link":"/Rust/test.html"},{"title":"Rust技巧","text":"代码省略 for i in i.iter() array[m..n] 问题明确 rust中slice也是左闭右开区间 其他技巧 随便定义变量数据类型，编译后通过编译器给出的信息得到 某个函数返回值类型","link":"/Rust/twistes.html"},{"title":"Unsafe Rust","text":"不安全的Rust存在原因 Rust在编译时强制执行内存安全保证，但这样的静态分析是 保守的，有些代码编译器认为不安全，但其实合法 底层计算机硬件的固有的不安全性，必须进行某些不安全操作 才能完成任务 因此需要通过unsafe关键字切换到不安全的Rust，开启存放 不安全代码的块，只能在不安全Rust中进行的操作如下 解引用裸指针， 调用不安全的函数、方法 访问或修改可变静态变量 实现不安全trait 需要注意的是，unsafe不会关闭借用检查器或其它Rust安全检查， 在不安全Rust中仍然会检查引用，unsafe关键字只告诉编译器忽略 上述4中情况的内存安全检查，此4种的内存安全由用户自己保证， 这就保证出现内存安全问题只需要检查unsafe块。可以将不安全 代码封装进安全的抽象并提供API，隔离不安全代码。 解引用裸指针（raw pointer） *const T：T类型不可变裸指针 *mut T：T类型可变裸指针 裸指针的上下文中，裸指针意味着指针解引用后不能直接赋值， 裸指针和引用、智能指针的区别 允许忽略借用规则，允许同时拥有不可变和可变指针，或者 多个相同位置（值）的可变指针 不保证指向有效的内存 允许为空 不能实现任何自动清理功能 12345678910111213141516let mut num = 5;let r1 = &amp;num as *const i32;let r2 = &amp;num as *mut i32; //`as`将不可变引用和可变引用强转为对应的裸指针类型 //同时创建`num`的可变裸指针和不可变裸指针 //创建裸指针是安全的unsafe{ println!(&quot;r1 is: {}&quot;, *r1); println!(&quot;r2 is: {}&quot;, *r2); //解引用裸指针是不安全的，需要放在`unsafe`块中}let address = 0x012345usize; //创建任意地址let r = address as *const i32; //创建指向任意内存地址的裸指针 调用不安全的函数或方法不安全函数和方法类似常规，在开头有unsafe关键字标记，表示 函数含有内存不安全的内容，Rust不再保证此函数内存安全，需要 程序员保证。 但是包含不安全代码并不意味着整个函数都需要标记为不安全，相反 将不安全代码封装于安全函数中是隔离unsafe代码的方法。应该 将不安全代码与调用有关的函数标记为unsafe。 1234567891011121314unsafe fn dangerous() {} //`unsafe`关键字表示此函数为不安全函数，含有内存不安全 //内容，需要程序员自身保证其内存安全 //但是，包含不安全代码的函数不意味着整个函数都需要标记为 //不安全，相反的，将不安全代码封装进安全函数是常用的 //不安全函数体也是`unsafe`块，在其中进行不安全操作时， //不需要包裹于`unsafe`块unsafe{ dangerous(); //调用不安全函数也需要在`unsafe`块中，表示调用者确认此 //“不安全”函数在此上下文中是*内存安全*} 调用不安全的函数时也需要放在unsafe中，表示程序员确认此函数 在调用上下文中是内存安全的。 split_at_mut的实现1234567let mut v = vec![1, 2, 3, 4, 5, 6];let r = &amp;mut v[..];let (a, b) r.split_at_mut(3); //以index=3分隔为两个列表引用（左开右闭）assert_eq!(a, &amp;mut [1, 2, 3]);assert_eq!(b, &amp;mut [4, 5, 6]); split_at_mut方法无法指通过安全Rust实现，一个大概的“函数” 实现可以如此 123456789101112131415161718192021222324use std::slice;fn split_at_mut(slice: &amp;mut [i32], mid: usize) -&gt; (&amp;mut [i32], &amp;mut [i32]) { //这里根据生命周期省略规则省略了生命周期注解 //在所有权里就有提到，这里不也是可变引用吗，为啥这样 //还可以通过编译，是对方法中的`self`有特殊的处理吗 let len = slice.len(); let ptr = slice.as_mut_ptr(); //`as_mut_ptr`返回`*mut T`可变裸指针 assert!(mid &lt;= len); unsafe{ (slice::from_raw_parts_mut(ptr, mid), //`from_raw_parts_mut`根据裸指针和长度两个参数 //创建slice，其是不安全的，因为其参数是一个 //裸指针，无法保证内存安全，另外长度也不总是有效 slice::from_raw_parts_mut(ptr.offset(mid as isize), len - mid)) //`offset`同样是不安全的，其参数地址偏移量无法 //保证始终有效 }} 使用extern函数调用外部代码extern关键字用于创建、使用外部函数接口 外部函数接口FFI：foreign function interface，编程语言 用以定义函数的方式，允许不同（外部）编程语言调用这些 函数 应用程序接口ABI：application binary interface，定义了 如何在汇编层面调用函数 12345678910extern &quot;C&quot; { //`&quot;C&quot;`定义了外部函数所使用的ABI fn abs(input: i32) -&gt; i32; //希望调用的其他语言中的（外部）函数签名}fn main(){ unsafe{ println!(&quot;absolute value of -3 according to C: {}&quot;, abs(-3)); }} extern块中声明的函数总是不安全的，因为其他语言并不强制执行 Rust的内存安全规则，且Rust无法检查，因此调用时需要放在 unsafe块中，程序员需要确保其安全 通过其他语言调用Rust函数123456#[no_mangle] //告诉Rust编译器不要mangle此函数名称pub extern &quot;C&quot; fn call_from_c(){ //此函数编译器为动态库并从C语言中链接，就可在C代码中访问 println!(&quot;just called a Rust function from C!&quot;);} mangle发生于编译器将函数名修改为不同的名称，这会增加 用于其他编译器过程中的额外信息，但是会使其名称难以阅读 而不同的编程语言的编译器mangle函数名的方式可能不同 访问或修改可变静态变量全局变量：Rust中称为静态（static）变量 12345static HELLO_WORLD: &amp;str = &quot;Hello, world!&quot;; //静态变量（不可变）fn main(){ println!(&quot;name is: {}&quot;, HELLO_WORLD);} 名称采用SCREAMING_SNAKE_CASE写法，必须标注变量类型 只能存储‘static生命周期的引用，因此无需显著标注 不可变静态变量和常量（不可变变量）有些类似 静态变量值有固定的内存地址，使用其总会访问相同地址 常量则允许在任何被用到的时候复制数据 访问不可变静态变量是安全的，但访问、修改不可变静态变量都是 不安全的，因为可全局访问的可变数据难以保证不存在数据竞争， 因此在任何可能情况，优先使用智能指针，借助编译器避免数据竞争 123456789101112131415161718static mut COUNTER： u32 = 0; //可变静态变量fn add_to_count(inc: u32){ unsafe { COUNTER += inc; //修改可变静态变量 }}fn main(){ add_to_count(3); unsafe{ println!(&quot;COUNTER: {}&quot;, COUNTER); //访问可变静态变量 }} 实现不安全trait存在方法中包含编译器不能验证的不变量的trait时不安全的，可以 在trait前增加unsafe将trait生命为unsafe，且实现trait 也需要标记为unsafe 1234unsafe trait Foo{}unsafe impl Foo for i32{} 如为裸指针类型实现（标记）Send、Synctrait时需要标记 unsafe，因为Rust不能验证此类型可以安全跨线程发送或多线程 访问，需要自行检查","link":"/Rust/unsafe_rust.html"},{"title":"Fenchel-Legendre Duality","text":"Legendre Transformation勒让德变换：用 $f^{ * }(p)$ 表示凸、可导函数 $f(x)$ 的变换，其中 $p$ 是 $f(x)$ 导数 f^{*}(p) = p^T x - f(x)|_{\\frac {d(p^T x - f(x))} {dx} = 0} $x$：参数，满足 $\\frac {d(p^T x - f(x))} {dx} = 0$，随 $p$ 取值改变 可导：有导数；凸：导数唯一 勒让德变换是实变量的实值凸函数的对合变换 把定义在线性空间上的函数变换至对偶空间的函数 是点、（切）线之间对偶关系的应用 严格凸函数中，切线、导数一一对应 函数关系 $f(x)$ 可使用 $(x, y=f(x))$ 点集表示，也可用切线集合表示 involution 对合：对合函数 $f$ 的反函数的为自身，即 $f(f(x))=x$；对合线性变换 $V$ 满足 $V^2 = E$ Legendre 变换理解（按 Fenchel 共轭） $f^{*}(p)$：可理解为斜率为 $p$、同 $f(x)$ 有交点 $x_0$ 的直线在零点处值（截距）和 $f(x_0)$ 的最大差 $x$：可以理解为函数 $f(x)$ 上距离给定斜率为 $p$、过原点的直线 $f(x)=px$ 竖直距离最大的点 类似一个端点为 $0$ 的 Bregman 散度 Legendre 变换为对合变换，进行两次的变换得到原函数 \\begin{align*} f^{**}(x) & = \\sup_{p \\in dom(f^{*})} [x^T p - f^{*}(p)] \\\\ & = \\sup_{u \\in dom(f)}[x^T \\nabla f(u) - \\nabla f(u)^T u + f(u)] \\\\ & = \\sup_{u \\in dom(f)}[f(u) + \\nabla f(u)^T (x-u)] \\\\ & = f(x) \\end{align*} 若视凸函数 $f(x)$ 视为积分，则其共轭 $f^{ * }(x)$ 为对另一轴积分，二者导函数互为反函数 f(x) + f^{*}(p) = xp, p = \\frac {df(x)} {dx} 以上性质均按 Fenchel 共轭，但要求 $f(x)$ 为凸、可导函数，故等价于 Legendre 变换 Legendre 变换最大值式定义\\begin{align*} L(p, x) &= px - f(x) \\\\ \\frac {\\partial (px - f(x))} {\\partial x} &= p - \\frac {df(x)} {dx} = 0 \\\\ \\Rightarrow & p = \\frac {df(x)} {dx} \\end{align*} Legendre 变换可以视为寻找 $px-f(x)$ 最大值（如前述） $f(x)$ 为凸函数，则 $p=\\frac {df(x)} {dx}$ 是最大值点 则将 $f(x)$ 导函数的反函数 $x=f^{-1}(p)$ 带入即可 Legendre 变换数学性质 标度性质 \\begin{align*} f(x) & = a g(x) \\rightarrow f^{*}(p) = a g^{*}(\\frac p a) \\\\ f(x) & = g(ax) \\rightarrow f^{*}(p) = g^{*}(\\frac p a) \\end{align*}由此，$r$次齐次函数的勒让德变换是$s$次齐次函数，满足 \\frac 1 r + \\frac 1 s = s 平移性质 \\begin{align*} f(x) & = g(x) + b \\rightarrow f^{*}(p) = g^{*}(p) - b f(x) & = g(x+y) \\rightarrow f*^{*}(p) = g^{*}(p) - py \\end{align*} 反演性质 f(x) = g^{-1}(x) \\rightarrow f^{*}(p) = -p g^{*}(\\frac 1 p) 线性变换性质 (Af)^{*} = f^{*}A^{*} $f$：$R^n$上的凸函数 $A$：$R^n \\rightarrow R^m$的线性变换 $A^{}: &lt;Ax, y^{}&gt; = $：$A$伴随算子 Fenchel Conjugate / 凸共轭 f^{*}(p) = \\sup_{x \\in R}{p^Tx - f(x)} Fenchel 共轭是对 Legendre 变换的扩展，不再局限于凸、可导函数 Fenchel 共轭可类似 Legendre 理解，但是适用范围更广 对凸函数 Fenchel 共轭的共轭即为原函数，对非凸函数 Fenchel 共轭得到原函数凸包 用罗尔中值定理描述极值、导数关系：兼容 Legendre 变换中导数支撑面 非凸函数线性外包络是凸函数 Fenchel-Young不等式 f(x) + f^{*}(p) \\geq 证明 \\begin{align*} f(x) + f^{*}(p) & = f(x) + \\sup_{x \\in dom(f)} {(x^T p - f(x))} \\\\ & \\geq f(x) + x^T p - f(x) = x^T p \\end{align*} 按积分理解，仅$p$为$x$共轭时取等号 Fenchel Conjugate 推导 Lagrange Duality 原问题 Prime \\begin{align*} & \\min {f(x)} \\\\ s.t. & g(x) \\leq 0 \\\\ \\end{align*} 约束条件 $g(x) \\leq 0$ 扰动函数化、求 Fenchel 共轭 \\begin{align*} p(u) & = \\inf_{x \\in X, g(x) \\leq u} f(x) \\\\ p^{*}(y) & = \\sup_{y \\in R^r} \\{u^T y - p(u)\\} \\end{align*} 记 $\\lambda = -y$，并将 $y=-\\lambda$ 带入 $-p^{*}(y)$ 中得到 \\begin{align*} -p^{*}(y) & = \\inf_{u \\in R^r} \\{p(u) - u^T y\\} \\\\ d(\\lambda) & = \\inf_{u \\in R^r} \\{p(u) + u^T \\lambda\\} \\\\ & = \\inf_{u \\in R^r} \\{\\inf_{x \\in X, g(x) \\leq u} f(x) + \\lambda^T u\\} \\end{align*} $\\lambda = -y$ 将 $\\inf_{x \\in X, g(x) \\leq u}$ 外提，并考虑到约束 $g(x) \\leq u$（即 $u \\geq g(x)$），则 \\begin{align*} \\lambda \\geq 0 & \\Rightarrow \\lambda^T g(x) \\leq \\lambda u \\\\ d(\\lambda) & = \\left \\{ \\begin{array}{l} \\inf_{x \\in X} \\{f(x) + \\lambda^T g(x)\\}, & \\lambda \\geq 0 \\\\ -\\infty, & otherwise \\end{array} \\right. \\end{align*} 考虑 Fenchel 不等式 \\begin{align*} p(u) + p^{*}(-y) & \\geq u^T (-y) \\\\ p(0) + p^{*}(-y) & \\geq 0 \\\\ p(0) & \\geq -p^{*}(-y) \\\\ p(0) & \\geq d(\\lambda) \\end{align*} 则可得 Lagrange 对偶 Prime、Dual 最优关系 L(x, \\lambda) = f(x) + \\lambda^T g(x), \\lambda \\geq 0 \\\\ D^{*} := \\max_{\\lambda \\geq 0} \\min_x L(x, \\lambda) \\leq \\min_x \\max_{\\lambda \\geq 0} L(x, \\lambda) =: P^{*} Lagrange Duality 推导 Fenchel 对偶 Fenchel 对偶可以视为 Lagrange 对偶的应用 原问题、等价问题 \\begin{align*} & \\min_x & f(x) - g(x) \\\\ \\Leftrightarrow & \\min_{x,z} & f(x) - g(z) \\\\ & s.t. & x = z \\end{align*} 对上式取 Lagrange 对偶 $L(u)$、等价得到 \\begin{align*} L(u) &= \\min_{x,z} f(x) - g(z) + u^T(z-x) \\\\ &= -(f^{*}(u) - g^{(-u)}) \\end{align*} Fenchel 对偶：寻找截距差值最大的平行切线","link":"/Math-Analysis/Optimization/fenchel_duality.html"},{"title":"Fourier Transformation","text":"Fourier Transformation（连续）傅里叶变换：将时域映射到频域的变换 F(\\xi) = \\int_{-\\infty}^{+\\infty} f(x) e^{-2\\pi ix \\xi} dx $x$：自变量，多表示时间 $F(\\xi)$：频率 傅里叶变换理解 将自变量 $x$ 线性映射为极坐标系中角度，调整线性映射的比例（即频率），即可绘制出不同的曲线 计算不同频率下曲线围成的图像的质心（径向）坐标 质心的角度坐标只需原函数沿 $x$ 轴平移即可改变 若原图像不关于 $x$ 轴对称，则质心在频率 0 点处有较大值 据以上：周期函数映射在极坐标系下图像，其质心位置在对应频率下取波峰值 https://charlesliuyx.github.io/2018/02/18/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E8%AE%A9%E4%BD%A0%E6%B0%B8%E8%BF%9C%E5%BF%98%E4%B8%8D%E4%BA%86%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E8%A7%A3%E6%9E%90/ 傅里叶变换计算 利用复数项 $e^{-2\\pi ix \\xi}$ 表示在复平面中的旋转角度 $x$ 为函数自变量，$\\xi$ 为频率（即自变量映射比例） 傅里叶变换中旋转为缺省为顺时针，所以补足负号 函数在复平面中则表示为 $f(x) e^{-2\\pi ix \\xi}$ 函数围成的曲线质心则为 $\\frac 1 {x2 - x_1} \\int{x_1}^{x_2} f(x) e^{-2\\pi ix \\xi} dx$ 系数 $\\frac 1 {x_2 - x_1}$ 将积分结果放缩回质心，可省略 将原积分区域外函数值定为 0，积分上下限扩展至 $-\\infty, \\infty$ 不影响积分结果 函数有效取值部分越长，质心波动约迅速 傅里叶变换Discrete Fourier TransformationDFT：归一化二维离散傅里叶变换 \\begin{align*} F(u,v) & = \\frac 1 {\\sqrt{NM}} \\sum_{x=0}^{N-1} \\sum_{y=0}^{M-1} f(x,y) e^{-\\frac {2\\pi i} N ux} e^{-\\frac {2\\pi i} M vy} \\\\ f(x,y) & = \\frac 1 {\\sqrt{NM}} \\sum_{u=0}^{N-1} \\sum_{v=0}^{M-1} F(u,v) e^{\\frac {2\\pi i} N ux} e^{\\frac {2\\pi i} M vy} \\\\ \\end{align*}Discrete Consine Transformation余弦变换 在给定区间为满足狄利克雷条件的连续实对称函数，可以展开为 仅含余弦项的傅里叶级数 对于定义在正实数域上的函数，可以通过偶延拓、或奇延拓满足 上述条件 离散余弦变换 $(x,y) or (u,v) = (0,0)$时 \\begin{align*} F(u,v) & = \\frac 1 N \\sum_{x=0}^{N-1} \\sum_{y=0}^{N-1} f(x,y) cos[\\frac \\pi N u(x + \\frac 1 2)] cos[\\frac \\pi N v(y + \\frac 1 2)] \\\\ f(x,y) & = \\frac 1 N \\sum_{u=0}^{N-1} \\sum_{v=0}{N-1} F(u,v) cos[\\frac \\pi N u(x + frac 1 2)] cos[\\frac \\pi N v(y + \\frac 1 2)] \\end{align*} 其他 \\begin{align*} F(u,v) & = \\frac 1 {2N} \\sum_{x=0}^{N-1} \\sum_{y=0}^{N-1} f(x,y) cos[\\frac \\pi N u(x + \\frac 1 2)] cos[\\frac \\pi N v(y + \\frac 1 2)] \\\\ f(x,y) & = \\frac 1 {2N} \\sum_{u=0}^{N-1} \\sum_{v=0}{N-1} F(u,v) cos[\\frac \\pi N u(x + frac 1 2)] cos[\\frac \\pi N v(y + \\frac 1 2)] \\end{align*}","link":"/Math-Analysis/Fourier-Analysis/fourier_transform.html"},{"title":"Lagrange 对偶","text":"Langrangian Duality拉格朗日对偶 考虑优化问题：找到$f(x)$满足约束的最好下界 z^{*} = \\min_{x} f(x) \\\\ \\begin{align*} s.t. \\quad & g_i(x) \\leq 0, i=1,2,\\cdots,m \\\\ & x \\in X \\end{align*} 考虑方程组 \\left \\{ \\begin{array}{l} f(x) < v \\\\ g_i(x) \\leq 0, i=1,2,\\cdots,m \\end{array} \\right. 方程组无解：$v$是优化问题的一个下界 方程组有解：则可以推出 \\forall \\lambda \\geq 0, \\exists x, f(x) + \\sum_{i=1}^m \\lambda_ig_i(x) < v 显然，取$g_1 + g_2 = 0, g_1(x) &gt; 0$是反例，不能 推出原方程有解 由以上方程组有解逆否命题：方程组无解充分条件如下 \\exists \\lambda \\geq 0, \\min_{x} f(x) + \\sum _{i=1}^m \\lambda_ig_i(x) \\geq v 由此方法推出的最好下界，即拉格朗日对偶问题 v^{*} = \\max_{\\lambda \\geq 0} \\min_{x} f(x) + \\sum_{i=1}^m \\lambda_ig_i(x) 说明 拉格朗日对偶对实数域上的优化问题都存在，对目标函数、 约束函数都没有要求 强对偶定理：$v^{} = z^{}$，需要$f,g$满足特定条件才成立 线性规划 半正定规划 凸优化 即需要给约束条件加以限制，使得 \\forall \\lambda \\geq 0, \\exists x, f(x) + \\sum_{i=1}^m \\lambda_ig_i(x) < v 是上述方程组有解的冲要条件 弱对偶定理：$v^{} \\leq z^{}$，永远成立（以上即可证） 通过弱对偶定理，可以得到原问题的一个下界 对求解原问题有帮助，比如：分支界限法中快速求下界 对偶问题相关算法往往原问题算法在实际应用中往往更加有效 dual-simplex primal-dual interior point method augmented Lagrangian Method 原始问题约束最优化问题 \\begin{array}{l} \\min_{x \\in R^n} & f(x) \\\\ s.t. & c_i(x) \\leq 0, i = 1,2,\\cdots,k \\\\ & h_j(x) = 0, j = 1,2,\\cdots,l \\end{array}Generalized Lagrange Function 引入Generalized Lagrange Function L(x, \\alpha, \\beta) = f(x) + \\sum_{i=1}^k \\alpha_i c_i(x) + \\sum_{j=1}^l \\beta_j h_j(x) $x=(x_1, x_2, \\cdots, x_n) \\in R^n$ $\\alpha_i \\geq 0, \\beta_j$：拉格朗日乘子 考虑关于x的函数 \\theta_P(x) = \\max_{\\alpha, \\beta: \\alpha_i \\geq 0} L(x, \\alpha, \\beta) $P$：primal，原始问题 若x满足原始问题的两组约束条件，则$\\theta_P(x)=f(x)$ 若x违反等式约束j，取$\\beta_j \\rightarrow \\infty$， 则有$\\theta_P(x) \\rightarrow \\infty$ 若x违反不等式约束i，取$\\alpha_i \\rightarrow \\infty$ ，则有$\\theta_P(x) \\rightarrow \\infty$ 则有 \\theta_P(x) = \\left \\{ \\begin{array}{l} f(x), & x 满足原始问题约束条件 \\\\ +\\infty, & 其他 \\end{array} \\right. 则极小化问题，称为广义拉格朗日函数的极小极大问题 \\min_x \\theta_P(x) = \\max_{\\alpha, \\beta: \\alpha_i \\geq 0} L(x, \\alpha, \\beta)与原始最优化问题等价，两问题最优值相同，记为 p^{*} = \\min_x \\theta_P(x) 对偶问题 定义 \\theta_D (\\alpha, \\beta) = \\min_x L(x, \\alpha, \\beta) 再考虑极大化$\\theta_D(\\alpha, \\beta)$，得到广义拉格朗日 函数的极大极小问题，即 \\max_{\\alpha, \\beta: \\alpha \\geq 0} \\theta_D(\\alpha, \\beta) = \\max_{\\alpha, \\beta: \\alpha \\geq 0} \\min_x L(x, \\alpha, \\beta)表示为约束最优化问题如下 \\begin{align*} \\max_{\\alpha, \\beta} & \\theta_D(\\alpha, \\beta) = \\max_{\\alpha, \\beta} \\min_x L(x, \\alpha, \\beta) \\\\ s.t. & \\alpha_i \\geq 0, i=1,2,\\cdots,k \\end{align*}称为原始问题的对偶问题，其最优值定义记为 d^{*} = \\max_{\\alpha, \\beta: \\alpha \\geq 0} \\theta_D(\\alpha, \\beta) 原始、对偶问题关系定理1 若原始问题、对偶问题都有最优值，则 d^{*} = \\max_{\\alpha, \\beta: \\alpha \\geq 0} \\min_x L(x, \\alpha, \\beta) \\leq \\min_x \\max_{\\alpha, \\beta: \\alpha \\geq 0} L(x, \\alpha, \\beta) = p^{*} $\\forall x, \\alpha, \\beta$有 \\theta_D(\\alpha, \\beta) = \\min_x L(x, \\alpha, \\beta) \\leq L(x, \\alpha, \\beta) \\leq \\max_{\\alpha, \\beta: \\alpha \\geq 0} = \\theta_P(x)即 \\theta_D(\\alpha, \\beta) \\leq \\theta_P(x) 而原始、对偶问题均有最优值，所以得证 设$x^{}$、$\\alpha^{}, \\beta^{}$分别是原始问题、对偶 问题的可行解，且$d^{} = p^{*}$，则其分别是原始问题、 对偶问题的最优解","link":"/Math-Analysis/Optimization/lagrange_duality.html"},{"title":"内点法","text":"","link":"/Math-Analysis/Optimization/inner_pointer.html"},{"title":"外点法","text":"","link":"/Math-Analysis/Optimization/outer_pointer.html"},{"title":"Projected Gradient Descent","text":"Projected Gradient Descent受限优化问题 \\min_{x \\in C} f(x) $C \\subseteq R^d$：受限凸集 投影梯度下降：采用后处理的方式，将迭代位置拉回到约束条件内 使用一般下降算法进行位置更新，新位置$x_{t+1}^{‘}$可能 不再满足约束条件 为使新位置$x{t+1}^{‘}$符合受限集合，可以选择在$L_2$范数 下距离受限集合$C$最近的的点 $x{t+1}=\\arg\\min{x \\in C} |x - x{t+1}^{‘}|$作为下步 真正迭代位置 线性约束Projection Matrix 投影矩阵：矩阵$P \\in R^{n*n}$，若满足$P^T = P, P^2 = P$ 若$A \\in R^{m*n}$为行满秩矩阵，则$A$的零空间为 $L_A = {x \\in R^{n} | Ax = 0}$，对应正交空间为 $L_A^{\\perp} = {A^T y | y \\in R^m}$ 对$\\forall x \\in R^n$进行正交分解 \\begin{align*} \\forall x \\in R^n, x & = x_1 + x_2, x_1 \\in L_A, x_2 \\in L_A^{\\perp} \\\\ x_1 & = P_A x \\end{align*} $P_A = I - A^T (A A^T)^{-1} A$：$A$的投影矩阵 投影矩阵$P_A$可由点对线性约束的投影定义，利用拉格朗日 求解 证明 \\begin{align*} x_1 & = x - x_2 = x - A^T y \\\\ A x_1 & = A x - A A^T y \\\\ \\Rightarrow y & = (A A^T)^{-1} A (x - x_1) \\\\ \\Rightarrow x_1 & = x - A^T[(A A^T)^{-1} A (x - x_1)] \\\\ & = x - A^T (A A^T)^{-1} A x - A^T (A A^T)^{-1} A x_1 \\\\ & = (I - A^T (A A^T)^{-1} A) x = P_A x \\end{align*} 投影矩阵$P$对值应用多次线性变换和只应用一次结果相同， 保持像不变 Projection Operator\\begin{array}{l} \\min & f(x) \\\\ s.t. & A_1 x \\leq b_1 \\\\ & A_2 x = b_2 \\end{array} 设$x^{k}$为当前迭代点，记$A{11}$、$A{12}$分别为紧、松 约束，即 \\begin{align*} A_1 & = \\begin{bmatrix} A_{1,1} \\\\ A_{1,2} \\end{bmatrix}, & b_1 & = \\begin{bmatrix} b_{1,1} \\\\ b_{1,2} \\end{bmatrix} \\\\ A_{1,1} x^k & = b_{1,1}, & A_{1,2} x^k & \\leq b_{1,2} \\end{align*} 记$M = [A_{1,1}^T, A_2^T]^T$，则$s \\in L_M$时是可行方向 对负梯度$\\nabla f(x^k)$，通过$M$的投影矩阵$P_M$将其投影 至$L_M$上即得可行下降方向$s^k = -P_M \\nabla f(x^k)$ $s^k \\neq 0$：为$x^k$处可行下降方向 $s^k = 0$：作如下讨论 投影方向为0 记$w = [u, v]^T = -(M M^T)^{-1}M \\nabla f(x^k)$，则有 \\begin{align*} 0 & = \\nabla f(x^k) + M^T w \\\\ & = \\nabla f(x^k) + [A_{1,1}^T, A_2^T] \\begin{bmatrix} u \\\\ v \\end{bmatrix} \\\\ & = \\nabla f(x^k) + A_{1,1}^T u + A_2^T v \\end{align*} 若$u \\geq 0$，则$x^{k}$是KKT点 \\nabla f(x^k) + A_{1,1}^T u + A_{1,2}^T v = 0 \\Rightarrow x^k 为KKT点 否则若$u$中有负分量，可设$u0 &lt; 0$，记$\\bar M$为$M$中 去除对应列矩阵，则$\\bar s^k = -P{\\bar M}\\nabla f(x^k)$ 为$x^k$可行下降方向 先反证法证明$\\bar s^k \\neq 0$，若$\\bar s^k = 0$ \\begin{align*} 0 & = \\nabla f(x^k) - \\bar M^T (\\bar M \\bar M^T)^{-1} \\bar M \\nabla f(x^k) \\\\ & = \\nabla f(x^k) + \\bar M^T \\beta \\\\ \\beta & = -(\\bar M \\bar M^T)^{-1} \\bar M \\nabla f(x^k) \\end{align*}考虑到 \\begin{align*} 0 & = \\nabla f(x^k) + M^T w \\\\ & = \\nabla f(x^k) + u_0 \\alpha_0 + \\bar M^T \\bar w \\end{align*} $\\alpha_0$：$M$中$u_0$对应行 则有 u_0 \\alpha_0 + \\bar M^T (\\bar w - \\beta) = 0与$M$行满秩条件矛盾，故$\\bar s^k \\neq 0$ 证明$\\bar s^k$为下降方向 \\begin{align*} \\nabla f(x^k)^T \\bar s^k & = -\\nabla f(x^k) P_{\\bar M} \\nabla f(x^k) \\\\ & = -\\nabla f(x^k) P_{\\bar M}^T P_{\\bar M} \\nabla f(x^k) \\\\ & = -\\|P_{\\bar M} \\nabla f(x^k)\\|_2^2 \\leq 0 \\end{align*} 证明$\\bar s^k$方向可行（满足约束） 由$P{\\bar M}$定义：$\\bar M P{\\bar M} = 0$，则 \\begin{align*} \\bar M \\bar s^k & = -\\bar M \\bar P_{\\bar M} \\nabla f(x^k) \\\\ & = \\begin{bmatrix} \\bar A_{1,1} \\\\ A_2 \\end{bmatrix} \\bar s^k = 0 \\end{align*} 则只需证明$\\alpha_0^T \\bar s^k &lt; 0$ \\begin{align*} 0 & = \\nabla f(x^k) + M^T w \\\\ & = \\nabla f(x^k) + u_0 \\alpha_0 + \\bar M^T \\bar w \\\\ \\Rightarrow & = \\nabla f(x^k)^T \\bar s^k + u_0 \\alpha_0^T \\bar s^k + \\bar w^T \\bar M \\bar s^k \\\\ & = \\nabla f(x^k)^T \\bar s^k + u_0 \\alpha_0^T \\bar s^k \\end{align*}考虑到$u_0 &lt; 0$，则$\\alpha_0^T \\bar s^k &lt; 0$ 即此时有紧约束变为松约束 算法 初始化：初始点$x^0$、$k=0$、精度参数$\\epsilon &gt; 0$ 构造$M = [A_{1,1}^T, A_2^T]^T$ 若$M=0$（在可行域内），令$s^k = -\\nabla f(x^k)$为 迭代方向 否则令$s^k = -P_M \\nabla f(x^k)$为迭代方向 若$|s^k|_2^2 \\geq \\epsilon$ 若$M$为空（无可下降方向），停止 若$M$非空、$u &gt; 0$，停止 否则，构建$M = \\bar M$继续 若$|s^k|_2^2 &gt; \\epsilon$，确定步长$\\lambda_k$ 显然只需保证$A_2 x_k + \\lambda_k A_2 d_k \\leq b_2$ 即可 若$A_2 d_k &lt; 0$，则$\\lambda_k$无约束，否则 \\lambda_k = \\max \\{\\frac {(b_2 - A_2 x_k)_i} {(A_2 d_k)_i}\\} 即单纯型法中确定步长方法 得到新迭代点$x^{k+1} = x^k + \\lambda_k s^k$、$k=k+1$","link":"/Math-Analysis/Optimization/projection_method.html"},{"title":"Proximal Gredient Method","text":"Proximal Operator prox_{f}(x) = \\arg\\min_u (f(u) + \\frac 1 2 \\|u - x\\|^2) $f(x)$：凸函数 由于$L_2$范数的强凸性，近端算子也强凸，解总是唯一存在 直观理解：寻找距离点$x$不太远、$f(u)$尽可能小的$u$ 以下算法都是近端算法的特例 shrinkage thresholding algorithm projected Landweber projected gradient alternating projections alternating-directions method of multipliers alternating split Bregman 近端算子连续可微 Moreau Envolop\\begin{align*} M_{\\gamma, f}(x) & = prox_{\\gamma, f}(x) \\\\ &= \\arg\\min_u (f(u) + \\frac 1 {2\\gamma} \\|u - x\\|^2) \\\\ \\nabla prox_{\\gamma, f}(x) & = \\frac 1 {\\gamma}(x - prox_f(x)) \\end{align*} $\\gamma &gt; 0$：平衡参数，$\\gamma = 1$即为普通近端算子 近端算子求解 对一般凸$f(x)$，通常使用次梯度进行优化，其近端算子解为 （即解变动方向$p-x$为负次梯度方向） p = prox_f(x) \\Leftrightarrow x - p \\in \\partial f(p) \\quad (\\forall (x,p) \\in R^N * R^N) 对光滑凸函数$f$，上述等式对其近端算子约简为 （即解变动方向$p-x$为负梯度方向） p = prox_f(x) \\Leftrightarrow x-p = \\bigtriangledown f(p) 性质分离函数\\begin{align*} f(x_1, \\cdots, x_m) & = \\sum_{i=1}^m f_i(x_i) \\\\ prox_f(x_1, \\cdots, x_m) & = [prox_{f_1}(x_1), \\cdots, prox_{fm}(x_m)] \\end{align*} 取$f(x) = |x|_1$，即可得即软阈值算子 (prox_{\\gamma, f}(x))_i = \\left \\{ \\begin{array}{l} x_i - \\gamma, & x_i \\geq \\gamma \\\\ 0, & |x_i| < \\gamma \\\\ x_i + \\gamma, & x_i \\leq -\\gamma \\end{array} \\right. 参考坐标下降：近端算子中二次项中各分量无关，所以一轮 迭代即为最优解 仿射函数分解\\begin{align*} f(x) & = g(Ax + b) \\\\ prox_f(x) & = x + \\frac 1 {\\alpha} A^T (prox_{\\alpha g}(Ax + b) - Ax - b) \\end{align*} $A^T A = \\alpha I, \\alpha &gt; 0$：线性变换 $g$：良好闭凸函数 第一投影定理 取$f(x)$为示性函数、约束条件，即得到投影算子 \\begin{align*} prox_{\\gamma, f}(x) & = proj_C(x) = \\arg\\min_{u \\in C} \\|u - x\\|_2^2 \\\\ f(x) & = I_C(x) = \\left \\{ \\begin{array}{l} 0, x \\in C \\\\ \\infty, x \\notin C \\end{array} \\right. \\end{align*}第二临近定理 $f$为良好闭凸函数，则以下三条等价 $y = prox_f(x)$ $x - y \\in \\partial f(y)$：由近端算子定义即得 $\\forall z, \\leq f(z) - f(y)$ Moreau Decomposition\\begin{align*} prox_f(x) + prox_{f^{*}}(x) & = x \\\\ prox_{\\lambda f}(x) + \\lambda prox_{f^{*}/lambda}(x/\\lambda) & = x, \\lambda > 0 \\end{align*}最小值\\begin{align*} \\min_x prox_f(x) & = \\min_x f(x) \\\\ \\arg\\min_x prox_f(x) & = \\arg\\min_x f(x) \\end{align*}证明 \\begin{align*} f(x_f) & = f(x_f) + \\frac 1 2 \\|x_f - x_f\\|_2^2 \\\\ & \\geq \\min_u {f(u) + \\frac 1 2 \\|u - x_f\\|_2^2} \\\\ & = prox_f(x_f) \\\\ & \\geq prox_f(x_p) \\\\ & = f(x_p) + \\frac 1 2 \\|x_p - x_f\\|_2^2 \\\\ & \\geq f(x_p) \\geq f(x_f) \\end{align*} $x_f = \\arg\\min_x f(x)$ $x_p = \\arg\\min_x prox_f(x)$ 例 $f(x)=c$：prox_{f}(x) = x Projection Operator投影算子 \\begin{align*} proj_C(x) & = \\arg\\min_{y \\in C} \\|y - x\\|^2 \\\\ & = \\arg\\min_{y \\in R^N} l_C(x) + \\frac 1 2 \\|y-x\\|^2 \\end{align*} 点$x$在凸集$C$上的投影：$X$上距离$x$的欧式距离最近的点 Alternating Projection MethodPOCS/project onto convex sets method：用于解同时满足多个 凸约束的算法 $f_i$作为非空闭凸集$C_i$示性函数，表示一个约束，则整个 问题约简为convex feasibility problem 只需要找到位于所有$C_i$交集的解即可 每次迭代 x^{(k+1)} = P_{C_1}P_{C_2} \\cdots P_{C_n}x_k 在其他问题中投影算子不再适合，需要更一般的算子，在其他 各种同样的凸投影算子中，近端算子最合适 Proximal Gradient Method近端算法：分两步分别优化可微凸$F(x)$、凸$R(x)$，近似优化目标 函数整体，不断迭代直至收敛 \\min_{x \\in \\mathcal{H}}F(x) + R(x) $F(x)$：可微、凸函数 $\\nabla F(x)$：Lipschitz continous、利普希茨常数为$L$ $R(x)$：下半连续凸函函数，可能不光滑 $\\mathcal{H}$：目标函数定义域集合，如：希尔伯特空间 gredient step：从$x^{(k)}$处沿$F(x)$负梯度方向微小移动 达到$x^{(k.5)}$ x^{(k.5)} = x^{(k)} - \\gamma \\nabla F(x^{(k)}) proximal operator step：在$x^{(k.5)}$处应用$R(x)$近端 算子，即寻找$x^{(k.5)}$附近且使得$R(x)$较小点 x^{(k+1)} = prox_{\\gamma R}(x^{(k.5)}) 目标函数推导\\begin{align*} prox_{\\gamma R}(x - \\gamma \\nabla F(x)) & = \\arg\\min_u (R(u) + \\frac 1 {2\\gamma} \\|u - x + \\gamma \\nabla F(x)\\|_2^2) \\\\ & = \\arg\\min_u (R(u) + \\frac {\\gamma} 2 \\|\\nabla F(x)\\|_2^2 + \\nabla F(x)^T (u-x) + \\frac 1 {2\\gamma} \\|u-x\\|_2^2) \\\\ & = \\arg\\min_u (R(u) + F(x) + \\nabla F(x)^T (u-x) + \\frac 1 {2\\gamma} \\|u - x\\|_2^2) \\\\ & \\approx \\arg\\min_u(R(u) + F(u)) \\end{align*} $\\frac {\\gamma} 2 |\\nabla F(x)|_2^2, F(x)$：与$u$无关 ，相互替换不影响极值 $0 &lt; \\gamma \\leq \\frac 1 L$：保证最后反向泰勒展开成立 则$prox_{\\gamma R}(x-\\gamma \\nabla F(x))$解即为 “原问题最优解”（若泰勒展开完全拟合$F(x)$） 近端算法中距离微调项部分可加法分离 若$R(x)$部分也可分离，则整个目标函数可以分离，可以 拆分为多个一元函数分别求极值 考虑泰勒展开是局部性质，$u$作为极小值点只能保证在$x$附近 领域成立，可将近端算子解作为下个迭代点 x^{(k+1)} = prox_{\\gamma R}(x^{(k)} - \\gamma \\nabla F(x^{(k)})) 迭代终止条件即 \\hat x = prox_{\\gamma R}(\\hat x - \\gamma \\nabla F(\\hat x)) 二阶近似证明\\begin{align*} F(u) & = F(x) + \\nabla F(x)^T (u - x) + \\frac 1 2 (u - x)^T \\nabla^2 F(\\zeta)(u - x) \\\\ & \\geq F(x) + \\nabla F(x)^T (u - x) \\\\ & \\leq F(x) + \\nabla F(x)^T (u - x) + \\frac L 2 \\|u-x\\|^2 \\end{align*} $\\nabla^2 F(\\zeta)$：凸函数二阶导正定 $|\\nabla F(u) - \\nabla F(x)|_2 \\leq L |u-x|_2$： $\\nabla F(x)$利普希茨连续性质 参数确定 $L$已知时，可直接确定$\\gamma \\in (0, \\frac 1 L]$， 否则可线性迭代搜索$\\gamma := \\beta \\gamma,\\beta &lt; 1$， 直至 F(x - PG_{\\gamma R}(x)) \\leq F(x) - \\nabla F(x) PG_{\\gamma R}(x) + \\frac 1 2 \\|PG_{\\gamma R}(x)\\|_2^2 $PG{\\gamma R}(x)=x-prox{\\gamma R}(x-\\gamma \\nabla F(x))$ 直接根据下述利普希茨条件须求Hasse矩阵，计算量较大 反向推导 对$F(x)+R(x)$在$x_0$附近作泰勒展开 F(u)+R(u) \\leq F(x) + \\nabla F(x)^T (u - x) + \\frac 1 {2\\gamma} \\|u - x\\|_2^2 + R(x) $\\lambda \\in (0, \\frac 1 L]$ $L$：$F(x)$利普希茨常数 $\\leq$：由Lipschitz连续可取 则不等式右边就是$F(x)+R(x)$的一个上界，可以对将对其 求极小化转化对此上界求极小 考虑对极小化目标添加常数项不影响极值，对不等式右侧添加 与$u$无关项$\\frac \\gamma 2 |\\nabla F(x)|_2^2$、剔除 剔除$F(x)$凑出近端算子 \\begin{align*} prox_{\\gamma R} & = \\arg\\min_u (R(u) + \\frac {\\gamma} 2 \\|\\nabla F(x)\\|_2^2 + \\nabla F(x)^T (u-x) + \\frac 1 {2\\gamma} \\|u-x\\|_2^2) \\\\ & = \\arg\\min_u (R(u) + \\|u - x + \\frac 1 {2\\gamma} \\nabla F(x)\\|_2^2) \\end{align*} 近端算法推广问题推广 求解non-differentiable凸优化问题的通用投影形式 \\min_{x \\in R^N} \\sum_{i=1}^N f_i(x) $f_i(x)$：凸函数，不一定处处可微 目标函数中包含不处处连续可微函数，整个目标函数不光滑 无法使用传统的光滑优化手段，如：最速下降、共轭梯度 极小化条件为$0 \\in \\partial(F+R)(x)$ 分开考虑各个函数，对非光滑函数使用近端算子处理 算子推广 考虑使用Bregman Divergence替代近端算子中欧式距离 prox_{\\gamma, f}(x) = \\arg\\min_u (f(u) + \\mu(u) - \\mu(x) + ) 取$\\mu(x) = \\frac 1 2 |x|_2^2$时，即为普通近端算子","link":"/Math-Analysis/Optimization/proxmial_method.html"},{"title":"约束问题","text":"约束问题局部解\\begin{array}{l} \\min & f(x), x \\in R^n \\\\ s.t. & c_i(x) = 0, i \\in E = \\{1,2,\\cdots,l\\}, \\\\ & c_i(x) \\leq 0, i \\in I = \\{l,l+1,\\cdots,l+m\\} \\end{array} 对于一般约束优化问题，记其可行域为 D = \\{x| c_i(x) = 0, i \\in E, c_i(x) \\leq 0, i \\in I\\} 若 $\\forall x^{} \\in D, \\exists \\epsilon$，使得当 $x \\in D, |x - x^{}| \\leq \\epsilon$ 时，总有 f(x) \\geq f(x^{*})则称$x^{*}$为约束问题的局部解，简称为最优解 若 $x \\in D, 0 &lt; |x - x^{*}| \\leq \\epsilon$ 时，总有 f(x) > f(x^{*})则称$x^{*}$是约束问题的严格局部最优解 约束问题局部解一阶必要条件定理1 设 $a_1,a_2,\\cdots,a_m$ 和 $w \\in R^n$，$C$ 定义如下 $$ C = \\{v |\\sum_{i=1}^m \\lambda_i a_i, \\lambda_i \\geq 0, i=1,2,\\cdots,m \\} 若 $w \\notin C$，则存在超平面 $d^T w = 0$，分离 $C$ 和 $w$，即 \\begin{align*} d^T w &amp; \\leq 0 \\\\ d^T w &amp; &gt; 0 \\end{align*}$$ 显然C是闭凸集，则$\\exists d \\in R^n, d \\neq 0$， $\\alpha \\in R$，使得 \\begin{array}{l} d^T x \\leq \\alpha, & \\forall x \\in C \\\\ d^T w > \\alpha & \\end{array} 又C是锥，有$0 \\in C$，所以$\\alpha \\geq 0$，即$d^T w &gt; 0$ 若$\\exists \\bar x \\in C, d^T \\bar x &gt; 0$，则 $\\forall \\lambda \\geq 0, \\lambda \\bar x \\in C$，则有 \\lambda d^T \\bar x \\leq \\alpha而$\\lambda \\rightarrow \\infty$，左端趋于无穷，矛盾 Farkas引理 设$a_1,a_2,\\cdots,a_m$和$w \\in R^n$，则以下两个系统有且 仅有一个有解 系统I：存在$d$满足\\begin{align*} a_i^T d & \\leq 0, & i=1,2,\\cdots,m \\\\ w^T d & > 0 \\end{align*} 系统II：存在非负常数$\\lambda_1,\\cdots,\\lambda_m$使得 w =\\sum_{i=1}^m \\lambda_i a_i 若系统II有解，则系统I无解 若系统II有解，即存在$\\lambda_1,…,\\lambda_m$且 $\\lambda_i \\geq 0,i=1,2,\\cdot,m$，使得 w = \\sum_{i=1}^m \\lambda_i a_i 若系统I有解，则有 0 < w^T d = \\sum_{i=1}^m \\lambda_i a_i^T d \\leq 0矛盾，因此系统I无解 若系统II无解，则系统I有解 系统II误解，构造闭凸锥 C = \\{v |\\sum_{i=1}^m \\lambda_i a_i, \\lambda_i \\geq 0, i=1,2,\\cdots,m \\}显然$w \\notin C$ 由定理1，存在d满足 \\begin{array}{l} d^T x \\leq 0, & \\forall x \\in C, \\\\ d^T w & > 0 \\end{array} 此定理就是点要么在凸锥C内、边缘（系统II），要么在凸锥 外（系统I） 推论1 设$a_1,a_2,\\cdots,a_m$和$w \\in R^n$，则以下系统有且仅有 一个有解 系统I：存在d满足\\begin{array}{l} a_i^T d \\leq 0, & i=1,2,\\cdots,m \\\\ d_j \\geq 0, & j=1,2,\\cdots,n \\\\ w^T d > 0 & \\end{array} 系统II：存在非负常数$\\lambda_1,…,\\lambda_m$使得 w \\leq \\sum_{i=1}^m \\lambda_i a_i 若系统II有解，则系统I无解 若系统I有解，取d带入矛盾 若系统II无解，则系统I有解 若系统I无解todo 推论2 设$a1,a_2,\\cdots,a{l+m}$和$w \\in R^n$，则以下两个系统 有且进一有一个存在解 存在d满足\\begin{array}{l} a_i^T d = 0, & i=1,2,\\cdots,l \\\\ a_i^T d \\leq 0, & i=l+1,l+2,\\cdots,l+m \\\\ w^T d > 0 \\end{array} 存在常数$\\lambda1,\\lambda_2,\\cdots,\\lambda{l+m}$ 且$\\lambda_i \\geq 0, i=l+1, l+2, \\cdots, l+m$使得 w = \\sum_{i+1}^{l+m} \\lambda_i a_i 迭代求解参数部分更新参数部分更新：每次更新一个或一组待估参数 应用场合 适合待估参数较少、同时估计较慢，待估参数较多可能更新 速度慢，往往需要多次迭代更新参数 一般用在机器学习算法中比较多 特点（某些算法） 良好的并行特性：能够同时更新多个参数 Alternating Direction Method of Multipliers 采用贪心策略的算法：可能无法得到最优解 前向回归 深度学习：网络层次太深，有些算法采用固化部分 网络结构，估计剩余部分 能够平衡全局、局部：得到较好的解 LARS","link":"/Math-Analysis/Optimization/constrained_problems_thoeries.html"},{"title":"Norm","text":"Norm$\\mathcal{L_p}$ 范数 $\\mathcal{L_p}$ 范数 \\|x\\|_p = (|x_1|^p + |x_2|^p + \\cdots + |x_N|^p)^{1/p} $x \\in R^n$ $\\mathcal{L_p}$ Dual Norm 对偶范数 \\|x\\|^{*} = \\mathop \\sup_{z}{x^Tz|\\|z\\| \\leq 1} $x \\in R^N$ $|x|$：$x$的某个范数","link":"/Math-Analysis/Functional-Analysis/norm.html"},{"title":"无约束优化","text":"无约束局部解 minf(x), x \\in R^n 若存在$x^{ } \\in R^n, \\epsilon &gt; 0, \\forall x \\in R^n$ 使得$|x - x^{ }| &lt; \\epsilon$时，恒有 $f(x) \\geq f(x^{ })$：则称$x^{ }$为f(x)的 local minimum point/solution（局部极小点/局部解） $f(x) &gt; f(x^{ })$：则称$x^{ }$为f(x)的 严格局部极小点/局部解 最优性条件First-Order Necessary Condtion 无约束问题局部解的一阶必要条件：设f(x)有连续的一阶偏导， 弱$x^{ * }$是无约束问题的局部解，则\\triangledown f(x{* }) = 0 Second-Order Necessary Condition 无约束问题局部解的二阶必要条件：设f(x)有连续二阶偏导， 若$x^{ * }$是无约束问题的局部解，则 \\triangledown f(x^{ * }) = 0 \\triangledown^2 f(x^{ * })半正定 Second-Order Sufficient Condition 无约束问题局部解的二阶充分条件：设f(x)有连续二阶偏导， 若在$x^{ }$处满足以下，则x^{ }是无约束问题的 严格局部解 \\triangledown f(x^{ * }) = 0 \\triangledown^2 f(x^{ * })正定 下降算法迭代算法：将当前迭代点向正确方向移动一定步长，然后 检验目标值是否满足一定要求 方向、步长就是不同优化算法主要关心的两个方面 还关心算法的rate of convergence（收敛速率） 一般下降算法框架 取初始点$x^{(1)}$，置精度要求$\\epsilon$，置k=1 若在点$x^{(k)}$处满足某个终止准则，则停止计算，得无约束 优化问题最优解$x^{(k)}$，否则适当地选择$x^{(k)}$处 搜索方向 进行适当的一维搜索，求解一维问题 \\arg\\min_{\\alpha} \\phi(\\alpha) = f(x^{(k)} + \\alpha d^{(k)}) 置k=k+1，转2 要使下降算法可行，需要确定 某点出搜索方向 负梯度方向 Newton方向：求方向的时候已确定步长，也可用做步长搜索 拟Newton方向 求步长地一维搜索方式 试探法 0.618法 Fibonacci方法（分数法） 二分法 插值法 三点二次插值法 二点二次插值法 两点三次插值法 非精确一维搜索方法 Glodstein方法 Armijo方法 Wolfe-Powell方法 算法终止准则 $|\\triangledown f(x^{(k)})| &lt; \\epsilon$ $|x^{(k+1)} - x^{(k)}| &lt; \\epsilon$ $|f(x^{(k+1)}) - f(x^{(k)})| &lt; \\epsilon$ 实际计算中最优解可能永远无法迭代达到，应该采用较弱 终止准则 算法收敛性 收敛：序列${x^{(k)}}$或其一个子列（仍记${x^{(k)}}$） 满足 \\lim_{k \\rightarrow \\infty} x^{(k)} = x^{ * } $x^{ * }$：无约束问题局部解 但是这样强的结果难以证明 往往只能证明${x^{(k)}}$的任一聚点的稳定点 或是更弱的 \\lim_{k \\rightarrow \\infty} inf \\|\\triangledown f(x^{(k)}) \\| = 0 局部收敛算法：只有初始点充分靠近极小点时，才能保证产生 序列收敛 全局收敛算法：对任意初始点，产生序列均能收敛 收敛速率设序列${x^{(k)}}$收敛到$x^{ * }$，若以下极限存在 \\lim _ {k \\rightarrow \\infty} \\frac {\\|x^{(k+1)} - x^{*}\\|} {\\|x^{(k)} - x^{*}\\|} = \\beta $0 &lt; \\beta &lt; 1$：线性收敛 $\\beta = 0$：超线性收敛 $\\beta = 1$：次线性收敛（收敛速率太慢，一般不考虑） 算法的二次终止性 二次终止性：若某算法对任意正定二次函数，从任意初始点出发 ，都能经过有限步迭代达到其极小点，则称该算法有二次终止性 具有二次终止性的算法被认为时好算法，否则计算效果较差，原因 正定二次目标函数有某些好的性质，好的算法应该能在有限步内 达到其极小点 对于一个一般的目标函数，若其在极小点处的Hesse矩阵 $\\triangledown f(x^{( * )})$，则由泰勒展开式得到 \\begin{align*} f(x) & = f(x^{*}) + \\triangledown f(x^ {*})^T(x - x^{*}) \\\\ & + \\frac 1 2 (x - x^{*})^T \\triangledown^2 f(x^{*}) (x - x^{*}) \\\\ & + o(\\|x - x^{*}\\|^2) \\end{align*}即目标函数f(x)在极小点附近与一个正定二次函数近似，所以对 正定二次函数好的算法，对一般目标函数也应该具有较好的性质","link":"/Math-Analysis/Optimization/unconstrained_problems_thoeries.html"},{"title":"凸优化问题","text":"Linear Programming数学模型一般数学模型线性规划问题（LP）可以抽象为一般的数学模型 \\begin{array}{l} (\\min_x, \\max_x) & S=c_1 x_1 + c_2 x_2 + \\cdots + c_n x_n \\\\ s.t. & \\left \\{ \\begin{array} {l} a_{1,1} x_1 + a_{1,2} x_2 + \\cdots + a_{1,n} x_n (\\geq = \\leq) b_1 \\\\ a_{2,1} x_1 + a_{2,2} x_2 + \\cdots + a_{2,n} x_n (\\geq = \\leq) b_2 \\\\ \\vdots \\\\ a_{m,1} x_1 + a_{m,2} x_2 + \\cdots + a_{m,n} x_n (\\geq = \\leq) b_m \\end{array} \\right. \\end{array} $S = c_1 x_1 + c_2 x_2 + \\cdots + c_n x_n$：目标函数 $x_1, x_2, …, x_n$：待求解变量 $bi、c_i、a{ij}$：实常数 $(\\geq = \\leq)$：在三种符号中取一种 标准形式\\begin{array}{l} \\min_x & S=c_1 x_1 + c_2 x_2 + \\cdots + c_n x_n \\\\ s.t. & a_{1,1} x_1 + a_{1,2} x_2 + \\cdots + a_{1,n} x_n = b_1 \\\\ & \\vdots \\\\ & a_{t,1} x_1 + a_{t,2} x_2 + \\cdots + a_{t,n} x_n = b_t \\\\ & a_{t+1,1} x_1 + a_{t+1,2} x_2 + \\cdots + a_{t+1, n} x_n \\leq b_{t+1} \\\\ & \\vdots \\\\ & a_{t+l,1} x_1 + a_{t+l,2} x_2 + \\cdots + a_{t+l, n} x_n \\leq b_{t+l} \\\\ \\end{array} $\\max_x$：目标函数取翻转换为$\\min_x$ $\\geq$：不等式左右取反转换为$\\leq$ 线性规划一般模式都可以等价转换为标准形式 Simplex Method单纯型法：利用线性规划极值点必然在单纯型顶点取得，不断迭代顶点求出极值 算法 初始化：标准化线性规划问题，建立初始表格 最小化目标函数：目标函数系数取反，求极大 不等式约束：加入松弛变量（代表不等式两端差值） 变量非负：定义为两个非负变量之差 最优测试 若目标行系数都为非负，得到最优解，迭代停止 基变量解在右端列中，非基变量解为 0 确定主元列 从目标行的前 $n$ 个单元格中选择一个非负单元格，确定主元列 选择首个非负：解稳定，若存在最优解总是能取到 选择绝对值最大：目标函数下降快，但有可能陷入死循环，无法得到最优解（不满足最优条件） 确定主元（分离变量）（行） 对主元列所有正系数，计算右端项和其比值 $\\Theta$ 比率 最小 $\\Theta$ 比率确定主元（行）（类似的为避免死循环，总是选择首个最小者） 转轴变换（建立新单纯形表） 主元变 1：主元行所有变量除以主元 主元列变 0：其余行减去其主元列倍主元行 交换基变量：主元行变量标记为主元列对应变量 特点 算法时间效率 极点规模随着问题规模指数增长，所以最差效率是指数级 实际应用表明，对 $m$ 个约束、$n$ 个变量的问题，算法迭代次数在 $m$ 到 $3m$ 之间，每次迭代次数正比于 $nm$ 迭代改进 Two-Phase Simplex Method两阶段单纯形法：单纯型表中没有单元矩阵，无法方便找到基本可行解时使用 在给定问题的约束等式中加入人工变量，使得新问题具有明显可行解 利用单纯形法求解最小化新的线性规划问题 其他一些算法 大 M 算法 Ellipsoid Method 椭球算法 算法时间效率 可以在多项式时间内对任意线性规划问题求解 实际应用效果较单纯形法差，但是最差效率更好 Karmarkar 算法 内点法（迭代改进） 凸优化\\begin{array}{l} \\min_x & f(x) \\\\ s.t. & g_i(x) \\leq 0, i=1，2,\\cdots,k \\\\ & h_i(x) = 0, i=1,2,\\cdots,l \\end{array} $f(x), g(x)$：$R^n$ 上连续可微的凸函数 $h_i(x)$：$R^n$ 上仿射函数 仿射函数：满足 $f(x)=ax+b, a \\in R^n, b \\in R, x \\in R^n$ 二次规划\\begin{array}{l} \\min_x & f(x)=\\frac 1 2 x^TGx + c^Tx \\\\ s.t. & Ax \\leq b \\end{array} $G \\in R^{n * n}$：$n$ 阶实对称矩阵 $A \\in R^{m n}$：$m n$ 实矩阵 $b \\in R^m$ $c \\in R^n$ $G$ 正定 此时目标函数 $f(x)$ 为凸函数 凸二次规划 问题有唯一全局最小值 问题可可由椭球法在多项式时间内求解 $G$ 半正定 此时目标函数 $f(x)$ 为凸函数 半定规划 若约束条件可行域不空，且目标函数在此可行域有下界，则问题有全局最小值 $G$非正定 目标函数有多个平稳点（局部极小），NP-hard 问题 求解 椭球法 内点法 增广拉格朗日法 投影梯度法 二阶锥规划\\begin{array}{l} \\min_x & f^Tx \\\\ s.t. & \\|A_ix + b_i \\|_2 \\leq c_i^Tx + d_i, i=1,2,\\cdots,m \\\\ & Bx=g \\end{array} $f \\in R^n$ $A_i \\in R^{n_i * n}$，$b_i \\in R^{n_i}$，$c_i \\in R^{n_i}$，$d_i \\in R$ $B \\in R^{p * n}$，$g \\in R^n$ $A_i=0,i=1,\\cdots,m$：退化为线性规划 一般的二阶规划可以转换为二阶锥规划 X^TAX + qTX + C \\leq 0 \\Rightarrow \\|A^{1/2}x + \\frac 1 2 A^{-1/2}q\\|^{1/2} \\leq -\\frac 1 4 q^TA^{-1}q - c 二阶锥规划可以使用内点法很快求解（多项式时间） 非线性最小二乘\\begin{align*} f(x) & = \\frac 1 2 \\sum_{i=1}^m r^2_i(x) \\\\ & = \\frac 1 2 r(x) r^T(x) \\end{align*} $r_i(x)$：通常为非线性函数 $r(x) = (r_1(x), \\cdots, r_n(x))^T$ $x \\in R^n, m \\geq n$ 考虑目标函数梯度、Hesse 矩阵 \\begin{align*} \\nabla f(x) & = \\sum_{i=1}^m \\nabla r_i(x) r_i(x) \\\\ & = J(x)^T r(x) \\\\ \\nabla^2 f(x) & = \\sum_{i=1}^m \\nabla r_i(x) r_i(x) + \\sum_{i=1}^m r_i \\nabla^2 r_i(x) \\\\ & = J(x)^T J(x) + \\sum_{i=1}^m r_i(x) \\nabla^2 r_i(x) \\end{align*} J(x) = \\begin{bmatrix} \\frac {\\partial r_1} {\\partial x_1} & \\frac {\\partial r_1} {\\partial x_2} & \\cdots & \\frac {\\partial r_1} {\\partial x_n} \\\\ \\frac {\\partial r_2} {\\partial x_1} & \\frac {\\partial r_2} {\\partial x_2} & \\cdots & \\frac {\\partial r_2} {\\partial x_n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac {\\partial r_m} {\\partial x_1} & \\frac {\\partial r_m} {\\partial x_2} & \\cdots & \\frac {\\partial r_m} {\\partial x_n} \\end{bmatrix} = \\begin{bmatrix} \\nabla r_1(x)^T \\\\ \\nabla r_2(x)^T \\\\ \\vdots \\\\ \\nabla r_m(x)^T \\\\ \\end{bmatrix} 为$r(x)$的 Jacobi 矩阵 Gauss-Newton 法 为简化计算，略去 Newton 法中 Hesse 矩阵中 $\\sum_{i=1}^m r_i(x) \\nabla^2 r_i(x)$ 项，即直接求解方程组 J(x^{(k)})^T J(x^{(k)}) d = -J(x^{(k)})^T r(x^{(k)}) 求解同一般 Newton 法 特点 实际问题中 局部解 $x^{ }$ 对应的目标函数值 $f(x^{ })$ 接近 0 时，采用 Gauss-Newton 法效果较好，此时 $|r(x^{(k)})|$ 较小 曲线$r_i(x)$接近直线 $\\nabla^2 r_i(x) \\approx 0$ 否则效果一般 矩阵 $J(x^{(k)})^T J(x^{(k)})$ 是半正定矩阵 当 Jacobi 矩阵列满秩时为正定矩阵，此时虽然 $d^{(k)}$ 是下降方向，但仍需类似修正牛顿法增加一维搜索策略保证目标函数值不上升 Levenberg-Marquardt 方法 考虑到 $J(x^{(k)})$ 中各列线性相关、接近线性相关，求解 Newton-Gauss 方法中的方程组会出现困难，可以改为求解 (J(x^{(k)})^T J(x^{(k)}) + vI) d = -J(x^{(k)})^T r(x^{(k)}) $v$：迭代过程中需要调整的参数，LM 方法的关键即如何调整 定理1 若 $d(v)$ 是以上方程组的解，则 $|d(v)|^2$ 是 $v$ 的连续下降函数，且 $v \\rightarrow +\\infty, |d(v)| \\rightarrow 0$ $J(x^{(k)})^T J(x^{(k)})$ 是对称半正定矩阵，则存在正交阵 (P^{(k)})^T J(x^{(k)})^T J(x^{(k)}) P^{(k)} = \\Lambda^{(k)} 则可以解出 $|d(v)|^2$ 增大 $v$ 可以限制 $|d^{(k)}|$，所以 LM 方法也被称为阻尼最小二乘法 定理2 若 $d(v)$ 是以上方程的解，则 $d(v)$ 是 $f(x)$ 在 $x^{(k)}$ 处的下降方向，且 $v \\rightarrow + \\infty$ 时，$d(v)$ 的方向与 $-J(x^{(k)})^T r(x^{(k)})$ 方向一致 下降方向：$\\nabla f(x^{(k)}) d(v) &lt; 0$ 即可 方向一致：夹角余弦 $v$充分大时，LM 方法产生的搜索方向 $d^{(k)}$ 和负梯度方向一致 参数调整方法 使用梯度、近似 Hesse 矩阵定义二次函数 q(d) = f(x^{(k)}) + (J(x^{(k)})^T r(x^{(k)}))^T d + \\frac 1 2 d^T (J(x^{(k)})^T J(x^{(k)})) d 其增量为 \\begin{align*} \\Delta q^{(k)} & = q(d^{(k)}) - q(0) \\\\ & = (J(x^{(k)})^T r(x^{(k)}))^T d^{(k)} + \\frac 1 2 (d^{(k)})^T (J(x^{(k)})^T J(x^{(k)})) d^{(k)} \\end{align*} 目标函数增量 \\begin{align*} \\Delta f^{(k)} & = f(x^{(k)} + d^{(k)}) - f(x^{(k)}) \\\\ & = f(x^{(k+1)}) - f(x^{(k)}) \\end{align*} 定义$\\gamma_k = \\frac {\\Delta f^{(k)}} {\\Delta q^{(k)}}$ $\\gamma_k$接近1说明$\\Delta f^{(k)}$接近$\\Delta q^{(k)}$ 即$f(x^{(k)} + d^{(k+1)})$接近$q(d^{(k)})$ 即$f(x)$在$x^{(k)}$附近接近二次函数 即使用Gauss-Newton方法求解最小二乘问题效果较好 即LM方法求解时$v$参数应该较小 $\\gamma_k$接近0说明$\\Delta f^{(k)}$与$\\Delta q^{(k)}$ 近似程度不好 $d^{(k)}$不应取得过大，应减少$d^{(k)}$得模长 应该增加参数$v$进行限制 迭代方向趋近于负梯度方向 $\\gamma_k$适中时，认为参数$v$选取合适，不做调整 临界值通常为0.25、0.75 算法 初始点 $x^{(1)}$、初始参数 $v$（小值）、精度要求 $\\epsilon$，置 $k=k+1$ 若 $|J(x^{(k)})^T r(x^{(k)})| &lt; \\epsilon$，则停止计算，得到问题解 $x^{(k)}$，否则求解线性方程组 (J(x^{(k)})^T J(x^{(k)}) + v_kI) d = -J(x^{(k)})^T r(x^{(k)})得到 $d^{(k)}$ 置 $x^{(k+1)} = x^{(k)} + d^{(k)}$，计算 $\\gamma_k$ 考虑 $\\gamma$ $\\gamma &lt; 0.25$，置$v_{k+1} = 4 v_k$ $\\gamma &gt; 0.75$，置$v_{k+1} = v_k / 2$ 否则置$v_{k+1} = v_k$ 置k=k+1，转2 其他问题整形规划整形规划：求线性函数的最值，函数包含若干整数变量，并且满足线性等式、不等式的有限约束 Unregularized Least Squares Learning Problem w_T = \\frac \\gamma n \\sum_{i=0}^{T-1} (I - \\frac \\gamma n {\\hat X}^T \\hat X)^i {\\hat X}^T \\hat Y $\\gamma$：被引入保证 $|I - \\frac \\gamma n {\\hat X}^T \\hat X| &lt; 1$ 策略 考虑 \\min_w I_s(w) = \\frac 1 {2n} \\|\\hat X w - \\hat Y\\|^2 将$w_{t+1}$带入$I_s(w)$即可证明每次迭代$I_s(w)$减小 w_0 = 0 \\\\ w_{t+1} = (I - \\frac \\gamma n {\\hat X}^T \\hat X)w_t + \\frac \\gamma n {\\hat X}^T \\hat Y","link":"/Math-Analysis/Optimization/optimization_problems.html"},{"title":"Conjugate Gradient Method","text":"共轭方向 设G为$n * n$阶正定对称矩阵，若$d^{(1)}, d^{(2)}$满足 (d^{(1)})^T G d^{(2)} = 0 则称$d^{(1)}, d^{(2)}$关于G共轭 类似正交方向，若$d^{(1)},\\cdots,d^{(k)}(k \\leq n)$关于 G两两共轭，则称其为G的k个共轭方向 特别的，$G=I$时，共轭方向就是正交方向 定理1 设目标函数为 f(w) = \\frac 1 2 w^T w + r^T w + \\sigma $q^{(1)}, \\cdots, q^{(k)}$是$k, k \\leq n$个非零正交方向 ，从任意初始点$w^{(1)}$出发，依次沿着以上正交方向做 精确一维搜索，得到$w^{(1)}, \\cdots, w^{(k+1)}$， 则$w^{(k+1)}$是$f(w)$在线性流形 \\bar W_k = \\{w = w^{(1)} + \\sum_{i=1}^k \\alpha_i q^{(i)} | -\\infty < \\alpha_i < +\\infty \\} 上的唯一极小点，特别的k=n时，$w^{(n+1)}$是$f(w)$在整个 空间上的唯一极小点 $\\bar W_k$上的存在唯一极小点$\\hat w^{(k)}$，在所有方向 都是极小点，所以有 = 0, i=1,2,.. 将$\\hat w^{(k)}$由正交方向表示带入梯度，求出系数表达式 解精确搜索步长，得到$w^{(k+1)}$系数表达式 扩展子空间定理 设目标函数为 f(w) = \\frac 1 2 x^T G x + r^T x + \\sigma $d^{(1)}, \\cdots, d^{(k)}$是$k, k \\leq n$个非零正交方向 ，从任意初始点$x^{(1)}$出发，依次沿着以上正交方向做 精确一维搜索，得到$x^{(1)}, \\cdots, x^{(k+1)}$， 则$x^{(k+1)}$是$f(x)$在线性流形 \\bar x_k = \\{x = x^{(1)} + \\sum_{i=1}^k \\alpha_i d^{(i)} | -\\infty < \\alpha_i < +\\infty \\} 上的唯一极小点，特别的k=n时，$x^{(n+1)}$是$f(x)$在整个 空间上的唯一极小点 引进变换$w = \\sqrt G x$即可证 在以上假设下，有 = 0, i=1,2... Conjugate Gradient Method共轭梯度法 对正定二次函数函数 f(x) = \\frac 1 2 x^T G x + r^T x + \\sigma 任取初始点$x^{(1)}$，若$\\triangledown f(x^{(1)}) = 0$， 停止计算，得到极小点$x^{(1)}$，否则取 d^{(1)} = -\\triangledown f(x^{(1)}) 沿着$d^{(1)}$方向进行精确一维搜索得到$x^{(2)}$，若 $\\triangledown f(x^{(2)}) \\neq 0$，令 d^{(2)} = -\\triangledown f(x^{(2)}) + \\beta_1^{(2)} d^{(1)}且满足$(d^{(1)})^T G d^{(2)} = 0$，即二者共轭，可得 \\beta_1^{(2)} = \\frac {(d^{(1)})^T G \\triangledown f(x^{(2)})} {((d^{(1)})^T G d^{(1)})} 这里$d^{(2)}$方向的构造方式是为类似构造后面$d^{(k)}$ ，得到能方便表示的系数 类似于将向量组$\\triangledown f(x^{(i)})$正交化 如此重复搜索，若$\\triangledown f^(x^{i)}) \\neq 0$，构造 $x^{(k)}$处搜索方向$d^{(k)}$如下 \\begin{align*} 0 & = (d^{(i)})^T G d^{(k)} \\\\ & = -(d^{(i)})T G \\triangledown f(x^{(k)}) + \\sum_{j=1}^{k-1} \\beta_j^{(k)} (d^{(i)})^T G d^{(j)} \\\\ & = -(d^{(i)})^T G \\triangledown f(x^{(k)}) + \\beta_i^{(k)} (d^{(i)})^T G d^{(i)} \\end{align*}可得 \\beta_i^{(k)} = \\frac {(d^{(i)})^T G \\triangledown f(x^{(k)})} {(d^{(i)})^T G d^{(i)}}此时$d^{(k)}$与前k-1个方向均关于G共轭，此k个方向是G的k个 共轭方向，由扩展空间子定理，$x^{(k+1)}$是整个空间上极小 计算公式简化期望简化$d^{(k)}$的计算公式 由扩展子空间定理推论有 $\\triangledown f(x^{(k)})^T d^{(i)} = 0, i=1,2…,k-1$ 结合以上$d^{(k)}$的构造公式，有 \\begin{align*} & \\triangledown f(x^{(k)})^T \\triangledown f(x^{(i)}) \\\\ = & \\triangledown f(x^{(k)})^T ( -d^{(i)} + \\beta_1^{(i)} d^{(1)} + \\cdots + \\beta_{i-1}^{(i)} d^{(i-1)} ) \\\\ = & 0, i=1,2,...,k-1 \\end{align*} 则有 \\begin{align*} (d^{(i)})^T G \\triangledown f(x^{(k)}) & = \\triangledown f(x^{(k)})^T G d^{(i)} \\\\ & = \\frac 1 {\\alpha_i} \\triangledown f(x^{(k)})^T G (x^{(i+1)} - x^{(i)}) \\\\ & = \\frac 1 {\\alpha_i} \\triangledown f(x^{(k)})^T (\\triangledown f(x^{(i+1)}) - \\triangledown f(x^{(i)})) \\\\ & = 0, i=1,2,\\cdots,k-2 \\end{align*} $d^{(k)} = \\frac 1 {\\alpha_i} x^{(i+1)} - x^{(i)}$ 所以上述$d^{(k)}$构造公式可以简化为 d^{(k)} = -\\triangledown f(x^{(k)}) + \\beta_{k-1} d^{(k-1)} 类似以上推导有 \\begin{align*} (d^{(k-1)})^T G \\triangledown f(x^{(k)}) & = \\frac 1 {\\alpha_i} \\triangledown f(x^{(k)})^T (\\triangledown f(x^{(k)}) - \\triangledown f(x^{(k-1)})) \\\\ & = \\frac 1 {\\alpha_i} \\triangledown f(x^{(k)})^T \\triangledown f(x^{(k)}) \\\\ \\end{align*}\\begin{align*} (d^{(k-1)})^T G d^{(k-1)} & = \\frac 1 {\\alpha_i} (d^{(k-1)})^T (\\triangledown f(x^{(k)}) - \\triangledown f(x^{(k-1)})) \\\\ & = -\\frac 1 {\\alpha_i} (d^{(k-1)})^T \\triangledown f(x^{(x-1)}) \\\\ & = -\\frac 1 {\\alpha_i} (\\triangledown f(x^{(k-1)}) - \\beta_{k-2}d^{(k-2)})^T \\triangledown f(x^{(x-1)}) \\\\ & = -\\frac 1 {\\alpha_i} \\triangledown f(x^{(k-1)})^T \\triangledown f(x^{(k-1)}) \\end{align*}最终的得到简化后系数$\\beta_{k-1}, k&gt;1$的PRP公式 \\beta_{k-1} = \\frac {\\triangledown f(x^{(k)})^T (\\triangledown f(x^{(k)}) - \\triangledown f(x^{(k-1)}))} {\\triangledown f(x^{(k-1)})^T \\triangledown f(x^{(k-1)})}或FR公式 \\beta_{k-1} = \\frac {\\|\\triangledown f(x^{(k)})\\|^2} {\\|\\triangledown f(x^{(k-1)}) \\|^2} 以上推导虽然是根据正定二次函数得出的推导，但是仍适用于 一般可微函数 $\\beta _ {k-1}$给出两种计算方式，应该是考虑到目标函数 可能不是标准正定二次函数、一维搜索数值计算不精确性 将$\\beta _ {k-1}$分子、分母推导到不同程度可以得到其他 公式 Growder-Wolfe公式 \\beta_{k-1} = \\frac {\\triangledown f(x^{(k)})^T (\\triangledown f(x^{(k)}) - \\triangledown f(x^{(k-1)}))} {(d^{(k-1)})^T (\\triangledown f(x^{(k)}) - \\triangledown f(x^{(k-1)}))} Dixon公式 \\beta_{k-1} = \\frac {\\triangledown f(x^{(k)})^T \\triangledown f(x^{(k)})} {(d^{(k-1)})^T \\triangledown f(x^{(k-1)})} FR/PRP算法 初始点$x^{(1)}$、精度要求$\\epsilon$，置k=1 若$|\\triangledown f(x^{(k)}) | \\leq \\epsilon$，停止 计算，得到解$x^{(k)}$，否则置 d^{(k)} = -\\triangledown f(x^{(k)}) + \\beta_{k-1}d^{(k-1)}其中$\\beta_{k-1}=0, k=1$，或由上述公式计算 一维搜索，求解一维问题 \\arg\\min_{\\alpha} \\phi(\\alpha) = f(x^{(k)} - \\alpha d^{(k)})得$\\alpha_k$，置$x^{(k+1)} = x^{(k)} + \\alpha_k d^{(k)}$ 置k=k+1，转2 实际计算中，n步重新开始的FR算法优于原始FR算法 PRP算法中 $\\triangledown f(x^{(k)}) \\approx \\triangledown f(x^{(k-1)})$ 时，有$\\beta_{k-1} \\approx 0$，即 $d^{(k)} \\approx -\\triangledown f(x^{(k)})$，自动重新开始 试验表明，对大型问题，PRP算法优于FR算法 共轭方向下降性 设$f(x)$具有连续一阶偏导，假设一维搜索是精确的，使用共轭 梯度法求解无约束问题，若$\\triangledown f(x^{(k)}) \\neq 0$ 则搜索方向$d^{(k)}$是$x^{(k)}$处的下降方向 将$d^{(k)}$导入即可 算法二次终止性 若一维搜索是精确的，则共轭梯度法具有二次终止性 对正定二次函数，共轭梯度法至多n步终止，否则 目标函数不是正定二次函数 或目标函数没有进入正定二次函数区域， 此时共轭没有意义，搜索方向应该重新开始，即令 d^{(k)} = -\\triangledown f(x^{(k)})即算法每n次重新开始一次，称为n步重新开始策略","link":"/Math-Analysis/Optimization/conjugate_gradient.html"},{"title":"Gradient Descent Method","text":"思想：最速下降&amp;牛顿对目标函数$f(x)$在$x^{(1)}$进行展开 f(x) = f(x^{(1)}) + \\nabla f(x^{(1)})(x - x^{(1)})+ \\frac 1 2 \\nabla^2 f(x^{(1)})(x - x^{(1)})^2 + o((x - x^{(1)})^2) 最速下降法：只保留一阶项，即使用线性函数近似原目标函数 Newton法：保留一阶、二阶项，即使用二次函数近似 利用近似函数求解元素问题极小值 最速下降法：线性函数无极值，需要确定步长、迭代 Newton法：二次函数有极值，直接求导算出极值、迭代 最速下降法 只考虑一阶导：甚至说根本没有考虑拟合原目标函数 Newton法 考虑二阶导：每步迭代还考虑了二阶导，即当前更新完毕 后，下一步能够更好的更新（二阶导的意义） 甚至从后面部分可以看出，Newton法甚至考虑是全局特征， 不只是局部性质（前提目标函数性质足够好） 二次函数拟合更接近函数极值处的特征 最速下降算法思想 设$x=x(t)$为最优点$x$从初始点、沿负梯度方向经过的曲线， 则有 \\left \\{ \\begin{array}{l} & \\frac {dx(t)} {dt} = -\\nabla f(x(t)) \\\\ & x(t_1) = x^{(1)} \\end{array} \\right. $t_1, x^{(1)}$：初始时刻、初始位置 可以证明，$x(t)$解存在，且$t \\rightarrow \\infty$时，有 $x(t) \\rightarrow x^{ * }$，即得到无约束问题最优解 但微分方程组求解可能很麻烦，可能根本无法求解 考虑将以上曲线离散化，每次前进到“不应该”前进为止 然后更换方向，逐步迭代得到最优解 算法 搜索方向最速下降方向：负梯度方向 终止准则：$\\nabla f(x^{(k)})=0$ 取初始点$x^{(1)}$，置k=1 若$\\nabla f(x^{(k)})=0$，则停止计算，得到最优解， 否则置 d^{(k)} = -\\nabla f(x^{(k)})以负梯度作为前进方向 一维搜索，求解一维问题 \\arg\\min_{\\alpha} \\phi(\\alpha) = f(x^{(k)} + \\alpha d^{(k)})得$\\alpha_k$前进步长，置 x^{(k+1)} = x^{(k)} + \\alpha_k d^{(k)} 置k=k+1，转2 最速下降算法不具有二次终止性 叠加惯性模拟物体运动时惯性：指数平滑更新步长 Momentum冲量方法：在原始更新步上叠加上次更新步，类似指数平滑 v^{(t)} = \\gamma v^{(t-1)} + (1 - \\gamma) \\eta \\bigtriangledown_\\theta L(\\theta^{(t-1)}) \\\\ \\theta^{(t)} = \\theta^{(t-1)} - v^{(t)} $v^{(t)}$：第$t$步时第k个参数更新步 $L(\\theta)$：往往是batch损失函数 更新参数时，一定程度保持上次更新方向 可以在一定程度上保持稳定性，学习速度更快 能够越过部分局部最优解 Nesterov MomentumNGA：在使用冲量修正最终方向基础上，使用冲量对当前 参数位置进行修正，即使用“未来”位置计算梯度 先使用冲量更新一步 再在更新后位置计算新梯度进行第二步更新 v^{(t)} = \\gamma v^{(t-1)} + \\eta \\bigtriangledown_\\theta L(\\theta^{(t-1)} - \\gamma v^{(t-1)}) \\\\ \\theta^{(t)} = \\theta^{(t-1)} - v^{(t)}动态学习率 学习率太小收敛速率缓慢、过大则会造成较大波动 在训练过程中动态调整学习率大小较好 模拟退火思想：达到一定迭代次数、损失函数小于阈值时，减小 学习速率 Vanilla Gradient Descent每次迭代减小学习率$\\eta$ \\eta^{(t)} = \\frac \\eta {\\sqrt {t+1}} \\\\ \\theta^{(t)} = \\theta^{(t-1)} - \\eta^{(t)} \\bigtriangledown_\\theta L(\\theta^{(t-1)}) 学习率逐渐减小，避免学习后期参数在最优解附近反复震荡 Adagradadaptive gradient：训练中不同参数学习率随着迭代次数、 梯度动态变化，使得参数收敛更加平稳 v^{(t)}_k = \\bigtriangledown_{\\theta_k} L(\\theta^{(t-1)}) \\\\ \\theta^{(t)}_k = \\theta^{(t-1)}_k - \\frac \\eta {\\sqrt {\\sum_{i=0}^{t-1} (v^{(i)}_k)^2 + \\epsilon}} v^{(t)}_k $\\epsilon$：fuss factor，避免分母为0 $\\theta^{(t)}_k$：第t轮迭代完成后待估参数第k个分量 （之前未涉及参数间不同，统一为向量） 特点 较大梯度参数真正学习率会被拉小；较小梯度真正学习率 参数被拉小幅度较小 可以和异步更新参数结合使用，给不常更新参数更大学习率 缺点 在训练后期，分母中梯度平方累加很大，学习步长趋于0， 收敛速度慢（可能触发阈值，提前结束训练） RMSproproot mean square prop：指数平滑更新学习率分母 v^{(t)}_k = \\bigtriangledown_{\\theta_k} L(\\theta^{(t-1)}) \\\\ \\theta^{(t)}_k = \\theta^{(t-1)}_k - \\frac \\eta {\\sqrt { \\gamma \\sum_{i=1}^{t-1}(v^{(i)}_k)^2 + (1 - \\gamma)((v^{(t)})^2 + \\epsilon} } v^{(t)} 赋予当前梯度更大权重，减小学习率分母，避免学习速率下降 太快 Adamadptive moment estimation：指数平滑更新步、学习率分母 \\begin{align*} v^{(t)}_k & = \\gamma_1 v^{(t-1)}_k + (1 - \\gamma_1) \\bigtriangledown_{\\theta_k} L(\\theta^{(t-1)}) \\\\ s^{(t)}_k & = \\gamma_2 s^{(t-1)}_k + (1 - \\gamma_2) \\bigtriangledown_{\\theta_k} L(\\theta^{(t-1)})^2 \\\\ \\hat{v^{(t)}_k} & = \\frac {v^{(t)}_k} {1 - \\gamma_1^t} \\\\ \\hat{s^{(t)}_k} & = \\frac {s^{(t)}_k} {1 - \\gamma_2^t} \\\\ \\theta^{(t)}_k & = \\theta^{(t-1)}_k - \\frac \\eta {\\sqrt{\\hat{s^{(t)}_k} + \\epsilon}} \\hat{v^{(t)}_k} \\end{align*} $\\gamma_1$：通常为0.9 $\\gamma_2$：通常为0.99 $\\hat{v^{(t)}_k} = \\frac {v^{(t)}_k} {1 - \\gamma_1^t}$ ：权值修正，使得过去个时间步，小批量随机梯度权值之和为1 利用梯度的一阶矩$v^{(t)}$、二阶矩$s^{(t)}$动态调整每个 参数学习率 类似于mommentum、RMSprop结合 经过偏执矫正后，每次迭代学习率都有确定范围，参数比较平稳 Adadelta指数平滑更新学习率（分子）、学习率分母 \\begin{align*} s^{(t)}_k & = \\gamma_1 s^{(t-1)}_k + (1 - \\gamma_1) \\bigtriangledown_{\\theta_k} L(\\theta^{(t-1)})^2 \\\\ \\hat{v^{(t)}_k} & = \\sqrt {\\frac {\\Delta \\theta^{(t-1)}_k + \\epsilon} {s^{(t)}_k + \\epsilon}} \\bigtriangledown_{\\theta_k} L(\\theta^{(t-1)})^2 \\\\ \\Delta \\theta^{(t)}_k & = \\gamma_1 \\Delta \\theta^{(t-1)}_k + (1 - \\gamma_1) \\hat{v^{(t)}_k}^2 \\\\ \\theta^{(t)}_k & = \\theta^{(t)}_k - \\hat{v^{(t)}_k} \\end{align*} $s, \\Delta \\theta$共用超参$\\gamma_1$ 在RMSprop基础上，使用$\\sqrt {\\Delta \\theta}$作为学习率 $\\hat v$：中超参$\\gamma_1$在分子、分母“抵消”，模型对 超参不敏感 样本量Singular Loss/Stocastic Gradient DescentSGD：用模型在某个样本点上的损失极小化目标函数、计算梯度、 更新参数 单点损失度量模型“一次”预测的好坏 代表模型在单点上的优劣，无法代表模型在总体上性质 具有很强随机性 单点损失不常用，SGD范围也不局限于单点损失 损失函数具体参见ml_xxxxx 全局估计全局损失：用模型在全体样本点上损失极小化目标函数、计算梯度、 更新参数 \\theta^{(t)} = \\theta^{(t-1)} - \\eta \\bigtriangledown_\\theta L_{total}(\\theta_{(t-1)}) $\\theta^{(t)}$：第t步迭代完成后待估参数 $\\eta$：学习率 $L{total}(\\theta) = \\sum{i=1}^N L(\\theta, x_i, y_i)$： 训练样本整体损失 $N$：训练样本数量 若损失函数有解析解、样本量不大，可一步更新（计算） 完成（传统参数估计场合） 矩估计 最小二乘估计 极大似然估计 否则需要迭代更新参数 样本量较大场合 并行计算 Mini-Batch Lossmini-batch loss：用模型在某个batch上的损失极小化目标函数、 计算梯度、更新参数 \\theta^{(t)} = \\theta^{(t-1)} - \\eta \\bigtriangledown_\\theta L_{batch}(\\theta^{(t-1)}) $L{batch}(\\theta)=\\sum{i \\in B} L(\\theta, x_i, y_i)$： 当前batch整体损失 $B$：当前更新步中，样本组成的集合batch batch-loss是模型在batch上的特征，对整体的代表性取决于 batch大小 batch越大对整体代表性越好，越稳定；越小对整体代表 越差、不稳定、波动较大、难收敛 batch大小为1时，就是SGD batch大小为整个训练集时，就是经验（结构）风险 batch-loss是学习算法中最常用的loss，SGD优化常指此 实际中往往是使用batch-loss替代整体损失，表示经验风险 极小化 batch-loss同样可以带正则化项，表示结构风险极小化 损失极值：SVM（几何间隔最小） 优点 适合样本量较大、无法使用样本整体估计使用 一定程度能避免局部最优（随机batch可能越过局部极值） 开始阶段收敛速度快 缺点 限于每次只使用单batch中样本更新参数，batch-size较小时， 结果可能不稳定，往往很难得到最优解 无法保证良好的收敛性，学习率小收敛速度慢，学习率过大 则损失函数可能在极小点反复震荡 对所有参数更新应用相同学习率，没有对低频特征有优化 （更的学习率） 依然容易陷入局部最优点","link":"/Math-Analysis/Optimization/gredient_based.html"},{"title":"Line Search","text":"综述一维搜索/线搜索：单变量函数最优化，即求一维问题 \\arg\\min _ {\\alpha} \\phi(\\alpha) = f(x^{(k)} + \\alpha d^{(k)})最优解的$\\alpha_k$的数值方法 exact line search：精确一维搜索，求得最优步长 $\\alpha_k$使得目标函数沿着$d^{(k)}$方向达到极小，即 inexact line search：非精确一维搜索，求得$\\alpha_k$ 使得 \\begin{align*} f(x^{(k)} + \\alpha_k d^{(k)}) & < f(x^{(k)}) \\\\ \\phi(\\alpha_k) & < \\phi(0) \\end{align*} 一维搜索基本结构 确定搜索区间 用某种方法缩小搜索区间 得到所需解 搜索区间 搜索区间：设$\\alpha^{ }$是$\\phi(\\alpha)$极小点，若存在 闭区间$[a, b]$使得$\\alpha^{ } \\in [a, b]$，则称 $[a, b]$是$phi(\\alpha)$的搜索区间 确定搜索区间的进退法 取初始步长$\\alpha$，置初始值 \\mu_3 = 0, \\phi_3 = \\phi(\\mu_3), k = 0 置 \\mu = \\mu_3 + \\alpha, \\phi = \\phi(\\mu), k = k+1 若$\\phi &lt; \\phi_3$，置 \\mu_2 = \\mu_3, \\phi_2 = \\phi_3 \\\\ \\mu_3 = \\mu, \\phi_3 = \\phi \\\\ \\alpha = 2\\alpha, k = k+1 若k =1，置 \\mu_2 = mu, \\phi_2 = \\phi, \\alpha = -\\alpha转2，否则置 \\mu_1 = \\mu_2, \\phi_1 = \\phi_2 \\\\ \\mu_2 = \\mu_3, \\phi_2 = \\phi_3 \\\\ \\mu_3 = \\mu, \\phi_3 = \\phi并令$a=min{\\mu_1,\\mu_3}, b=max{\\mu_1,\\mu_3}$，停止搜索 通常认为目标函数此算法得到搜索区间就是单峰函数 试探法 在搜索区间内选择两个点，计算目标函数值 需要获得两个点取值才能判断极值点的所属区间 去掉函数值较大者至离其较近端点段 0.618法 置初始搜索区间$[a, b]$，置精度要求$\\epsilon$，计算左右 试探点 \\begin{align*} a_l & = a + (1 - \\tau)(b - a) \\\\ a_r & = a + \\tau(b - a) \\end{align*}其中$\\tau = \\frac {\\sqrt 5 - 1} 2$，及相应函数值 \\begin{align*} \\phi_l & = \\phi(a_l) \\\\ \\phi_r & = \\phi(a_r) \\end{align*} 若$\\phi_l&lt;\\phi_r$，置 b= a_r, a_r = a_l, \\phi_l = \\phi_l并计算 a_l = a + (1 - \\tau)(b - a), \\phi_l = \\phi(a_l)否则置 a = a_l, a_l = a_r, \\phi_l = \\phi_r并计算 a_r = a + \\tau(b - a), \\phi_r = \\phi(a_r) 若$|b - a| \\geq \\epsilon$ 若$\\phi_l &lt; \\phi_r$，置$\\mu = a_l$ 否则置$\\mu = \\alpha_r$ 得到问题解$\\mu$，否则转2 0.618法除第一次外，每次只需要计算一个新试探点、一个新 函数值，大大提高了算法效率 收敛速率线性，收敛比为$\\tau = \\frac {\\sqrt 5 - 1} 2$常数 Fibonacci方法 置初始搜索区间$[a, b]$，置精度要求$\\epsilon$，选取分离 间隔$\\sigma &lt; \\epsilon$，求最小正整数n，使得 $F_n &gt; \\frac {b - a} \\epsilon$，计算左右试探点 $\\begin{align} al &amp; = a + \\frac {F{n-2}} {Fn} (b - a)\\ a_r &amp; = a + \\frac {F{n-1}} {F_n} (b - a) \\end{align} 置n=n-1 若$\\phi_l &lt; \\phi_r$，置 b = a_r, a_r = a_l , \\phi_r = \\phi_l 若n&gt;2，计算 \\begin{align*} a_l & = a + \\frac {F_{n-2}} {F_n} (b - a) \\\\ \\phi_r & = \\phi(a_l) \\end{align*} 否则计算 \\begin{align*} a_l & = a_r - \\sigma \\\\ \\phi_l & = \\phi(a_l) \\end{align*} 若$\\phi_l \\geq \\phi_r$，置 a = a_l, a_l = a_r , \\phi_l = \\phi_r 若n&gt;2，计算 \\begin{align*} a_l & = a + \\frac {F_{n-1}} {F_n} (b - a) \\\\ \\phi_r & = \\phi(a_r) \\end{align*} 否则计算 \\begin{align*} a_r & = a_l + \\sigma \\\\ \\phi_r & = \\phi(a_r) \\end{align*} 若n=1 若$\\phi_l &lt; \\phi_r$，置$\\mu = a_r$ 否则置$\\mu = a_r$ 得到极小点$\\mu$，停止计算，否则转2 Finonacci方法是选取实验点的最佳策略，即在实验点个数相同 情况下，最终的极小区间最小的策略 Finonacci法最优性质可通过设最终区间长度为1，递推使得原始 估计区间最大的取实验点方式，得出 插值法 利用搜索区间上某点的信息构造插值多项式（通常不超过3次） $\\hat \\phi(\\alpha)$ 逐步用$\\hat \\phi(\\alpha)$的极小点逼近$\\phi(\\alpha)$ 极小点$\\alpha^{*}$ $\\phi^{ * }$解析性质比较好时，插值法较试探法效果好 三点二次插值法思想以过三个点$(\\mu_1,\\phi_1), (\\mu_2,\\phi_2), (\\mu_3,\\phi_3)$ 的二次插值函数逼近目标函数 \\begin{align*} \\hat \\phi(\\alpha) & = \\phi_1 \\frac {(\\alpha - \\mu_2) (\\alpha - \\mu_3)} {(\\mu_1 - \\mu_2)(\\mu_1 - \\mu_3)} \\\\ & + \\phi_2 \\frac {(\\alpha - \\mu_1) (\\alpha - \\mu_3)} {(\\mu_2 - \\mu_1)(\\mu_2 - \\mu_3)} \\\\ & + \\phi_3 \\frac {(\\alpha - \\mu_1) (\\alpha - \\mu_2)} {(\\mu_3 - \\mu_1)(\\mu_3 - \\mu_2)} \\end{align*} 求导，得到$\\hat \\phi(\\alpha)$的极小点 \\mu = \\frac {2[\\phi_1(\\mu_2-\\mu_3) + \\phi_2(\\mu_3-\\mu_1) + \\phi_3(\\mu_1 - \\mu_2)]} {[\\phi_1 (\\mu_2^2-\\mu_3^2) + \\phi_2(\\mu_3^2-\\mu_1^2) + \\phi_3(\\mu_1^2 - \\mu_2^2)]} 若插值结果不理想，继续构造插值函数求极小点近似值 算法 取初始点$\\mu_1&lt;\\mu_2&lt;\\mu_3$，计算$\\phi_i=\\phi(\\mu_i)$， 且满足$\\phi_1 &gt; \\phi_2, \\phi_3 &gt; \\phi_2$，置精度要求 $\\epsilon$ 计算 A = 2[\\phi_1(\\mu_2 - \\mu_3) + \\phi_2(\\mu_3 - \\mu_1) + \\phi_3(\\mu_1 - \\mu_2)] 若A=0，置$\\mu = \\mu_2, \\phi = \\phi_2$，停止计算， 输出$\\mu, \\phi$ 计算 \\mu = [\\phi_1 (\\mu_2^2 - \\mu_3^2) + \\phi_2(\\mu_3^2 - \\mu_1^2) + \\phi_3(\\mu_1^2 - \\mu_2^2)] / A 若$\\mu&lt;\\mu_1 或 \\mu&gt;\\mu_3,\\mu \\notin (\\mu_1,\\mu_3)$ ，停止计算，输出$\\mu, \\phi$ 计算$\\phi = \\phi(\\mu)$，若$|\\mu - \\mu_2| &lt; \\epsilon$， 停止计算，得到极小点$\\mu$ 若$\\mu \\in (\\mu_2, \\mu_3)$ 若$\\phi &lt; \\phi_2$，置 \\mu_1=\\mu_2, \\phi_1=\\phi_2, \\mu_2=\\mu, \\phi_2=\\phi 否则置\\mu_3 = \\mu, \\phi_3 = \\phi 否则 若$\\phi &lt; \\phi_2$，置 \\mu_3=\\mu_2, \\phi_3=\\phi_2, \\mu_2=\\mu, \\phi_2=\\phi 否则置 \\mu_1 = \\mu, \\phi_1 = \\phi 转2 两点二次插值法思想以$\\phi(\\alpha)$在两点处$\\mu_1, \\mu_2$函数值 $\\phi_1=\\phi(\\mu_1)$、一点处导数值 $\\phi_1^{‘}=\\phi^{‘}(\\mu_1) &lt; 0$构造二次函数逼近原函数 \\begin{align*} \\hat \\phi(\\alpha) & = A(\\alpha - \\mu_1)^2 + B(\\alpha - \\mu_1) + C \\\\ A & = \\frac {\\phi_2 - \\phi_1 - \\phi_1^{'}(\\mu_2 - \\mu_1)} {(\\mu_2 - \\mu_1)^2} \\\\ B & = \\phi_1^{'} \\\\ C & = \\phi_1 \\end{align*} 为保证$[\\mu_1, \\mu_2]$中极小点，须有 $\\phi_2 &gt; \\phi_1 + \\phi_1^{‘}(\\mu_2 - \\mu_1)$ 求解，得到$\\hat \\phi (\\mu)$极小值为 \\mu = \\mu_1 - \\frac {\\phi_1^{'}(\\mu_2 - \\mu_1)^2} {2[\\phi_2 - \\phi_1 - \\phi_1^{'}(\\mu_2 - \\mu_1)]} 若插值不理想，继续构造插值函数求极小点的近似值 算法 初始点$\\mu_1$、初始步长$d$、步长缩减因子$\\rho$、精度要求 $\\epsilon$，计算 \\phi_1 = \\phi(\\mu_1), \\phi_2 = \\phi_(\\mu_2) 若$\\phi_1^{‘} &lt; 0$，置$d = |d|$，否则置$d = -|d|$ 计算 \\mu_2 = \\mu_1 + d, \\phi_2 = \\phi(\\mu_2) 若$\\phi_2 \\leq \\phi_1 + \\phi_1^{‘}(\\mu_2 - \\mu_1)$，置 $d = 2d$，转3 计算 \\mu = \\mu_1 - \\frac {\\phi_1^{'}(\\mu_2 - \\mu_1)^2} {2[\\phi_2 - \\phi_1 - \\phi_1^{'}(\\mu_2 - \\mu_1)]} \\\\ \\phi = \\phi(\\mu), \\phi^{'} = \\phi^{'}(\\mu) 若$|phi^{‘}| \\leq \\epsilon$，停止计算，得到极小点$\\mu$， 否则置 \\mu_1 = \\mu, \\phi_1 = \\phi, \\phi_1^{'} = \\phi^{'}, \\alpha = \\rho \\alpha 其中通常取$d = 1, \\rho = 0.1$ 两点三次插值法原理以两点$\\mu_1, \\mu_2$处函数值$\\phi_i = \\phi(\\mu_i)$和其导数值 $\\phi_i^{‘} = \\phi^{‘}(\\mu_i)$，由Himiter插值公式可以构造 三次插值多项式$\\hat \\phi(\\alpha)$ 求导置0，得到$\\hat \\phi(\\alpha)$极小点 \\begin{align*} \\mu & = \\mu_1 + (\\mu_2 - \\mu_1)(1 - \\frac {\\phi_2^{'} + w + z} {\\phi_2^{'} - \\phi_1^{'} + 2w}) \\\\ z & = \\frac {3(\\phi_2 - \\phi_1)} {\\mu_2 - \\mu_1} - \\phi_1^{'} - \\phi_2^{'} \\\\ w & = sign(\\mu_2 - \\mu_1) \\sqrt {z^2 - \\phi_1^{'} \\phi_2^{'}} \\end{align*} 算法 初始值$\\mu_1$、初始步长$d$、步长缩减因子$\\rho$、精度要求 $\\epsilon$，计算 \\phi_1 = \\phi(\\mu_1), \\phi_1^{'} = \\phi^{'}(\\mu_1) 若$\\phi_1^{‘} &gt; 0$，置$d = -|d|$，否则置$d = |d|$ 置$\\mu_2 = \\mu_1 + \\alpha$，计算 \\phi_2 = \\phi(\\mu_2), \\phi_2^{'} = \\phi^{'}(\\mu_2) 若$\\phi_1^{‘} \\phi_2{‘} &gt; 0$，置 d = 2d, \\mu_1 = \\mu_2, \\phi_1 = \\phi_2, \\phi_1^{'} = \\phi_2^{'}转3 计算 \\begin{align*} \\mu & = \\mu_1 + (\\mu_2 - \\mu_1)(1 - \\frac {\\phi_2^{'} + w + z} {\\phi_2^{'} - \\phi_1^{'} + 2w}) \\\\ z & = \\frac {3(\\phi_2 - \\phi_1)} {\\mu_2 - \\mu_1} - \\phi_1^{'} - \\phi_2^{'} \\\\ w & = sign(\\mu_2 - \\mu_1) \\sqrt {z^2 - \\phi_1^{'} \\phi_2^{'}} \\\\ \\phi & = \\phi(\\mu) \\\\ \\phi^{'} = \\phi^{'}(\\mu) \\end{align*} 若$|\\phi^{‘}| &lt; \\epsilon$，停止计算，得到极小点$\\mu$， 否则置 d = \\rho d, \\mu_1 = \\mu, \\phi_1 = \\phi, \\phi_1^{'} = \\phi^{'}转2 通常取$d = 1, \\rho = 0.1$ 非精确一维搜索 对无约束问题整体而言，又是不要求得到极小点，只需要一定 下降量，缩短一维搜索时间，使整体效果最好 求满足$\\phi(\\mu) &lt; \\phi(0)$、大小合适的$\\mu$ $\\mu$过大容易不稳定 $\\mu$过小速度慢 GoldStein方法原理 预先指定精度要求$0&lt; \\beta_1 &lt; \\beta_2 &lt; 1$ 以以下不等式限定步长 \\begin{align*} \\phi(\\mu) & \\leq \\phi(0) + \\mu\\beta_1 \\phi^{'}(0) \\\\ \\phi(\\mu) & \\geq \\phi(0) + \\mu\\beta_2 \\phi^{'}(0) \\end{align*} 算法 初始试探点$\\mu$，置$\\mu{min} = 0, \\mu{max} = \\infty$， 置精度要求$0 &lt; \\beta_1 &lt; \\beta_2 &lt; 1$ 对$\\phi(mu)$ 若$\\phi(\\mu) &gt; \\phi(0) + \\beta1 \\phi^{‘}(0) \\mu$， 置$\\mu{max} = \\mu$ 否则若$\\phi(\\mu) &gt; \\phi(0) + \\beta_2 \\phi^{‘}(0)\\mu$ ，则停止计算，得到非精确最优解$\\mu$ 否则置$\\mu_{min} = \\mu$ 若$\\mu{max} &lt; \\infty$，置 $\\mu = \\frac 1 2 (\\mu{min} + \\mu{max})$，否则置 $\\mu = 2 \\mu{min}$ 转2 Armijo方法Armijo方法是Goldstein方法的变形 预先取$M &gt; 1, 0 &lt; \\beta_1 &lt; 1$ 选取$\\mu$使得其满足以下，而$M\\mu$不满足 \\phi(\\mu) \\leq \\phi(0) + \\mu \\beta_1 \\phi^{'}(0) M通常取2至10 Wolfe-Powell方法 预先指定参数$0 &lt; \\beta_1 &lt; \\beta_2 &lt;1$ 选取$\\mu$满足 \\begin{align*} \\phi(\\mu) & \\leq \\phi(0) + \\mu \\beta_1 \\phi^{'}(0) \\\\ \\phi^{'}(\\mu) & \\geq \\beta_2 \\phi^{'}(0) \\end{align*} 能保证可接受解中包含最优解，而Goldstein方法不能保证","link":"/Math-Analysis/Optimization/line_search.html"},{"title":"Coordinate Descent","text":"坐标下降坐标下降法：在当前点处延一个坐标方向进行一维搜索以求得函数 的局部极小值 非梯度优化算法，但能提供超过一阶的信息 SMO算法就是两块贪心坐标下降 说明 优化方向从算法一开始就固定，如：选择线性空间中一组基作为 搜索方向 循环极小化各坐标方向上目标函数值，即：若$x^k$给定，则 x_i^{(k+1)} = \\arg\\min_{x \\in R} f(x_1^{k+1}, \\cdots, x_{i-1}^{k+1}, x, x_{i+1}^{k}, \\cdots, x_n^k) $k$：第k轮迭代 $i$：某轮迭代中更新第i个方向 对初始值为$X_0$得到迭代序列$X_1, \\cdots, X_n$，对精确 一维搜索类似最速下降有 F(X_0) \\geq F(X_1) \\geq \\cdots \\geq F(x_n) 若某轮迭代中目标函数无法被有优化，说明已经达到驻点 Adaptive Coordinate Descent自适应坐标下降：变换坐标系使得在考虑目标函数的情况下，新坐标 间尽可能不相关 对非可拆分函数（可加？），算法可能无法在较小迭代步数中 求得最优解 可采用适当坐标系加速收敛，如：主成分分析进行自适应 编码 性能远超过传统坐标下降算法，甚至可以达到梯度下降的 性能 自适应坐标下降具有以下特性，和最先进的进化算法相当 缩放不变性 旋转不变性 Block Coordinate Descent块坐标下降：在当前点处在一个超平面内方向进行搜索以求得函数 的局部极小值 即同时更新一组坐标的坐标下降 例Lasso求解 目标函数 L(x) = RSS(x) + \\lambda \\|x\\|_1 = \\frac 1 2 (Ax - y)^T(Ax - y) + \\lambda \\|x\\|_1 RSS求导 \\begin{align*} \\frac {\\partial RSS} {\\partial x} & = (Ax - y)^T A \\\\ (\\frac {\\partial RSS} {\\partial x})_i & = (Ax - y)^T A_{:i} \\\\ & = (Ax_{i0} - y)^T A_{:i} + x_i A_{:i}^T A_{:i} \\\\ & = z_i + \\rho_i x_i \\end{align*} $(\\frac {\\partial RSS} {\\partial x})_i$：RSS对$x$ 导数第$i$分量，即对$x_i$偏导 $A_{:i}$：$A$第$i$列 $x_{i0}$：$x$第$i$分量置零 $zi = (Ax{i0} - y)^T A_{:i}$ $\\rhoi = A{:i}^T A_{:i}$ 则$x_i$整体次梯度为 \\frac {\\partial L} {\\partial x_i} = z_i + \\rho_i x_i + \\left \\{ \\begin{array}{l} -\\lambda, & x_i < 0 \\\\ [-\\lambda, \\lambda], & x_i = 0 \\\\ \\lambda, & x_i > 0 \\end{array} \\right. 分类讨论：令整体次梯度为0求解$x_i$、回带确定参数条件 x_i = \\left \\{ \\begin{array}{l} \\frac {-z_i + \\lambda} {\\rho_i}, & z_i > \\lambda \\\\ 0 , & -\\lambda < z_i < \\lambda \\\\ \\frac {-z_i - \\lambda} {\\rho_i}, & z_i < -\\lambda \\end{array} \\right. 此算子也称soft threshholding","link":"/Math-Analysis/Optimization/coordinate_descent.html"},{"title":"Newton&#39;s Method","text":"Newton法思想 若$x^{ * }$是无约束问题局部解，则有 \\nabla f(x^{ * }) = 0可求解此问题，得到无约束问题最优解 原始问题是非线性，考虑求解其线性逼近，在初始点$x^{(1)}$ 处泰勒展开 \\nabla f(x) \\approx \\nabla f(x^{(1)}) + \\nabla^2 f(x^{(1)})(x - x^{(1)})解得 x^{(2)} = x^{(1)} - (\\nabla^2 f(x^{(1)}))^{-1} \\nabla f(x^{(1)})作为$x^{ * }$的第二次近似 不断迭代，得到如下序列 x^{(k+1)} = x^{(k)} + d^{(k)} $d^{(k)}$：Newton方向，即以下方程解 \\nabla^2 f(x^{(k)}) d = -\\nabla f(x^{(k)}) 算法 初始点 $x^{(1)}$、精度要求 $\\epsilon$，置 $k=1$ 考虑 $|\\nabla f(x^{(k)})| \\leq \\epsilon$ 若满足，则停止计算，得到最优解 $x^{(k)}$ 否则求解如下方程，得到 $d^{(k)}$ \\nabla^2 f(x^{(k)}) d = -\\nabla f(x^{(k)}) 如下设置，并转2 x^{(k+1)} = x^{(k)} + d^{(k)}, k = k+1 特点 优点 产生点列 ${x^{k}}$ 若收敛，则具有二阶收敛速率 具有二次终止性，事实上对正定二次函数，一步即可收敛 缺点 可能会在某步迭代时目标函数值上升 当初始点 $x^{(1)}$ 距离最优解 $x^{ * }$ 时，产生的点列 可能不收敛，或者收敛到鞍点 需要计算 Hesse 矩阵 计算量大 Hesse 矩阵可能不可逆，算法终止 Hesse 矩阵不正定，Newton 方向可能不是下降方向 阻尼/修正 Newton 法 克服 Newton 法目标函数值上升的缺点 一定程度上克服点列可能不收敛缺点 算法 初始点 $x^{(1)}$、精度要求 $\\epsilon$，置 $k=1$ 考虑 $|\\nabla f(x^{(k)})| \\leq \\epsilon$ 若满足，停止计算，得到最优解 $x^{(k)}$ 否则求解如下方程得到 $d^{(k)}$ \\nabla^2 f(x^{(k)}) d = -\\nabla f(x^{(k)}) 一维搜索，求解一维问题 \\arg\\min_{\\alpha} \\phi(\\alpha) = f(x^{(k)} + \\alpha d^{(k)})得到 $\\alpha_k$，如下设置并转2 x^{(k+1)} = x^{(k)} + \\alpha_k d^{(k)}, k = k+1 其他改进 Newton 法、修正 Newton 法的改进方向 结合最速下降方向修正迭代方向 Hesse 矩阵不正定情形下的替代 结合最速下降方向 将 Newton 方向和最速下降方向结合 设 $\\theta_k$ 是 $$ 之间夹角，显然希望 $\\theta &lt; \\frac \\pi 2$ 则置限制条件 $\\eta$，取迭代方向 d^{(k)} = \\left \\{ \\begin{array}{l} d^{(k)}, & cos\\theta_k \\geq \\eta \\\\ -\\nabla f(x^{(k)}), & 其他 \\end{array} \\right. Negative Curvature 当 Hesse 矩阵非正定时，选择负曲率下降方向 $d^{(k)}$（一定存在） Hesse 矩阵非正定时，一定存在负特征值、相应特征向量 $u$ 取负曲率下降方向作为迭代方向 d^{(k)} = -sign(u^T \\nabla f(x^{(k)})) u $x^{(k)}$ 处负曲率方向 $d^{(k)}$ 满足 {d^{(k)}}^T \\nabla^2 f(x^{(k)}) d^{(k)} < 0 修正 Hesse 矩阵 取迭代方向 $d^{(k)}$ 为以下方程的解 (\\nabla^2 f(x^{(k)}) + v_k I) d = -\\nabla f(x^{k}) $v_k$：大于 $\\nabla^2 f(x^{(k)})$ 最大负特征值绝对值","link":"/Math-Analysis/Optimization/newtons.html"},{"title":"在线最优化","text":"Truncated GradientL1正则化法L1正则化 w^{(t+1)} = w^{(t)} - \\eta^{(t)}g^{(t)} - \\eta^{(t)} \\lambda sgn(w^{(t)}) $\\lambda$：正则化项参数 $sgn$：符号函数 $g^{(t)}=\\nabla_w L(w^{(t)}, Z^{(t)})$：损失函数对参数梯度 L1正则化项在0处不可导，每次迭代使用次梯度计算正则项梯度 OGD中每次根据观测到的一个样本进行权重更新 （所以后面正则项次梯度只考虑非0处？？？） 简单截断法简单截断法：以$k$为窗口，当$t/k$非整数时，使用标准SGD迭代， 否则如下更新权重 \\begin{align*} w^{(t+1)} & = T_0 (w^{(t)} - \\eta^{(t)} G^{(t)}, \\theta) \\\\ T_0(v_i, \\theta) & = \\left \\{ \\begin{array}{l} 0, & |v_i| \\leq \\theta \\\\ v_i, & otherwise \\end{array} \\right. \\end{align*} $w^{(t)}$：模型参数 $g^{(t)}$：损失函数对模型参数梯度 $T_0$：截断函数 $\\theta$：控制参数稀疏性 截断梯度法截断梯度法：以$k$为窗口，当$t/k$非整数时，使用标准SGD迭代， 否则如下更新权重 \\begin{align*} w^{(t+1)} & = T_1(w^{(t)} - \\eta^{(t)} g^{(t)}, \\lambda^{(t)} \\eta^{(t)}, \\theta) \\\\ T_1(v_i, \\alpha, \\theta) & = \\left \\{ \\begin{array}{l} max(0, v_i - \\alpha), & v_i \\in [0, \\theta] \\\\ min(0, v_1 + \\alpha), & v_i \\in [-\\theta, 0] \\\\ v_i, & otherwise \\end{array} \\right. \\end{align*} $\\lambda, \\theta$：控制参数$w$稀疏性 对简单截断的改进，避免在实际（OgD）中参数因训练不足过小 而被错误截断，造成特征丢失 Forward-Backward SplitingFOBOS：前向后向切分，权重更新方式为proximal method如下 \\begin{align*} w^{(t.5)} & = w^{(t)} - \\eta^{(t)} g^{(t)} \\\\ w^{(t+1)} & = \\arg\\min_w \\{ \\frac 1 2 \\|w - w^{(t.5)}\\| + \\eta^{(t+0.5)} \\Phi(w) \\} \\\\ & = \\arg\\min_w \\{ \\frac 1 2 \\|w - w^{(t)} + \\eta^{(t)} g^{(t)}\\| + \\eta^{(t+0.5)} \\Phi(w) \\} \\end{align*}L1-FOBOSL1-FOBOS：即令$Phi(w)=\\lambda |w|_1$，则根据可加性如下 \\begin{align*} w^{(t+1)} & = \\arg\\min_w \\sum_{i=1}^N (\\frac 1 2 (w_i - v_i)^2 + \\tilde \\lambda |w_i|) w_i^{(t+1)} = \\arg\\min_{w_i} (\\frac 1 2 (w_i - v_i)^2 + \\tilde \\lambda |w_i|) \\end{align*} $V=[v_1, v_2, \\cdots, v_N]:=w^{(t.5)}$：为方便 $\\tilde \\lambda := \\eta^{t.5} \\lambda$：为方便 $\\eta^{t.5}$：学习率，常取 $\\eta^{(t)} \\in \\theta(\\frac 1 {\\sqrt t})$ 则对$w_i$求次梯度、分类讨论，解得 w_i^{(t+1)} = \\left \\{ \\begin{array}{l} v_i - \\tilde \\lambda, & v_i > \\tilde \\lambda \\\\ 0, & |v_i| < \\tilde \\lambda \\\\ v_i + \\tilde \\lambda, & v_i < -\\tilde \\lambda \\end{array} \\right. 可以理解为：到当前样本为止，维度权重小于阈值 $\\eta^{(t.5)} \\lambda$）时，认为该维度不够重要， 权重置为0 可视为$k=1, \\theta=\\infty$的Tg算法 另外，显然有$w_i^{(t+1)} v_i \\geq 0$ \\begin{align*} \\frac 1 2 (w_i^{(t+1)} - v_i)^2 + \\tilde \\lambda |w_i^{(t+1)}| & = \\frac 1 2((w_i^{(t+1)})^2 - 2 w_i^{(t+1)} v_i + v_i^2) + \\tilde \\lambda |w_i^{(t+1)}| \\\\ & \\leq \\frac 1 2 v_i^2 \\end{align*} 考虑$w_i^{(t+1)}$使得目标函数最小，带入$w=0$则得 Regularized Dual AveragingRDA算法：正则对偶平均算法，权重更新方式为 包含[增广]正则项的最速下降 w^{(t+1)} = \\arg\\min_w {\\frac 1 t \\sum_{r=1}^t g^{(r)} w + \\Phi(w) + \\frac {\\beta^{(t)}} t h(w)} 目标函数包括三个部分 $\\frac 1 t \\sum_{r=1}^t g^{(r)} w$：包含之前所有梯度 均值 $\\Phi(w)$：正则项 $\\frac {\\beta^{(t)}} t h(w)$：额外正则项，严格凸，且 不影响稀疏性 相较于TG、FOBOS是从另一方面求解在线最优化，更有效地提升 特征权重稀疏性 L1 RDAL1 RDA：令$\\Phi(w) := \\lambda |w|_1$， 再设$h(w) := |w|_2^2$，根据可加性则有 \\begin{align*} w^{(t+1)} & = \\arg\\min_w \\{ \\frac 1 t \\sum_{r=1}^t + \\lambda \\|w\\|_1 + \\frac {\\gamma} {2\\sqrt t} \\|w\\|_2^2 \\} \\\\ w_i^{(t+1)} & = \\arg\\min_{w_i} \\{bar g_i^{(t)} w_i + \\lambda |w_i| \\frac {\\gamma} {2 \\sqrt t} w_i^2 \\} \\end{align*} $\\lambda &gt; 0, \\gamma &gt; 0$ $\\bar gi^{(t)} = \\frac 1 t \\sum{r=1}^t g_i^{(r)}$ 对$w_i$求次梯度、置零、求解得 w_i^{(t+1)} = \\left \\{ \\begin{array}{l} -\\frac {\\sqrt t} {\\gamma} (\\bar g^{(t)} - \\lambda), & \\bar g_i^{(t)} > \\lambda \\\\ 0, & |\\bar g_i^{(t)}| \\leq \\lambda \\\\ -\\frac {\\sqrt t} {\\gamma} (\\bar g^{(t)} + \\lambda), & \\bar g_i^{(t)} < -\\lambda \\\\ \\end{array} \\right. 可以理解为：某维度梯度累计均值绝对值$|bar g_i^{(t)}$ 小于阈值$\\lambda$时，对应权重被置零、产生稀疏性 相较于L1-FOBOS的截断 截断阈值为常数，更加激进、容易产生稀疏性 截断判断对象为梯度累加均值，避免由于训练不足而产生 截断 只需条件$\\lambda$参数，容易权衡精度、稀疏性 Follow the Regularized LeaderFTRL：综合考虑L1-RDA、L1-FOBOS L1-FOBOS、L1-RDA变换 将L1-FOBOS类似近端算法收敛证明中展开、去除无关项、放缩， 得到类似L1-RDA目标函数 \\begin{align*} w^{(t+1)} & = \\arg\\min_w \\{ \\frac 1 2 \\|w - w^{(t)} + \\eta^{(t)} g^{(t)}\\| + \\eta^{(t)} \\lambda \\|w\\|_1 \\} \\\\ & = \\arg\\min_w \\{ g^{(t)} w + \\lambda \\|w\\|_1 + \\frac 1 {2 \\eta^{(t)}} \\|w - w^{(t)}\\|_2^2 \\} \\end{align*} 将L1-RDA目标函数整体整体放缩，得到 w^{(t+1)} = \\arg\\min_w \\{ g^{(1:t)} w + t \\lambda \\|w\\|_1 + \\frac 1 {2\\eta^{(t)}} \\|w - 0\\|_2^2 \\} $g^{(1:t)} := \\sum_{r=1}^t g^{(r)}$ FTRL综合考虑L1-FOBOS、L1-RDA，得到目标函数 w^{(t+1)} = \\arg\\min_w \\{ g^{(1:t)} W + \\lambda_1 \\|w\\|_1 + \\frac {\\lambda_2} 2 \\|w\\|_2^2 + \\frac 1 2 \\sum_{r=1}^t \\sigma^{(r)} \\|w - w^{(r)}\\|_2^2 \\} 使用累加梯度更新，避免因训练不充分错误截断 包含L1-FOBOS、L1-RDA全部正则化项 求解 将FTRL中最后一项拆分、去除无关项 \\begin{align*} w^{(t+1)} & = \\arg\\min_w \\{(g^{(1:t)} - \\sum_{r=1}^t \\sigma^{(r)} w^{(r)})w + \\lambda_1 \\|w\\|_1 + \\frac 1 2 (\\lambda_2 + \\sum_{r=1}^t \\sigma^{(r)}) \\|w\\|_2^2 + \\frac 1 2 \\sum_{r=1}^t \\sigma^{(r)} \\|w^{(r)}\\|_2^2 \\} \\\\ & = \\arg\\min_w \\{ z^{(t)} w + \\lambda_1 \\|w\\|_1 + \\frac 1 2 (\\lambda_2 + \\sum_{r=1}^t \\sigma^{(r)}) \\|w\\|_2^2 \\} \\\\ z^{(t)} &= g^{(1:t)} - \\sum_{r=1}^t \\sigma^{(r)} w^{(r)} \\end{align*} 则同样根据可加性，对各分量求次梯度、置零、求解得 w_i^{(t+1)} = \\left \\{ \\begin{array}{l} \\frac 1 {\\lambda_1 + \\sum_{r=1}^t \\sigma^{(r)}} (z_i^{(t)} - \\lambda_1 z_i), & z_i > \\lambda_1 \\\\ 0, & |z_i^{(t)}| \\leq \\lambda_1 \\\\ \\frac 1 {\\lambda_1 + \\sum_{r=1}^t \\sigma^{(r)}} (z_i^{(t)} + \\lambda_1 z_i), & z_i < -\\lambda_1 \\\\ \\end{array} \\right. 其中学习率$\\eta$为类似Adagrad优化器的学习率，但包括可学习 参数$\\alpha, \\beta$ \\eta_i^{(t)} = \\frac {\\alpha} {\\beta + \\sqrt{\\sum_{r=1}^t (g_i^{(r)})^2}}","link":"/Math-Analysis/Optimization/online_optimization.html"},{"title":"Quasi-Newton Method&#x2F;Variable Metric Method","text":"综述拟Newton法/变度量法：不需要求解Hesse矩阵，使用一阶导构造 二阶信息的近似矩阵 使用迭代过程中信息，创建近似矩阵$B^{(k)}$代替Hesse矩阵 用以下方程组替代Newton方程，其解$d^{(k)}$作为搜索方向 B^{(k)} d = - \\triangledown f(x^{(k)}) 思想 考虑$\\triangledown f(x)$在$x^{(k+1)}$处泰勒展开 \\triangledown f(x) \\approx \\triangledown f(x^{(k+1)}) + \\triangledown^2 f(x^{(k+1)})(x - x^{(k+1)}) 取$x = x^{(k)}$，有 \\begin{align*} \\triangledown f(x^{(k+1)}) - \\triangledown f(x^{(k)}) & \\approx \\triangledown^2 f(x^{(x+1)}) (x^{(k+1) } - x^{(k)}) \\\\ \\triangledown^2 f(x^{k+1}) s^{(k)} & \\approx y^{(k)} \\end{align*} $s^{(k)} = x^{(k+1)} - x^{(k)}$ $y^{(k)} = \\triangledown f(x^{(k+1)}) - \\triangledown f(x^{(k)})$ 要求$B^{(k)}$近似$\\triangledown^2 f(x^{(k)})$，带入并将 $\\approx$改为$=$，得到拟Newton方程 B^{(k+1)} s^{(k)} = y^{(k)}并假设$B^{(k)}$对称 拟Newton方程不能唯一确定$B^{(k+1)}$，需要附加条件，自然 的想法就是$B^{(k+1)}$可由$B^{(k)}$修正得到，即 B^{(k+1)} = B^{(k)} + \\Delta B^{(k)}且修正项$\\Delta B^{(k)}$具有“简单形式” Hesse矩阵修正对称秩1修正认为简单指矩阵秩小：即认为$\\Delta B^{(k)}$秩为最小值1 设$\\Delta B^{(k)} = u v^T$，带入有 \\begin{align*} y^{(k)} & = B^{(k+1)} s^{(k)} \\\\ & = B^{(k)} s^{(k)} + (v^T s^{(k)}) u \\\\ y^{(k)} - B^{(k)} s^{(k)} & = (v^T s^{(k)}) u \\end{align*} 这里有的书会设$\\Delta B^{(k)} = \\alpha u v^T$， 其实对向量没有必要 $v^T s^{(k)}$是数，所以$u$必然与共线，同理也没有必要 考虑系数，直接取相等即可 而且系数不会影响最终结果 可取$u = y^{(k)} - B^{(k)} s{(k)}$，取$v$满足 $v^T s^{(k)} = 1$ 由$B^{(k)}$的对称性、并希望$B^{(k+1)}$保持对称，需要 $u, v$共线，则有 \\begin{align*} v & = \\lambda u = \\lambda (y^{(k)} - B^{(k)} s^{(k)}) \\\\ 1 & = \\lambda (y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)} \\end{align*} 得到$B^{(k)}$的对称秩1修正公式 B^{(k+1)} = B^{(k)} + \\frac {(y^{(k) - B^{(k)} s^{(k)}}) (y^{(k)} - B^{(k)} s^{(k)})^T} {(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)}} 算法 初始点$x^{(1)}$、初始矩阵$B^{(1)} = I$、精度要求 $\\epsilon$、置$k=1$ 若$|\\triangledown f(x^{(k)})| \\leq \\epsilon$，停止计算 ，得到解$x^{(k)}$，否则求解以下方程得到$d^{(k)}$ B^{(k)} d = -\\triangle f(x^{(k)}) 一维搜索，求解 \\arg\\min_{\\alpha} \\phi(\\alpha)=f(x^{(k)} + \\alpha d^{(k)})得到$\\alpha_k$，置$x^{(k+1)}=x^{(k)} + \\alpha_k d^{(k)}$ 修正$B^{(k)}$ \\begin{align*} s^{(k)} & = x^{(k+1)} - x^{(k)} \\\\ y^{(k)} & = \\triangledown f(x^{(k+1)}) - \\triangledown f(x^{(k)}) \\\\ B^{(k+1)} & = B^{(k)} + \\frac {(y^{(k) - B^{(k)} s^{(k)}}) (y^{(k)} - B^{(k)} s^{(k)})^T} {(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)}} \\end{align*} 置$k = k+1$，转2 特点 缺点 要求$(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)} \\neq 0$， 否则无法继续计算 不能保证正定性传递，只有 $(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)} &gt; 0$才能保证 $B^{(k+1)}$也正定 即使$(y^{(k)} - B^{(k)} s^{(k)})^T s^{(k)} &gt; 0$， 也可能很小，容易产生较大的舍入误差 对称秩2修正 为克服秩1修正公式缺点，考虑$\\Delta B^{(k)}$秩为2，设 \\Delta B^{(k)} = u^{(1)} (v^{(1)})^T + u^{(2)} (v^{(2)})^T 带入拟Newton方程有 B^{(k)} s^{(k)} + ((v^{(1)})^T s^{(k)}) u^{(1)} + ((v^{(2)})^T s^{(k)}) u^{(2)} = y^{(k)} 类似的取 \\left \\{ \\begin{array}{l} u^{(1)} = y^{(k)} \\\\ (v^{(1)})^T s^{(k)} = 1 \\end{array} \\right.\\left \\{ \\begin{array}{l} u^{(2)} = -B^{(k)} s^{(k)} \\\\ (v^{(2)})^T s^{(k)} = 1 \\end{array} \\right. 同秩1公式保持对称性推导，得到对称秩2修正公式/BFGS公式 B^{(k+1)} = B^{(k)} - \\frac {B^{(k)} s^{(k)} (s^{(k)})^T B^{(k)}} {(s^{(k)})^T B^{(k)} s^{(k)}} + \\frac {y^{(k)} (y^{(k)})^T} {(y^{(k)})^T s^{(k)}} BFGS算法类似同秩1修正算法，仅第4步使用对称秩2修正公式 Hesse逆修正对称秩2修正 考虑直接构造近似于$(\\triangledown^2 f(x^{(k)}))^{-1}$的 矩阵$H^{(k)}$ 这样无需求解线性方程组，直接计算 d^{(k)} = -H^{(k)} \\triangledown f(x^{(k)}) 相应拟Newton方程为 H^{(k+1)} y^{(k)} = s^{(k)} 可得$H^{(k)}$的对称秩1修正公式 H^{(k+1)} = H^{(k)} + \\frac {(s^{(k)} - H^{(k)} y^{(k)}) (s^{(k)} - H^{(k)} y^{(k)})T} {(s^{(k)} - H^{(k)} y^{(k)})^T y^{(k)}} 可得$H^{(k)}$的对称秩2修正公式/DFP公式 H^{(k+1)} = H^{(k)} - \\frac {H^{(k)} y^{(k)} (y^{(k)})^T H^{(k)}} {(y^{(k)})^T H^{(k)} y^{(k)}} + \\frac {s^{(k)} (s^{(k)})^T} {(s^{(k)})^T y^{(k)}} DFP算法类似BFGS算法，只是 使用$H^{(k)}$计算更新方向 使用$H^{(k)}$的对称秩2修正公式修正 对正定二次函数，BFGS算法和DFP算法效果相同 对一般可微（非正定二次函数），一般认为BFGS算法在收敛性质 、数值计算方面均由于DFP算法 Hesse逆的BFGS算法 考虑 \\begin{align*} B^{(k+1)} & = B^{(k)} + u^{(1)} (v^{(1)})^T + u^{(2)} (v^{(2)})^T \\\\ H^{(k+1)} & = (B^{(k+1)})^{-1} \\\\ & = (B^{(k)} + u^{(1)} (v^{(1)})^T + u^{(2)} (v^{(2)})^T)^{-1} \\\\ \\end{align*} 两次利用Sherman-Morrison公式，可得 H^{(k+1)} = (I - \\frac {s^{(k)} (y^{(k)})^T} {(y^{(k)})^T s^{(k)}}) H^{(k)} (I - \\frac {s^{(k)} (y^{(k)})^T} {(y^{(k)})^T s^{(k)}})^T + \\frac {s^{(k)} (s^{(k)})^T} {(y^{(k)})^T s^{(k)}} todo 还可以进一步展开 H^{(k+1)} = H^{(k)} + (\\frac 1 {(s^{(k)})^T y^{(k)}} + \\frac {(y^{(k)})^T H^{(k)} y^{(k)}} {((s^{(k)})^T y^{(k)})^2}) s^{(k)} (s^{(k)})^T - \\frac 1 {(s^{(k)})^T y^{(k)}} (H^{(k)} y^{(k)} (s^{(k)})^T + s^{(k)} (y^{(k)})^T H^{(k)}) 变度量法的基本性质算法的下降性定理1 设$B^{(k)}$（$H^{(k)}$）是正定对称矩阵，且有 $(s^{(k)})^T y^{(k)} &gt; 0$，则由BFGS（DFS）公式构造的 $B^{(k+1)}$（$H^{(k+1)}$）是正定对称的 考虑$B^{(k)}$对称正定，有 $B^{(k)} = (B^{(k)})^{1/2} (B^{(k)})^{1/2}$ 带入利用柯西不等式即可证 中间插入正定矩阵的向量内积不等式也称为广义柯西不等式 定理2 若$d^{(k)}$v是下降方向，且一维搜索是精确的，设 $B^{(k)}$（$H^{(k)}$）是正定对称矩阵，则有BFGS（DFP） 公式构造的$B^{(k+1)}$（$H^{(k+1)}$）是正定对称的 精确一维搜索$(d^{(k)})^T \\triangledown f(x^{(k+1)}) = 0$ 则有$(s^{(k)})^T y^{(k)} &gt; 0$ 定理3 若用BFGS算法（DFP算法）求解无约束问题，设初始矩阵 $B^{(1)}$（$H^{(1)}$）是正定对称矩阵，且一维搜索是精确的 ，若$\\triangledown f(x^{(k)}) \\neq 0$，则产生搜索方向 $d^{(k)}$是下降方向 结合上2个结论，数学归纳法即可 总结 若每步迭代一维搜索精确，或满足$(s^{(k)})^T y^{(k)} &gt; 0$ 停止在某一稳定点 或产生严格递减的序列${f(x^{(k)})}$ 若目标函数满足一定条件我，可以证明变度量法产生的点列 ${x^{(k)}}$收敛到极小点，且收敛速率超线性 搜索方向共轭性 用变度量法BFGS（DFP）算法求解正定二次函数 $$ min f(x) = \\frac 1 2 x^T G x + r^T x + \\sigma $$ 若一维搜索是精确的，假设已经进行了m次迭代，则 搜索方向$d^{(1)}, \\cdots, d^{(m)}$是m个非零的G共轭方向 对于$j = 1, 2, \\cdots, m$，有 $$ B^{(m+1)} s^{(j)} = y^{(j)} (H^{(m+1)} y^{(j)} = s^{(j)}) $$ 且$m = n$时有吧 $$ B^{(n+1)} = G(H^{(n+1)} = G^{-1}) $$ 变度量法二次终止 若一维搜索是精确的，则变度量法（BFGS、DFP）具有二次终止 若$\\triangle f(x^{(k)}) = 0, k \\leq n$，则得到最优解 $x^{(k)}$ 否则得到的搜索方向是共轭的，由扩展空间子定理， $x^{(n+1)}$是最优解","link":"/Math-Analysis/Optimization/quasi_newtons.html"},{"title":"无约束优化特殊问题","text":"正定二次目标函数 min f(x) = \\frac 1 2 x^T G x + r^T x + \\sigma非线性最小二乘\\begin{align*} f(x) & = \\frac 1 2 \\sum_{i=1}^m r^2_i(x) \\\\ & = \\frac 1 2 r(x) r^T(x) \\end{align*} $r_i(x)$：通常为非线性函数 $r(x) = (r_1(x), \\cdots, r_n(x))^T$ $x \\in R^n, m \\geq n$ 则 \\begin{align*} \\nabla f(x) & = \\sum_{i=1}^m \\nabla r_i(x) r_i(x) \\\\ & = J(x)^T r(x) \\\\ \\nabla^2 f(x) & = \\sum_{i=1}^m \\nabla r_i(x) r_i(x) + \\sum_{i=1}^m r_i \\nabla^2 r_i(x) \\\\ & = J(x)^T J(x) + \\sum_{i=1}^m r_i(x) \\nabla^2 r_i(x) \\end{align*} J(x) = \\begin{bmatrix} \\frac {\\partial r_1} {\\partial x_1} & \\frac {\\partial r_1} {\\partial x_2} & \\cdots & \\frac {\\partial r_1} {\\partial x_n} \\\\ \\frac {\\partial r_2} {\\partial x_1} & \\frac {\\partial r_2} {\\partial x_2} & \\cdots & \\frac {\\partial r_2} {\\partial x_n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac {\\partial r_m} {\\partial x_1} & \\frac {\\partial r_m} {\\partial x_2} & \\cdots & \\frac {\\partial r_m} {\\partial x_n} \\end{bmatrix} = \\begin{bmatrix} \\nabla r_1(x)^T \\\\ \\nabla r_2(x)^T \\\\ \\vdots \\\\ \\nabla r_m(x)^T \\\\ \\end{bmatrix} 为$r(x)$的Jacobi矩阵 Gauss-Newton法Newton法中为简化计算，略去其Hesse矩阵中 $\\sum_{i=1}^m r_i(x) \\nabla^2 r_i(x)$项，即直接求解 方程组 J(x^{(k)})^T J(x^{(k)}) d = -J(x^{(k)})^T r(x^{(k)})算法同Newton法，仅求解Newton方程改为求解以上方程组 特点 实际问题中 局部解$x^{ }$对应的目标函数值$f(x^{ })$接近0 时，$|r(x^{(k)})|$较小 曲线$r_i(x)$接近直线， $\\nabla^2 r_i(x) \\approx 0$ 采用Gauss-Newton法效果较好，否则效果一般 矩阵$J(x^{(k)})^T J(x^{(k)})$是半正定矩阵，当Jacobi矩阵 列满秩时为正定矩阵，此时虽然$d^{(k)}$是下降方向，但仍需 类似修正牛顿法增加一维搜索策略保证目标函数值不上升 Levenberg-Marquardt方法但$J(x^{(k)})$中各列线性相关、接近线性相关，则求解 Newton-Gauss方法中的方程组会出现困难，可以改为求解 (J(x^{(k)})^T J(x^{(k)}) + vI) d = -J(x^{(k)})^T r(x^{(k)}) $v$：迭代过程中需要调整的参数，LM方法的关键即如何调整 定理1 若$d(v)$是以上方程组的解，则$|d(v)|^2$是$v$的连续下降 函数，且$v \\rightarrow +\\infty, |d(v)| \\rightarrow 0$ $J(x^{(k)})^T J(x^{(k)})$是对称半正定矩阵，则存在正交阵 (P^{(k)})^T J(x^{(k)})^T J(x^{(k)}) P^{(k)} = \\Lambda^{(k)} 则可以解出$|d(v)|^2$ 增大$v$可以限制$|d^{(k)}|$，所以LM方法也被称为阻尼最小 二乘法 定理2 若$d(v)$是以上方程的解，则$d(v)$是$f(x)$在$x^{(k)}$处的 下降方向，且$v \\rightarrow + \\infty$时，$d(v)$的方向与 $-J(x^{(k)})^T r(x^{(k)})$方向一致 下降方向：$\\nabla f(x^{(k)}) d(v) &lt; 0$即可 方向一致：夹角余弦 $v$充分大时，LM方法产生的搜索方向$d^{(k)}$和负梯度方向 一致 参数调整方法使用梯度、近似Hesse矩阵定义二次函数 q(d) = f(x^{(k)}) + (J(x^{(k)})^T r(x^{(k)}))^T d + \\frac 1 2 d^T (J(x^{(k)})^T J(x^{(k)})) d 其增量为 \\begin{align*} \\Delta q^{(k)} & = q(d^{(k)}) - q(0) \\\\ & = (J(x^{(k)})^T r(x^{(k)}))^T d^{(k)} + \\frac 1 2 (d^{(k)})^T (J(x^{(k)})^T J(x^{(k)})) d^{(k)} \\end{align*} 目标函数增量 \\begin{align*} \\Delta f^{(k)} & = f(x^{(k)} + d^{(k)}) - f(x^{(k)}) \\\\ & = f(x^{(k+1)}) - f(x^{(k)}) \\end{align*} 定义$\\gamma_k = \\frac {\\Delta f^{(k)}} {\\Delta q^{(k)}}$ $\\gamma_k$接近1说明$\\Delta f^{(k)}$接近$\\Delta q^{(k)}$ 即$f(x^{(k)} + d^{(k+1)})$接近$q(d^{(k)})$ 即$f(x)$在$x^{(k)}$附近接近二次函数 即使用Gauss-Newton方法求解最小二乘问题效果较好 即LM方法求解时$v$参数应该较小 $\\gamma_k$接近0说明$\\Delta f^{(k)}$与$\\Delta q^{(k)}$ 近似程度不好 $d^{(k)}$不应取得过大，应减少$d^{(k)}$得模长 应该增加参数$v$进行限制 迭代方向趋近于负梯度方向 $\\gamma_k$适中时，认为参数$v$选取合适，不做调整 临界值通常为0.25、0.75 算法 初始点$x^{(1)}$、初始参数$v$（小值）、精度要求$\\epsilon$ ，置k=k+1 若$|J(x^{(k)})^T r(x^{(k)})| &lt; \\epsilon$，则停止计算， 得到问题解$x^{(k)}$，否则求解线性方程组 (J(x^{(k)})^T J(x^{(k)}) + v_kI) d = -J(x^{(k)})^T r(x^{(k)})得到$d^{(k)}$ 置$x^{(k+1)} = x^{(k)} + d^{(k)}$，计算$\\gamma_k$ 若 $\\gamma &lt; 0.25$，置$v_{k+1} = 4 v_k$ $\\gamma &gt; 0.75$，置$v_{k+1} = v_k / 2$ 否则置$v_{k+1} = v_k$ 置k=k+1，转2","link":"/Math-Analysis/Optimization/unconstrained_specials.html"},{"title":"Cone","text":"Cone 锥：$C \\subset V, \\forall x \\in C, a&gt;0 \\Rightarrow ax \\in C$ 锥总是无界的 $V$：向量空间 Convex Cone 凸锥：$\\forall x,y \\in C, \\forall a,b &gt; 0 \\Rightarrow ax + by \\in C$ 凸锥必然是凸集 非凸锥：凸锥的补集 Norm Cone $n$ 维标准锥：$C = { (x,t)| |x|_2 \\leq t, x \\in R^{n-1}, t \\in R }$ Second Order Cone 二阶锥：$C = { (x,t)|Ax+b|_2 \\leq c^Tx + d }$ 二阶锥相对于对标准锥做了仿射变换（平移变换）","link":"/Math-Analysis/Real-Analysis/cone.html"},{"title":"凸分析","text":"Notations and TerminologyStrong Convexity 凸函数 $f$ 满足 \\forall x, y \\in R, \\forall \\lambda \\in (0,1), f(\\lambda x + (1-\\lambda) y) \\leq \\lambda f(x) + (1-\\lambda)f(y) 强凸函数：不等式严格不等的凸函数 为保证强凸性，常添加二次项保证，如：增广拉格朗日 凸集相关标记 $C \\subseteq R^N$：非空凸集 $x \\in R^N$ 点 $x \\in R^N$ 到 $C$ 的距离为 D_C(x) = \\min_{y \\in C} \\|x-y\\|_2 点 $x \\in R^N$ 在 $C$ 上投影为 P_Cx \\in C, D_C(x) = \\|x - P_Cx\\|_2 $C \\subseteq R^N$：闭凸集 Indicator Function 凸集 $C$ 的示性函数为 l_C(x) = \\left \\{ \\begin{array} 0 & if x \\in C \\\\ +\\infty & if x \\notin C \\end{array} \\right.","link":"/Math-Analysis/Real-Analysis/convex.html"},{"title":"函数","text":"齐次函数齐次函数：有倍数性质的函数，若变量乘以系数 $\\alpha$，则新函数为原函数乘上 $\\alpha^k$ 倍 f(\\alpha x) = \\alpha^k f(x) $\\alpha \\neq 0 \\in F, x \\in X$ $f: X \\rightarrow W$：域 $F$ 内两个向量空间之间的 $k$ 次齐次函数 线性函数 $f: X \\rightarrow W$ 是一次齐次函数 多线性函数 $f: x_1 x_2 \\cdots * x_n \\rightarrow W$ 是 $n$ 次齐次函数 基本定理 欧拉定理：函数 $f: R^n \\rightarrow R$ 可导、$k$ 次齐次函数，则有 $x \\nabla f(x) = kf(x)$","link":"/Math-Analysis/Real-Analysis/functions.html"},{"title":"次梯度","text":"次梯度 次梯度：实变量凸函数 $f$ 在点 $x_0$ 的次梯度 $c$ 满足 \\forall x, f(x) - f(x_0) \\geq c(x - x_0) 可证明凸函数 $f$ 在 $x_0$ 处所有次梯度的集合 $\\partial f(x)$ 是非空凸紧集 $\\partial f(x) = [a, b]$，其中$a, b$为单侧极限 \\begin{align*} a & = lim_{x \\rightarrow x_0^{-}} \\frac {f(x) - f_0(x)} {x - x_0} \\\\ b & = lim_{x \\rightarrow x_0^{+}} \\frac {f(x) - f_0(x)} {x - x_0} \\end{align*} 凸函数均指下凸函数，梯度不减 次梯度性质运算性质 数乘性质 \\partial(\\alpha f)(x) = \\alpha \\partial f(x), \\alpha > 0 加法性质 \\begin{align*} f &= f_1 + f_2 + \\cdots + f_m, \\\\ \\partial f &= \\partial f_1 + \\cdots + \\partial f_m \\end{align*} 仿射性质：$f$为凸函数 \\begin{align*} h(x) &= f(Ax + b) \\\\ \\partial h(x) &= A^T \\partial f(Ax + b) \\end{align*} 最优化性质 凸函数 $f$ 在点 $x_0$ 可导，当且仅当次梯度仅包含一个点，即该点导数 点 $x_0$ 是凸函数 $f$ 最小值，当且仅当次微分中包含 0 （此性质为“可导函数极小点导数为 0 ”推广） 负次梯度方向不一定是下降方向 次梯度求解 逐点（分段）极值的函数求次梯度 求出该点相应极值函数 求出对应梯度即为次梯度 Pointwise Maximum逐点最大函数：目标函数为 \\begin{align*} f(x) & = max \\{f_1(x), f_2(x), \\cdots, f_m(x)\\} \\\\ I(x) & = \\{i | f_i(x) = f(x)\\} \\end{align*} $I(x)$：保存 $x$ 处取值最大的函数下标 弱结果：$I(x)$ 中随机抽取，以 $f_i(x)$ 在该处梯度作为次梯度 强结果 \\partial f(x) = conv \\cup_{i \\in I(x)} \\partial f_i(x) 先求支撑平面，再求所有支撑平面的凸包 可导情况实际上是不可导的特殊情况 分段函数 折点处 \\partial f(x) = conv\\{a_i, a_{i+1}\\} = [a_i, a_{i+1}] 非折点处 \\partial f(x) = {a_i} $L_1$范数 PointWise Supremum逐点上确界：目标函数为 \\begin{align*} f(x) &= \\sup_{\\alpha \\in A} f_{\\alpha}(x) \\\\ I(x) &= \\{\\alpha \\in A | f_{\\alpha}(x) = f(x)\\} \\end{align*} 弱结果：可行梯度为 \\partial (\\max_{\\alpha} f_{\\alpha}(x)) \\in partial f(x) 强结果 \\partial f(x) = conv \\cup_{\\alpha \\in I(x)} \\partial f_{alpha}(x) \\subseteq \\partial f(x) 最大特征值\\begin{align*} f(x) & = \\lambda_{max}(A(x)) = \\sup_{\\|y\\|_2 = 1} \\\\ A(x) & = A_0 + x_1 A_1 + \\cdots + x_n A_n \\end{align*} $A_n$：对称矩阵 对确定 $\\hat {x}$，$A(x)$ 最大特征值 $\\lambda_{max}$、对应特征向量 $y$，则该点此梯度为 (y^T A_0 y, \\cdots, y^T A_n y) Pointwise Inferior逐点下确界：目标函数为 f(x) = \\inf_y h(x, y) $h$：凸函数 弱结果：给定$x = \\hat x$，可行次梯度为 (\\partial h(x, \\hat y)|_{x=\\hat x}, 0) \\in \\partial f(x) 复合函数 f(x) = h(f_1(x), \\cdots, f_n(x)) $h$：凸、不降函数 $f_i$：凸函数 弱结果：给定$x = \\hat x$，可行次梯度为 g = z_1 g_1 + \\cdots + z_k g_k \\in \\partial f(\\hat x) $z \\in \\partial h(f_1(\\hat x), \\cdots, f_k(\\hat x))$ $g_i \\in \\partial f_i(\\hat x)$ 证明 \\begin{align*} f(x) & \\geq h(f_1(\\hat x) + g_1^T(x - \\hat x), \\cdots, f_k(\\hat x) + g_k^T(x - \\hat x) \\\\ & \\geq h(f_1(\\hat x), \\cdots, f_k(\\hat x)) + z^T(g_1^T(x - \\hat x), \\cdots, g_k^T(x - \\hat x)) \\\\ & = f(\\hat x) + g^T(x - \\hat x) \\end{align*} 次梯度法\\begin{align*} x^{(k+1)} & = x^{(k)} + \\alpha_k g^{(k)} \\\\ f_{best}^{(k+1)} & = min{f_{best}^{(k)}, f(x^{(k+1)})} \\end{align*} $g^{(k)}$：函数$f$在$x^{(k)}$处次梯度 求解凸函数最优化的问题的一种迭代方法 相较于较内点法、牛顿法慢 应用范围更广泛：能够用于不可微目标函数，目标函数可微时，无约束问题次梯度与梯度下降法有同样搜索方向 空间复杂度更小 可以和分解技术结合，得到简单分配算法 通常不会产生稀疏解 步长选择 次梯度法选取步长方法很多，以下为保证收敛步长规则 恒定步长：$\\alpha_k = \\alpha$ 恒定间隔：$\\alpha_k = \\gamma / |g^{(k)}|_2$ 步长平方可加、步长不可加：$\\sum{k=1}^{\\infty} \\alpha_k^2 &lt; \\infty, \\sum{k=1}^{\\infty} \\alpha_k = \\infty$ 步长不可加、但递减：$lim_{k \\rightarrow \\infty} \\alpha_k = 0$ 间隔不可加、但递减：$lim_{k \\rightarrow \\gamma_k} \\gamma_k = 0$","link":"/Math-Analysis/Real-Analysis/subgredient.html"},{"title":"Bash 脚本执行","text":"脚本执行#!脚本首行注释 文件执行时，shell会将文件内容发送至#!之后的解释器上 不限于shell脚本，也适合其他类型的脚本语言 当然要求#为脚本语言支持的注释符 建议在首行使用env命令而不是硬编码解释器路径，这样可以 减少对机器的依赖12#!/usr/bin/env python#!/usr/bin/env shell 4种执行方式 $ file_name：表示在当前shell执行文件，需要有文件的执行 权限 $ source/. file_name：source和.意义一致，表示读取 文件内容在shell中，然后在shell里执行文件内容，需要读权限 $ sh file_name：表示开启一个新的shell进程，并读取文件 内容在新的shell中然后执行，同样的需读权限 例以下面的文件test.sh为例 12345#!/bin/bashecho &quot;fisrt&quot;sleep 1000echo &quot;second&quot;slepp 1000 $ test.sh：产生两个新进程test.sh和sleep，在second输出 之前&lt;ctrl-c&gt;，会同时终止两个进程，不会继续输出second $ sh test.sh：产生两个新进程，shell和sleep，在second 输出之前&lt;ctrl-c&gt;，同样的会同时终止两个进程，不会继续 输出second（实际上first是在新的shell里输出的） source/. test.sh：产生一个新进程sleep，在second输出之前 &lt;ctrl-c&gt;，只有sleep进程被终止，而test.sh的内容在当前 shell里直接执行，当前shell没有被终止，second会继续输出 结论 如果需要对当前shell进行设置，应该使用source/. 否则这三种执行方式除了进程产生、权限要求应该没有差别 Shell环境环境变量 设置环境变量直接：$ ENV_NAME=value（=前后不能有空格） 但是此时环境变量只能在当前shell中使用，需要export命令 导出之后才可在子shell中使用 环境变量设置代理 12export http_proxy=socks://ipexport https_proxy=socks5://ip 输入输出 0：STDIN_FILENO，标准输入 1：STDOUT_FILENO，标准输出 2：STDERR_FILENO，标准错误 说明： 标准输出和标准错误虽然都是在命令行上显示，但是两个是 不同的流。输出重定向&gt;只能将标准输出重定向，不会将 标准错误重定向，其仍然会在命令行显示 重定向 &lt;：重定向标准输入 &gt;：标准输出write重定向 &gt;&gt;：标准输出add重定向 2&gt;：标准错误重定向 说明： 输出重定向就是1 &gt; output，command &gt; output只是省略 1的简写 命名自己不是输出，不能重定向 是命令产生的标准输出重定向 可以通过2&gt;&amp;1将标准错误重定向到标准输出，从而将命令的 标准输出、错误输出同时输出 &amp;这里表示等效于标准输出（标准输出的引用） command&gt;a 2&gt;a和command&gt;a 2&gt;&amp;1看起来类似，实际上 前者写法会打开两次a，stderr覆盖stdout，而后者是 引用，不会覆盖、IO效率更高 2&gt;&amp;1放在后面大概是因为需要获取stdout的引用，所以 需要标准输出先给出重定向 这种写法还有个简写&amp;&gt;、&gt;&amp; 可以重定向到设备，在*nix系统中，设备也被视为文件 1$ echo &quot;hello&quot; &gt; /dev/tty01 特别的设备/dev/null可以作为不需要输出的重定向目标 HereDoc FormatHereDoc Format：特殊的重定向，指示shell从标准输入读取输入 直至遇到标记行（前后不能有空白符） 123&lt;CMD&gt; &lt;&lt; &lt;EOF&gt;here-doc&lt;EOF&gt; EOF：标记字符串，常用EOF、STOP等 若标记中含有字符被quote（如被引号包括） 结束标记为去除quotation结果 here-doc中不执行参数扩展、命令替换、算数扩展 若标记中没有quotation here-doc中执行参数扩展、命令替换、算数扩展 此时\\、$、反引号需要\\转义 管道|：将一个程序的标准输出发送到另一个程序的标准输入 一些平台会并行启动以管道连接的程序，此时使用类似迭代器 输出、输入能提高效率 Shell内置命令 which命令无法找到的命令 setset：设置所使用的shell选项、列出shell变量 ：不带参数，显示全部shell变量 -a：输出之后所有至export（环境变量） -b：使被终止后台程序立即汇报执行状态 -B：执行括号扩展 -C：重定向所产生的文件无法覆盖已存在文件 -d：shell默认使用hash表记忆已使用过的命令以加速 执行，此设置取消该行为 -e：若指令回传值不为0，立即退出shell -f：取消使用通配符 -h：寻找命令时记录其位置??? -H：（默认）允许使用!加&lt;编号&gt;方式执行history中 记录的命令 -k：命令后的=也被视为设置命令的环境变量 -m：监视器模式，启动任务控制 后台进程已单独进程组运行 每次完成任务时显示包含退出的状态行 -n：读取命令但不执行 通常用于检查脚本句法错误 -p：允许set-user/group-id 禁止处理$ENV文件、从文件中继承shell函数 -P：处理cd等改变当前目录的命令时，不解析符号链接 -t：读取、执行下条命令后退出 -u：使用未设置变量作为错误处理 -v：输入行被读取时，显示shell输出行 -x：显示简单命令的PS4扩展值（包括所有参数）、当前命令 的环境变量 -o：option-name，下列之一 allexport：同-a braceexpand shell：（默认）执行花括号扩展 emacs：（默认）使用emacs风格命令行编辑接口 errexit：同-e errtrace：同-E functrace：同-T hashall：同-h histexpand：同-H history：记录命令历史 ignoreeof：读取EOF时不退出shell interactive-comments：允许交互式命令中出现注释 keyword：同-k monitor：同-m noclobber：同-C noexec：同-n noglob：同-f noglob：currently accepted but ignored nohash：同-d notify：同-b nounset：同-u physical：同-P pipfail：管道命令返回值为最后返回值非0命令的状态， 若没有非0返回值返回0 posix：改变shell属性以匹配标准，默认操作不同于 POSIX1003.2标准 priviledged：同-p verbose：同-v vi：使用vi风格的命令编辑接口 xtrace：同-x +：加以上参数取消标志位设置（包括o参数） --：给所有剩余参数设置标志位，没有剩余参数则unset -：给所有剩余参数设置标志位 $-中存放有当前已设置标志位 letlet：执行计算的工具，用于执行一个、多个表达式 变量计算中不需要$标识变量 表达式中包含特殊字符，需要引起来 declaredeclare：声明变量内容 -a：声明变量为普通数组 -A：声明变量为关联数组（下标支持字符串，类似字典） -i：声明变量为整形 -r：声明变量只读 -x：设置为环境变量（export） -g：在函数中创建全局变量 +：和以上联合使用，取消定义的变量类型 -f：列出脚本中定义的函数名称、函数体 -F：列出脚本中定义的函数名称 -p：查看变量属性、值 readread：从标准输入读入变量内容 12$ read [&lt;option&gt;] &lt;var&gt;[ &lt;var2&gt;...]$ read -p &quot;Enter names: &quot; name1, nem 读取值数目大于变量数目时，多余值均赋给最后变量 -p：命令行提示内容 -n：不换行 -d：分隔标记 -t：阻塞等待时常，之后返回非零 -s：隐藏输入 -r：反折号不被视为转义标记 123cat README | while read -r line; do echo $linedone shiftshift：移除参数列表中头部部分参数，缺省移除1个 shift移除从$1开始，无法移除$0 getoptsgetopts：逐个读取解析单字符指示的参数 1234567891011121314151617function func (){ echo OPTIND: $OPTIND while getopts &quot;:a:B:cdef&quot; opt; do case $opt in a) echo &quot;this is -a the arg is ! $OPTARG at $OPTIND&quot; ;; B) echo &quot;this is -B the arg is ! $OPTARG at $OPTIND&quot; ;; c) echo &quot;this is -c the arg is ! $OPTARG at $OPTIND&quot; ;; \\?) echo &quot;Invalid option: -$OPTARG&quot; ;; esac done echo OPTIND: $OPTIND echo $@ shift $(($OPTIND - 1)) echo $@}func -a 23 -B 1904-03-04 343 age $OPTARG：参数值 $OPTIND：在参数列表中位移，初始值为1，常配合shift 使用剔除已处理参数 遇到未指定option则返回0 option字符后:：字符可以带有参数，赋给$OPTARG；否则 仅表示标志，仅该字符被处理 option_string开头:可以避免错误输出 :标记option不带参数时 待匹配值设为: $OPTARG设为option option无效时 待匹配值设为? $OPTARG设为option 函数内部处理函数参数，否则处理脚本参数 参数标识-可省略","link":"/Linux/Bash-Programming/execution.html"},{"title":"Shell执行控制","text":"符号命令执行 ;：连续执行指令，分割多条命令 所以如果不是在一行内执行，;是可以有任意多个 :：内建空指令，返回值为0 &amp;&amp;, ||：逻辑与、或，全部（任意）之前的命令执行成功才会 执行下连接中的命令 “转义” \\\\：转义字符 放在指令前，取消alias 特殊符号前转义，Shell将不对其后字符作特殊处理，当作 普通字符（即$, \\', \\&quot;） 行尾表示连接下一行，回车符只起换行作用，视为空格 $：变量符号，表示其后字符串为一个变量 \\', \\&quot;：内部视为字符串 --：命令行中转义-，否则shell认为-是参数选项 12$ rm -- -file # 删除文件`-file` 还可以在之前加上路径避免-被解释为参数选项 \\、''等均无效 引号单引号'' 单引号括起字符都作为普通字符，变量无效 单引号字串中不能出现单独的单引号，使用转义符也不行，但是 可以成对出现，作为字符串拼接使用 双引号&quot;&quot; 双引号字串中可以有变量、转义字符 反引号``反引号扩起字符串表示Shell解释命令，执行时shell首先解释其， 以标准输出替代整个反引号 括号中语句为命令，分号连接 ``中的表达式只需要符合C语言的运算规则 即可，甚至可以使用三目预算符、逻辑表达式 命令和括号之间无空格 $``可以将命令输出作为变量返回值，同$() 括号() 命令组/运算表达式：其中的命令列表将在新子shell运行 其中变量之后不能使用，不影响当前shell环境 多个命令之间分号分隔，最后命令可以省略 命令和括号之间可以无空格 命令替换：等同于引号`` bash扫描命令行，执行$()结构中命令，将标准输出作为 匿名变量值 ()中出现()不需要转义，``需要转义 ()中不能使用C风格的运算表达式 部分shell可能不支持()，如：tcsh 初始化数组：参见数组 (()) 整数扩展：计算、扩展算数表达式结果 表达式结果为0则退出状态为1、false 表达式结果为1则退出状态为0、true 12a=5;((a++)) # 自增运算符b=$((16#5f)) # 进制转换 退出状态和[]完全相反 其中可使用任何符合C语言的运算，包括三目运算符 算术比较： 其中变量可以不使用$前缀、支持多个表达式逗号分隔 可直接使用C风格表达式，如：for、while循环语句中 1234567for((i=0;i&lt;5;i++))for i in `seq 0 4`for i iin {0..4} # 三者等价if ((i&lt;5))if [ $i -lt 5 ] # 二者等价 []、[[]] [] 条件测试表达式：参见if 数组索引 正则表达式范围 [[]] 条件测试表达式：参见if {} 创建匿名函数 不开启新进程 括号内变量之后可继续使用 括号内命令分号分隔，最后一个语句也要有分号 {和第一个语句之间要有空格 字符串 默认值替换：参见字符串默认值替换 获取子串：参见字符串子串 获取切片：参见字符串子串 字符串替换：参见字符串子串 $后包括变量名精确分隔变量名，参见变量使用 其他符号!Shell中!称为事件提示符，可以方便的引用历史命令：当! 后跟随字母不是空格、换行、回车、=、(时，做命令替换 ![-]n：引用history中的正数/倒数第n个命令 !!：等同!-1，执行上条命令 !cmd：引用最近以cmd开头的命令，包括参数 !cmd:gs/pattern/replace：将上条cmd开头命令中 pattern替换为replace !?str[?]：引用最近包含str的命令，str可以是参数 参数引用 !$：最后一个参数 !:-：除最后一个参数 !*：所有参数 控制语句if、[]用于条件控制结构，结构如下 1234if test_expression; then then command_1 else command_2fi test &lt;expr&gt;：bash内部命令，判断表达式是否为真 其后只能有一个表达式判断，无法使用逻辑与、或连接 [ &lt;expr&gt; ]：基本等同于test 整数比较：-ne、-eq、-gt、-lt 字符串比较：转义形式大、小号\\&lt;、/&gt; 逻辑表达式连接：-o（或）、-a（与）、!（非） （不能使用||（或）、&amp;&amp;（与）） 123if [ $? == 0 ]if test $? == 0 # 二者等价 注意内部两边要有空格 事实上是[等同于test，]表示关闭条件判断，新版 bash强制要求闭合 [[ &lt;expr&gt; ]]条件测试 整数比较：!=、=、&lt;、&gt; 字符串：支持模式匹配（此时右侧模式时不能加引号） 逻辑表示式连接：||（或）、&amp;&amp;（与）、!（非） 1234if [[ $a != 0 &amp;&amp; $b == 1 ]]if [ $a -eq 0 ] &amp;&amp; [ $b -eq 1]if [ $a -eq 0 -a $b -eq 1] # 三者等价 [[：bash关键字，bash将其视为单独元素并返回退出 状态码 case1234567891011121314151617case chars inchar_pattern_1) # `)`是必要的 # 匹配即停止，不会下沉 command_1;; # 每个模式字符串可以有多条命令，最后一条必须以`;;`结尾char_pattern_2 | char_pattern_3) # `|`分隔，或，可以匹配其中一个模式即可 command_2;;*) # 匹配所有字符串模式，捕获所有 command_3;;esac # 返回值位最后执行命令的退出值，未执行命令则为0 while123456while test_expression # test_expression是指`test`、`[]`语句 # 测试条件为真进入循环体do command_1done until12345until test_exprssion # 测试条件为假进入循环体do command_1done forCStyle12345for ((i=0; i&lt;limit; i++)) # C-style fordo command_1done ListStyle12345for var in var_arr # list-style fordo commanddone FileIterator123456for var in /path/to/file_regex # `var`依次取（当前）目录下的与正则表达式匹配的文件名 # 执行循环体语句do commanddone /path/to/file_regex注意 路径不存在：$var为该字符串 不能用&quot;&quot;括起，否则：$var只取路径下所有匹配合并 ，空格分隔 ParamsIterator123456for var[ in $*] # `var`依次取位置参数的值，执行循环体中命令 # `[ in $*]`可以省略do commanddone RangeIterator123456789for i in $(seq start end)do commanddonefor i in {start..end}do commanddone break, continue, exit break[n]：跳出n层循环体，默认跳出一层循环体 continue[n]：跳过n层循环体在其之后的语句，回到循环开头 ，默认跳过一次循环体 exit：退出程序，后跟返回值","link":"/Linux/Bash-Programming/flow_control.html"},{"title":"Shell编程基础","text":"变量定义、使用、删除 定义变量 定义时不加$符号 变量名和等号之间不能有空格 变量名只能由英文字母、数字、下划线，且不以数字开头， 不能用bash中的关键字 已经定义变量可以重新定义 使用变量 var_name`/`${var_name}`：变量名前加`即可使用， 未定义变量直接使用不报错，返回空值 {}可选，但是{}能够明确定义变量名范围，帮助阅读、 解释器执行 匿名变量 可以认为所以语句（命令）的执行结果都存储在一个匿名 变量中，可以在其之前加上$获取其结果 readonly：设置变量为只读变量，更改（重定义）变量报错 unset：删除变量，不能删除只读变量 局部变量局部变量：在脚本、命令中定义 仅在当前shell实例中有效 shell变量默认为global，作用域从被定义处开始到脚本 末尾（即使在函数内部定义） 显式local声明作用域局限于函数内部 其他shell启动的程序不能访问局部变量 环境变量环境变量：就是shell中的普通变量，只是这些变量往往被进程读取 用于自身初始化、设置 狭义：export/declare -x声明的变量，只有这样的变量 才能默认被子进程继承 广义；shell中所有的变量（包括局部变量） 环境变量设置在shell中设置环境变量有两种方式 export/declare -x：设置全局（环境）变量 任何在该shell设置环境变量后，启动的（子）进程都会 继承该变量 对于常用、许多进程需要的环境变量应该这样设置 &lt;ENV_NAME&gt;=... cmd：设置临时环境变量 &lt;ENV_NAME&gt;=...不能被子进程继承，所以必须在其后立刻 接命令 只对当前语句有效，也不能覆盖同名变量 用途 环境变量是某些程序正常运行的必要条件 所有程序都能访问环境变量，可用作进程通信 在程序中设置环境变量，供其他进程访问变量 父进程为子进程设置环境变量，供其访问 Shell变量Shell变量：shell程序设置的特殊变量，包括环境变量、局部变量， 保证shell的正常运行 $0：shell执行脚本名 交互式bash（即普通终端中）该参数为-bash 则source执行脚本时，该参数可能非预期 以下shell变量均不考虑$0，如 函数中$0也是脚本名 shift无法跳过该参数 $1,..., $9：向脚本传递的位置参数 $@：脚本、函数参数列表 $*：脚本、函数参数字符串 $#：脚本、函数参数数量 $?：上条命令执行结果 $$$$：脚本进程号 $!：执行脚本最后一条命令 字符串拼接 shell中字符默认为字符串，自动拼接 通配符 *：匹配任意长度字符串 不包括.、/，必须显式匹配 ?：匹配一个字符 []：匹配出现在[]中的字符 12ls /[eh][to][cm]* # 匹配`/etc`、`/home`等 {} 枚举全部 123456$ mkdir {user1, user2}-{home, bin} # 笛卡尔积（字符串连接） # 等价于建立`user1-home, user1-bin, user2-home, user2-bin`$ echo {1..10} # 生成序列 # 见`for`中`RangeIterator`部分 子串12$ file=/dir1/dir2/dir3/file.txt.bak$ null=&quot;&quot; 切片 ${&lt;var_name&gt;:n[:m]}：从第n开始m个字符 n、m非负值 n：从0开始的下标起始 m：切片长度，缺省表示到末尾 n、m使用0-负值表示 n：从0开始的负向下标起始 m：从0开始的负向下标终止 命令 解释 结果 ${file:0:5} 提取首个字符开始的5个字符 /dir1 ${file:5:5} 提取第5个字符开始的5个字符 /dir2 ${file:5} 提取第5个字符开始至末尾 /dir2... ${file:0-5} 反向计算下标 t.bak ${file:0-5:0-1} 反向计算下标 t.ba ${file:5:0-2} 提取第5个字符开始至-2下标处 /dir2.../t.b 子串匹配1234${&lt;var_name&gt;%&lt;pattern&gt;}${&lt;var_name&gt;%%&lt;pattern&gt;}${&lt;var_name&gt;#&lt;pattern&gt;}${&lt;var_name&gt;##&lt;pattern&gt;} #：去掉字符串左边最短pattern ##：去掉字符串左边最长pattern %：去掉字符串右边最短pattern %%：去掉字符串右边最长pattern 注意：var_name前不要变量标志$ 以上4种模式返回新值，不改变原变量值 仅在pattern中使用通配符时，最短、最长匹配才有区别 命令 解释 结果 ${file#*/} 去除首个/及其左边 dir2/dir3/file.txt.bak ${file##*/} 仅保留最后/右边 file.txt.bak ${file#*.} 去除首个.及其左边 txt.bak ${file##*.} 仅保留最后.右边 bak ${file%/*} 去除最后/及其右边 /dir1/dir2/dir3 ${file%%*/} 去除首个/及其右边 空值 ${file%*.} 去除最后.及其右边 /dir1/dir2/dir3/file.txt ${file%%*.} 去除首个.及其右边 /dir1/dir2/dir3/file.txt 替换 /from/to：替换首个from为to //from/to：替换全部from为to 命令 解释 结果 ${file/dir/path} 替换首个dir为path /path1/dir2/dir3/file.txt.bak ${file/dir/path} 替换全部dir为path /path1/path2/path3/file.txt.bak 默认值替换 -：变量未设置返回 +：变量设置返回 =：变量未设置返回、设置变量 ?：变量未设置输出至stderr :：以上命令条件包括空值（空值视为未设置） 命令 解释 示例 结果 ${井&lt;var_name&gt;} 获取字符串长度 ${井file} 27 ${&lt;var_name&gt;-&lt;default&gt;} 变量未设置返回默认值 ${invalid-file.txt.bak} file.txt.bak ${&lt;var_name&gt;:-&lt;default&gt;} 变量未设置、空值返回默认值 ${null-file.txt.bak} file.txt.bak ${&lt;var_name&gt;+&lt;default&gt;} 变量设置返回默认值 ${file-file.txt.bak} fil.txt.bak ${&lt;var_name&gt;:+&lt;default&gt;} 变量非空返回默认值 ${file-file.txt.bak} file.txt.bak ${&lt;var_name&gt;=&lt;default&gt;} 变量未设置，返回默认值、并设置变量为默认值 ${invalid=file.txt.bak} file.txt.bak ${&lt;var_name&gt;:=&lt;default&gt;} 变量未设置、空值返回默认值、并设置变量为默认值 ${null=file.txt.bak} file.txt.bak {$&lt;var_name&gt;?&lt;default&gt;} 变量未设置输出默认值至stderr {invalid?file.txt.bak} file.txt.bak输出至stderr {$&lt;var_name&gt;:?&lt;default&gt;} 变量未设置、空值输出默认值至stderr {$null:?file.txt.bak} file.txt.bak输出至stderr 字符串比较 =, !=, -z, -n：字符串相等、不相等、为空、非空 使用=比较变量是否为某字符串时，其中在两侧添加字符 保证=不为空值，否则若$test为空值，表达式报错 123if [[ &quot;$text&quot;x = &quot;text&quot;x ]]; then commandfi 比较变量时要在两侧加上双引号&quot;&quot;，否则可能报错、结果不 符合预期 数组1$ A=(a b c def) 取值 []：选择数组元素 [n]：返回数组第n个元素 [*]/[@]：返回数组全部元素 命令 解释 结果 ${A[@]} 返回全部元素 a b c def ${A[*]} 同上 同上 ${A[0]} 返回数组第一个元素 a ${井A[@]} 返回数组元素总数 4 ${井A[*]} 同上 同上 ${井A[3]} 返回数组第4个元素长度 3 A[3]=xyz 设置数组第4个元素值 数值 (())/[]：在其中执行整数运算 let：执行数值运算 规则 返回的数据结果相当于存储在一个匿名变量中，使用的话需要 在之前加上$ (())`/`$[]`中的变量名称可以省略`123$ a=5; b=7; c=2;$ echo $((a + b * $c)) # 19 $((N#xx))/$[$#xx]：将其他进制数据转换为10进制 12$ echo $((2#110)) # 6 自增、自减运算可以在(())/[]中直接执行 12$ a=5; ((a++)); echo $a; # 6 特殊运算符 ~：位与 |：位或 ^：位异或 &gt;&gt;：位右移 &lt;&lt;：位左移 **：数值平方 +=, ++, -=, --, *=, \\=：自变化运算符 逻辑运算 -eq, -ne, -ge, -le, -lt, -gt：比较 ==, !=, &gt;=, &lt;=, &lt;, &gt;：数值比较 文件 -e：目标存在 -f：文件为一般文件（非目录、设备） -s：文件大小非0 -d：目标为目录 -b：文件为块设备（软盘、光驱） -c：文件为流设备（键盘、modem、声卡） -p：文件为管道 -h/L：目标为符号链接 -S：目标为Socket -t：文件描述符被关联到终端 一般用于检测脚本的stdin是否来自终端[ -t 0 ]，或 输出是否输出至终端[ -t 1 ] -r：目标是否可读权限 -w：目标是否可写权限 -x：目标是否可执行权限 -g：目标是否设置有set-group-id -u：目标是否设置有set-user-id -k：目标是否设置sticky bit -O：用户是否是文件所有者 -G：用户是否属于文件所有组 -N：文件从上次读取到现在为止是否被修改 f1 -nt f2：文件f1比f2新 f1 -ot f2：文件f1比f2旧 f1 -ef f2：文件f1、f2指向相似文件实体（相同的硬链接）","link":"/Linux/Bash-Programming/variables.html"},{"title":"CentOS7 常用配置","text":"网络配置编辑/etc/sysconfig/network-scripts/ifcfg-ens33 123456789101112131415161718192021TYPE = Ethernet # 网卡类型：以太网PROXY_METHOD=none # 代理方式：无BROWSER_ONLY=no # 仅浏览器：否BOOTPROTO=dhcp # 网卡引导协议DEFROUTE=yes # 默认路由：是IPV4_FAILURE_FATAL=no # 开启IPV4致命错误检测：否IPV6INIT=yes # IPV6自动初始化：是IPV6_AUTOCONF=yes # IPV6自动配置：是IPV6_DEFROUTE=yes # IPV6是否可为默认路由：是IPV6_FAILURE_FATAL=no # 开启IPV6致命错误检测：否IPV6_ADDR_GEN_MODE=stable-privacy # IPV6地地址生成模型：stable-privacyNAME=ens33 # 网卡物理设备名称UUID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx # 通用唯一识别码DEVICE=ens33 # 网卡设备名称ONBOOT=yes # 开启启动：是DNS1=xxx.xxx.xxx.xxx # DNS地址IPADDR=xxx.xxx.xxx.xxx # IP地址PREFIX=24 # 子网掩码GATEWAY=xxx.xxx.xxx.xxx # 网关 UUID不能相同相同 ifcfg-ens33这个文件感觉像是个模板，但是不知道真正应用 配置文件在哪 常用应用源EPELExtra Packages for Enterprise Linux 由Fedora社区创建、维护的RPM仓库，通常不会与官方源发生冲突 或相互替换文件，包括应用有：chromium 直接使用yum安装：$ sudo yum install epel-release RPMFusion提供Fedora和RedHat由于开源协议或者是禁止商业用途而无法提供 RPM安装包，包括两个仓库 和NuxDextop源有冲突，如：gstreamer，感觉上比NuxDextop更加权威 包含应用：mplayer、gstreamer-pluginsXXXX、 free：开源软件但是由于其他原因无法提供，安装方式 $&gt;sudo yum localinstall --nogpgcheck https://download1.rpmfusion.org/free/el/rpmfusion-free-release-7.noarch.rpm nonfree：闭源软件，包括不能用于商业用途，安装方式 $&gt;sudo rpm -ivh https://download1.rpmfusion.org/nonfree/el/rpmfusion-nonfree-release-7.noarch.rpm ELRepo包含和硬件相关的驱动程序，通过以下命令安装 $&gt;rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org $&gt;rpm -Uvh http://www.elrepo.org/elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm NuxDextop包含与多媒体相关应用的RPM仓库，好像是个人作者维护，有的依赖 可能在EPEL源中，因此可能需要先安装EPEL，可能和其他源 （RPMFusion）有冲突，可以设置默认情况下不启用，即修改 /etc/yum.repos.d/nux.dextop.repo文件，设置enable=0， 开启时手动启用 $&gt;yum --enablerepo=nux-dextop install PACKAGENAME $&gt;rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm 装机必备rhytmbox-mp3centos7的gnome默认安装rhythmbox，但无法解码mp3，需要安装 rpmfusion-free源中的 gstreamer-plugins-ugly.x86_64 gstreamer1-plugins-ugly.x86_64 chromium 安装EPEL源之后直接安装 flash插件 adobe官网下载flash-player-ppapi： http://get.adobe.com/flashplayer 下载chromium-pepper-flash ppapi好像就是pepperapi的简称，但是两个flash插件不一样， 安装的是pkgs上下载的,fedora社区维护的 html5视频播放支持：ffmpeg-libs google准备不再支持h.264格式（绝大部分）的视频，所以装 了这个还需要其他设置，但firefox可播放大部分html5视频 wqy中文字体yum源里的字体文件都是*.ttc文件，需要*ttf字体文件，有 在线解压网站可以解压 安装包常识 app和app-devel/app-dev：后者包括头文件、链接库，在编译 使用了app的源代码才需要 系统配置文件目录常识 /usr/share/applications里*.desktop是“桌面图标”文件， centos会 菜单中的会展示的“应用”就是这些","link":"/Linux/Configuration/centos_conf.html"},{"title":"Linux介绍","text":"Linux版本内核版本内核版本号由3个数字组成X.Y.Z-P X：主版本号，比较稳定，短时间不会改变 Y：次版本号，表示版本类型 偶数：稳定版 奇数：测试版 Z：发布号，数字越大，功能越完善 P：patch号 Linux分区/boot引导分区目录该分区（目录）存放系统内核、驱动模块引导程序，需要独立 分区 避免（根）文件系统损坏造成无法启动 避使用lilo引导时1024柱面问题（Grub无此问题） 方便管理多系统引导 /boot修复进入grub模式后#todo /swap分区目录系统物理内存不足时，释放部分空间，其中数据被临时保存在 swap空间中 不是所有物理内存中交换的数据都会被放在交换空间中，有部分 数据直接交换到文件系统 交换空间比内存慢 安装时，系统会尝试将交换分区安装到磁盘外端 有多个磁盘控制器时，在每个磁盘上都建立交换空间 尽量将交换空间安装在访问在频繁的数据区附近 交换空间大小一般设置为内存1-2倍 不推荐为交换空间划分单独分区，可以使用交换文件作为交换 空间，方便、容易扩展 交换文件12345678910111213$ dd if=/dev/zero of=/swapfile bs=1024 count=32000 # 或$ fallocate -l 32G /swapfile # 创建有连续空间的交换文件，大小为1024*32000=32G$ chmod 600 /swapfile # 修改交换文件权限$ mkswap /swapfile # 设置交换文件$ /usr/sbin/swapon /swapfile # 激活上步创建的`/swapfile`交换文件$ /usr/sbin/swapoff swapfile # 关闭交换文件 不需要交换文件时可以直接rm删除 可以在fstab文件中添加交换文件，自动挂载，格式参见 config_files /根分区目录 /usr：用户程序 /sbin：系统管理员执行程序 /bin：基本命令 /lib：基本共享库、核心模块 /home：用户目录 /etc：配置文件目录 /opt：附加应用程序包目录 /mnt：设备/文件系统挂载目录 /dev：设备 /tmp：临时文件 /var：可变信息区 file spool logs requests mail /proc：进程（映射）信息","link":"/Linux/Configuration/linux_intro.html"},{"title":"Bash 编程技巧","text":"检查命令是否成功 原版 1234567echo abcdee | grep -q abcdif [ $? -eq 0 ]; then echo &quot;foundelse echo &quot;not found&quot;fi 简洁版 12345if echo abcdee | grep -q abc; then echo &quot;found&quot;else echo &quot;not found&quot;fi 精简版 1echo abcdee | grep -q abc &amp;&amp; echo &quot;found&quot; || echo &quot;not found&quot; 标准输出、错误输出重定向到/dev/null 原版 1$ grep &quot;abc&quot; text.txt 1&gt;/dev/null 2&gt;&amp;1 简洁版 1$ grep &quot;abc&quot; text.txt &amp;&gt; /dev/null awk使用 原版1$ sudo xm li | grep vm_name | awk `{print $2}` 简洁版1$ sudo xm li | awk `/vm_name/{print $2}` 逗号连接所有行 原版：sed 1$ sed &quot;:a;$!N;s/\\n/,;ta&quot; test.txt 简洁：paste 1$ paste -sd, /tmp/test.txt 过滤重复行 原版：sort 1$ sort text.txt | unique 简洁版 1$ sort -u text.txt","link":"/Linux/Bash-Programming/twists.html"},{"title":"Linux 安装后常用配置","text":"用户设置设置 root 密码 Linux 安装之初，在设置 root 密码之前无法使用 $ su 切换到 root 用户，需要先设置root用户密码 1$ sudo passwd root 应用设置Debian配置文件 Debian 源配置文件：/etc/apt/source.list 修改完成后运行 $ sudo apt update 更新索引 163 源：https://mirrors.163.com/.help/debian.html 12345678deb http://mirrors.163.com/debian/ &lt;VERSION&gt; main non-free contribdeb http://mirrors.163.com/debian/ &lt;VERSION&gt;-updates main non-free contribdeb http://mirrors.163.com/debian/ &lt;VERSION&gt;-backports main non-free contribdeb-src http://mirrors.163.com/debian/ &lt;VERSION&gt; main non-free contribdeb-src http://mirrors.163.com/debian/ &lt;VERSION&gt;-updates main non-free contribdeb-src http://mirrors.163.com/debian/ &lt;VERSION&gt;-backports main non-free contribdeb http://mirrors.163.com/debian-security/ &lt;VERSION&gt;/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ &lt;VERSION&gt;/updates main non-free contrib USTC 源：https://mirrors.ustc.edu.cn/help/debian.html 12345678deb http://mirrors.ustc.edu.cn/debian/ &lt;VERSION&gt; main contrib non-freedeb-src http://mirrors.ustc.edu.cn/debian/ &lt;VERSION&gt; main contrib non-freedeb http://mirrors.ustc.edu.cn/debian/ &lt;VERSION&gt;-updates main contrib non-freedeb-src http://mirrors.ustc.edu.cn/debian/ &lt;VERSION&gt;-updates main contrib non-freedeb http://mirrors.ustc.edu.cn/debian/ &lt;VERSION&gt;-backports main contrib non-freedeb-src http://mirrors.ustc.edu.cn/debian/ &lt;VERSION&gt;-backports main contrib non-freedeb http://mirrors.ustc.edu.cn/debian-security/ &lt;VERSION&gt;/updates main contrib non-freedeb-src http://mirrors.ustc.edu.cn/debian-security/ &lt;VERSION&gt;/updates main contrib non-free 为 debian 的版本名，根据版本改变 一般的，直接将默认配置文件中 http://deb.debian.org 修改为相应源地址即可：$ sudo sed -i 's/deb.debian.org/&lt;mirror_addr&gt;/g' /etc/apt/sources.list openSUSE openSUSE 使用 MirrorBrain 技术，中央服务器会按照 IP 中转下载请求到附近的镜像，所以更改软件源通常只会加快刷新软件元的速度，对下载速度影响不大 命令行 USTC 源：https://mirrors.ustc.edu.cn/help/opensuse.html 12345678# 禁用原有软件源$ sudo zypper mr -da$ sudo zypper ar -fcg https://mirrors.ustc.edu.cn/opensuse/distribution/leap/\\$releasever/repo/oss USTC:OSS$ sudo zypper ar -fcg https://mirrors.ustc.edu.cn/opensuse/distribution/leap/\\$releasever/repo/non-oss USTC:NON-OSS$ sudo zypper ar -fcg https://mirrors.ustc.edu.cn/opensuse/update/leap/\\$releasever/oss USTC:UPDATE-OSS$ sudo zypper ar -fcg https://mirrors.ustc.edu.cn/opensuse/update/leap/\\$releasever/non-oss USTC:UPDATE-NON-OSS# 15.3 或更高版本需要$ sudo zypper ar -fgc https://mirrors.ustc.edu.cn/opensuse/update/leap/\\$releasever/sle USTC:UPDATE-SLE $releasever：OpenSuSe leap 版本，若知晓可以自行替换 配置文件 openSUSE 源配置文件夹：/etc/zypp/repo.d 配置文件格式 12345[&lt;ALIAS&gt;] # 源别名enabled=1 # 默认是否启用autorefresh=0baseurl=url # 源地址type=rpm-md CentOS 发行版中 yum 一般自带 fast-mirrors 插件，一般无需更新官方源 三方源配置 Extra Packages for Enterprise Linux：由 Fedora 社区创建、维护的 RPM 仓库，通常不会与官方源发生冲突或相互替换文件 安装 EPEL：$ sudo yum install epel-release 包括应用有 Chromium RPMFusion：提供 Fedora 和 RedHat 由于开源协议或者是禁止商业用途而无法提供 RPM 安装包 包括两个仓库free、nofree free：开源软件但是由于其他原因无法提供 non-free：闭源软件，包括不能用于商业用途 包含应用有 mplayer gstreamer-pluginsXXXX ELRepo：包含和硬件相关的驱动程序 安装12$ rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org$ rpm -Uvh http://www.elrepo.org/elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm NuxDextop：包含与多媒体相关应用的 RPM 仓库 安装1$ rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm 说明 有的依赖在 EPEL 中，因此可能需要先安装 EPEL 和其他源有（RPMFusion）冲突时 可以设置默认情况下不启用，即修改 /etc/yum.repos.d/nux.dextop.repo 文件，设置 enable=0 需要时手动启用：$ yum --enablerepo=nux-dextop install &lt;PACKAGENAME&gt; 应用安装方式 包管理器 安装应用比较方便 但某些发行版中应用源更新缓慢 自行下载二进制版本安装 Linux 大部分应用是 noarch，即与架构无关，无需考虑兼容问题 下载源码编译安装 安装流程 查询文档安装编译依赖 ./configure配置编译选择，如：安装路径等 make &amp; make install 注意事项 自行安装应用可以若设置安装路径不是推荐路径，记得检查环境变量 XXXX_HOME 应用文件夹通常带有版本号，建议 保留文件夹版本号 另行创建无版本号符号链接指向所需版本文件夹 本地化字体 终端中字体需要为 monospace 在多语言环境下，非 monospace 字体字符宽度不同，导致字符重叠 字体名称不是字体文件名，其定义在字体文件内部定义 指定未安装字体只能通过文件名 指定已安装字体可直接使用字体名称 LocaleLocale：特定于某个国家、地区的编码设定 代码页 数字、货币、时间与日期格式","link":"/Linux/Configuration/os_to_do.html"},{"title":"Terminal、CLI、Shell、TTY","text":"Terminal Termianl 终端：计算机领域的终端是指用于 与计算机进行交互的输入输出设备，本身不提供运算处理功能 大部分情况下，终端将用户的字符以外键盘输入转为控制序列 但接收到 &lt;C-C&gt; 等特殊组合键时，发送特殊信号 Console 控制台：和计算机一体的特殊终端，用于管理主机，比普通终端权限更高 一台主机一般只有一个控制台，但可以连接多个普通终端 Console、Terminal随着PC普及已经基本时同义词 TTY TTY：原含义即为直电传打字机 TeletypePrinter、TeletypeWriter：键盘输入指令、纸带打印信号 UNIX 为支持电传打字机设计了名为 tty 的子系统 之后 tty 名称被保留成为终端的统称（虽然终端设备不局限于 tty） 类 UNIX 系统中 具体终端硬件设备抽象为操作系统内部 /dev/tty* 设备文件 /dev/tty[1-6] 即对应 6 个虚拟控制台 另外，早期计算机上 Serial Port 最大用途就是连接终端设备 所以会把行端口上设备同样抽象为 tty 设备 /dev/ttyS* 对应串口设备 Linux TTY/PTS概述 Linux 系统中，&lt;C-A—[F1-F6]&gt; 可以切换终端 可通过 $ stty -a 查看当前终端设置 分类 Character/Text Terminal：字符终端，只能接受、显示文本信息的终端 Dumb Terminal：哑终端 Intelligent Terminal：智能终端，相较于哑终端 理解转义序列 定位光标、显示位置 Graphical Terminal：图形终端，可以显示图形、图像 现在专门图形终端已经少见，基本被 全功能显示器 取代 Terminal Emulator终端模拟器：默认传统终端行为的程序，用于与传统的、不兼容图形接口命令行程序（如：GNU 工具集）交互 对 CLI 程序，终端模拟器假装为传统终端设备 对现代图形接口，终端模拟器假装为 GUI 程序 捕获键盘输入 将输入发送给 CLI 程序（bash） 得到命令行程序输出结果 调用图形接口（如：X11），将输出结果渲染至显示器 tty[1-6] 也是终端模拟器，只是不运行在图形界面中、由内核直接提供，也称虚拟控制台 Shell 和 Terminal Shell 更多指提供和内核交互入口的软件，提供 命令提示符 Prompt 行编辑、输入历史、自动补全（但是也有些终端自己实现 此功能） Terminal 更多指 IO 端口硬件，提供 上、下翻页查看内容 终端中复制、粘贴功能 Shell Shell：提供 用户界面 的程序，接受用户输入命令和内核沟通 Shell 向用户提供操作系统入口 避免普通用户随意操作导致系统崩溃 虽然Shell会调用其他应用程序，其他应用程序再调用系统调用，而不是直接与内核交互 Command-Line Interface：命令行 Shell，通常不支持鼠标，通过键盘输入指令 sh：Bourne Shell bash：Bourne-Again Shell zhs：Z Shell fish：Friendly Interactive Shell cmd.exe：这个应该看作是 Shell，而不是 Terminal 可与内核进行交互 接受键盘输入是其宿主的功能（即宿主作为隐式 Terminal Emulator） PowerShell GUI：Graphic User Interface 图形 Shell Windows 下的 explorer.exe","link":"/Linux/terminal.html"},{"title":"Shell 应用程序","text":"包管理apt install update remove autoremove clean rpmyum说明 yum在不使用yum makecache手动检查源配置文件时，可能 很长时间都不会更新cache，也就无法发现软件仓库的更新 （当然，可能和仓库类型有关，使用ISO镜像作为仓库时如此， 即使不挂载镜像，yum在执行其他操作也不会发现有个仓库无法 连接） dpkgzypperpacman库、依赖ldconfig创建、查看动态链接库缓存 根据/etc/ld.so.conf文件中包含路径，搜索动态链接库文件 ，创建缓存文件/etc/ld.so.cache 默认包含/lib、/lib64、/usr/lib、/usr/lib64， 优先级逐渐降低，且低于/etc/ld.so.conf中路径 参数 生成动态链接库缓存，并打印至标准输出 -v/--verbose：详细版 -n：仅扫描命令行指定目录 -N：不更新缓存 -X：不更新文件链接 -p：查看当前缓存中库文件 -f CONF：指定配置文件，默认/etc/ld.so.conf -C CACHE：指定生成缓存文件 -r ROOT：指定执行根目录，默认/（调用chroot实现） -l：专家模式，手动设置 -f Format/--format=Format：缓存文件格式 ld：老格式 new：新格式 compat：兼容格式 ldd查看程序所需共享库的bash脚本 通过设置一系列环境变量，如LD_TRACE_LOADED_OBJECTS、 LD_WARN、LD_BIND_NOW、LD_LIBRARY_VERSION、 LD_VERBOSE等 当LD_TRACE_LOAD_OBJECTS环境变量不空时，任何可执行程序 运行时只显示模块的依赖，且程序不真正执行 实质上是通过ld-linux.so实现 123$ /lib/ld-linux.so* --list exe$ ldd exe // 二者等价 ld-linux.so*参见cppc/func_lib.md 参数 -v：详细模式 -u：打印未使用的直接依赖 -d：执行重定位，报告任何丢失对象 -r：执行数据、函数重定位，报告任何丢失的对象、函数 打印 第1列：程序动态链接库依赖 第2列：系统提供的与程序需要的库所对应的库 第3列：库加载的开始地址 首行、尾行可能是两个由kernel向所有进程都注入的库 strings查看系统glibc支持的版本 objdump查看目标文件的动态符号引用表","link":"/Linux/Shell/sh_apps.html"},{"title":"Linux 归档、压缩","text":"归档、压缩tar多个文件保存进行归档、压缩 gzip压缩、解压缩gzip文件 gunzip解压缩gzip文件 zcmp调用diff比较gzip压缩文件 unzip解压缩zip文件 zip压缩zip文件 zcat查看zip压缩文件 zless查看zip压缩文件 zipinfo列出zip文件相关详细信息 zipsplit拆分zip文件 zipgrep在zip压缩文件中搜索指定字符串、模式 zmore查看gzip/zip/compress压缩文件 rpm2cpio将rpm包转变为cpio格式文件，然后可以用cpio解压 1$ rpm2cpio rpm_pkg | cpio -div","link":"/Linux/Shell/sh_compress.html"},{"title":"Shell 任务","text":"定时任务atq列出用户等待执行的作业 atrm删除用户等待执行的作业 watch定期执行程序 at设置在某个时间执行任务 1234567at now+2minutes/ now+5hours # 从现在开始计时at 5:30pm/ 17:30 [today] # 当前时间at 17:30 7.11.2018/ 17:30 11/7/2018/ 17:30 Nov 7 # 指定日期时间 # 输入命令之后，`&lt;c-d&gt;`退出编辑，任务保存 crontab针对用户维护的/var/spool/cron/crontabs/user_name文件，其中 保存了cron调度的内容（根据用户名标识） -e：编辑 -l：显示 -r：删除 任务计划格式见文件部分 任务、作业Crontab文件/var/spool/cron/crontabs/user_name使用用户名标识的每个用户的定时任务计划文件，文件中每行为一个 cron调度内容（也可以使用crontab -e直接编辑） 共6个字段，前5个字段为执行调度时间分配 分钟、小时（24）、日期（31）、月份（12）、星期 *表示每个当前时间 -时间区间 ,时间分隔 [range]/[n]：范围内每隔多久执行一次，范围为*可省 最后字段为调度内容 例 12343,15 8-11 */2 * * command # 每隔两天的8-11点第3、15分执行3,15 8-11 * * 1 command # 每个星期一的上午8-11点的第3、15分钟执行 /etc/crontabs系统级crontab文件，类似于用户crontab文件，只是多一个用户名 字段位于第6个 服务系统服务 服务systemctl脚本目录优先级从低到高 [/usr]/lib/systemd/system：系统、应用默认存放位置 ，随系统、应用更新会改变 /etc/systemd/system：推荐在此自定义配置，避免 被更新覆盖 12.include /lib/systemd/system/&lt;service_name&gt;.service# customized changes /run/systemd/system：进程运行时创动态创建服务文件 目录，仅修改程序运行时参数才会修改 自定义系统服务方法 创建&lt;service_name&gt;.service文件，其中写入配置 创建&lt;service_name&gt;.service.d目录，其中新建.conf 文件写入配置 系统服务控制命令systemctl参见linux/shell/cmd_sysctl .service&lt;some_name&gt;.service：服务配置unit文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445[Unit] # 包含对服务的说明Description= # 服务简单描述Documentation= # 服务文档Requires= # 依赖unit，未启动则当前unit启动失败Wants= # 配合unit，不影响当前unit启动BindsTo= # 类似`Requires`，若其退出则当前unit # 退出Before= # 若该字段指定unit要启动，则必须在 # 当前unit之后启动After= # 若该字段指定unit要启动，则必须在 # 当前unit之前启动Conflicts= # 冲突unitCondition= # 条件，否则无法启动Assert= # 必须条件，否则启动失败[Service] # 服务具体运行参数设置，仅 # *service unit*有该字段Type= # 服务启动类型PIDFile= # 存放PID文件路径RemainAfterExit= # 进程退出后是否认为服务仍处于激活ExecStartPre= # 服务启动前执行的命令ExecStartPost= # 服务启动后执行的命令ExecStart= # 服务具体执行、重启、停止命令ExecReload=ExecStop=Restart= # 重启当前服务的情况RestartSec= # 自动重启当前服务间隔秒数TimeoutSec= # 停止当前服务之前等待秒数PrivateTmp= # 是否给服务分配临时空间KillSignal=SIGTERMKillMode=mixedEnvironmen= # 指定环境变量[Install]WantedBy= # unit所属的target，`enable`至相应 # targetRequiredBy= # unit被需求的targetAlias= # unit启动别名Also= # `enable`当前unit时，同时被`enable` # 的unit Type：服务启动类型 simple：默认，执行ExecStart启动主进程 Systemd认为服务立即启动 适合服务在前台持续运行 服务进程不会fork 若服务要启动其他服务，不应应该使用此类型启动， forking：以fork方式从父进程创建子进程，然后父进程 立刻退出 父进程退出后Systemd才认为服务启动成功 适合常规守护进程（服务在后台运行） 启动同时需要指定PIDFile=，以便systemd能跟踪 服务主进程 oneshot：一次性进程 Systemd等待当前服务退出才继续执行 适合只执行一项任务、随后立即退出的服务 可能需要同时设置RemainAfterExit=yes，使得 systemd在服务进程推出后仍然认为服务处于激活状态 notify：同simple 但服务就绪后向Systemd发送信号 idle：其他任务执行完毕才会开始服务 dbus：通过D-Bus启动服务 指定的BusName出现在DBus系统总线上时，Systemd 即认为服务就绪 WantedBy：服务安装的用户模式，即希望使用服务的用户 multi-user.target：允许多用户使用服务 .target&lt;some_name&gt;.target：可以理解为系统的“状态点” target通常包含多个unit 即包含需要启动的服务的组 方便启动一组unit 启动target即意味将系统置于某个状态点 target可以和传统init启动模式中RunLevel相对应 但RunLevel互斥，不能同时启动 |RunLevel|Target| |——-|——-| |0|runlevel0.target或poweroff.target| |1|runlevel1.target或rescue.target| |2|runlevel2.target或multi-user.target| |3|runlevel3.target或multi-user.target| |4|runlevel4.target或multi-user.target| |5|runlevel5.target或graphical.target| |6|runlevel6.target或reboot.target| enable设置某个服务自启动，就是在服务配置.service中 WantedBy、RequiredBy指明的target注册 WantedBy向target对应目录中 /etc/systemd/system/&lt;target_name&gt;.target.wants 添加符号链接 RequiredBy向target对应目录中 /etc/systemd/system/&lt;target_name&gt;.target.required 添加符号链接 systemctl disable &lt;unit&gt;就是移除对应symlink .socket日志/etc/systemd/journal.confSystemd日志配置文件 Systemd（服务） Systemd作为新系统管理器，替代service更加强大 支持服务并行启动，提高效率 具有日志管理、快照备份和恢复、挂载点管理 包括一组命令 Systemd可以管理所有系统资源，不同资源统称为Unit service unit：系统服务 target unit：多个unit构成的组 devie unit：硬件设备 mount unit：文件系统挂载点 automount unit：自动挂载点 path unit：文件、路径 scope unit：不是由Systemd启动外部进程 slice unit：进程组 snapshot unit：Systemd快照，可以切换某个快照 socket unit：进程间通信socket swap unit：swap文件 timer unit：定时器 unit配置文件状态（无法反映unit是否运行） enabled：已建立启动链接 diabled：未建立启动链接 static：配置文件没有[Install]部分，只能作为 其他unit配置文件依赖，不能独立注册 masked：被禁止建立启动链接 systemd进程ID为1，掌管所有进程 unit配置文件参见linux/shell/config_files systemctl systemctl通过d-bus和systemd交流，在docker和wsl中可能 没有systemd-daemon，此命令可能不能使用，使用service 代替 查看服务、系统状态 status &lt;unit&gt;：查看系统、unit（服务）状态 -H &lt;host&gt;：查看远程主机unit状态 show &lt;unit&gt;：查看unit底层参数 -p &lt;attr&gt;：查看某个具体属性参数 三个查询状态的简单方法，方便脚本使用 is-active &lt;serivce&gt; is-failed &lt;serivce&gt; is-enabled &lt;serivce&gt; reset-failed &lt;unit&gt;：清除错误状态 list-units：列出所有已加载unit list-unit-files：列出所有系统中unit配置文件、状态 --type=：指定特定类型文件 --status=：指定特定状态文件 list-dependencies &lt;unit&gt;：查看依赖关系 -all：展开target类型 状态点/启动级别 get-default：查看默认target set-default &lt;target&gt;：设置默认target isolate &lt;target&gt;：切换target，其他target的unit将 被停止 设置服务、系统 start &lt;service&gt;：启动服务 stop &lt;service&gt;：关闭服务 enable &lt;service&gt;：开机自启动服务 行为参见linux/shell/config_files disable &lt;service&gt;：关闭开机自启动服务 enable启动后的服务仅仅disable不会立刻停止服务 kill &lt;service&gt;：杀死服务的所有子进程 mask &lt;service&gt;：禁用服务 无法通过start、restart启动服务 可以防止服务被其他服务间接启动 umask &lt;service&gt;：启用已禁用服务 daemon-reload：重新读取所有服务项 修改、删除、添加服务项后执行该命令 poweroff：关机 reboot：重启 rescue：进入rescue模式 配置文件 cat &lt;service_name&gt;.service：查看Unit定义文件 edit &lt;service_name&gt;.service：编辑Unit定义文件 reload &lt;service_name&gt;.service：重新加载Unit定义文件 journalctljournalctl：统一管理所有日志：内核日志、应用日志 -k：仅内核日志 --since：指定日志时间 -n：指定查看日志行数 -f：最新日志 _PID=：进程日志 _UID=：用户日志 -u：unit日志 -p：日志有限集 emerg：0 alert：1 crit：2 err：3 warning：4 notice：5 info：6 debug：7 --nopager：非分页输出 -o：日志输出格式 json json-pretty --disk-usage：日志占用空间 --vacuum-size=：指定日志占用最大空间 --vacuum-time=：指定日志保持时间 systemd-analyzesystemd-analyze：查看系统启动耗时 blame：查看各项服务启动耗时 critical-chain：瀑布状启动过程流 hostnamectlhostnamectl：查看主机当前信息 set-hostname &lt;hostname&gt;：设置主机名称 localectllocalctl：查看本地化设置 set-locale LANG=en_GB.utf8 set-keymap en_GB timedatectltimedatectl：查看当前时区设置 list-timezones：显示所有可用时区 set-timezone America/New_York set-time YYYY-MM-DD set-time HH:MM:SS loginctlloginctl：查看当前登陆用户 list-sessions：列出当前session list-users：列出当前登陆用户 show-user &lt;user&gt;：显示用户信息 service控制系统服务","link":"/Linux/Shell/sh_jobs.html"},{"title":"Linux 系统启动","text":"登陆、退出、关机、重启login登陆系统 logout退出shell exit退出shell（常用） rlogin远程登陆服务器 poweroff关闭系统，并将关闭记录写入/var/log/wtmp日志文件 ctrlaltdel强制或安全重启服务器 shutdown关闭系统 halt关闭系统 reboot重启系统 init 0/6关机/重启","link":"/Linux/Shell/sh_init.html"},{"title":"Shell 环境变量","text":"环境export显示、设置环境变量，使其可在shell子系统中使用 设置环境变量直接$ ENV=value即可，但是此环境变量 不能在子shell中使用，只有$ export ENV导出后才可 -f：变量名称为函数名称 -n：取消导出变量，原shell仍可用 -p：列出所有shell赋予的环境变量 系统环境变量NAME PATH：用户命令查找目录 HOME：用户主工作目录 SHELL：用户使用shell LOGNAME：用户登录名 LANG/LANGUAGE：语言设置 MAIL：用户邮件存储目录 PS1：命令基本提示符 PS2：命令附属提示符 HISTSIZE：保存历史命令记录条数 HOSTNAME：主机名称 /etc/passwd、/etc/hostname等文件中设置各用户部分 默认值，缺省随系统改变 PATHC PATH LIBRARY_PATH：程序编译时，动态链接库查找路径 LD_LIBRARAY_PATH：程序加载/运行时，动态链接库查找路径 动态链接库寻找由/lib/ld.so实现，缺省包含/usr/lib、 /usr/lib64等 建议使用/etc/ld.so.conf配置替代LD_LIBRARY_PATH， 或在编译时使用-R&lt;path&gt;指定 手动添加动态链接库至/lib、/usr/lib等中时，可能 需要调用ldconfig生成cache，否则无法找到","link":"/Linux/Shell/sh_envs.html"},{"title":"Shell 系统监控","text":"系统监控scar收集、报告、保存系统活动信息 iostat报告CUP统计数据，设备、分区输入/输出信息 iotopI/O监控 mpstat报告CPU相关统计数据 vmstat报告虚拟内存统计 tload加载显示系统平均负载、指定tty终端平均负载 time显示资源资源使用时间 uptime显示系统已运行时间 ipcs提供IPC设施信息 ipcrm删除消息队列、信号量集、共享内存ID lslk列出本地锁","link":"/Linux/Shell/sh_monitor.html"},{"title":"Shell 常用工具","text":"获取命令系统帮助help重看内部shell命令帮助信息（常用） man显示在线帮助手册（常用） infoinfo格式的帮助文档 打印、日期、时间echo输出至标准输出 env打印当前所有环境变量 cal显示日历信息 datedate：显示、设置系统日期时间 1date -d &lt;time&gt; &quot;+&lt;format&gt;&quot; -d：指定时间，缺省今天 +：指定输出格式 %Y-%m-%d %h-%M-%S：年月日时（24时）分秒 %a/%A：星期缩写、完整 %b/%B：月份缩写、完整 %D：MM/DD/YY %F：YYYY-MM-DD hwclock查看、设置硬件时钟 clockdiff主机直接测量时钟差 rdate通过网络获取时间 sleep暂停指定时间 数值计算bc任意精度计算器 expr将表达式值打印到标准输出，注意转义","link":"/Linux/Shell/sh_tools.html"},{"title":"Shell 本地化","text":"本地化字体fc- fc-list：列出系统已安装字体 12# 仅展示中文字体$ fc-list :lang=zh fc-cache：创建字体信息缓存文件 mkfontdir/mkfontscale：创建字体文件索引 字体安装 将字体文件复制至字体文件夹 $HOME/.fonts /usr/share/fonts fc-cache 更新缓存信息","link":"/Linux/Shell/sh_locale.html"},{"title":"Shell 用户配置","text":"用户、组用户信息/etc/passwd用户属性 用户名 口令：在/etc/passwd文件中以x显示 user-id：UID，用户标识 linux事实上不直接处理用户名，只识别UID UID对用户是唯一的 group-id：GID，用户的默认组标识 用户可以隶属多个不同的组，但是只有一个默认组，即用户 创建文件默认隶属的组 描述：用户描述 用户主目录：用户登陆目录 登陆shell：用户登陆系统使用的shell 缺省为空，可能是/bin/sh /etc/shadow用户口令属性 用户名 加密的密码 自1/1/1970起，密码被修改的天数 密码将被允许修改之前的天数（0为在任何时候可修改） 系统强制用户修改为新密码之前的天数（1永远不能修改） 提前警告用户密码过期前天数（-1无警告） 禁用用户账户在密码过期后天数（-1永不禁用） 用户被禁用天数（-1被启用） /etc/group群组账号信息文件 群组名 密码：以x显示 群组ID（GID） 系统群组：安装Linux以及部分服务型程序时自动设置的 群组，GID&lt;500 私人组群：由root新建的群组，默认GID&gt;500 附加用户列表 /etc/gshadow群组口令信息文件 /etc/sudoerssudo配置文件 根据配置文件说明取消注释即可赋予用户、组sudo权限 用户配置文件 login-shell：用户登陆（创建session）时的shell模式，该 模式下shell会自动执行profile文件 subshell：用户登陆后载入的shell的模式，该模式下shell会 自动执行rc文件 profile-一般在login-shell模式会执行一次，从名称看起来更像是 用户配置 全局、被所有用户默认执行的文件在/etc目录下，用户个人 profile在用户目录 ^profile$是所有类型shell（bash、zsh、ash、csh）都会 执行 不同类型的shell可能有其特定的profile文件，如： /etc/bash_profile、~/.bash_profile，不过不常见 （可以理解，毕竟是用户配置） 有的发行版本（ubuntu）还有有/etc/profile.d文件夹，在 /etc/profile中会设置执行其中的配置文件 rcrc应该是run command的简称，在每次subshell模式会执行，从 名称看起来更像是shell配置（很多应用配置文件rc结尾） 全局、被所有用户执行的文件在/etc目录下，用户个人rc 则在用户目录 应该是因为rc本来就是对shell的配置文件，所以是不存在 通用的^rc$配置的，最常用的bash对应就是~/.bashrc、 ~/bash.bashrc 总结 其实rc也会在用户登陆时执行 login-shell会立刻载入subshell？ profile里设置了立刻调用？ 应该写在profile里的配置 shell关系不大、更像是用户配置，如：特定应用环境变量 不需要、不能重复执行，因为rc在用户登录时已经执行 过一次，launch subshell时会重复执行，如： export PATH=$PATH:xxxx/bin/ 应该写在rc里的配置 和shell关系紧密的shell配值，如：alias 在用户登陆后会该边，需要在每次launch subshell时执行 的配置 配置文件执行顺序 没有一个确定顺序，不同的linux发行版本有不同的设置， 有的还会在脚本中显式写明相互调用，如：/etc/profile 中调用/etc/bashrc，~/.bashrc调用/etc/bashrc 但是可以确认的是/etc/profile一般是第一个被调用， ~/.xxxxrc、/etc/xxxxxrc中的一个最后调用 还有一些其他配置文件 ~/.bash_logout：退出bash shell时执行 对于wsl，可能是因为将用户登陆windows视为create session， ~/.profile好像是不会执行的 /etc/environment系统在登陆时读取第一个文件 用于所有为所有进程设置环境变量 不是执行此文件中的命令，而是根据KEY=VALUE模式的 代码，如：PATH=$PATH:/path/to/bin 用户命令用户类型 超级用户：root用户 系统用户：与系统服务相关的用户，安装软件包时创建 普通用户：root用户创建，权限有限 显示登陆用户w详细查询已登录当前计算机用户 who显示已登录当前计算机用户简单信息 logname显示当前用户登陆名称 users用单独一行显示当前登陆用户 last显示近期用户登陆情况 lasttb列出登陆系统失败用户信息 lastlog查看用户上次登陆信息 用户、用户组newusers更新、批量创建新用户 lnewusers从标准输入中读取数据创建用户 userdel删除用户账户 groupdel删除用户组 passwd设置、修改用户密码 chpassws成批修改用户口令 change更改用户密码到期信息 chsh更改用户账户shell类型 pwck校验/etc/passwd和/etc/shadow文件是否合法、完整 grpck验证用户组文件/etc/grous/和/etc/gshadow完整性 newgrp将用户账户以另一个组群身份进行登陆 finger用户信息查找 groups显示指定用户的组群成员身份 id显示用户uid及用户所属组群gid su切换值其他用户账户登陆 sudo以superuser用户执行命令 Archlinux中需要自行安装 配置文件为/etc/sudoers useradd/adduser创建用户账户（adduser：useradd命令的符号链接） -c：用户描述 -m：创建用户目录 -d：用户起始目录 -g：指定用户所属组 -n：取消建立以用户为名称的群组 -u：指定用户ID -s：指定用户登录shell 缺省为空，默认值应该是/bin/sh，很多发行版会设置 其为/bin/bash 查看$SHELL环境变量查看当前shell 文件/etc/shells包含支持shell类型 usermod修改用户 -e：账户有效期限 -f：用户密码过期后关闭账号天数 -g：用户所属组 -G：用户所属附加组 -l：用户账号名称 -L：锁定用户账号密码 -U：解除密码锁定 groupadd新建群组 -g：强制把某个ID分配给已经存在的用户组，必须唯一、非负 -p：用户组密码 -r：创建系统用户组 groupmod -g：设置GID -o：允许多个用户组使用同一个GID -n：设置用户组名","link":"/Linux/Shell/sh_usrgrp.html"},{"title":"文件、目录","text":"显示文本文件cat cat：显示文本文件内容 zcat：查看压缩文件内容 more more：单向分页显示文本文件 zmore：单向分页显式压缩文本文件 less less：双向分页显示文本文件内容 zless：双向分页显式压缩文件内容 headhead：显示文件指定前若干行 tailtail：实现文件指定后若干行 nlnl：显示文件行号、内容 文件处理sort对文件中数据排序 uniq删除文件中重复行 cut从文件的每行中输出之一的字节、字符、字段 diff逐行比较两个文本文件 diff3逐行比较三个文件 cmp按字节比较两个文件 tr从标准输入中替换、缩减、删除字符 split将输入文件分割成固定大小的块 tee将标准输入复制到指定温婉 expand将文件中tab转换为空格输出到标准输出 1$ expand -n 4 file_name nanoawk一门模式匹配的编程语言 主要功能是匹配文本并处理 同时还有一些编程语言才有的语法：函数、分支循环语句、变量 等等 使用awk可以 将文本文件视为字段、记录组成的文本数据库 操作文本数据库时能够使用变量 能够使用数学运算和字符串操作 能够使用常见地编程结构，如：条件、分支循环 能够格式化输出 能够自定以函数 能够在awk脚本中执行linux命令 能够处理linux命令的输出结果 命令行语法12$ awk [-F ERE] [-v assignment] ... program [argument...]$ awk [-F ERE] -f progfile ... [-v assignment] ... [argument ...] sedsed：非交互式、面向字符流的编辑器 sed也是默认从stdin读取输入、输出至stdout，除非 参数filename被指定，会从指定文件获取输入，但是注意 sed是面向字符流的编辑器，所以输入、输出文件不能是同一个 sed按行处理文本数据，每次处理一行在行尾添加换行符 1$ sed [-hnV] [-e&lt;script&gt;][-f&lt;script-file&gt;][infile] 参数 -e&lt;script&gt;/--expression=&lt;script&gt;：以指定script 处理infile（默认参数） 默认不带参数即为-e -f&lt;script-file&gt;/--file=&lt;script-file&gt;：以指定的script 文件处理输入文本文件 文件内容为sed的动作 -i：直接修改原文件 -n/--quiet：仅显示script处理后结果 -h/--help：帮助 -V/--version：版本信息 动作 [n]a\\string：行添加，在n行后添加新行string [n]i\\string：行插入 [n]c\\string：行替换 [n,m]d：删除，删除n-m行 [start[,end]]p：打印数据 [start[,end]]s/expr/ctt[/g]：正则替换 高级语法示例1234567891011121314151617$ sed '2anewline' ka.file$ sed '2a newline' ka.file$ sed 2anewline ka.file$ sed 2a newline ka.file # 在第2行添加新行`newline`$ sed 2,$d ka.file # 删除2至最后行$ sed 2s/old/new ka.file # 替换第2行的`old`为`new`$ nl ka.file | sed 7,9p # 打印7-9行$ sed &quot;:a;N;s/\\n//g;ta&quot; a.txt # 替换换行符 查找字符串、文件grep查找符合条件的字符串 egrep在每个文件或标准输入中查找模式 find列出文件系统内符合条件的文件 whereis插卡指定文件、命令、手册页位置 whatis在whatis数据库中搜索特定命令 which显示可执行命令路径 type输出命令信息 可以用于判断命令是否为内置命令","link":"/Linux/Shell/sh_viewer_editor.html"},{"title":"Linux 文件系统配置","text":"硬件磁盘挂载/etc/fstab/etc/fstab：包含存储设备、文件系统信息，配置自动挂载 各种文件系统格式硬盘、分区、可移动设备、远程设备 （即mount参数存盘） 1&lt;fs&gt; &lt;mountpoint&gt; &lt;type&gt; &lt;opts&gt; &lt;dump&gt; &lt;pass&gt; &lt;fs&gt;：挂载设备/分区名 /dev/sda：设备/分区名 UUID=xxxxx：使用设备UUID值表示设备 tmpfs：tmpfs分区，默认被设置为内存的一半（可在 &lt;opts&gt;中添加size=2G指定最大空间） 所有设备/分区都有唯一UUID，由文件系统生成工具mkfs. 创建文件系统时生成 &lt;mountpoint&gt;：挂载点，路径名（文件夹） / /boot 路径名中包含可以空格使用\\040（8进制）表示 &lt;type&gt;：文件系统类型 ext2 ext3 reiserfs xfs jfs iso9660 vfat ntfs swap tmpfs：临时文件系统，驻留在交换分区、内存中 提高文件访问速度，保证重启时自动清除这些文件 常用tmpfs的目录：/tmp、/var/lock、/var/run auto：由mount自动判断 &lt;opts&gt;：文件系统参数 noatime：关闭atime特性 不更新文件系统上inode访问记录，提高性能，否则 即使从缓冲读取也会产生磁盘写操作 老特性可以放心关闭，能减少loadcycle 包含nodiratime nodiratime：不更新文件系统上目录inode访问记录 relatime：实时更新inode访问记录，只有记录中访问 时间早于当前访问才会被更新 类似noatime，但不会打断其他程序探测，文件在 上次访问后是否需被修改（的进程） auto：在启动、终端中输入$ mount -a时自动挂载 noauto：手动挂载 ro：挂载为自读权限 rw：挂载为读写权限 exec：设备/分区中文件可执行 noexec：文件不可以执行 sync：所有I/O将以同步方式进行 async：所有I/O将以异步方式进行 user：允许任何用户挂载设备，默认包含 noexec,nosuid,nodev（可被覆盖） nouser：只允许root用户挂载 suid：允许set-user/group-id（固化权限）执行 set-user/group-id参见linux/shell/config_files nosuid：不允许set-user/group-id权限位 dev：解释文件系统上的块特殊设备 nodev：不解析文件系统上块特殊设备 umask：设备/分区中文件/目录默认权限掩码 权限掩码参见linux/kernel/file_system.md dmask：设备/分区中目录默认权限掩码 fmask：设备/分区中普通文件默认权限掩码 nofail：设备不存在则直接忽略不报错 常用于配置外部设备 defaults：默认配置，等价于 rw,suid,exec,auto,nouser,async &lt;dump&gt;：决定是否dump备份 1：dump对此文件系统做备份 0：dump忽略此文件系统 大部分用户没有安装dump，应该置0 &lt;pass&gt;：是否以fsck检查扇区，按数字递增依次检查（相同 则同时检查） 0：不检验（如：swap分区、/proc文件系统） 1：最先检验（一般根目录分区配置为1） 2：在1之后检验（其他分区配置为2） /etc/fstab是启动时配置文件，实际文件系统挂载是记录到 /etc/mtab、/proc/mounts两个文件中 根目录/必须挂载，必须先于其他的挂载点挂载 文件系统配置Ext 配置文件 /etc/mke2fs.conf 12345678910111213141516171819[defaults] base_features = sparse_super,large_file,filetype,resize_inode,dir_index,ext_attr default_mntopts = acl,user_xattr enable_periodic_fsck = 0 blocksize = 4096 # 块大小 inode_size = 256 # Inode 大小 inode_ratio = 16384 # 分配 Inode 号间隔[fs_types] ext3 = { features = has_journal } ext4 = { features = has_journal,extent,huge_file,flex_bg,metadata_csum,64bit,dir_nlink,extra_isize inode_size = 256 }[options] fname_encoding = utf8","link":"/Linux/File-System/fs_config.html"},{"title":"Linux 文件系统命令","text":"文件系统状态du、df https://www.junmajinlong.com/linux/du_df 目录、文件操作pwdpwd：显示当前工作目录绝对路径 cdcd：更改工作目录路径 缺省回到用户目录 -：回到上个目录 ls1$ ls [params] expr 列出当前工作目录目录、文件信息 参数 -a：列出所有文件，包括隐藏文件 -l：文件详细信息 详细信息格式、含义参见config_file -t：按最后修改时间排序 -S：按文件大小排序 -r：反向排序 -h：显示文件大小时增加可读性 -F：添加描述符到条目后 @：符号链接 *：文件 /：目录 -i：显示索引节点 输出结果 文件权限：包括10个字符 第1字符：文件类型 -；普通文件 d：目录 l：link，符号链接 s：socket b：block，块设备 c：charactor，字符设备（流） p：FIFO Pipe 第2-4字符：owner，文件属主权限 第5-7字符：group，同组用户权限 第8-10字符：other，其他用户权限 权限分别为r读、w写、x执行 相应位置为-表示没有此权限 执行位还可能是其他特殊字符 users：文件set-user-id、执行权限同时被置位 groups：文件set-group-id、执行权限同时被置位 userS：文件set-user-id被置位，执行权限未置位 groupS：文件set-group-id被置位，执行权限未置位 othert：文件sticky bit、执行权限均被置位 otherT：文件sticky bit被置位、执行权限未置位 关于权限具体含义，参见linux/kernel/file_system 权限设置，参见linux/shell/cmd_fds 文件数量 一般文件：硬链接数目 目录：目录中第一级子目录个数 文件属主名 文件属主默认用户组名 文件大小（Byte） 最后修改时间 文件名 dirs显示目录列表 touch创建空文件或更改文件时间 mkdir创建目录 rmdir删除空目录 cp复制文件和目录 mv移动、重命名文件、目录 rm删除文件、目录 删除目录link时，注意末尾不要带/，否则被认为是目录， 此时rm -r &lt;target&gt;会删除源目录中文件 file查询文件的文件类型 du显示目录、文件磁盘占用量（文件系统数据库情况） 参数 -a/--all：显示所有后代各文件、文件夹大小 否则默认为显示所有后代文件夹大小 -c/--total：额外显示总和 -s/--summarize：仅显示总和 --max-depth=[num]：显示文件夹的深度 -S/--separate-dirs：文件夹大小不包括子文件夹大小 -b/--bytes：以byte为单位 -k/--kilobytes：以KB为单位 -m/--megabytes：以MB为单位 -h：human-readable，提升可读性 -H/--si：同-h，但是单位换算以1000为进制 -x/--one-file-system：以最初处理的文件系统为准，忽略 其他遇到的文件系统 -L=/--dereference=：显示选项中指定的符号链接的源文件 大小 -D/--dereference-args：显示指定符号链接的源文件大小 -X=/--exclude-from=[file]：从文件中读取指定的目录、 文件 --exclude=[dir/file]：掠过指定目录、文件 -l/--count-links：重复计算hard-link wc统计文件行数、单词数、字节数、字符数 - `-l, -w, -c` tree树状图逐级列出目录内容 cksum显示文件CRC校验值、字节统计 mk5sum显示、检查MD5（128bit）校验和 sum为文件输出校验和及块计数 dirname输出给出参数字符串中的目录名（不包括尾部/） ，如果参数中不带/输出.表示当前目录 basename输出给出参数字符串中的文件、目录名 ln创建链接文件 stat显示文件、文件系统状态 文件、目录权限、属性chown更改文件、目录的用户所有者、组群所有者 chgrp更改文件、目录所属组 umask显示、设置文件、目录创建默认权限掩码 getfacl显示文件、目录ACL setfacl设置文件、目录ACL chacl更改文件、目录ACL lsattr查看文件、目录属性 chattr更改文件、目录属性 umask查看/设置权限掩码，默认0000 123456$ umask # 数字形式返回当前权限掩码$ umask -S # 符号形式返回当前权限掩码$ umask 0003 # 设置权限掩码为`0003` 权限掩码参见linux/kernel/permissions chmod关于文件、目录权限参见config_files###文件描述 普通用户只能修改user权限位 root用户可以修改任意用户、任意文件权限 参数 -R：对整个目录、子文件（目录）同时修改权限 操作12$ chmod [ugoa][+-=][rwxst] file$ chmod xxxx file ugoa：分别表示user、group、other、all权限位 +-=：表示增加、减少、设置权限 rwxst：表示5不同的权限 S、T不是一种权限，只是一种特殊的状态 设置状态时s时，是根据相应的x是否有确定s/S 设置状态t同理 xxxx：每个8进制数表示一组权限，对应二进制表示相应权限 是否置位 第1个数字：set-user-id、set-group-id、sticky bit 后面3个数字分别表示user、group、other权限 第1个数字位0时可以省略（常见） 示例12$ chmod u+s file1$ chmod 7777 file1 磁盘df文件系统信息 fdisk查看系统分区 mkfs格式化分区 fsck检查修复文件系统 mount查看已挂载的文件系统、挂载分区 umount卸载指定设备 free查看系统内存、虚拟内存占用","link":"/Linux/File-System/fs_cmds.html"},{"title":"Linux Interrupt","text":"中断 软中断： 硬中断：外围设备完成用户请求后，会向CPU发出中断信号 CPU会暂停执行下条将要执行的指令，转而执行中断信号 对应处理程序，并将进程转入内核态 Interrupt 中断属性 中断号：标识不同中断 中断处理程序：不同中断有不同处理程序 interrupt vector table：内核中维护，存储所有中断处理 程序地址 中断号就是相应中断在中断向量表中偏移量","link":"/Linux/IPC/ipc_interrupt.html"},{"title":"Ext 文件系统","text":"Ext 文件系统Ext 文件系统结构 dumpe2fs 命令可以获取 Ext 类文件系统信息 https://www.junmajinlong.com/linux/ext_filesystem/ Index NodeIndex Node/Inode 索引节点：记录文件的元信息 文件元信息 文件大小 访问权限 创建时间 修改时间 数据块位置 Inode 是文件的唯一标识，和文件一一对应 存储在磁盘中，占用磁盘空间，大小为 126B 整数倍 通常会把索引节点加载到内存中，加速文件的访问 Inode 并未存储 Inode 号、文件名，而是存储在文件所在目录的数据块中 Inode 号 Inode 号在同一文件系统内部唯一，可以、且被用于确定、定位 Inode 创建文件系统时，每个块组中起始 Inode 号、Inode Table 起始地址确定 Inode 号按分配比率（间隔字节数）预分配 若系统中大文件较多，Inode 分配比率应较大，避免 Inode Table 占用过大空间 根据 Inode 号、Inode 结构大小计算偏移即可查确定 Ext 预留部分 Inode 作特殊用途 0：不存在，用于标识已删除文件 1：虚拟文件系统，如：/proc、/sys 2：根目录 3：ACL 索引 4：ACL 数据 5：boot loader 6：未删除的目录 7：Reserved GDT 8：日志 11：首个非预留 Inode 号，通常是 lost+found 目录 Inode 大小默认值在 /etc/mke2fs.conf 文件中指定 ls -i 可查看文件 Inode 号 find 可以使用 -inum 参数寻找指定 Inode 号文件 Inode 寻址 Ext2/3 中 Inode 寻址混合直接查找、多级索引 Inode 中包含 15 个指针 i_block[0..14]，分为 4 级 i_block[0..11]：直接寻址指针，直接指向数据块 i_block[12]：一级间接寻址指针，指向存储指针的块 i_block[13]：二级间接寻址指针 i_block[14]：三级间接寻址指针 根据文件大小选择不同的寻址方法 文件小于 12block 时，直接用直接寻址指针 文件较大时则利用更高级别的间接寻址指针，多级索引 Ext2/3 对超大文件存取效率低下，需要核对指针过多 Inode 内容Hard Link 硬链接：指向 Inode（文件） 的 目录项 此处文件、硬链接说明 文件：Inode、相应数据块 硬链接：目录文件中目录项 硬链接是目录项 同一个文件的多个硬链接应是仅文件名不同的目录项 Ext 文件系统中 Inode 号、文件名均在存储在目录项中即完美支持硬链接 硬链接创建、删除 创建硬链接会增加文件的硬链接数 不能跨分区创建硬链接：不同分区 Inode 号会重复 不能手动对目录文件创建硬链接：防止路径混乱，文件系统已经为目录创建硬链接 .：当前目录硬链接 ..：上级目录硬链接 目录的硬链接数 = 2 + 一级子目录数 父目录中目录项 自身 . 目录项 子目录中 .. 目录项 删除文件实质上就是删除硬链接，文件的硬链接数量归 0 时才被真正删除 ls -l 中第二行即为文件的硬链接数（包含文件自身） / 根目录是自引用的（唯一），即 .. 也指向自身 Symbolic Link 符号链接 / 软链接：通过文件名的链接文件的 文件 符号链接是文件 文件内容可认为是指向的目标路径，这也决定温文件大小 符号链接文件本身也可以有多个硬链接、符号链接 一般不占用数据块，Inode 记录即可描述完成 只有符号链接指向的目标路径过长（大于 60B）时才会分配数据块 符号链接权限不重要，取决于最终目标文件 readlink 可以查看符号链接之 设备文件、FIFO、Socket 设备文件、FIFO、Socket 没有大小，不占用数据块，在 Inode 记录中即可描述完成 主设备号：标识设备类型 次设备号：标识同种设备类型的不同编号 Block GroupBlock Group 块组：逻辑上对块分组，提高查询效率 块组划分是文件系统创建的一部分 一个磁盘分区包含多个块组 块组是逻辑层面的划分，不会类似分区在磁盘上标记、划分 每个块组包含多个元数据区、数据区 元数据区：存储 Bmap、Inode Table、Imap 等数据 数据区：存储文件数据 块组特点 块组大小（包含块数）= 块 bit 数，即单个 block （作为）Bmap 能标记的块数量 此大小包含元数据区（也需要 Bmap 标记是否被占用） 块组设置的 Inode 数量、Inode Table 由系统决定 分区级 Block 以下这些块不会出现在所有块组中，存储文件系统级别信息 Boot Block Boot Block / Boot Sector：存放有 boot loader 的块 特点 位于分区的首个块 占用 1024B 只有装有系统的主分区、逻辑分区才有 Boot Block Boot Block 在不同分区时称为 主分区装有操作系统时：Volume Boot Records 逻辑分区装有操作系统时：Extended Boot Records MBR 会引导 VBR/EBR，开机启动时，首先加载 MBR 上 boot loader 单操作系统时，直接定位到所在分区的 Boot Block，加载此处的 boot loader 多操作系统时，加载 MBR 中 boot loader 后列出操作系统菜单，指向各分区的 boot block 通过 MBR 管理启动菜单方式已经被 Grub 取代 Super Block Super Block：存储文件系统信息、属性元数据 存储的信息包括 块组的 block 数量、Inode 号数量 文件系统本身的空闲 block 数量、Inode 数量 文件系统本身的属性信息：时间戳、是否正常、自检时间 （首个）超级块的位置取决于块大小 块大小为 1KB 时，引导块正好占用 1 个 block，则超级块号为 1 块大小大于 1KB 时，超级块和引导块均位于 0 号块 超级块对文件系统至关重要 超级块丢失和损坏必然导致文件系统损坏 Ext2 只在 0、1 和 3、5、7 的幂次块组中保存超级块信息 但文件系统只使用首个块组的超级块信息获取文件系统属性，除非损坏或丢失 有些旧式文件系统将超级块备份至每个块组 df 命令读取文件系统的超级块，统计速度快 Group Descriptor Table GDT 块组描述符表：存储块组的信息、属性元数据 Ext 每个块组使用 32B 描述，被称为块组描述符，所有块组描述符组成 GBT GDT 和超级块同时出现在某些块组中 默认也只会读取 0 号块组的中 GDT Reserved GDT：保留作为 GDT 使用的块（扩容之后块组增加） 和 GDT、超级块同时出现，同时修改 GDT、Reserved GDT、超级块在某些块组同时出现，能提升维护效率 块组级 BlockBlock BitmapBlock Bitmap/Bmap 块位图：标记各块空闲状态 Bmap 只优化写效率 向磁盘写数据时才需要寻找空闲块，读数据时按照索引读取即可 Bamp 查询速度足够快，则向磁盘写数据效率极大取决于磁盘的随机读写效率 Inode Table Inode Table：物理上将多个 Inode 合并存储在块中 Inode 大小一般小于块大小，合并存储能节约存储空间 Inode BitmapInode Bitmap/Imap 位图：标记各 Inode 号占用状态 Data Blocks Data Blocks：直接存储数据的块 数据占用的块由文件对应 Inode 记录中块指针找到 不同类型文件在数据块中存储的内容不同 常规文件：存储文件数据 目录：存储目录下文件、一级子目录 符号链接：目标路径名较短则直接存储在 Inode 中，否则分配数据块保存 目录文件数据块 目录文件数据块存储多条目录项，每条目录项包含目录下 文件 Inode 号 目录项长度 rec_len 文件名长度 name_len 文件类型 0：未知 1：普通文件 2：目录 3：*character devicev 4：block device 5：命名管道 6：socket 7：符号链接 文件名：文件名、一级子目录名、.、.. Directory EntryDirectory Entry/Dentry 目录项（缓存）：存放内存中的缩略版磁盘文件系统目录树结构 Dentry 中需要记录 文件名称 Inode 指针：与文件名建立映射关系 与其他目录项的层级关联关系 包括：父目录、子目录链表 多个目录项通过指针关联起来就形成目录结构 Dentry 是由内核维护，缓存在内存中 内核会把读过的文件用 Dentry 缓存在内存中，提高文件系统效率 Inode、Dentry 是一对多的关系 即一个文件可以有多个别字 硬链接实现就是多个 Dentry 中的 Inode 指向同一个文件 文件系统挂载 Mount 挂载：将文件系统关联到路径 文件系统必须要挂载在一定路径下才能被使用 文件系统体现在系统中即目录，即其文件系统的入口目录（根目录） 而入口目录无名、无显式 Inode 号 Ext 中文件名、Inode 号存储在父目录中，入口目录是文件系统最底层目录，不存在父目录 入口目录无名，所以挂载在任何目录下都是合理的 入口目录被预留 Inode 号为 2，可直接寻址 挂载方式 / 根目录下挂载根文件系统，在系统启动之初即挂载 其余文件系统则挂载在根文件系统的目录之下 挂载逻辑 挂载实现逻辑 新建 Inode，将其寻址指针指向待挂载文件系统 将挂载点目录 Inode 标记为不可用 修改挂载点目录在其父目录目录项至新建 Inode 挂载期间原目录会被遮蔽 挂载点仍然是所在文件系统的文件，但是其数据不在 同步挂载信息 挂载完成后，将挂载记录、相关信息写入 /proc/self/{mounts, mountstats, mountinfo} 同步 /proc/self/mounts 同步至 /etc/mtab（若有必要） 文件操作文件读取 / 文件系统在系统启动时即挂载，此时已经读取超级块、GDT 等文件系统块 同文件系统内 / 开头绝对地址 根据 GDT 确定各块组 Inode Table 块号 在 Inode Table 中查找 / 目录文件 Inode / Inode 号已知为预留 Inode 号 2，可直接在 Inode Table 中定位 获取 / 数据块，并读取其中目录项 在目录项中查找目标记录，获取文件 Inode 号 如上重复，直到找到目标文件 Inode，根据 i_block 寻址指针读取数据块 相对地址 按照所处目录的目录项获取 Inode 号，同绝对地址即可 跨文件系统地址 类似同文件系统 但挂载点目录会指向目标文件系统入口目录，再同绝对地址即可 文件删除 删除普通文件 同读取找到文件 Inode、数据块 将文件 Inode 硬链接数量减一 若硬链接数量归 0，执行删除，否则不变 将 Inode 中寻址指针删除 此时即无法找到文件数据 在 Imap 中标记文件 Inode 号为未使用 删除文件所属目录的目录项 实务中会将目录项 Inode 号标记为 0，避免产生空洞 此时文件即不可见 将 Bmap 中文件数据块块号标记为未使用 此时即释放文件占用空间，若此时有其他进程持有数据块的指针，则文件系统不会立即释放该空间 Ext 系统中此步骤会导致删除大文件效率低 删除目录文件 若目录非空，则尝试递归删除其中文件、子目录 若目录为空，类似普通文件删除目录 文件移动、重命名 同目录文件重命名：修改文件所属目录的目录项中文件名 同文件系统下移动：增、删目录项 文件移动不修改 Inode、Inode 号等 不同文件系统下移动：先复制、再删除 命名冲突时，覆盖会删除冲突文件，并修改相应目录项至新文件 因此，Ext 无法用同名子目录覆盖父目录，在尝试删除父目录时即失败 文件存储、复制 文件存储 读取 GDT，寻找空闲块组 根据块组 Imap 为文件分配未使用 Inode 号 在 Inode Table 中完善 Inode 中文件元数据 在所属目录中添加目录项 将数据写入数据块 Ext2/3 中每次调用 block 分配器为数据分配 1 个数据块，直至写入完毕 Ext4 中允许一次分配多个数据块 在 Inode Table 中更新 Inode 寻址指针 文件复制同文件存储 Ext2/3/4 迭代 Ext 文件系统特点 在创建时即划分好，方便使用时分配 不支持动态划分、分配 格式化超大磁盘时较慢 Ext3 日志功能 Ext2 中只有两个区：元数据区、数据区 从数据块中写入数据的中断中恢复检查一致性需要大量时间，甚至失败 Ext3 增加日志区 在向数据块中写入数据前会在日志区标记 则根据日志区的标记即可判断操作完成情况，提高一致性确认效率 Ext4 段分配 Ext2/3 中 Bmap 标记、分配块能提高效率，但扫描 Bmap 效率仍很低 多级索引寻址效率低 Ext4 中使用 extent 管理数据块 extent 尽可能包含物理上连续的块 Inode 中使用 4 个 extent 片段流替代多级索引指针 每个 extent 片段流设定起始块号、块数量 extent 指向的块保存数据或索引指针 支持调用一次 block 分配器分配多个块，并标记对应 Bmap Ext 删除数据 会依次释放 Bmap 位、更新目录结构、释放 Inode 空间","link":"/Linux/File-System/fs_ext.html"},{"title":"Linux 网络接口配置","text":"网络配置HOST/etc/hostname设置主机名称，直接填写字符串即可 1PC-NAME /etc/hostsipd地址-主机名称映射 理论上说，这里主机名称应该是本机称呼，不要求其他主机 /etc/hostname与这里的主机名一致 123127.0.0.1 localhostxxx.xxx.xxx.xxx namexxx.xxx.xxx.xxx domain.name DNS Resolver相关问题 Temporary failure in name resolution 问题：可能是DNS服务器配置缺失、错误 场景：$ ping 解决：设置nameserver配置DNS服务器地址 /etc/resolv.conf域名解析器（resolver）（DNS客户机）配置文件 设置DNS服务器IP地址、DNS域名 包含主机域名搜索顺序 1234nameserver 114.114.114.114 # DNS服务器IP地址domain localhost # 本地域名search search_list # 域名搜索列表sortlist # 允许将得到域名结果进行排序 说明 nameserver：可以有多行，每行一个ip地址，查询时按照 顺序依次查找 domain：声明主机域名 查询无域名主机时需要使用 邮件系统需要使用 未配置则使用主机名 search：其参数指明域名查询顺序 查询无域名主机时，将在其参数声明域中分别查找 domain、search不共存，同时存在时，后者覆盖前者 sortlist：对得到的域名结果进行特定排序 参数未网络/掩码对时，允许任意排列顺序 系统设置/etc/sysconfig/etc/sysconfig/network[-scripts]文件夹包含网卡配置文件 一般linux ifcfg-ethXX：linux默认ethernet网卡配置文件名称 ifcfg-wlanXX：无线局域网网卡配置文件名称 CentOS7网卡名称 前两个字符 en：Enthernet以太网 wl：WLAN无线局域网 ww：WWAN无线广域网 第3个字符 o&lt;index&gt;：on-board device index number, s&lt;slot&gt;：hotplug slot index number x&lt;MAC&gt;：MAC address p&lt;bus&gt;s&lt;slot&gt;：PCI geographical location/USB port number chain 命名优先级 板载设备：固件、BIOS提供的索引号信息可读：eno1 固件、BIOS提供的PCI-E热拔插索引号可读：ens33 硬件接口物理位置：enp2s0 linux传统方案：eth0 接口MAC地址：enxXXXXXXXXXXXXXXXXX，默认不使用， 除非用户指定使用 示例 enoXX：主板bios内置网卡 ensXX：主板bios内置PCI-E网卡 enpXXs0：PCI-E独立网卡 恢复传统命名方式编辑grub文件，然后使用grub2-mkconfig重新生成 /boot/grub2/grub.cfg，这样系统就会根据传统linux网卡文件 命名方式查找配置文件 123 # `/etc/sysconfig/grub`GRUB_CMDLINE_LINUX=&quot;net.ifnames=0 biosdevname=0&quot; # 为`GRUB_CMDLINE_LINUX`增加2个参数 CentOS7配置格式123456789101112131415161718192021222324252627282930313233343536373839404142434445DEVICE=ens33 # 网络连接名称（实际显示的网络名称）NAME=ens33 # 网卡物理设备名称TYPE = Ethernet # 网卡类型：以太网ONBOOT=yes # 开机启动：是DEFROUTE=yes # 是否设置此网卡为默认路由：是NM_CONTROLLED=yes # 是否可由Network Manager托管：是BOOTPROTO=dhcp # 网卡引导协议 # `none`：禁止DHCP # `static`：启用静态IP地址 # `dhcp`：开启完整DHCP服务IPADDR=xxx.xxx.xxx.xxx # IP地址IPV4_FAILURE_FATAL=no # IPV4致命错误检测（失败禁用设备）：否IPV6INIT=yes # IPV6自动初始化：是IPV6_AUTOCONF=yes # IPV6自动配置：是IPV6_DEFROUTE=yes # IPV6是否可为默认路由：是IPV6_FAILURE_FATAL=no # IPV6致命错误检测（失败禁用设备）：否IPV6_ADDR_GEN_MODE=stable-privacy # IPV6地地址生成模型：stable-privacyDNS1=xxx.xxx.xxx.xxx # DNS服务器地址1DNS2=xxx.xxx.xxx.xxx # DNS服务器地址2PEERDNS=no # 是否允许DHCP获得DNS覆盖本地DNS：否GATEWAY=xxx.xxx.xxx.xxx # 网关PREFIX=24 # 子网掩码使用24位NETMASK=255.255.255.0 # 子网掩码 # 两个参数应该只需要使用一个即可BROADCAST= HWADDR=xxxxxxxxxx # 接口MAC地址 # 配置文件都会被执行，`HWADDR` # 能匹配上硬件，配置才会生效， # 否则硬件使用默认配置 # 若多个配置文件配置相同`HWADDR` # 则操作network服务时报错UUID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx # 通用唯一识别码：不能相同（注意虚拟机）PROXY_METHOD=none # 代理方式：无BROWSER_ONLY=no # 仅浏览器：否USERCTL=no # 是否允许非root用户控制此设备：否MASTER= # 主设备名称？SLAVE= # 从社会名称？NETWORK= # 网络地址","link":"/Linux/Network/net_config.html"},{"title":"Linux文件系统设计","text":"文件系统磁盘存储 Sector 扇区：扇区概念来源于机械硬盘，指磁盘上各磁道上的扇环 物理扇区：磁盘读写的最小单位 早期硬盘多为 512B 大小，新式硬盘多为 4096B 或更高以提高数据记录密度 逻辑扇区：硬盘可以接受读写指令的最小操作单元 为兼容性而设计，硬盘内部将物理扇区逻辑上划分多个 512B 扇区片段提供给文件系统 实际读写时由硬盘固件负责逻辑扇区、物理扇区间转换，对文件系统透明 Logical Block Address （逻辑）块/簇：多个扇区组成的操作系统最小读写单位 常见的块大小为 4KB，一般为扇区 $2^N$ 倍 特点 提高了读写效率 减少文件碎片 造成一定空间浪费 分区：从磁盘上划分出了的连续的扇区 分区格式化：对分区范围内扇区使用进行规划 引导分区设置 扇区分组为块、编号 分区对齐：将逻辑块对齐到磁盘物理扇区 分区格式化是按照逻辑扇区划分，若分区中存储起始位置没有对齐至物理扇区边缘，则分区中块也无法对齐到物理扇区边缘 分区未对齐更多是因为引导区占用扇区数不是物理扇区整数倍，导致之后存储区域无法对齐 则分区一般是将分区起始位置对齐到物理扇区整数倍处即可 分区未对齐时，操作系统每次读、写会多读、写一个物理扇区，降低磁盘性能 4K 对齐：多数磁盘物理扇区大小为 4K，实际对齐需检查物理扇区大小 固态存储同样有扇区概念，但还有页等概念，更加复杂 磁盘存储区域 超级块：存储文件系统的详细信息，文件系统挂载时载入内存 块数量 块大小 空闲块 索引节点区：存储索引节点，文件被访问时载入内存 数据块区：存储文件、目录数据 文件 Linux 系统中：一切皆文件 普通的文件 目录（不是目录项） 同样用 Inode 唯一标识 其中存储的内容是子目录、文件 块设备 管道 Socket 文件读写 操作系统会跟踪进程打开的所有文件，即为每个进程维护一个打开文件表 文件表中每项代表文件描述符（open 函数返回） 即文件描述符是打开文件的标识 文件表中维护打开文件状态、信息 文件指针：系统跟踪上次读写位置作为当前文件位置指针，对某进程唯一 文件打开计数器：跟踪文件打开、关闭数量，仅计数为 0 时关闭文件，删除条目 文件磁盘位置：避免磁盘交互 访问权限（访问模式）：方便操作系统允许、拒绝 I/O 请求 文件系统屏蔽了用户字节操作和磁盘数据块操作之间差异 用户读取 1byte 数据时，文件系统获取所在块，返回所需部分 用户写入 1byte 数据时，文件系统获取应写入的块，修改后写回 文件在磁盘中的存储 连续空间存储方式：文件存储在磁盘连续的物理空间中 需预先知道待存储的文件大小：Inode 中需包含文件起始块位置、长度 特点 读写效率高 磁盘空间碎片化 文件长度不易扩展 非连续空间存放方式：链表方式 隐式链表：文件头中包含首块、尾块位置，各数据块中包含指向下个数据块的指针 无法直接访问数据块：只能通过指针顺序访问 稳定性差：任何指针丢失、损坏都会导致文件数据损坏 显式链表：将链接各数据块的指针显式存储在链接表（File Allocation Table）中（改进隐式链表问题） 链接表为每个磁盘设置一张，其中每项表示一个数据块，内容为下个数据块指针 链接表可存放在内存中以提高检索速度，但会占用内存空间，也因此不适合大磁盘 长期使用会使文件资料逐渐分散 特点 可消除磁盘碎片 文件长度可动态扩展 存储指针的有额外空间开销 索引存储方式：为每个文件创建索引数据块，存储指向文件数据块的指针列表 文件头中需包含指向索引数据块的指针 特点 文件创建、增大、缩小方便 无磁盘碎片问题 支持顺序读写、随机读写 存储索引有额外空间开销 文件系统效率与查找策略高度相关 大文件支持扩展 链式索引块：链表链接索引 多级索引块：索引索引索引 文件系统文件系统：操作系统用于明确存储设备或分区上文件的方法和数据结构 文件系统即在存储设备上组织文件（持久数据）的子系统 基本数据单位是文件，对文件的组织方式的不同即形成不同的文件系统 存储设备：磁盘、光盘、网络存储、虚拟数据 存储设备可以包含多个文件系统 Virtual File System 虚拟文件系统：包含一组所有文件系统都支持的数据结构和标准接口 作为提供给用户的统一接口 操作系统中负责管理、存储文件信息的软件称为文件管理系统，简称文件系统 文件系统分类 磁盘文件系统：数据存储在磁盘中 EXT2 Linux 的正宗文件系统，早期常用 支持 undelete，误删文件可恢复，但是操作比较麻烦 EXT3 由 EXT2 发展而来 支持大文件 不支持反删除，Redhat、Fedora 推荐 ReiserFS 支持大文件 支持反删除，操作简单 内存文件系统：数据存储在内存中 如：/proc、/sys 等文件系统 读写此类文件实际上是读写内核中相关数据 网络文件系统：访问其他计算机主机数据的文件系统 NFS SMB FileSystem File Size Limit Filesystem Size Limit ext2/ext3 with 1KB blocksize 16448MB 2048GB ext2/ext3 with 2KB blocksize 256GB 8192GB ext2/ext3 with 4KB blocksize 2048GB 8192GB ext2/ext3 with 8KB blocksize 65568GB 32TB ReiserFS3.5 2GB 16TB ReiserFS3.6 1EB 16TB XFS 8EB 8EB JFS with 512B blocksize 8EB 512TB JFS with 4KB blocksize 8EB 4PB NFSv2(client side) 2GB 8EB NFSv3(client side) 8EB 8EB 文件系统要先挂在在某个目录上才能正常使用，Linux 会把文件系统挂载到根目录 File Allocation Table FAT 文件分配表：采用 FAT 显式链表组织文件的文件系统 简单，几乎所有的个人操作系统均支持，适合移动介质的文件系统 FAT12：12bits 寻址长度 FAT16：16bits 寻址长度 FAT32：目前只使用了其中 28bits 寻址长度 按 4KB 块计算，FAT32 最大容量为 1TB FAT32 起始扇区中记录有扇区总数，此限制 FAT32 最大容量 2TB FAT32 最大支持 4GB 大小文件 Extended File Allocation Table 优点 允许更大分区容量、更大文件、更大逻辑块大小 采用空余空间寻址，空间分配、删除性能得以改进 缺点 兼容性不如 FAT32：旧设备、UEFI 不支持 https://zh.wikipedia.org/wiki/%E6%AA%94%E6%A1%88%E9%85%8D%E7%BD%AE%E8%A1%A8 https://zhuanlan.zhihu.com/p/121807427 https://zh.wikipedia.org/wiki/ExFAT 权限设计 r：读文件 w：修改、删除文件 x：可以执行文件 s：强制位权限（固化用户/组权限） set-user-id：user执行权限位出现 set-group-id：group执行权限位出现 t：粘滞位权限（在swap中停留） 权限判断规则 linux中权限是根据user-id、group-id判断用户和资源 关系，然后选择相应的类型用户（user、group、other）权限组 判断是否有相应权限 需要注意的是，访问资源实际上不是用户，而是用户开启的 进程，所以这里涉及了4中不同的用户标识 real-user-id：UID，用户id real-group-id：GID，用户默认组id effective-user-id：是针对进程（可执行文件）而言， 指内核真正用于判断进程权限的user-id effective-group-id：同effective-user-id，内核 判断真正判断进程权限的group-id 一般情况下effective-user-id就是read-user-id，即启动 进程用户的UID，所以一般来说用户创建的进程的对资源访问 权限就是就是自身权限 可执行文件权限 r：读文件 w：写文件 x：执行文件 s权限当可执行文件具有set-user-id权限时 其他用户执行该文件启动的进程的effective-user-id不再是 real-user-id，即和执行用户的UID不再一致，而是用户属主 的UID 内核根据进程effective-user-id判断进程权限，进程的权限 实际上同属主的权限，而不是执行用户权限 这样用户就在执行这种可执行文件，暂时拥有该可执行文件属主 执行该可执行文件权限，否则可能由于进程访问其他资源原因 无法正常执行 可看作是将属主的部分权限（在该文件上涉及到的权限） 固化在文件上 set-group-id类似的可以看作是将属主默认组权限固化在文件上 t权限 文件被执行时，文本段会被加载到swap中，程序结束后仍然 保留在swap中 下次执行文件时，文本段直接从swap中加载，因为swap为连续 block，加载速度会提高 目录权限说明linux中目录是一种特殊的文件，其包含目录下所有文件（包括 子目录）的文件名、i-node号 r：列出目录下所有文件 w：增加、删除、重命名目录下的文件 x：可以是（搜索）路径的一部分 即必须对要访问的文件中路径中所有目录都有执行权限 可以将目录执行权限看作是过境证明 s：好像没啥用 t：用户只能增加、删除、重命名目录下属于自己文件 对w权限补充，否则用户拥有目录w权限则可以操作目录 下所有文件 /home目录权限就是1777，设置有粘滞位权限 权限掩码文件/目录默认权限 = 现有权限（0777）减去权限掩码 权限掩码设置参见linux/shell/cmd_fs、 linux/shell/config_file、","link":"/Linux/File-System/fs_vfs.html"},{"title":"Linux 网络接口命令","text":"网络ping向被测试目的主机地址发送ICMP报文并收取回应报文 -c：要求回应的次数 -i：发送ICMP报文时间间隔 -R：记录路由过程 -s：数据包大小 -t：存活数值（路由跳数限制） ifconfig显示、设置网络 netmask：设置网卡子网掩码 up：启动指定网卡 down：关闭指定网络设备 ip：指定网卡ip地址 netstat显示与网络相关的状态信息：查看网络连接状态、接口配置信息、 检查路由表、取得统计信息 -a：显示网络所有连接中的scoket -c：持续列出网络状态 -i：显示网络界面信息表单 -n：直接使用IP地址而不是主机名称 -N：显示网络硬件外围设备号连接名称 -s：显示网络工作信息统计表 -t：显示TCP传输协议连接状况 route查看、配置Linux系统上的路由信息 traceroute跟踪UDP路由数据报 -g：设置来源来路由网关 -n：直接使用IP地址而不是主机名称 -p：设置UDP传输协议的通信端口 -s：设置本地主机送出数据包的IP地址 -w：超时秒数（等待远程主机回报时间）","link":"/Linux/Network/net_cmds.html"},{"title":"Linux 进程调度命令","text":"进程管理ps查看当前进程瞬时快照 top显示当前正在运行进程（动态更新） 按照使用内存大小排序，可以用于查找内存使用情况 pgrep按名称、属性查找进程 pidof根据进程名查找正在运行的进程进程号 kill终止进程 killall按名称终止进程 pkill按名称、属性终止进程 timeout在指定时间后仍然运行则终止进程 wait等待指定进程 fuser显示使用指定文件、socket的进程 pmap报告进程的内存映射 lsof列出打开的文件 chkconfig为系统服务更新、查询运行级别信息 作业&amp;放在命令之后，命令后台执行 123$ ./pso &gt; pso.file 2&gt;&amp;1 &amp; # 将`pso`放在后台运行，把终端输出（包括标准错误） # 重定向的到文件中 nohup不挂起job，即使shell退出 1234$ nohup ./pso &gt; pso.file 2&gt;&amp;1 &amp; # 不挂起任务，输出重定向到文件$ nohup -p PID # 不挂起某个进程 jobs列出活动的作业 -l：返回任务编号、进程号 bg恢复在后台暂停工作的作业 12$ bg %n # 将编号为`n`的任务转后台运行 fg将程序、命令放在前台执行 12$ fg %n # 将编号为`n`的任务转前台运行 setsid在一个新的会话中运行程序 1234$ setsid ./test.sh &amp;` # 新会话中非中断执行程序，此时当前shell退出不会终止job$ (./test.sh &amp;) # 同`setsid`，用`()`括起，进程在subshell中执行 `disown123$ disown -h %job_id # *放逐*已经在后台运行的job， # 则即使当前shell退出，job也不会结束 screen创建断开模式的虚拟终端 123456$ screen -dmS screen_test # 创建断开（守护进程）模式的虚拟终端screen_test$ screen -list # 列出虚拟终端$ screen -r screen_test # 重新连接screen_test，此时执行的任何命令都能达到nohup 快捷键 &lt;c-z&gt;：挂起当前任务 &lt;c-c&gt;：结束当前任务","link":"/Linux/Process-Schedual/ps_cmds.html"},{"title":"Vim 配置","text":"打印信息 :echo：打印信息，但是信息不会保存 :echom：打印信息会保存在:messages中 :messages：查看:echom保存的信息 设置选项 设置选项方式 命令行一次设置多个选项：:set number numberwidth=6 本地缓冲区设置：:setlocal nonumber 设置 bool 选项 :set &lt;name&gt;：打开选项 :set no&lt;name&gt;：关闭选项 :set &lt;name&gt;!：切换选项 :set &lt;name&gt;?：查看选项值（返回或no） 设置键值选项 :set &lt;name&gt;=value：设置选项值 :set &lt;name&gt;?：查看选项值 键值选项支持运算：+= 等 statusline 状态栏设置 状态栏代码通用格式：%-0{minwid}.{maxwid}{item} -：左对齐 0：使用”0”填充 %=：切换到状态栏右侧 %f：文件名 %F：完整路径文件名 %y：文件类型（[text]，[python]） %Y：文件类型（TEXT，PYTHON） %l：当前行号 %L：总行数 %v/%V：列号 %c：字符列号 %p：文件位置百分比 %n：buffer number %{&amp;ff}：文件格式（DOS、UNIX） %b：当前字符ACSII码 %B：当前字符16进制值 %m：modified flag（[+]，[-]表示不可修改） 设置状态栏显式格式，既可以一行完成配置，也可以分开配置 123456set statusline=%f\\ -\\ filetype:\\ %yset statusline=%fset statusline+=%=set statusline+=%lset statusline+=/set statusline+=%L 中间空格需要用“\\“转义，“%%”转义“%” laststatus：设置状态栏显示模式 1：默认值，两个以上窗口才显示 2：一直显示 折叠设置 foldmethod manual：手动折叠选中的行（默认 zf 触发） marker：{{{` 到 `}}} 标记待折叠行（默认 za 触发） indent：折叠缩进 syntax：语法折叠 foldlevel=&lt;num&gt;：设置 indent 折叠起始水平（zm 触发），即从 &lt;num&gt; 水平开始尝试折叠 foldlevelstart=&lt;num&gt;：设置文件打开时默认折叠水平 -1：初始不折叠 foldcolumn=&lt;num&gt;：用 &lt;num&gt; 行表示可可折叠状态 一些常用关键字 iskeyword=@,_,48-57,192_255：指定关键字 下划线 ASCII 码位在 48-57 之间的字符（0-9）、192-255之间的字符 conceallevel=0：隐藏等级 1 2 键盘映射 https://yianwillis.github.io/vimcdoc/doc/map.html 1:&lt;mode&gt;map &lt;mark&gt; {lhs} {rhs} 注意：映射后不能跟注释，vim会认为整行都是命令 映射工作模式 映射的工作模式可区分 6 种 normal 模式：输入命令时 visual 模式：可视区域高亮并输入命令时 select 模式：类似可视模式，但键入的字符对选择区替换 operator-pending 模式：操作符等待中 insert 模式：包括替换模式 command-line 模式：输入 :、/ 命令时 映射命令设置 映射命令设置的模式如下，对应都有如下非递归、取消命令 &lt;mode&gt;noremap[!]：非递归映射，即不会在其他映射中再次被展开 &lt;mode&gt;unmap[!]：取消映射 &lt;mode&gt;mapclear[!]： |命令|模式| |——-|——-| |:map|normal、visual、select、operator-pending| |:nmap|normal| |:vmap|visual、select| |:smap|selection| |:xmap|visual| |:omap|operator-pending| |:map!|insert、command-line| |:imap|insert| |:lmap|insert、command-line、Lang-Arg| |:cmap|command-line| |:tmap|终端作业| 特殊参数 映射特殊参数 &lt;buffer&gt;：映射将局限于当前缓冲区 优先级比全局映射高 清除映射时同样需要添加参数 可使用 &lt;leader&gt; 替代 &lt;localleader&gt; 可工作，但是不推荐 &lt;nowait&gt;：存在较短映射时，失效以其作为前缀的较长映射 &lt;silent&gt;：映射不在命令行上回显 &lt;special&gt;：特殊键可以使用&lt;&gt;记法 &lt;script&gt;：映射只使用通过以&lt;SID&gt;开头来定义的脚本局部映射来重映射优右值中的字符 &lt;unique&gt;：若存在相同命令、缩写则定义失败 定义局部映射时，同样会检查全局映射 &lt;expr&gt;：映射的右值将被作为表达式被计算 特殊参数说明 特殊参数的尖括号&lt;&gt;是本身具有的，必须紧跟命令后面 有些特殊参数在取消映射时同样需注明 omap 应用方法：operator （操作） + operator-pending （移动、范围选择） 预定义的 operator-pending 映射如 w、aw、i(、t, |按键 |操作 |移动 | |———-|———————-|———————-| |dw |删除(delete) |到下一个单词 | |ci( |修改(change) |在括号内 | |yt, |复制 |到逗号前 | 自定义的 operator-pending 映射则需要 选取一定范围：可同时指定开头、结尾（一般通过进入 visual 模式下选择范围） 1234567&quot; 下个括号内内容onoremap in( :&lt;c-u&gt;normal! f(vi(&lt;cr&gt;&quot; 当前括号内容onoremap il( :&lt;c-u&gt;normal! f)vi(&lt;cr&gt;`&quot; 选取使用 `===` 标记 markdown 标题onoremap ih :&lt;c-u&gt;execute &quot;normal! ?^==\\\\+$\\r:nohlsearch\\rkvg_&quot;&lt;cr&gt;onoremap ah :&lt;c-u&gt;execute &quot;normal! ?^==\\\\+$\\r:nohlsearch\\rg_vk0&quot;&lt;cr&gt; 指定光标位置：光标当前位置为开头、指定位置为结尾 12&quot; 移动至 `return` 前一行onoremap b /return&lt;cr&gt; leaders、localleaderleader、localleader：作为“前缀”的不常用的按键，后接其他字符作为整体映射 用途 避免覆盖太多按键原始功能 约定俗成的规范，容易理解 方便更改 &lt;leader&gt;、&lt;localleader&gt; 作为前缀设置 &lt;leader&gt;：对全局映射而设置的映射的前缀 &lt;localleader&gt;：只对某类（个）文件而设置的映射的前缀 &lt;leader&gt; 和 &lt;localleader&gt; 除了设置不同以外，没有太大区别，应用场合时约定规范，不是强制性的 &lt;leader&gt;、&lt;localleader&gt; 设置 1234:let mapleader = &quot;-&quot;:nnoremap &lt;leader&gt;d dd:let maplocalleader = &quot;\\\\&quot;:nnoremap &lt;buffer&gt; &lt;localleader&gt;c I#&lt;esc&gt; vim 会对 mapleader、maplocalleader 进行特殊的处理，不是简单的声明 Abbreviations 缩写 iabbrev：紧跟缩写输入非关键字后，缩写会替换为相应的完整字符串 相较于映射 iabbrev 用于 insert、replace、command-line 模式 iabbrev 会注意缩写前后的字符，只在需要的时候替换 iabbrev 同样支持特殊参数 &lt;buffer&gt;：仅限本地缓冲区 12345678&quot; 纠错iabbrev waht what&quot; 简化输入iabbrev @@ xyy15926@gmail.com&quot; 替换 `----` 为前个单词iabbrev &lt;buffer&gt; ---- &amp;mdash&quot; 替换 `return` 为 nulliabbrev &lt;buffer&gt; return nopenopenope :set iskeyword? 即可查看关键字字符 Autocmd 自动命令autocmd 使用 autocmd 注意事项 同时监听多个事件，使用 , 分隔，中间不能有空格 一般同时监听 bufnewfile、bufread，这样打开文件时无论文件是否存在都会执行命令 所有事件后面都需要注明适用场景，可用*表示全部场景，中间也不能有空格 autocmd 是定义命令，不是执行命令 每次执行都会定义命令，而vim 不会忽略重复定义 如：:autocmd bufwrite * :sleep 200m，每次执行时都会重复定义命令 缓冲区事件 1234autocmd bufnewfile * :writeautocmd bufnewfile *.txt :writeautocmd bufwritepre *.html :normal gg=gautocdm bufnewfile,bufread *.html setlocal nowrap filetype 事件（vim 设置缓冲区 filetype 时触发） 1234autocmd filetype javascript nnoremap &lt;buffer&gt; &lt;localleader&gt;c i//&lt;esc&gt;autocmd filetype python nnoremap &lt;buffer&gt; &lt;localleader&gt;c i#&lt;esc&gt;autocmd filetype javascript :iabbrev &lt;buffer&gt; iff if ()&lt;left&gt;autocmd filetype python :iabbrev &lt;buffer&gt; iff if:&lt;left&gt; augroup 自动命令组 自动命令组 1234augroup cmdgroup autocmd bufwrite * :echom &quot;foo&quot; autocmd bufwrite * :echom &quot;bar&quot;augroup end 注意事项 类似 autocmd，vim 不会忽略重复定义，但是可以通过 :autocmd! 清除一个组 :augroup cmdgroup : autocmd! : autocmd bufwrite :echom “foo” : autocmd bufwrite :echom “bar” :augroup end Vim安装安装选项12345678$ ./configure --with-features=huge\\ --enable-multibyte \\ --enable-python3interp \\ --with-python3-config-dir=/usr/lib64/python3.4/config-3.4m/ \\ --enable-pythoninterp \\ --with-python-config-dir=/usr/lib64/python2.7/config/ \\ --prefix=/usr/local --enable-cscope 按照以上命令配置，编译出的Vim版本中是动态支持 +python/dyn和 +python3/dyn 此时Vim看似有python支持，但是在Vim内部 :echo has(&quot;python&quot;)和:echo has(&quot;python3&quot;)都返回0 之后无意中尝试去掉对python的支持，编译出来的Vim就是 可用的python3，不直到为啥","link":"/Linux/Tool/Vi/config.html"},{"title":"Vim KeyMapper CMD","text":"Vim模式Normal模式Insert模式Visual模式Quickfix模式quickfix模式主要思想时保存一个位置列表，然后提供一系列命令， 实现在这个位置列表中的跳转 位置列表来源 编译器输出信息 grep命令输出信息（cscope命令） :vimgrep命令 quickfix中常用的命令有 :copen/:cw：打开quickfix模式窗口 :cclose：关闭quickfix窗口 :cc：显示详细错误信息 :cp：跳至下一个错误 :cn：跳至上一个错误 :cl：列出所有错误 :cw：如果有错误列表，则打开quickfix窗口 :colder/col：到前一个旧错误列表 :cnewer/cnew：到后一个新错误列表 Ex模式底层编辑模型，normal下Q进入 Paste模式Motion快捷键normal模式下移动，visual模式下选取，无特殊说明visual和normal 模式通用 固定移动基本 hjkl：左、上、下、右 gj/gk：虚上、虚下（光标移动排版意义上行） （可以尝试noremap交换和j/k的逻辑方便使用） M：窗口中间行首各非空白字符 H/L：窗口顶/底scrolloff处行首各非空白字符 &lt;c-i&gt;/&lt;c-o&gt;：跳至下一个/上一个编辑处 （可以跨文件） 行内 w：下个单词开头 aw：整个单词 b/e：当前单词首/尾 W/B：下/上个非空格开头 E: 下个非空格结尾 g_：行尾，visual模式下不包括换行符 $：行尾，visual模式下包括换行符 0：行首 ^：非空白字符行首 |：当前行第一列 &lt;int&gt;|：当前行第n列（不是字符） 全文 gg：文件首 G：文件尾 &lt;int&gt;G：第&lt;int&gt;行 '&lt;：之前visual模式选取起始行（一直保存直至下次选取） '&gt;：之前visual模式选取结束行 {/}：下/上一个空行 .：当前行 %：全文选取??? 组合这些快捷键的效果取决于当前状态 行内 f/F：向前/后移动到某字符（;、,同向、反向重复） t/T：till，向前/后移动到某字符前 i：在某个区域（(), [], {}, w等）内（显然不能单独用 于normal） 全文 //?：命令行向前、向后查找（n、N同向、反向重复） */#：向前、向后查找当前单词 g*/g#：向前、向后查找当前字符串，包括非单独单词 Operation快捷键对区域进行操作可以和motion连用 内容修改插入 i：insert进入insert模式 I(normal)：行首insert进入insert模式 I(visual block)：选中区域同时插入 a：add进入insert模式 A：行尾add进入insert模式 &lt;c-e&gt;：insert模式下复制下行当前位置字符至当前行 删除 d：删除选取区域 c：删除（修改）选中区域，进入insert模式 x/X：删除当前/前一个字符 s：删除字符，进入insert模式 dd：删除当前行 D：normal模式删除当前位置至行尾 &lt;c-h&gt;/&lt;m-h&gt;：insert模式backspace 复制、粘贴 [&quot;&lt;reg&gt;]y：复制选中区域至寄存器&lt;reg&gt;，默认 &quot;&lt;reg&gt; yy：复制当前行 [&quot;&lt;reg&gt;]p：粘贴&quot;&lt;reg&gt;寄存器中内容，默认&quot;&lt;reg&gt; 其他 J：合并下一行，&lt;space&gt;分隔 u/U(visual)：转换为小、大写 ~(normal)：当前字符大、小写切换（光标移动至下个字符） ~(visual)：选中区域大、小写切换 gu/gU(normal)：区域转换为小、大写 g~：区域大、小写切换 [num]&gt;/&lt;：右/左移动区域num个shiftwidth单位 =：区域格式化（修改为标准缩进） &lt;c-d&gt;/&lt;c-i&gt;：insert模式减少/增加缩进 gc(visual/normal)：选中区域按行注释/取消注释 （应该是按vim的filetype确定注释格式） &lt;c-a&gt;/&lt;c-x&gt;：将光标下数字增加/减少1，支持多种进制 功能性记录 q&lt;reg&gt;：宏记录，记录行为于寄存器&lt;reg&gt;中，按下q则 停止记录 @&lt;reg&gt;：调用寄存器&lt;reg&gt;中的宏操作（不一定是q&lt;reg&gt; 记录的结果） m&lt;char&gt;：记录当前位置于&lt;char&gt;中（不是寄存器中未知） `\\：回到&lt;char&gt;中记录的位置 撤销、redo .：重复上一个操作 u：撤销上一个操作 &lt;c-r&gt;：继续执行，撤销u &lt;c-m&gt;：等同于&lt;cr&gt; 外部功能 K：对当前单词调用keywordprg设置的外部程序，默认“man” Diff ]c/[c：比较窗口中移至下个不同的为止 do/dp：将当前比较窗口中不同区域，同步为/至另一个 窗口该位置 其他 q:：vim命令历史窗口 界面变动窗口Window &lt;c-w-h/j/k/l&gt;：切换至左/下/上/右窗口 &lt;c-w-w&gt;：轮换窗口（切换活动窗口） &lt;c-w-t/b/p&gt;：切换至最左上/右下/前个窗口 &lt;c-w-+/-&gt;：竖直方向扩展/收缩当前窗口 &lt;c-w-&gt;/&lt;&gt;：水平方向扩展/收缩当前窗口 &lt;c-w-=&gt;：恢复当前窗口高度 &lt;c-w-H/J/K/L&gt;：移动窗口至tab左/下/上/右，占据全部高/宽 &lt;c-w-T&gt;：移动窗口至新tab &lt;c-w-r/x&gt;：交换窗口位置（具体逻辑未知） ZZ：保存退出 ZQ：放弃保存退出 Tab [n]gt/gT：下/上一个tab；第n个tab 内容折叠 foldmethod=marker：{{{`、`}}}标记折叠区域（各花括号之间无空格） zf：创建折叠（在选中区域前后添加标记） zf[n]G：创建当前行至第n行折叠 [n]zf[+]：创建当前行至后n行折叠 [n]zf[-]：创建当前行至前n行折叠 zd：删除 包含 当前位置折叠 zD：递归 删除包含当前位置折叠、及子折叠 zE：删除窗口中所有折叠 za：折叠 toggle zo：折叠展开 zc：折叠 foldmethod=indent：缩进标记折叠 zc：折叠 zC：递归 折叠 zo：展开折叠 zO：递归展开折叠 [z：移至当前折叠开始 ]z：移至当前折叠末尾 zj：移至下个折叠开始（包括关闭折叠） zk：移至上个折叠结束（包括开闭折叠） zm：提高折叠水平，即依次折叠当前最高水平缩进 zr：降低折叠水平，即依次展开当前最高水平缩进 zn：禁用折叠 zN：启用折叠 foldmethod=manual：手动折叠 zf&lt;range&gt;：折叠选中区域 zf70j：折叠之后70行 zfa(：折叠 ( 包围区域 mkview：保存折叠状态 loadview：载入折叠状态 Vim Cmd常用命令内容相关查找//?:/foo向下查找，:?foo向上查找 set ingorecase时，不敏感查找；set smartcase时，如果 查找中有大写字符则敏感； :/foo\\c手动强制大小写不敏感，:/foo\\C强制敏感 n、N重复同向、反向之前查找 :vimgrep文件间搜索 1:vim[grep] /pattern/[g][j] files 选项 g：全局匹配（匹配每行全部） j：查找完毕后，进更新quickfix列表，光标不跳转 files %：当前文件 *：当前目录 **/*：仅子目录 **/xxxx：当前目录及子目录所有满足xxxx模式文件 pattern：满足pattern的文件 global 在[range]范围（默认整个文件）中查找{pattern}，标记 匹配行 对匹配行执行命令{command}（默认print命令） 若标记行在被操作之前已经被删除、移动、合并等而消失， 则不对器执行操作 1:[range]g[lobal][!]/{pattern}/{command} 选项 [!]：对不匹配者执行草在 123456789101112:g/^/m 0 # 将文件反序:g/^/+1 d:%normal jdd # 删除偶数行:g/^/d|m.:%normal jkdd # 删除奇数行:g!/aaa/d # 删除不包含`aaa`行:g/aaa/&quot;ay # 复制包含`aaa`行至寄存器`&quot;` 替换:s1:[start,end]s/foo/bar[/i][I][g] 替换区域：默认只替换当前行 手动指定具体行号：:2,4s/foo/bar（左闭右开） 特殊符号 全文替换%：:%s/foo/bar 第一行^：:^,4s/foo/bar 当前行.：:.,6s/foo/bar 末尾行$：:4,$s/foo/bar visual模式下，手动选择区域命令行自动补全为:'&lt;,'&gt; 替换标志 大小写不敏感/i、\\c：:%s/foo/bar/i或:%s/foo\\c/bar 大小写敏感/I、\\C：%s/foo/bar/I或:%s/foo\\C/bar 全局替换/g（替换每行全部模式）：:%s/foo/bar/g 默认情况下只替换首个模式：foo,foobar被替换为 bar,foobar 全局替换模式下：foo,foobar被替换为bar,barbar 交互（确认）替换：:%s/foo/bar/c，每次替换前会询问 超级变量 &amp;：代表被替换模式字串 文本移动&gt;/&lt;12:[range]&gt;:[range]&lt; 范围内文本块右、左移动1个shiftwidth 移动num个shiftwidth添加num个&gt;/&lt; move1:[range]m[ove] [n] 移动范围内行至第[n]行后 12:m0 # 移动当前行至首行 t1:[range]t [n] 复制范围内至第[n]行后 12:t. # 复制当前行至下行 文件相关放弃修改、重新加载、保存 :w[rite]：保存此次修改 :e!：放弃本次修改（和:q!不同在于不会退出vim） :bufdo e!：放弃vim所有已打开文件修改 :e：重新加载文件 :e#：当前窗口加上个buffer（反复切换） :bufdo e：重新加载vim所有已打开文件 :saveas new_file_name：另存为，不删除原文件 :sb[n]：split窗口加载第n个buffer :b[n]：当前窗口加载第n个buffer :n[n]：当前窗口加载下/第n个buffer Window :sp[lit]：水平分割当前窗口，展示当前文件 :vs[plit]：竖直分割当前窗口，展示当前文件 :new：水平分割当前窗口，新文件 :vnew：竖直分割当前窗口，新文件 :sview：水平分割当前窗口，只读[缺省当前]文件 :[n]winc &gt;/&lt;：水平方侧扩展/收缩 :[n]winc +/-：竖直方向扩展/收缩 :res+/-[n]：竖直方向扩展/收缩 :vertical res+/-[n]：水平方向扩展/收缩 :ressize[n]：高度设置为n单位 :vertical res[n]：宽度设置为n单位 :q[uit][!]：退出当前窗口 !：强制退出，修改不保存 :close：关闭当前窗口（不能关闭最后窗口） :only：关闭其他窗口 :qa：退出所有窗口 :wq：保存、退出当前窗口 :x：类似于wq，但是未修改则不写入 注： 水平方向：扩张优先左侧变化，收缩右侧变化 竖直方向：扩展收缩均优先下侧变化 Tab :tabnew [opt] [cmd] [file_name]：打开新tab :tabc：关闭当前tab :tabo：关闭其他tab :tabs：vim cmd区域查看所有打开的tab信息 :tabp：查看前一个tab :tabfirst/:tablast：第一个/最后一个tab :tabn [num]：查看下一个/第num个tab Diff :diffsplit [filename]：上下分割窗口和当前窗口比较 默认同当前文件进行diff :difft：将当前窗口变为比较窗口 若没有其他比较窗口，则没有明显变化 若存在其他比较窗口，则加入比较 :diffu[pdate][!]：更新当前比较窗口 比较状态下修改当前文件后，重新生成比较信息 !：重新载入文件后更新（外部修改文件） :diffo[!]：关闭当前窗口比较状态 !：关闭所有窗口比较状态 Session :mksession[!] &lt;session-file-name&gt;：将当前状态写入 session 文件 :source &lt;session-file-name&gt;：载入已有 session 文件 其他多行语句“|”管道符可以用于隔开多个命令:echom &quot;bar&quot; | echom &quot;foo&quot; :vertical:vertical基本可以用所和窗口有关命令之前，表示左右（分割） :vert split/:vs：左右分割窗口 :vert sb[n]：左右分割窗口载入buff[n] :vert diffs file_name：左右分割窗口diffs :vert res +/-[n]：调整窗口大小 其他CMD命令编辑过程中使用shell :!{shell command}即可直接执行shell命令并暂时跳出vim :r !{shell command}可以将输出结果读取到当前编辑 :w !{sheel command}可以将输出结果输出到vim命令行 :shell即可暂时进入到shell环境中，$exit即可回到vim中 &lt;c-z&gt;暂时后台挂起vim回到shell环境中，$fg即可回到之前 挂起的进程（此时为vim，详见fg命令） 读取结果 :read cmd：读取cmd结果至光标下一行 :read !date：读取系统date命令结果 交换文件处理 确认需要恢复：直接恢复R 确认丢弃：直接删除D 没有明确目标：只读打开O 比较交换文件、现在文件差别 恢复打开R 另存为其他文件:saveas filname.bak 与当前文件对比:diffsplit filename 一般不会直接E（edit anyway） Vim命令行参数vim $ vim [filname]：打开一般窗口 -r [filename]：常看交换文件（特定文件对应交换文件） -R [filename]：只读方式打开文件 -S session-file：打开session的方式启动vim 需要 :mksession[!] &lt;session-file&gt; 先创建 session 文件 vimdiff $ vimdiff [file1] [file2]：打开比较窗口 -u：合并模式比较 -c：上下文模式比较 后面两个模型可常用于输出重定向至新文件","link":"/Linux/Tool/Vi/kmp_cmd.html"},{"title":"Vim 内建函数、变量","text":"文件、路径相关函数 expand(option)：根据参数返回当前文件相关信息 fnamemodify(file_name, option)：返回当前文件夹下文件 信息 globpath(dir, type)：返回的dir下符合type的文件 列表值字符串，使用,分隔，type为**时将递归的列出 文件夹及文件 特殊变量command-line模式的特殊变量，在执行命令前会将其替换为相应的 变量 &lt;cword&gt;：光标处单词 &lt;cWORD&gt;：光标处单词大写形式 寄存器寄存器相关快捷键、命令 &lt;c-r&gt;&lt;reg&gt;：insert模式下直接输入&lt;reg&gt;中的值 一般寄存器Readonly RegisterExpression Register（&quot;=）&quot;=实际上并不是一个寄存器，这是使用命令表达式的一种方法， 按下=之后，光标会移动到命令行，此时可以输入任何表达式， （不只有&quot;=才会激活命令行，&lt;c-m&gt;&quot;也能激活） 输入表达式之后 按下&lt;esc&gt;，表达式值被丢弃 按下&lt;cr&gt;，表达式值计算后存入&quot;=中12:nnoremap time &quot;=strftime(&quot;%c&quot;)&lt;cr&gt;p:inoremap time &lt;c-r&gt;strftime(&quot;%c&quot;)&lt;cr&gt; 之后:put或者按下p将粘贴&quot;=中的值 寄存器中的值一定是字符串，如果是其他类型变量，会被强制 转换之后存入&quot;=寄存器中 Vim特殊换行 \\0：空转义序列（ASCII码位0）&lt;Nul&gt; &lt;c-v&gt; 000：输入&lt;Nul&gt; Vim在内存中使用&lt;NL&gt;存储&lt;Nul&gt;，在读、写文件时即 发生转换 Vi无法处理&lt;Nul&gt;，应该是为了兼容Vi \\n：换行转义序列&lt;NL&gt; &lt;c-v&gt;&lt;c-j&gt;：输入&lt;NL&gt;，会被替换为输入&lt;Nul&gt;， 等同于&lt;c-v&gt; 000 在搜索表达式中：字面意义的newline序列被匹配 在替换表达式中：在内部被替换为&lt;Nul&gt;被输入，即 不再表示newline \\r：回车转义序列&lt;CR&gt; 被Vim视为为换行，可在替换表达中表示&lt;NL&gt; &lt;c-v&gt;&lt;c-j&gt;：输入&lt;CR&gt;字符本身 vim在内存换行应该同一使用&lt;CR&gt;，在读、写时，根据当前 fileformat设置自动转换换行字符（序列）","link":"/Linux/Tool/Vi/builtins.html"},{"title":"Vimscripts 编程","text":"变量普通变量创建变量、变量赋值都需要用到let关键字 1234let foo = &quot;bar&quot;echo foolet foo = &quot;foo&quot;echo foo 数字 Number32位带符号整形（整形之间除法同c） :echo 0xef：16进制 :echo 017：8进制（鉴于以下，不建议使用） :echo 019：10进制（9不可能出现，vim自动处理） Float :echo 5.1e-3：科学计数法） :echo 5.0e3：科学计数法中一定要有小数点 类型转换：Number和Float运算时会强制转换为Float 字符串类型转换 +、if这些“运算”中，vim会强制转换变量类型 数字开头的字符串会转为相应Number（即使符合Float也 会舍弃小数点后） 而非数字开头 则转换为0 连接. .连接时vim可以自动将Number转换为字符串然后连接 但是对于 Float，vim不能自动转换 转义\\： 注意echom &quot;foo\\nbar&quot;类似的输出时，echom不会像 echo一样输出两行，而是将换行输出为vim默认 （即使设置了listchars）的“换行符” 字符串字面量'' 所见即所得（py中r’’)，注意连续两个单引号表示单引号 内建字符串函数 strlen(str)（len(str)效果对字符串同） split(str, token=&quot; &quot;) join([str], token=&quot; &quot;) tolower(str) toupper(str) 字符串比较==、==？、==# ==：对字符串比较是否大小写敏感取决于设置 123456789set noignorecaseif &quot;foo&quot;==&quot;Foo&quot; echo &quot;bar&quot;（不会输出）endifset ignorecaseif &quot;foo&quot;==&quot;Foo&quot; echo &quot;bar&quot;（会输出）endif ==?：对字符串比较大小写永远不敏感 ==#：对字符串比较大小写永远敏感 &lt;、&gt;：同上，也有3种 集合类型变量列表vim列表特点 有序、异质 索引从0开始，可以使用负数索引，使用下标得到对应元素 支持切割 是闭区间（这个和python不同） 可以负数区间切割 可以忽略起始/结尾索引表示从0开始/末尾截至 切割区间越界是安全的 字符串可以像列表一样切割、索引，但是不可以使用负数 索引，却可以使用负数切割 +用于连接两个列表 列表内建函数 add(list, item)：添加新元素 len(list)：列表长度 get(list, index, default_val)：获取列表元素，越界则 返回default_val index(list, item)：返回元素索引，不存在返回-1 join(list, token)：将列表中元素转换为字符串后，使用 toke连接，缺省为&lt;space&gt; reverse(list)：反转列表 字典字典特性 值是异质的，键可以不是字符串，但是会被强制转换为字符串， 因此，在查找值时也可以使用非字符串dict[100]，同样会被 强制转换为字符串dict[&quot;100&quot;]之后查找 支持属性.查找，甚至可以后接Number 添加新元素就和普通赋值一样：let dict.100 = 100 移除字典中的元素 remove(dict, index) unlet dict.index/unlet dict[index] 移除不存在的元素事报错 允许定义时多一个, 内建函数 get(dict, index, default_val)：同列表 has_key(dict, index)：检查字典中是否有给定键，返回 1（真）或0（假） item(dict)：返回字典键值对，和字典一样无序 keys(dict)：返回字典所有键 values(dict)：返回字典所有值 作为变量的选项 bool选项输出0、1 12:set wrap:set nowrap 键值选项 12:set textwidth=80:echo &amp;textwidth 本地选项（l:作用域下） 1let &amp;l:number=1 选项变量还可以参与运算 12let &amp;textwidth=100let &amp;textwidht = &amp;textwidth + 10 作为变量的寄存器1234let @a = &quot;hello&quot;echo @aecho @&quot;echo @/ 变量作用域以&lt;char&gt;:开头表示作用域变量 变量默认为全局变量 b:：当前缓冲区作用域变量 g:：全局变量 语句条件语句vim中没有not关键字，可以使用!表示否定 !：否 ||：或 &amp;&amp;：与 12345678if &quot;1one&quot; echo &quot;one&quot;（会输出）endifif ! &quot;one&quot; echo &quot;one&quot;（会输出）else echo &quot;two&quot;endif finish关键字finally时结束整个vimscripts的运行 循环语句for语句12345let c = 0for i in [1,2,3] let c+=iendforechom c while语句1234567let c = 1let total = 0while c&lt;=4 let total+=c let c+=1endwhileechom total 函数没有作用域限制的vimscripts函数必须以大写字母开头 （有作用域限制最好也是大写字母开头） 12345678func Func(arg1,...) echo &quot;Func&quot; echo a:arg1（arg1） echo a:0（额外（可变）参数数量） echo a:1（第一个额外参数） echo a:000（所有额外参数的list） return &quot;Func&quot;endfunction 当function后没有紧跟!时，函数已经被定义，将会给出 错误，而function!时会直接将原函数替换，除非原函数正在 执行，此时仍然报错 调用方式 :call Func()：call直接调用（return值会被直接丢弃） :echo Func()：表达式中调用 函数结束时没有return，隐式返回0 函数参数：最多20个 参数全部位于a:参数作用域下 a:arg1：一般参数 a:0：额外（可变）参数数量 a:n：第n个额外参数 a:000：包含额外参数list 参数不能重新赋值 vim中函数可以赋值给变量，同样的此时变量需要大写字母开头， 当然可以作为集合变量的元素，甚至也可以作为参数传递 1234567891011121314151617function! Reversed(l) let nl = deepcopy(a:l) call reverse(nl) return nlendfunctionlet Myfunc = function(&quot;Reversed&quot;)function! Mapped(func, l) let nl = deepcopy(a:l) call map(nl, string(a:func) . '(v:val)') return nlendfunctioncall Mapped(function(&quot;Reversed&quot;), [[3,2], [1,2]])let funcs = [function(&quot;Reversed&quot;), function(&quot;Mapped&quot;)] 更多函数参见functions.vim（如果完成了） Execute、Normal :execute：把字符串当作vimscript命令执行（命令行输入） :execute &quot;echom 'hello, world'&quot;&lt;cr&gt; 大多数语言中应该避免使用”eval”之类构造可执行字符串，但是 vimscripts代码大部分只接受用户输入，安全不是严重问题， 使用:execute命令能够极大程度上简化命令 :execute命令用于配置文件时，不要忽略结尾的&lt;cr&gt;， 表示“执行命令” :normal：接受一串键值，并当作是normal模式接受按键 :normal后的按键会执行映射，:normal!忽略所有映射 :normal无法识别“”这样的特殊字符序列 :normal /foo&lt;cr&gt; 这样的命令并不会搜索，因为“没有按回车” :execute和:normal结合使用，让:normal接受按下 “无法打印”字符（&lt;cr&gt;、&lt;esc&gt;等），execute能够接受 按键 12:execute &quot;normal! gg/foo\\&lt;cr&gt;dd&quot;:execute &quot;normal! mqA;\\&lt;esc&gt;`q&quot; 正则表达式vim有四种不同的解析正则表达式的“模式” 默认模式下\\+表示“一个或多个之前字符”的正常+意义， 其他的符号如{,},*也都需要添加转义斜杠表示正常意义， 否则表示字符字面意 :execute &quot;normal! gg/for .\\\\+ in .\\\\+:\\&lt;cr&gt;： execute接受字符串，将\\\\转义，然后正则表达式解析， 查找python的for语句 :execute &quot;normal! gg&quot;.'/for .\\+ in .\\+:'.&quot;\\&lt;cr&gt;&quot;： 使用字符串字面量避免\\\\，但是注意此时\\&lt;cr&gt;也不会 被转义为按下回车（\\n才是换行符），所以需要分开 书写、连接 \\v模式下，vim使用“very magic”正常正则解析模式 :execute &quot;normal! gg&quot;.'/\\vfor .+ in .+:'.&quot;\\&lt;cr&gt;&quot;","link":"/Linux/Tool/Vi/vimscripts.html"},{"title":"统计量 - 相关","text":"Pearson 积矩相关系数 \\rho_{X,Y} = \\frac {cov(X, Y)} {\\sigma_X \\sigma_Y} $cov(X, Y)$：变量 $X, Y$ 协方差 $\\sigma_X, \\sigma_Y$：变量 $X, Y$ 方差 Pearson 积矩相关系数取值范围为 $[-1, 1]$ $1, -1$ 分别表示变量成正线性、负线性函数关系 显著性检验Fisher 变换 z = \\frac 1 2 ln(\\frac {1+r} {1-r}) = arctanh(r) $z$：Pearson 积矩相关系数的 Fisher 变换 $r$：样本的 Pearson 积矩相关系数值 当 $(X, Y)$ 为二元正态分布时，$z$ 近似正态分布 均值：$\\frac 1 2 ln(\\frac {1+\\rho} {1-\\rho})$ 标准差：$\\frac 1 {\\sqrt {N - 3}}$ 基于数学的近似方法 t = r \\sqrt{\\frac {N - 2} {1 - r^2}} 当 $(X, Y)$ 为二元正态分布且不相关时，$t$ 服从自由度为 $n-2$的 t-分布 Spearman 秩相关系数\\begin{align*} \\rho_{X, Y} & = \\frac {cov(Rank(X) - Rank(Y))} {\\sigma_{Rank(X)} \\sigma_{Rank(Y)}} \\\\ & = 1 - \\frac {6 \\sum_i^N d_i^2} {N(N^2-1)} \\\\ \\end{align*} $Rank(X), Rank(Y)$：变量 $X, Y$ 的秩（应同序）（相同值秩取均值） $d_i$：变量对 $X, Y$ 中，二者秩差值 Spearman 秩相关系数被定义为变量秩的 Pearson 相关系数 Spearman 秩相关系数也可以使用 Fisher 变换检验显著性 Kendell 秩相关系数\\begin{align*} \\tau_a &= \\frac {N_c - N_d} {N_0} \\\\ \\tau_b &= \\frac {N_c - N_d} {\\sqrt{(N_0 - N_X)(N_0 - N_Y)}} \\\\ \\tau_c &= \\frac {2(N_c - N_d)} {N^2 \\frac {M-1} M} \\end{align*} $N_0 = \\frac {N(N-1)} 2$：变量对数量 $N_c, N_d$：变量对 $X, Y$ 中有序对数量、无序对数量 $N_X, N_Y$：变量对 $X, Y$ 中 $X$ 取值、$Y$ 取值相同对数量 $M$：变量 $X, Y$ 中较小取值数量者取值数量 Kendell 秩相关系数取值范围同样为 $[-1, 1]$ -1 仅在变量 $X, Y$ 取值完全反向取到 $\\tau_a$ 是 $\\tau_b$ 在变量不存在取值相同时的特例 $\\tau_c$ 适合“层级”数据，即两个变量取值类似划分、内部细分 ||A|B|C| |——-|——-|——-|——-| |I-1|30|0|0| |I-2|30|0|0| |II-1|0|30|0| |II-1|0|30|0| |III-2|0|0|30| |III-2|0|0|30| 对以上数据，$\\tau_b$ 取值在 0.9 附近，而 $\\tau_c$ 取 1 有序对：对 $(X_i, Y_i), (X_j, Y_j)$，满足 $X_i &lt; X_j, Y_i &lt; Y_j$ 或 $X_i &gt; X_j,Y_i &gt; Y_j$ 则为有序对 无序对：对$(X_i, Y_i), (X_j, Y_j)$，满足 $X_i &lt; X_j, Y_i &gt; Y_j$ 或 $X_i &gt; X_j, Y_i &lt; Y_j$ 则为无序对 卡方统计量卡方统计量：通过观察实际与理论值的偏差确定理论正确与否 \\chi^2 = \\sum \\frac {(A - E)^2} E $A$：自变量、因变量组合对应频数观察值 $E$：自变量、因变量组合对应频数期望值 将模型预测结果视为实际分布、先验分布（均匀分布）视为理论分布 卡方检验：检验定性变量之间相关性，假设两个变量确实独立，观察实际值、理论值偏差程度判断变量之间相关性 若偏差足够小，认为误差是自然的样本误差，两者确实独立 若偏差大到一定程度，误差不可能由偶然、测量精度导致， 认为两者相关 若模型预测结果同先验分布差别很大，说明模型有效，且卡方统计量值越大表示预测把握越大 特点 由于随机误差存在，卡方统计量容易 夸大频数较小的特征影响 相应的，取值数较少（各取值频数相对而言可能较大）特征影响容易被低估 分布证明 考虑随机变量 $X=(x_1,\\cdots,x_D)$ 服从 Multinomial 分布，分布参数为 $n, p=(p_1,\\cdots,p_D)$ 考虑服从理论分布的随机变量 $X$ 协方差矩阵 \\begin{align*} \\Sigma = Cov(X) &= \\begin{bmatrix} np_1(1-p_1) & -np_1p_2 & \\cdots & -np_1p_D \\\\ np_2p_1 & -np_2(1-p_2) & \\cdots & -np_2p_D \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ -np_Dp_1 & -np_Dp_2 & \\cdots & np_D(1-p_D) \\end{bmatrix} \\\\ &= n\\begin{bmatrix} p_1 & 0 & \\cdots & 0 \\\\ 0 & p_2 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & p_D \\end{bmatrix} - npp^T \\\\ \\end{align*} 则由中心极限定理有，如下依分布收敛的结论 \\begin{align*} \\frac {(X - np)} {\\sqrt n} & \\overset {D} {\\rightarrow} N(0,\\Sigma) \\\\ \\end{align*} 考虑服从理论分布的随机变量 $X$ 的 $\\chi^2$ 参数 \\begin{align*} \\chi^2 &= \\frac 1 n (X-np)^T D^2 (X-np) \\\\ D &= \\begin{bmatrix} \\frac 1 {\\sqrt {p_1}} & 0 & \\cdots & 0 \\\\ 0 & \\frac 1 {\\sqrt {p_2}} & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & \\frac 1 {\\sqrt {p_D}} \\end{bmatrix} \\end{align*} 并由连续映射定理可以得到 $D\\frac {x-np} {\\sqrt n}$ 分布，且其协方差矩阵 $\\Sigma_0$ 满足 \\begin{align*} D\\frac {x-np} {\\sqrt n} & \\overset {D} {\\rightarrow} N(0, D \\Sigma D^T) \\\\ \\Sigma_0 &= D \\Sigma D^T \\\\ \\Sigma_0^2 &= (E - \\sqrt p {\\sqrt p}^T)(E - \\sqrt p {\\sqrt p}^T) = \\Sigma_0 \\\\ \\end{align*} 由以上，$\\Sigma_0$ 仅有特征值 0，1 特征值 0 对应特征向量有且仅有 $\\sqrt p$ 特征值 1 对应特征向量有 $D-1$ 个 \\begin{align*} \\Sigma_0 \\sqrt p - 0 \\sqrt p &= \\sqrt p - \\sqrt p = 0 \\\\ \\Sigma_0 \\lambda - 1 \\lambda &= \\lambda - \\sqrt p {\\sqrt p}^T \\lambda = \\sqrt p {\\sqrt p}^T \\lambda = 0 \\end{align*} 则 $\\chi^2$ 统计量依分布收敛于自由度为 $D-1$ 的卡方分布 \\begin{align*} \\chi^2 &= \\sum_{d=1}^D \\frac {(x_d - np_d)^2} {np_d} \\overset {D} {\\rightarrow} \\chi_{D-1} \\end{align*} 可据此构造统计量进行卡方检验，检验实际值实际分布频率 $(a_1,\\cdots,a_D)$ 是否符合该分布 构造卡方统计量 $\\chi^2 = \\sum_{d=1}^D \\frac {(x_d - na_d)^2} {na_d}$ 则卡方统计量在随机变量满足多项分布情况下依分布收敛于自由度为 $D-1$ 的卡方分布 https://www.zhihu.com/question/309694332/answer/952401910 https://zhuanlan.zhihu.com/p/198864907","link":"/Math-Mixin/Statistics/stat_corrs.html"},{"title":"统计量 - 衍生特征","text":"Odds/Odds Ratio Odds：几率/优势，事件发生与不发生的概率比值 odds = \\frac p {1-p} $p$：事件发生概率 Odds Ratio：优势比，两组事件 odds 的比值 OR = \\frac {odds_1} {odds_0} WOE 值WOE 值：将预测变量（二分类场景中）集中度作为分类变量编码的数值 \\begin{align*} WOE_i & = log(\\frac {\\%B_i} {\\%G_i}) \\\\ & = log(\\frac {\\#B_i / \\#B_T} {\\#G_i / \\#G_T}) \\\\ & = log(\\frac {\\#B_i / \\#G_i} {\\#B_T / \\#G_T}) \\\\ & = log(\\frac {\\#B_i} {\\#G_i}) - log(\\frac {\\#B_T} {\\#G_T}) \\\\ & = log(\\frac {\\#B_i / ({\\#B_i + \\#G_i})} {\\#G_i / (\\#B_i + \\#G_i)}) - log(\\frac {\\#B_T} {\\#G_T}) \\\\ & = log(odds_i) - log(odds_T) \\end{align*} $\\%B_i, \\%G_i$：分类变量取第 $i$ 值时，预测变量为 B 类、G 类占所有 B 类、G 类比例 $#B_i, #B_T$：分类变量取第 $i$ 值时预测变量为 B 类数量，所有 B 类总数量 $#G_i, #G_T$：分类变量取第 $i$ 值时预测变量为 G 类数量，所有 G 类样本总数量 $odds_i$：分类变量取第 $i$ 值时，预测变量取 B 类优势 $odds_T$：所有样本中，预测变量取 B 类优势 其中 $log$ 一般取自然对数 WOE 编码是有监督的编码方式，可以衡量分类变量各取值中 B 类占所有 B 类样本比例、G 类占所有 G 类样本比例的差异 B 类、G 类比例，与所有样本中 B 类、G 类比例的差异 WOE 编码值能体现分类变量取值的预测能力，变量各取值 WOE 值方差越大，变量预测能力越强 WOE 越大，表明该取值对应的取 B 类可能性越大 WOE 越小，表明该取值对应的取 G 类可能性越大 WOE 接近 0，表明该取值预测能力弱，对应取 B 类、G 类可能性相近 OR与WOE线性性\\begin{align*} log(OR_{j,i}) &= log(odds_i) - log(odds_j) \\\\ &= WOE_i - WOE_j \\end{align*} 即：预测变量对数优势值与 WOE 值呈线性函数关系 预测变量在取 $i,j$ 值情况下，预测变量优势之差为取 $i,j$ 值的 WOE 值之差 WOE 值编码时，分类变量在不同取值间跳转时类似于线性回归中数值型变量 考虑到对数优势的数学形式，单变量 LR 模型中分类型变量 WOE 值可以类似数值型变量直接入模 当然，WOE 值编码在多元 LR 中无法保证单变量分类情况下的线性 或者说多变量 LR 中个变量系数值不一定为 1 在基于单变量预测能力优秀在多变量场合也优秀的假设下，WOE 值编码（IV 值）等单变量分析依然有价值 Bayes Factor、WOE 编码、多元 LR\\begin{align*} ln(\\frac {P(Y=1|x_1,x_2,\\cdots,x_D)} {P(Y=0|x_1,x_2,\\cdots,x_D)}) &= ln(\\frac {P(Y=1)} {P(Y=0)}) \\\\ & \\overset {conditionally independent} {=} ln (\\frac {P(Y=1)} {P(Y=0)}) + \\sum_{i=1}^D ln(\\frac {P(x_i|Y=1)} {P(x_i|Y=0)}) \\\\ ln(\\frac {P(Y=1|x_1,x_2,\\cdots,x_D)} {P(Y=0|x_1,x_2,\\cdots,x_D)}) & \\overset {semi} {=} ln (\\frac {P(Y=1)} {P(Y=0)}) + \\sum_{i=1}^D \\beta_i ln(\\frac {P(x_i|Y=1)} {P(x_i|Y=0)}) \\end{align*} $\\frac {P(x_i|Y=1)} {P(x_i|Y=0)}$：贝叶斯因子，常用于贝叶斯假设检验 Naive Bayes 中满足各特征 $X$ 关于 $Y$ 条件独立的强假设下，第二个等式成立 Semi-Naive Bayes 中放宽各特征关于 $Y$ 条件独立假设，使用权重体现变量相关性，此时则可以得到多元 LR 的预测变量取值对数 OR 形式 则多元 LR 场景中，WOE 值可以从非完全条件独立的贝叶斯因子角度理解 IV 值\\begin{align*} IV_i &= (\\frac {\\#B_i} {\\#B_T} - \\frac {\\#G_i} {\\#G_T}) * WOE_i \\\\ &= (\\frac {\\#B_i} {\\#B_T} - \\frac {\\#G_i} {\\#G_T}) * log(\\frac {\\#B_i / \\#B_T} {\\#G_i / \\#G_T}) \\\\ IV &= \\sum IV_i \\end{align*} $IV_i$：特征 $i$ 取值 IV 值 $IV$：特征总体 IV 值 特征总体的 IV 值实际上是其各个取值 IV 值的加权和 类似交叉熵为各取值概率的加权和","link":"/Math-Mixin/Statistics/stat_derived.html"},{"title":"统计量 - 熵","text":"Entropy （信息）熵：在概率分布上对复杂程度/多样性/不确定性/混乱程度的度量 \\begin{align*} HOD(X) & = -E_P log P(x) \\\\ & = \\sum_d^D P(x_d) log \\frac 1 {P(x_d)} \\\\ & = - \\sum_d^D p_d log p_d \\\\ \\end{align*} $p_d$：随机变量各取值对应概率 事件 $i$ 发生概率 $p_d=0$：约定 $p_d log(p_d)$ 为 0 其中 $log$ 以 2 为底，单位为 bit，以 $e$ 为底，单位为 nat 信息论中，熵越高能传输越多信息 可携带的信息量 = 单位消息熵 * 消息长度 熵衡量系统复杂程度，提高系统确定性即削弱系统多样性，降低熵 概率分布包含的信息即其复杂程度（可能取值数量） 考虑按照 $(p_1,\\cdots,p_D)$ 分布、长度为 $N$ 的随机变量序列，其可能排列数为 $\\frac {N!} {\\prod_d^D (p_d N)!}$ 则根据 Stirling 公式有 \\begin{align*} log (\\frac {N!} {\\prod_d^D (p_d N)!}) & = log(N!) - \\sum_d^D log((p_d N)!) \\\\ & \\overset {\\lim_{N \\rightarrow \\infty}} = log(\\sqrt {2\\pi N} ({\\frac N e})^N) + \\sum_d^D log(\\sqrt {2\\pi p_dN} ({\\frac {p_dN} e})^{p_dN}) \\\\ & = log(\\sqrt {2\\pi N}) + N(logN-1) - \\sum_d^D log(\\sqrt {2\\pi p_dN}) - \\sum_d^D p_dN (log(p_dN) - 1) \\\\ & = log(\\sqrt {2\\pi N} + \\sum_d^D log(\\sqrt {2\\pi p_dN})) + N \\sum_d^D p_d log p_d \\\\ & \\approx N \\sum_d^D p_d log p_d \\end{align*} 则长度为 $N$ 的随机变量串的多样性、信息量为 $H * N$，其中 $H=\\sum_d^D p_d log p_d$ 概率分布的信息熵 某个事件包含的信息可以用编码长度理解 对概率 $p$ 事件，编码 $1/p$ 个需编码（2进制编码）长度 $log_2 \\frac 1 p$ 则概率 $p$ 事件包含信息量可以定义为 $log \\frac 1 p$，即事件包含的信息量可用表示事件需要编码的长度表示 （底数则取决于编码元，只影响系数） 则整个随机变量的信息为各事件信息量加权和 熵可以视为变量取值概率的加权和 只依赖随机变量 $X$ 的分布，与其取值无关，可将其记为 $H(P)$ 由定义 $0 \\leq H(P) \\leq log_2 k$ $H(p) = 0$：$\\exists j, p_j=1$，随机变量只能取一个值，无不确定性 $H(p) = log k$：$\\forall j, p_j=1/k$，随机变量在任意取值概率相等，不确定性最大 empirical entropy：经验熵，熵中的概率由数据估计时（尤极大似然估计） 参考链接 https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA) https://zhuanlan.zhihu.com/p/27876027 https://zhuanlan.zhihu.com/p/73710585 Stirling 公式即用积分近似计算 $\\sum logn$：https://zhuanlan.zhihu.com/p/143992660 熵的性质 对称性：事件取值不影响熵 极值性 所有符号有同等机会出现的情况下，熵达到极大（琴生不等式） \\begin{align*} H(X) & = E[log(\\frac 1 {P(X)})] \\leq log(E[\\frac 1 {P(x)}]) & = log(n) \\end{align*} 仅有一个符号确定出现的情况下，熵达到极小 0 Continuity连续性：度量连续，概率微小变化只能引起熵微小变化 Normalization规范化：$H_2(\\frac 1 2, \\frac 1 2) = 1$ Grouping组合法则/可加和性：熵与过程如何划分无关 （此即要求熵形式为对数） 若子系统间相互作用已知，则可以通过子系统熵值计算系统整体熵 H(X) = H(X_1,\\cdots,X_K) + \\sum_{k=1}^K \\frac {|X_k|} {|X|} H(X_k) $X_1,\\cdots,X_K$：$K$ 个子系统，可以理解为将随机变量 $X$ 划分为 $K$ 种情况 $H(X_1,\\cdots,X_K)$：子系统相互作用熵 子系统相互作用熵可以认为是，通过已知信息消除的多样性（即信息增益） 子系统熵之和则是利用已知信息消除多样性之后，系统剩余混乱程度 一般的，两个事件 $X,Y$ 熵满足以下计算关系 \\begin{align*} H(X, Y) & = H(X) + H(Y|X) \\\\ & = H(Y) + H(X|Y) \\\\ & \\leqslant H(X) + H(Y) \\\\ H(X|Y) & \\leqslant H(X) \\\\ \\end{align*} 特别的，若事件 $X, Y$ 相互独立 \\begin{align*} H(X|Y) &= H(X) \\\\ H(X, Y) &= H(X) + H(Y) \\end{align*} 满足以上特性的熵定义必然为如下形式 $$ -K \\sum P(x)log(P(x)) $$ 在热力学、信息论等领域，熵有多种不同定义，满足熵性质的测度泛函，只能具有（Shannon 熵和 Hartley 熵）或（von Neumann 熵和 Shannon 熵）线性组合的函数形式，若不要求满足组合法则，还有 Tsallis 熵等 Conditinal Entropy条件熵：随机变量 $X$ 给定条件下，随机变量 $Y$ 的条件概率分布的熵对 $X$ 的数学期望 \\begin{align*} H(Y|X) & = \\sum_{i=1}^N p_i H(Y|X=x_i) \\\\ H(Y|x=x_i) & = - \\sum_j P(y_j|x_i) log P(y_j|x_i) \\end{align*} $P(X=xi, Y=y_j)=p{i,j}$：随机变量 $(X,Y)$ 联合概率分布 $p_i=P(X=x_i)$ $H(Y|X=x_i)$：后验熵 特别的，考虑数据集 $D$ 被分为 $D_1,\\cdots,D_m$，条件经验熵可计算如下 \\begin{align*} H(D|A) & = \\sum_{m=1}^M \\frac {|D_m|} {|D|} H(D_m) \\\\ & = -\\sum_{m=1}^M \\frac {|D_m|} {|D|} \\sum_{k=1}^K \\frac {|D_{m,k}|} {|D_m|} log_2 \\frac {|D_{m,k}|} {|D_m|} \\end{align*} postorior entropy：后验熵，随机变量 $X$ 给定条件下，随机变量 $Y$ 的条件概率分布的熵 empirical conditional entropy：经验条件熵，概率由数据估计 Infomation Gain/Mutual Infomation互信息/信息增益：（经验）熵与（经验）条件熵之差 \\begin{align*} g(Y|X) & = H(Y) - H(Y|X) \\\\ & = \\sum_{x \\in X} \\sum_{y \\in Y} P(x,y) log \\frac {P(x,y)} {P(x)P(y)} \\end{align*} 与数据集具体分布有关、与具体取值无关 绝对大小同易受熵影响，（经验）熵较大时，互信息也相对较大 由于误差存在，分类取值数目较多者信息增益较大 可衡量变量 $X$ 对 $Y$ 预测能力、减少不确定性的能力 信息增益越大，变量之间相关性越强，自变量预测因变量能力越强 只能考察特征对整个系统的贡献，无法具体到特征某个取值 只适合作全局特征选择，即所有类使用相同的特征集合 Infomation Gain Ratio信息增益比：信息增益对原始信息熵的比值 \\begin{align*} g_R(Y|X) & = \\frac {g(Y|X)} {H(X)} \\end{align*} 考虑熵大小，减弱熵绝对大小的影响 Cross Entropy 信息论：基于相同事件测度的两个概率分布 $P, Q$，基于非自然（相较于真实分布 $P$）概率分布 $Q$ 进行编码，在事件集合中唯一标识事件所需 bit 概率论：概率分布 $P, Q$ 之间差异 \\begin{align*} H(P, Q) & = E_P[-log Q] = \\left \\{ \\begin{array}{l} -\\sum_{X} P(x) logQ(x), & 离散分布 \\\\ -\\int_X P(x) log(Q(x)) d(r(x)), & 连续分布 \\end{array} \\right. \\\\ & = H(P) + D_{KL}(P||Q) \\end{align*} $P(x), Q(x)$：概率分布（密度）函数 $r(x)$：测度，通常是 $Borel \\sigma$ 代数上的勒贝格测度 $D_{KL}(P||Q)$：$P$ 到 $Q$ 的 KL 散度（$P$ 相对于 $Q$ 的相对熵） 信息论中，交叉熵可以看作是信息片段在错误分布 $Q$ 分布下的期望编码长度 信息实际分布实际为 $P$，所以期望基于 $P$ 交叉熵是常用的损失函数：效果等价于 KL 散度，但计算方便 sigmoid 激活函数时：相较于二次损失，收敛速度更快 Entropy 衍生指标Kullback-Leibler DivergenceKL 散度/相对熵：衡量概率分布 $P, Q$ 之间差异的量化指标 \\begin{align*} D_{KL}(P||Q) & = E_P[(-log Q(x)) - (-log P(x))] \\\\ & = E_P[log P(x) - log Q(x)] \\\\ & = \\sum_{d=1}^D P(x_d) (log P(x_d) - log Q(x_d)) \\\\ & = \\sum_{d=1} P(x_d) log \\frac {P(x_d)} {Q(x_d)} \\end{align*} KL 散度含义 原始分布 $P$、近似分布 $Q$ 之间对数差值期望 若使用观察分布 $Q$ 描述真实分布 $P$，还需的额外信息量 KL 散度不对称，分布 $P$ 度量 $Q$、$Q$ 度量 $P$ 损失信息不同 从计算公式也可以看出 KL散度不能作为不同分布之间距离的度量 Population Stability IndexPSI：衡量分布 $P, Q$ 之间的差异程度 \\begin{align*} PSI &= \\sum_d^D (P_d - Q_d) * log \\frac {P_d} {Q_d} \\\\ &= \\sum_d^D P_d log \\frac {P_d} {Q_d} + \\sum_d^D Q_d log \\frac {Q_d} {P_d} \\\\ &= D_{KL}(P||Q) + D_{KL}(Q||P) \\end{align*} 是 KL 散度的对称操作 更全面的描述两个分布的差异 Gini 指数基尼指数：可视为信息熵的近似替代 \\begin{align*} Gini(p) & = \\sum_{k=1}^K p_k(1-p_k) \\\\ & = 1 - \\sum_{k=1}^K p_k^2 \\end{align*} $p$：概率分布 异质性最小：Gini 系数为 0 异质性最大：Gini 系数为 $1 - \\frac 1 k$ Gini 指数度量分布的不纯度 包含类别越多，Gini 指数越大 分布越均匀，Gini 指数越大 熵较 Gini 指数对不纯度判罚更重 经济学领域的 Gini 系数更类似 AUC 值 与 Entropy 关系\\begin{align*} H(X) & = -E_P log P(x) \\\\ & = - \\sum_i^N p_i log p_i \\\\ & = - \\sum_i^N p_i (log (1 + (p_i-1))) \\\\ & = - \\sum_i^N p_i (p_i - 1 + \\xi(p_i^{'}-1)) \\\\ & \\approx 1 - \\sum_i^N p_i^2 \\end{align*} Gini 指数可以视为是熵在 1 附近的一阶泰勒展开近似 条件 Gini 指数 Gini(Y|X) = \\sum_{k=1}^K P(X=x_k)Gini(Y|X=x_k) 性质类似信息增益","link":"/Math-Mixin/Statistics/stat_entropy.html"},{"title":"统计量","text":"统计量统计量：统计理论中对数据进行分析、检验的变量 传统的统计量具有显式解析表达式 均值：数据之和除数量 中位数：数据中间者 统计量同样可以理解为和数据相关优化问题的解 均值：离差平方和最小 中位数：划分均匀 优化问题目标本身也是统计量","link":"/Math-Mixin/Statistics/stat_stats.html"},{"title":"常用统计量","text":"混淆矩阵 对比实际类别值、预测类别值，编制混淆矩阵 基于混淆矩阵，计算各类错判率、总错判率（总错判率会受到数据不平衡性的影响） 真实情况\\预测结果 正例 反例 正例 TP（真正例） FN（假反例） 反例 FP（假正例） TN（真反例） F-MeasureF-测度：准率率和召回率综合值，越大越好 F-measure = \\frac {(\\beta^2 + 1) * P * R} {\\beta^2 * P + R} $P = \\frac {TP} {TP+FP}$：查准率、精确率 $R = \\frac {TP} {TP+FN}$：查全率、召回率、覆盖率 F1 值F1值：$\\beta=1$ 时的 F测度 \\begin{align*} \\frac {1} {F_{1}} &= \\frac {1} {2} \\left( \\frac {1} {P} + \\frac {1} {R} \\right) \\\\ \\Rightarrow F_{1} &= \\frac {2 * P * R} {P + R} = \\frac {2 * TP} {样例总数 + TP - TN} \\end{align*}TPR、FPR TPR、FPR 可视为对 TP、FP 用样本数量归一化的结果 样本全体中正、负样本数量往往差距很大，直接比较 TP、FP 不合理 考虑使用样本正、负数量归一化，即计算正比例 TPR、负比例 FPR TPR 越高越好，FPR 越低越好，但是这两个指标相互制约，两者同时增加、减小 模型倾向于将样本 判定为 为正例，则 TP、FP 同时增加，TPR、FPR 同时变大 即模型取不同阈值，会产生正相关的 TPR、FPR 的点列 Recevier Operating Characteristic CurveROC 曲线：不同 正样本概率 划分阈值下 TPR、FPR 绘制的折线/曲线 TPR = \\frac {TP} {TP+FN} \\\\ FPR = \\frac {FP} {FP+TN} ROC 曲线即以 FPR 为横坐标、TPR 为正坐标绘制曲线 FPR 接近 1 时，TPR 也接近 1，这是不可避免的 而 FPR 接近 0 时，TPR 越大越好 所以模型 ROC 曲线下方面积越大，模型判断正确效果越好 理解 将正负样本的正样本概率值分别绘制在 x=1、x=-1 两条直线上 阈值即为 y=threshold 直线 TPR、FPR 则为 x=1、x=-1 两条直线在阈值直线上方点数量，与各直线上所有点数量比值 Accuracy准确率、误分率：评价分类器性能一般指标 \\begin{align*} acc & = \\frac 1 N sign(y_i = \\hat y_i) \\\\ & = \\frac {TP+TN} N \\\\ mis & = 1 - acc \\end{align*} $y_i$：第 $i$ 样本实际类别 $\\hat y_i$：第 $i$ 样本预测类别 $N$：样本数量 对给定测试集，分类器正确分类样本数与总样本数比值 即 0-1 损失函数时经验风险 Top PR头部准召：评估模型头部性能 pr_{top} = \\frac {TP_{top}} {TOP} $TOP$：指定的头部数量 $TP_{top}$：头部中正例数量（正例指已知原 $TOP$ 样本） Area Under CurveAUC 值：ROC 曲线下方面积，越大越好 AUC 值实际含义：随机抽取一对正、负样本，对其中正样本的正样本预测概率值、大于负样本的正样本预测概率值的概率 $=1$：完美预测，存在一个阈值可以让模型 TPR 为 1，FPR 为 0 $(0.5, 1)$ ：优于随机预测，至少存在某个阈值，模型 $TPR &gt; FPR$ $=0.5$：同随机预测，无价值 $[0, 0.5)$：差于随机预测，但是可以反向取预测值 AUC 计算 绘制 ROC 曲线，计算曲线下面积 给定一系列阈值（最精确时为样本数量），分别计算 TPR、FPR 根据 TPR、FPR 计算 AUC 正负样本分别配对，计算正样本预测概率大于负样本比例 \\begin{align*} auc & = \\frac {\\sum I(P_P > P_N)} {M * N} \\\\ I(P_P, P_N) & = \\left \\{ \\begin{array}{l} 1, & P_P > P_N, \\\\ 0.5, & P_P = P_N, \\\\ 0, & P_P < P_N \\end{array} \\right. \\end{align*} $M, N$：正、负样本数量 Mann-Witney U 检验：即正、负样本分别配对的简化公式 auc = \\frac {\\sum_{i \\in Pos} rank(i) - \\frac {M * (M+1)} 2} {M * N} $Pos$：正样本集合 $rank(i)$：样本 $i$ 的按正样本概率排序的秩（对正样本概率值相同样本，应将秩加和求平均保证其秩相等） Weighted-AUCWAUC：给 每个样本 赋权，计算统计量时考虑样本权重 FPR、TPR 绘图 \\begin{align*} WTPR & = \\frac {\\sum_{i \\in Pos} w_i I(\\hat y_i=1)} {\\sum_{i \\in Pos} w_i} \\\\ WFPR & = \\frac {\\sum_{j \\in Neg} w_j I(\\hat y_j=1)} {\\sum_{j \\in Neg} w_j} \\end{align*} $WTPR, WFPR$：加权 TPR、加权 FPR $\\hat y_i$：样本预测类别 $w_i$：样本权重 Mann-Witney U 检验：考虑其意义，带入权重即可得 \\begin{align*} auc = \\frac {\\sum_{i \\in Pos} w_i * rank(i) - \\sum_{i \\in Pos} w_i * rank_{pos}(i)} {\\sum_{i \\in Pos} w_i * \\sum_{j \\in Neg} w_j} \\end{align*} $rank_{pos}(i)$：正样本内部排序，样本$i$秩 $Neg$：负样本集合 多分类 AUC Micro-AUC：将每个类别视为样本标签，计算全体样本的正标签、负标签的 AUC $n$ 个样本的 $m$ 维标签展平， 则其中有 $n$ 个正样本、$n * (m-1)$ 个负样本 $n$ 个样本的 $m$ 个分类器共 $n * m$ 个得分展平 使用以上预测得分、标签计算 AUC 12345678910# one-vs-rest分类器得分y_score = classifer.transform(X_test)# 展平后计算fpr、tprfpr_micro, tpr_micro, threshhold_micro = \\ skilearn.metrics.roc_curve(y_test.ravel(), y_score.ravel())# 利用fpr、tpr计算aucauc_micro = skilearn.metrics.auc(fpr_micro, tpr_micro)# 等价于直接调用auc_micro = skilearn.metrics.roc_auc_score(y_test, y_score, average=&quot;micro&quot;) Macro-AUC：对各类别，分别以计算 ROC 曲线（即 TPR、FPR），计算平均 ROC 曲线得到 AUC 对各类别分别计算 TPR、FPR，共 $m$ 组 TPR、FPR 平均合并 TPR、FPR，计算 AUC 方法1：合并 FPR、去除重复值，使用 $m$ 组 TPR、FPR 分别求合并后 FPR 插值 12345678910111213141516# 分别计算各类别fpr、tprfprs, tprs = [0] * n_classes, [0] * n_classesfor idx in range(n_classes): fprs[idx], tprs[idx], _ = sklearn.metrics.ruc_curve( y_test[:, i], y_score[:, i])# 合并fprall_fpr = np.unique(np.concatenate(fprs))mean_tpr = np.zeros_like(all_fpr)# 计算合并后fpr插值for idx in range(n_classes): mean_tpr += scipy.interp(all_fpr, fpr[idx], tpr[idx])mean_tpr /= n_classesauc_macro = sklearn.metrics.auc(all_fpr, mean_tpr)# 但是和以下结果不同auc_macro = sklearn.metrics.roc_auc_score(fprs) 以上分类器均为 one-vs-rest 分类器，$m$ 个类别则 $m$ 个分类器、每个样本 $m$ 个得分 Kolmogorov-Smirnov 统计量KS 值：刻画区分正负样本能力 KS = max \\{|TPR - FPR|\\} KS 值体现 最理想情况 下，对正负样本区分能力 即 ROC 曲线与 $TPR = FPR$ 直线的最远距离 Squared ErrorMean Squared ErrorMSE：均方误差（偏差） MSE = \\frac 1 n \\sum_{i=1}^{n} (y_{i} - \\hat{y_{i}})^{2}Mean Absolute ErrorMAE：平均绝对误差 MAE = \\frac 1 n \\sum_{i=1}^n |y_i - \\hat {y_i}|Mean Absolute Percentage ErrorMAPE：平均绝对百分比误差 MAPE = \\frac 1 n \\sum_{i=1}^n |\\frac {y_i - \\hat {y_i}} {y_i}|Symmetric Mean Absolute Percentage ErrorSMAPE：对称平均绝对百分比误差 MAPE = \\frac 1 n \\sum_{i=1}^n |\\frac {y_i - \\hat {y_i}} {(|y_i| + |\\hat {y_i}|) / 2}|$R^2$\\begin{align*} R^2 & = 1 - \\frac {SSE} {SST} = \\frac {SSR} {SST} \\\\ R^2_{adj} & = 1 - \\frac {1 - R^2} {n - p - 1} \\end{align*} $n, p$：样本量、特征数量 $SSE$：残差平方和 $SSR$：回归平方和、组内平方和 $SST$：离差平方和 $R^2_{adj}$：调整的$R^2$ Akaike Information CriterionAIC ：赤池信息准则 \\begin{align*} AIC & = -2log(L(\\hat \\theta, x)) + 2p \\\\ & = nln(SSE/n) + 2p \\end{align*} $n, p$：样本量、特征数量 $\\theta$：带估参数 $L(\\theta, x)$：似然函数 $SSE$：残差平方和 Bayesian Information CriterionBIC：贝叶斯信息准则 \\begin{align*} BIC & = -2log(L(\\hat \\theta, x)) + ln(n)p \\\\ & = nln(SSE/n) + ln(n)p \\end{align*}$C_p$\\begin{align*} C_p & = \\frac {SSE} {\\hat {\\sigma^2}} - n + 2p \\\\ & = (n - m - 1) \\frac {SSE_p} {SSE_m} - n + 2p \\end{align*} $p$：选模型特征子集中特征数量 $m$：所有特征数量 $SSE_p$：选模型中残差平方和 $SSE_m$：全模型中残差平方和","link":"/Math-Mixin/Statistics/stat_evaluation.html"},{"title":"确定性时序分析","text":"Time Series Decomposition 因素分解方法：克服其他因素干扰，单纯测度某个确定性因素（季节、趋势、交易日）的序列的影响 指数平滑预测方法：根据序列呈现的确定性特征，选择适当的方法对序列进行综合预测 因素分解模型 因素分解模型思想 所有序列波动可以归纳为受到以下 4 种因素影响（全部或部分） 导致序列呈现不同的波动特征，即任何时间序列可以用 4 因素的某个函数进行拟合 $x_t = f(T_t, C_t, S_t, I_t)$ Trend：序列呈现的长期递增、递减的变化趋势 Circle：序列呈现的从高到低、在由低到高的反复循环波动 很多经济、社会现象确实有循环周期，但是这个周期往往很长、长度不固定 如何观测值序列不够长，没有包含多个周期，周期的一部分会和趋势重合，无法准确、完整地提取周期影响 在经济学领域常用的周期有 基钦周期：平均 40 个月 朱格拉周期：平均 10 年 库兹涅茨周期：平均 20 年 康德拉季耶夫周期：平均 53.3 年 Season：和季节变化相关的稳定周期波动 Immediate：其他不能用确定性因素解释的序列波动 常用模型（函数） 加法模型：$x_t = T_t + C_t + S_t + I_t$ 乘法模型：$x_t = T_t C_t S_t * I_t$ 伪加法模型：$x_t = T_t * (S_t + D_t + I_s)$ 对数加法模型：$log{x_t} = log{Tt} + log{St} + log{Dt} + log{I_t}$ 考虑节假日 有些社会、经济现象显示某些 特殊日期 是很显著的影响因素，但是在传统因素分解模型中，没有被纳入研究 股票交易受交易日影响 超市销售受周末、节假日影响 交通、运输、旅游同样受到周末、节假日影响 如果观察时期不足够长，考虑将模型中 Circle（周期） 改为 Day（节假日） Exponential Smoothing 根据序列是否具有长期趋势、季节效应，可以把序列分为3大类 既没有长期趋势、又没有季节效应 只有长期趋势、没有季节效应 有季节效应，无论是否有长期趋势 简单指数平滑简单移动平均 对无趋势、季节的水平平稳序列 可以认为序列在比较短时间内，序列取值比较稳定，序列值差异主要是随机波动造成 根据此假定，可以使用最近一段时间内平均值作为未来几期预测值 \\begin{align*} \\hat x_{t+1} & = \\frac {x_t + x_{t-1} + \\dots + x_{t_n+1}} n \\\\ \\hat x_{t+2} & = \\frac {\\hat x_t + x_t + x_{t-1} + \\dots + x_{t-n+2}} n \\\\ \\hat x_{t+l} & = \\frac {\\hat x_{t+1-1} + \\hat x_{t+l-2} + \\dots + \\hat x_{t+1} + x_t + \\dots + x_{t-n+l}} n \\\\ \\end{align*} 简单移动平均假定无论时间远近，近 $n$ 期的序列观测值影响力一样 简单指数平滑预测 实务中，对一般的随机事件，近期的结果对现在的影响更大 指数平滑法构造思想 考虑到事件间隔对事件发展的影响，各期权重随时间间隔增大而指数衰减 \\begin{align*} \\hat x_{t+1} & = \\alpha x_t + \\alpha (1-\\alpha) x_{t-1} + \\alpha (1-\\alpha)^2 x_{t-2} + \\dots \\\\ & = \\alpha x_t (1-\\alpha) [\\alpha x_{t-1} + \\alpha (1-\\alpha) x_{t-2} + \\alpha (1-\\alpha)^2 x_{t-3} + \\dots] \\\\ & = \\alpha x_t + (1-\\alpha) \\hat x_t \\end{align*} 初值：很多方法可以确定，最简单指定 $\\hat x_1 = x_1$ 平滑系数 $\\alpha$ 经验值在 $[0.05, 0.3]$， 对于变化较缓慢的序列，取较小值 对于变化迅速的序列，取较大值 如果 $\\alpha$ 过大，说明序列波动性过强，不适合使用简单指数平滑 理论上可以预测任意期值，但是任意期预测值都是常数 因为没有新的观测值提供新信息 Holt 两参数指数平滑 两参数指数平滑 适合对含有线性趋势的序列进行修匀 即分别用指数平滑的方法，结合序列最新观察值，不断修匀参数 $a, b$ 的估计值 \\begin{align*} x_t & = a_0 + bt + \\epsilon_t \\\\ & = a_0 + b(t-1) + b + \\epsilon \\\\ & = (x_{t-1} + \\epsilon_{t-1}) + b + \\epsilon_t \\\\ & = a(t-1) + b(t) \\end{align*} $a(t-1) = x{t-1} - \\epsilon{t-1}$ $b(t) = b + \\epsilon_t$ 两参数递推公式 \\begin{align*} \\hat a(t) & = \\alpha x_t + (1-\\alpha)[\\hat \\alpha(t-1) + \\hat b(t-1)] \\\\ \\hat b(t) & = \\beta [\\hat a(t) - \\hat a(t-1)] + (1-\\beta) \\hat b(t-1) \\end{align*} 序列预测公式 \\hat x_{t+k} = \\hat a(t) + \\hat b(t)*k \\\\ 初值设置 $\\hat a(0)=x_1$ $\\hat b(0)=\\frac {x_{n+1} - x_1} n$ Holt-Winter 三参数指数平滑 三参数指数平滑 在 Holt 指数平滑的基础上构造，以修匀季节效应 加法模型 模型表达式 \\begin{align*} x_t & = a_0 + bt + c_t + \\epsilon_t \\\\ & = a_0 + b(t-1) + b + c_t + \\epsilon_t \\\\ & = (x_{t-1} - c{t-1} - \\epsilon_{t-1}) + b + \\epsilon_t + (Sd_j + e_t) \\\\ & = a(t-1) + b(t) + c(t) \\end{align*} $a(t-1) = x{t-1} - c{t-1} - \\epsilon_{t-1}$ $b(t) = b + \\epsilon_t$ $c_t = Sd_t + e_t, e_t \\sim N(0, \\sigma_e^2)$ 三参数递推式 \\begin{align*} \\hat a(t) & = \\alpha(x_t - c(t-s)) + (1-\\alpha)[\\hat a(t-1) + \\hat b(t-1)] \\\\ \\hat b(t) & = \\beta[\\hat a(t) - \\hat a(t-1)] + (1-\\beta)\\hat b(t-1) \\\\ \\hat c(t) & = \\gamma[x_t - \\hat a(t)] + (1-\\gamma)c(t-s) \\end{align*} 序列预测公式 \\hat x_{t+k} = \\hat a(t) + \\hat b(t) + \\hat c(t + mod(k,s) -s) 乘法模型 模型表示式 \\begin{align*} x_t & = (a_0 + bt + \\epsilon_t)c_t \\\\ & = (a_0 + b(t-1) + b + \\epsilon_t)c_t \\\\ & = [(x_{t-1}/c{t-1} - \\epsilon_{t-1})+ (b + \\epsilon_{t-1})](S_j + e_t) \\\\ & = [a(t-1) + b(t)]c(t) \\end{align*} $a(t-1) = x{t-1}/c{t-1} - \\epsilon_{t-1}$ $b(t) = b + \\epsilon_t$ $c_t = S_j + e_t, e_t \\sim N(0, \\sigma_e^2)$ 三参数递推式 \\begin{align*} \\hat a(t) & = \\alpha(x_t / c(t-s)) + (1-\\alpha)[\\hat a(t-1) + \\hat b(t-1)] \\\\ \\hat b(t) & = \\beta[\\hat a(t) - \\hat a(t-1)] + (1-\\beta)\\hat b(t-1) \\\\ \\hat c(t) & = \\gamma[x_t / \\hat a(t)] + (1-\\gamma)c(t-s) \\end{align*} 序列预测公式 \\hat x_{t+k} = [\\hat a(t) + \\hat b(t) * k] \\hat c(t + mod(k,s) -s)","link":"/Math-Mixin/Time-Series/models_sure_analysis.html"},{"title":"协整与误差修正模型","text":"Spurious Regression 多变量分析中，平稳性非常重要，忽略序列平稳性判断，容易出现伪回归现象 Granger、Newbold 的非平稳序列的伪回归随机模型实验（两个独立随机游走模型）表明 非平稳场合，参数显著性检验犯弃真错误的概率远大于 $\\alpha$，伪回归显著成立 即 $P(|t| \\geqslant t_{\\alpha/2}(n) | 非平稳序列) \\leqslant \\alpha$ Cointegration 协整关系 y_t = \\beta_0 + \\sum_{i=1}^k \\beta_i x_{it} + \\epsilon_t ${x_1}, {x_2}, \\cdots, {x_k}$：自变量序列 $y_t$：响应变量序列 ${\\epsilon_t}$：平稳回归残差序列 协整检验 假设条件 $H_0: \\epsilon_t ~ I(k), k \\geqslant 1$：多元非平稳序列之间不存在协整关系 $H_1: \\epsilon_t ~ I(0)$：多元非平稳序列之间存在协整关系 建立响应序列与输入序列之间的回归模型 对回归残差序列进行 EG 平稳性检验 Error Correction ModelECM：误差修正模型，解释序列短期波动关系 Granger 证明协整模型、误差修正模型具有 1-1 对应关系 协整模型度量序列之间长期均衡关系 实务中，响应序列与解释序列很少处于均衡点上，实际观测的是序列间短期或非均衡关系 Granger 表述定理 如果变量 $X$、$Y$ 是协整的，则他们之间的短期非均衡关系总能用一个误差修正模型表述 $$ \\Delta Y_t = lagged(\\Delta Y, \\Delta X) - \\lambda ECM_{t-1} + \\epsilon_t $$ 对关系 $y_t = \\beta x_t + \\epsilon_t$ \\begin{align*} y_t - y_{t-1} & = \\beta x_t - \\beta x_{t-1} - \\epsilon_{t-1} + \\epsilon_t \\\\ \\Delta y_t & = \\beta \\delta x_t - ECM_{t-1} + \\epsilon_t \\end{align*} 响应序列当期波动 $\\Delta y_t$ 主要受到三方面短期波动影响 $\\Delta x_t$：输出序列当前波动 $ECM_{t-1}$：上一期误差 $\\epsilon_t$：纯随机波动 误差修正模型 \\Delta y_t = \\beta_0 \\Delta x_t + \\beta_1 ECM_{t-1} + \\epsilon_t $\\beta_1 &lt; 0$：表示负反馈机制 $ECM_{t-1} &gt; 0$：正向误差，则会导致下一期值负向变化 $ECM_{t-1} &lt; 0$：负向误差，则会导致下一期值正向变化 Granger 因果关系 因果关系：原因导致结果 时间角度：原因发生在前，结果发生在后 影响效果：$X$ 事件发生在前，且对 $Y$ 事件发展结果有意义 Granger 检验可检验统计学意义上的 Granger 因果关系 统计意义上的因果关系和现实意义上因果关系不同 现实意义上变量因果关系强调逻辑自洽 Granger 因果关系 序列 $X$ 是序列 $Y$ 的 Granger 原因，当且仅当最优线性预测函数使得下式成立 $$ \\theta^2(y_{t+1}|I_t) \\leq \\theta^2(y_{t+1}|I_t-X_t) $$ $It = { x_t, x{t-1}, \\cdots, yt, y{t-1}, \\cdots }$：$t$ 时刻所有有用信息集合 $Xt = { x_t, x{t-1}, \\cdots }$：t时刻所有序列信息集合 $\\theta^2(y_{t+1}|I_t)$：使用所有可获得历史信息 （包括 ${x}$ 序列历史信息）得到的一期预测值方差 $\\theta^2(y_{t+1}|I_t-X_t)$：从所有信息中刻意扣除 ${x}$ 序列历史信息得到的一期预测值方差 Granger 因果关系分类 $(x, y)$：相互独立 $(x \\leftarrow y)$：$x$ 是 $y$ 的 Granger 原因 $(x \\rightarrow y)$：$y$ 是 $x$ 的 Granger 原因 $(x \\leftrightarrow y)$：互为因果 Granger 因果检验 建立回归方程 y_t = \\alpha_0 + \\sum_{i=1}^m \\alpha_i x_{t-i} + \\sum_{j=1}^n b_j y_{t-j} + \\sum_k cz_{t-k} + \\epsilon_t $z_t$：其他解释变量集合 $\\epsilon_t \\sim I(0)$ 假设 $H_0: \\alpha_1 = \\alpha_2 = \\cdots = \\alpha_m = 0$ $H_1: \\alpha_i 不全为0$ 检验统计量：F统计量 F = \\frac {(SSE_r - SSE_u) / q} {SSE_u/n-q-p-1} \\sim F(q, n-p-q-1) Granger 因果检验说明 Granger 因果检验思想：对响应变量预测精度有显著提高的自变量，就视为响应变量的因 因果性可以推出预测精度提高，但预测精度提高不能等价推出因果性 即使检验结果显著拒绝原假设，也不能说明两个序列之间有真正因果关系 Granger 因果检验是处理复杂变量关系时的工具 借助因果检验信息，可以帮助思考模型结果 不一定准确，但是提供信息比完全没有信息好 Granger 因果结果说明 检验结果严重依赖解释变量的延迟阶数，不同延迟阶数可能会得到不同的检验结果 检验结果会受到样本随机性影响，样本容量越小随机性越大，所以最好在样本容量比较大时进行检验","link":"/Math-Mixin/Time-Series/co_integration.html"},{"title":"GARCH波动性建模","text":"白噪声检验进行ARIMA模型拟合时，通过检验查询序列是否通过LB检验（白噪声 检验）判断模型显著性，但是实际上 LB检验只检验了白噪声序列的纯随机性 对于方差齐性没有进行检验 至于零均值，可以在建模时通过拟合常数项解决 方差齐性变换如果已知异方差函数的具体形式，找到其转换函数，进行方差齐性 变换 若异方差形式为：\\sigma_t^2 = h(\\mu_t)，寻找转换函数g(x) \\\\ \\Rightarrow g(x) \\approx g(\\mu_t) + (x_t - \\mu_t)g'(\\mu_t) \\\\ \\Rightarrow Var[g(x_t) \\approx [g'(\\mu_t)^2]Var(x_t) \\\\ \\Rightarrow [g'(mu_t)]^2 h(\\mu_t) = \\sigma^2 \\\\ \\Rightarorw Var[g(x_t)] = \\sigma^2 \\\\拟合条件异方差模型","link":"/Math-Mixin/Time-Series/models_garch.html"},{"title":"统计检验","text":"JJ 检验检验思想 JJ 检验：检验 $VAR(k)$ 模型的协整关系 参考多元分析中典型相关分析的构造思想 \\begin{align*} Y_t & = c + \\Pi_1 Y_{t-1} + \\Pi_2 Y_{t-2} + \\cdots + \\Pi_k Y_{t-k} + u_t + \\Phi D_t \\\\ \\Delta Y_t & = y_{t-1} + \\Pi Y_{t-1} + \\Gamma_1 \\Delta Y_{t-2} + \\cdots + \\Gamma_{k-1} \\Delta Y_{t-p+1} + \\epsilon_t + \\Phi D_t \\end{align*} $Yt = (y{1,t}, y{2,t}, \\cdots, y{N,t})^T \\sim I(1)$ $\\Pi = \\sum_{i=1}^k \\Pi_i - I$ $\\Gammai = -\\sum{j=i+1}^k$ 基础协整关系 = $\\Pi$ 非零特征根数量 基础协整关系的任意线性组合依然是协整的 系统中协整关系至少为非零特征根数量 检验方法 假设 $\\lambda_1 \\geq \\lambda_2 \\geq \\cdots \\lambda_m$ 是 $\\Pi$ 的所有特征根 最大特征根检验 检验统计量：Bartlette 统计量 $Q = -Tln(1-\\lambda_i^2)$ 假设 原假设：$H_0: \\lambda_i = 0$ 检验流程 从 $\\lambda_1$ 开始检验是否显著不为 0 直到某个 $\\lambda_k$ 非显著不为0，则系统有 $k-1$ 个协整关系 迹检验 检验统计量：Bartlette 统计量 $Q = -T \\sum_{j=i}^m ln(1-\\lambda_j^2)$ 假设 原假设：$H0: \\sum{j=i}^m \\lambda_j = 0$ 检验流程 从 $\\sum_{j=1}^m \\lambda_j = 0$ 开始检验是否显著不为 0 直到某个 $\\sum_{j=k}^m ln(1-\\lambda_j^2)$ 非显著不为 0，说明系统存在$k-1$个协整关系","link":"/Math-Mixin/Time-Series/stat_tests.html"},{"title":"时间序列分析","text":"时间序列分析 时间序列数据：在不同时间点收集到的数据，反映某事物、现象随实际变化状态、程度 描述性时序分析：通过直观的数据比较、绘图观测，寻找序列中蕴含的发展规律 操作简单、直观有效，是时序分析的第一步 但是只能展示非常明显的规律性 最早的时序分析方法，所有时序分析的基础 帮助人们找到自然规律 尼罗河的泛滥 范蠡稳定粮价 小麦价格指数序列 太阳黑子运动规律 确定性时序分析：根据序列的观察特征，先构想一个序列运行的理论，默认序列按照此理论确定性运作 侧重于确定性信息的提取 通常不能通过分析误差自行修正模型，只能通过新的模型假定， 推翻旧模型实现分析方法的改进 假定条件决定了序列的拟合精度，如果确定性的假定条件不对， 误差将很大，因此限制其使用范围 时域分析确定性时域分析 原理：事件的发展通常具有一定的惯性，用统计语言描述就是序列值之间存在一定的相关关系，即某种统计规律 目的：寻找序列值之间的相关关系的统计规律，并拟合适当数学模型描述，进而用于预测 特点 理论基础扎实 操作步骤规范 分析结果易于解释 常用领域 宏观经济领域的 Time Series Decomposition 确定性趋势预测 趋势预测：线性趋势预测、非线性趋势预测 指数平滑预测：简单、两参、三参指数平滑 随机性时域分析 原理：假设序列为随机变量序列，利用对随机变量分析方法研究序列 特点 预测精度更高 分析结果可解释性差 是目前时域分析的主流方法 频域分析 思想：假设任何一种无趋势的实现序列，都可以分解成若干不同频率的周期波动（借助傅里叶变换，用三角函数逼近） 时域分析发展启蒙阶段 AR 模型：George Undy Yule MA 模型、Yule-Walker 方程：Sir Gilbert Thomas Walker 核心阶段 ARIMA：经典时间序列分析方法，是时域分析的核心内容 Box &amp; Jenkins 书中系统的阐述了ARIMA模型的识别、估计、检验、预测原理和方法 完善阶段 异方差场合 ARCH：Robert Fry Engle GARCH：Bollerslov GARCH 衍生模型 EGARH IGARCH GARCH-M NGARCH QGARCH TGARCH 多变量场合 ARIMAX：Box &amp; Jenkins Co-intergration and error correction model：C.Granger，协整理论 SYSLIN：Klein，宏观经济连理方程组模型 Vector Autoregressive Model：Sims，货币政策及其影响 非线性场合 Threshold Autoregressive Model Artificical Neural Network Hebbian Learning：神经可塑性假说 Multivariate Adaptive Regression Splines Linear Classifier Support Vector Machines","link":"/Math-Mixin/Time-Series/stat_time_series.html"},{"title":"Vector Auto-regression Model","text":"Vector Auto-regression ModelVAR 模型：向量自回归模型 模型特点 不以经济理论为基础 结构简介明了 预测精度高 模型方程特点 采用多方程联立的形式 需要估计 $m(mp+1)$ 个参数的，对样本数量要求高 模型的每个方程中，内生变量 对模型的全部内生变量滞后项进行回归，估计全部内生变量的动态关系 模型用途 脉冲响应分析 方差分解 VAR 模型参数 VAR 模型系数由统计相关性估计 不具有逻辑上的因果关系 通常不直接解读 VAR 模型每个方程的经济学意义 VAR 模型参数不进行参数显著性检验，但是允许研究人员对参数施加特殊约束 VAR 模型通常是由一系列 非平稳序列构造的平稳系统 所以若包含非平稳变量，其中至少存在 1 个协整关系 协整关系具有经济学意义，可以解读系数（所以需要进行协整检验） VAR模型形式两变量 VAR(1) 方程组形式 \\begin{cases} & y_{1,t} = c_1 + \\pi_{1,1}y_{1,t-1} + \\pi_{1,2}y_{2,t-1} + u_{1t} \\\\ & y_{2,t} = c_2 + \\pi_{2,1}y_{1,t-1} + \\pi_{2,2}y_{2,t-1} + u_{2t} \\\\ \\end{cases} 矩阵形式 \\begin{bmatrix} y_{1,t} \\\\ y_{2,t} \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix} + \\begin{bmatrix} \\pi_{1,1} & \\pi_{1,2} \\\\ \\pi_{2,1} & \\pi_{2,2} \\\\ \\end{bmatrix} \\begin{bmatrix} y_{1,t-1} \\\\ y_{2,t-1} \\end{bmatrix} + \\begin{bmatrix} u_{1,t} \\\\ u_{2,t} \\end{bmatrix} $u{1,t}, u{2,t} \\overset {i.i.d.} {\\sim} (0, \\theta^2)$：随机波动项，$Cov(u{1,t}, u{2,t}) = 0$ 多变量的 VAR(k)（含外生变量） Y_t = C + \\Pi_1 Y_{t-1} + \\Pi_2 Y_{t-2} + \\cdots + \\Pi_k Y_{t-k} + U_t + \\Phi Z_t $Yt = (y{1,t}, y{2,t}, \\cdots, y{N,t})^T$：内生变量 $C = (c_1, c_2, \\cdots, c_N)^T$：常数项 $\\Pi_j = \\begin{bmatrix} \\pi_{11,j} &amp; \\pi_{12,j} &amp; \\cdots &amp; \\pi_{1N,j} \\\\ \\pi_{21,j} &amp; \\pi_{22,j} &amp; \\cdots &amp; \\pi_{2N,j} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\pi_{N1,j} &amp; \\pi_{N2,j} &amp; \\cdots &amp; \\pi_{NN,j} \\\\ \\end{bmatrix}$：内生变量待估参数 $Ut = (u{1,t}, u{2,t}, \\cdots, u{N,t})^T \\overset {i.i.d.} {\\sim} (0, \\Omega)$：随机波动项 $Zt = (z{1,t}, z{2,t}, \\cdots, z{N, t})^T$：外生变量 VAR(k) 变换 VAR(k) 模型可通过变换附加伴随矩阵式，改写为 VAR(1) \\begin{align*} Y_t & = \\Pi_1 Y_{t-1} + \\Pi_2 Y_{t-2} + \\cdots + \\Pi_k Y_{t-k} + U_t \\\\ & = \\begin{bmatrix} \\Pi_1 & \\Pi_2 & \\cdots & \\Pi_k \\end{bmatrix} \\begin{bmatrix} Y_{t-1} \\\\ Y_{t-2} \\\\ \\vdots \\\\ Y_{t-k} \\end{bmatrix} + U_t \\\\ & = AY + U_t \\end{align*}Structured VARSVAR：结构 VAR 模型，在 VAR 模型基础上加入内生变量当期值 即解释变量中含有当期变量 两变量 SVAR(1) \\begin{cases} & y_{1t} = c_1 + \\pi_{11}y_{2t} + \\pi_{12}y_{1,t-1} + \\pi_{13}y_{1,t-2} + u_1 \\\\ & y_{2t} = c_2 + \\pi_{21}y_{1t} + \\pi_{22}y_{1,t-1} + \\pi_{23}y_{1,t-2} + u_2 \\\\ \\end{cases}含外生变量 VAR(1)\\begin{align*} AY_t & = D + BY_{t-1} + FZ_t + V_t \\\\ Y_t & = A^{-1}D + A^{-1}BY_{t-1} + A^{-1}FZ_t + A^{-1}v_t \\\\ & = C + \\Pi_1 Y_{t-1} + HZ_t + U_t \\end{align*} $Y_t, Z_t, V_t$：内生变量向量、外生变量向量、误差项向量 $A, D, B, F$：模型结构参数 $C=A^{-1}D, \\Pi_1=A^{-1}B, H=A^{-1}F, U_t=A^{-1}V_t$ VAR 模型稳定性 把脉冲施加在 VAR 模型中某个方程的 Iinnovation 过程上 随着时间推移，冲击会逐渐消失，则模型稳定 冲击不消失的则模型不稳定 一阶 VAR 模型分析\\begin{align*} Y_t & = C + \\Pi_1Y_{t-1} + U_t \\\\ & = (I + \\Pi_1 + \\Pi_1^2 + \\cdots + \\Pi_1^{t-1})C + \\Pi_1^tY_0 + \\sum_{i=0}^{t-1} \\Pi_1^i U_{t-i} \\end{align*} $\\mu = (I + \\Pi_1 + \\Pi_2^2 + \\cdots + \\Pi_1^{t-1})C$：漂移向量 $Y_0$：初始向量 $U_t$：新息向量 $t \\rightarrow \\infty$ 时有 I + \\Pi_1 + \\Pi_2^2 + \\cdots + \\Pi_1^{t-1} = (I-\\Pi_1)^{-1} 两变量 VAR(1) 稳定条件 Y_t = C + \\Pi_1 Y_{t-1} + U_t 稳定条件 特征方程$|\\Pi_1 - \\lambda I|=0$根都在单位圆内 相反的特征方程$|I - L\\Pi_1|=0$根都在单位圆外 VAR(k) 稳定条件\\begin{align*} \\begin{bmatrix} Y_t \\\\ Y_{t-1} \\\\ Y_{t-2} \\\\ \\vdots \\\\ Y_{t-k+1} \\end{bmatrix} & = \\begin{bmatrix} C \\\\ 0 \\\\0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} \\Pi_1 & \\Pi_2 & \\cdots & \\Pi_{k-1} & \\Pi_{k} \\\\ I & 0 & \\cdots & 0 & 0 \\\\ 0 & I & \\cdots & 0 & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\ 0 & 0 & \\cdots & I & 0 \\end{bmatrix} \\begin{bmatrix} Y_{t-1} \\\\ Y_{t-2} \\\\ Y_{t-3} \\\\ \\vdots \\\\ Y_{t-k} \\end{bmatrix} + \\begin{bmatrix} U_t \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\\\ & = [C|0]^T + AY + U \\end{align*} $A$：$Nk$ 阶方阵 $N$：回归向量维度 $k$：自回归阶数 稳定条件 特征方程 $|A - \\lambda I| = 0$ 根全在单位圆内 相反的特征方程 $|I - LA| = 0$ 根全在单位圆外 VEC 模型N 变量 VEC(k)\\begin{align*} \\Delta Y_t & = y_{t-1} + \\Pi Y_{t-1} + \\Gamma_1 \\Delta Y_{t-2} + \\cdots + \\Gamma_{k-1} \\Delta Y_{t-p+1} + U_t + \\Phi Z_t \\end{align*} $\\Pi = \\sum_{i=1}^k \\Pi_i - I$：影响矩阵 $\\Gammai = -\\sum{j=i+1}^k$ VEC(1)\\begin{align*} \\Delta Y_{t} & = \\Pi Y_{t-1} + \\Gamma \\Delta Y_{t-1} \\\\ & = \\alpha \\beta^{'} Y_{t-1} + \\Gamma \\Delta Y_{t-1} \\\\ & = \\alpha ECM_{t-1} + \\Gamma \\Delta Y_{t-1} \\end{align*}Impulse-Response Function脉冲响应函数：描述内生变量对误差冲击的反应 脉冲响应函数含义 在随机误差下上施加标准查大小的冲击后，对内生变量当期值和未来值所带来的影响 即将 VAR 模型表示为无限阶的向量 $MA(\\infty)$ 过程 对脉冲响应函数的解释的困难源于，实际中各方程对应误差项不是完全非相关 误差相关时，其有一个共同组成部分，不能被任何特定变量识别 故，左乘变换矩阵 $M$ 得到 $V_t = MU_t$ 修正相关性（常用 Cholesky 分解求解） 即将其协方差矩阵变换为对角矩阵 $V_t = MU_t \\sim (0, \\Omega)$ VAR(1) 转换为 MA \\begin{align*} Y_t & = AY_{t-1} + U_t \\\\ (I - LA)Y_t & = U_t \\\\ Y_t & = (I-LA)^{-1} U_t \\\\ & = U_t + AU_{t-1} + A^2U_{t-2} + \\cdots + A^sU_t + \\cdots\\\\ Y_{t+s} & = U_{t+s} + \\Psi_1U_{t+s-1} + \\Psi_2U_{t+s-2} + \\cdots + \\Psi_sU_t + \\cdots \\end{align*} $\\Psis = A^s = \\frac {\\partial Y{t+s}} {\\partial U_t}$ $\\Psis[i, j] = \\frac {\\partial y{i,t+s}} {\\partial u{j,t}}$：脉冲响应函数，表示其他误差项在任何时期都不变条件下，第 $j$ 个变量 $y{j,t}$ 在对应误差项 $u{j,t}$ 在 $t$ 期受到一个单位冲击后，对第 $i$ 个内生变量 $y{i,t}$ 在 $t+s$ 期造成的影响 方差分解方差分解：分析未来 $t+s$ 期 $y_{j, t+s}$ 的预测误差受不同新息冲击影响比例 均方误差 误差可以写为 MA 形式 Y_{t+s} - \\hat Y_{t+s|t} = U_{t+s} + \\Psi_1U_{t+s-1} + \\Psi_2U_{t+s-2} + \\cdots + \\Psi_{s-1}U_{t+1} 则预测s期的均方误差为 \\begin{align*} MSE(\\hat Y_{t+s|t}) & = E[(Y_{t+s} - \\hat Y_{t+s|t}) (Y_{t+s} - \\hat Y_{t+s|t})^T] \\\\ & = \\Omega + \\Psi_1\\Omega\\Psi_1^T + \\cdots + \\Psi_{s-1}\\Omega\\Psi_{s-1}^T \\end{align*} $\\Omega = E(U_tU_t^T)$：不同期 $U_t$ 协方差阵为 0 计算比例\\begin{align*} U_t &= MV_t \\\\ &= m_1v_{1,t} + m_2v_{2,t} + \\cdots + m_Nv_{N,t} \\\\ \\Omega & = E(U_t, U_t^T) \\\\ & = (MV_t)(MV_t)^T \\\\ & = m_1m_1^TVar(v_{1,t} + \\cdots + m_Nm_N^TVar(v_{N,t}) \\end{align*} $v{1,t}, v{2,t}, \\cdots, v_{N,t}$不相关 将 $\\Omega$ 带入 MSE 表达式中，既可以得到第 $j$ 个新息对 $s$ 期预测量 $\\hat Y_{t+s|t}$ 的方差贡献比例 VAR 建模 进行单变量平稳性检验 拟合 VAR(p) 模型 确定模型阶数 理论上初步模型阶数可以任意确定 然后根据 AIC、BIC、对数似然函数值选择相对最优阶数 若所有变量平稳，则 Granger 因果检验 VAR 模型通过平稳性检验，理论上就可以利用模型进行分析、预测 但 VAR 模型是超系数模型，默认所有内生变量互为因果 但实际上变量之间因果关系复杂 可通过 Granger 因果检验判断变量之间长期、短期因果关系 若有变量非平稳 检验模型平稳性 Granger 因果检验 协整检验：JJ 检验 非平稳系统必然存在协整关系，具有经济学意义 所以需要找出存在的基础协整关系，解读其代表的长期、短期相关影响 构建 VEC 模型 如果协整检验显示基本协整关系满秩，说明系统中每个序列都是平稳序列，直接建立VAR模型 如果协整检验限制基本协整关系为 0 秩，则系统不存在协整关系，通常说明系统不平稳，需要重新选择变量， 或者适当差分后建模 最常见情况是协整检验显示基本协整关系数量处于 0 至满秩中间，此时建立 $VEC$ 模型 脉冲响应分析 方差分析 模型预测","link":"/Math-Mixin/Time-Series/stat_var.html"},{"title":"Cmd Markdown Reference","text":"我们理解您需要更便捷更高效的工具记录思想，整理笔记、知识，并将其中承载的价值传播给他人，Cmd Markdown 是我们给出的答案 —— 我们为记录思想和分享知识提供更专业的工具。 您可以使用 Cmd Markdown： 整理知识，学习笔记 发布日记，杂文，所见所想 撰写发布技术文稿（代码支持） 撰写发布学术论文（LaTeX 公式支持） 除了您现在看到的这个 Cmd Markdown 在线版本，您还可以前往以下网址下载： Windows/Mac/Linux 全平台客户端 请保留此份 Cmd Markdown 的欢迎稿兼使用说明，如需撰写新稿件，点击顶部工具栏右侧的 新文稿 或者使用快捷键 Ctrl+Alt+N。 什么是 MarkdownMarkdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号以最小的输入代价生成极富表现力的文档：譬如您正在阅读的这份文档。它使用简单的符号标记不同的标题，分割不同的段落，粗体 或者 斜体 某些文字，更棒的是，它还可以 1. 制作一份待办事宜 Todo 列表 [ ] 支持以 PDF 格式导出文稿 [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 [x] 新增 Todo 列表功能 [x] 修复 LaTex 公式渲染问题 [x] 新增 LaTex 公式编号功能 2. 书写一个质能守恒公式LaTeXE=mc^23. 高亮一段代码code1234567@requires_authorizationclass SomeClass: pass if __name__ == '__main__': # A comment print 'hello world' 4. 高效绘制 流程图12345678st=&gt;start: Startop=&gt;operation: Your Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 5. 高效绘制 序列图123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! 6. 高效绘制 甘特图12345678910111213title 项目开发流程 section 项目确定 需求分析 :a1, 2016-06-22, 3d 可行性报告 :after a1, 5d 概念验证 : 5d section 项目实施 概要设计 :2016-07-05 , 5d 详细设计 :2016-07-08, 10d 编码 :2016-07-15, 10d 测试 :2016-07-22, 5d section 发布验收 发布: 2d 验收: 3d 7. 绘制表格 项目 价格 数量 计算机 $1600 5 手机 $12 12 管线 $1 234 8. 更详细语法说明想要查看更详细的语法说明，可以参考我们准备的 Cmd Markdown 简明语法手册，进阶用户可以参考 Cmd Markdown 高阶语法手册 了解更多高级功能。 总而言之，不同于其它 所见即所得 的编辑器：你只需使用键盘专注于书写文本内容，就可以生成印刷级的排版格式，省却在键盘和工具栏之间来回切换，调整内容和格式的麻烦。Markdown 在流畅的书写和印刷级的阅读体验之间找到了平衡。 目前它已经成为世界上最大的技术分享网站 GitHub 和 技术问答网站 StackOverFlow 的御用书写格式。 什么是 Cmd Markdown您可以使用很多工具书写 Markdown，但是 Cmd Markdown 是这个星球上我们已知的、最好的 Markdown 工具——没有之一 ：）因为深信文字的力量，所以我们和你一样，对流畅书写，分享思想和知识，以及阅读体验有极致的追求，我们把对于这些诉求的回应整合在 Cmd Markdown，并且一次，两次，三次，乃至无数次地提升这个工具的体验，最终将它演化成一个 编辑/发布/阅读 Markdown 的在线平台——您可以在任何地方，任何系统/设备上管理这里的文字。 1. 实时同步预览我们将 Cmd Markdown 的主界面一分为二，左边为编辑区，右边为预览区，在编辑区的操作会实时地渲染到预览区方便查看最终的版面效果，并且如果你在其中一个区拖动滚动条，我们有一个巧妙的算法把另一个区的滚动条同步到等价的位置，超酷！ 2. 编辑工具栏也许您还是一个 Markdown 语法的新手，在您完全熟悉它之前，我们在 编辑区 的顶部放置了一个如下图所示的工具栏，您可以使用鼠标在工具栏上调整格式，不过我们仍旧鼓励你使用键盘标记格式，提高书写的流畅度。 3. 编辑模式完全心无旁骛的方式编辑文字：点击 编辑工具栏 最右侧的拉伸按钮或者按下 Ctrl + M，将 Cmd Markdown 切换到独立的编辑模式，这是一个极度简洁的写作环境，所有可能会引起分心的元素都已经被挪除，超清爽！ 4. 实时的云端文稿为了保障数据安全，Cmd Markdown 会将您每一次击键的内容保存至云端，同时在 编辑工具栏 的最右侧提示 已保存 的字样。无需担心浏览器崩溃，机器掉电或者地震，海啸——在编辑的过程中随时关闭浏览器或者机器，下一次回到 Cmd Markdown 的时候继续写作。 5. 离线模式在网络环境不稳定的情况下记录文字一样很安全！在您写作的时候，如果电脑突然失去网络连接，Cmd Markdown 会智能切换至离线模式，将您后续键入的文字保存在本地，直到网络恢复再将他们传送至云端，即使在网络恢复前关闭浏览器或者电脑，一样没有问题，等到下次开启 Cmd Markdown 的时候，她会提醒您将离线保存的文字传送至云端。简而言之，我们尽最大的努力保障您文字的安全。 6. 管理工具栏为了便于管理您的文稿，在 预览区 的顶部放置了如下所示的 管理工具栏： 通过管理工具栏可以： &lt;/i&gt; 发布：将当前的文稿生成固定链接，在网络上发布，分享 新建：开始撰写一篇新的文稿 &lt;/i&gt; 删除：删除当前的文稿 导出：将当前的文稿转化为 Markdown 文本或者 Html 格式，并导出到本地 &lt;/i&gt; 列表：所有新增和过往的文稿都可以在这里查看、操作 模式：切换 普通/Vim/Emacs 编辑模式 7. 阅读工具栏 通过 预览区 右上角的 阅读工具栏，可以查看当前文稿的目录并增强阅读体验。 工具栏上的五个图标依次为： &lt;/i&gt; 目录：快速导航当前文稿的目录结构以跳转到感兴趣的段落 视图：互换左边编辑区和右边预览区的位置 &lt;/i&gt; 主题：内置了黑白两种模式的主题，试试 黑色主题，超炫！ 阅读：心无旁骛的阅读模式提供超一流的阅读体验 全屏：简洁，简洁，再简洁，一个完全沉浸式的写作和阅读环境 8. 阅读模式在 阅读工具栏 点击 或者按下 Ctrl+Alt+M 随即进入独立的阅读模式界面，我们在版面渲染上的每一个细节：字体，字号，行间距，前背景色都倾注了大量的时间，努力提升阅读的体验和品质。 9. 标签、分类和搜索在编辑区任意行首位置输入以下格式的文字可以标签当前文档： 标签： 未分类 标签以后的文稿在【文件列表】（Ctrl+Alt+F）里会按照标签分类，用户可以同时使用键盘或者鼠标浏览查看，或者在【文件列表】的搜索文本框内搜索标题关键字过滤文稿，如下图所示： 10. 文稿发布和分享在您使用 Cmd Markdown 记录，创作，整理，阅读文稿的同时，我们不仅希望它是一个有力的工具，更希望您的思想和知识通过这个平台，连同优质的阅读体验，将他们分享给有相同志趣的人，进而鼓励更多的人来到这里记录分享他们的思想和知识，尝试点击 (Ctrl+Alt+P) 发布这份文档给好友吧！ 再一次感谢您花费时间阅读这份欢迎稿，点击 (Ctrl+Alt+N) 开始撰写新的文稿吧！祝您在这里记录、阅读、分享愉快！ 作者 @ghosert2016 年 07月 07日 LaTeX. 支持 LaTeX 编辑显示支持，例如：$\\sum_{i=1}^n a_i=0$， 访问 MathJax 参考更多使用方法。 ↩ code. 代码高亮功能支持包括 Java, Python, JavaScript 在内的，四十一种主流编程语言。 ↩","link":"/Tool/Markup-Language/md_reference.html"},{"title":"二进制文件格式","text":"IDXIDX：MNIST数据集独创的数据格式 用于存储多维数组 后可以跟数字表示存储数组的维度 idx1：存储1维数组 idx3：存储3维数组 格式 2bytes：格式版本号 一直是0x0000 1bytes：数组中每个元素的数据类型 0x08：unsigned byte 0x09：signed byte 0x0B：short（2bytes） 0x0C：int（4bytes） 0x0D：float（4bytes） 0x0E：double（8bytes） 1bytes：数组维度d d * 4bytes(int)：数组各维度长度 数据部分 数据类型已知、长度已知 若元素格式符合文件头要求，表明解析正确，否则文件损坏","link":"/Tool/Markup-Language/binary_format.html"},{"title":"配置文件笔记","text":"IniTomlYaml基本语法规则 大小写敏感 缩进代表层级关系 必须空格缩进 不要求空格数目 同层左对齐 数据结构 -、:、?等符号后总是需要空格 #表示注释 对象/映射对象/映射：键值对集合，:表示、{}行内表示 1234567891011121314151617181920// `:`后要空格key: value// 多层级对象key: child_key1: val1 child_key2: val2// 流式表示key: {child_key1: val1, child_key2: value2}// 复杂对象格式：键、值都是数组// `? `（空格）表示复杂key? - complex_key1 - complex_key2// `: `（空格）表示复杂value: - complex_val1 - complex_val2 数组数组：-开头、[]行内表示 12345678910111213// `[[ele1, ele2]]`- - ele1 - ele2// `pkey: [{key1: val1}, {key2: val2, key3: val3}]`pkey: - key1: val1 - key2: val2 key3: val3 标量1234567891011121314151617181920212223boolean: - TRUE # true, True均可 - FALSE # false, False均可float: - 3.14 - 3.14e+2 # 科学计数法int: - 13 - 0b1010_1010_1010_1010 #二进制null: key: ~ # `~`表示nullstring: - 'hello world' # 单、双引号包括特殊字符 - line1 line2 # 字符串可以拆成多行，换行转换为空格datetime: - 2019-07-10 # ISO 8601格式，`yyyy-MM-dd` - 2019-07-10T17:53:23+08:00 # ISO 8601格式，`&lt;date&gt;T&lt;time&gt;+&lt;timezone&gt;` 特殊符号 ---：表示文档开始 ...：文档结束 二者配合在文件中记录多个yaml配置项 !!：强制类型转换 &gt;：折叠换行符为空格 |：保留换行符 &amp;：锚点 不能独立定义，即非列表、映射值 *：锚点引用 可以多次引用 被引用值可能会之后被覆盖 &lt;&lt;：合并内容 主要配合锚点使用 相当于unlist解构 1234567891011121314151617181920--- # 文档开始string: - !!str 13 - !!str true... # 文档结束---!!set # 强转为set- A1: &amp;A1 {x: 1, y: 2} # 定义名称为`A1`锚点- A2: &amp;A2 {a: 3, b: 4} # 定义名称为`A2`锚点- B: &gt; # 折叠换行符 this line will collapse- C: | # 保留换行符 this paragraph keeps the &lt;CR&gt;- D: *A` # 引用名为`SS`的锚点- E: # E等价于`{x:1, y:2, a:34, b:4}` &lt;&lt;: [*A1, *A2] a: 34... API Java package：org.yaml.snakeyaml.Yaml Python package：PyYaml import yaml Xml","link":"/Tool/Markup-Language/config_formation.html"},{"title":"FireFox常用设置","text":"Aboutabout:config ntl.charset.fallback.utf8_for_file：是否默认以 utf-8 编码打开文件 避免纯文本文件打开乱码","link":"/Tool/Web-Browser/firefox.html"},{"title":"MarkDown Basics","text":"[TOC] 标题 Setext形式: 以底线的形式 = 表示最高阶标题 - 表示次阶标题 Atx形式: 在行首插入1-6各#表示1-6阶标题 [TOC]可以生成标题链接目录(兼容性不好,不是标准实现) 段落 类似html格式， md忽略文件中的换行符 如果需要新开段落, 手动使用空行(可包含不可见&lt;space&gt; &lt;tab&gt;字符) 区块引用 使用email形式的&gt;标识 可嵌套, 根据层次添加不同数量的&gt; 其中可使用其他形式的语法, 如: 标题, 列表, 代码区块 也可以只给整个”段落”第一行加上&gt; 修辞和强调 *和_包裹输出为html标签&lt;em&gt; **和__包裹则是输出为html标签&lt;strong&gt; ~~包裹输出&lt;del&gt;(删除线) 符号两边如果有空格则会当作普通符号 可以\\*, \\_转义的方式输出普通符号 列表 无序列表: -, +, *都可以输出无序列表 有序列表: 数字接半角句点. 列表项目标记一般放在最左边, 也可以缩进, 最多3个空格, 项目 标记后面一定要&lt;space&gt;或&lt;tab&gt; MD其实不关心有序列表中数字的顺序正确性, 只是单纯的输出为 &lt;li&gt;, 如果需要避免将1.类似输出为有序列表, 需要转义 1\\. 在列表项目间增加空行, 会把列表内容用&lt;p&gt;包裹, 列表 项目可以包含多个段落, 此时列表内段落间也需要空行分隔, 且 项目下所有段落都需要缩进&lt;tab&gt;或4个&lt;space&gt; (这里的段落是指MD意义上的一段, 不是源文件的一段, 即缩进 也只是需要在MD意义上一段的第一行缩进, 当然所有行都缩进 比较美观) 在列表项目内添加引用, &gt;需要缩进, 而代码块本身就需要 缩进, 所以需要缩进2个&lt;tab&gt;或8个&lt;space&gt; 链接 行内形式: 直接在链接内容之后用括号添加链接 [link_content](link &quot;title(optional)&quot;) 参考形式: 为链接定义一个名称, 然后可以在其他地方给出地址 [link_content][id] [id]: link &quot;title(optional)&quot; [id]: link 'title' [id]: link (title) 参考形式中 三种定义title的方式都可以 id可以包括空格, 不区分大小写 隐式链接标记功能可以省略id, 此时链接标记(id)视为等同 于链接内容 自动链接 &lt;link&gt;: 自动转换为链接, 内容就是链接地址 &lt;email&gt;: 自动转换为邮箱链接 图片 行内形式: ![alt text](link &quot;title(optional)&quot;) 参考形式: ![alt text][id] [id]: link &quot;title(optional)&quot; 代码 段落内代码: 使用`包裹回输出html标签&lt;code&gt; 代码区块 每行缩进&lt;tab&gt;或者4个&lt;space&gt; 3个`包裹, 后面还可以接代码类型, 可能会有代码高亮 12def fn(): print('hello markdown') def fn(): print('hello markdown') 表格 |: 纵向边界 -: 表头和内容边界, 可用于设置对齐 :----: 左对齐 -----: 默认左对齐 :---:: 居中对齐 ----:: 右对齐 特殊字符对于html中特殊字符&lt;(起始标签)和&amp;(标记html实体)会自动 “智能”转义. 如果使用的&amp;字符是html实体字符的一部分, 那么会 保留原状, 否则会转换为&amp;amp 如: 输入&copy;会被保留, 直接显示为copyright字符 分隔线一行中3个以上的-, *, _可以建立分隔线, 符号之间可以有 空格, 不能有其他东西 其他 注脚: 在注脚文字后接[^footer1]footer1, 然后在其他 地方[^footer1]: 注脚内容","link":"/Tool/Markup-Language/markdown_notes.html"},{"title":"TeX、LaTeX、XeLaTeX","text":"TeXTeX：由Donald Knuth开发的高质量排版系统 TeX的范畴包括标记语法（命令）、具体实现（引擎），在不同 场合含义不同，类似语言、编译器 初版TeX包含300左右命令，随后Donald添加Plain TeX扩展包 定义了600左右常用宏命令 TeX中将标记关键字称为命令，其实关键字确实类似命令，可能 系统对应命令、语言对应关键字 TeX宏包 *.cls类文件：定义文档结构 *.sty包/样式文件：提供类未包括的任何东西 对类文件功能的补充：提供从属于类文件的功能 对类文件功能的修改：改变类文件的风格 基础排版宏包 LaTeX：Leslie Lamport设计的更高层次、更抽象的排版格式 包含以TeX命令为基础的一系列高层、抽象宏命令，包括 \\section、\\usepackage等 用户可以使用模板而不必决定具体排版、打印，使用更加 方便 是学界事实上的标准排版格式 ConTeXt：Pragma-ADE公司设计的文档制造格式 为TeX提供对先进打印特性的易用接口 生成的编译文件更美观，适合专业印刷行业使用 TeXinfo：FSF（Free Software Foundation）设计的格式 是Linux系统的标准文档系统 中文排版宏包 xeCJK：在XeTeX引擎下处理中日韩文字断行、标点调整、字体 选择的基础性宏包 基础从CCT、CJK以来的标点禁则、标点压缩、NFSS字体补丁 实际上仅对简体中文处理机制比较完全 XeTeX本身已经能够大概处理中文文档的排版，但在某些 细节部分仍然可以改进 类似的宏包还有：zhspacing、xCJK、xCCT CTeX：提供了编写中文文档时常用的宏命令 其他宏包 AMS-TeX/AMS-LaTeX：AMS（American Mathematical Society） 设计的格式 提供了额外的数学字体、多行数学表述排版 TeX引擎 pdfTex：将TeX文本编译输出为pdf格式的引擎实现 最初TeX/LaTeX实现将TeX编译为DVI格式，然后方便转换为 PostScript文件用于打印 而pdf格式超越PostScript格式成为更流行的预打印格式 因此事实上，现在LaTeX发行版中包含4个部分：TeX、 pdfTeX、LaTeX、pdfLaTeX XeTeX：扩展了TeX的字符、字体支持的引擎实现 最初TeX/LaTeX仅仅支持英语数字、字母 XeTeX提供了对Unicode字符和TrueType/OpenType字体的 直接支持 LuaTeX：将TeX扩展为更sensible的编程语言的实现 TeX发行版TeX LiveTeX Live：TUG（TeX User Group）发布、维护的TeX系统 TeX Live包含 与TeX系统相关的各种程序 pdfTeX XeTeX LuaTeX 编辑查看工具 DVIOUT DVI Viewer PS View TeXworks 常用宏包 LaTeX 常用字体 多个语言支持 TeX Live官网：https://tug.org/texlive MiKTeXMiKTeX：Christian Schenk开发的在MSWin下运行文字处理系统 MiKTeX官网：http://miktex.org CTeXCTeX：CTeX学会开发，将MiKTeX及常用应用封装 集成WinEdt编辑器 强化了对中文的处理","link":"/Tool/Markup-Language/tex.html"},{"title":"数据预处理","text":"数据说明数据模式 结构化数据：行数据，可用二维表逻辑表达数据逻辑、存储在数据库中 可以看作是关系型数据库中一张表 行：记录、元组，表示一个样本信息 列：字段、属性，有清晰定义 非结构化数据：相对于结构化数据而言，不方便用二维逻辑表达的数据 包含信息无法用简单数值表示 没有清晰列表定义 每个数据大小不相同 研究方向 社交网络数据 文本数据 图像、音视频 数据流 针对不同类型数据、具体研究方面有不同的具体分析方法，不存在普适、可以解决所有具体数据的方法 半结构化数据：介于完全结构化数据、完全无结构数据之间的数据 一般是自描述的，数据结构和内容混合、没有明显区分 树、图（XML、HTML 文档也可以归为半结构化数据） 结构化数据：先有结构、再有数据 半结构化数据：先有数据、再有结构 数据拼接 利用外键拼接不同来源的数据时，注意不同数据间粒度差异 外键低于问题标签粒度时，考虑对数据作聚合操作再拼接 保证拼接后用于训练的记录粒度和问题一致 避免维度爆炸 各数据来源数据厚薄不同，会改变数据分布 外键高于、等于目标粒度时，可考虑直接直接连接 数据问题稀疏特征 产生原因 数据缺失 统计数据频繁 0 值 特征工程技术，如：独热编码 缺失值产生原因 信息暂时无法获取、成本高 信息被遗漏 属性不存在 缺失值影响 建模将丢失大量有用信息 模型不确定性更加显著、蕴含规则更难把握 包含空值可能使得建模陷入混乱，导致不可靠输出 缺失利用 直接使用含有缺失值特征：有些方法可以完全处理、不在意缺失值 分类型变量可以将缺失值、异常值单独作为特征的一种取值 数值型变量也可以离散化，类似分类变量将缺失值单独分箱 删除含有缺失值特征 一般仅在特征缺失率比较高时才考虑采用，如缺失率达到 90%、95% 插值补全 非模型补全缺失值 均值、中位数、众数 同类/前后均值、中位数、众数 固定值 矩阵补全 最近邻补全：寻找与样本最接近样本相应特征补全 手动补全：根据对所在领域理解，手动对缺失值进行插补 需要对问题领域有很高认识理解 缺失较多时费时、费力 建模预测：回归、决策树模型预测 若其他特征和缺失特征无关，预测结果无意义 若预测结果相当准确，缺失属性也没有必要纳入数据集 多重插补：认为待插补值是随机的 通常估计处待插补值 再加上不同噪声形成多组可选插补值 依据某准则，选取最合适的插补值 高维映射：one-hot 编码增加维度表示某特征缺失 保留所有信息、未人为增加额外信息 可能会增加数据维度、增加计算量 需要样本量较大时效果才较好 压缩感知：利用信号本身具有的稀疏性，从部分观测样本中恢复原信号 感知测量阶段：对原始信号进行处理以获得稀疏样本表示 傅里叶变换 小波变换 字典学习 稀疏编码 重构恢复阶段：基于稀疏性从少量观测中恢复信号 异常值 异常值/离群点：样本中数值明显偏离其余观测值的个别值 异常值分析：检验数据是否有录入错误、含有不合常理的数据 非模型异常值检测 简单统计 观察数据统计型描述、散点图 箱线图：利用箱线图四分位距对异常值进行检测 $3\\sigma$ 原则：取值超过均值 3 倍标准差，可以视为异常值 依据小概率事件发生可能性“不存在” 数据最好近似正态分布 模型异常值检测 基于模型预测：构建概率分布模型，计算对象符合模型的概率，将低概率对象视为异常点 分类模型：异常点为不属于任何类的对象 回归模型：异常点为原理预测值对象 特点 基于统计学理论基础，有充分数据和所用的检验类型知识时，检验可能非常有效 对多元数据，可用选择少，维度较高时，检测效果不好 基于近邻度的离群点检测：对象离群点得分由其距离 k-NN 的距离确定 k 取值会影响离群点得分，取 k-NN 平均距离更稳健 特点 简单，但时间复杂度高 $\\in O(m^2)$，不适合大数据集 方法对参数 k 取值敏感 使用全局阈值，无法处理具有不同密度区域的数据集 基于密度的离群点检测 定义密度方法 k-NN 分类：k 个最近邻的平均距离的倒数 DSSCAN 聚类中密度：对象指定距离 d 内对象个数 特点 给出定量度量，即使数据具有不同区域也能很好处理 时间复杂度 $\\in O^(m^2)$，对低维数据使用特点数据结构可以达到 $\\in O(mlogm)$ 参数难以确定，需要确定阈值 基于聚类的离群点检测：不属于任何类别簇的对象为离群点 特点 （接近）线性的聚类技术检测离群点高度有效 簇、离群点互为补集，可以同时探测 聚类算法本身对离群点敏感，类结构不一定有效，可以考虑：对象聚类、删除离群点再聚类 检测出的离群点依赖类别数量、产生簇的质量 One-class SVM Isolation Forest 异常值处理 删除样本 简单易行 观测值很少时，可能导致样本量不足、改变分布 视为缺失值处理 作为缺失值不做处理 利用现有变量信息，对异常值进行填补 全体/同类/前后均值、中位数、众数修正 将缺失值、异常值单独作为特征的一种取值 很多情况下，要先分析异常值出现的可能原因，判断异常值是否为真异常值 类别不平衡问题创造新样本 对数据集重采样 尝试随机采样、非随机采样 对各类别尝试不同采样比例，不必保持 1:1 违反现实情况 同时使用过采样、欠采样 属性值随机采样 从类中样本每个特征随机取值组成新样本 基于经验对属性值随机采样 类似朴素贝叶斯方法：假设各属性之间相互独立进行采样，但是无法保证属性之前的线性关系 对模型进行惩罚 类似 AdaBoosting：对分类器小类样本数据增加权值 类似 Bayesian分类：增加小类样本错分代价，如：penalized-SVM、penalized-LDA 需要根据具体任务尝试不同惩罚矩阵 新角度理解问题 将小类样本视为异常点：问题变为异常点检测、变化趋势检测 尝试不同分类算法 使用 one-class 分类器 对问题进行分析，将问题划分为多个小问题 大类压缩为小类 使用集成模型训练多个分类器、组合 需要具体问题具体分析 模型评价 尝试其他评价指标：准确度在不平衡数据中不能反映实际情况 混淆矩阵 精确度 召回率 F1 得分 ROC 曲线 Kappa 数据量缺少图片数据扩充Data Agumentation：根据先验知识，在保留特点信息的前提下，对原始数据进行适当变换以达到扩充数据集的效果 对原始图片做变换处理 一定程度内随机旋转、平移、缩放、裁剪、填充、左右翻转，这些变换对应目标在不同角度观察效果 对图像中元素添加噪声扰动：椒盐噪声、高斯白噪声 颜色变换 改变图像亮度、清晰度、对比度、锐度 先对图像进行特征提取，在特征空间进行变换，利用通用数据 扩充、上采样方法 SMOTE Fine-Tuning 微调：直接接用在大数据集上预训练好的模型，在小数据集上进行微调 简单的迁移学习 可以快速寻外效果不错针对目标类别的新模型 特征缩放 正则化：针对单个样本，将每个样本缩放到单位范数 归一化：针对单个属性，需要用到所有样本在该属性上值 Normalizaion归一化/标准化：将特征/数据缩放到指定大致相同的数值区间 某些算法要求数据、特征数值具有零均值、单位方差 消除样本数据、特征之间的量纲/数量级影响 量级较大属性占主导地位 降低迭代收敛速度：梯度下降时，梯度方向会偏离最小值，学习率必须非常下，否则容易引起宽幅震荡 依赖样本距离的算法对数据量机敏感 决策树模型不需要归一化，归一化不会改变信息增益（比），Gini 指数变化 Min-Max Scaling线性函数归一化：对原始数据进行线性变换，映射到 $[0, 1]$ 范围 X_{norm} = \\frac {X - X_{min}} {X_{max} - X_{min}} 训练集、验证集、测试集都使用训练集归一化参数 Z-Score Scaling零均值归一化：将原始数据映射到均值为 0，标准差为 1 的分布上 Z = \\frac {X - \\mu} {\\sigma}其他一些变换方式 对数变换：$X^{‘} = lg(X)$ 反余切函数变换：$X^{‘} = \\frac {2 arctan(x)} {\\pi}$ Sigmoid 变换：$X^{‘} = \\frac 1 {1 + e^{-x}}$ 模糊向量变：$X^{‘} = \\frac 1 2 + \\frac 1 2 sin \\frac {X - \\frac{max(X) - min(X)} 2} {max(X) - min(X)} * \\pi$ Regularization正则化：将样本/特征某个范数缩放到单位 1 \\begin{align*} \\overrightarrow x_i & = ( \\frac {x_i^{(1)}} {L_p(\\overrightarrow x_i)}, \\frac {x_i^{(2)}} {L_p(\\overrightarrow x_i)}, \\cdots, \\frac {x_i^{(d)}} {L_p(\\overrightarrow x_i)})^T \\\\ L_p(\\overrightarrow x_i) & = (|x_i^{(1)}|^p + |x_i^{(2)}|^p + \\cdots + |x_i^{(d)}|^p)^{1/p} \\end{align*} $L_p$：样本的 $L_p$ 范数 使用内积、二次型、核方法计算样本之间相似性时，正则化很有用","link":"/ML-Technique/Feature-Engineering/data_preprocessing.html"},{"title":"GGPLOT","text":"GGPlot 绘图12345678910111213141516171819p &lt;- ggplot(data=mtcars, aes(x=wt, y=mpg))geom_bar(color, fill, alpha)geom_histogram(color, fill, alpha, linetype, binwidth)geom_boxplot(color, fill, alpha, notch, width)geom_violin(color, fill, alpha, linetype)geom_density(color, fill, alpha, linetype)geom_rug(color, side)geom_smooth(method, formula, color, fill, linetype, size)geom_hline(color, alpha, linetype, size)geom_gitter(color, size, alpha, shape)geom_line(color, alpha, linetype, size)geom_point(color, alpha, shape, size)geom_vline(color, alpha, linetype, size)geom_text() color：点、线、填充区域着色 fill：对填充区域着色，如：条形、密度区域 alpha：颜色透明度，0~1逐渐不透明 linetype：图案线条 1：实线 2：虚线 3：点 4：点破折号 5：长破折号 6：双破折号 size：点尺寸、线宽度 shape：点形状 1：开放的方形","link":"/RLang/ggplot.html"},{"title":"R可视化","text":"R图形参数使用、保存图形保存图形12345678910111213141516171819202122232425262728293031323334353637png( file= &quot;Rplot%03d.png&quot;, width= 480, height= 480, units= &quot;px&quot;, # 图片分辨率 pointsize= 12, # 文字大小 bg= &quot;white&quot;, res= NA, family= &quot;&quot;, restoreConsole= TRUE, type= c(&quot;windows&quot;, &quot;cairo&quot;), antialias) # `par`语句生效必须放在`png`、`dev.off`中间 # 这个语句会强制覆盖与`par`语句重合的部分参数，即使这个 # 函数后调用pdf(filename)win.metafile(filename)jpeg(filename)bmp(filename)tiff(filename)xfig(filename)postscript(filename) # 开启目标图形设备dev.off() # 关闭目标图形设备 # 绘图语句至于其中，包括`par`dev.new() # 打开新的图形窗口，防止多次绘图覆盖dev.next()dev.prev()dev.set() # 选择将图形发送到不同窗口 parpar函数设置对整个工作空间图像设置均有效 12345678opar &lt;- par() # 无参调用，生成含有当前图形参数设置的列表opar &lt;- par(no.readonly= TRUE) # 生成一个可以修改的当前图形参数列表par(opar) # 恢复为`opar`中的参数设置par(attr_name) # 获取某个属性设置值 符号、线条12345678910par( pch= int, # 绘制点时使用的符号 cex= num, # 符号大小，相对于默认大小缩放倍数 lty= int, # 线条类型 lwd= num, # 线条宽度，相对于默认线条宽度的倍数) 颜色12345678910111213141516par( col= str/c(str), # 绘图颜色，循环使用 col.axis= str/c(str), # 坐标轴刻度文字颜色 col.lab= str/c(str), # 坐标轴标签颜色 col.main= str/c(str), # 标题颜色 col.sub= str/c(str) # 副标题颜色 fg= str/c(str), # 前景色 bg= str/c(str), # 背景色) 文本属性123456789101112par( cex= num, # 文本大小，相对默认 cex.axis= num, # 坐标轴刻度文字的缩放倍数 cex.lab= num, # 坐标轴标签缩放倍数 cex.main= num, # 标题缩放倍数 cex.sub= num, # 副标题缩放倍数) 字体、字号、字样1234567891011121314par( font= int, # 绘图使用字体样式 # 1：常规、2：粗体、3：斜体、4：粗斜体 font.axis= int, # 坐标轴刻度字体样式 font.lab= int, font.main= int, font.sub= int, ps= num, # 字体磅值 # 文本最终大小为`cex*ps` family= &quot;serif&quot;/&quot;sans&quot;/&quot;mono&quot;/str,) 图形、边界尺寸123456789101112par( pin= c(width, height), # 图片尺寸，单位英寸 mai= c(bot, left, top, right), # 边界大小，单位英寸 mar= c(bot, left, top, right), # 边界大小，单位英分（1/12英寸） # 默认值`c(5, 4, 4, 2)+ 0.1` mgp= c(axis_labels, tick_title, tick), # 坐标轴标签、刻度标签、刻度线位置 # 图形边缘为0，单位为行) 文本、自定坐标、图例titletitle函数可以为图形添加标题、坐标轴标签 123456789101112title( main= str, sub= str, xlab= str, ylab= str, col.main= str, # 也可以指定文本大小、字体、旋转角度、颜色 col.sub= str, col.lab= str, cex.lab= str) axis创建自定义坐标轴 123456789101112131415161718192021222324axis( side= int, # 坐标轴位置 # 1-4：下、左、上、右 at= c(int), # 需要绘制刻度线的位置 labels= c(str), # 刻度线对应labels # 默认为`at`中值 pos= num, # 坐标轴线绘制位置坐标，即与另一坐标轴交点 lty= num, # 线条类型 col= str, # 线条、刻度颜色 las= 0/2, # 标签平行、垂直坐标轴 tck= num, # 刻度线长度，相对于绘图区域大小分数表示 # 负值表示在图形外侧 # `0`表示禁用刻度线 # `1`表示绘制网格线 # 默认`-0.01`) minor.tick次要刻度线 12345678library(Hmisc)minor.tick( nx= int, # x轴次要刻度**区间**数 ny= int, tick.ratio= num # 次要刻度线相较主要刻度线比例) abline添加参考线 1234567abline( h= c(int), # 水平参考线位置（多根） v= c(int), lty= int, col= str,) legend添加图例 123456789101112131415161718192021222324legend( location= c(x, y)/ # 指定`x, y`坐标 &quot;bottom&quot;/&quot;bottomleft&quot;/&quot;left&quot;/&quot;topleft&quot;/ &quot;top&quot;/&quot;topright&quot;/&quot;right&quot;/&quot;bottoright&quot;/&quot;center&quot;/ # 使用关键字指定图例位置 locator(1), # 鼠标交互式指定 inset= num, # `location`使用关键字指定位置，设置图例向图形内侧移动 # 移动`num`绘图区域比例 title= str, # 图例标题字符串 legend= c(str), # 图例labels字符串向量 col= c(col_str), pch= c(pch_int), # 若图例标识符号不同的点 lwd= c(lwd_int), lty= c(lty_int), # 若图例标识宽度、样式不同的线 fill= c(col_str), # 若图例标识颜色填充的盒型) mtext、text mtext：向图形四个边界之一添加文本 text：向绘图区域内部添加文本 123456789101112131415161718192021222324252627282930text( location, # 同`legend` &quot;text to place&quot;, pos= int, # 文本相对于`location`方向 # 1-4：下、左、上、右 offset= num, # 文本相对`location`偏移量 cex= num, col= c(col_str), font= num,)mtext( &quot;text to place&quot;, side= int, # 放置文本的边 # 1-4：下、左、上、右 line= num, # 向内、外移动文本 # 越大文本越向外移动 adj= int, # 1：文本坐下对齐 # 2：文本右上对齐 cex= num, col= c(col_str), font= num,) 图形组合par1234567891011121314par( mfrow= c(nrows, ncols)) # 设置按行填充的图形矩阵par( mfcol= c(nrows, ncols)) # 设置按列填充的图形矩阵 # 然后按照的绘图顺序依次填充矩阵par( fig= c(x1, x2, y1, y2)) # 接下来图形在`fig`指定范围内绘制 layout12345678910layout( mat= matrix(int), # `mat`中元素值`n`表示第n个绘制的图形 # 其在矩阵中所处的位置即其填充的位置 widths= c(num), # 各列宽度值向量 # 相对图形比例可以直接数值表示 # 绝对数值可以通过函数`lcm`指定 heights= c(num), # 各行高度值向量 R原始图表条形图12345678barplot( H, xlab, ylab, main, names.arg, col) 一般条形图123456789101112131415161718192021222324H &lt;- c(7, 12, 28, 3, 41)M &lt;- c(&quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;)png(file = &quot;barchart.png&quot;) # 设置图表文件名barplot( H, # 各组数据大小 names.arg = M, # 各组labels xlab = &quot;Month&quot;, # x轴名 ylab = &quot;Revenue&quot;, # y轴名 col = &quot;blue&quot;, # 条形填充颜色 main = &quot;Revenue Chart&quot;, # 标题 border = &quot;red&quot; # 条形边框颜色) # 绘制图表dev.off() # 保存图表 组合、堆积条形图12345678910111213141516171819202122232425colors &lt;- c(&quot;green&quot;, &quot;orange&quot;, &quot;brown&quot;)months &lt;- c(&quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;)regions &lt;- c(&quot;East&quot;, &quot;West&quot;, &quot;North&quot;)values &lt;- matrix( c(2,9,3,11,9,4,8,7,3,12,5,2,8,10,11), nrow = 3, ncol = 5, byrow = TRUE)png(file = &quot;barchart_stacked.png&quot;)barplot( values, main = &quot;total revenue&quot;, names.arg = months, xlab = &quot;month&quot;, ylab = &quot;revenue&quot;, col = colors)legend( &quot;topleft&quot;, regions, cex = 1.3, fill = colors)dev.off() 饼图12345678pie( x, labels, radius, main, col, clockwise) 一般饼图12345678910111213141516171819202122x &lt;- c(21, 62, 10, 53)labels &lt;- c(&quot;London&quot;, &quot;New York&quot;, &quot;Singapore&quot;, &quot;Mumbai&quot;)piepercents &lt;- round(100 * x / sum(x), 1) # `round`取小数位数png(file = &quot;city.png&quot;)pie( x, labels = piepercents, main = &quot;city pie chart&quot;, col = rainbow(length(x)))legend( &quot;topright&quot;, labels, # 饼图注解设为百分比，所以这里设置各组别labels cex = 0.8, fill = rainbow(length(x)))dev.off() 3D饼图1234567891011121314library(plotrix)x &lt;- c(21, 62, 10, 53)labels &lt;- c(&quot;London&quot;, &quot;New York&quot;, &quot;Singapore&quot;, &quot;Mumbai&quot;)png(file = &quot;3d_pie_charts.jpg&quot;)pie3D( x, labels, explode = 0.1 main = &quot;pie charts of countries&quot;)dev.off() 直方图1234567891011hist( v, main, xlab, xlim, ylim, breaks, # 每个直方的宽度 col, border) 一般直方图123456789101112131415v &lt;- c(9,13,21,8,36,22,12,41,31,33,19)png(file = &quot;histogram.png&quot;)hist( v, xlab = &quot;weight&quot;, col = &quot;green&quot;, border = &quot;blue&quot; xlim = c(0, 40), ylim = c(0, 5), breaks = 5)dev.off()","link":"/RLang/r_visualization.html"},{"title":"R语法","text":"生存配置注释 R语言的注释和其他脚本语言类似，使用#注释行，但是R没有 多行注释语法 可以使用if(FALSE)语句进行“注释”123if(FALSE) { &quot;comments&quot;} 工作路径1234getwd() # 返回当前工作路径，默认`~/Documents`setwd(/path/to/dir) # 设置当前工作路径 变量 R中有效的变量名称由字母、数字、点、下划线组成，变量名以 字母、后不跟数字的点开头 R中变量为动态类型，可多次更改变量数据类型 变量无法被声明，在首次赋值时生成 赋值12345678910var.1 = c(0, 1, 2, 3) # 不常用var.2 &lt;- c(&quot;learn&quot;, &quot;R&quot;) # 常用方法var .3 &lt;&lt;- c(3, 1, TRUE, 2+3i) # 特殊赋值符，可以扩展变作用域为“整个”工作空间 c(TRUE, 1) -&gt; var.4 # 右赋值符c(TRUE, 2+3i) -&gt;&gt; var.5 搜索ls函数可以搜索当前工作空间中所有可用变量 123456ls( pattern = &quot;var_pattern&quot;, all.name = FALSE/TRUE) # `pattern`：使用模式匹配变量名 # `all.name`：开头变量默认隐藏，可通过设置参数展示 删除rm函数可以删除变量 1234rm(var.3)rm(list = ls()) # 删除所有变量 数据导入edit1234567891011mydata &lt;- data.frame( age = numeric(0), gender = character(0), weight = numeric(0)) # `numeric(0)`类似的赋值语句创建指定模式但不含数据变量mydata &lt;- edit(mydata) # `edit`会调用允许手动输入数据的文本编辑其 # `edit`在副本上操作，需要重新给变量fix(mydata) # `mydata &lt;- edit(mydata)`等价写法，直接在原对象上操作 read.table12345678910111213DF &lt;- read.table( file(/path/to/file), header = TRUE/FALSE, sep = &quot; \\t\\n\\r&quot;/&quot;,&quot;, row.names = c(), col.names = c(&quot;V1&quot;, &quot;V2&quot;, ...)/c(str), na.strings = NULL/c(str)), colClasses = NULL/c(&quot;numeric&quot;, &quot;character&quot;, &quot;NULL&quot;), quote = &quot;'&quot;&quot;/str, skip = 0/int, stringAsFactors = TRUE/FALSE, test = str) 说明：从带分隔符的文本文件中导入数据 参数 header：第一行是否包含变量名 sep：分隔符，默认数个空格、tab、回车、换行 row.names：指定行标记符 col.names：指定DF对象列名 na.strings：表示缺失值的字符串向量，其包含字符串 读取时转为NA colClasses：设置DF对象每列数据模式 “NULL”表示跳过 长度小于列数时开始循环 读取大型文本可以提高速度 quote：字符串划定界限，默认&quot;' StringAsFactor：标记字符向量是否转换为factor colClasses优先级更高 设为FALSE可以提升读取速度 text：读取、处理的字符串，而不是file 常用函数123456789print() # 浏览对象取值str() # 查看对象结构ls() # 管理对象remove()rm() # 删除指定对象 数据模式（类型） 数据模式是指R存储数据的方式 即从存储角度对R数据对象划分 class函数就是返回数据模式（类型） Logical只需要1byte存储 TRUE/T FALSE/F Integer占用2-4byte 2L、0L Numeric可进一步分 float占用4byte double占用8byte R中数值型数据默认为double 12.3、4 Complex comlplex：3+2i CharacterR中'、&quot;对中的任何值视为字符串 '、&quot;必须在开头、结尾成对存在 '、&quot;结尾的字符串中，只能插入对方 paste连接多个字符串 1234567Chars = paste( ..., # 要组合的任意数量变量 sep = &quot; &quot;, # 分隔符 collapse = NULL) # 消除两个字符串之间空格 format将数字、字符串格式为特定样式 12345678910111213Chars = format( x([num, chars], # 向量 digits(int), # 显示的总位数 nsmall(int), # 小数点右边最小位数 scientific=FALSE/TRUE, # `TRUE`则显示科学计数法 width(int), # 在开始处填充空白来显示的最小宽度 justify = c(&quot;left&quot;, &quot;right&quot;, &quot;centre&quot;, &quot;none&quot;)) # 字符串显示位置 nchar计算包括空格在内的字符串长度 123int = nchar( x(chars)) toupper、tolower改变字符串大小写 123456chars = toupper( x(chars))chars = tolower( x(chars)) substring获取字符串子串 123456chars = substring( x(chars), first(int), last(int)) # 包括头尾 R对象是指可以赋值给变量的任何事物，包括常量、数据结构、 函数 对象都拥有某种模式，描述对象如何存储 对象拥有某个“类”，向print这样的泛型函数表明如何处理 此对象 Raw raw：v &lt;- charToRaw(&quot;Hello&quot;)（byte类型） 结构角度划分R对象Vector用于存储数值型、字符型、逻辑型数据的一维数组 单个向量中的出数据必须拥有相同的类型、模式（数值型、字符 型、逻辑型） R中没有标量，标量以单元素向量形式出现 12345678910apple &lt;- c(&quot;red&quot;, &quot;green&quot;, &quot;yellow&quot;) apple[1] # 访问单个元素，从1开始apple[1: 3] # 切片，闭区间apple[7] = &quot;seven&quot; # 将值赋给某个向量、矩阵、数组或列表中一个不存在的元素时 # R将自动扩展其以容纳新值，中间部分设为`NA`is.vector(apple) 创建向量123456789101112rep(start: end, each=repeat_time) # 元素重复rep(start: end, times=repeat_time) # 向量重复seq(from=start, to=end, by=step) # 指定步长seq(from=start, to=end, length=len) # 指定个数vector(length=len) # 元素为`FALSE` 访问向量元素1234567a[1]a[1:2]a[c(1,3)]a[c(T, F, T)]a[-c(1:2)] # 负号不能用于逻辑向量 Matrix二维数组：组织具有相同存储类型的一组变量 每个元素都拥有相同的模式（数值型、字符型、逻辑型） 创建矩阵123456789101112131415mtx &lt;- matrix( vector, nrow(int) ncol(int), byrow = FALSE/TRUE, dimnames = list( c(row_names), c(col_names) ))is.matrix()cbind() # 将多个已有向量（列）合并为矩阵 矩阵信息123456dim(mtx) # 显示矩阵行、列colnames(mtx)colnames(mtx[, col_start: col_end])rownames(mtx)ronnames(mtx[row_start: row_end, ]) 访问矩阵元素12 Array类似于矩阵，但是维度可以大于2 其中元素也只能拥有一种模式 12345arr &lt;- array( vector, dimensions(c(int)), dimnames = c(dim_names)) Data.Frame数据帧是表、二维数组类似结构 不同的列可以包含不同的模式 每列包含一个变量的值，每行包含来自每列的一组值 数据帧的数据可是数字、因子、字符串类型 1234567891011121314151617df &lt;- data.frame( col1(c()), col2(c()), ..., row.names = coln) # `row.names`：指定实例标识符，即indexemp.data &lt;- data.frame( emp_id = c(1:5), emp_name = c(&quot;Rick&quot;,&quot;Dan&quot;,&quot;Michelle&quot;,&quot;Ryan&quot;,&quot;Gary&quot;), salary = c(623.3,515.2,611.0,729.0,843.25), start_date = as.Date(c(&quot;2017-01-01&quot;, &quot;2017-09-23&quot;, &quot;2017-11-15&quot;, &quot;2017-05-11&quot;, &quot;2018-03-27&quot;)), stringsAsFactors = FALSE) # 创建DF 统计性质12345str(emp.data) # 可以获得DF结构summary(emp.data) # 获得DF的统计摘要、性质 筛、删、减123456789101112131415161718192021222324emp.data.cols &lt;- data.frame( emp.data$emp_name, emp.data$salary) # 列名称获取DF中特定列emp.data.rows &lt;- emp.data([1:2, ] # 行切片获取特定行emp.data.rows_2 &lt;- emp.data[c(3, 5), c(2, 4)] # 行、列list获取特定行、列emp.data$dept &lt;- c(&quot;IT&quot;, &quot;Operations&quot;, &quot;IT&quot;, &quot;HR&quot;, &quot;Finance&quot;) # 新列名添加新列emp.newdata &lt;- data.frame( emp_id = c(6: 8), emp_name = c(&quot;Rasmi&quot;,&quot;Pranab&quot;,&quot;Tusar&quot;), salary = c(578.0,722.5,632.8), start_date = as.Date(c(&quot;2013-05-21&quot;,&quot;2013-07-30&quot;,&quot;2014-06-17&quot;)), dept = c(&quot;IT&quot;,&quot;Operations&quot;,&quot;Fianance&quot;), stringsAsFactors = FALSE)emp.finaldata &lt;- rbind(emp.data, emp.newdata) # `rbind`将新DF同原DFconcat，达到添加新行 拼、接rbind结合两个DF对象行 1234567891011121314151617181920city &lt;- c(&quot;Tampa&quot;, &quot;Seattle&quot;, &quot;Hartford&quot;, &quot;Denver&quot;)state &lt;- c(&quot;FL&quot;, &quot;WA&quot;, &quot;CT&quot;, &quot;CO&quot;)zipcode &lt;- c(33602, 98104, 06161, 80294)address &lt;- cbind(city, state, zipcode) # `cbind`连接多个向量创建DFnew.address &lt;- data.frame( city = c(&quot;Lowry&quot;, &quot;Charlotte&quot;), state = c(&quot;CO&quot;, &quot;FL&quot;), zipcode = C(&quot;80230&quot;, &quot;33949&quot;), stringAsFactors = FALSE) # 使用`data.fram`创建DFall.address &lt;- rbind( address, new.address) # `rbind`结合两个DF的行 merge根据两DF列进行merge 12345678910lirary(MASS) # 加载数据集merged.Pima &lt;- merge( x = Pima.te, y = Pima.tr, by.x = c(&quot;bp&quot;, &quot;bmi&quot;), by.y = c(&quot;bp&quot;, &quot;bmi&quot;)) # 根据DF某（些）列merge melt、cast12345678910111213library(MASS)library(reshape2)melton.ships &lt;- melt( ships, id = c(&quot;type&quot;, &quot;year&quot;)) # `melt`将剩余列转换为`variable`、`value`标识recasted.ship &lt;- cast( molten.ship, type+year~variable,sum) # 和`melt`相反，以某些列为“轴”合并 绑定attach、detach12345678910111213attach(emp.data) # `attach`可以将数据框加入R的搜索路径 # 之后R遇到变量名之后，将检查搜索路径的数据框 # 注意，如果之前环境中已经有df对象列同名变量，那么原始 # 对象优先，不会被覆盖 emp.data.cols.copy &lt;- data.frame( emp_name, salary ) # 否则需要之前一样使用`$`detach(emp.data) # 将数据框从搜索路径移除 with12345678910with(emp.data, { emp.data.cols.copy &lt;&lt;- data.frame( emp_name, salary )}) # `{}`中的语句都针对`emp.data`执行，如果只有一条语句， # 花括号可以省略 # `with`语句内`&lt;-`赋值仅在其作用于内生效，需要使用`&lt;&lt;-` # 特殊赋值符保存至“全局”变量中 Factor分类变量、有序变量在R中称为因子，其决定了数据的分析方式、 如何进行视觉呈现 1234567891011121314fctr &lt;- factor( vector(c(factors)), ordered = FALSE/TRUE, levels = c(ordered_unique_factors), labels = c(factor_labels) # `ordered`：默认不是有序变量 # `levels`：指定factors的“排序”，确定映射的整数值， # 对于分类变量也可以设置 # 没有在`levels`中显式指定的factor视为缺失 # `labels`：设置各factor labels，输出则按照labels输出 # 注意`labels`顺序必须和`levels`一致 # 对数值型factor尤其有用) factor以整形向量的形式存储类别值 整数取值范围为1~k，k为定性（分类、有序）变量中 唯一值个数 同时一个由字符串（原始值）组成的内部向量将映射到这些整数 分类变量：字符串映射的整数值由字母序决定 有序变量：按字母序映射可能与逻辑顺序不一致，可以使用 参数levels指定顺序 List一些对象、成分的有序集合 允许整合若干（可能无关）的对象到单个对象下 很多R函数结果运行结果以列表形式返回，由调用者决定使用 其中何种成分 12345678910111213l &lt;- list( [name1 =]object1, [name2 =]object2, ...) # 可以给列表中的对象命名 # 命名成分`l$name1`也可以正常运行list1 &lt;- list(c(2, 5, 3), 21, 3, sin)print(list1)print(class(list1)) 运算符算术运算符算术操作符作用与向量的每个元素 12345678910111213v &lt;- c(2, 5.5, 6)t &lt;- c(8, 3, 4)print(v + t) # 算术操作符作用与向量的每个元素print(v - t)print(v * t)print(v/t)print(v %% t) # 向量求余print(v %/% t) # 求商print(v ^ t) # 指数运算 关系运算符比较两个向量的相应元素，返回布尔值向量 123456789v &lt;- c(2, 5.5, 6, 9)t &lt;- c(8, 2.5, 14, 9)print (v &gt; t) # 比较两个向量的相应元素，返回布尔值向量print (v &lt; t)print (v == t)print (v != t)print (v &lt;= t)print (v &gt;= t) 逻辑运算符只适用于逻辑、数字、复杂类型向量，所有大于1的数字被认为是 逻辑值TRUE 12345678910v &lt;- c(3, 1, TRUE, 2+3i)t &lt;- c(4, 1, False, 2+3i)print(v &amp; t) # 比较两个向量相应元素，返回布尔值向量print(v | t)print(!v)print(v &amp;&amp; t) # 只考虑向量的第一个元素，输出单个bool值元素向量print(v || t) 其他运算符123456789101112131415t &lt;- 2: 8 # 为向量按顺序创建一系列数字v1 &lt;- 8v2 &lt;- 12print (v1 %in% t)print (v2 %in% t) # 标识元素是否属于向量M = matrix(c(2, 6, 5, 1, 10, 4), nrow = 2, ncol = 3, byrow = TRUE)t = M %*% t(M) # 矩阵相乘 R语句条件123ifelseswitch 循环12345repeatwhileforbreaknext 函数12345func_name &lt;- function( arg_1, arg_2,...){} R内置函数123print(seq(32, 44))print(mean(25: 82))print(sum(41: 68)) 自定义参数1234567891011121314151617181920212223242526272829new.function_1 &lt;- fucntion(){ # 无参数函数 for(i in 1: 5){ print(i ^ 2) }}new.function_1()new.function_2 &lt;- function(a, b, c){ # 有参数函数 result &lt;- a * b + c print(result)}new.function_2(5, 3, 11) # 按参数顺序调用函数new.function_2( a = 11, b = 5, c = 3) # 按参数名称调用new.function_3 &lt;- function(a=3, b=6){ # 含有默认参数函数 result &lt;- a * b print(result)}new.function_3 # 无参数（使用默认参数）new.function_3(9, 5) 函数功能延迟计算1234567new.function &lt;- function(a, b){ print(a ^ 2) print(a) print(b)}new.function(6) # 调用函数能部分执行成功，直到`print(b)` 包R语言包是R函数、编译代码、样本数据的集合 存储在R环境中名为library的目录下 默认情况下，只有R安装时提供默认包可用，已安装的其他包 必须显式加载 12345678.libPaths() # 获取包含R包的库位置library() # 获取已安装所有软件包列表search() # 获取当前R环境中加载的所有包 安装包 直接从CRAN安装 1install.package(&quot;pkg_name&quot;) 手动安装包：从https://cran.r-project.org/web/packages/available_packages_by_name.html 中下载包，将zip文件保存 1install.package(/path/to/pkg.zip, repos=NULL, type=&quot;source&quot;) 加载包123library(&quot;pkg_name&quot;, lib.loc=/path/to/library) # `lib.loc`参数默认应该就是`.libPaths`，一般不用设置","link":"/RLang/r_grammer.html"},{"title":"特征工程","text":"综述 特征工程：对原始数据进行工程处理，将其提炼为特征，作为输入供算法、 模型使用 本质上：表示、展示数据的过程 目的：去除原始数据中的杂质、冗余，设计更高效的特征以刻画求解的 问题、预测模型之间的关系 把原始数据转换为可以很好描述数据特征 建立在其上的模型性能接近最优 方式：利用数据领域相关知识、人为设计输入变量 数据、特征决定了机器学习的上限，模型、算法只是逼近上限，特征越好 模型选择灵活性越高：较好特征在简单模型上也能有较好 效果，允许选择简单模型 模型构建越简单：较好特征即使在超参不是最优时效果也 不错，不需要花时间寻找最优参数 模型性能越好 排除噪声特征 避免过拟合 模型训练、预测更快 特征工程要：小步快跑、多次迭代 便于及时发现问题、定位问题，如：数据穿越","link":"/ML-Technique/Feature-Engineering/feature_engineering.html"},{"title":"特征选择","text":"Feature Selection特征选择：从特征集合中选择最具统计意义的特征子集 特征分类 relevant feature：相关特征，对当前学习任务有用的属性、特征 特征选择最重要的是确保不丢失重要特征 irrelevant feature：无关特征，对当前学习任务无用的属性、特征 redundant feature：冗余特征，包含的信息可以由其他特征中推演出来 冗余特征通常不起作用，剔除可以减轻模型训练负担 若冗余特征恰好对应完成学习任务所需要的中间概念，则是有益的，可以降低学习任务的难度 特征选择会降低模型预测能力，因为被剔除特征中可能包含有效信息 保留尽可能多特征，模型性能会提升，模型更复杂、计算复杂度同样提升 剔除尽可能多特征，模型性能会下降，模型更简单、降低计算复杂度 特征选择原因 维数灾难问题：仅需要选择一部分特征构建模型，可以减轻 维数灾难问题，从此意义上特征选择和降维技术有相似动机 剔除无关特征可以降低学习任务难度，简化模型、降低计算复杂度 特征选择方法可以分解为 特征子集搜索 特征子集评价：能判断划分之间差异的机制都能作为特征子集的准则 特征选择过程 generation procedure：产生过程，搜索特征子集 evaluation function：评价函数，评价特征子集优劣 stopping criterion：停止准则，与评价函数相关的阈值，评价函数达到与阈值后可以停止搜索 validation procedure：验证过程，在验证数据集上验证选择特征子集的有效性 特征子集搜索 遍历：从初始特征集合选择包含所有重要信息的特征子集 适合没有先验（问题相关领域）知识的情况 特征数量稍多会出现组合爆炸 迭代：产生候选子集、评价优劣，基于评价结果产生下个候选子集 不断迭代，直至无法找到更好的后续子集 需要评价得子集数量较少 可能无法找到最优子集 迭代搜索 给定特征 $A={A_1, A_2, \\cdots, A_d}$，将每个特征视为候选子集（每个子集只有一个元素），对 $d$ 个候选子集进行评价 在上轮选定子集中加入特征，选择包含两个特征的最优候选子集 假定在 $k+1$ 轮时，最优特征子集不如上轮最优的特征子集，则停止生成候选子集，将上轮选定特征子集作为特征选择结果 Forward Feature Elimination：前向特征选择，逐渐增加相关特征 Backward Feature Elimination：后向特征选择，从完整特征集合开始，每次尝试去掉无关特征，逐渐剔除特征 Bidirectional Feature Elimination：双向特征选择，结合前向、后向搜索 每轮逐渐增加选定的相关特征，特征在后续迭代中确定不会被去除，同时减少无关特征 特征子集评价特征子集评价：能判断划分之间差异的机制都能作为特征子集的选择准则 方差 方差越大，特征对预测值区分能力越强 相关系数 Pearson 积矩相关系数 Kendell 秩相关系数 Spearman 秩相关系数 卡方统计量 距离指标 划分增益 Gini 指数 IG 信息增益/互信息 信息增益比 排序指标 AUC 特征问题定位 模型出现过拟合问题时，可能是特征工程步骤中出现信息泄露（数据穿越、标签入特征），一般通过单变量特征评价指标定位有问题的特征 数据泄露涉及的特征的定位（经验） 线性模型 单变量 AUC 值：超过 0.8 则高度可疑 非线性模型（树） 基于信息增益的特征重要性 Filter过滤式：对数据集进行的特征选择过程与后续学习器无关，即设计统计量过滤特征，不考虑后续学习器问题 通过分析特征子集内部特点衡量特征优劣，描述自变量、目标变量的关联 特点 时间效率高 对过拟合问题较稳健 倾向于选择单个、冗余特征，没有考虑特征之间相关性 单特征过滤单特征过滤：直接选择合适特征子集评价标准处理各特征，选择满足要求特征 Relief: Relavant FeaturesRelief 方法：设置相关统计量度量特征重要性 特征子集对应统计量中每个分量对应一个初始特征，特征子集重要性由子集中每个特征对应的相关统计量分量之和决定 特征选择方法 指定阈值 $k$：选择比 $k$ 大的相关统计量分量对应特征 指定特征个数 $m$：选择相关统计量分量最大的 $m$ 个特征 只适合二分类问题，扩展变体 Relief-F 可以处理多分类问题 Wrapper包裹式：把最终要使用的学习器性能作为特征子集评价标准，为给定学习器选择最有利其性能、特化的特征子集 优点 直接针对特定学习器进行优化 考虑了特征之间的关联性，通常训练效果较过滤式好 缺点 特征选择过程中需要多次训练学习器，计算效率较低 观测数据较少时容易过拟合 Las Vegas WrapperLVW：在 Las Vegas Method 框架下使用随机策略进行子集搜索，以最终分类器误差作为特征子集评价标准 包含停止条件控制参数T，避免每次子集评价训练特征子集开销过大 若初始特征数量很多、T设置较大、每轮训练时间较长，算法执行很长时间都不会停止 LVM 可能无法得到解（拉斯维加斯算法本身性质） 递归特征消除法递归特征消除法：使用基模型进行多轮训练，每轮训练消除若干权值系数的特征，再基于特征集进行下一轮训练 Stepwise变量选择 前向变量选择 后向变量选择 前向-后向变量选择 最优子集选择 Embedded嵌入式：将特征选择、学习器训练过程融合，在同一优化过程中同时完成，即学习器训练过程中自动进行特征选择 优点：兼具筛选器、封装器的优点 缺点：需要明确好的选择 正则化约束$L_1$、$L_2$ 范数：主要用于线性回归、逻辑回归、SVM 等算法 Ridge：$L_2$ 范数 Lasso：$L_1$ 范数 除降低过拟合风险，还容易获得稀疏解 参数 $\\lambda$ 越大，稀疏性越大，被选择特征越少 SVM、逻辑回归 超参参数范数权重越大，稀疏性越大，被选择特征越少 决策树决策树思想：决策树自上而下选择分裂特征就是特征选择 所有树结点划分属性根据先后顺序组成的集合就是选择出来的特征子集 参见ml_models/unlinear_models/decision_tree 神经网络神经网络：训练时同时处理贡献度问题，不重要特征权重被剔除","link":"/ML-Technique/Feature-Engineering/feature_selection.html"},{"title":"抽样方法","text":"数据抽样 抽样作用 提高速度、效率，将精力放在建立模型、选择模型上 帮助分析特殊性问题：有些问题涉及到破坏性试验，抽取产品的一部分做耐用性实验经济有效 降低成本：合理抽样可以保证在大部分信息不丢失情况下，降低数据采集、社会调查成本 从效率、成本角度看，适当、合理抽样有必要 数据越多信息越丰富、数据量尽量多为好 抽样可以降低求解的时空代价，但是可能会丢失部分信息，可能会使分析结果产生偏差 在分析阶段，若抽样误差能够接受，完全可以抽样 样本应能充分代表总体 一般样本容量越大，和总体的相似程度越高，样本质量越高 但大样本不等于总体：理论上再大的局部抽样也不如随机抽样有代表性 样本评价 样本容量、样本质量是衡量抽样样本的两个最重要因素 样本容量：抽样过程中抽取的样本数 样本质量：衡量抽样样本的代表性 样本质量样本质量：抽样样本与整体的相似性 \\begin{align*} J(S, D) & = \\frac {1} {D} \\sum_{k=1}^{r} J_{k}(S, D) \\\\ J_{k}(S, D) & = \\sum_{j=1}^{N_k}(P_{Sj} - P_{Dj}) log \\frac {P_{Sj}} {P_{Dj}} \\\\ Q(s) & = exp(-J) \\end{align*} $D$：数据集，包含 $r$ 个属性 $S$：抽样样本集 $J_k=J(S, D)$：Kullblack-Laible 散度，数据集 $S$、$D$ 在属性 $k$ 上偏差程度，越小偏差越小 $Q(S) \\in [0, 1]$：抽样集 $S$ 在数据集 $D$ 中的质量，越大样本集质量越高 若整体 $D$ 分布稀疏，容易得到 $S$ 在某些数据点观测值数为 0，得到 $I(S, D) \\rightarrow infty$ 可以把该点和附近的点频率进行合并，同时调整总体频率分布 过度合并会导致无法有效衡量数据集局部差异性 对于连续型变量 可以把变量进行适当分组：粗糙，不利于刻画数据集直接的局部差异 计算数据集各个取值点的非参估计，如核估计、最近邻估计等，再在公式中用各自的非参估计代替相应频率，计算样本质量 数据包含多个指标时 可以用多个指标的平均样本质量衡量整体样本质量 也可以根据指标重要程度，设置不同的权重 样本容量 样本容量是评价样本的另一个重要维度 样本量大、质量好、准确性高，但计算效率低 样本质量差、准确性低、计算效率高 样本质量提高不是线性的，高位样本容量上，边际效用往往较低 同一样本容量的不同样本的样本质量也会有差异，即样本质量不是样本容量的单调函数，包含随机扰动 Statistical Optimal Sample SizeSOSS：统计最优样本数 输入：数据集 $D$，包含 $N$ 个实例 根据某种抽样方法，随机产生 $R$ 个样本容量分别为 $n_i, n_i \\in [1, N]$ 的样本 $S$ $n_i$ 取值较小处应密度比较大，因为随着 $n_i$ 增加，样本质量趋近 1，不需要太多样本 可以考虑使用指数序列产生在较大值处稀疏的序列作为 $n_i$ 序列的取值 计算每个样本 $S$ 在数据集 $D$ 中的样本质量 $Q$ 并计算各个样本容量对应的样本质量均值 $\\bar {Q_{n}}$ 绘制曲线 $(n, \\bar {Q_{n}})$ 根据给定的样本质量要求，在样本容量对应样本质量的曲线上确定近似的最优样本容量 测试集、训练集 测试集、训练集划分逻辑前提 在样本量足够的情况下，减少部分样本量不会影响模型精度 模型评价需要使用未参与建模数据验证，否则可能夸大模型效果 测试集、训练集划分作用 测试集直接参与建模，其包含信息体现在模型中 训练集仅仅用于评价模型效果，其包含信息未被利用， 因此，若无评价、对比模型需求，或有其他无需划分测试集即可评价模型，则划分测试集无意义 测试集、训练集划分Hold Out旁置法：将样本集随机划分为训练集、测试集，只利用训练集训练 模型 适合样本量较大的场合 减少部分训练数据对模型精度影响小 否则大量样本未参与建模，影响模型精度 常用划分比例 8:2 7:3 旁置法建立模型可直接作为最终输出模型 旁置法一般只建立一个模型 且使用旁置法场合，模型应该和全量数据训练模型效果差别不大 N-fold Cross ValidationN 折交叉验证：将数据分成N份，每次将其中一份作为测试样本集， 其余N-1份作为训练样本集 N折交叉验证可以视为旁置法、留一法的折中 克服了旁置法中测试样本选取随机性的问题：每个样本都 能作为测试样本 解决了留一法计算成本高的问题：重复次数少 典型的“袋外验证” 袋内数据（训练样本）、袋外数据（测试样本）分开 N折交叉验证会训练、得到N个模型，不能直接输出 最终应该输出全量数据训练的模型 N折建立N次模型仅是为了合理的评价模型效果，以 N 个模型的评价指标（均值）作为全量模型的评价 Leave-One-Out Cross Validation留一法：每次选择一个样本作为测试样本集，剩余 n-1 个观测值作为训练样本集，重复 n 次计算模型误差 可以看作是 N 折交叉验证的特例 数据泄露 特征泄露：训练过程中使用有包含有上线之后无法获取的数据 时序数据中数据穿越：使用未来数据训练模型，模型将学习不应获取的未来信息 记录泄露/训练数据泄露：切分数据集时训练集包含了测试集中部分数据 会导致评估指标失真 样本重抽样Bootstrap重抽样自举：有放回的重复抽样，以模拟多组独立样本 对样本量为 $n$ 的样本集 $S$ 做$k$次有放回的重复抽样 每轮次抽取 $n$ 个样本 抽取得到样本仍然放回样本集中 得到 $k$ 个样本容量仍然为 $n$ 的随机样本 $S_i，(i=1,2,…,k)$ 过采样 over-sampling：过采样，小类数据样本增加样本数量 synthetic minority over-sampling technique：过采样算法，构造不同于已有样本小类样本 基于距离度量选择小类别下相似样本 选择其中一个样本、随机选择一定数据量邻居样本 对选择样本某属性增加噪声，构造新数据 SMOTEBorderline-SMOTE欠采样 under-sampling：欠采样，大类数据样本减少样本数量","link":"/ML-Technique/Feature-Engineering/sampling.html"},{"title":"特征编码","text":"数值化：分类-&gt;数值Ordinal Encoding序号编码：使用一位序号编码类别 一般用于处理类别间具有大小关系的数据 编码后依然保留了大小关系 One-hot Encoding独热编码：采用N位状态位对N个可能取值进行编码 一般用于处理类别间不具有大小关系的特征 独热编码后特征表达能力变差，特征的预测能力被人为拆分为多份 通常只有部分维度是对分类、预测有帮助，需要借助特征选择降低维度 在经典统计中，为避免完全多重共线性，状态位/哑变量会比取值数量少 1 优点 能处理非数值属性 一定程度上扩充了特征 编码后向量时稀疏向量：可以使用向量的稀疏存储节省空间 能够处理缺失值：高维映射方法中增加维度表示缺失 缺点 k-NN 算法：高维空间两点间距离难以有效衡量 逻辑回归模型：参数数量随维度增加而增大，增加模型复杂度，容易出现过拟合 决策树模型 产生样本切分不平衡问题，切分增益非常小 每个特征只有少量样本是 1，大量样本是 0 较小的拆分样本集占总体比例太小，增益乘以所占比例之后几乎可以忽略 较大拆分样本集的几乎就是原始样本集，增益几乎为 0 影响决策树的学习 决策树依赖数据统计信息，独热编码将数据切分到零散小空间上，统计信息不准确、学习效果差 独热编码后特征表达能力边人为拆分，与其他特征竞争最优划分点失败，最终特征重要性会比实际值低 Binary Encoding二进制编码：先用序号编码给每个类别赋予类别 ID，然后将类别 ID 对应二进制编码作为结果 本质上利用二进制类别 ID 进行哈希映射，得到 0/1 特征向量 特征维度小于独热编码，更节省存储空间 Weight of Evidence EncodingWOE 编码：以分类变量各取值的 WOE 值作为编码值 \\begin{align*} WOE_i & = log(\\frac {\\%B_i} {\\%G_i}) \\\\ & = log(\\frac {\\#B_i / \\#B_T} {\\#G_i / \\#G_T}) \\end{align*} $\\%B_i, \\%G_i$：分类变量取第 $i$ 值时，预测变量为 B 类、G 类占所有 B 类、G 类比例 $#B_i, #B_T$：分类变量取第 $i$ 值时，预测变量为 B 类占所有 B 类样本比例 $#G_i, #G_T$：分类变量取第 $i$ 值时，预测变量为 G 类占所有 G 类样本比例 WOE 编码是有监督的编码方式，可以衡量分类变量各取值中 B 类占所有 B 类样本比例、G 类占所有 G 类样本比例的差异 B 类、G 类比例，与所有样本中 B 类、G 类比例的差异 WOE 编码值能体现分类变量取值的预测能力，变量各取值 WOE 值方差越大，变量预测能力越强 WOE 越大，表明该取值对应的取 B 类可能性越大 WOE 越小，表明该取值对应的取 G 类可能性越大 WOE 接近 0，表明该取值预测能力弱，对应取 B 类、G 类可能性相近 优势 相较于 one-hot 编码 特征数量不会增加，同时避免特征过于稀疏、维度灾难 避免特征筛选过程中，一部分特征取值被筛选，一部分被遗弃，造成特征不完整 将特征规范到同一尺度的数值变量，同时也便于分析特征间相关性 在 LR 模型中，WOE 编码线性化赋予模型良好的解释性 WOE 编码本身即可反应特征各取值贡献 可以用于给评分卡模型中各分箱评分 分类化/离散化：数值-&gt;分类 分类型变量本质上无法建模，因为取值从含义上无法进行数值计算 将数值型映射为分类型，往往只是中间步骤，最终会将分类型取值映射回数值型 若分箱数量为 2，也被成为是二元化/布尔化 离散化综述 模型使用离散特征、连续特征，是“海量离散特征+简单模型”、“少量连续特征+复杂模型”的权衡 海量离散特征+简单模型：难点在于特征工程，成功经验可以推广，可以多人并行研究 少量连续特征+复杂模型：难点在于模型调优，不需要复杂的特征工程 一般的，连续特征对预测结果影响不会突变，合理的离散化不应造成大量信息丢失 且若特征存在突变，模型将难以拟合（线性模型尤其） 反而更应该离散化为多个分类特征，方便引入非线性 事实上，根据Cover定理，离散化增加特征维度类似于投影至高维，更可能得到较优模型（也更容易过拟合） 极限角度，对所有特征、取值均离散化，则可以得到完全可分模型（除特征完全一样分类不同） 描述角度 supervised vs. unsupervised：是否使用分类信息指导离散化过程 无监督 如：等距、等频划分 无法较好的处理异常值、不均匀分布 有监督 利用分类信息寻找合适切分点、间隔 根据使用分类信息的方式有许多种 dynamic vs. static：离散化、分类是否同时进行 global vs. local：在特征空间的局部还是全局进行离散化 spliting vs. merging/top-down vs. bottom-up：自顶向下划分还是自底向上合并 direct vs. incremental：直接根据超参数确定分箱数量还是逐步改善直到中止准则 典型过程 sort：排序 evaluate：评估分割点 split or merge：划分、合并 stop：停止离散化 评价 Simplicity：可用切分点数量衡量简单性 Consistency：可以通过最小不一致数量衡量一致性 不一致：样本具有相同的特征取值，但分类不同 分箱最小不一致数量则为，箱内样本数量减最大类别数量 Accuracy：可通过分类器进行交叉验证的准确率衡量 优势 方便工业应用、实现 离散特征的增加、减少容易，方便模型迭代 特征离散化处理缺失值、异常值更方便，可直接将其映射为某取值 数值化后可指定取值类型，如：one-hot编码为为稀疏向量 內积速度快 存储方便 容易扩展 方便引入历史经验 可以自由调整离散化结果，结合机器学习和历史经验得到最终的离散化结果 模型更稳健 模型不再拟合特征具体值，而是拟合某个概念，能够对抗数据扰动，更稳健 对异常数据鲁棒性更好，降低模型过拟合风险 某些场合需要拟合参数值更少，降低模型复杂度 （引入）非线性提升模型表达能力 利用经验、其他信息将数值特征分段，相当于引入非线性，提升线性模型表达能力 方便引入交叉特征，提升模型表达能力 适合场景 离散化特征更适合 LR 等线性模型 如下离散化优势：方便引入非线性等 模型中所有特征都会被考虑，考虑细节、个体（包括 $L_1$ 范数也是被考虑后剔除） GBDT 等树、抽样模型则不适合 特征离散化后，由于抽样误差的存在，可能存在某些离散特征对样本预测能力非常强，非线性模型容易给这些特征更大权重，造成过拟合 如：刚好抽取的 1000 个样本中某离散特征取值为 1 者全为正样本 树模型每次使用一个特征划分节点，特征数量较多不利于模型训练 若单个离散化特征预测能力不强，由于树深度限制，只有少量特征被作为划分依据，模型可能不收敛、表达能力更差 若单个离散化特征预测能力强，连续特征也应该也有较好效果 无监督 无监督分箱仅仅考虑特征自身数据结构，没有考虑特征与目标之间的关系 等频/等距/经验分箱 分箱逻辑 等频分箱：排序后按数量等分 避免离散化后特征仍然为长尾分布、大量特征集中在少量组内 对数据区分能力弱 等距分箱：取值范围等分 经验分箱 分箱数量、边界超参需要人工指定 根据业务领域经验指定 根据模型指定：根据具体任务训练分箱之后的数据集，通过超参数搜索确定最优分桶数量、边界 分箱经验、准则 若组距过大，组内属性取值差距过大 逻辑上分类不能够代表组内全部样本，组内取值影响可能完全不同 若组距过小，组内样本过少 随机性太强，不具备统计意义上说服力 特征影响跳变过多 聚类分箱 K-Means 聚类 层次聚类 聚类过程中需要保证分箱有序 有监督Binning：1R 分箱 分箱逻辑、步骤 将样本排序，从当前位置开始 初始化：以允许的最少样本作为一箱，将箱内最多类别作为箱标签 扩展：若下个样本类别与箱标签相同，则划至箱内 重复以上，得到多个分箱 将相邻具有相同标签的箱合并，得到最终分箱结果 Splitting 基于信息熵的 split，具体划分依据如下 ID3：信息增益 C4.5：信息增益比 D2： Minimum Description Length Principle：描述长度 Merge分箱 基于依赖相关的 merge，具体划分依据如下 Chimerge：使用卡方值衡量两个相邻区间是否具有类似分布，若具有类似分布则将其合并 具体算法 输入：目标分箱数量 $N$ 初始化 将变量升序排列 为减少计算量，若初始分箱数量大于阈值 $N_{max}$，则利用等频分箱进行粗分箱 缺失值单独作为一个分箱 合并区间 计算每对相邻区间的卡方值 将卡方值最小区间合并 重复以上直至分箱数量不大于 $N$ 分箱后处理 合并纯度为 1（只含有某类样本）的分箱 删除某类样本占比超过 95% 的分箱 若缺失值分箱各类样本占比同非缺失值分箱，则合并","link":"/ML-Technique/Feature-Engineering/feature_encoding.html"},{"title":"特征提取","text":"Feature Extraction/Feature Construction特征提取/构建：把原始数据中转换为具有物理、统计学意义特征，构建新的人工特征 主观要求高 对问题实际意义、相关领域有研究：思考问题形式、数据结构 对数据敏感：需要观察原始数据 分析能力强 目的：自动构建新特征 信号表示：抽取后特征尽可能丢失较少信息 信号分类：抽取后特征尽可能提高分类准确率 方法 组合属性：混合属性创建新特征 切分属性：分解、切分原有特征创建新特征，如将时间戳分割为日期、上下午 特征工程和复杂模型在某些方便不冲突 虽然很多复炸模型能够学习复杂规律，类似自行构造特征 但是考虑到计算资源、特征数量、学习效率，人工经验构造衍生特征是必要且有益的 特征选择：表示出每个特征对于模型构建的重要性 特征提取：有时能发现更有意义的特征属性 有时从额外划分特征构建，其相较于特征提取，需要人为的手工构建特征，偏经验、规则 通用特征提取数值型 幅度调整：提高 SGD 收敛速度 归一化 标准化 数据变换 数据标准化（参见 data_preprocessing） 二阶、三阶变换 数据离散化：连续值分段 等距切分：各类分布不均 分位数切分：各类分布均匀，但异质性不均 平方、开根：增加非线性化 分类型 one-hot 编码：赋予各特征等权 hash 技巧：针对文本类别数据，统计文本词表、倾向 多分类转二分类：输入变量类别合并，超类 twoing 策略：使两个超类差异足够大的合并点（分割点） ordering 策略：对有序类型，只有两个连续基类才能合并 统计型 统计特征 跨记录聚集：特征取值在样本全体中的情况 分位线 比例 次序 count（出现次数） 均值 方查 记录内聚合：属于同记录的同类特征统计指标 均值 方查 时序特征 视为连续型：持续时间、间隔时间 视为离散值：一年中某些时间段 组合特征 特征拼接：GBDT 生成特征组合路径 特征冲突验证：匹配、等于、不等于 关联特征：图传播 依赖于内部、外部关联图数据，如： 账户作为节点：已能确认正、负例样本 交易、社会关系作为边 交易频次、金额作为权重 图传播可以考虑多次传播，即考虑前一次的传播结果中置信度较高者作为下次的起始节点 特征交叉衍生：探索的范围较大，人工特征交叉衍生时建议最后考虑，根据经验： 优先从单变量评价指标较好的特征开始 连续特征内部可能会做交叉衍生 但离散特征内部往往不做交叉衍生 one-hot 后特征对应维数较大 单个维度信息量不多，交叉后维数爆炸，不适合某些模型，如：树模型 从离散、连续特征中 分别选择 进行交叉 交叉方式：连续特征为记录内聚合特征时，按离散特征分组聚合 优先考虑此种交叉衍生 降维Principal Component AnalysisPCA：主成分分析，找到数据中主成分，用主成分来表征原始数据，达到降维目的 思想：通过坐标轴转换，寻找数据分布的最优子空间 特征向量可以理解为坐标转换中新坐标轴方向 特征值表示对应特征向量方向上方差 特征值越大、方差越大、信息量越大 抛弃较小方差特征 PCA缺陷：线性降维方法 KPCA：核主成分分析，核映射对PCA进行扩展 流形映射降维方法：等距映射、局部线性嵌入、拉普拉斯 特征映射 步骤 对样本数据进行中心化处理（和统计中处理不同） 求样本协方差矩阵 对协方差矩阵进行特征值分解，将特征值从大至小排列 取前p个最大特征值对应特征向量作为新特征，实现降维 Linear Discriminant AnalysisLDA：线性判别分析，寻找投影方向，使得投影后样本尽可能按照 原始类别分开，即寻找可以最大化类间距离、最小化类内距离的方向 相较于PCA，LDA考虑数据的类别信息，不仅仅是降维，还希望 实现“分类” 优点：相较于PCA LDA更适合处理带有类别信息的数据 模型对噪声的稳健性更好 缺点 对数据分布有很强假设：各类服从正太分布、协方差相等， 实际数据可能不满足 模型简单，表达能力有限，但可以通过核函数扩展LDA处理 分布比较复杂的数据 Fisher判别分析 Independent Component AnalysisICA：独立成分分析，寻找线性变换$z=Wx$，使得$z$各特征分量 之间独立性最大 思想 假设随机信号$x$服从模型x = As $s$：未知源信号，分量相互独立 $A$：未知混合矩阵 ICA通过观察$x$估计混合矩阵$A$、源信号$s$，认为源信号 携带更多信息 若原信号非高斯，则分解唯一，否则可能有无穷多分解 因子分析，也称Blind Source Separation（盲源分离） 算法 大多数ICA算法需要进行数据预处理：先用PCA得到主成分$Y$， 再把各个主成分各分量标准化得到$Z$满足 $Z$各分量不相关 $Z$各分量方差为1 FastICA算法：寻找方向$w$使得随机变量$w^T z$某种 “非高斯性”度量最大化 四阶矩 图像特征提取 提取边缘、尺度不变特征变换特征 以下是传统的图像特征提取方法，现在应该都是CNN进行特征 提取、分类 详情参见machine_learning/cv LBP特征 Sobel Operator Laplace Operator Canny Edge Detector 基于角点 Moravec Harris GoodFeaturesToTrack FAST 基于尺度空间 Scale-Invariant Feature Transform Speeded Up Robust Feature Brief Oriented Brief HOG特征方向梯度直方图特征：通过计算、统计图像局部区域梯度方向直方图 实现特征描述 步骤 归一化处理：图像转换为灰度图像，再利用伽马校正实现 提高图像特征描述对光照、环境变量稳健性 降低图像局部阴影、局部曝光、纹理失真 尽可能抵制噪声干扰 计算图像梯度 统计梯度方向 特征向量归一化（块内） 克服光照不均匀变化及前景、背景对比差异 生成特征向量 文本特征提取 具体参见ml_specification/natural_language_processing/#todo 词袋模型词袋模型：将文本以词为单位切分token化 文章可以表示为稀疏长向量，向量每个维度代表一个单词 针对有序语句，将单词两两相连 维度权重反映单词在原文章中重要程度 通常使用TF-IDF统计量表示词权重 TF-IDF \\begin{align*} TF-IDF(t, d) & = TF(t, d) * IDF(t) \\\\ IDF(t) & = log \\frac {文章总数} {包含单词t的文章总数 + 1} \\end{align*} $TF(t, d)$：单词$t$在文档$d$中出现的频率 $IDF(t)$：逆文档频率，衡量单词对表达语义的重要性 若单词在多篇文章中出现过，则可能是通用词汇，对区分 文章贡献较小，$IDF(t)$较小、权重较小 N-gram模型N-gram模型：将连续出现的$n, n \\leq N$个词组成的词组N-gram 作为单独特征放到向量中 相较于词袋模型，考虑单词组合意义 word stemming：将不同词性单词统一为同一词干形式 同一个词可能有多种词性变化，却拥有相同含义 Word-Embedding模型词嵌入模型：将每个词都映射为低维空间上的稠密向量 Word2Vec：常用词嵌入模型，底层神经网络 Continuous Bag of Words：根据上下文词语预测当前词 生成概率 Skip-gram：根据当前词预测上下文中各个词的生成概率 实际上直接使用矩阵作为源文本特征作为输入进行训练，难以 得到好结果，往往需要提取、构造更高层特征","link":"/ML-Technique/Feature-Engineering/feature_extraction.html"},{"title":"Convolutional","text":"Convolutional卷积：卷积区域逐点乘积、求和作为卷积中心取值 用途： 提取更高层次的特征，对图像作局部变换、但保留局部特征 选择和其类似信号、过滤掉其他信号、探测局部是否有相应模式，如 sobel 算子获取图像边缘 可变卷积核与传统卷积核区别 传统卷积核参数人为确定，用于提取确定的信息 可变卷积核通过训练学习参数，以得到效果更好卷积核 卷积类似向量内积 特点 局部感知：卷积核所覆盖的像素只是小部分、局部特征 类似于生物视觉中的 receptive field 多核卷核：卷积核代表、提取某特征，多各卷积核获取不同特征 权值共享：给定通道、卷积核，共用滤波器参数 卷积层的参数取决于：卷积核、通道数 参数量远小于全连接神经网络 receptive field：感受野，视觉皮层中对视野小区域单独反应的神经元 相邻细胞具有相似和重叠的感受野 感受野大小、位置在皮层之间系统地变化，形成完整的视觉空间图 发展历程 1980 年 neocognitron 新认知机提出 第一个初始卷积神经网络，是感受野感念在人工神经网络首次应用 将视觉模式分解成许多子模式（特征），然后进入分层递阶式的特征平面处理 卷积应用Guassian Convolutional Kernel高斯卷积核：是实现 尺度变换 的唯一线性核 \\begin{align*} L(x, y, \\sigma) & = G(x, y, \\sigma) * I(x, y) \\\\ G(x, y, \\sigma) & = \\frac 1 {2\\pi\\sigma^2} exp\\{\\frac {-((x-x_0)^2 + (y-y_0)^2)} {2\\sigma^2} \\} \\end{align*} $G(x,y,\\sigma)$：尺度可变高斯函数 $I(x,y)$：放缩比例，保证卷积核中各点权重和为 1 $(x,y)$：卷积核中各点空间坐标 $\\sigma$：尺度变化参数，越大图像的越平滑、尺度越粗糙","link":"/ML-Model/Model-Component/convolutional.html"},{"title":"Attention Machanism","text":"Attention Machanism注意力机制：将query、key-value映射至输出的权重生成机制 Attention(Q, K, V) = \\phi(f_{Att}(Q, K), V) $V_{L d_v}$：value矩阵，*信息序列矩阵 $K_{L * d_k}$：key矩阵，大部分情况即为$V$ $Q_{L * d_k}$：query矩阵，其他环境信息 $L, d_k, d_v$：输入序列长度、key向量维度、value向量维度 key、value向量为$K, V$中行向量 合理分配注意力，优化输入信息来源 给重要特征分配较大权 不重要、噪声分配较小权 在不同模型间学习对齐 attention机制常联合Seq2Seq结构使用，通过隐状态对齐 如：图像至行为、翻译 Attention Model Attenion机制一般可以细化如下 \\begin{align*} c_t & = \\phi(\\alpha_t, V) \\\\ \\alpha_{t} & = softmax(e_t) \\\\ & = \\{ \\frac {exp(e_{t,j})} {\\sum_{k=1}^K exp(e_{t,k})} \\} \\\\ e_t & = f_{Att}(K, Q) \\end{align*} $c_t$：context vector，注意力机制输出上下文向量 $e_{t,j}$：$t$时刻$i$标记向量注意力得分 $\\alpha_{t,i}$：$t$时刻$i$标记向量注意力权重 softmax归一化注意力得分 $f_{Att}$：计算各标记向量注意力得分 additive attention multiplicative/dot-product attention： local attention 其参数需联合整个模型训练、输入取决于具体场景 $\\phi_{Att}$：根据标记向量注意力权重计算输出上下文向量 stochastic hard attention deterministic soft attention $Q$可能包括很多信息 Decoder结构输出、Encoder结构输入 $W$待训练权重矩阵 LSTM、RNN等结构隐状态 Additive Attention 单隐层前馈网络（MLP） e_{t,j} = v_a^T f_{act}(W_a [h_{t-1}; g_j]) $h_{t-1}$：输出结构隐状态 $g_j$：输入结构隐状态 $W_a, v_a$：待训练参数 $f_{act}$：激活函数$tanh$、$ReLU$等 Multiplicative/Dot-product Attention e_{t,j} = \\left \\{ \\begin{array}{l} h_{t-1}^T g_j, & dot \\\\ h_{t-1}^T W_a g_j, & general \\\\ W_a h_{t-1}, & location \\end{array} \\right. 相较于加法attention实际应用中更快、空间效率更高 （可以利用高度优化的矩阵乘法运算） MLP 內积形式 Tricks 将输出作为输入引入，考虑上一次输出影响 Scaled Dot-Product Attention f_{Att} = \\frac {Q K^T} {\\sqrt{d_k}} 避免內积随着key向量维度$d_k$增大而增大，导致softmax 中梯度过小 Stochastic Hard Attentionhard attention：随机抽取标记向量作为注意力位置 注意力位置视为中间one-hot隐向量，每次只关注某个标记向量 模型说明 $f_{Att}$为随机从标记向量$a$中抽取一个 $\\alpha$视为多元伯努利分布参数，各分量取值表示对应 标记向量被抽中概率，此时上下文向量也为随机变量 \\begin{align*} p(s_{t,i}=1) & = \\alpha_{t,i} \\\\ c_t & = V s \\end{align*} $s$：注意力位置，中间隐one-hot向量，服从$\\alpha$指定的 多元伯努利分布 $h_i$：第$i$上下文向量 参数训练 参数$\\alpha$不可导、含有中间隐变量$s$，考虑使用EM算法 思想求解 \\begin{align*} log p(y) & = log \\sum_s p(s) p(y|s) \\\\ & \\geq \\sum_s p(s) log p(y|s) := L_s \\\\ \\frac {\\partial L_s} {\\partial W} & = \\sum_s [ \\frac {\\partial p(s)} {\\partial W} + \\frac 1 {p(y|s)} \\frac {\\partial p(y|s)} {\\partial W}] \\\\ & = \\sum_s p(s) [\\frac {\\partial log p(y|s)} {\\partial W} + log p(y|s) \\frac {\\partial log p(s|a)} {\\partial W}] \\end{align*} $L_s$：原对数似然的函数的下界，以其作为新优化目标 $W$：参数 用蒙特卡罗采样方法近似求以上偏导 $s$按多元伯努利分布抽样$N$次，求$N$次偏导均值 \\frac {\\partial L_s} {W} \\approx \\frac 1 N \\sum_{n=1}^N [\\frac {\\partial log p(y|\\tilde s_n)} {\\partial W} + log p(y|\\tilde s_n) \\frac {\\partial log p(\\tilde s_n|a)} {\\partial W}] $\\tilde s_n$：第$n$次抽样结果 可对$p(y|\\tilde s_n)$进行指数平滑减小估计方差 Deterministic Soft Attentionsoft attention：从标记向量估计上下文向量期望 考虑到所有上下文向量，所有标记向量加权求和上下文向量 模型说明 $f_{Att}$计算所有标记向量注意力得分 $\\alpha$可视为个标记向量权重 E_{p(s_t)} [c_t] = \\sum_{i=1}^L \\alpha_{t,i} a_i 模型光滑可微：可直接用反向传播算法训练 Local Attentionlocal attention：从所有标记向量中选取部分计算soft attention 可以视为hard、soft attention结合 hard attention选取标记向量子区间，避免噪声干扰 soft attention加权求和，方便训练 子区间选取 为目标$t$选取对齐位置$p_t$，得到子区间$[p_t-D, p_t+D]$ （$D$为经验选取） monotonic alignment：直接设置$p_t=t$ predictive alignment： p_t = S sigmoid(v_p^T tanh(W_p h_t)) $W_p, v_p$：待学习参数 可以使用高斯分布给注意力权重加权，强化$p_t$附近标记向量 （根据经验可以设置$\\sigma = \\frac D 2$） \\alpha_{t,j} = softmax(e_{t,j}) exp(-\\frac {(j - p_t)^2} {2\\sigma^2}) Self AttentionSelf Attention/Intra-Attention：关联同一序列内不同位置、 以学习序列表示的attenion机制 类似卷积、循环结构 将不定长的序列映射为等长的另一序列 从序列中提取高层特征 特点 类似卷积核，多个self attention可以完全并行 无需循环网络多期传递信息，输入序列同期被处理 可使用local attention机制限制计算复杂度 Multi-Head AttentionMulti-Head Attention：从相同输入、输出序列学习多个 attention机制 \\begin{align*} MultiHead(X) & = Concat(head1, ..., head_h) W^O \\\\ head_i & = Attention(QW_i^Q, KW_i^K, VW_i^V) \\end{align*} $Q, K, V$：元信息矩阵，据此训练多组query、key-value， 一般就是原始输入序列矩阵 可以并行训练，同时从序列中提取多组特征","link":"/ML-Model/Model-Component/attention.html"},{"title":"Interaction Layers","text":"人工交互作用层交互作用层：人工设置特征之间交互方式 Flatten Layer展平层：直接拼接特征，交互作用交由之后网络训练 f_{Flat}(V_x) = \\begin{bmatrix} x_1 v_1 \\\\ \\vdots\\\\ x_M v_M \\end{bmatrix} $V_x$：特征向量集合 对同特征域特征处理方式 平均 最大 二阶交互作用二阶交互作用层：特征向量之间两两逐元素交互 交互方式 逐元素 乘积 求最大值：无 按向量 聚合方式 求和 平权 Attention加权 求最大值：无 Bi-Interaction LayerBi-Interaction Layer：特征向量两两之间逐元素乘积、求和 \\begin{align*} f_{BI}(V) & = \\sum_{i=1}^M \\sum_{j=i+1}^M v_i \\odot v_j \\\\ & = \\frac 1 2 (\\|\\sum_{i=1}^M v_i\\|_2^2 - \\sum_{i=1}^M \\|v_i\\|_2^2) \\end{align*} $\\odot$：逐元素乘积 没有引入额外参数，可在线性时间$\\in O(kM_x)$内计算 可在低层次捕获二阶交互影响，较拼接操作更informative 方便学习更高阶特征交互 模型实际中更容易训练 Attention-based PoolingAttention-based Pooling：特征向量两两之间逐元素乘积、加权 求和 f_{AP}(V) & = \\sum_{i=1}^M \\sum_{j=i+1}^M \\alpha_{i,j} (v_i \\odot v_j) $\\alpha_{i,j}$：交互作用注意力权重，通过注意力网络训练","link":"/ML-Model/Model-Component/interaction.html"},{"title":"Embedding","text":"Embedding嵌入层：将高维空间中离散变量映射为低维稠密 embedding 向量表示 embedding 向量更能体现样本之间关联 內积（內积）体现样本之间接近程度 可通过可视化方法体现样本差异 embedding 向量更适合某些模型训练 模型不适合高维稀疏向量 embedding 向量矩阵可以联合模型整体训练，相当于提取特征 embedding 向量也可能类似迁移学习独立训练之后直接融入模型中 Embedding：将度量空间中对象映射到另个（低维）度量空间，并尽可能保持不同对象之间拓扑关系，如 Word-Embedding Embedding表示 特征不分组表示 \\begin{align*} \\varepsilon_x & = E x \\\\ & = [x_1v_1, x_2v_2, \\cdots, x_Mv_M] \\\\ & = [x_{M_1} v_{M_1}, \\cdots, x_{M_m} v_{M_m}] \\end{align*} $E$：embedding向量矩阵 $M$：特征数量 $v_i$：$k$维embedding向量 $x_i$：特征取值，对0/1特征仍等价于查表，只需考虑非0特征 $x_{M_i}$：第$j$个非0特征，编号为$M_i$ $m$：非零特征数量 $\\varepsilon_x$：特征向量集合 特征分组表示 \\begin{align*} \\varepsilon_x & = [V_1 g_1, V_2 g_2, \\cdots, V_G g_G] \\end{align*} $G$：特征组数量 $V_i$：第$i$特征组特征向量矩阵 $g_i$：第$i$特征组特征取值向量","link":"/ML-Model/Model-Component/embedding.html"},{"title":"Pooling Layers","text":"池化/下采样池化：在每个区域中选择只保留一个值 用于减小数据处理量同时保留有用的信息 相邻区域特征类似，单个值能表征特征、同时减少数据量 保留值得选择有多种 极值 平均值 全局最大 直观上 模糊图像，丢掉一些不重要的细节 Max Pooling最大值采样：使用区域中最大值作为代表 Average Pooling平均值采样：使用池中平均值作为代表","link":"/ML-Model/Model-Component/pooling.html"},{"title":"Recurrent Neural Network","text":"Recurrent Neural NetworkRNN：处理前后数据有关联的序列数据 左侧：为折叠的神经网络，右侧：按时序展开后的网络 $h$：循环隐层，其中神经元之间有权连接，随序列输入上一期 隐层会影响下一期 $o$、$y$：输出预测值、实际值 $L$：损失函数，随着时间累加 序列往往长短不一，难以拆分为独立样本通过普通DNN训练 结构 普通的DNN：固定大小输入得到固定输出 单个输入、序列输出：输入图片，得到描述文字序列 序列输入、单个输出：情感分析 异步序列输入、输出：机器翻译 同步序列输入、输出：视频帧分类 权值连接 循环隐层内神经元之间也建立权连接，即循环 基础神经网络只在层与层之间建立权值连接是RNN同普通DNN 最大不同之处 循环隐层中神经元只会和其当前层中神经元建立权值连接 即不受上期非同层神经元影响 循环隐层中神经元$t$期状态$h^{(t)}$由当期输入、 $h^{(t-1)}$共同决定 Gated Feedback RNN：循环隐层会对下期其他隐层产生影响 逻辑结构 RNN网络实际结构是线性、折叠的，逻辑结构则是展开的结构， 考虑RNN性质应该在展开的逻辑结构中考虑 序列输入 实际结构：依次输入 逻辑结构：里是整体作为一次输入、才是一个样本，损失、 反向传播都应该以完整序列为间隔 权值共享 实际结构：不同期的权值实际是同一组 逻辑结构：称为权值共享 重复模块链 实际结构：同一个模块 逻辑结构：不同期模块之间信息流动形成链式形式 信息传递 RNN循环层中信息只能由上一期直接传递给下一期 输入、输出相关信息间隔较近时，普通RNN可以胜任 当间隔很长，RNN理论上虽然能够处理，但由于梯度消失问题， 实际上长期依赖会消失，需要LSTM网络 Forward Propogation $h^{(t)} = \\sigma(z^{(t)}) = \\sigma(Ux^{(t)} + Wh^{(t-1)} +b )$ $\\sigma$：RNN激活函数，一般为$tanh$ $b$：循环隐层偏置 $o^{(t)} = Vh^{(t)} + c$ $c$：输出层偏置 $\\hat{y}^{(t)} = \\sigma(o^{(t)})$ $\\sigma$：RNN激活函数，分类时一般时$softmax$ Back-Propogation Through TimeBPTT：训练RNN的常用方法 本质仍然是BP算法，但是RNN处理序列数据，损失随期数累加， 即计算梯度时使用最终损失$L = \\sum_{t=1}^\\tau L^{(t)}$ 对循环层中参数，梯度沿着期数反向传播，第t期反向传播时， 需要逐级求导 序列整体作为一次输入，进行一次反向传播 理论上可以漂亮的解决序列数据的训练，但是和DNN一样有梯度 消失的问题，尤其是序列很长时，所以一般不能直接应用 非循环层 $\\frac{\\partial L}{\\partial c}$ \\begin{align*} \\frac{\\partial L}{\\partial c} & = \\sum_{t=1}^{\\tau} \\frac{\\partial L^{(t)}}{\\partial c} & = \\sum_{t=1}^{\\tau}\\frac{\\partial L^{(t)}} {\\partial o^{(t)}} \\frac{\\partial o^{(t)}}{\\partial c} & = \\sum_{t=1}^{\\tau}\\hat{y}^{(t)} - y^{(t)} \\end{align*} $L^{(t)} = \\frac 1 2 (\\hat{y}^{(t)} - y^{(t)})^2$： 使用平方损失 $\\frac{\\partial L}{\\partial V}$ \\begin{align*} \\frac{\\partial L}{\\partial V} & = \\sum_{t=1}^{\\tau} \\frac{\\partial L^{(t)}}{\\partial V} & = \\sum_{t=1}^{\\tau} \\frac{\\partial L^{(t)}} {\\partial o^{(t)}} \\frac{\\partial o^{(t)}}{\\partial V} & = \\sum_{t=1}^{\\tau}(\\hat{y}^{(t)} - y^{(t)}) (h^{(t)})^T \\end{align*} 循环层 为方便定义： $\\delta^{(t)} = \\frac {\\partial L} {\\partial h^{(t)}}$ $\\delta^{(t)}$ \\begin{align*} \\delta^{(t)} & = \\frac {\\partial L} {\\partial h^{(t)}} \\\\ & = \\frac{\\partial L}{\\partial o^{(t)}} \\frac{\\partial o^{(t)}}{\\partial h^{(t)}} + \\frac{\\partial L}{\\partial h^{(t+1)}} \\frac{\\partial h^{(t+1)}}{\\partial h^{(t)}} & = V^T(\\hat{y}^{(t)} - y^{(t)}) + W^T\\delta^{(t+1)}diag(1-h^{(t+1)})^2) \\end{align*} $\\frac{\\partial h^{(t+1)}}{\\partial h^{(t)}} = diag(1-h^{(t+1)})^2)$ ：$tanh(x)$梯度性质 $h^{(t)}(t&lt;\\tau)$梯度：被后一期影响（反向传播），需递推 $\\delta^{(\\tau)}$ \\begin{align*} \\delta^{(\\tau)} & = \\frac{\\partial L}{\\partial o^{(\\tau)}} \\frac{\\partial o^{(\\tau)}}{\\partial h^{(\\tau)}} & = V^T(\\hat{y}^{(\\tau)} - y^{(\\tau)}) \\end{align*} $\\tau$期后没有其他序列，可以直接求出 $\\frac{\\partial L}{\\partial W}$ \\begin{align*} \\frac{\\partial L}{\\partial W} & = \\sum_{t=1}^{\\tau} \\frac{\\partial L}{\\partial h^{(t)}} \\frac{\\partial h^{(t)}}{\\partial W} & = \\sum_{t=1}^{\\tau}diag(1-(h^{(t)})^2) \\delta^{(t)}(h^{(t-1)})^T \\end{align*} 需要由$\\sigma^{(t)}$累加得到 $\\frac{\\partial L}{\\partial b}$ \\begin{align*} \\frac{\\partial L}{\\partial b} & = \\sum_{t=1}^{\\tau} \\frac{\\partial L}{\\partial h^{(t)}} \\frac{\\partial h^{(t)}}{\\partial b} & = \\sum_{t=1}^{\\tau} diag(1-(h^{(t)})^2)\\delta^{(t)} \\end{align*} $\\frac{\\partial L}{\\partial U}$ \\begin{align*} \\frac{\\partial L}{\\partial U} & = \\sum_{t=1}^{\\tau} \\frac{\\partial L}{\\partial h^{(t)}} \\frac{\\partial h^{(t)}}{\\partial U} & = \\sum_{t=1}^{\\tau}diag(1-(h^{(t)})^2) \\delta^{(t)}(x^{(t)})^T \\end{align*} }$$","link":"/ML-Model/Model-Component/recurrent.html"},{"title":"Long Short Term Memory","text":"Long Short Term MemoryLSTM：通过刻意设计、默认可以学习长期依赖信息的RNN网络 LSTM中每个重复的模块（层）称为细胞 细胞结构经过特殊设计，相较于准RNN简单细胞结构能较好 保留长时信息 多个LSTM细胞可以组成block，其中细胞门权值共享 block中各个细胞状态不同 这个是同时刻、不同层的真权值共享，类似CNN中的卷积核 减少参数个数，效率更高 long term memory：长期记忆，参数 short term memory：短期记忆，数据流 long short term memory：长[的]短期记忆，细胞状态 LSTM标准细胞结构 \\begin{align*} i^{(t)} & = \\sigma(W_i[x^{(t)}, h^{(t-1)}], b_i), & input gate \\\\ f^{(t)} & = \\sigma(W_f[x^{(t)}, h^{(t-1)}], b_f), & forget gate \\\\ o^{(t)} & = \\sigma(W_o[x^{(t)}, h^{(t-1)}], b_o), & output gate \\\\ \\tilde C^{(t)} & = tanh((W_c[x^{(t)}, h^{(t)}])), & memory alternates \\\\ C^{(t)} & = f^{(t)} \\odot c^{(t-1)} + i^{(t)} \\odot c^{(t)}, & new memory \\\\ h^{(t)} & = o^{(t)} \\odot tanh(c^{(t)}), & output \\end{align*} $W_i, b_i, W_f, b_f, W_o, b_o$：输入门、遗忘门、输出门 参数 $\\odot$：逐项乘积 $x_t$：第$t$期输入 $i^{(t)}$：输出门权重，决定需要更新的信息 $f^{(t)}$：遗忘门权重，决定需要遗忘的信息 $o^{(t)}$：输出门权重，决定需要输出的信息 $h^{(t-1)}$：第$t-1$期细胞状态输出 $\\tilde C_t$：第$t$期更新备选内容 $C^{(t)}$：第$t$期更新完成后细胞状态 输入、遗忘、输出门特点 当期输入$x^{(t)}$、上期输出$h^{(t-1)}$作为输入 sigmoid作为激活函数，得到$[0,1]$间控制、权重向量 1：完全保留 0：完全舍弃 细胞状态、输出特点 tanh作激活函数，得到$[-1,1]$间信息向量 $h^{(t-1)}, x^t$：备选更新信息输入 $C^{(t-1)}$：输出信息输入 与门限权重逐项乘积确定最终遗忘、输入、输出 细胞状态选择（候选、输出）都是使用双曲正切激活，应该 是为了有正由负 Gates Forget Gate：遗忘门，决定要从细胞状态中舍弃的信息 Input Gate：输入门，决定向细胞状态中保留的信息 Ouput Gate：输出门，决定从细胞状态中输出的信息 Cell State细胞状态：LSTM中最重要的核心思想 随着时间流动，承载之前所有状态信息，代表长期记忆 类似于传送带，直接在整个链上运行，只有少量线性交互 信息其上流派很容易保持不变 通过“三个门”保护、控制 LSTM可以保证长短时记忆可以理解为 $C_t$中历史信息比重由$f^{(t)}$确定 $f^{(t)}$趋近于1时历史信息能较好的保留 Gated Recurrent Unit \\begin{align*} r^{(t)} & = \\sigma(W_r [h^{(t-1)}, x^{(t)}] + b_r), & reset gate \\\\ z^{(t)} & = \\sigma(W_z [h^{(t-1)}, x^{(t)}] + b_z), & update gate \\\\ \\tilde h^{(t)} &= tanh(W_h [r^{(t)} h^{(t-1)}, x^{(t)}]), & memory alternates\\\\ h^{(t)} & = (1 - z^{(t)}) \\odot h^{(t-1)} + z^{(t)} \\odot \\tilde h^{(t)}, & new memory \\end{align*} $W_r, b_r, W_z, b_z$：重置门、更新门参数 $h^{(t)}$：原细胞状态、隐层输出合并 $\\tilde{h}_t$：第$t$期更新备选信息 $r^{(t)}$：重置门权重输出，重置上期状态$h_{t-1}$再作为更新 门输入 $z^{(t)]$：更新门权重输出，当期状态$ht$中$h{t-1}$、 $\\tilde{h}_t$占比（遗忘、更新的结合） 合并细胞状态、隐层输出 合并遗忘门、输出门为更新门 其他变体结构Vanilla LSTM Peephole Connection：细胞状态也作为3个门中sigmoid的 输入，影响控制向量的生成 Coupled Input and Forget Gate $1-f_i$代替$i_t$，结合遗忘门、输入门 结构比较在Vanilla LSTM基础上的8个变体在TIMIT语音识别、手写字符识别、 复调音乐建模三个应用中比较 No Input Gate：NIG，没有输入门 No Forget Gate：NFG，没有遗忘门 No Output Gate：NOG，没有输出门 No Input Acitivation Function：NIAF，输入门没有tanh 激活 No Output Activation Function：NOAF，输出门没有tanh 激活 No Peepholes：NP，普通LSTM Coupled Input and Forget Gate：CIFG，遗忘、输出门结合 Full Gate Recurrence：FGR，所有门之间有回路 Vanilla LSTM效果均良好，其他变体没有性能提升 细胞结构 遗忘门、输入门是最重要的部分 遗忘门对LSTM性能影响十分关键 输出门对限制无约束细胞状态输出必要 CIFG、NP简化结构，单对结果没有太大影响 超参 学习率、隐层数量是LSTM主要调节参数 两者之间没有相互影响，可以独立调参 学习率可以可以使用小网络结构独立校准 动量因子影响不大 高斯噪声的引入有损性能、增加训练时间 ?时间","link":"/ML-Model/Model-Component/long_short_term_memory.html"},{"title":"Seq2Seq","text":"Seq2SeqSeq2Seq/Encoder-Decoder：允许任意长度序列输入、输出学习 \\begin{align*} p(y_1, \\cdots, y_{T^{'}} | x_1, \\cdots, x_T) & = \\prod_{t=1}^T p(y_t|c, y_1, \\cdots, y_{t-1}) \\\\ c & = q(\\{h_1, \\cdots, h_T\\}) \\\\ h_t & = f(x_t, h_{t-1}) \\end{align*} $T^{‘} \\neq T$：输出序列长度、输入序列长度 $p(y_t|\\cdots)$：一般为softmax函数计算字典中各词概率 $c$：定长向量 $h_t$：隐状态 $q$：将隐状态映射为定长向量存储信息，如： $q(\\cdots) = h_T$ $f$：根据输入映射为隐状态，如：RNN、LSTM 实现策略 encoder：将输入序列映射为定长向量 decoder：将该定长向量映射为目标输出 （通过将联合概率有序分解来定义翻译概率） RNN：以内部隐状态作为定长向量存储输入信息 理论上可实现在定长向量中存储相关信息、再解码 但由于长时梯度消失，实际难以训练 LSTM：类似RNN在内部隐状态中存储信息 学习长时依赖更有效、容易训练 Seq2Seq with Attention 采用LSTM、RNN结构的Seq2Seq结构很难将输入序列转化为定长 向量而保存所有有效信息 序列末尾对定长向量影响更大，难以学习长距离依赖 随着输入序列长度增加，预测效果显著下降 使用Attention机制的Seq2Seq无需多期迭代传递信息，不存在 长距离依赖 BiRNN2RNN with Attention \\begin{align*} p(y_t | y_1, \\cdots, y_{t-1}, x) & = g(y_{t-1}, s_t, c_t) \\\\ s_t & = f(s_{t-1}, y_{t-1}, c_t) \\\\ c_t & = \\sum_{j=t}^T \\alpha_{j=1}^T \\alpha_{t,j} h_j \\\\ \\alpha_{t,j} & = softmax(e_{t,j}) \\\\ & = \\frac {exp(e_{t,j})} {\\sum_{k=1}^T exp(e_{t,k})} \\\\ e_{t,j} & = a(s_{t-1}, h_j) \\end{align*} $y_t$：当前$t$时刻输出 $p(y_t|\\cdots)$：$t$时刻输出条件概率 $s_t$：解码器$t$时刻隐状态 $h_j$：编码器$j$时刻隐状态 $c_t$：expected annotation，对输出$t$的上下文向量 $T$：输入序列长度 $e{t,j}, \\alpha{t,j}$：输入$j$对输出$t$重要性，反映 模型注意力分布 $a$：alignment model，输入输出相关性模型，同整个系统 联合训练的前向神经网络，attention机制核心 编码器：Bi-RNN 解码器：attention机制加权的RNN","link":"/ML-Model/Model-Component/sys2sys.html"},{"title":"Naive Bayes","text":"Naive Bayes Classifier朴素贝叶斯：在训练数据集上学习联合概率分布$P(X,Y)$，利用后验 分布作为结果 朴素：条件概率分布有条件独立性假设，即特征在类别确定 下条件独立 模型 输出Y的先验概率分布为 P(Y = c_k), k = 1,2,\\cdots,K 先验概率是指输出变量，即待预测变量的先验概率分布， 反映其在无条件下的各取值可能性 同理所有的条件概率中也是以输出变量取值作为条件 条件概率分布为 P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)},\\cdots,X^{(D)}=x^{(D)}| Y=c_k) $D$：用于分类特征数量 其中有指数数量级的参数（每个参数的每个取值都需要参数） 因此对条件概率分布做条件独立性假设，即分类特征在类别 确定条件下是独立的 \\begin{align*} P(X=x|Y=c_k) & = P(X^{(1)}=x^{(1)},\\cdots,X^{(D)}=x^{(D)} |Y=c_k) \\\\ & = \\prod_{j=1}^D P(X^{(j)}=x^{(j)}|Y=c_k) \\end{align*} 条件独立性假设是比较强的假设，也是朴素的由来 其使得朴素贝叶斯方法变得简单，但有时也会牺牲准确率 以上即可得到联合概率分布$P(X,Y)$ 朴素贝叶斯学习到的联合概率分布$P(X,Y)$是数据生成的 机制，即其为生成模型 策略策略：选择使得后验概率最大化的类$c_k$作为最终分类结果 P(Y=c_k|X=x) = \\frac {P(Y=c_k, X=x)} {\\sum_{i=1}^K P(Y=c_k, X=x)} $K$：输出类别数量 后验概率根计算根据贝叶斯定理计算 \\begin{align*} P(Y=c_k|X=x) & = \\frac {P(X=x|Y=c_k)P(Y=c_k)} {\\sum_{k=1}^K P(X=x|Y=c_k) P(Y=c_k)} \\\\ & = \\frac {P(Y=c_k) \\prod_{j=1}^D P(X^{(j)}|Y=c_k)} {\\sum_{k=1}^K P(Y=c_k) \\prod_{j=1}^D P(X^{(j)}|Y=c_k)} \\end{align*} 考虑上式中分母对所有$c_k$取值均相等，则最终分类器为 y = \\arg\\max_{c_k} P(Y=c_k) \\prod_{j=1}^D P(X^{(j)} = x^{(j)}|Y=c_k) 即分类时，对给定输入$x$，将其归类为后验概率最大的类 策略性质后验概率最大化等价于0-1损失的经验风险最小化 经验风险为 \\begin{align*} R_{emp}(f) & = E[L(Y, f(X))] \\\\ & = E_x \\sum_{k=1}^K L(y, c_k) P(c_k | X) \\end{align*} 为使经验风险最小化，对训练集中每个$X=x$取极小化，对每个 个体$(x,y)$有 \\begin{align*} f(x) & = \\arg\\min_{c_k} \\sum_{k=1}^K L(y, c_k) P(c_k|X=x) \\\\ & = \\arg\\min_{c_k} \\sum_{k=1}^K P(y \\neq c_k|X=x) \\\\ & = \\arg\\min_{c_k} (1-P(y=c_k|X=x)) \\\\ & = \\arg\\max_{c_k} P(y=c_k|X=x) \\end{align*}即后验概率最大化 算法极大似然估计 先验概率的极大似然估计为 P(Y=c_k) = \\frac {\\sum_{i=1}^N I(y_i = c_k)} N, k=1,2,\\cdots,K 条件概率的极大似然估计为 P(X^{(j)}=a_{j,l}|Y=c_k) = \\frac {\\sum_{i=1}^N I(x_i^{(j)}=a_{j,l}, y_i=c_k)} {\\sum_{i=1}^N I(y_i=c_k)} \\\\ j=1,2,\\cdots,N;l=1,2,\\cdots,S_j;k=1,2,\\cdots,K $a_{j,l}$；第j个特征的第l个可能取值 $S_j$：第j个特征的可能取值数量 $I$：特征函数，满足条件取1、否则取0 算法 输入：训练数据T 输出：朴素贝叶斯分类器 依据以上公式计算先验概率、条件概率 将先验概率、条件概率带入，得到朴素贝叶斯分类器 y = \\arg\\max_{c_k} P(Y=c_k) \\prod_{j=1}^D P(X^{(j)} = x^{(j)}|Y=c_k) 贝叶斯估计 条件概率贝叶斯估计 P(X^{(j)}=a_{j,l}|Y=c_k) = \\frac {\\sum_{i=1}^N I(x_i^{(j)}=a_{j,l}, y_i=c_k) + \\lambda} {\\sum_{i=1}^N I(y_i=c_k) + S_j \\lambda} \\\\ j=1,2,\\cdots,N;l=1,2,\\cdots,S_j;k=1,2,\\cdots,K $\\lambda \\geq 0$ $\\lambda=0$时就是极大似然估计 常取$\\lambda=1$，此时称为Laplace Smoothing 以上设计满足概率分布性质\\begin{align*} P_{\\lambda}(X^{(j)}=a_{j,l}|Y=c_k) \\geq 0 \\\\ \\sum_{l=1}^{S_j} P_{\\lambda}(X^{(j)}=a_{j,l}|Y=c_k) = 1 \\end{align*} 先验概率贝叶斯估计 P_{\\lambda}(Y=c_k) = \\frac {\\sum_{i=1}^N I(y_i = c_i) + \\lambda} {N + K\\lambda} 极大似然估计可能出现所需估计概率值为0，影响后验概率计算 结果，贝叶斯估计能够避免这点 Semi-Naive Bayes Classifier半朴素贝叶斯分类器：适当考虑部分特征之间的相互依赖信息 Semi-Naive Bayes可以视为是利用规则对变量加权，以 此来体现相关变量的协同影响 y = \\arg\\max_{c_k} P(Y=c_k) \\prod_{j=1}^D \\beta_j P(X^{(j)} = x^{(j)}|Y=c_k) 特别的：权值为0/1即为变量筛选 One-Depentdent Estimator独依赖估计：假设特征在类别之外最多依赖一个其他特征，这是半 朴素贝叶斯分类器中最常用的一种策略 P(X=x|Y=c_k) = \\prod_{j=1}^D P(X^{(j)}=x^{(j)} | Y=c_k, pa_j) $pa_j$：特征$X^{(j)}$依赖的父特征 若父特征已知，同样可以使用条件概率计算 $P(X^{(j)}=x^{(j)} | Y=c_k, pa_j)$ P(X^{(j)}=x^{(j)} | Y=c_k, pa_j) = \\frac {P(X^{(j)}=x^{(j)}, Y=c_k, pa_j)} {P(Y=c_k, pa_j)} ODE形式半朴素贝叶斯分类器相应的策略为 y = \\arg\\max_{c_k} P(Y=c_k) \\prod_{j=1}^D P(X^{(j)} = x^{(j)}|Y=c_k, pa_j) 根据确定各特征父特征的不同做法，可以分为不同类型的独依赖 分类器 Super-Parent ODE：假设所有特征都依赖同一父特征 Averaged ODE：类似随机森林方法，尝试将每个属性作为 超父特征构建SPODE Tree Augmented Naive Bayes：基于最大带权生成树发展 SPODESPODE：每个特征只与其他唯一一个特征有依赖关系 y = \\arg\\max_{c_k} P(Y=c_k, pa) \\prod_{j=1}^D P(X^{(j)} = x^{(j)}|Y=c_k, pa) $pa$：所有特征共有的依赖父特征 AODEAODE：以所有特征依次作为超父特征构建SPODE，以具有足够训练 数据支撑的SPODE集群起来作为最终结果 y = \\arg\\max_{c_k} (\\sum_{i=1}^D P(Y=c_k, X^{(i)}) \\prod_{j=1}^D P(X^{(j)} = x^{(j)}|Y=c_k, X^{(i)})) 这里只选取训练数据足够，即取特征$X^{(i)}$某个取值的样本 数量大于某阈值的SPODE加入结果 TANTAN步骤 计算任意特征之间的互信息 g(X^{(i)}, X^{(j)}| Y) = \\sum P(X^{(i)}, X^{(j)} | Y=c_k) log \\frac {P(X^{(i)}, X^{(j)} | Y=c_k)} {P(X^{(i)} | Y=c_k) P(X^{(j)} | Y=c_k)} 以特征为节点构建完全图，节点边权重设为相应互信息 构建此完全图的最大带权生成树 挑选根变量 将边设置为有向 加入预测节点$Y$，增加从$Y$到每个属性的有向边 特点 条件互信息$g(X^{(i)}, X^{(j)}| Y)$刻画了特征在已知类别 情况下的相关性 通过最大生成树算法，TAN仅保留了强相关属性之间的依赖性","link":"/ML-Model/Linear-Model/naive_bayes.html"},{"title":"Factorization Machine","text":"因子分解机因子分解机：将变量交互影响因子化 （每个变量用隐向量代表、衡量其交叉影响） \\hat y(x) := w_0 + \\sum_{i=1}^m w_i x_i + \\sum_{i=1}^m \\sum_{j=i+1}^m x_i x_j $w_0$：全局偏置 $w_i$：变量$i$权重 $w_{i,j} := $：变量$i$、$j$之间交互项权重 $v_i$：$k$维向量，变量交叉影响因子 FM通过因子化交互影响解耦交互项参数 即使没有足够数据也能较好估计高维稀疏特征交互影响参数 无需大量有交互影响（交互特征取值同时非0）样本 包含某交互影响数据也能帮助估计相关的交互影响 可以学习数据不存在的模式 可以视为embedding，特征之间关联性用embedding向量 （隐向量）內积表示 参数数量、模型复杂度均为线性 可以方便使用SGD等算法对各种损失函数进行优化 无需像SVM需要支持向量，可以扩展到大量数据集 适合任何实值特征向量，对某些输入特征向量即类似 biased MF、SVD++、PITF、FPMC 另外还有d-way因子分解机，交互作用以PARAFAC模型因子化 \\hat y(x) := w_0 + \\sum_{i=1}^n w_i x_i + \\sum_{l=2}^d \\sum_{i_1=1} \\cdots \\sum_{i_l=i_{l-1}+1}(\\prod_{j=1}^l x_{i_j}) (\\sum_{f=1} \\prod_{j=1}^l v_{i_j,f}^{(l)}) \\\\ $V^{(l)} \\in R^{n * k_l}, k_l \\in N_0^{+}$ 模型表达能力 考虑任何正定矩阵$W$总可以被分解为$W=V V^T$，则$k$足够大 时，FM总可以表达（还原）交叉项权重矩阵$W$ FM是MF降维的推广，在用户-物品评分矩阵基础上集成其他 特征 特征组合发生所有变量之间 实际应该选取较小的$k$ 对较大$k$，稀疏特征没有足够数据估计复杂交叉项权重 矩阵$W$ 限制FM的表达能力，模型有更好的泛化能力、交互权重矩阵 模型求解\\begin{align*} \\sum_{i=1}^m \\sum_{j=i+1}^m x_i x_j & = \\frac 1 2 \\sum_{i=1}^m \\sum_{j=i}^m x_i x_j - \\frac 1 2 \\sum_{i=1}^m x_i^2 \\\\ & = \\frac 1 2 (x^T V^T V x - x^T diag(V^T V) x) \\\\ & = \\frac 1 2 (\\|Vx\\|_2^2 - x^T diag(V^T V) x) \\\\ & = \\frac 1 2 \\sum_{f=1}^k ((\\sum_{i=1}^m v_{i,f} x_i)^ 2 - \\sum_{i=1}^m v_{i,f}^2 x_i^2) \\\\ \\end{align*} $V = (v_1, v_2, \\cdots, v_m)$ $x = (x_1, x_2, \\cdots, x_m)^T$ 模型计算复杂度为线性$\\in O(kn)$ 模型可以使用梯度下降类方法高效学习 \\begin{align*} \\frac {\\partial \\hat y(x)} {\\partial \\theta} & = \\left \\{ \\begin{array}{l} 1, & \\theta := w_0 \\\\ x_i, & \\theta := w_i \\\\ x_i Vx - v_i x_i^2& \\theta := v_i \\end{array} \\right. \\\\ & = \\left \\{ \\begin{array}{l} 1, & \\theta := w_0 \\\\ x_i, & \\theta := w_i \\\\ x_i \\sum_{j=1}^m v_{j,f} x_j - v_{i,f} x_i^2, & \\theta := v_{i,f} \\end{array} \\right. \\end{align*} 考虑到稀疏特征，內积只需计算非零值 模型适用 回归：直接用$\\hat y(x)$作为回归预测值 二分类：结合logit损失、hinge损失优化 ranking：$\\hat y(x)$作为得分排序，使用成对分类损失优化 Field-aware Factorization Machines域感知因子分解机：在FM基础上考虑对特征分类，特征对其他类别 特征训练分别训练隐向量 \\begin{align*} \\hat y(x) & = w_0 + \\sum_{i=0}^m w_i x_i + \\sum_{a=1}^m \\sum_{b=a+1}^m x_a x_b \\\\ & = w_0 + \\sum_{i=1}^M \\sum_{j=1}^{M_i} w_{i,j} x_{i,j} + \\sum_{i=1}^M \\sum_{j=1}^{M_i} \\sum_{a=i}^M \\sum_{b=1}^{M_i} x_{i,j} x_{a,b} \\end{align*} $m$：特征数量 $M, M_i$：特征域数量、各特征域中特征数量 $V_{i,j,a}$：特征域$i$中$j$特征对特征与$a$的隐向量 $V_{a, f_b}$：特征$x_a$对特征$b$所属域$f_b$的隐向量 FFM中特征都属于特定域，相同特征域中特征性质应该相同， 一般的 连续特征自己单独成域 离散0/1特征按照性质划分，归于不同特征域 特征对其他域分别有隐向量表示和其他域的隐含关系 考虑交互作用时，对不同域使用不同隐向量计算交互作用 FFM中隐变量维度也远远小于FM中隐向量维度 算法 模型特点 模型总体类似FM，仅通过多样化隐向量实现细化因子分解 模型总体较FM复杂度大、参数数量多 无法抽取公因子化简为线性 数据量较小时可能无法有效训练隐向量","link":"/ML-Model/Linear-Model/factorization_machine.html"},{"title":"External Memory","text":"","link":"/ML-Model/Model-Component/external_memory.html"},{"title":"Perceptron","text":"输入：实例的特征向量 输出：实例类别+1、-1 感知机模型感知机：线性二分类模型（判别模型） f(x) = sign(wx + b) $x \\in \\chi \\subseteq R^n$：输入空间 $y \\in \\gamma \\subseteq R^n$：输出空间 $w \\in R^n, b \\in R$：weight vector、bias 也常有$\\hat w = (w^T, b^T)^T, \\hat x = (x^T + 1)^T$， 则有$\\hat w \\hat x = wx + b$ 感知机模型的假设空间是定义在特征空间的所有 linear classification model/linear classifier，即函数 集合${f|f(x)=wx+b}$ 线性方程$wx+b=0$：对应特征空间$R^n$中一个hyperplane $w$：超平面法向量 $b$：超平面截距 超平面将特征空间划分为两个部分，其中分别被分为正、负 两类 也被称为separating hyperplane Linearly Separable Data Set 对数据集$T={(x_1,y_1),\\cdots,(x_N,y_N)}$，若存在超平面 $S: wx + b=0$能够将正、负实例点，完全正确划分到超平面 两侧，即\\begin{align*} wx_i + b > 0, & \\forall y_i > 0 \\\\ wx_i + b < 0, & \\forall y_i < 0 \\end{align*} 则称数据集T为线性可分数据集 感知机学习策略感知机学习策略：定义适当损失函数，并将经验风险极小化，确定 参数$w, b$ 0-1损失经验风险：误分率（误分点总数） 不是参数$w, b$的连续可导函数，不易优化 绝对值损失经验风险：误分类点到超平面距离 对误分类数据$(x_i, y_i)$，有$-y_i(wx_i + b) &gt; 0$ 则误分类点$(x_i, y_i)$到超平面S距离 \\begin{align*} d_i & = \\frac 1 {\\|w\\|} |wx_i + b| \\\\ & =-\\frac 1 {\\|w\\|} y_i(wx_i + b) \\end{align*} 则感知机损失函数可定义为 $L(w,b) = -\\sum_{x_i \\in M} y_i(wx_i + b)$ $M$：误分类点集合 损失函数是$w, b$的连续可导函数：使用$y_i$替代绝对值 损失函数$L(w,b)$梯度有 \\begin{align*} \\bigtriangledown_wL(w, b) & = -\\sum_{x_i \\in M} y_ix_i \\\\ \\bigtriangledown_bL(w, b) & = -\\sum_{x_i \\in M} y_i \\end{align*} 学习算法Stochastic Gradient Descent随机梯度下降法 输入：数据集$T$、学习率$\\eta, 0 \\leq \\eta \\leq 1$ 输出：$w,b$、感知模型$f(x)=sgn(wx+b)$ 选取初值$w_0, b_0$ 随机选取一个误分类点$(x_i, y_i)$，即$y_i(wx_i+b) \\leq 0$ ，对$w, b$进行更新 \\begin{align*} w^{(n+1)} & \\leftarrow w^{(n)} + \\eta y_ix_i \\\\ b^{(n+1)} & \\leftarrow b^{(n)} + \\eta y_i \\end{align*} $0 &lt; \\eta \\leq 1$：learning rate，学习率，步长 转2，直至训练集中无误分类点 不同初值、随机取点顺序可能得到不同的解 训练数据线性可分时，算法迭代是收敛的 训练数据不线性可分时，学习算法不收敛，迭代结果发生震荡 直观解释：当实例点被误分类，应该调整$w, b$值，使得分离 超平面向误分类点方向移动，减少误分类点与超平面距离， 直至被正确分类 学习算法对偶形式todo算法收敛性为方便做如下记号 $\\hat w = (w^T, b^T)^T, \\hat w \\in R^{n+1}$ $\\hat x = (x^T, 1)^T, \\hat x \\in R^{n+1}$ 此时，感知模型可以表示为 xw + b = \\hat w \\hat x = 0 数据集$T={(x_1, y_1), (x_2, y_2),…}$线性可分，其中： $x_i \\in \\mathcal{X = R^n}$， $y_i \\in \\mathcal{Y = {-1, +1}}$，则 存在满足条件$|\\hat w{opt}|=1$超平面 $\\hat w{opt} \\hat x = 0$将训练数据完全正确分开，且 $\\exists \\gamma &gt; 0, yi(\\hat w{opt} x_i) \\geq \\gamma$ 令$R = \\arg\\max_{1\\leq i \\leq N} |\\hat x_i|$，则 随机梯度感知机误分类次数$k \\leq (\\frac R \\gamma)^2$ 超平面存在性 训练集线性可分，存在超平面将训练数据集完全正确分开，可以 取超平面为$\\hat w_{opt} \\hat x = 0$ 令$|\\hat w_{opt}| = 1$，有 \\forall i, y_i(\\hat w_{opt} \\hat x_i) > 0可取 \\gamma = \\min_i \\{ y_i (\\hat w_{opt} \\hat x) \\}满足条件 感知机算法收敛性 给定学习率$\\eta$，随机梯度下降法第k步更新为 $\\hat wk = \\hat w{k-1} + \\eta y_i \\hat x_i$ 可以证明 $\\hat wk \\hat w{opt} \\geq k\\eta\\gamma$ \\begin{align*} \\hat w_k \\hat w_{opt} & = \\hat w_{k-1} \\hat w_{opt} + \\eta y_i \\hat w_{opt} \\hat x_i \\\\ & \\geq \\hat w_{k-1} \\hat w_{opt} + \\eta\\gamma \\\\ & \\geq k\\eta\\gamma \\end{align*} $|\\hat w_k|^2 \\leq k \\eta^2 R^2$ \\begin{align*} \\|\\hat w_k\\|^2 & = \\|\\hat w_{k-1} + \\eta y_i x_i \\|^2 \\\\ & = \\|\\hat w_{k-1}\\|^2 + 2\\eta y_i \\hat w_{k-1} \\hat x_i + \\eta^2 \\|\\hat x_i\\|^2 \\\\ & \\leq \\|w_{k-1}\\|^2 + \\eta^2 \\|\\hat x_i\\|^2 \\\\ & \\leq \\|w_{k-1}\\|^2 + \\eta^2 R^2 \\\\ & \\leq k\\eta^2 R^2 \\end{align*} 则有 \\begin{align*} k \\eta \\gamma & \\leq \\hat w_k \\hat w_{opt} \\leq \\|\\hat w\\| \\|\\hat w_{opt}\\| = \\|\\hat w\\| \\leq \\sqrt k \\eta R \\\\ k^2 \\gamma^2 & \\leq k R^2 \\end{align*} 直观理解就是超平面最大移动次数不大于最大移动距离 除以最小移动步长 $\\eta \\gamma^2$：超平面法向量最小增加量（移动步长） $\\eta R^2$：超平面法向最大增加量（移动距离） 但是超平面不可能将所有点都归为同一侧 误分类次数有上界，经过有限次搜索可以找到将训练数据完全 正确分开的分离超平面，即训练数据集线性可分时，算法的迭代 形式是收敛的","link":"/ML-Model/Linear-Model/perceptron.html"},{"title":"回归变量选择","text":"子集回归 特征子集选择独立于回归模型拟合，属于封装器特征选择 最优子集 特点 可以得到稀疏的模型 但搜索空间离散，可变性大，稳定性差 Forward Feature Elimination前向变量选择 步骤 初始变量集合$S_0 = \\varnothing$ 选择具有某种最优特性的变量进入变量集合，得到$S_1$ 第j步时，从剩余变量中选择最优变量进入集合，得到$S_{j+1}$ 若满足终止条件，则结束，否则重复上步添加变量 j达到上限 添加剩余变量均无法满足要求 Backward Feature Elimination后向变量选择 步骤 初始变量集合$S_0$包含全部变量 从变量集合中剔除具有某种最差特性变量，得到$S_1$ 第j步时，从剩余变量中剔除最差变量，得到$S_{j+1}$ 若满足终止条件，则结束，否则重复上步添加变量 j达到上限 剔除剩余变量均无法满足要求 范数正则化约束 回归过程中自动选择特征，属于集成特征选择 Ridge Regression \\min_{\\beta \\in R^n} \\left\\{ ||y - X\\beta||_2^2 + \\lambda ||\\beta||_2^2 \\right\\} 在L2范数约束下最小化残差平方 作为连续收缩方法 通过bias-variance trade-off，岭回归较普通最小二乘 预测表现更好 倾向于保留所有特征，无法产生疏系数模型 LASSO \\min_{\\beta \\in R^n} \\left\\{ ||y - X\\beta||_2^2 + \\lambda||\\beta||_1 \\right\\}能够选择部分特征，产生疏系数模型 p &gt; n时，即使所有特征都有用，LASSO也只能从中挑选n个 如果存在相关性非常高的特征，LASSO倾向于只从该组中选择 一个特征，而且是随便挑选的 极端条件下，两个完全相同的特征函数，严格凸的罚函数 （如Ridge）可以保证最优解在两个特征的系数相等，而 LASSO的最优解甚至不唯一 Elastic NetNaive Elastic Net \\begin{align*} & \\min_{\\beta \\in R^n} \\left\\{ ||y - X\\beta||_2^2 + \\lambda_1||\\beta||_1 + \\lambda_2||\\beta||_2^2 \\right\\} \\\\ \\Rightarrow & \\min_{\\beta^* \\in R^p} \\left\\{ ||y - X^*\\beta^*||_2^2 + \\lambda^*||\\beta^*||_1 \\right\\} \\\\ where: & y^* = \\begin{pmatrix} y \\\\ \\vec 0_p \\end{pmatrix} \\\\ & X^* = \\frac 1 {\\sqrt {1+\\lambda^2}} \\begin{pmatrix} X \\\\ \\sqrt {\\lambda_2} I_p \\end{pmatrix} \\\\ & \\beta^* = \\sqrt {1+\\lambda_2} \\beta \\\\ & \\lambda^* = \\frac {\\lambda_1} {1+\\lambda_2} \\\\ \\end{align*} 弹性网在Lasso的基础上添加系数的二阶范数 能同时做变量选择和连续收缩 并且可以选择一组变量 传统的估计方法通过二阶段估计找到参数 首先设置ridge系数$\\lambda_2$求出待估参数$\\beta$， 然后做lasso的收缩 这种方法有两次收缩，会导致估计偏差过大，估计不准 弹性网可以变换为LASSO，因而lasso的求解方法都可以用于 elastic net elastic_net Least Angle Regression 线性回归即找的一组系数能够用自变量的线性组合表示 因变量 Forward Selection/Forward Stepwise Regression 从所有给定predictors中选择和y相关系数绝对值最大的变量 $x_{j1}$，做线性回归 对于标准化后的变量，相关系数即为变量之间的内积 变量之间相关性越大，变量的之间的夹角越小，单个变量 能解释得效果越好 此时残差同解释变量正交 将上一步剩余的残差作为reponse，将剩余变量投影到残差上 重复选择步骤 k步之后即可选出一组变量，然后用于建立普通线性模型 前向选择算法非常贪心，可能会漏掉一些有效的解释变量，只是 因为同之前选出向量相关 Forward Stagewise前向选择的catious版本 和前向选择一样选择和y夹角最小的变量，但是每次只更新较小 步长，每次更新完确认和y夹角最小的变量，使用新变量进行 更新 同一个变量可能会被多次更新，即系数会逐渐增加 每次更新一小步，避免了前向选择的可能会忽略关键变量","link":"/ML-Model/Linear-Model/linear_regression.html"},{"title":"最大熵模型","text":"逻辑斯蒂回归逻辑斯蒂分布\\begin{align*} F(x) & = P(X \\leq x) = \\frac 1 {1 + e^{-(x-\\mu)/\\gamma}} \\\\ f(x) & = F^{'}(x) = \\frac {e^{-(x-\\mu)/\\gamma}} {\\gamma(1+e^{-(x-\\mu)/\\gamma})^2} \\end{align*} $\\mu$：位置参数 $\\gamma$：形状参数 分布函数属于逻辑斯蒂函数 分布函数图像为sigmoid curve 关于的$(\\mu, \\frac 1 2)$中心对称 F(-x+\\mu) - \\frac 1 2 = -F(x+\\mu) + \\frac 1 2 曲线在靠近$\\mu$中心附近增长速度快，两端速度增长慢 形状参数$\\gamma$越小，曲线在中心附近增加越快 模型优点 模型输出值位于0、1之间，天然具有概率意义，方便观测 样本概率分数 可以结合$l-norm$正则化解决过拟合、共线性问题 实现简单，广泛用于工业问题 分类时计算量比较小、速度快、消耗资源少 模型缺点 特征空间很大时，性能不是很好，容易欠拟合，准确率一般 对非线性特征需要进行转换 Binomial Logistic Regression Model二项逻辑斯蒂回归模型：形式为参数化逻辑斯蒂分布的二分类 生成模型 \\begin{align*} P(Y=1|x) & = \\frac {exp(wx + b)} {1 + exp (wx + b)} \\\\ P(Y=0|x) & = \\frac 1 {1 + exp(wx + b)} \\\\ P(Y=1|\\hat x) & = \\frac {exp(\\hat w \\hat x)} {1 + exp (\\hat w \\hat x)} \\\\ P(Y=0|\\hat x) & = \\frac 1 {1+exp(\\hat w \\hat x)} \\end{align*} $w, b$：权值向量、偏置 $\\hat x = (x^T|1)^T$ $\\hat w = (w^T|b)^T$ 逻辑回归比较两个条件概率值，将实例$x$归于条件概率较大类 通过逻辑回归模型，可以将线性函数$wx$转换为概率 线性函数值越接近正无穷，概率值越接近1 线性函数值越接近负无穷，概率值越接近0 Odds/Odds Ratio 在逻辑回归模型中，输出$Y=1$的对数几率是输入x的线性函数 log \\frac {P(Y=1|x)} {1-P(Y=1|x)} = \\hat w \\hat x OR在逻辑回归中意义：$x_i$每增加一个单位，odds将变为原来 的$e^{w_i}$倍 \\begin{align*} odd &= \\frac {P(Y=1|x)} {1-P(Y=1|x)} = e^{\\hat w \\hat x} \\\\ OR_{x_i+1 / x_i} &= e^{w_i} \\end{align*} 对数值型变量 多元LR中，变量对应的系数可以计算相应 Conditional OR 可以建立单变量LR，得到变量系数及相应 Marginal OR 对分类型变量 可以直接计算变量各取值间对应的OR 变量数值化编码建立模型，得到变量对应OR 根据变量编码方式不同，变量对应OR的含义不同，其中 符合数值变量变动模式的是WOE线性编码 策略极大似然：极小对数损失（交叉熵损失） \\begin{align*} L(w) & = log \\prod_{i=1}^N [\\pi(x_i)]^{y_i} [1-\\pi(x_i)]^{1-y_i} \\\\ & = \\sum_{i=1}^N [y_i log \\pi(x_i) + (1-y_i)log(1-\\pi(x_i))] \\\\ & = \\sum_{i=1}^N [y_i log \\frac {\\pi(x_i)} {1-\\pi(x_i)} log(1-\\pi(x_i))] \\\\ & = \\sum_{i=1}^N [y_i(\\hat w \\hat x_i) - log(1+exp(\\hat w \\hat x_i))] \\end{align*} $\\pi(x) = P(Y=1|x)$ 算法 通常采用梯度下降、拟牛顿法求解有以上最优化问题 Multi-Nominal Logistic Regression Model多项逻辑斯蒂回归：二项逻辑回归模型推广 \\begin{align*} P(Y=j|x) & = \\frac {exp(\\hat w_j \\hat x)} {1+\\sum_{k=1}^{K-1} exp(\\hat w_k \\hat x)}, k=1,2,\\cdots,K-1 \\\\ P(Y=K|x) & = \\frac 1 {1+\\sum_{k=1}^{K-1} exp(\\hat w_k \\hat x)} \\end{align*} 策略、算法类似二项逻辑回归模型 Generalized Linear ModeltodoMaximum Entropy Model最大熵原理最大熵原理：学习概率模型时，在所有可能的概率模型（分布）中， 熵最大的模型是最好的模型 使用约束条件确定概率模型的集合，则最大熵原理也可以表述为 在满足约束条件的模型中选取熵最大的模型 直观的，最大熵原理认为 概率模型要满足已有事实（约束条件） 没有更多信息的情况下，不确定部分是等可能的 等可能不容易操作，所有考虑使用可优化的熵最大化 表示等可能性 最大熵模型最大熵模型为生成模型 对给定数据集$T={(x_1,y_1),\\cdots,(x_N,y_N)}$，联合分布 P(X,Y)、边缘分布P(X)的经验分布如下 \\begin{align*} \\tilde P(X=x, Y=y) & = \\frac {v(X=x, Y=y)} N \\\\ \\tilde P(X=x) & = \\frac {v(X=x)} N \\end{align*} $v(X=x,Y=y)$：训练集中样本$(x,y)$出频数 用如下feature function $f(x, y)$描述输入x、输出y之间 某个事实 f(x, y) = \\left \\{ \\begin{array}{l} 1, & x、y满足某一事实 \\\\ 0, & 否则 \\end{array} \\right. 特征函数关于经验分布$\\tilde P(X, Y)$的期望 E_{\\tilde P} = \\sum_{x,y} \\tilde P(x,y)f(x,y) 特征函数关于生成模型$P(Y|X)$、经验分布$\\tilde P(X)$ 期望 E_P(f(x)) = \\sum_{x,y} \\tilde P(x)P(y|x)f(x,y) 期望模型$P(Y|X)$能够获取数据中信息，则两个期望值应该相等 \\begin{align*} E_P(f) & = E_{\\tilde P}(f) \\\\ \\sum_{x,y} \\tilde P(x)P(y|x)f(x,y) & = \\sum_{x,y} \\tilde P(x,y)f(x,y) \\end{align*}此即作为模型学习的约束条件 此约束是纯粹的关于$P(Y|X)$的约束，只是约束形式特殊， 需要通过期望关联熵 若有其他表述形式、可以直接带入的、关于$P(Y|X)$约束， 可以直接使用 满足所有约束条件的模型集合为 \\mathcal{C} = \\{P | E_{P(f_i)} = E_{\\tilde P (f_i)}, i=1,2,\\cdots,n \\} 定义在条件概率分布$P(Y|X)$上的条件熵为 H(P) = -\\sum_{x,y} \\tilde P(x) P(y|x) logP(y|x) 则模型集合$\\mathcal{C}$中条件熵最大者即为最大是模型 策略最大熵模型的策略为以下约束最优化问题 \\begin{array}{l} \\max_{P \\in \\mathcal{C}} & -H(P)=\\sum_{x,y} \\tilde P(x) P(y|x) logP(y|x) \\\\ s.t. & E_P(f_i) - E_{\\tilde P}(f_i) = 0, i=1,2,\\cdots,M \\\\ & \\sum_{y} P(y|x) = 1 \\end{array} 引入拉格朗日函数 \\begin{align*} L(P, w) & = -H(P) - w_0(1-\\sum_y P(y|x)) + \\sum_{m=1}^M w_m(E_{\\tilde P}(f_i) - E_P(f_i)) \\\\ & = \\sum_{x,y} \\tilde P(x) P(y|x) logP(y|x) + w_0 (1-\\sum_y P(y|x)) + \\sum_{m=1}^M w_m (\\sum_{x,y} \\tilde P(x,y)f_i(x, y) - \\tilde P(x)P(y|x)f_i(x,y)) \\end{align*} 原始问题为 \\min_{P \\in \\mathcal{C}} \\max_{w} L(P, w) 对偶问题为 \\max_{w} \\min_{P \\in \\mathcal{C}} L(P, w) 考虑拉格朗日函数$L(P, w)$是P的凸函数，则原始问题、 对偶问题解相同 记 \\begin{align*} \\Psi(w) & = \\min_{P \\in \\mathcal{C}} L(P, w) = L(P_w, w) \\\\ P_w & = \\arg\\min_{P \\in \\mathcal{C}} L(P, w) = P_w(Y|X) \\end{align*} 求$L(P, w)$对$P(Y|X)$偏导 \\begin{align*} \\frac {\\partial L(P, w)} {\\partial P(Y|X)} & = \\sum_{x,y} \\tilde P(x)(logP(y|x)+1) - \\sum_y w_0 - \\sum_{x,y}(\\tilde P(x) \\sum_{i=1}^N w_i f_i(x,y)) \\\\ & = \\sum_{x,y} \\tilde P(x)(log P(y|x) + 1 - w_0 - \\sum_{i=1}^N w_i f_i(x, y)) \\end{align*}偏导置0，考虑到$\\tilde P(x) &gt; 0$，其系数必始终为0，有 \\begin{align*} P(Y|X) & = \\exp(\\sum_{i=1}^N w_i f_i(x,y) + w_0 - 1) \\\\ & = \\frac {exp(\\sum_{i=1}^N w_i f_i(x,y))} {exp(1-w_0)} \\end{align*} 考虑到约束$\\sum_y P(y|x) = 1$，有 \\begin{align*} P_w(y|x) & = \\frac 1 {Z_w(x)} exp(\\sum_{i=1}^N w_i f_i(x,y)) \\\\ Z_w(x) & = \\sum_y exp(\\sum_{i=1}^N w_i f_i(x,y)) \\\\ & = exp(1 - w_0) \\end{align*} $Z_w(x)$：规范化因子 $f(x, y)$：特征 $w_i$：特征权值 原最优化问题等价于求解偶问题极大化问题$\\max_w \\Psi(w)$ \\begin{align*} \\Psi(w) & = \\sum_{x,y} \\tilde P(x) P_w(y|x) logP_w(y|x) + \\sum_{i=1}^N w_i(\\sum_{x,y} \\tilde P(x,y) f_i(x,y) - \\sum_{x,y} \\tilde P(x) P_w(y|x) f_i(x,y)) \\\\ & = \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^N w_i f_i(x,y) + \\sum_{x,y} \\tilde P(x,y) P_w(y|x)(log P_w(y|x) - \\sum_{i=1}^N w_i f_i(x,y)) \\\\ & = \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^N w_i f_i(x,y) - \\sum_{x,y} \\tilde P(x,y) P_w(y|x) log Z_w(x) \\\\ & = \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^N w_i f_i(x,y) - \\sum_x \\tilde P(x) log Z_w(x) \\end{align*}记其解为 w^{*} = \\arg\\max_w \\Psi(w)带入即可得到最优（最大熵）模型$P_{w^{*}}(Y|X)$ 策略性质 已知训练数据的经验概率分布为$\\tilde P(X,Y)$，则条件概率 分布$P(Y|X)$的对数似然函数为 \\begin{align*} L_{\\tilde P}(P_w) & = N log \\prod_{x,y} P(y|x)^{\\tilde P(x,y)} \\\\ & = \\sum_{x,y} N * \\tilde P(x,y) log P(y|x) \\end{align*} 这里省略了系数样本数量$N$ 将最大熵模型带入，可得 \\begin{align*} L_{\\tilde P_w} & = \\sum_{x,y} \\tilde P(y|x) logP(y|x) \\\\ & = \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^N w_i f_i(x,y) - \\sum_{x,y} \\tilde P(x,y)log Z_w(x) \\\\ & = \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^N w_i f_i(x,y) - \\sum_x \\tilde P(x) log Z_w(x) \\\\ & = \\Psi(w) \\end{align*}对偶函数$\\Psi(w)$等价于对数似然函数$L_{\\tilde P}(P_w)$， 即最大熵模型中，对偶函数极大等价于模型极大似然估计 改进的迭代尺度法 思想 假设最大熵模型当前参数向量$w=(w_1,w_2,\\cdots,w_M)^T$ 希望能找到新的参数向量（参数向量更新） $w+\\sigma=(w_1+\\sigma_1,\\cdots,w_M+\\sigma_M)$ 使得模型对数似然函数/对偶函数值增加 不断对似然函数值进行更新，直到找到对数似然函数极大值 对给定经验分布$\\tilde P(x,y)$，参数向量更新至$w+\\sigma$ 时，对数似然函数值变化为 \\begin{align*} L(w+\\sigma) - L(w) & = \\sum_{x,y} \\tilde P(x,y) log P_{w+\\sigma}(y|x) - \\sum_{x,y} \\tilde P(x,y) log P_w(y|x) \\\\ & = \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^M \\sigma_i f_i(x,y) - \\sum_x \\tilde P(x) log \\frac {Z_{w+\\sigma}(x)} {Z_w(x)} \\\\ & \\geq \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^M \\sigma_i f_i(x,y) + 1 - \\sum_x \\tilde P(x) \\frac {Z_{w+\\sigma}(x)} {Z_w(x)} \\\\ & = \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^M \\sigma_i f_i(x,y) + 1 - \\sum_x \\tilde P(x) \\sum_y P_y(y|x) exp(\\sum_{i=1}^M \\sigma_i f_i(x,y)) \\end{align*} 不等式步利用$a - 1 \\geq log a, a \\geq 1$ 最后一步利用 \\begin{align*} \\frac {Z_{w+\\sigma}(x)} {Z_w(x)} & = \\frac 1 {Z_w(x)} \\sum_y exp(\\sum_{i=1}^M (w_i + \\sigma_i) f_i(x, y)) \\\\ & = \\frac 1 {Z_w(x)} \\sum_y exp(\\sum_{i=1}^M w_i f_i(x,y) + \\sigma_i f_i(x,y)) \\\\ & = \\sum_y P_w(y|x) exp(\\sum_{i=1}^n \\sigma_i f_i(x,y)) \\end{align*} 记上式右端为$A(\\sigma|w)$，则其为对数似然函数改变量的 一个下界 L(w+\\sigma) - L(w) \\geq A(\\sigma|w) 若适当的$\\sigma$能增加其值，则对数似然函数值也应该 增加 函数$A(\\sigma|w)$中因变量$\\sigma$为向量，难以同时 优化，尝试每次只优化一个变量$\\sigma_i$，固定其他变量 $\\sigma_j$ 记 f^{**} (x,y) = \\sum_i f_i(x,y)考虑到$f_i(x,y)$为二值函数，则$f^{**}(x,y)$表示所有特征 在$(x,y)$出现的次数，且有 A(\\sigma|w) = \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^M \\sigma_i f_i(x,y) + 1 - \\sum_x \\tilde P(x) \\sum_y P_w(y|x) exp(f^{**}(x,y) \\sum_{i=1}^M \\frac {\\sigma_i f_i(x,y)} {f^{**}(x,y)}) 考虑到$\\sum_{i=1}^M \\frac {f_i(x,y)} {f^{**}(x,y)} = 1$， 由指数函数凸性、Jensen不等式有 exp(\\sum_{i=1}^M \\frac {f_i(x,y)} {f^{**}(x,y)} \\sigma_i f^{**}(x,y)) \\leq \\sum_{i=1}^M \\frac {f_i(x,y)} {f^{**}(x,y)} exp(\\sigma_i f^{**}(x,y))则 A(\\sigma|w) \\geq \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^M \\sigma_i f_i(x,y) + 1 - \\sum_x \\tilde P(x) \\sum_y P_w(y|x) \\sum_{i=1}^M \\frac {f_i(x,y)} {f^{**}(x,y)} exp(\\sigma_i f^{**}(x,y)) 记上述不等式右端为$B(\\sigma|w)$，则有 L(w+\\sigma) - L(w) \\geq B(\\sigma|w)其为对数似然函数改变量的一个新、相对不紧的下界 求$B(\\sigma|w)$对$\\sigma_i$的偏导 \\frac {\\partial B(\\sigma|w)} {\\partial \\sigma_i} = \\sum_{x,y} \\tilde P(x,y) f_i(x,y) - \\sum_x \\tilde P(x) \\sum_y P_w(y|x) f_i(x,y) exp(\\sigma_i f^{**}(x,y))置偏导为0，可得 \\sum_x \\tilde P(x) \\sum_y P_w(y|x) f_i(x,y) exp(\\sigma_i f^{**}(x,y)) = \\sum_{x,y} \\tilde P(x,y) f_i(x,y) = E_{\\tilde P}(f_i)其中仅含变量$\\sigma_i$，则依次求解以上方程即可得到 $\\sigma$ 算法 输入：特征函数$f_1, f_2, \\cdots, f_M$、经验分布 $\\tilde P(x)$、最大熵模型$P_w(x)$ 输出：最优参数值$wi^{*}$、最优模型$P{w^{*}}$ 对所有$i \\in {1,2,\\cdots,M}$，取初值$w_i = 0$ 对每个$i \\in {1,2,\\cdots,M}$，求解以上方程得$\\sigma_i$ 若$f^{**}(x,y)=C$为常数，则$\\sigma_i$有解析解 \\sigma_i = \\frac 1 C log \\frac {E_{\\tilde P}(f_i)} {E_P(f_i)} 若$f^{**}(x,y)$不是常数，则可以通过牛顿法迭代求解 \\sigma_i^{(k+1)} = \\sigma_i^{(k)} - \\frac {g(\\sigma_i^{(k)})} {g^{'}(\\sigma_i^{(k)})} $g(\\sigma_i)$：上述方程对应函数 上述方程有单根，选择适当初值则牛顿法恒收敛 更新$w_i$，$w_i \\leftarrow w_i + \\sigma_i$，若不是所有 $w_i$均收敛，重复2 BFGS算法对最大熵模型 为方便，目标函数改为求极小 \\begin{array}{l} \\min_{w \\in R^M} f(w) = \\sum_x \\tilde P(x) log \\sum_{y} exp(\\sum_{i=1}^M w_i f_i(x,y)) - \\sum_{x,y} \\tilde P(x,y) \\sum_{i=1}^M w_i f_i(x,y) \\end{array} 梯度为 \\begin{align*} g(w) & = (\\frac {\\partial f(w)} {\\partial w_i}, \\cdots, \\frac {\\partial f(w)} {\\partial w_M})^T \\\\ \\frac {\\partial f(w)} {\\partial w_M} & = \\sum_{x,y} \\tilde P(x) P_w(y|x) f_i(x,y) - E_{\\tilde P}(f_i) \\end{align*} 算法将目标函数带入BFGS算法即可 输入：特征函数$f_1, f_2, \\cdots, f_M$、经验分布 $\\tilde P(x)$、最大熵模型$P_w(x)$ 输出：最优参数值$wi^{*}$、最优模型$P{w^{*}}$ 取初值$w^{(0)}$、正定对称矩阵$B^{(0)}$，置k=0 计算$g^{(k)} = g(w^{(k)})$，若$|g^{(k)}| &lt; \\epsilon$， 停止计算，得到解$w^{*} = w^{(k)}$ 由拟牛顿公式$B^{(k)}p^{(k)} = -g^{(k)}$求解$p^{(k)}$ 一维搜索，求解 \\lambda^{(k)} = \\arg\\min_{\\lambda} f(w^{(k)} + \\lambda p_k) 置$w^{(k+1)} = w^{(k)} + \\lambda^{(k)} p_k$ 计算$g^{(k+1)} = g(w^{(k+1)})$，若 $|g^{(k+1)}| &lt; \\epsilon$，停止计算，得到解 $w^{*} = w^{(k+1)}$，否则求 B^{(k+1)} = B^{(k)} - \\frac {B^{(k)} s^{(k)} (s^{(k)})^T B^{(k)}} {(s^{(k)})^T B^{(k)} s^{(k)}} + \\frac {y^{(k)} (y^{(k)})^T} {(y^{(k)})^T s^{(k)}} $s^{(k)} = w^{(k+1)} - w^{(k)}$ $y^{(k)} = g^{(k+1)} - g^{(k)}$ 置k=k+1，转3","link":"/ML-Model/Linear-Model/maximum_entropy.html"},{"title":"CMD说明","text":"CMD说明CMD字体要求 CMD/Powershell对字体要求比较严格 等宽字体 不能为斜体字体 不能有A或C负空间 若是TrueType字体，则必须是FF_MODERN 若不是TrueType字体，则必须是OEM_CHARSET 对于CJK（亚洲字体），还有额外附加条件 若不是TrueType字体，字体名必须是Terminal 若是TrueType字体，必须使用亚洲语言字符集 在字体元信息里声明支持CP936","link":"/Tool/Windows/cmd.html"},{"title":"MSYS配置","text":"功能Ctags https://ctag.sourceforge.net下载ctag.exe 加入/path/to/mingw64/bin","link":"/Tool/Windows/msys.html"},{"title":"PowerPoint 技巧","text":"插入元素插入网页 WebView加载项：可以在ppt应用市场中获取 只支持https页面 本地页面都不支持 尝试自建https服务器（自签发证书）失败 可以在编辑状态查看页面效果 在OFFICE2010及以前不可用 Microsoft Web Browser控件 调用IE渲染页面，因此网页对IE的兼容性很重要 控件不会自动加载网页，需要通过VB通过触发事件调用其 Navigate2方法加载网页，所以只有在ppt播放页面才能 看到实际效果123456789101112// 页面切换事件// 注意不要`Private Sub`，否则事件不会被触发// 若想手动触发可以使用button控件的`CommandButton&lt;X&gt;_Click`事件Sub OnSlideShowPageChange() Dim FileName As String FileName = &quot;&lt;FILENAME&gt;&quot; // `WebBrowser1`：控件名称，唯一（单个slide内）标识控件 // `ActivePresentation.PATH`：当前工作目录（未保存文件返回空）， // 浏览器默认`http://`协议 // `Navigate`方法可能会无法加载 WebBrowser1.Navigate2(ActivePresentation.PATH + &quot;/&quot; + &quot;&lt;FILENAME&gt;&quot;)End Sub","link":"/Tool/Windows/ppt.html"},{"title":"Excel技巧","text":"EXCEL密码破解VBAProject密码 vbaProject.bin中密码对应字段 DPB：当前已存在密码，后跟加密密码值 xls：97-03格式表格是RAR格式压缩文件 解压之后再次压缩一般无法正常打开，应该是有特殊的压缩 规则 可以直接用编辑器打开、修改整个文件，但要注意以二进制 格式打开 xlsm：07之后带宏表格是ZIP压缩文件 解压之后再次zip打包也无法正常打开，但是zip格式可以 直接替换其中文件，所以可以直接修改单个文件 vim对zip格式文件处理类型文件夹，所以使用vim二进制打开 可以修改其中单个文件 修改二进制文件 处理方法：将密码对应字段“无效” 需要保持文件前后大小不改变 密码字段无效化 “删除”密码字段 将DPB字段替换为等长其他名称 密码无法被正常识别 文件大小没有改变，仅字符被替换 再次打开文件，启用宏会报错 不断点击确认之后即可查看vba工程 为vba工程设置新密码，覆盖替换后错误字段，保存 可得已知密码文件 右键VBAProject 工程属性 保护 查看工程属性密码：修改为新密码即可 替换密码字段 将DPB后密码值替换为其他值 为保证文件大小不变 若新密码较短需要用0填充不足部分 较原始密码长则无需额外操作 打开文件则可以使用已知密码查看vba工程 1234567891011 # 二进制打开文件，否则vim会做某些处理，损坏文件$ vim -b &lt;file&gt; # 调用xxd转换字符格式为16进制 # 可看到16进制、字符对应格式 # 仅修改左侧16进制有效，修改右侧字符表示不影响文件 # 内容$ !%xxd # 16进制转换回原始表示$ !%xxd -r VBA脚本穷举密码 xls格式：打开VBA编辑器执行代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566'移除VBA编码保护Sub MoveProtect() Dim FileName As String FileName = Application.GetOpenFilename(&quot;Excel文件（*.xls &amp; *.xla）,*.xls;*.xla&quot;, , &quot;VBA破解&quot;) If FileName = CStr(False) Then Exit Sub Else VBAPassword FileName, False End IfEnd Sub '设置VBA编码保护Sub SetProtect() Dim FileName As String FileName = Application.GetOpenFilename(&quot;Excel文件（*.xls &amp; *.xla）,*.xls;*.xla&quot;, , &quot;VBA破解&quot;) If FileName = CStr(False) Then Exit Sub Else VBAPassword FileName, True End IfEnd Sub Private Function VBAPassword(FileName As String, Optional Protect As Boolean = False) If Dir(FileName) = &quot;&quot; Then Exit Function Else FileCopy FileName, FileName &amp; &quot;.bak&quot; End If Dim GetData As String * 5 Open FileName For Binary As #1 Dim CMGs As Long Dim DPBo As Long For i = 1 To LOF(1) Get #1, i, GetData If GetData = &quot;CMG=&quot;&quot;&quot; Then CMGs = i If GetData = &quot;[Host&quot; Then DPBo = i - 2: Exit For Next If CMGs = 0 Then MsgBox &quot;请先对VBA编码设置一个保护密码...&quot;, 32, &quot;提示&quot; Exit Function End If If Protect = False Then Dim St As String * 2 Dim s20 As String * 1 '取得一个0D0A十六进制字串 Get #1, CMGs - 2, St '取得一个20十六制字串 Get #1, DPBo + 16, s20 '替换加密部份机码 For i = CMGs To DPBo Step 2 Put #1, i, St Next '加入不配对符号 If (DPBo - CMGs) Mod 2 &lt;&gt; 0 Then Put #1, DPBo + 1, s20 End If MsgBox &quot;文件解密成功......&quot;, 32, &quot;提示&quot; Else Dim MMs As String * 5 MMs = &quot;DPB=&quot;&quot;&quot; Put #1, CMGs, MMs MsgBox &quot;对文件特殊加密成功......&quot;, 32, &quot;提示&quot; End If Close #1End Function Sheet保护密码VBA脚本 xlsx：打开VBA编辑器执行代码 1234567Sub pj()Dim sht As WorksheetFor Each sht In Worksheetssht.Protect AllowFiltering:=Truesht.UnprotectNextEnd Sub xls：打开VBA编辑器执行代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148Public Sub AllInternalPasswords()' Breaks worksheet and workbook structure passwords. Bob McCormick' probably originator of base code algorithm modified for coverage' of workbook structure / windows passwords and for multiple passwords'' Norman Harker and JE McGimpsey 27-Dec-2002 (Version 1.1)' Modified 2003-Apr-04 by JEM: All msgs to constants, and' eliminate one Exit Sub (Version 1.1.1)' Reveals hashed passwords NOT original passwordsConst DBLSPACE As String = vbNewLine &amp; vbNewLineConst AUTHORS As String = DBLSPACE &amp; vbNewLine &amp; _&quot;Adapted from Bob McCormick base code by&quot; &amp; _&quot;Norman Harker and JE McGimpsey&quot;Const HEADER As String = &quot;AllInternalPasswords User Message&quot;Const VERSION As String = DBLSPACE &amp; &quot;Version 1.1.1 2003-Apr-04&quot;Const REPBACK As String = DBLSPACE &amp; &quot;Please report failure &quot; &amp; _&quot;to the microsoft.public.excel.programming newsgroup.&quot;Const ALLCLEAR As String = DBLSPACE &amp; &quot;The workbook should &quot; &amp; _&quot;now be free of all password protection, so make sure you:&quot; &amp; _DBLSPACE &amp; &quot;SAVE IT NOW!&quot; &amp; DBLSPACE &amp; &quot;and also&quot; &amp; _DBLSPACE &amp; &quot;BACKUP!, BACKUP!!, BACKUP!!!&quot; &amp; _DBLSPACE &amp; &quot;Also, remember that the password was &quot; &amp; _&quot;put there for a reason. Don't stuff up crucial formulas &quot; &amp; _&quot;or data.&quot; &amp; DBLSPACE &amp; &quot;Access and use of some data &quot; &amp; _&quot;may be an offense. If in doubt, don't.&quot;Const MSGNOPWORDS1 As String = &quot;There were no passwords on &quot; &amp; _&quot;sheets, or workbook structure or windows.&quot; &amp; AUTHORS &amp; VERSIONConst MSGNOPWORDS2 As String = &quot;There was no protection to &quot; &amp; _&quot;workbook structure or windows.&quot; &amp; DBLSPACE &amp; _&quot;Proceeding to unprotect sheets.&quot; &amp; AUTHORS &amp; VERSIONConst MSGTAKETIME As String = &quot;After pressing OK button this &quot; &amp; _&quot;will take some time.&quot; &amp; DBLSPACE &amp; &quot;Amount of time &quot; &amp; _&quot;depends on how many different passwords, the &quot; &amp; _&quot;passwords, and your computer's specification.&quot; &amp; DBLSPACE &amp; _&quot;Just be patient! Make me a coffee!&quot; &amp; AUTHORS &amp; VERSIONConst MSGPWORDFOUND1 As String = &quot;You had a Worksheet &quot; &amp; _&quot;Structure or Windows Password set.&quot; &amp; DBLSPACE &amp; _&quot;The password found was: &quot; &amp; DBLSPACE &amp; &quot;$$&quot; &amp; DBLSPACE &amp; _&quot;Note it down for potential future use in other workbooks by &quot; &amp; _&quot;the same person who set this password.&quot; &amp; DBLSPACE &amp; _&quot;Now to check and clear other passwords.&quot; &amp; AUTHORS &amp; VERSIONConst MSGPWORDFOUND2 As String = &quot;You had a Worksheet &quot; &amp; _&quot;password set.&quot; &amp; DBLSPACE &amp; &quot;The password found was: &quot; &amp; _DBLSPACE &amp; &quot;$$&quot; &amp; DBLSPACE &amp; &quot;Note it down for potential &quot; &amp; _&quot;future use in other workbooks by same person who &quot; &amp; _&quot;set this password.&quot; &amp; DBLSPACE &amp; &quot;Now to check and clear &quot; &amp; _&quot;other passwords.&quot; &amp; AUTHORS &amp; VERSIONConst MSGONLYONE As String = &quot;Only structure / windows &quot; &amp; _&quot;protected with the password that was just found.&quot; &amp; _ALLCLEAR &amp; AUTHORS &amp; VERSION &amp; REPBACKDim w1 As Worksheet, w2 As WorksheetDim i As Integer, j As Integer, k As Integer, l As IntegerDim m As Integer, n As Integer, i1 As Integer, i2 As IntegerDim i3 As Integer, i4 As Integer, i5 As Integer, i6 As IntegerDim PWord1 As StringDim ShTag As Boolean, WinTag As BooleanApplication.ScreenUpdating = FalseWith ActiveWorkbookWinTag = .ProtectStructure Or .ProtectWindowsEnd WithShTag = FalseFor Each w1 In WorksheetsShTag = ShTag Or w1.ProtectContentsNext w1If Not ShTag And Not WinTag ThenMsgBox MSGNOPWORDS1, vbInformation, HEADERExit SubEnd IfMsgBox MSGTAKETIME, vbInformation, HEADERIf Not WinTag ThenMsgBox MSGNOPWORDS2, vbInformation, HEADERElseOn Error Resume NextDo 'dummy do loopFor i = 65 To 66: For j = 65 To 66: For k = 65 To 66For l = 65 To 66: For m = 65 To 66: For i1 = 65 To 66For i2 = 65 To 66: For i3 = 65 To 66: For i4 = 65 To 66For i5 = 65 To 66: For i6 = 65 To 66: For n = 32 To 126With ActiveWorkbook.Unprotect Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; _Chr(l) &amp; Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; _Chr(i3) &amp; Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)If .ProtectStructure = False And _.ProtectWindows = False ThenPWord1 = Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; Chr(l) &amp; _Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)MsgBox Application.Substitute(MSGPWORDFOUND1, _&quot;$$&quot;, PWord1), vbInformation, HEADERExit Do 'Bypass all for...nextsEnd IfEnd WithNext: Next: Next: Next: Next: NextNext: Next: Next: Next: Next: NextLoop Until TrueOn Error GoTo 0End IfIf WinTag And Not ShTag ThenMsgBox MSGONLYONE, vbInformation, HEADERExit SubEnd IfOn Error Resume NextFor Each w1 In Worksheets'Attempt clearance with PWord1w1.Unprotect PWord1Next w1On Error GoTo 0ShTag = FalseFor Each w1 In Worksheets'Checks for all clear ShTag triggered to 1 if not.ShTag = ShTag Or w1.ProtectContentsNext w1If ShTag ThenFor Each w1 In WorksheetsWith w1If .ProtectContents ThenOn Error Resume NextDo 'Dummy do loopFor i = 65 To 66: For j = 65 To 66: For k = 65 To 66For l = 65 To 66: For m = 65 To 66: For i1 = 65 To 66For i2 = 65 To 66: For i3 = 65 To 66: For i4 = 65 To 66For i5 = 65 To 66: For i6 = 65 To 66: For n = 32 To 126.Unprotect Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; _Chr(l) &amp; Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)If Not .ProtectContents ThenPWord1 = Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; Chr(l) &amp; _Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)MsgBox Application.Substitute(MSGPWORDFOUND2, _&quot;$$&quot;, PWord1), vbInformation, HEADER'leverage finding Pword by trying on other sheetsFor Each w2 In Worksheetsw2.Unprotect PWord1Next w2Exit Do 'Bypass all for...nextsEnd IfNext: Next: Next: Next: Next: NextNext: Next: Next: Next: Next: NextLoop Until TrueOn Error GoTo 0End IfEnd WithNext w1End IfMsgBox ALLCLEAR &amp; AUTHORS &amp; VERSION &amp; REPBACK, vbInformation, HEADEREnd Sub","link":"/Tool/Windows/excel.html"},{"title":"VSCode基础","text":"Settings VSCode配置文件分为两种（其中项目会重复） User Settings：用户对所有项目的配置 Workspace Settings：针对当前项目的设置 配置方式分为两种完全相同 UI：提示丰富 JSON：配置快捷，JSON字典格式 Command PalettePython 选择默认python环境 Terminal 选择默认terminal，可能的terminal包括cmd、powershell、 WSL（若启用Linux子系统） Original SettingTerminal12345678{ &quot;terminal.integrated.shell.windows&quot;：&quot;/path/to/shell&quot;, // 默认shell &quot;terminal.integrated.shellArgs.windows&quot;: [ ], &quot;terminal.integrated.shellArgs.linux&quot;: [ ], &quot;terminal.integrated.shellArgs.osx&quot;: [ ], // VSCode创建terminal启动参数（3系统分别配置）} VSCode terminal分为很integrated、external VSCode应该是兼容所有terminal shell，如 C:/Windows/System32/cmd.exe C:/Windows/System32/powershell.exe C:/Windows/System32/wsl.exe：WSL启用 “/path/to/git/bin/bash.exe”：Git中bash等 VSCode terminal虽然兼容多种shell，但只能创建默认shell 需要多种shell只能切换默认shell再创建 python shell等shell是特殊shell，无法默认创建，必须要 在命令面板中创建（虽然在普通shell中打开python环境， 但是VSCode不认可） Python1234567891011{ &quot;python.condaPath&quot;: &quot;/path/to/conda/Scripts&quot;, // conda安装目录Scripts文件夹 &quot;python.venvPath&quot;: &quot;/path/to/conda/envs&quot;, // 虚拟环境目录，VSCode会在其中查找虚拟环境，作为 // Command Palette中的备选项 &quot;python.pythonPath&quot;: &quot;/path/to/python.exe&quot;, // 默认python解释器路径 &quot;python.terminal.activateEnvironment&quot;: true, // 创建python shell时，尝试中激活虚拟环境} python.terminal.activateEnviroment激活的虚拟环境由 python.pythonPath决定 VSCode会尝试执行python.pythonPath同级中 Scripts/activate.bat激活虚拟环境 因此虚拟环境需要安装conda，否则没有 Scripts/ativate.bat无法正常激活默认虚拟环境 CPPC配置文件 .vscode/c_cpp_properties.json 123456789101112131415161718192021{ &quot;configurations&quot;: [ { &quot;name&quot;: &quot;WSL&quot;, &quot;includePath&quot;: [ &quot;${workspaceFolder}/**&quot; ], &quot;defines&quot;: [ &quot;LOCAL&quot;, &quot;_DEBUG&quot;, &quot;UNICODE&quot;, &quot;_UNICODE&quot; ], &quot;compilerPath&quot;: &quot;/usr/bin/gcc&quot;, &quot;cStandard&quot;: &quot;c11&quot;, &quot;cppStandard&quot;: &quot;c++14&quot;, &quot;intelliSenseMode&quot;: &quot;gcc-x64&quot; } ], &quot;version&quot;: 4} C/C++项目基本配置 .vscode/tasks.json：利用VSCode的Tasks功能调用WSL的 GCC/G++编译器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566{ // tasks.json // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ { &quot;label&quot;: &quot;Build&quot;, &quot;command&quot;: &quot;g++&quot;, &quot;args&quot;: [ &quot;-g&quot;, &quot;-Wall&quot;, &quot;-std=c++14&quot;, &quot;/mnt/c/Users/xyy15926/Code/cppc/${fileBasename}&quot;, &quot;-o&quot;, &quot;/mnt/c/Users/xyy15926/Code/cppc/a.out&quot;, &quot;-D&quot;, &quot;LOCAL&quot; ], &quot;problemMatcher&quot;: { &quot;owner&quot;: &quot;cpp&quot;, &quot;fileLocation&quot;: [ &quot;relative&quot;, &quot;${workspaceRoot}&quot; ], &quot;pattern&quot;: { &quot;regexp&quot;: &quot;^(.*):(\\\\d+):(\\\\d+):\\\\s+(warining|error):\\\\s+(.*)$&quot;, &quot;file&quot;: 1, &quot;line&quot;: 2, &quot;column&quot;: 3, &quot;severity&quot;: 4, &quot;message&quot;: 5 } }, &quot;type&quot;: &quot;shell&quot;, &quot;group&quot;: { &quot;kind&quot;: &quot;build&quot;, &quot;isDefault&quot;: true }, &quot;presentation&quot;: { &quot;echo&quot;: true, &quot;reveal&quot;: &quot;silent&quot;, &quot;focus&quot;: true, &quot;panel&quot;: &quot;shared&quot; } }, { &quot;label&quot;: &quot;Run&quot;, &quot;command&quot;: &quot;/mnt/c/Users/xyy15926/Code/cppc/a.out&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;dependsOn&quot;: &quot;Build&quot;, &quot;group&quot;: { &quot;kind&quot;: &quot;test&quot;, &quot;isDefault&quot;: true }, &quot;presentation&quot;:{ &quot;echo&quot;: true, &quot;reveal&quot;: &quot;always&quot;, &quot;focus&quot;: true, &quot;panel&quot;: &quot;shared&quot;, &quot;showReuseMessage&quot;: true } } ]} 这里为方便将运行程序任务同&gt; Task: Run Test Task 任务关联，可以在命令面板执行此指令 .vscode/launch.json：gdb调试配置 123456789101112131415161718192021222324252627282930313233343536373839{ // launch.json // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;name&quot;: &quot;(gdb) Bash on Windows Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;/mnt/c/Users/xyy15926/Code/cppc/a.out&quot;, &quot;args&quot;: [&quot;-f&quot;, &quot;Threading&quot;], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;/mnt/c/Users/xyy15926/Code/cppc/&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: true, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;pipeTransport&quot;: { &quot;debuggerPath&quot;: &quot;/usr/bin/gdb&quot;, &quot;pipeProgram&quot;: &quot;C:\\\\windows\\\\system32\\\\bash.exe&quot;, &quot;pipeArgs&quot;: [&quot;-c&quot;], &quot;pipeCwd&quot;: &quot;&quot; }, &quot;setupCommands&quot;: [ { &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: false } ], &quot;sourceFileMap&quot;: { &quot;/mnt/c&quot;: &quot;c:\\\\&quot;, &quot;/mnt/d&quot;: &quot;d:\\\\&quot; }, &quot;preLaunchTask&quot;: &quot;Build&quot; }, ]} Git1234{ &quot;git.ignore.MissingGitWarning&quot;: true, &quot;git.path&quot;: &quot;/path/to/xxxgit.exe&quot;} “git.path”既可以是windows下Git，也可以是“伪装”Git，使用 工具wslgit，让VSCode 直接使用WSL内的Git KeyMapper &lt;c-s-\\&gt;`：新建默认terminal绘画 &lt;c-s-p&gt;：command palette","link":"/Tool/Editor/vscode.html"},{"title":"网络设置","text":"VMware网络模式虚拟网络组件虚拟交换机Virtual Network Editor中默认有三个虚拟交换机 VMnet0(Bridged)：桥接模式下的虚拟交换机 VMnet1(Host-only)；仅主机模式下的虚拟交换机 VMnet8(NAT)：NAT模式下虚拟交换机 虚拟网卡在宿主机上安装完成VMware后，在网络适配器中会安装有两块 虚拟网卡 VMware Network Adapter VMnet1：主机模式下虚拟网卡 VMware Network Adapter VMnet8：NAT模式下虚拟网卡 卸载虚拟网卡后，可以Virtual Network Editor-&gt;还原默认设置， 还原虚拟网卡 Bridged桥接模式：将主机网卡同虚拟机网卡利用虚拟网桥进行通信 网络结构 在桥接作用下，类似从物理主机虚拟出一个交换机 所有桥接设置的虚拟机都连接到这个交换机的接口上 物理主机也同样连接在此交换机上 虚拟机就像是外部局域网中的独立主机，同宿主机逻辑上 同等地位 网络连通性 所以桥接下的网卡与网卡的都是交换模式的， 可以相互访问，不受干扰 虚拟机可以在外部网络上可见 机器网络配置 虚拟机IP地址需要和宿主机在同一网段（外网网段） 需要手动配置虚拟机配置IP地址、子网掩码 若需要联网，虚拟机Gateway、DNS需要和主机一致 适用场景 利用VMware在局域网中新建虚拟服务器，位局域网提供网络服务 网络环境ip资源充裕 网络设置 宿主机网络连接 网络连接属性中VMware Bridge Protocal是否勾选 （安装VMware后一般会默认勾选） 确认宿主机：IP、Gateway、DNS 虚拟机网络设置 编辑虚拟机设置-&gt;网络适配器-&gt;Bridged/桥接模式 虚拟机网卡配置：网卡配置文件方式参见config_file IP地址要和宿主机IP在同一网段 Gateway默认网关要和宿主机一致 NATNetwork Address Translation：网络地址转换，借助 虚拟NAT设备、虚拟DHCP服务器，使得虚拟机能够联网 网络结构 主机网卡与虚拟NAT设备相连 虚拟NAT设备、虚拟DHCP服务器、虚拟机共同连接在虚拟 交换机VMnet8上 VMnet8通过虚拟网卡VMware Network Adapter VMnet8和 宿主机相连，宿主机成为双网卡主机，同时参与宿主网络 和虚拟网络 网络连通性 借助虚拟NAT设备连通宿主机网卡、虚拟机，实现了 虚拟机通过宿主机网卡联网，所以虚拟机在外部网络 不可见 VNAV8连通宿主机、虚拟机，使得宿主机可以和虚拟机连通 ，要注意此时宿主机双网卡，连通虚拟局域网的网卡是虚拟 网卡 虚拟网卡只是起连通虚拟机、宿主机的作用，卸载不影响 虚拟机连通外网 机器网络配置 由于虚拟DHCP服务器的存在，虚拟机无需特殊配置，只需要 启用虚拟机网卡DHCP服务即可 适用场景 虚拟系统介入互联网简单，不需要其他配置，只需要宿主机能 访问网络即可 网络ip资源紧缺，且需要虚拟机能够联网 网络配置 宿主机服务设置 检查宿主机VMware DHCP Service、VMware NAT Service 服务是否启动（VMware安装一般默认启动此服务） Virtual Network Eidtor配置 VMnet8虚拟交换机默认为NAT模式 配置VMnet8-&gt;子网IP、VMnet8-&gt;子网掩码 配置VMnet8-&gt;NAT设置、VMnet8-&gt;DHCP参数 虚拟机网络配置 编辑虚拟机设置-&gt;网络适配器-&gt;NAT模式 虚拟机网卡配置 NAT虚拟网络有DHCP服务，只需要修改BOOTPRPOTO=dhcp， 使用DHCP协议即可 也可以设置静态ip，但是需要注意要在DHCP范围内 Host-Only仅主机模式：将虚拟机与外网隔开，使得虚拟机成为独立系统，只和 主机相互通讯 网络结构：类似于NAT模式 NAT模式去除了虚拟NAT设备 使用VMware Network Adapter VMnet1虚拟网卡连接宿主机 、VMnet1交换机 虚拟局域网可以认为是单独从属当前宿主机的私有网络 连通性 虚拟机网络、真实网络相互隔离，两者不相互连通 宿主机、虚拟机相互通过虚拟网卡VNAV1相互连接 事实上，可以在宿主机中设置，通过将主机网卡共享给 虚拟网卡VNAV1实现虚拟机联网 适用场景 特殊的网络调试环境下，要求真实环境、虚拟环境隔离开 网络设置 虚拟机网络设置 编辑虚拟机设置-&gt;网络适配器-&gt;Host-only/仅主机模式 Virtual Network Eidtor配置：类似于NAT模式，只是VMnet1 虚拟交换机才默认为Host-only模式 虚拟机网卡配置：类似NAT模式 共享宿主机网卡Host-only模式下下，虚拟局域网默认无法联网，需要将宿主机网卡 共享给给虚拟网卡VNAV8才能实现联网 网络连接-&gt;属性-&gt;共享-&gt;选择VMAV1 共享宿主机网卡可能会要强制修改虚拟网卡VMAV1的ip地址， 需要根据提示在虚拟网络编辑其中修改虚拟网络的DHCP参数 然后修改虚拟网卡Gateway、DNS为VMAV1的ip地址","link":"/Tool/Windows/vmware_network.html"},{"title":"Windows Linux Subsystem","text":"说明WSL是一个兼容层，类似反过来的Wine，但更底层 Linux、Windows程序不兼容，是因为二者内核提供的接口不同 如ls/dir命令 在Linux下调用getdents内核调用 在Windows下调用NtQueryDirectoryFile内核调用 WSL提供Linux内核接口，并转换为NT内核接口 在WSL中执行ls仍然调用getdents WSL收到请求，将系统调用转换为NT内核接口 NTQueryDirectoryFile NT内核收到WSL请求，返回执行结果 WSL将结果包装后返回 毕相较于真正Linux系统仍然有不足 Docker等涉及未实现的内核特性软件如法使用 Raw socket相关相关操作容易出错 I/O性能相对孱弱 Cygwin对比 Cygwin提供了完整的POSIX系统调用API（以运行库 Cygwin*.dll形式提供，但是仍然工作在User Mode Cygwin将POSIX系统调用转换为Win32 API（因为其架设在 Win32子系统上），很多内核操作（如：fork）受限于 Win32实现 Linux应用程序必须链接到Cynwin*.dll，需要修改源码 重新编译后才能执行，这样应用程序才不会直接请求内核， 而是调用Cygwin运行库，且编译出的可执行文件为 Win32 PE格式封装，只能在Windows下执行 WSL中Linux应用程序进程被包裹在Pico Process中，其发出的 所有系统调用会被直接送往Kernel Mode中的 lxcore.sys、lxss.sys WSL将POSIX系统调用转换为更底层的NP API调用（WSL和 Win32平行，直接架设在NT内核上） 可以直接执行ELF格式封装的Linux可执行程序 启用 控制面板 -&gt; 程序和功能 -&gt; 启用或关闭windows功能 -&gt; 适用于Linux的Windows子系统 其他 子系统可以替换为其他非官方支持发行版，如 archlinux) WSL可以可以通过X Server执行GUI应用程序 https://news.ycombinator.com/item?id=13603451 WSl官博 https://blogs.msdn.microsoft.com/wsl/ https://blogs.msdn.microsoft.com/commandline/tag/wsl/ 使用进入WSL除在图形界面中点击图标，以默认参数启动，还可以在terminal （cmd/powershell等）自定义进入WSL参数 wsl.exe：打开默认发行版中默认shell distroname.exe：打开指定发行版中默认shell bash.exe：打开默认发行版中bash shell 这些应用程序默认在path中，可以直接执行 版本管理 wslconfig.exe可以用于管理多个子系统的发行版 WSL、Windows互操作文件 Windows所有盘符挂载在WSL中/mnt目录下 WSL中所有数据存放在%HOME%/AppData/Local/Packages/{linux发行包名}/LocalState/rootfs中 不要在Windows下直接修改，造成权限错误 命令 在cmd中直接调用WSL命令12PS&gt; wsl [-e] ls -al // wsl带参数执行 在WSL中调用Windows命令行程序（在$PATH中） 12$ which ipconfig.exe$ ipconfig.exe 在WSL中启动Windows应用（在$PATH中） 1$ notepad.exe 通过pipes通信 12$ cat foo.txt | clip.exePS&gt; ipconfig | wsl grep IPv4 端口、环境变量 WSL与Windows共享端口（NT内核？） WSL继承Windows的部分环境变量，如：PATH Terminal推荐 wsl-terminal： 专为WSL开发的终端模拟器，基于mintty、wslbridge，稳定 易用 ConEmu：老牌终端模拟器， 功能强大 Hyper：基于Electron的跨平台 终端模拟器 WSL-Terminal WSL-Terminal中包含一些快捷工具 tools目录中包含一些脚本，可以通过wscripts.exe 执行修改注册列表，添加一些功能 添加WSL中vim、emacs等打开到右键菜单 添加在WSL中打开文件夹到右键菜单 run-wsl-file.exe可以用于在快捷执行wsl脚本，只需要 将其选择为文件打开方式 vim.exe可以用WSL中vim打开任何文件，当然一般是配合 tools/中脚本在右键注册后使用 配置 配置文件etc/wsl-terminal.conf 主题文件etc/themes/ mintty配置文件etc/mintty https://zhuanlan.zhihu.com/p/22033219 因为wslbridge的原因，WSL-Terminal必须在NTFS文件系统中 使用 mintty本身依赖cmd，包括字体等在内配置受限于cmd https://www.zhihu.com/question/36344262/answer/67191917、 https://www.zhihu.com/question/38752831 其他问题文件权限问题 在WSL中，windows实现了两种文件系统用于支持不同使用场景 VolFsVolFs：着力于在windows文件系统上提供完整的linux文件系统特性 ，通过各种手段实现了对Inodes、Directory Entries、 File Objects、File Descriptors、Special File Types 的支持 为支持Inodes，VolFS会把文件权限等信息保存在 NTFS Extended Attributes中 在Windows中新建的文件缺少此扩展参数，有些编辑器也会 在保存文件是去掉这些附加参数 所以不要在Windows中修改WSL文件，否则VolFs无法正确 获得文件metadata WSL中/就是VolFs文件系统 https://blogs.msdn.microsoft.com/wsl/2016/06/15/wsl-file-system-support/ https://blogs.msdn.microsoft.com/commandline/2018/01/12/chmod-chown-wsl-improvements/ DrvFsDrvFs：着力提供于Windows系统的互操作性，从Windows的文件权限 （即文件-&gt;属性-&gt;安全选项卡中的权限）推断出文件对应Linux权限 所有windows盘符挂在在WSL中/mnt是都使用DrvFs文件系统 由于DrvFs文件权限继承机制很微妙，结果就是所有文件权限 都是0777 所以ls结果都是绿色的 早期DrvFs不支持metadata，在Build 17063之后支持 文件写入metadata，但是需要重新挂载磁盘 可以通过设置DrvFs metadata设置默认文件权限 12345$ sudo umount /mnt/e$ sudo mount -t drvfs E: /mnt/e -o metadata // 此时虽然支持文件权限修改，但默认权限仍然是*0777*$ sudo mount -t drvfs E: /mnt/e -o metadata,uid=1000,gid=1000,umask=22,fmask=111 // 此时磁盘中默认文件权限为*0644* 更合适的方式是通过/etc/wsl.conf配置DrvFs自动挂载属性 AutoMatically Configuring WSL1234567891011121314151617 # `/etc/wsl.conf`[automount] # 是否自动挂载enabled = true # 是否处理`/etc/fstab`文件mountFsTab = true # 挂载路径root = /mnt/ # DrvFs挂载选项，若需要针对不同drive配置，建议使用`/etc/fstab`options = &quot;metadata,umask=023,dmask=022,fmask=001&quot;[network]generateHosts = truegenerateResolvConf = true[interop] # 是否允许WSL载入windows进程enabled = trueappendWindowsPath = true 如果需要给不同盘符设置不同挂载参数，需要再修改 /etc/fstab 1E: /mnt/e drvfs rw,relatime,uid=1000,gid=1000,metadata,umask=22,fmask=111 0 0 Automatically Configuring WSL https://blogs.msdn.microsoft.com/commandline/2018/02/07/automatically-configuring-wsl/ https://devblogs.microsoft.com/commandline/automatically-configuring-wsl/","link":"/Tool/Windows/wsl.html"},{"title":"频繁项集&#x2F;序列","text":"频繁项集 频繁项集：频繁出现项集合（无序） 频繁项序列：频繁出现项序列（有序） 相关关联规则算法：数据量大时，无法直接发现频繁项集 频繁项集评估标准 评估标准 支持度：数据关联出现概率，关联数据在数据集中出现次数占 总数据集比重 Support(X, Y) = P(XY) = \\frac {num(XY)} {num(All)} 支持度高数据不一定构成频繁项集，但支持度数据肯定不能 不构成频繁项集 置信度：数据出现条件概率，某个数据出现、另一数据出现概率 Confidence(X \\Leftarrow Y) = P(X|Y) = \\frac {P(XY)} {P(Y)} 提升度：数据之间关联关系，某数据出现、另一数据出现概率同 其总体出现概率之比 \\begin{align*} Lift(X \\Leftarrow Y) & = \\frac {P(X|Y)} {P(X)} \\\\ & = \\frac {Confidence(X \\Leftarrow)}{P(X)} \\\\ & = \\frac {P(XY)} {P(X)P(Y)} \\end{align*} 提升度大于1则为有效的强关联规则，否则为无效的强关联 规则 若X、Y不相关，则提升度为1 选择频繁数据集，一般需要自定义评估标准：自定义支持度、 自定义支持度和置信度组合 AprioriApriori算法 以支持度作为评估标准，找出数据集中最大的频繁$k$项集 找到符合支持度标准的频繁$k$项集 迭代直到无法找到项数更大的频繁项集 算法 输入：数据集合D、支持度阈值$\\alpha$ 输出：最大的频繁K项集 置$k=1$，扫描整个数据集，以所有出现过数据作为候选1项集 挖掘候选$k$项集 扫描数据、计算候选$k$项集支持度 去除支持度低于阈值$\\alpha$的项集得到频繁$k$项集 若频繁$k$项集只包含1项，直接返回 若频繁$k$项集为空，返回频繁$k-1$项集 基于频繁$k$项集连接、生成候选$k+1$项集 置$k=k+1$ 需要频繁扫描数据、效率低 频繁项集的子项集肯定也是频繁项集 FPTree/FPGrowthFPTree：对Apriori算法改进，不在需要多次扫描数据 FPTree引入部分数据结构以临时存储数据 项头表：按频繁1项集出现频数降序排列的表 FP Tree：包含原始数据、频数的多叉树 节点链表：链接项头表中频繁1项集、FPTree中相应节点 的链表 特点：效率高 只需要扫描两次数据 使用多叉树存储临时数据，利用高频频繁项集 算法 建立项头表 扫描数据，得到所有1项集频数、剔除支持度低于阈值者， 并按支持度（频数）降序排列 第二次扫描数据，剔除每条数据中非频繁1项集、 在每条数据内部按支持度降序排列 建立FPTree：逐条读取处理后排序后数据，依次插入树中 每条数据中排序靠前者为祖先节点 若有直系公共祖先则公共祖先节点计数+1 新节点通过链表和项头表链接 挖掘FPTree：对项表头中每项，找到其条件模式基 将子树中每个节点计数置为叶子节点计数和，则子树中节点 取值即为其与当前项组合出现频数/支持度 删除（当前子树内）支持度/频数低于支持度阈值$\\alpha$ 节点 剩余节点项、当前项组合即为相应频繁$k$项集 条件模式基：节点作为叶子节点所对应的FP子树 Prefix-Projected Pattern GrowthPrefixSpan：前缀投影模式挖掘 以支持度为标准，挖掘数据集中频繁序列 每条数据为若干项集组成的序列，序列内项集间有序 为方便，每条数据序列中项集中的项已排序 可以将每条数据序列整体视为串 频繁序列：频繁出现子序列 算法 输入：序列数据集$S$、支持度$\\alpha$ 所有满足阈值要求的频繁序列 找出所有长度1前缀（即所有项）、对应投影 计数、剔除持度小于阈值$\\alpha$者，得到频繁1项序列 置$k=1$ 对每个长度为$k$前缀递归挖掘 若前缀对应投影为空，返回 若前缀对应投影中所有项支持度均小于阈值$\\alpha$，返回 同满足阈值要求阈值$\\alpha$要求项合并，得到新前缀 置$k=k+1$ prefix：前缀，正在处理的子序列 projected：投影，各数据序列中位于前缀之后子串 ?串","link":"/ML-Model/Unsupervised-Model/associating.html"},{"title":"Auto-Encoders","text":"自编码机/稀疏编码/堆栈自编码器 起源：编码理论可以应用于视觉皮层感受野，大脑主要视觉皮层 使用稀疏原理创建可以用于重建输入图像的最小基函数子集 优点 简单技术：重建输入 可堆栈多层 直觉型，基于神经科学研究 缺点 贪婪训练每层 没有全局优化 表现较监督学习差 多层容易失效 输入的重建可能不是学习通用表征的理想metric","link":"/ML-Model/Unsupervised-Model/auto_encoder.html"},{"title":"聚类","text":"聚类算法聚类：按照某特定标准（如距离准则）把数据集分割成不同类、簇， 簇内数据相似性尽可能大、不同簇间数据对象差异性仅可能大 属于无监督学习，目标是把相似的样本聚集在一起 通常只需要给定相似度的计算即可 无需使用训练数据学习 聚类算法分类 基于划分 Hierarchical Methods：基于层次 基于密度 基于网络 基于模型 模糊聚类 基于约束 基于粒度 谱聚类 核聚类 量子聚类 衡量聚类算法优劣 算法的处理能力 处理大数据的能力 处理噪声数据能力 处理任意形状数据的能力，如：有间隙的嵌套数据 算法是否需要预测条件 聚类数目 相关领域知识 输入数据关联性 结果是否和数据输入顺序相关 对数据维度敏感性（是否能处理高维数据） 对数据类型要求 Hierarchical Methods层次聚类 自底向上合并的层次聚类 最底层开始，通过合并最相似类簇形成上层类簇 全部数据点合并到同一类簇、或达到终止条件时结束 自顶向下分裂的层次聚类 从包含全部数据点的类簇开始，递归分裂出最相异的下层 类簇 每个类簇仅包含单个数据点时结束 优点 可解释性好：如需要创建分类方法时 研究表明能产生高质量聚类，可以应用在较大K的K-means 后的合并阶段 可以解决非球形类簇 缺点 时间复杂度高$O(N^2 log N)$（$N$为数据点数目） 贪心算法无法取得最优解 距离选择参见ml_tech/#todo AGENSAGENS：自下向上层次聚类 组连接：组与组之间距离 single linkage average linkage complete linkage 算法复杂度：$n^2logn$ 流程 每个数据点视为一类，计算两两直接最小距离 合并距离最小两个两类别为新类 重新计算新类、所有类之间距离 重复以上，直至所有类合并为一类 Divisive AnalysisDIANA：自定向下层次聚类 算法流程 所有数据归为一组$C_1=(p_1, p_2, dots, p_n)$ 计算所有点之间的距离矩阵，选择到其他点平均距离最大的点， 记为$q$，取该点作为新组起始点 $\\forall p, p \\notin C_1$，计算 $d_arg(p, C_1) - d_arg(p, C_2)$， 若小于零则属于$C_1$，否则属于$C_2$ Balanced Itertive Reducing and Clustering Using HierarchiesBIRCH：利用层次方法的平衡迭代规约和聚类，利用层次方法聚类 、规约数据 特点 利用CF树结构快速聚类 只需要单遍扫描数据 适合在数据类型为数值型、数据量大时使用 常见算法、改进 A Hierarchical Clustering Algorithm Using Dynamic Modeling：使用KNN算法计算作为linkage、构建图 较BIRCH好，但算法复杂度依然为$O(n^2)$ 可以处理比较复杂形状 Partition-Based Methods基于划分的方法 基本流程 确定需要聚类的数目，挑选相应数量点作为初始中心点 再根据预定的启发式算法队数据点做迭代 直到达到类簇内点足够近、类簇间点足够远 优点 对大型数据集同样简单高效、时空复杂度低 缺点 数据集越大，结果容易越容易陷入局部最优 需要预先设置k值，对初始k中心点选取敏感 对噪声、离群点敏感 只适合数值性 不适合非凸形状 影响结果因素 原始问题是否可分 分类数目K 初始点选择 K-means 数据：$\\Omega={X_1, X_2, \\dots, X_N}$，分k个组 C_1, C_2, \\dots, C_k \\\\ C_1 \\cup C_2 \\cup \\dots \\cup C_k = \\Omega \\\\每个样本点包含p个特征：$X_i = (x_1, x_2, \\dots, x_p)$ 目标：极小化每个样本点到聚类中心距离之和 \\arg_{C_1, C_2, \\dots, C_K} \\min \\sum_{i=1}^K \\sum_{x_j in \\C_i} d(x_j, C_i) 若定义距离为平方欧式距离，则根据组间+组内=全， 极小化目标就是中心点距离极大化 优化问题是NP-hard问题，需要采用近似方法 K值选择 经验选择 特殊方法：Elbow Method，肘部法则，画出距离和K的点图， 选择剧烈变化的点的K值 Lloyd’s Algorithm 随机选择K对象，每个对象初始地代表类簇中心 对剩余对象，计算与各簇中心距离，归于距离最近地类簇 重新计算各类簇平均值作为新簇中心 不断重复直至准则函数收敛 算法时间效率：$\\in O(K * N^{\\pi})$ 常见算法、改进 K-means++、Intelligent K-means、Genetic K-means：改进 K-means对初值敏感 K-medoids、K-medians：改进K-means对噪声、离群点敏感 K-modes：适用于分类型数据 Kernel-Kmeans：可以解决非凸问题 Density-Based Methods基于密度的方法 优点 对噪声不敏感 能发现任意形状聚类 缺点 聚类结果和参数关系很大 相关概念 核心点：半径eps的邻域内点数量不少于阈值MinPts的点 直接可达：核心点半径eps的领域内被称为直接可达 没有任何点是由非核心点直接可达的 可达：若存在$p_1, \\cdots, p_n$点列中相邻点直接可达， 则$p_1, p_n$可达 非对称关系，因为核心点没有直接可达点 连接性：若存在点$o$可达$p,q$，则$p,q$称为[密度]连接 对称关系 聚类内点都是相连接的 若p由q可达，则p在q所属聚类中 局外点：不由任何点可达的点 DBSCAN Density-Based Spatial Clustering of Applications with Noise 算法流程 从任意对象点p开始 寻找合并核心点p对象直接密度可达对象 若p是核心点，则找到聚类 若p是边界，则寻找下个对象点 重复直到所有点被处理 说明 DBSCAN用固定参数识别聚类，类簇稀疏程度不同时，相同判断 标准会破坏类自然结构 较稀疏类簇会被划分为多个 密度大距离近多个类被合并 参数影响 eps过大大多数点聚为同一簇中、过小则会导致簇分裂 MinPts值过大则同簇中点被标记为噪声点、过小则有大量 核心点 超参半径eps、最小点数量MinPts经验选取 计算所有点k距离 对各点k距离排序、绘制折线图 观察折线图，以发现极具变化的位置对应k距离作为半径 k即作为最小点数量 k距离：距离点第k近点距离 常见算法、改进 Ordering Points to Indentify Clustering Structure：优先 搜索高密度，然后根据高密度特点设置参数，改善DBSCAN Grid-Based Methods基于网络的方法 优点 速度快，速度与数据对象个数无关，只依赖数据空间中每维 上单元数目 可以和基于密度算法共同使用 缺点 对参数敏感 无法处理不规则分布的数据 维数灾难 聚类结果精确性低：算法效率提高的代价 流程 将数据空间划分为网格单元：不同算法主要区别 将数据对象集映射到网格单元中，计算各单元密度 根据预设的阈值判断每个网格单元是否为高密度单元 将相连的高度密度网格单元识别为类簇 常见算法、改进 statistical information grid wave-cluster clustering-quest Model-Based Methods基于模型的方法：为每个类簇假定模型，寻找对给定模型的最佳拟合 优点 对类划分以概率形式表示 每类特征可以用概率表达 缺点 执行效率不高，尤其是分布数量多、数据量少时 SOMSOM：假设输入对象中存在一些拓扑结构、顺序，可以实现从输入 空间到输入平面的降维映射，且映射具有拓扑特征保持性质 网络结构 输入层：高维输入向量 输入层：2维网络上的有序节点 学习过程 找到、更新与输入节点距离最短的输出层单元，即获胜单元 更新邻近区域权值，保持输出节点具有输入向量拓扑特征 SOM算法流程 网络初始化：初始化输出层节点权重 随机选取输入样本作为输入向量，找到与输入向量距离最小的 权重向量 定义获胜单元，调整获胜单元邻近区域权重、向输入向量靠拢 收缩邻域半径、减小学习率、重复，直到小于允许值，输出聚类 结果 常见算法 概率生成模型：假设数据是根据潜在概率分布生成 Gaussian Mixture Model 基于神经网络模型的方法 Self Organized Maps 模糊聚类模糊聚类：样本以一定概率属于某个类 优点 对正态分布的数据聚类效果较好 算法对孤立点敏感 Fuzzy C-means(FCM)FCM：对K-means的推广软聚类 算法最终输出$C$个聚类中心向量、$C*N$模糊划分矩阵 表示每个样本点对每个类的隶属度 根据划分矩阵、按照最大隶属原则确定样本点归属 聚类中心表示类平均特征，可以作为类代表 特点 算法性能依赖初始聚类中心，需要依赖其他算法快速确定 初始聚类中心、或多次执行算法 不能确保收敛于最优解 soft cluster：点可以属于多个类 参数选择 聚类数目$C$：$C$远远小于聚类样本总数目，且大于1 柔性参数$m$ $m$过大：聚类效果差 $m$过小：算法接近HCM聚类算法 算法流程 标准化数据矩阵 建立模糊相似矩阵，初始化隶属矩阵 迭代，直到目标函数收敛到极小值 w_k(x_i) = \\frac 1 \\sum_{i=1}^k (\\frac {d(x_i, \\mu_k)} {d(x_i, \\mu_i} )^{1/(m-2)}) 根据迭代结果，由最终隶属矩阵确定数据所属类，得到聚类结果 常见算法、改进 HCM算法 基于约束的算法基于约束的算法：考虑聚类问题中的约束条件，利用约束知识进行 推理 约束 对聚类参数的约束 对数据点的约束 典型算法 Clustering with Obstructed Distance：用两点之间障碍 距离取代一般的欧式距离计算最小距离 量子聚类量子聚类：用量子理论解决聚类过程中初值依赖、确定类别数目的 问题 典型算法 基于相关点的Pott自旋、统计机理提供的量子聚类模型： 将聚类问题视为物理系统 核聚类核聚类：增加对样本特征的优化过程，利用Mercer核把输入空间映射 至高维特征空间，在特征空间中进行聚类 特点 方法普适 性能上优于经典聚类算算法 可以通过非线性映射较好分辨、提取、放大有用特征 收敛速度快 典型算法 SVDD算法 SVC算法 谱聚类谱聚类：建立在图论中谱图理论基础上，本质是将聚类问题转换为 图的最优划分问题 基本流程 根据样本数据集定义描述成对数据点的相似度亲和矩阵 计算矩阵特征值、特征向量 选择合适的特征向量聚类不同点","link":"/ML-Model/Unsupervised-Model/clustering.html"},{"title":"Batch Normalization","text":"Internal Covariate ShiftICS：由于网络参数变化，引起内部节点（输入）数据分布发生变化的过程 网络中层与层之间高度耦合，具有强关联性 网络中任意层都可以视为单独网络 上层输入可视为作为当前层外部输入 随训练进行，网络中参数不断发生改变 任意层中参数变化会导致之后层输入发生改变 高层需要不断适应输入分布的改变，即其输入分布性质影响 该层训练 由此导致模型训练困难 负面影响 上层网络需要不断调整输入适应数据分布变换，降低网络学习 效率 输入数据量级不稳定、各维度数据量级差距不稳定 降低学习效率 小量级维度参数要求更小的学习率 否则参数可能在最优解附近反复波动 容易出现梯度消失，难以训练饱和非线性模型 大量级维度训练过程中容易陷入梯度饱和区，参数更新 速度慢，减缓网络收敛速度 训练过程中参数更新更有可能使得输入移向激活函数 饱和区 且该效应随着网络深度加深被进一步放大 参数初始化需要更复杂考虑 还可以使用非饱和激活函数ReLU等避免陷入梯度饱和区 Batch NormalizationBatch Normalization：规范化batch数据，使样本各维度 标准化，即均值为0、方差为1 \\begin{align*} \\y & = BN_{\\gamma, \\beta}(z) = \\gamma \\odot \\hat z + \\beta \\\\ \\hat z & = \\frac {z - E(z)} {\\sqrt {Var(z) + \\epsilon}} \\end{align*} $B$：mini-batch $z, y$：某层输入向量、规范化后输入向量 （即以个神经元中激活前标量值$z=Wx+b$为一维） $\\odot$：逐元素乘积 $E(x)$：均值使用移动平均均值 $Var(x)$：方差使用移动平均无偏估计 $\\gamma, \\beta$：待学习向量，用于恢复网络的表示能力 $\\epsilon$：为数值计算稳定性添加 BN可以视为whitening的简化 简化计算过程：避免过高的运算代价、时间 保留数据信息：未改变网络每层各特征之间相关性 BN层引入可学习参数$\\gamma, \\beta$以恢复数据表达能力 Normalization操作缓解了ICS问题，使得每层输入稳定 ，也导致数据表达能力的缺失 输入分布均值为0、方差为1时，经过sigmoid、tanh激活 函数时，容易陷入其线性区域 $\\gamma = \\sqrt {Var(z)}, \\beta = E(z)$时为等价变换 ，并保留原始输入特征分布信息 Whitening：白化，对输入数据变换使得各特征同均值、 同方向、不相关，可以分为PCA白化、ZCA白化 训练 规范化在每个神经元内部非线性激活前$z=Wu$进行，而不是 [也]在上一层输出$u$上进行，即包含BN最终为 z = act(BN(Wu)) $act$：激活函数 偏置$b$：可以被省略，BN中减去均值 $u$的分布形状可以在训练过程中改变 而$u$两次正则化无必要 $z=Wu$分布更可能对称、稠密、类似高斯分布 以batch统计量作为整体训练样本均值、方差估计 每层均需存储均值、方差的移动平均统计量用于测试时 归一化测试数据 对卷积操作，考虑卷积特性，不是只为激活函数（即卷积核） 学习$\\gamma, \\beta$，而是为每个feature map学习 （即每个卷积核、对每个特征图层分别学习） 预测 预测过程中各参数（包括均值、方差）为定值，BN仅仅对数据 做了线性变换 使用训练总体的无偏统计量对测试数据归一化 （训练时存储） \\begin{align*} \\mu_{test} & = E(\\mu_{batch}) \\\\ \\sigma^2_{test} = \\frac m {m-1} E(\\sigma^2_{batch}) \\end{align*} 还可以使用样本指数加权平均统计量 用途 BN通过规范化输入数据各维度分布减少ICS，使得网络中每层 输入数据分布相对稳定 实现网络层与层之间的解耦 方便迁移学习 加速模型学习速度：后层网络无需不断适应输入分布变化， 利于提高神经网络学习速度 降低模型对网络超参数、初始值敏感度，使得网络学习更加稳定 简化调参过程 允许使用更大的学习率提高学习效率 \\begin{align*} BN(Wu) & = BN((aW)u) \\\\ \\frac {\\partial BN(aWu)} {\\partial u} & = \\frac {\\partial BN(Wu)} {\\partial u} \\\\ \\frac {BN(aWu)} {\\partial aW} & = \\frac 1 a \\frac {\\partial BN(Wu)} {\\partial W} \\end{align*} $a$：假设某层权重参数变动$a$倍 激活函数函数输入不受权重$W$放缩影响 梯度反向传播更稳定，权重$W$的Jacobian矩阵将包含接近 1的奇异值，保持梯度稳定反向传播 允许网络使用饱和激活函数（sigmoid、tanh等），而不至于 停滞在饱和处，缓解梯度消失问题 深度网络的复杂性容易使得网络变化积累到上层网络中， 导致模型容易进入激活函数梯度饱和区 有正则化作用，提高模型泛化性能，减少对Dropout的需求 不同batch均值、方差有所不同，为网络学习过程增加随机 噪声 与Dropout关闭神经元给网络带来噪声类似，一定程度上 有正则化效果 Layer Normalization层归一化：假设非线性激活前的输入随机变量分布接近，可以直接 基于每层所有非线性激活前输入估计均值、方差 \\begin{align*} \\mu^l & = \\frac 1 H \\sum_{i=1}^H h_i^l \\\\ \\sigma^l &= \\sqrt {\\frac 1 H \\sum_{i=1}^H (h_i^l - \\mu^l)^2} \\\\ h^l & = W^l x^{l-1} + b^l \\\\ LN(h^l) & = \\frac {g^l} {\\sigma^l} \\odot (h^l - \\mu^l) + b^l \\\\ x^l & = g(LN(h^l)) \\end{align*} $h^l$：第$l$隐层激活前值 $\\mu^l, \\sigma^l$：第$l$隐层对应LN均值、方差 （标量，是同层神经元激活前值统计量） 相对于BN，其适应范围更广 循环神经网络中，BN无法处理长于训练序列的测试序列 BN无法应用到在线学习、超大分布式模型任务，此时训练 batch较小，计算的均值、方差无法有效代表训练总体 LN假设非线性激活前输入随机变量分布接近，而CNN网络中图像 边缘对应kernel大量隐藏单元未被激活，假设不成立，所以 CNN网络中LN效果没有BN效果好","link":"/ML-Technique/Neural-Network/batch_normalization.html"},{"title":"激活函数","text":"指数类Sigmoid将实数映射到(0, 1)区间 sigmoid(z) = \\frac 1 {1+e^{-z}} $z= wx+b$ 用途 隐层神经元输出 二分类输出 缺点 激活函数计算量大，BP算法求误差梯度时，求导涉及除法 误差反向传播时容易出现梯度消失 函数收敛缓慢 Hard_Sigmoid计算速度比sigmoid激活函数快 hard_signmoid(z) = \\left \\{ \\begin {array} {l} 0 & z < -2.5 \\\\ 1 & z > 2.5 \\\\ 0.2*z + 0.5 & -2.5 \\leq z \\leq 2.5 \\\\ \\end {array} \\right. $z= wx+b$ Softmax主要用于多分类神经网络输出 softmax(z_i) = \\frac {e^{z_i}} {\\sum_{k=1}^K e^{z_k}} $z_i = w_i x + b_i$：$(w_i, b_i)$组数同分类数量，和输入 $x$维度无关 $K$：分类数目 工程意义：指数底 可导$max$：拉开数值之间差距 特征对输出结果为乘性：即$z_i$中输入增加会导致输出 随对应权重倍数增加 联合交叉熵损失避免导数溢出，提高数值稳定性 理论意义：概率论、最优化 softmax符合最大熵原理 假设各标签取值符合多元伯努利分布，而softmax是其 link functiond的反函数#todo 光滑间隔最大函数 Softmax回归参数$(w_i, b_i$$冗余，可以消去一组 Softplus softplus(z) = log(exp(z)+1) $z = wx + b$ Tanh双曲正切函数 \\begin{align*} tanh(z) & = \\frac {sinhz} {coshz} \\\\ & = \\frac {e^z - e^{-z}} {e^z + e^{-z}} \\\\ \\end{align*} $z = wx + b$ $\\frac{\\partial tanh(z)}{\\partial z} = (1 - tanh(z))^2$ ：非常类似普通正切函数，可以简化梯度计算 线性类Softsign softsign(z) = \\frac z {abs(z) + 1)}ReLURectfied Linear Units：修正线性单元 relu(z, max) = \\left \\{ \\begin{array} {l} 0 & z \\leq 0 \\\\ z & 0 < x < max \\\\ max & z \\geq max \\\\ \\end {array} \\right.LeakyReLULeaky ReLU：带泄露的修正线性 relu(z, \\alpha, max) = \\left \\{ \\begin {array} {l} \\alpha z & z \\leq 0 \\\\ z & 0 < z < max \\\\ max & z \\geq max \\\\ \\end {array} \\right. $\\alpha$：超参，建议取0.01 解决了$z &lt; 0$时进入死区问题，同时保留了ReLU的非线性特性 Parametric ReLUPReLU：参数化的修正线性 prelu(z) = \\left \\{ \\begin{array} {l} \\alpha z & z < 0 \\\\ z & z> 0 \\\\ \\end{array} \\right. $\\alpha$：自学习参数（向量），初始值常设置为0.25，通过 momentum方法更新 ThreshholdReLU带阈值的修正线性 threshhold_relu(z, theta)= \\left \\{ \\begin{array} {l} z & z > theta \\\\ 0 & otherwise \\\\ \\end{array} \\right.Linear线性激活函数：不做任何改变 线性指数类Exponential Linear UnitElu：线性指数 elu(z, \\alpha) = \\left \\{ \\begin{array} {l} z & z > 0 \\\\ \\alpha (e^z - 1) & x \\leqslant 0 \\\\ \\end{array} \\right. $\\alpha$：超参 $x \\leq 0$时，$f(x)$随$x$变小而饱和 ELU对输入中存在的特性进行了表示，对缺失特性未作定量 表示 网络深度超超过5层时，ELU相较ReLU、LReLU学习速度更快、 泛化能力更好 Gausssion Error Liear UnitGELU：ReLU的可导版本 Selu可伸缩指数线性激活：可以两个连续层之间保留输入均值、方差 正确初始化权重：lecun_normal初始化 输入数量足够大：AlphaDropout 选择合适的$\\alpha, scale$值 selu(z) = scale * elu(z, \\alpha)梯度消失激活函数导数太小（$&lt;1$），压缩误差（梯度）变化","link":"/ML-Technique/Neural-Network/func_activation.html"},{"title":"Dropout","text":"DropoutDropout：训练时根据随机隐藏部分神经元、对应连接边避免 过拟合 固定概率丢弃Dropout最简单方法：设置固定概率p，对每个神经元以概率p判定 是否需要保留 \\begin{align*} y & = f(W * d(x) + b) \\\\ d(x) & = \\left \\{ \\begin{array}{l} m \\odot x, & 训练阶段 px, & 测试阶段 \\end{array} \\right. \\end{align*} $d(x)$：丢弃函数 $m \\in {0, 1}^d$：丢弃掩码，通过概率为p的伯努利 分布随机生成 $p$可以设置为0.5，对大部分网络、任务比较有效 此时随机生成多的网络最具多样性 训练时 激活神经元数量为原来的p倍 每个batch分别进行drop，相当于对每个batch都有独特网络 测试时 所有神经元都被激活，造成训练、测试时网络输出不一致， 需将每个神经元输出乘p避免 也相当于把不同网络做平均 在预测时，类似bagging技术将多个模型组合 只是类似，各个drop后的子网并不独立，在不同子网中相同 神经元的权重相同 多个模型组合组合可以一定程度上抵消过拟合 因为在训练时子网中部分神经元被drop，剩余部分权重相较 完全网络有$\\frac 1 {1-p}$，所以在完整网络中，各部分 权重需要$ * (1-p)$ 讲道理应该是隐藏部分神经元而不是连接，否则会使神经元偏向 某些输入，还不如隐藏部分神经元，这样可以让神经元随机降低 样本权重，理论上能减弱过拟合 丢弃方法 输入层神经元丢弃率更接近1，使得输入变化不会太大 输入层神经元丢失时，相当于给数据增加噪声，提高网络 稳健性 循环神经网络丢弃 不能直接丢弃隐状态，会损害循环网络在时间维度上的记忆 能力 简单方法：可以考虑对非循环连接进行随机丢弃 变分丢弃法：根据贝叶斯对丢弃法是对参数的采样解释， 采样参数需要每个时刻保持不变 需要对参数矩阵的每个元素随机丢弃 所有时刻使用相同的丢弃掩码 解释 集成学习解释 每次丢弃，相当于从原网络采样得到子网络 每次迭代，相当于训练不同的子网络，共享原始网络参数 最终网络可以近似看作是集成了指数个不同网络的组合模型 贝叶斯学习解释 对需要学习的网络$y = f(x, \\theta)$，贝叶斯学习假设 参数$\\theta$为随机向量 设先验分布为$q(\\theta)$，贝叶斯方法预测为 \\begin{align*} E_{q(\\theta)}[y] & = \\int_q f(x, \\theta) q(\\theta) d\\theta \\\\ & \\approx \\frac 1 M \\sum_{m=1}^M f(x, \\theta_m) \\end{align*} $f(x, \\theta_m)$：第$m$次应用丢弃方法的网络 $\\theta_m$：对全部参数的采样","link":"/ML-Technique/Neural-Network/dropout.html"},{"title":"K-Nearest Neighor","text":"K-NN 输入：p维实例特征向量 将样本点视为p维特征空间的中点 输出：实例类别，可以取多类别 基本思想 在已有数据中找到与$X_0$相似的若干个观测 $(X_1, X_2, …, X_k)$，称为$X_0$的近邻 对近邻$(X_1, X_2, …, X_k)$的输出变量 $(y_1, y_2, …, y_k)$，计算诸如算术平均值 （加权平均值、中位数、众数），作为新观测$X_0$输出 变量取值$y_0$的预测值 特点 k近邻不具有显式学习过程、简单、直观 不需要假设$y=f(X)$函数体形式，实际上是利用训练数据集 对特征空间进行划分 局部方法k-NN是一种“局部”方法，仅适合特征空间维度较低的情况 给定k的情况下，在高维空间中，需要到更远的区域寻找近邻， 局部性逐渐丧失，近似误差变大 如：n个观测均匀分布在超立方体中，确定k后即确定$X_0$需要 寻找的近邻个数占总观测的比率r，即近邻覆盖的体积 考虑$X_0$在原点，则近邻分布的小立方体边期望长度为 Ed_p(r) = r^{1/p} \\\\ Ed_3(0.1) = 0.1^{1/3} = 0.46 \\\\ Ed_10(0.1)d = 0.1^{1/10} = 0.79 \\\\ Ed_10(0.01) = 0.1^{1/10} = 0.63 \\\\ 可以看出：减少近邻比例（数量）没有帮助，还会使得近似 误差变大，只能通过增大样本量解决 特征选择有必要 特征选择 变量本身考察 low variance filter：剔除标准差小于阈值数值型变量 missing values ratio：剔除缺失值大于阈值的变量 剔除众数比率大于阈值的分类型变量 变量与输出变量相关性角度考察 high correlation filter 对预测误差影响角度考察 Wrapper方法：逐个选择使错误率、均方误差下降最快变量 ，可使用Forward Feature Elimination k-NN模型K-NN是使用模型：实际上对应于特征空间的划分 模型包括3个基本要素，据此划分特征空间，确定特征空间中 每个点所属类 k值选择 距离度量：参见data_science/ref/functions 分类决策规则 k值选择k值选择对k-NN方法有重大影响 较小k值：相当于使用较小邻域中训练实例进行预测 复杂模型，容易发生过拟合 approximation error较小：只有于输入实例近、相似的 训练实例才会对预测结果有影响 estimation error较大：预测结果对近邻实例点非常敏感 较大k值：相当于使用较大邻域中训练实例进行预测 简单模型 估计误差较小 近似误差较大：同输如实例远、相似程度差的训练实例也会 对预测结果有影响 k=1只使用一个近邻做预测 找到距离$X_0$最近的近邻$X_i$，用其取值作为预测值 模型简单、效果较理想 尤其适合特征空间维度较低、类别边界不规则情况 只根据单个近邻预测，预测结果受近邻差异影响极大，预测 波动（方差）大，稳健性低 预测错误的概率不高于普通贝叶斯方法的两倍 \\begin{align*} P_e & = (1-p(y=1|X=X_0))P(y=1|X=X_0) + (1-p(y=0|X=X_0))P(y=0|X=X_0) \\\\ & = 2P(y=1|X=X_0)(1-P(y=1|X=X_0)) \\\\ & \\leq 2(1-P(y=1|X=X_0)) \\\\ \\end{align*} $P(y=1|X=X_0)$：普通贝叶斯方法做分类预测，预测结果 为1的概率 1-NN方法犯错的概率就是$X_0$、$X_i$二者实际值不同的 概率？？？？ k=N使用训练样本整体做预测 无论输入实例，预测结果完全相同 对分类预测，预测结果为“众数” 对回归预测，预测结果为“平均数” 模型过于简单、效果不好 忽略训练实例中大量信息 “稳健性”极好：预测值基本不受近邻影响，无波动 决策规则分类决策规则Majority Voting Rule多数表决规则：等价于经验风险最小化 分类损失函数为0-1损失函数，分类函数为 $f: \\mathcal{R^n} \\rightarrow {c_1, c_2, \\cdots}$ 误分类概率$P(Y \\neq f(X)) = 1 - P(Y=f(X))$ 给定实例$x \\in \\mathcal{X}$的误分率为 \\frac 1 k \\sum_{x \\in N_k(x)} I(y_i \\neq c_j) = 1 - \\frac 1 k \\sum_{x \\in N_k(x)} I(y_i = c_j) $N_k(x)$：最近邻k个实例构成集合 $c_j$：涵盖$N_k(x)$区域的类别 $I$：指示函数 为使误分率（经验风险）最小，应选择众数 经验风险的构造中，前提是近邻被认为属于相同类别$c_j$， 当然这个假设是合理的，因为k-NN方法就是认为近邻类别相同， 并使用近邻信息预测 $c_j$的选择、选择方法是模型选择的一部分，不同的$c_j$会 有不同的经验风险 数值决策规则算法 实现k近邻法时，主要问题是对训练数据进行快速k近邻搜索， 尤在特征空间维数大、训练数据量大 考虑使用特殊的结构存储训练数据，减少计算距离次数，提高 k近邻搜索效率 linear scan线性扫描：最简单的实现方法 需要计算输入实例与每个训练实例的距离，训练集较大时计算 非常耗时 kd树最近邻搜索 输入：已构造kd树 输出：x的最近邻 在kd树种找出包含目标点x的叶节点的 从根节点出发，比较对应坐标，递归进行访问，直到叶节点 为止 目标点在训练样本中不存在，必然能够访问到叶节点 以此叶节点为“当前最近点” 目标点在此叶节点中点所在的区域内，且区域内只有该 叶节点中点 回溯，并在每个节点上检查 如果当前节点保存实例点比当前最近点距离目标的更近， 更新该实例点为“当前最近点” 检查该节点另一子区域是否可能具有更近距离的点 即其是否同以目标点为圆心、当前最短距离为半径圆 相交 只需要比较目标点和相应坐标轴距离和最短距离即可 若二者相交，则将目标节点视为属于该子区域中点， 进行最近邻搜索，递归向下查找到相应叶节点，重新 开始回退 若二者不相交，则继续回退 退回到根节点时，搜索结束，最后“当前最近点”即为最近邻点 这里涉及到回溯过程中，另一侧子域是否访问过问题，可以通过 标记、比较相应轴坐标等方式判断 k&gt;1的情况类似，不过检测时使用最远近邻，新近邻需要和所有 原近邻依次比较 加权k-NN变量重要性计算变量的加权距离，重要变量赋予较高权重 变量重要性：Backward Feature Elimination得到各变量 重要性排序 FI_{(i)} = e_i + \\frac {1} {p} \\quad \\\\ w_{(i)} = \\frac {FI_{(i)}} {\\sum_{j=1}^p FI_{(j)}} $e_i$：剔除变量i之后的均方误差（错误率） 加权距离：$dw(x,y)=\\sqrt {\\sum{i=1}^{p} w^{(i)}(x_i - y_i)^2}$ 观测相似性目标点的k个近邻对预测结果不应有“同等力度”的影响，与$X_0$越 相似的观测，预测时重要性（权重）越大 权重：用函数$K(d)$将距离d转换相似性，$K(d)$应该有特性 非负：$K(d) \\geqslant 0, d \\in R^n$ 0处取极大：$max K(d) = K(0)$ 单调减函数，距离越远，相似性越小 核函数符合上述特征 且研究表明除均匀核外，其他核函数预测误差差异均不明显 步骤 依据函数距离函数$d(Z_{(i)}, Z_0)$找到$X_0$的k+1个近邻 使用第k+1个近邻距离作为最大值，调整距离在0-1之间 D(Z_{(i)}, Z_0) = \\frac {d(Z_{(i)}, Z_0)} {d(Z_{(k+1)}, Z_0)}, \\quad i=1,2,...,k 依据函数$w_i=K(d)$确定k各近邻的权重 预测 回归预测\\hat{y}_0 = \\frac 1 k (\\sum_{i=1}^k w_iy_i) 分类预测：多数表决原则 \\hat{y}_0 = max_r (\\sum_{i=1}^k w_iI(y_i=r)) \\\\ P(\\hat{y}_0=r|X_0)= \\frac {\\sum_{i=1}^k w_iI(y_i=r)} {\\sum_{i=1}^k w_i} Approximate Nearest Neighbor相似最近邻","link":"/ML-Model/Nolinear-Model/k_nearest_neighbors.html"},{"title":"参数优化","text":"参数初始化 合适参数初始化可以加速模型训练 避免反向传播的梯度信息被放大、缩小 导致出现梯度爆炸、消失 参数初始化值满足如下条件，则训练过程中能较好防止梯度信号被放缩 \\begin{align*} E(a^{(l-1)}) & = E(a^{(l)}) \\\\ Var(a^{(l-1)}) & = Var(a^{(l)}) \\end{align*} 激活值均值为 0 每层激活值方差保持一致 常数（零值）初始化常数初始化：将所有权值初始化为常数 任意常数初始化方法性能都不好，甚至无法训练 反向传播算法更新参数时，各参数各维度导数一致、更新后权值一致 各神经元在演化过程中对称，无法学习不同特征，退化为单神经元 在激活函数选择线性激活函数时 过大的初始化权重可能导致梯度爆炸 过小的初始化值可能导致梯度消失 随机初始化随机初始化：随机生成参数 权重 $W$：均值 0、方差 1 的正态分布生成，并乘以较小常数（如：0.01） 权值被初始化不同值，解决零值初始化存在网络退化问题 但较小权值可能导致梯度弥散，无法学习 偏置 $b$：初始化为 0 帮助变换系统初始处于线性域，加快梯度传播 Xavier 初始化Xavier 初始化：适合 tanh 激活函数的参数初始化方式 Var(W^{(l)}) = \\frac 2 {n^{(l-1)} + n^{(l)}} $n^{(l)}$：第 $l$ 层神经元数量 He 初始化He 初始化：适合 ReLU 激活函数的参数初始化方式 Var(W^{(l)}) = \\frac 1 {n^{(l)}} 基于 Xavier 初始化在 ReLU 上的改进，实际中二者都可以使用 超参搜索Random SearchGrid SearchBayesian Optimization","link":"/ML-Technique/param_adj.html"},{"title":"Model Enhancement","text":"Emsemble Learning 集成学习：训练多个基模型，并将其组合起来，以达到更好的 预测能力、泛化能力、稳健性 base learner：基模型，基于独立样本建立的、一组 具有相同形式的模型中的一个 组合预测模型：由基模型组合，即集成学习最终习得模型 源于样本均值抽样分布思路 $var(\\bar{X}) = \\sigma^2 / n$ 基于独立样本，建立一组具有相同形式的基模型 预测由这组模型共同参与 组合预测模型稳健性更高，类似于样本均值抽样分布方差 更小 关键在于 获得多个独立样本的方法 组合多个模型的方法 分类 homogenous ensemble：同源集成，基学习器属于同一类型 bagging boosting heterogenous ensemble：异源集成，基学习器不一定属于同 一类型 [genralization] stacking Target Data parallel Classifier Aggregation Bagging 减少方差 基于boostrap随机抽样，抗异常值、噪声 模型间并行 同源不相关基学习器，一般是树 分类：投票、回归：平均 Boosting 减少偏差 基于误分分步 模型间串行 同源若学习器 加权投票 Stacking 减少方差、偏差 K折交叉验证数据、基学习器输出 层内模型并行、层间串行 异质强学习器 元学习器 以上都是指原始版本、主要用途 Boosting提升方法：将弱可学习算法提升为强可学习算法的组合元算法 属于加法模型：即基函数的线性组合 各模型之间存在依赖关系 分类Boosting 依次学习多个基分类器 每个基分类器依之前分类结果调整权重 堆叠多个分类器提高分类准确率 boosting通过组合多个误分率略好于随机猜测的分类器得到 误分率较小的分类器，因此boosting适合这两类问题 个体之间难度有很大不同，boosting能够更加关注较难的 个体 学习器对训练集敏感，boosting驱使学习器在趋同的、 “较难”的分布上学习，此时boosting就和bagging一样能够 使得模型更加稳健（但原理不同） boosting能减小预测方差、偏差、过拟合 直觉上，使用在不同的样本上训练的基学习器加权组合， 本身就能减小学习器的随机变动 基于同样的理由，boosting同时也能减小偏差 过拟合对集成学习有些时候有正面效果，其带来多样性， 使模型泛化能力更好，前提是样本两足够大，否则小样本 仍然无法提供多样性 回归Boosting 依次训练多个基学习器 每个基学习器以之前学习器拟合残差为目标 堆叠多个学习器减少整体损失 boosting组合模型整体损失（结构化风险） R_{srm} = \\sum_{i=1}^N l(y_i, \\hat y_i) + \\sum_{t=1}^M \\Omega(f_t) $l$：损失函数 $f_t$：基学习器 $\\Omega(f_t)$：单个基学习器的复杂度罚 $N, M$：样本数目、学习器数目 基学习器损失 obj^{(t)} = \\sum_{i=1}^N l(y_i, \\hat y_i^{(t)}) + \\Omega(f_t) 最速下降法使用线性函数拟合$l(y_i, \\hat y_i^{(t)})$ \\begin{align*} obj^{(t)} & = \\sum_i^N l(y_i, \\hat y_i^{(t-1)} + f_t(x_i)) + \\Omega(f_t) \\\\ & \\approx \\sum_{i=1}^N [l(y_i, \\hat y^{(t-1)}) + g_i f_t(x_i)] + \\Omega(f_t) \\end{align*} $gi = \\partial{\\hat y} l(y_i, \\hat y^{t-1})$ 一次函数没有极值 将所有样本损失视为向量（学习器权重整体施加），则负梯度 方向损失下降最快，考虑使用负梯度作为伪残差 Newton法使用二次函数拟合$l(y_i, \\hat y_i^{(t)}$ \\begin{align*} obj^{(t)} & = \\sum_i^N l(y_i, \\hat y_i^{(t-1)} + f_t(x_i)) + \\Omega(f_t) \\\\ & \\approx \\sum_{i=1}^N [l(y_i, \\hat y^{(t-1)}) + g_i f_t(x_i) + \\frac 1 2 h_i f_t^2(x_i)] + \\Omega(f_t) \\\\ \\end{align*} $hi = \\partial^2{\\hat y} l(y_i, \\hat y^{t-1})$ 二次函数本身有极值 可以结合复杂度罚综合考虑，使得每个基学习器损失达到最小 Boosting&amp;Bagging 基分类器足够简单时，boosting表现均显著好于bagging 仅靠单次决策（单个属性、属性组合）分类 使用C4.5树作为基分类器时，boosting仍然具有优势，但是不够 有说服力 结论来自于Experiments with a New Boosting Algorithm Boosting&amp;Bagging 基分类器足够简单时，boosting表现均显著好于bagging 仅靠单次决策（单个属性、属性组合）分类 使用C4.5树作为基分类器时，boosting仍然具有优势，但是不够 有说服力 结论来自于Experiments with a New Boosting Algorithm 原理probably approximately correct：概率近似正确，在概率近似 正确学习的框架中 strongly learnable：强可学习，一个概念（类），如果存在 一个多项式的学习算法能够学习它，并且正确率很高，那么 就称为这个概念是强可学习的 weakly learnable：弱可学习，一个概念（类），如果存在 一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测 略好，称此概念为弱可学习的 Schapire证明：在PAC框架下强可学习和弱可学习是等价的 具体措施 弱学习算法要比强学习算法更容易寻找，所以具体实施提升就是 需要解决的问题 改变训练数据权值、概率分布的方法 提高分类错误样本权值、降低分类正确样本权值 将弱学习器组合成强学习器的方法 competeing simple majority voting weighted majority voting confidence-based weighting 学习器组合方式 很多模型无法直接组合，只能组合预测结果 simple majority voting/simple average：简单平均 h = \\frac 1 K \\sum_{k=1}_K h_k $h_k$：第k个预测 weighted majority voting/weighted average：加权平均 h = \\frac {\\sum_{k=1}^K w_k h_k} {\\sum_{k=1}^K w_k} $w_k$：第k个预测权重，对分类器可以是准确率 competing voting/largest：使用效果最优者 confidence based weighted：基于置信度加权 \\begin{align*} h = \\arg\\max_{y \\in Y} \\sum_{k=1}^K ln(\\frac {1 - e_k} {e_k}) h_k \\end{align*} $e_k$：第k个模型损失 Meta Learning元学习：自动学习关于关于机器学习的元数据的机器学习子领域 元学习主要目标：使用学习到元数据解释，自动学习如何 flexible的解决学习问题，借此提升现有学习算法性能、 学习新的学习算法，即学习学习 学习算法灵活性即可迁移性，非常重要 学习算法往往基于某个具体、假象的数据集，有偏 学习问题、学习算法有效性之间的关系没有完全明白，对 学习算法的应用有极大限制 要素 元学习系统必须包含子学习系统 学习经验通过提取元知识获得经验，元知识可以在先前单个 数据集，或不同的领域中获得 学习bias（影响用于模型选择的前提）必须动态选择 declarative bias：声明性偏见，确定假设空间的形式 ，影响搜索空间的大小 如：只允许线性模型 procedural bias：过程性偏见，确定模型的优先级 如：简单模型更好 Recurrent Neural networksRNN：self-referential RNN理论上可以通过反向传播学习到， 和反向传播完全不同的权值调整算法 Meta Reinforcement LearningMetaRL：RL智能体目标是最大化奖励，其通过不断提升自己的学习 算法来加速获取奖励，这也涉及到自我指涉 Additional Model加法模型：将模型视为多个基模型加和而来 f(x) = \\sum_{m=1}^M \\beta_m b(x;\\theta_m) $b(x;\\theta_m)$：基函数 $\\theta_m$：基函数的参数 $\\beta_m$：基函数的系数 则相应风险极小化策略 \\arg\\min_{\\beta_m, \\theta_m} \\sum_{i=1}^N L(y_i, \\sum_{m=1}^M \\beta_m b(x_i;\\theta_m)) $L(y, f(x))$：损失函数 Forward Stagewise Algorithm前向分步算法：从前往后，每步只学习加法模型中一个基函数 及其系数，逐步逼近优化目标函数，简化优化复杂度 即每步只求解优化 \\arg\\min_{\\beta, \\theta} \\sum_{i=1}^N L(y_i, \\hat f_m(x_i) + \\beta b(x_i;\\theta)) $\\hat f_m$：前m轮基函数预测值加和 步骤 输入：训练数据集$T={(x_1,y_1), \\cdots, (x_N,y_N)}$，损失 函数$L(y,f(x))$，基函数集${b(x;\\theta)}$ 输出：加法模型$f(x)$ 初始化$f_0(x)=0$ 对$m=1,2,\\cdots,M$，加法模型中M个基函数 极小化损失函数得到参数$\\beta_m, \\theta_m$ (\\beta_m, \\theta_m) = \\arg\\min_{\\beta, \\theta} \\sum_{i=1}^N L(y_i, f_{m-1}(x_1) + \\beta b(x_i; \\theta)) 更新 f_m(x) = f_{m-1}(x) + \\beta_m b(x;y_M) 得到加法模型 f(x) = f_M(x) = \\sum_{i=1}^M \\beta_m b(x;\\theta_m) AdaBoost&amp;前向分步算法AdaBoost（基分类器loss使用分类误差率）是前向分步算法的特例， 是由基本分类器组成的加法模型，损失函数是指数函数 基函数为基本分类器时加法模型等价于AdaBoost的最终分类器 $f(x) = \\sum_{m=1}^M \\alpha_m G_m(x)$ 前向分步算法的损失函数为指数函数$L(y,f(x))=exp(-yf(x))$ 时，学习的具体操作等价于AdaBoost算法具体操作 假设经过m-1轮迭代，前向分步算法已经得到 \\begin{align*} f_{m-1}(x) & = f_{m-2}(x) + \\alpha_{m-1}G_{m-1}(x) \\\\ & = \\alpha_1G_1(x) + \\cdots + \\alpha_{m-1}G_{m-1}(x) \\end{align*} 经过第m迭代得到$\\alpha_m, G_m(x), f_m(x)$，其中 \\begin{align*} (\\alpha_m, G_m(x)) & = \\arg\\min_{\\alpha, G} \\sum_{i=1}^N exp(-y_i(f_{m-1}(x_i) + \\alpha G(x_i))) \\\\ & = \\arg\\min_{\\alpha, G} \\sum_{i=1}^N \\bar w_{m,i} exp(-y_i \\alpha G(x_i)) \\end{align*} $\\bar w{m,i}=exp(-y_i f{m-1}(x_i))$：不依赖 $\\alpha, G$ $\\forall \\alpha &gt; 0$，使得损失最小应该有 （提出$\\alpha$） \\begin{align*} G_m^{*}(x) & = \\arg\\min_G \\sum_{i=1}^N \\bar w_{m,i} exp(-y_i f_{m-1}(x_i)) \\\\ & = \\arg\\min_G \\sum_{i=1}^N \\bar w_{m,i} I(y_i \\neq G(x_i)) \\end{align*}此分类器$G_m^{*}$即为使得第m轮加权训练误差最小分类器 ，即AdaBoost算法的基本分类器 又根据 \\begin{align*} \\sum_{i=1}^N \\bar w_{m,i} exp(-y_i \\alpha G(x_i)) & = \\sum_{y_i = G_m(x_i)} \\bar w_{m,i} e^{-\\alpha} + \\sum_{y_i \\neq G_m(x_i)} \\bar w_{m,i} e^\\alpha \\\\ & = (e^\\alpha - e^{-\\alpha}) \\sum_{i=1}^N (\\bar w_{m,i} I(y_i \\neq G(x_i))) + e^{-\\alpha} \\sum_{i=1}^N \\bar w_{m,i} \\end{align*}带入$G_m^{*}$，对$\\alpha$求导置0，求得极小值为 \\begin{align*} \\alpha_m^{*} & = \\frac 1 2 log \\frac {1-e_m} {e_m} \\\\ e_m & = \\frac {\\sum_{i=1}^N (\\bar w_{m,i} I(y_i \\neq G_m(x_i)))} {\\sum_{i=1}^N \\bar w_{m,i}} \\\\ & = \\frac {\\sum_{i=1}^N (\\bar w_{m,i} I(y_i \\neq G_m(x_i)))} {Z_m} \\\\ & = \\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)) \\end{align*} $w_{m,i}, Z_M$同AdaBoost中 即为AdaBoost中$\\alpha_m$ 对权值更新有 \\bar w_{m+1,i} = \\bar w_{m,i} exp(-y_i \\alpha_m G_m(x))与AdaBoost权值更新只相差规范化因子$Z_M$","link":"/ML-Theory/Model-Enhencement/model_enhancement.html"},{"title":"AdaBoost","text":"AdaBoost通过改变训练样本权重，学习多个分类器，并将分类器进行线性 组合，提高分类性能 对离群点、奇异点敏感 对过拟合不敏感 Boosting实现 改变训练数据权值或概率分布：提高分类错误样本权值、降低 分类正确样本权值 弱分类器组合：加权多数表决，即加大分类误差率小的弱分类器 权值，使其在表决中起更大作用；减小分类误差率大的弱分类器 权值，使其在表决中起更小作用 步骤 输入：训练数据集$T={(x_1, y_1), \\cdots, (x_N, y_N)}$， 弱分类器算法$G(x)$ $x_i \\in \\mathcal{X \\subset R^n}$ $y_i \\in \\mathcal{Y} = {-1, +1 }$ 输出：最终分类器$G(x)$ 初始化训练数据权值分布： $D1=(w{11}, \\cdots, w{1N}), w{1i}=\\frac 1 N$ 对$m=1,2,\\cdots,M$（即训练M个弱分类器） 使用具有权值分布$D_m$的训练数据学习，得到基本 分类器 G_m(x):\\mathcal{X} \\rightarrow \\{-1, +1\\} 计算$G_m(x)$在训练数据集上的分类误差率 \\begin{align*} e_m & = P(G_m(x_i)) \\neq y_i) \\\\ & = \\sum_{i=1}^N w_{mi}I(G_m(x_i) \\neq y_i) \\\\ & = \\sum_{G_m(x_i) \\neq y_i} w_{mi} \\end{align*} 计算$G_m(x)$组合为最终分类器时权重 \\alpha = \\frac 1 2 log \\frac {1-e_m} {e_m} $\\alpha_m$表示就简单分类器$G_m(x)$在最终分类器中 的重要性，随$e_m$减小而增加 （弱分类器保证$e_m \\leq 1/2$） 更新训练集权值分布 \\begin{align*} D_{m+1} & = (w_{m+1,1}, \\cdots, w_{m+1,N}) \\\\ w_{m+1,i} & = \\frac {w_{mi}} {Z_m} exp(-\\alpha y_i G_m(x_i)) = \\left \\{ \\begin{array}{l} \\frac {w_mi} {Z_m} e^{-\\alpha_m}, & G_m(x_i) = y_i \\\\ \\frac {w_mi} {Z_m} e^{\\alpha_m}, & G_m(x_i) \\neq y_i \\\\ \\end{array} \\right. \\\\ Z_m & = \\sum_{i=1}^N w_{mi} exp(-\\alpha_m y_i G_m(x_i)) \\end{align*} $Zm$：规范化因子，是第m轮调整后的权值之和，其 使得$D{m+1}$成为概率分布 误分类样本权值相当于被放大 $e^{2\\alpha_m} = \\frac {e_m} {1 - e_m}$倍 构建基本分类器线性组合 f(x) = \\sum_{m=1}^M \\alpha_m G_m(x)得到最终分类器 G(x) = sign(f(x)) = sign(\\sum_{m=1}^M \\alpha_m G_m(x)) 这里$\\alpha_m$没有规范化，和不为1，规范化没有必要 $f(x)$符号决定分类预测结果，绝对值大小表示分类确信度 AdaBoost中分类器学习和之后的分类误差率“无关”，基分类器 学习算法中的loss不是分类误差率，可以是其他loss，只是需要 考虑训练数据的权值分布 好像基学习器的loss就要是和集成部分调权的loss一致todo 按权值分布有放回的抽样，在抽样集上进行训练 各样本loss按权重加权，类似分类误差率中加权 训练误差边界AdaBoost算法最终分类器的训练误差边界为 \\frac 1 N \\sum_{i=1}^N I(G(x_i) \\neq y_i) \\leq \\frac 1 N \\sum_i exp(-y_if(x_i)) = \\prod_m Z_m $G(x_i) \\neq y_i$时，$y_if(x_i)&lt;0$，所以 $exp(-y_i f(x_i)) \\geq 1$，则不等式部分可证 \\begin{align*} \\frac 1 N \\sum_i exp(-y_i f(x_i)) & = \\frac 1 N \\sum_i exp(-\\sum_{m=1}^M \\alpha_m y_i G_m(x_i)) \\\\ & = \\sum_i (w_{1,i} \\prod_{m=1}^M exp(-\\alpha_m y_i G_m(x_i))) \\\\ & = \\sum_i (Z_1 w_{2,i} \\prod_{m=2}^M exp(-\\alpha_m y_i G_m(x_i))) \\\\ & = \\prod_{m=1}^M Z_i \\sum_i w_{M+1,i} \\\\ & = \\prod_{m=1}^M Z_i \\end{align*} AdaBoost训练误差边界性质的关键：权重调整与基本分类器权重 调整共系数（形式不完全一样） 这也是AdaBoost权重调整设计的依据，方便给出误差上界 二分类训练误差边界 \\prod_{m=1}^M Z_m = \\prod_{m=1}^M (2\\sqrt{e_m(1-e_m)}) = \\prod_{m=1}^M \\sqrt{(1-4\\gamma_m^2)} \\leq exp(-2\\sum_{m=1}^M \\gamma_m^2) $\\gamma_m = \\frac 1 2 - e_m$ \\begin{align*} Z_m & = \\sum_{i=1}^N w_{m,i} exp(-\\alpha y_i G_m(x_i)) \\\\ & = \\sum_{y_i = G_m(x_i)} w_{m,i}e^{-\\alpha_m} + \\sum_{y_i \\neq G_m(x_i)} w_{m,i}e^{\\alpha_m} \\\\ & = (1-e_m)e^{-\\alpha_m} + e_m e^{\\alpha_m} \\\\ & = 2\\sqrt{e_m(1-e_m)} \\\\ & = \\sqrt{1-4\\gamma^2} \\end{align*} 由$\\forall x \\in [0, 0.5], e^{-x} &gt; \\sqrt{1-2x}$可得， $\\sqrt{1-4\\gamma_m^2} \\leq exp(-2\\gamma_m^2)$ 二分类AdaBoost误差边界性质的关键：$\\alpha$的取值，也是 前向分步算法（损失函数）要求 若存$\\gamma &gt; 0$，对所有m有$\\gamma_m \\geq \\gamma$，则 \\frac 1 N \\sum_{i=1}^N I(G(x_i) \\neq y_i) \\neq exp(-2M\\gamma^2) 即AdaBoost的训练误差是指数下降的 分类器下界$\\gamma$可以未知，AdaBoost能适应弱分类器各自 训练误差率，所以称为adptive Adaboost.M1Adaboost.M1是原版AdaBoost的多分类升级版，基本思想同Adaboost Boosting实现 基分类器组合方式 仍然是加权投票，且投票权重同Adaboost 出于多分类考虑，没有使用sign符号函数 改变训练数据权值或概率分布：和Adaboost形式稍有不同，但 相对的错误分类样本提升比率完全相同 被上个分类器错误分类样本，权值保持不变 被上个分类器正确分类样本，权值缩小比例是Adaboost平方 步骤 输入 训练集：$T={x_i, y_i}, i=1,\\cdots,N; y_i \\in C, C={c_1, \\cdots, c_m}$ 训练轮数：T 弱学习器：I 输出：提升分类器 H(x) = \\arg\\max_{y \\in C} \\sum_{m=1}^M ln(\\frac 1 {\\beta_m}) [h_m(x) = y] $h_t, h_t(x) \\in C$：分类器 $\\beta_t$：分类器权重 误分率上界 对弱学习算法产生的伪损失$\\epsilon1,\\cdots,\\epsilon_t$， 记$\\gamma_t = 1/2 \\epsilon_t$，最终分类器$h{fin}$误分率 上界有 \\frac 1 N |\\{i: h_{fin}(x_i) \\neq y_i \\}| \\leq \\prod_{t-1}^T \\sqrt {1-4\\gamma^2} \\leq exp(-2 \\sum_{t-1}^T \\gamma^2) 特点Adaboost.M1和Adaboost基本上没有区别 类别数目为2的Adaboost.M1就是Adaboost 同样无法处理对误分率高于0.5的情况，甚至在多分类场合， 误分率小于0.5更加难以满足 理论误分率上界和Adaboost相同 Adaboost.M2AdaboostM2是AdaboostM1的进阶版，更多的利用了基分类器信息 要求基学习器能够输出更多信息：输出对样本分别属于各类别 的置信度向量，而不仅仅是最终标签 要求基分类器更加精细衡量错误：使用伪损失代替误分率 作为损失函数 Psuedo-Loss\\begin{align*} L & = \\frac 1 2 \\sum_{(i,y) \\in B} D_{i,y} (1 - h(x_i, y_i) + h(x_i, y)) \\\\ & = \\frac 1 2 \\sum_{i=1}^N D_i (1 - h(x_i, y_i) + \\sum_{y \\neq y_i} (w_{i,y} h(x_i, y))) \\end{align*} $D$：权重分布（行和为1，但不满足列和为1） $D_{i,y}$：个体$x_i$中错误标签$y$的权重，代表从个体 $x_i$中识别出错误标签$y$的重要性 $B = {(i, y)|y \\neq y_i, i=1,2,\\cdots,N }$ $w$：个体各错误标签权重边际分布 $h(x, y)$：模型$h$预测样本$x$为$y$的置信度 $h(x_i,y_i)$：预测正确的置信度 $h(x_i,y), y \\neq y_i$：预测$x_i$为错误分类$y$置信度 伪损失函数同时考虑了样本和标签的权重分布 通过改变此分布，能够更明确的关注难以预测的个体标签， 而不仅仅个体 Boosting实现 改变数据权值或者概率分布 使用psuedo-loss替代误分率，以此为导向改变权值 对多分类每个错误分类概率分别计算错误占比，在此基础上 分别计算 基分类器组合方式：同Adaboost.M1 步骤 训练误差上界 对弱学习算法产生的伪损失$\\epsilon1,\\cdots,\\epsilon_t$， 记$\\gamma_t = 1/2 \\epsilon_t$，最终分类器$h{fin}$误分率 上界有 \\frac 1 N |\\{i: h_{fn}(x_i) \\neq y_i \\}| \\leq (M-1) \\prod_{t-1}^T \\sqrt {1-4\\gamma^2} \\leq (M-1) exp(-2 \\sum_{t-1}^T \\gamma^2)特点 基于伪损失的Adaboost.M2能够提升稍微好于随机预测的分类器 Adaboosting.M2能够较好的解决基分类器对噪声的敏感性，但是 仍然距离理论最优Bayes Error有较大差距，额外误差主要 来自于 训练数据 过拟合 泛化能力 控制权值可以有效的提升算法，减小最小训练误差、过拟合 、泛化能力 如对权值使用原始样本比例作为先验加权 其分类结果不差于AdaBoost.M1（在某些基分类器、数据集下）","link":"/ML-Theory/Model-Enhencement/adaboost.html"},{"title":"Bagging","text":"Baggingbagging：bootstrap aggregating，每个分类器随机从原样本 中做有放回的随机抽样，在抽样结果上训练基模型，最后根据 多个基模型的预测结果产生最终结果 核心为bootstrap重抽样自举 步骤 建模阶段：通过boostrap技术获得k个自举样本 $S_1, S_2,…, S_K$，以其为基础建立k个相同类型模型 $T_1, T_2,…, T_K$ 预测阶段：组合K个预测模型 分类问题：K个预测模型“投票” 回归问题：K个预测模型平均值 模型性质 相较于单个基学习器，Bagging的优势 分类Bagging几乎是最优的贝叶斯分类器 回归Bagging可以通过降低方差（主要）降低均方误差 预测误差总有部分观测未参与建模，预测误差估计偏乐观 OOB预测误差：out of bag，基于袋外观测的预测误差， 对每个模型，使用没有参与建立模型的样本进行预测，计算预测 误差 OOB观测比率：样本总量n较大时有 r = (1 - \\frac 1 n)^n \\approx \\frac 1 e = 0.367 每次训练样本比率小于10交叉验证的90% Random Forest随机森林：随机建立多个有较高预测精度、弱相关（甚至不相关） 的决策树（基础学习器），多棵决策树共同对新观测做预测 RF是Bagging的扩展变体，在以决策树为基学习器构建Bagging 集成模型的基础上，在训练过程中引入了随机特征选择 适合场景 数据维度相对较低、同时对准确率有要求 无需很多参数调整即可达到不错的效果 步骤 样本随机：Bootstrap自举样本 输入属性随机：对第i棵决策树通过随机方式选取K个输入变量 构成候选变量子集$\\Theta_I$ Forest-Random Input：随机选择$k=log_2P+1或k=\\sqrt P$ 个变量 Forest-Random Combination 随机选择L个输入变量x 生成L个服从均匀分布的随机数$\\alpha$ 做线性组合 $vj = \\sum{i=1}^L \\alpha_i x_i, \\alpha_i \\in [-1, 1]$ 得到k个由新变量v组成的输入变量子集$\\Theta_i$ 在候选变量子集中选择最优变量构建决策树 生成决策树时不需要剪枝 重复以上步骤构建k棵决策树，用一定集成策略组合多个决策树 简单平均/随机森林投票 优点 样本抽样、属性抽样引入随机性 基学习器估计误差较大，但是组合模型偏差被修正 不容易发生过拟合、对随机波动稳健性较好 一定程度上避免贪心算法带来的局部最优局限 数据兼容性 能够方便处理高维数据，“不用做特征选择” 能处理分类型、连续型数据 训练速度快、容易实现并行 其他 可以得到变量重要性排序 启发式操作 优化操作 缺点 决策树数量过多时，训练需要资源多 模型解释能力差，有点黑盒模型","link":"/ML-Theory/Model-Enhencement/bagging.html"},{"title":"LightGBM","text":"LightGBM","link":"/ML-Theory/Model-Enhencement/lightgbm.html"},{"title":"Stacked Generalization","text":"Stacked Generalization堆栈泛化：使用多种模型分别训练训练，将其结果叠加作为下层 模型的输入，最终得到预测输出 属于异源集成模型，可以视为 复合函数 短路网络 从某种意义上，复杂模型都是stacking 思想 不同模型侧重于获取数据不同方面的特征 使用基学习器抽取数据特征进行表示学习，提取不同角度的 数据高维特征 考虑到使用全量训练数据训练、预测作为下层模型输入会 导致过拟合，可使用K折交叉验证避免过拟合 有些基学习器只使用适合其部分特征训练 GBDT、DNN适合低维稠密特征 元学习器组合多个基学习器的输出 从数据高维特征学习数据模式，具有更好的泛化能力，避免 过拟合 算法 输入：模型$M1, M_2, \\cdots, M_d$、训练特征：$X{n*m}$、 训练标签$Y_{n}$、测试特征$X^{‘}$ 输出：stacking模型、预测标签 将训练数据K折划分，对第$i$轮划分 使用模型$M1, M_2, \\cdots, M_d$分别在相应训练集 $[X[:n_i,:], X[n{i+1}:,:]]$、 $[Y[:ni], Y[n{i+1}:]]$上训练 在相应验证集$X[ni:n{i+1}, :]$上验证、并记录验证 结果 将验证集验证结果叠加得到部分样本新特征 $N[ni: n{i+1}, d]$ 将K轮划分得到的部分新特征拼接得到训练集的完整新特征 $N_{n * d}$，将新特征作为输入，训练下层模型，得到最终 stacking模型 将测试特征如上作为输入经过两层模型预测，得到最终预测结果 以上以2层stacking为例，有深层stacking 常用模型基学习器 交叉项、原始特征本身也可以视为线性基学习器学习到的特征 具体模型参见 ml_specification/rec_system/ctr_stacking_models GBDT 各树中各节点对应元学习器一维输入特征 适合低维稠密通用特征，对输入特征分布没有要求 GBDT树根据熵增益（Gini系数增益）划分节点，每条路径 都代表一定区分能力 以叶子节点（路径）作为特征，相当于自动进行特征 转换、组合、选择、离散化，得到高维组合特征 GDBT相较于单棵树、或RF更适合stacking 单棵树表达能力弱，无法表达多个有区分性特征组合， 集成模型可将样本映射为多个特征 GBDT拟合残差意味着各树对样本区分度不同，对各特征 区别对待更合理 DNN 适合普通稠密特征、embedding特征 模型表达能力强，能抽取有良好分布数据的深层次特征，提高 模型准确性、泛化能力 容易扩充其他类别特征，如：图片、文字 元学习器 LR 适合低维稀疏特征，可对所有特征离散化以引入非线性 FM 适合低维稀疏特征 LR基础上自动组合二阶交叉项 Linear：训练模型、对训练结果线性加权 ?","link":"/ML-Theory/Model-Enhencement/stacking.html"},{"title":"Robust Optimization","text":"背景稳健优化：利用凸理论、对偶理论中概念，使得凸优化问题中的解 对参数的bounded uncertainty有限不确定性（波动）不敏感 稳健优化在机器学习涉及方面：不确定优化、过拟合 Connecting Consistency Generalization Ability Sparsity Stability 不确定性来源 模型选择错误 假设不成立 忽略必要因素 经验分布、函数无法正确估计整体分布 过拟合判断依据 metric entropy VC-dimension 对比优化问题对问题参数的扰动非常敏感，以至于解经常不可行、次优 Stochastic Programming：使用概率描述参数不确定性， 稳健优化则假设问题参数在某个给定的先验范围内随意变动 不考虑参数的分布 利用概率论的理论，而不用付出计算上的代价 策略（最优化问题） \\begin{align*} \\min_x & : f_0(x) \\\\ s.t. & : f_i(x) \\leq 0, i=1,2,\\cdots,m \\end{align*} \\begin{align*} \\min_x & : f_0(x) \\\\ s.t. & : f_i(x, u_i) \\leq 0, \\forall u_i \\in \\mathcal{U}_i, i=1,2,\\cdots,m \\end{align*} $\\mathcal{U}_i $：uncertainty set，不确定集 Computational Tractablity稳健优化易解性：在满足标准或一点违反 Slater-like regularity conditions情况下，求解稳健优化问题 等同于求解对以下凸集$\\mathcal{X(U)}$的划分（求出凸集） \\mathcal{X(U)} \\overset {\\triangle} {=} \\{ x: f_i(x, u_i) \\leq 0, \\forall u_i \\in \\mathcal{U}_i, i=1,2,\\cdots,m \\} 若存在高效算法能确定$x \\in \\mathcal{X(U)}$、或者能够提供 分离超平面，那么问题可以在多项式时间中求解 即使所有的约束函数$f_i$都是凸函数，此时$\\mathcal{X(U)}$ 也是凸集，也有可能没有高效算法能够划分出$\\mathcal{X(U)}$ 然而在大部分情况下，稳健化后的问题都能高效求解下，和原 问题复杂度相当 复杂度说明 LP + Polyhedra Uncertainty：LP LP + Ellipsoidal Uncertainty：SOCP CQP + Ellipsoidal Uncertainty：SDP SDP + Ellipsoodal Uncertainty：NP-hard LP：Linear Program，线性规划 SOCP：Second-Order Cone Program，二阶锥规划 CQP：Convex Quadratic Program，凸二次规划 SDP：Semidefinite Program，半定规划 Polyhedra Uncertainty：多项式类型不确定 Ellipsodial Uncertainty：椭圆类型不确定 NP-hard：NP难问题，至少和NPC问题一样困难得问题 ExampleLinear Programs with Polyhedral Uncertainty 概率解释、结果 稳健优化的计算优势很大程度上来源于，其形式是固定的，不再 需要考虑概率分布，只需要考虑不确定集 计算优势使得，即使不确定性是随机、且分布已知，稳健优化 仍然具有吸引力 在一些概率假定下，稳健优化可以给出稳健化问题解的某些 概率保证，如：可行性保证（在给定约束下，解能以多大概率 不超过约束） Uncertainty SetAtomic Uncertainty Set原子不确定集 \\begin{align*} (I) & 0 \\in \\mathcal{U}_0 \\\\ (II) & \\forall w_0 \\in R^n: \\sup_{u \\in \\mathcal{U}_0 [-w_0^T u^{'} < +\\infty \\end{align}Robust Optimization and Adversary Resistant Learning即稳健优化在机器学习中处理不确定性（随机的、对抗性的） 稳健优化中在机器学习中应用 稳健学习在很多学习任务中都有提出 学习和规划 Fisher线性判别分析 PCA 这里考虑经典的二分类软阈值SVM \\begin{align*} \\min_{w,b,\\xi}: \\quad & \\mathcal{ r(w,b) + C\\sum_{i=1}^m \\xi_i} \\\\ s.t.: & \\xi_i \\geq [1-y_i( + b)], i=1,\\cdots,m; \\\\ & \\xi_i \\geq 0, i=1,\\cdots,m; \\end{align*}Corrupted Location 椭圆不确定集：随机导致的 正则化项使用 传统的二范数，一范数同样使用的稀疏的解 概率解释：风险控制 Missing Data 多项式不确定：对抗删除数据（alpha go） 使用无效特征消去偏置 对max损失取对偶得到min带入得到SOCP Robust Optimization and Regularization 统一从稳健优化的角度解释学习算法中的优秀性质 正则化 稀疏 一致性 指导寻找新的算法 大数定理、中心极限定理表明即使各个特征上随机不确定项 是独立的，其本身也会有强烈的耦合倾向，表现出相同特征 、像会相互影响一样 这促使寻找新的稳健算法，其中随机不确定项是耦合的 SVM","link":"/ML-Theory/Optimization/robust_optimization.html"},{"title":"模型评估","text":"评估方向模型误差 给定损失函数时，基于损失函数的误差显然评估学习方法的标准 回归预测模型：模型误差主要使用 MSE 分类预测模型：模型误差主要是分类错误率 ERR=1-ACC 模型训练时采用损失函数不一定是评估时使用的 Training Error训练误差：模型在训练集上的误差，损失函数 $L(Y, F(X))$ 均值 e_{train} = R_{emp}(\\hat f) = \\frac 1 N \\sum_{i=1}^N L(y_i, \\hat {f(x_i)}) $\\hat f$：学习到的模型 $N$：训练样本容量 训练时采用的损失函数和评估时一致时，训练误差等于经验风险 训练误差对盘对给定问题是否容易学习是有意义的，但是本质上不重要 模型训练本身就以最小化训练误差为标准，如：最小化 MSE、最大化预测准确率，一般偏低，不能作为模型预测误差的估计 训练误差随模型复杂度增加单调下降（不考虑模型中随机因素） Test Error测试误差：模型在测试集上的误差，损失函数 $L(Y, f(X))$ 均值 e_{test} = \\frac 1 {N^{'}} \\sum_{i=1}^{N^{'}} L(y_i,\\hat {f(x_i)}) $\\hat f$：学习到的模型 $N$：测试样本容量 测试误差反映了学习方法对未知测试数据集的预测能力，是模型 generalization ability 的度量，可以作为模型误差估计 测试误差随模型复杂度增加呈U型 偏差降低程度大于方差增加程度，测试误差降低 偏差降低程度小于方差增加程度，测试误差增大 训练误差小但测试误差大表明模型过拟合，使测试误差最小的模型为理想模型 模型复杂度 approximation error：近似误差，模型偏差，代表模型对训练集的拟合程度 estimation error：估计误差，模型方差，代表模型对训练集波动的稳健性 模型复杂度越高 低偏差：对训练集的拟合充分 高方差：模型紧跟特定数据点，受其影响较大，预测结果不稳定 远离真实关系，模型在来自同系统中其他尚未观测的数据集上预测误差大 而训练集、测试集往往不完全相同 复杂度较高的模型（过拟合）在测试集上往往由于其高方差效果不好，而建立模型最终目的是用于预测未知数据 所以要兼顾偏差和方差，通过不同建模策略，找到恰当模型，其复杂度不太大且误差在可接受的水平 使得模型更贴近真实关系，泛化能力较好 简单模型：低方差高偏差 复杂模型：低偏差高方差 模型复杂度衡量参data_science/loss Over-Fitting过拟合：学习时选择的所包含的模型复杂度大（参数过多），导致模型对已知数据预测很好，对未知数据预测效果很差 若在假设空间中存在“真模型”，则选择的模型应该逼近真模型（参数个数相近） 一味追求对训练集的预测能力，复杂度往往会比“真模型”更高 解决方法 减少预测变量数量 最优子集回归：选择合适评价函数（带罚）选择最优模型 验证集挑选模型：将训练集使用 抽样技术 分出部分作为 validation set，使用额外验证集挑选使得损失最小的模型 正则化（罚、结构化风险最小策略） 岭回归：平方损失，$L_2$ 范数 LASSO：绝对值损失，$L_1$ 范数 Elastic Net 减弱变量特化程度：仅适合迭代求参数的方法 EarlyStop：提前终止模型训练 Dropout：每次训练部分神经元 模型信息来源 训练数据包含信息 模型形成过程中提供的先验信息 模型：采用特定内在结构（如深度学习不同网络结构）、条件假设、其他约束条件（正则项） 数据：调整、变换、扩展训练数据，让其展现更多、更有用的信息 评价指标 Classification 分类问题：输出变量$Y$为有限个离散变量 混淆矩阵 F-Measure TPR、FPR ROC AUC Tagging 标注问题：输入 $X^{(1)}, X^{(2)}, \\cdots, X^{(n)}$、输出 $Y^{(1)}, Y^{(2)}, \\cdots, Y^{(n)}$ 均为变量序列 类似分类问题 Regression 回归问题 Squared Error MSE $R^2$、$R^2_{Adj}$ AIC BIC Absolute Error MAE MAPE SMAPE 经验损失、结构损失总是能用作评价模型，但是意义不明确","link":"/ML-Theory/Loss/model_evaluation.html"},{"title":"损失函数理论","text":"参数估计 矩估计：建立参数和总体矩的关系，求解参数 除非参数本身即为样本矩，否则基本无应用价值 应用场合 均值：对应二次损失 $\\arg\\min{\\mu} \\sum{i=1}^N (x_i - \\mu)^2$ 方差：对应二次损失? 极大似然估计：极大化似然函数，求解概率上最合理参数 需知道（假设）总体 概率分布形式 似然函数形式复杂，求解困难 往往无法直接给出参数的解析解，只能求数值解 应用场合 估计回归参数：对数损失 $\\mathop{\\arg\\min}{\\beta} \\sum{i=1}^N lnP(y_i|x_i, \\beta)$ 损失函数估计：极小化损失函数，求解损失最小的参数 最泛用的参数求解方法 适合求解有大量参数的待求解的问题 往往通过迭代方式逐步求解 特别的 线性回归使用 MSE 作为损失函数时，也被称为最小二乘估计 极大似然估计同对数损失函数 参数估计都可以找到合适损失函数，通过迭代求解损失最小化 随机模拟估计参数 需要设计随机模拟实验估计参数 应用场合 蒙特卡洛类似算法：随机化损失 迭代求解参数 损失函数定义不同 包含样本量数量不同 惩罚项设置不同 异步更新参数 同时求解参数数量：全部、部分、单个 参数升维 更新方向 梯度 海瑟矩阵 次梯度 更新方式 叠加惯性 动态学习率 Loss Models模型（目标函数）在样本整体的损失：度量模型整体预测效果 代表模型在整体上的性质，有不同的设计形式 可以用于 设计学习策略、评价模型 风险函数 评价函数 有时在算法中也会使用整体损失 Expected Risk / Expected Loss / Generalization Loss期望风险（函数）：损失函数 $L(Y, f(X))$（随机变量）期望 R_{exp}(f) = E_p[L(Y, f(X))] = \\int_{x*y} L(y,f(x))P(x,y) dxdy $P(X, Y)$：随机变量 $(X, Y)$ 遵循的联合分布，未知 风险函数值度量模型预测错误程度 反映了学习方法的泛化能力 评价标准（监督学习目标）就应该是选择期望风险最小 联合分布未知，所以才需要学习，否则可以直接计算条件分布概率，而计算期望损失需要知道联合分布，因此监督学习是一个病态问题 Empirical Risk / Empirical Loss经验风险：模型关于给定训练数据集的平均损失 \\begin{align*} R_{emp}(f) & = \\sum_{i=1}^N D_i L(y_i, f(x_i;\\theta)) \\\\ E(R_{emp}(f)) & = R_{exp}(f) \\end{align*} $\\theta$：模型参数 $D_i$：样本损失权重，常为 $\\frac 1 N$，在 Boosting 框架中不同 经验风险损失是模型 $f(x)$ 的函数 训练时，模型是模型参数的函数 即其为模型参数函数 根据大数定律，样本量容量 $N$ 趋于无穷时，$R{emp}(f)$ 趋于 $R{exp}(f)$ 但是现实中训练样本数目有限、很小 利用经验风险估计期望常常并不理想，需要对经验风险进行矫正 例子 maximum probability estimation：极大似然估计 模型：条件概率分布（贝叶斯生成模型、逻辑回归） 损失函数：对数损失函数 Structual Risk / Structual Loss结构风险：在经验风险上加上表示 模型复杂度 的 regularizer（penalty term） R_{srm} = \\frac 1 N \\sum_{i=1}^N L(y_i, f(x_i)) + \\lambda J(f) $J(f)$：模型复杂度，定义在假设空间$F$上的泛函 $\\lambda$：权衡经验风险、模型复杂度的系数 结构风险最小化 添加 regularization（正则化），调节损失函数（目标函数） 模型复杂度 $J(f)$ 表示对复杂模型的惩罚：模型 $f$ 越复杂，复杂项 $J(f)$ 越大 案例 maximum posterior probability estimation：最大后验概率估计 损失函数：对数损失函数 模型复杂度：模型先验概率对数后取负 先验概率对应模型复杂度，先验概率越小，复杂度越大 岭回归：平方损失 + $L2$ 正则化 $\\mathop{\\arg\\min}{\\beta} \\sum_{i=1}^N (y_i - f(x_i, \\beta))^2 + |\\beta|$ LASSO：平方损失 + $L1$ 正则化 $\\mathop{\\arg\\min}{\\beta} \\sum_{i=1}^N (y_i - f(x_i, \\beta))^2 + |\\beta|_1$ Generalization Ability泛化能力：方法学习到的模型对未知数据的预测能力，是学习方法本质、重要的性质 测试误差衡量学习方法的泛化能力不可靠，其依赖于测试集，而测试集有限 学习方法的泛化能力往往是通过研究泛化误差的概率上界进行 Generalization Error Bound泛化误差上界：泛化误差的 概率 上界 是样本容量函数，样本容量增加时，泛化上界趋于 0 是假设空间容量函数，假设空间容量越大，模型越难学习，泛化误差上界越大 泛化误差 根据 Hoeffding 不等式，泛化误差满足 \\begin{align*} & \\forall h \\in H, & P(|E(h) - \\hat E(h)| \\geq \\epsilon) \\leq 2 e^{-2 N \\epsilon^2} \\\\ \\Rightarrow & \\forall h \\in H, & P(|E(h) - \\hat E(h)| \\leq \\epsilon) \\geq 1 - 2|H|e^{-2N\\epsilon^2} \\end{align*} $H$：假设空间 $N$：样本数量 $E(h) := R_{exp}(h)$ $\\hat E(h) := R_{emp}(h)$ 证明如下： \\begin{align*} P(\\forall h \\in H: |E(h) - \\hat E(h)| \\leq \\epsilon|) & = 1 - P(\\exists h \\in H: |E(h) - \\hat E(h)| \\geq \\epsilon) \\\\ & = 1 - P((|E(h_1) - \\hat E(h_1) \\geq \\epsilon) \\vee \\cdots \\vee (|E(h_{|H|}) - \\hat E_{|H|}| \\geq \\epsilon)) \\\\ & \\geq 1 - \\sum_{i=1}^{|H|} P(|E(h_i) - \\hat E(h_i)| \\geq \\epsilon) \\\\ & \\geq 1 - 2|H|e^{-2N \\epsilon^2} \\end{align*} 对任意 $\\epsilon$，随样本数量 $m$ 增大， $|E(h) - \\hat E(h)| \\leq \\epsilon$ 概率增大，可以使用经验误差近似泛化误差 二分类泛化误差上界 由 Hoeffding 不等式 \\begin{align*} P(E(h) - \\hat E(h) & \\geq \\epsilon) \\leq exp(-2N\\epsilon^2) \\\\ P(\\exists h \\in H: E(h) - \\hat E(h) \\geq \\epsilon) & = P(\\bigcup_{h \\in H} \\{ E(h) - \\hat E(h) \\geq \\epsilon \\}) \\\\ & \\leq \\sum_{h \\in H} P(E(h) - \\hat E(h) \\geq \\epsilon) \\\\ & \\leq |H| exp(-2 N \\epsilon^2) \\end{align*} 则 $\\forall h \\in H$，有 P(E(h) - \\hat E(h) < \\epsilon) \\geq 1 - |H| exp(-2 N \\epsilon)则令 $\\sigma = |H| exp(-2N\\epsilon^2)$，则至少以概率 $1-\\sigma$ 满足如下，即得到泛化误差上界 \\begin{align*} E(h) & \\leq \\hat E(h) + \\epsilon(|H|, N, \\sigma) \\\\ \\epsilon(|H|, N, \\sigma) & = \\sqrt {\\frac 1 {2N} (log |H| + log \\frac 1 {\\sigma})} \\end{align*} Probably Approximate Correct 可学习PAC 可学习：在短时间内利用少量（多项式级别）样本能够找到假设 $h^{‘}$，满足 P(E(h^{'}) \\leq \\epsilon) \\geq 1 - \\sigma, 0 < \\epsilon, \\sigma < 1 即需要假设满足两个 PAC 辨识条件 近似条件：泛化误差 $E(h^{‘})$ 足够小 可能正确：满足近似条件概率足够大 同等条件下 模型越复杂，泛化误差越大 满足条件的样本数量越大，模型泛化误差越小 PAC 学习理论关心能否从假设空间 $H$ 中学习到好的假设 $h$ 由以上泛化误差可得，取 $\\sigma = 2|H|e^{-2N\\epsilon^2}$，则样本量满足 $N = \\frac {ln \\frac {2|H|} \\sigma} {2 \\epsilon^2}$ 时，模型是 PAC 可学习的 Regularization正则化：（向目标函数）添加额外信息以求解病态问题、避免过拟合 常应用在机器学习、逆问题求解 对模型（目标函数）复杂度惩罚 提高学习模型的泛化能力、避免过拟合 学习简单模型：稀疏模型、引入组结构 有多种用途 最小二乘也可以看作是简单的正则化 岭回归中的 $\\mathcal{l_2}$ 范数 模型复杂度模型复杂度：经常作为正则化项添加作为额外信息添加的，衡量模型复杂度方式有很多种 函数光滑限制 多项式最高次数 向量空间范数 $\\mathcal{L_0} - norm$：参数个数 $\\mathcal{L_1} - norm$：参数绝对值和 $\\mathcal{L_2}$- norm$：参数平方和 $\\mathcal{L_0} - norm$ $\\mathcal{l_0} - norm$ 特点 稀疏化约束 解 $\\mathcal{L_0}$ 范数正则化是 NP-hard 问题 $\\mathcal{L_1} - norm$ $\\mathcal{L_1} - norm$ 特点 $\\mathcal{L_1}$ 范数可以通过凸松弛得到 $\\mathcal{L_0}$ 的近似解 有时候出现解不唯一的情况 $\\mathcal{L_1}$ 范数凸但不严格可导，可以使用依赖次梯度的方法求解极小化问题 应用 LASSO 求解 Proximal Method LARS $\\mathcal{L_2} - norm$ $\\mathcal{L_2} - norm$ 特点 凸且严格可导，极小化问题有解析解 $\\mathcal{L_1 + L_2}$ $\\mathcal{L_1 + L_2}$ 特点 有组效应，相关变量权重倾向于相同 应用 Elastic Net 稀疏解产生稀疏解：待估参数系数在某些分量上为 0 $\\mathcal{L_1} - norm$ 稀疏解的产生 $\\mathcal{L_1}$ 范数在参数满足 一定条件 情况下，能对 平方损失 产生稀疏效果 在 $[-1,1]$ 内 $y=|x|$ 导数大于 $y=x^2$（除 0 点） 则特征在 0 点附近内变动时，为了取到极小值，参数必须始终为 0 高阶项在 0 点附近增加速度较慢，所以 $\\mathcal{L_1} - norm$ 能产生稀疏解是很广泛的 $mathcal{L_1} - norm$ 前系数（权重）越大，能够容许高阶项增加的幅度越大，即压缩能力越强 在 0 附近导数 “不小”，即导数在 0 点非 0 对多项式正则化项 $\\mathcal{L_1} - norm$ 项对稀疏化解起决定性作用 其他项对稀疏解无帮助 对“非多项式”正则化项 $e^{|x|}-1$、$ln(|x|+1)$ 等在0点泰勒展开同样得到 $\\mathcal{L_1} - norm$ 项 但是此类正则化项难以计算数值，不常用 $\\mathcal{L_1} - norm$ 稀疏解推广 正负差异化：在正负设置权重不同的 $\\mathcal{L_1}$，赋予在正负不同的压缩能力，甚至某侧完全不压缩 分段函数压缩：即只要保证在 0 点附近包含 $\\mathcal{L_1}$ 用于产生稀疏解，远离 0 处可以设计为常数等不影响精确解的值 Smoothly Clipped Absolute Deviation R(x|\\lambda, \\gamma) = \\left \\{ \\begin{array} {l} \\lambda|x| \\qquad & if |x| \\leq \\lambda \\\\ \\frac {2\\gamma\\lambda|x| - x^2 - {\\lambda}^2 } {2(\\gamma - 1)} & if \\gamma< |x|","link":"/ML-Theory/Loss/loss_thoery.html"},{"title":"Loss Function","text":"损失函数 损失函数可以视为模型与真实的距离的度量 因此损失函数设计关键即，寻找可以代表模型与真实的距离的统计量 同时为求解方便，应该损失函数最好应满足导数存在 Surrogate Loss代理损失函数：用优化方便的损失函数代替难以优化的损失函数，间接达到优化原损失函数的目标 如 0-1 损失难以优化，考虑使用二次损失、交叉熵损失替代 损失函数设计 对有监督学习：真实 已知，可以直接设计损失函数 对无监督学习：真实 未知，需要给定 真实标准 NLP：需要给出语言模型 EM 算法：熵最大原理 常用损失函数 0-1 Loss L(y, f(x)) = \\left \\{ \\begin{array}{l} 1, & y \\neq f(x) \\\\ 0, & y = f(x) \\end{array} \\right. 0-1 损失函数梯度要么为 0、要么不存在，无法通过梯度下降方法优化 0-1 损失 适用场合 二分类：Adaboost 多分类：Adaboost.M1 Quadratic / Squared Error Loss L(y, f(x)) = \\frac 1 2 (y - f(x))^2 平方错误损失函数可导，可以基于梯度下降算法优化损失函数 适用场合 回归预测：线性回归 分类预测：0-1 二分类（根据预测得分、阈值划分） Logistic SE 平方损失用于二分类时存在如下问题（模型输出无限制） 若模型对某样本非常确信为正例，给出大于1预测值 此时模型会进行不必要、开销较大的优化 考虑对模型输出进行 sigmoid 变换后作为预测值，再应用平方错误损失函数 L(y, f(x)) = \\frac 1 2 (y - \\sigma(f(x)))^2 Logistic SE 损失函数曲线对 0-1 损失拟合优于平方损失 但负区间存在饱和问题，损失最大只有 0.5 Cross Entropy交叉熵损失 \\begin{align*} L(y, f(x)) & = -ylog(f(x)) \\\\ & = - \\sum_{k=1}^K y_k log f(x)_k \\end{align*} $y$：样本实际值 $f(x)$：各类别预测概率 $K$：分类数目 交叉熵损失综合二次损失、logistic SE 优势，以正样本为例 预测值较大时：损失接近 0，避免无效优化 预测值较小时：损失偏导趋近于 -1，不会出现饱和现象 $y$ 为 one-hot 编码时实际值时 分类问题仅某分量为 1：此时交叉熵损失同对数损失（负对数极大似然函数） 标签问题则可有分量为 1 适合场合 多分类问题 标签问题 Hinge Loss\\begin{align*} L(y, f(x)) & = [1 - yf(x)]_{+} \\\\ [z]_{+} & = \\left \\{ \\begin{array}{l} z, & z > 0 \\\\ 0, & z \\leq 0 \\end{array} \\right. \\end{align*} $y \\in {-1, +1}$ 合页损失函数：0-1 损失函数的上界，效果类似交叉熵损失函数 要求分类不仅正确，还要求确信度足够高损失才为 0 即对学习有更高的要求 适用场合 二分类：线性支持向量机 收敛速度对比 指数激活函数时：相较于二次损失，收敛速度更快 二次损失对 $w$ 偏导 \\frac {\\partial L} {\\partial w} = (\\sigma(z) - y) \\sigma^{'}(z) x $\\sigma$：sigmoid、softmax 激活函数 $z = wx + b$ 考虑到 sigmoid 函数输入值绝对值较大时，其导数较小 激活函数输入 $z=wx+b$ 较大时，$\\sigma^{‘}(z)$ 较小，更新速率较慢 Softmax 激活函数时，交叉熵对 $w$ 偏导 \\begin{align*} \\frac {\\partial L} {\\partial w} & = -y\\frac 1 {\\sigma(z)} \\sigma^{'}(z) x \\\\ & = y(\\sigma(z) - 1)x \\end{align*} 特别的，对 sigmoid 二分类 \\begin{align*} \\frac {\\partial L} {\\partial w_j} & = -(\\frac y {\\sigma(z)} - \\frac {(1-y)} {1-\\sigma(z)}) \\sigma^{'}(z) x \\\\ & = -\\frac {\\sigma^{'}(z) x} {\\sigma(z)(1-\\sigma(z))} (\\sigma(z) - y) \\\\ & = x(\\sigma(z) - y) \\end{align*} 考虑 $y \\in {(0,1), (1,0)}$、$w$ 有两组 带入一般形式多分类也可以得到二分类结果 不常用损失函数Absolute Loss绝对损失函数 L(y, f(x)) = |y-f(x)| 适用场合 回归预测 Logarithmic Loss对数损失函数（负对数极大似然损失函数） L(y, P(y|x)) = -logP(y|x) 适用场合 多分类：贝叶斯生成模型、逻辑回归 Exponential Loss指数函数函数 L(y, f(x)) = exp\\{-yf(x)\\} 适用场合 二分类：前向分步算法 Pseudo Loss伪损失：考虑个体损失 $(x_i, y_i)$ 如下，据此构造伪损失 $h(x_i, y_i)=1, \\sum h(x_i, y)=0$：完全正确预测 $h(x_i, y_i)=0, \\sum h(x_i, y)=1$：完全错误预测 $h(x_i, y_i)=1/M$：随机预测（M为分类数目） L(y, f(x)) = \\frac 1 2 \\sum_{y^{(j)} \\neq f(x)} w_j (1 - f(x, y) + f(x, y^{(j)})) $w_j$：样本个体错误标签权重，对不同个体分布可不同 $f(x, y^{(j)})$：分类器将输入 $x$ 预测为第 $j$ 类 $y^{(j)}$ 的置信度 伪损失函数考虑了预测 标签 的权重分布 通过改变此分布，能够更明确的关注难以预测的个体标签，而不仅仅个体 伪损失随着分类器预测准确率增加而减小 分类器 $f$ 对所有可能类别输出置信度相同时，伪损失最大达到 0.5，此时就是随机预测 伪损失大于 0.5 时，应该将使用 $1-f$ 适用场景 多分类：Adaboost.M2","link":"/ML-Theory/Loss/func_loss.html"},{"title":"Local Binary Pattern","text":"综述局部二值模式：描述图像局部纹理的特征算子 具有旋转不变性、灰度不变性 通过对窗口中心的、领域点关系进行比较，重新编码形成新特征 以消除外界场景对图像影响，一定程度上解决了复杂场景下 （光照变换）特征描述问题 分类 经典LBP：3 * 3正方向窗口 圆形LBP：任意圆形领域 Classical LBPSobel OperatorLaplace OperatorCanny Edge DetectorCircular LBP缩略图Hash 对图像进行特征提取得到0、1特征向量 通过比较图片向量特征间汉明距离即可计算图片之间相似度 Average HashingaHash：平均哈希算法 将原始图片转换为64维0、1向量，即提取出的特征 步骤 缩放图片：将图像缩放到8 * 8=64像素 保留结构、去掉细节 去除大小、纵横比差异 灰度化：把缩放后图转换为256阶灰度图 计算平均值：计算灰度图像素点平均值 二值化：遍历64个像素点，大于平均值者记为1、否则为0 Perceptual HashingpHash：感知哈希算法 利用离散余弦变换降低频率，去除成分较少的高频特征 特点 相较于aHash更稳定 步骤 缩放图片：将图片缩放至32 * 32 灰度化：将缩放后图片转换为256阶灰度图 计算DCT：把图片分离成频率集合 缩小DCT：保留32 32左上角8 8代表图片最低频率 计算平均值：计算缩小DCT均值 二值化：遍历64个点，大于平均值者记为1、否则为0 Differential HashingdHash：差异哈希算法 基于渐变实现 特点 相较于dHash非常快 相较于aHash效果好 步骤 缩放图片：将图片缩放至9 * 8 灰度化：将缩放后图片转换为256阶灰度图 计算差异值：对每行像素计算和左侧像素点差异，得到8 * 8 二值化：遍历64个点，大于0记为1、否则为0","link":"/ML-Specification/Computer-Vision/local_binary_pattern.html"},{"title":"系统安装常识","text":"Win10/8系统在已经安装win10/8系统的机器上安装linux系统，需要注意 电源设置中关闭快速启动，其有可能影响grub开机引导 boot中关闭secureboot U盘启动盘Win下usbwriter和ultraiso都可以制作，但是 usbwriter用于archlinux的制作 打开 启动-&gt;写入磁盘映像 写入方式—USB-HDD+ ultraiso用于ubuntu和centos的制作 archlinux使用ultraiso和usbwriter制作u盘不同，用usbwriter的 u盘好像有隐藏分区，只能看到一个很小容量的盘，使用ultraiso 制作的启动盘好像没用 bootloader（启动引导器）双系统根据需求选择 Windows使用EasyBCD引导LinuxEasyBCDWindows下的一个引导器 NeoGrub是EasyBCD自带的grub（不是已经更加常用的grub2）， 可以配置EasyBCD在无法找到其他Linux系统的grub的情况下， 将控制权转移给NeoGrub，使用其引导系统，这个NeoGrub就和 普通的grub类似，可以引导多个系统 有很多文件系统格式无法识别，能够确认可识别的只有ext2， 不能的有xfs、ext4，其中ext4会被错认为ex2fs， 不能正确读取分区文件， 据说只能识别标准格式的分区，无法识别lvm格式的分区 因此，如果需要使用NeoGrub引导系统，需要注意分区格式问题 分区 Ubuntu：”安装启动引导器的设备”设置为sdXY，即磁盘X的 Y分区，这样不会更改默认引导程序，此时会安装grub，但是 没有覆盖磁盘中默认的win引导，重启后会自动进入win，可以 使用easybsd自动检测引导分区，直接就能添加引导条目 Centos：选择不安装启动引导器grub(centos无法选择引导器 安装在某个分区），EasyBCD无法自动检测Linux的引导分区， 需要手动配置EasyBCD自带的NeoGrub，并添加此条目 引导文件编写添加NeoGrub条目之后，其配置文件仍然为空，因此选择此条目之后 会直接进入grub控制台，在此尝试boot其他系统。 root (hdX,：X表示磁盘代号，&lt;tab&gt;给出的候选分区， 确定boot分区Y root (hdX,Y)：指定根目录（中间有空格） kernel /vmlinuz：&lt;tab&gt;给出候选的内核文件，确定内核 文件（一般会有一个rescue的文件肯定不是） kernel /vmlinuz---------- ro root=/dev/sdXY ro quite vga=791： 其中X不再是hd后面的数字而是字母，Y是root中Y+1 initrd /initramfs：tab给出候选initrd镜像文件 initrd /initramfs--------- boot 如果成功进入系统，说明以上的命令可行，记录以上真正有效的 命令，据此修改NeoGrub配置文件 title name root (hdX,Y) kernel /vmlinuz------------ ro root=/dev/sdXY ro quite vga=791 initrd /initramfs---------- boot 可以在EasyBCD中打开配置文件，也可以直接修改C:/NST/menu.ls 文件 Linux使用grub引导Windowsgrub可以引导包括win、linux在内的大部分系统，而且大部分教程 都是默认这种方式 Ubuntu：”安装启动引导器的设备”设置为sdX，即直接安装在 磁盘的最开始，修改默认引导 Centos：选择安装启动引导器 Archlinux：要手动安装os-prober（检测已安装系统）、grub， 配置grub启动文件，具体方法参见grub使用或是archlwiki 分区 /根分区：唯一必须分区 boot分区：一般建议单独给boot分区 根分区位于lvm、RAID，或者是文件系统不能被引导程序 识别，单独的boot分区可以设为其他格式 可以以只读方式挂载boot分区，防止内核文件被破坏 多系统可以共享内核 swap分区 如果设置swap分区，一般设置为内存的1～2倍 建议使用交换文件代替，这样的比较灵活，而且如果内存 够用的话可以不启用swap文件，这样提升效率、保护硬盘 fallocate -l SIZE /SWAPFILENAME：创建交换文件 ，其中SIZE后面要跟单位（M、G） chmod 600 /SWAPFILENAME：更改交换文件权限 mkswap /SWAPFILENAME：设置交换文件 swapon /SWAPFILENAME：启用一次交换文件 或修改/etc/fstab文件，每次开机默认启用交换文件 /SWAPFILENAME none swap defaults 0 0 /SWAPFILENAME swap swap sw 0 0 前者是Arch教程，后者是Centos7教程，这两种写法应该 是一样的","link":"/Daily-Life/os_installation.html"},{"title":"传统图像特征提取","text":"Scale-Invariant Feature TransformSIFT：通过求图中interest/corner point、及其scale和 orientation描述子得到特征，并进行图像特征点匹配 SIFT是检测局部特征的算法 实质：在不同尺度空间查找关键点，计算关键点大小、方向 、尺度信息，进而组成对关键点得描述 SIFT查找的关键点为突出、稳定的特征点，不会因光照、 仿射变换、噪声等因素而改变 角点 边缘点 暗区亮点 亮区暗点 匹配过程就是对比特征点过程 优点 稳定性：具有旋转、尺度、平移、视角、亮度不变性， 利于对目标特征信息进行有效表达 独特性：信息量丰富，适合海量特征数据中进行匹配 多量性：少数物体也可以产生大量SIFT特征向量 可扩展性：可以方便同其它形式特征向量联合 对参数调整稳健性好：可以根据场景调整特征点数量进行 特征描述、方便特征分析 缺点 不借助硬件加速、专门图像处理器难以实现 构建尺度空间图像的尺度空间：解决如何对图像在所有尺度下描述的问题 思想：对原始图像进行尺度变换，获得多尺度空间下图像表示 序列，模拟图像数据的多尺度特征 对序列进行尺度空间主轮的提取 以主轮廓作为特征向量，实现边缘、角点检测、不同分辨率 上稳定关键点提取 对高斯金字塔生成的O组、L层不同尺度图像，$(O, L)$就构成 高斯金字塔的尺度空间 即以高斯金字塔组$O$、层$L$作为坐标 给定一对$(o,l)$即可唯一确定一幅图像 图像金字塔图像金字塔：以多分辨率解释图像的结构 通过对原始图像进行多尺度像素采样方式生成N个不同 分辨率的图像 图像分辨率从下至上逐渐减小 直至金字塔顶部只包含一个像素 获取图像金字塔步骤 利用低通滤波器平滑图像 对平滑图像进行采样 上采样：分辨率逐渐升高 下采样：分辨率逐渐降低 高斯金字塔高斯金字塔：由很多组图像金字塔构成，每组金字塔包含若干层 同一组金字塔中 每层图像尺寸相同 仅高斯平滑系数$\\sigma$不同，后一层图像是前一层$k$倍 不同组金字塔中 后一组图像第一个图像是前一组倒数第三个图像二分之一 采样 图像大小是前一组一半 构建过程 构建第1组图像金字塔 第1层：将原图扩大一倍得到 第2层：第1层图像经过高斯卷积得到 SIFT算子中，高斯平滑参数$\\sigma=1.6$ 第k层： $\\sigma$乘以比例系数得到新平滑因子 $\\sigma = k\\sigma$， 使用平滑因子平滑第k层图像得到 不断重复得到L层图像 构建第k组图像金字塔 第1层：将第k-1组金字塔倒数第3层做比例因子为2的降采样 得到 之后同第1组图像金字塔 不断重复得到O组图像金字塔，共计O * L个图像 Difference of GaussianDOG金字塔：差分金字塔 DOG金字塔第0组第k层由高斯金字塔第0组第k+1层减去第k层得到 DOG金字塔每组比高斯金字塔少一层 按高斯金字塔逐组生成$O * (L-1)$个差分图像 DOG图像包含大量信息（需要归一化才能人眼可见） 在不同DOG层（即不同模糊程度、不同尺度）都存在的特征 即SIFT要提取的稳定特征 后续SIFT特征点都是在DOG金字塔中进行 空间极值点检测空间极值点检测：关键点初步查探 寻找DOG图像极值点：每个像素点和其所有相邻点比较 需要同时比较图像域、尺度空间域相邻点 保证关键点在尺度空间、二维图像空间上都是局部极值点 对二维图像空间，对中心点 图像域：与3 * 3领域内8个点比较 同组尺度空间：和上下两层图像中2 * 9个点比较 极值点是在不同尺度空间下提取的，保证了关键点尺度不变性 精确定位稳定关键点精确定位 DOG值对噪声、边缘敏感，需要对局部极值进一步筛选，去除 不稳定、错误检测极值点 构建高斯金字塔时采用下采样图像，需要求出下采样图像中 极值点对应在原始图像中确切位置 方向信息分配稳定关键点方向信息分配 为关键点分配方向信息赋予关键点旋转不变性 通过对稳定关键点求梯度实现方向分配 计算方式 梯度幅度值 m(x, y) = \\sqrt {(L(x+1,y) - L(x-1,y))^2 + (L(x,y+1) - L(x,y-1))^2} 梯度方向 \\theta(x,y) = tan^{-1} (\\frac {L(x,y+1) - L(x,y-1)} {L(x+1,y) - L(x-1,y)}) 通过梯度方向直方图给出关键点梯度方向 计算关键点为中心领域内所有点梯度方向，在0~360度范围 把所有梯度方向划分到36个区域，每个方向代表10度 累计每个方向关键点数目，生成梯度方向直方图 将直方图中峰值代表方向作为关键点主方向 若存在相当于峰值80%大小的方向，则作为辅方向 辅方向可以增强匹配的鲁棒性 Lowe指出：大概15%关键点具有辅方向，且这些关键点 对稳定匹配起关键作用 关键点描述关键点描述：以数学方式定义关键点的过程，包括关键点周围对其 有贡献的领域点 对关键点周围像素区域分块 计算块内梯度直方图 生成具有独特性的向量，作为对该区域图像信息的抽象表述 如下图 将关键点周围分为2 * 2块 对每块所有像素点梯度做高斯加权（softmax拉开差距？） 每块最终取8个方向，得到2 2 8维向量，作为中心 关键点数学描述 Lowe实验表明：采用4 4 8共128维描述子表征关键点， 综合效果最好 特征点匹配特征点匹配：计算两组特征点128维描述向量的欧式距离 欧式距离越小、相似度越高，小于指定阈值时既可认为匹配成功 Speeded Up Robust FeatureSURF特征：对SIFT算法的改进，降低了时间复杂度，提高了稳健性 主要是简化SIFT一些运算 高斯二阶维分模型简化，卷积平滑操作仅需要转换为加减 运算 最终生成特征向量维度从128维减少为64维 BriefOriented BriefORB：Brief算法改进版 比SIFT算法快100倍","link":"/ML-Specification/Computer-Vision/metric_space_features.html"},{"title":"风险控制","text":"欺诈风险 欺诈：以故意欺瞒事实而诱使对方发生错误认识的故意行为，通常目的是使欺诈者获利 欺诈的行为要素 使人发生错误认识为目的 故意行为 欺诈可以分为 冒用：冒用他人身份，通过生物信息技术等容易发现 伪装：伪造部分信息，相对而言更难识别 金融领域“资金就是生产资料”使得欺诈者的非法获利更容易 https://zhuanlan.zhihu.com/p/31708263 欺诈事件 白户：账户信息缺失，没有足够数据对借款人进行风险评估 内部白户：新注册、无申贷历史记录 外部白户：人行征信、三方征信无覆盖 黑户：账户存在逾期、失信、欺诈记录 内部黑户：历史订单逾期 外部黑户：人行征信、三方征信黑 论坛、公开渠道监控 恶意欺诈：账户通过伪造资料、蓄意骗贷 伪造账单流水记录骗取更高额度 恶意欺诈账户可能涉及不良嗜好，如黄赌毒等 身份冒用：伪冒他人身份进行欺诈骗贷 熟人冒用 他人盗用 一般可通过信审、人脸识别、活体验证核验借款人身份 以贷养贷 放大共贷风险杠杆 可通过三方征信机构的多头借贷产品识别 中介欺诈：黑中介哄骗或招揽客户实施骗贷 黑中介利用风控漏洞大规模攻击，造成大量资损 传销：有组织的开展收费并发展多级下线，存在集中骗贷风险 存在老客拉新，从关系网络上具有明显星状结构 欺诈者身份 第一方欺诈：欺诈者用真实身份进行欺诈 严格来说不是欺诈，没有在身份信息上误导平台 应对措施 黑名单 第二方欺诈：企业、渠道内员工进行内部欺诈、内外勾结 即巴塞尔协议操作风险中的内部欺诈 应对措施 内控：权限获取合理、流程上风险分散、操做可追溯 第三方欺诈：非欺诈者自身、企业内部的第三方欺诈 名义借贷者身份信息通过黑色产业链购买、养号，作为黑产军团的一个链条 申请欺诈 账户盗用 资料造假 恶意违约 交易欺诈 账户冒险 养卡 套现 应对措施 对抗性强、低侵入、性价比各种能力和技术 社交网络发现 数据交叉对比 模型客户用户画像 获取非法收益的时间 First Payment Default 首轮欺诈 首期失联 Bust-out 余额欺诈 短时间将授信刷高再获利离场 收益来源环节 单个客户利润 = 贷款收益 - 资金成本 - 信用成本 - 获客成本 获客成本 - 税收成本 骗贷：信用成本中的风险成本 羊毛：获客成本中的补贴 刷量：获客成本中的广告费 虚假短信：运营费用中的短信流量费 得利方、损失方 C骗C：在互金领域不多 即使是P2P，也会有平台兜底 B骗C C骗B B骗B 反欺诈 防范欺诈的重要障碍是欺诈难以标注，是通过贷后表现推断贷前 意图 一般只有真正联系到本人或失联，很难有足够证据证明是欺诈导致的逾期，而不是信用导致逾期 欺诈导致逾期往往有以下特征 首逾：最常作为欺诈指标 对第一方、第三方欺诈，往往会发生首逾 对第二方欺诈，考虑到内部人员的考核、规避等 原因，有可能会正常还款1到2期，此类欺诈较难认定 催收追回率更高 反欺诈调研步骤 风险事件发现：具有敏锐的风险嗅觉，发现可疑事件 欺诈场景还原：广泛收集各渠道信息还原欺诈场景，调研分析背后可能原因 风险规则提炼：从欺诈场景中提炼相应专家规则，拦截欺诈 技术算法支持：搜集相应数据，根据数据类型和场景特点寻找合适算法识别欺诈 反欺诈除了常规的策略部署外，还需要考虑人性：延迟模型和规则的效用 抓大放小：允许小资损，随机抽取小比例的欺诈者通过 隐藏防控点，用于积累黑名单 迷惑欺诈团伙 虚假额度：设置虚假授信额度，但借口其他理由不放款 https://zhuanlan.zhihu.com/p/96778969 https://zhuanlan.zhihu.com/c_147252758 调研欺诈风险渠道 实时大盘监控：适合识别黑中介风险、传销风险等团伙欺诈 设备聚集性风险 LBS、WIFI 地域欺诈风险，如朋克村 信审催收反馈 通过电话外呼、核验用户身份、咨询借款动机，根据用户反应发现身份伪冒 论坛舆情监控 对相关论坛、讨论组等检测仪监控，发现市场动向 理解欺诈人群的心理特征、社会身份 黑产卧底调研 线上加入相关社区，站在欺诈账户立场上，找寻风控系统弱点 线下去欺诈案件多发地，实地调研、学习黑产手法 反欺诈专家规则 针对网贷黑中介识别的风险规则 中介通讯录长常常会存储客户号码，并加以备注 因为需要联系客户，运营商数据中往往会留下痕迹 中介网贷申请手法更熟练，在申请页面停留时间短 使用网络可能包含“网贷”等敏感信息 人脸活体验证时存在照片翻拍、视频通话 对反欺诈规则同样可按照一般规则进行评价 规则欺诈命中次数、命中率 规则欺诈命中次数 = 命中触发报警之后被认定为欺诈次数 欺诈命中率 = 规则欺诈命中次数 / 规则报警次数 综合欺诈命中次数 综合欺诈次数 = 规则欺诈命中次数 + 逾期调查认定欺诈数 综合欺诈命中率 考虑到欺诈逾期特征，可以把首逾、催收回账户重点调查 专家规则有高准确率的优点，但是覆盖的人群有限，性价比低，过多会导致规则集冗长，不利于维护 反欺诈算法 应用方向 辅助调查人员从单个案件的调查上升到对团体的调查，提高人工审核效率 通过用户之间的关联关系，给调查人员提供更多分析线索 算法研究方向 基于社交网络的模型 基于通讯录、运营商数据，采用基于图的社区发现算法 基于无监督聚类的模型 知识图谱 Embedding 特征构建 基于埋点行为数据，生成 Embedding 特征 文本分类 基于论坛文本、通讯录名称、WIFI 名称分类 First Payment Deliquency模型 FPD 模型：以首逾作为目标变量建立模型 假设：欺诈者动机是骗钱，那么第一期就会逾期 入模变量一般是负面特征 安装负面 App 数量 历史逾期次数 基于欺诈的还款表现作为理论支撑，但是也存在一定缺陷 逾期标签存在滞后性，首逾标签存在至少一个月，不利于快速响应 放贷样本同总体有偏，在其上训练模型存在偏差，会低估风险 信用风险","link":"/ML-Specification/FinTech/Risk-Control/credit_risks.html"},{"title":"PC硬件","text":"SSD硬盘接口/插槽类型M.2接口/插槽M.2曾经称为NGFF M.2接口的SSD有很多长度版本，常用的是42/60/80mm这三种 版本 M.2根据接口（金手指）/插槽的缺口位置、针脚数量可以 分为两类 B Key(Socket2)：缺口偏左，左侧6个针脚宽，对应SSD 金手指（接口）左侧6个针脚（插槽上针脚数-1为5） M Key(Socket3)：缺口偏右，右侧5个针脚宽，对应SSD 金手指（接口）右侧5个针脚（插槽上针脚数-1为4） B&amp;M：大部分M.2SSD跳过了B Key金手指，采用B&amp;M类型的 金手指，这种类型的金手指有偏左、偏右均有一个缺口，兼容 B Key和M Key类型的插槽 SATA串口mSATA串口IDE并口总线标准PCI-EPCI-Express PCI-E 3.0*2： PCI-E 3.0*4：总带宽有32Gbps SATA3.0SATA3.0带宽仅有6Gbps，采用此类总线标准的SSD速度较慢 传输协议AHCIAHCI是SATA总线对应的传输协议标准（逻辑设备接口标准）， 可以看作是一种SATA的优化驱动 可以在BIOS中开启该协议 NVMeNVMe是针对PCI-E总线SSD的告诉传输协议 就目前而言，支持NVMe协议的M.2SSD一定采用了PCI-E 3.0*4 总线标准，但反之不一定 总结M.2SSD B&amp;M金手指 SATA总线：&lt;600MB/s PCI-E 3.0*2总线：&lt;1000MB/s M Key金手指 PCI-E 3.0*2总线：&lt;1000MB/s PCI-E 3.0*4总线 支持NVMe协议：可以超过2000MB/s 不支持NVMe协议：&lt;1500MB/s","link":"/Daily-Life/pc_hardware.html"},{"title":"评分卡模型","text":"模型 模型是策略的工具，策略包含模型，是模型的延伸 相较于专家规则，机器学习模型 允许加入更多特征维度，描述更加全面 上限更高、下限更低 涉及更多维度特征时，维护更方便 机器学习模型和专家规则并非相互替代，更多的是串联 业务问题转换为带解决数学问题 尽量将业务问题转换为更容易解决分类问题而不是回归问题 数学问题应尽量贴近业务：评估指标好不等于业务价值高 远离业务问题的训练出模型，其线下评估效果好也不意味着上线效果好，如：针对客户而不是订单评价 影响客户体验，如：客户等待时间预估偏低而不是偏高 样本构造 标签定义 尽量为客观事实（是否、数量），而非主观判断（等级） 样本粒度贴合实际、业务（订单粒度、客户粒度） 样本数量 二分类场景：正例样本大于 2000，占比超过 1% 采样 尽量不进行人工采样，保持训练数据正、负例比例和真实情况对齐 传统评分卡 评分卡 复杂学习 特征筛选 需筛选强特征，依赖业务经验 支持弱特征入模 特征处理 WOE 分箱，稳定性好 非线性 仅 WOE 分箱提供非线性，解释性好 非线性充分挖掘数据信息，解释性差 复杂度 模型简单，泛化性好，样本需求小 模型复杂，表达能力强，样本少时容易过拟合 调参 超参少 调参难度大 模型提升方向 分（样本）群建模 Stacking 结合评分卡 信用评分卡模型：利用模型将账户的属性特征按取值分组、并赋予一定分数，对账户进行信用评分 最常见的金融风控手段之一，用于决定是否给予授信以及授信的额度和利率 常用逻辑回归作为模型 应用形式为查分组得分表、得分加和 变量总是被分组，同组内得分相同 用户属性变化不足以跨越箱边界，则得分不改变 评分卡更关注得分相对值，即得分变动情况，评分绝对值含义意义不大 常用 LR 中 sigmoid 函数内线性函数结果作为初始得分 根据 LR 意义，此时得分可以映射为账户的违约概率 为美观，可能会对得分做线性变换 常对各特征得分做放缩、对账户得分和做平移，此时放缩比例除以 $ln2$ 即为 PDO （对特征得分同时做等比例放缩、平移可行但蠢） 线性变换后得分绝对值无意义，特征重要性可用特征各分组得分差距衡量 评分卡在不同业务阶段体现的方式、功能不一样，按照借贷用户借贷时间可以分为 申请评分卡 Application Score Card：贷前申请评分卡 行为评分卡 Behavior Score Card：贷中行为评分卡 催收评分卡 Collection Score Card：贷后催收评分卡 Stacking 评分卡 考虑将评分卡、机器学习模型结合，使用机器学习模型构建特征，在此基础之上建立评分卡模型 Stacking 思想下的模型架构 原始数据域 数据挖掘、特征工程 数据域特征子模型 评分卡模型 架构优势 可解释性：保留在数据域粒度上的可解释性 信息提取：子模型提取弱特征信息，降低特征工程门槛 维度多样性：特征子模型机制，降低特征筛选必要性，保证各数据域都有特征入模 模块化：具有良好扩展性，支持子模型替换、删除 并行化：各数据域特征子模型专业、独立负责，提高效率 架构劣势 牺牲部分可解释性：若策略、模型使用相同变量，策略阈值调整对模型影响难以估计 控制入模变量数目，便于快速定位 利用 SHAP、LIME 等工具解释模型 增加上线、维护成本：需要上线多个模型，且对多个架构多个层次都进行监控 协同建模增加对接成本 分数据域特征子模型建模，容易造成数据孤岛，无法捕捉不同数据域间的数据联系 跨数据域构造特征，构建跨数据域子模型 B 卡 - Behavior Scoring贷中风控：根据借款人放贷后行为表现，预测未来逾期风险 B 卡用于动态监控放款后风险变化 贷前阶段对借款人履约行为掌握少，且为静态数据 一般无需实时，离线T+1计算即可 B 卡适合的信贷场景 还款周期长 长周期场景用户风险变化可能性大，与 A 卡形成区分 引入贷中客户信息、还款履约行为，更准确识别客户逾期风险 循环授信 贷前阶段，无法很好识别客户风险，设置初始额度 贷中与客户更多交互之后，可根据获取的贷中行为信息进行提额、降额操作 B 卡区分度一般很高 除贷前数据之外，还可以使用账户的贷中表现数据 特别的，不考虑排序性的情况下，使用是否逾期作为划分依据也能得到较高的 TPR-FPR，给出 KS 的下限 B 卡建模主要基于老客 老客有足够长的申贷、还款记录 新、老客定义口径 新客：无历史结清订单 老客：至少有1笔结清订单 C 卡 - Collection Scoring贷后催收评分卡：当前状态为逾期情况下，预测未来出催可能性 现阶段业界对 C 卡不够重视 贷前风控最重要，优秀的贷前带来更容易的贷中、贷后 催收效果和人员更相关，而逾期发生之后往往会委外 随信贷行业的发展，贷后催收会趋向于精细化、专业化的发展，模型+策略的优化愈发重要 模型分群 新老入催用户 首次入催 再次入催 MOB 信息（数据厚薄） 还款月份数 催记月份数 订单详情 利率 期限 金额 样本选择 建模样本窗口选择 特征覆盖度：保证数据厚薄程度相同 催收动作变化：出催没有大幅度变动 客群变化：入催没有大幅变动 同用户订单合案 不合案：同用户多笔订单视为不同样本 表现期内入催当期结清视为出催 合案：同用户相近观察点入催订单合并 表现期内入催当期所有账单还清视为出催 对发生过 M2+ 逾期者，可将只要出催一期即视为出催 C 卡模型 根据模型作用时间段分类 M1 全量模型：预测 M1 阶段（逾期 30 天内）还款概率 样本：所有入催样本整体 若缓催期内催出用户较多，则模型主要学习了缓催样本信息，约等于缓催响应模型，对非缓催样本效果较差 时间窗口 观察点：还款日 表现期：M1 阶段 缓催响应模型：预测适合缓催人群 样本：需要积累足够的缓催响应样本 若有足够缓催响应样本，可以和M1全量模型同时构建 否则，在 M1 全量模型得分高（出催概率高）人群上进行 AB Test，积累缓催响应样本 时间窗口 观察点：还款日 表现期：缓催响应日(2-3 天) 贷后 N 天流转模型：预测贷后N天后的还款概率 样本：缓催内未出催样本 去除缓催样本影响，更多学习缓催期外出催样本信息 优先对催出概率高的人群进行催收，提高出催概率 时间窗口 观察点：还款日（逾期）后 N 天 表现期：至下个流转模型观察点、逾期阶段结束时间点 M2+ 模型：预测 M2+ 阶段的还款概率（类似贷后流转模型） 样本：M1 阶段未出催样本 时间窗口 观察点：M2 阶段起始 表现期：至下个流转模型观察点、逾期阶段结束时间点 模型应用方法 缓催响应人群确定 交叉 M1 模型、缓催响应模型，根据模型交叉结果设置阈值 根据阈值筛选缓催响应人群 限定缓催期（2-3 天），将缓催响应样本分为人工催收、缓催两组，观察两组在缓催期限内出催率变化 若出催率相同，则认为缓催响应人群分析方法可行，对缓催响应人群可采取缓催策略 若出催率相差较大，则调整缓催响应人群分析方法 缓催模型响应时间（缓催期）可根据响应时间段内的出催率变化设置 模型搭建策略 M1 阶段出催概率较大，在M1阶段会设计多个细分模型 至少：M1 阶段全量模型 缓催样本足够 缓催响应模型 贷后 N 天流转模型 精细化管理：多个不同时间窗口的贷后流转模型 M2+ 阶段根据样本量、精细化程度设置适量模型 开发流程标准化 风控模型开发流程标准化意义 提高建模效率：可批量快速生产模型，提高效率 帮助理解指标逻辑、业务含义，利于调试优化 流程规范约束 统一建模流程，减少出错概率、便于问题回溯 统一命名方式，便于汇总文档 数据预处理特征编码 特征离散化 WOE 编码特征 WOE 曲线应符合业务逻辑（一般单调），并且经过跨时间 窗口验证，否则应该调整 LR 模型中特征权重应该全为正值，否则 同数据 WOE 值体现的逻辑相违背 负值权重特征存在较严重共线性 one-hot 编码特征 同特征下个分箱单独作为独立变量取值 权重灵活性更大，模型效果可能较好 变量数量多，需要样本数量大，模型效果可能较差（随机解法） 各特征分箱之间无联系，难以通过模型剔除某个变量 样本赋权 样本赋权：充分利用所有样本的信息，避免样本有偏 按样本距今时间赋权，近期样本高权重 按业务特性赋权，不同额度、利率、期限不同权重 按账户类型赋权 拒绝推断 Reject Inference 拒绝推断：避免样本偏差导致模型估计过于乐观 Exploratory Data Analysis 风控领域样本较少，一般按月粒度观察，即将样本按月分组为 vintage 进行分析，探索、评估数据 稳定性 信息量 信息重复/相关性 实操中可逐阶段设置多组阈值，分布进行变量探索、筛选 多组阈值逐步剔除能尽可能保留高信息量特征 避免相关性、RF 特征重要度等 非单变量指标 剔除过多特征 模型评估 有效性/区分度 GINI 指数 KS 值 坏样本率：组内、累计 提升度 = 召回样本坏样本率 / 全部样本坏样本率 odds = 坏样本率 / 好样本率 排序性 AUC 值/ROC 曲线 稳定性 PSI 各 Vintage 内坏占比、Lift 值、odds 等指标稳定性 模型得分展示表 箱内样本数 好、坏样本数 箱内坏样本、比例 累计好、坏样本 累计好、坏样本比例：TPR、FPR、TPR-FPR 累计通过率、坏样本比例 模型应用Calibration 模型校准 一致性校准：将模型预测概率校准到真实概率 尺度变换：将风险概率转换为整数分数 导出得分 原始得分 one-hot 编码：LR 模型系数 WOE 编码：LR 模型系数（权重）、WOE 值之积 常对各特征得分做放缩、对账户得分和做平移 PDO：违约翻倍得分 用于缩放原始得分 得分按 $\\frac {PDO} {ln2}$ 缩放后，得分减少 $PDO$ 分，用户违约 odds 翻倍，缺省即 $ln2$ 账户得分总和平移则仅仅是为了美观 对特征得分同时做等比例放缩、平移可行但蠢","link":"/ML-Specification/FinTech/Risk-Control/rc_models.html"},{"title":"风控规则","text":"风控规则 规则的类型 条件判断：决策路径独立 决策表：决策路径有交集、规律 决策树：决策路径不规律、可能重复检查同一数据 规则引擎：接受数据输入，解释业务规则，根据业务规则、使用 预定义语义做出业务决策 制定原则 监管、公司政策类 年龄准入 行业准入 有金融属性行业 政策敏感娱乐行业 地域准入 场景准入 风控层面 黑名单类 多头类：申请次数 共债类：申请量 反欺诈类 评分拒绝类 规则发现规则评分 强弱规则 强规则：可作为独立规则，直接指导决策 弱规则：具有一定区分度，但不决定性 弱规则可组合使用，通过评分方式衡量弱规则 使用规则评分衡量规则影响力 规则影响力则可以通过命中坏占比、odds变动衡量 设置阈值，命中规则的评分之和超过阈值才触发报警 笛卡尔积法 步骤 获取变量：定义好坏，关联特征变量 变量筛选：通过IV值等指标快速筛选变量 指标统计：分组统计申请量、放款量、坏账量等指标 透视呈现：分申请率、放款率、坏账率等指标制作交互，如列联表等 规则提取：结合各维度选择满足要求的组别，提取规则逻辑 规则评估：评估跨期稳定性 策略上线 决策树法 决策树法优势 可根据划分依据自动对人群细分 决策树法缺陷 难以调整决策树划分结果 划分结果可能缺乏业务意义 可能出现过拟合现象 规则阈值设置 阈值设置指标 Lift 值 收益/风险比 阈值设置依据 对分类取值，根据 Lift 值、收益/风险比 确定是否作为规则 对有序、数值取值，结合不同阈值点计算 Lift 值、收益/风险比，绘制曲线 曲线平缓变化，则阈值切分收益变化稳定，阈值调整空间比较大 曲线存在明显陡、缓变化，则阈值切分收益在拐点处收益较大，阈值调整空间有限 规则评价 案件调查 用信前报警调查 逾期后调查 根据不同目标，可以对不同的案件区分重点调查 线下 / 离线（标签已知）效果评估 自身效果评估 混淆矩阵 TPR/FPR 准确率/误拒率 提升度 拒绝样本中坏样本Lift提升度 通过样本中好样本Lift提升度 通过率、拒绝率 加权收益：好数量 好收益 + 坏数量 坏收益 对比/增量效果评估：和其他数据源比较 有效差异率：查得命中 / 其他通过且为坏样本 无效差异率：查得命中 / 其他拒绝 类似名单类数据评估 线上 / 在线（标签未知）效果评估 规则报警次数、报警率 规则（触发）报警次数：命中规则后账户被拒绝次数 对强规则，即为规则命中次数 对弱规则，小于规则命中次数 规则报警率 = 规则报警次数 / 规则命中次数 规则报警率低、趋势走低表明规则需修正 规则调查次数、调查率 规则调查次数 = 对案件调查分析时调查其次数 （短路调查） 规则调查率 = 规则调查次数 / 规则报警次数 调查率低则因考虑其他规则替代该规则，或or合并规则 规则可以为调查提供提示，而过多不能给调查提供提示的 规则反而浪费时间 规则命中次数、命中率 规则命中次数 = 命中触发报警之后被认定为坏样本数 规则命中率 = 规则命中次数 / 规则报警次数 综合命中次数 综合命中次数 = 规则命中次数 + 逾期调查认定坏样本数 综合命中率 = 综合命中次数 / 规则报警次数 在线效果效果是无法在体系内自评估的，必须引入外部信息，包括：人工审核、额外数据源、扩招回机制等 规则稳定性通过率波动应对 寻找通过率变动的时点 计算各维度通过率波动程度PSI 定位各策略节点主次影响 分析主要影响策略节点规则、阈值 指导决策 逾期率波动应对 定位逾期率波动客群：存量客户、新增客户 MOD 旁路规则Swap Set Analysis 新、旧模型可用离线指标比较优劣，但最终要在业务中比较通过率、坏账率，二者正相关，swap set 则是反应模型的通过的变化 Swap Set Analysis 用于分析新、旧模型更替 根据订单在新、旧模型的通过情况，可以分为三类 Swap-in Population：旧模型拒绝但新模型接受 Swap-out Population：旧模型接受但新模型拒绝 No Change：新、旧模型同时接受、拒绝 从 swap set 角度评价 “新模型优于旧模型” Swap-in Population &gt;= Swap-out Population 且坏账率不升 Swap-in Population = Swap-out Population 、坏账率不变，但用户响应率提升 实务中，已上线的旧模型拒绝订单无法获取表现期，只能通过拒绝推断近似得到坏账率 同时间窗 A/B-Test：切分流量让旧模型只打分不拒绝 跨时间窗 A/B-Test：用旧模型在灰度期坏账率替代 扩召回扩召回：独立召回之外，利用额外模型扩召回部分样本 此处召回一般指通过 成熟 的规则、模型从全体中获取部分样本 召回一般为历史沉淀、专家经验规则 召回的理由充足，但泛化性较差 扩召回和二次排序训练用的样本是相同的，但 二次排序是在召回的样本基础上再次排序 目标：（全局）排序能力 评价标准：AUC、头部准召 扩召回一般是独立于召回建立的模型 目标：学习召回样本的规律，完善召回机制、补充召回样本 因此，扩招回也可以用召回样本作为正样本 扩召回也可用于在线验证新、旧规则的有效性 评价标准：额外召回准确率（对召回样本的学习能力） 事实上，若采用召回样本作为正样本，则 AUC 为 1 的扩召回是无价值的，只是复现了召回 特征：可能包含一些专供于扩召回使用的特征 扩召回的正样本可能还包括人工举报、隐案等 准入规则 风控准入规则应为强拒绝规则 不满足任何规则均会被拒绝 规则无需经过复杂的规则衍生 策略理念：验证借款人依法合规未被政策限制 风控流程中首道防线 准入策略已经趋同 但对不同信贷场景仍应采取更适应业务的准入规则 基础认证模块 风控基础认证模块：验证申请人真实性 身份证信息验证 人脸信息验证 银行卡四要素验证 运营商三要素验证 按数据来源分类 个人信用类 个人基本信息 年龄准入 地区准入 行业准入 经济能力信息 月收入 流水 社交信息 设备信息 短信 APP安装信息 外部数据源 征信报告 外部黑名单 行为数据 活动轨迹 登录、注册时间 评分卡规则 黑、白名单白名单 白名单：风险相对可知可控的客户构成的内部名单 业务初期：通过白名单控制入口 控制放量节奏 降低风险 通过宽松风控规则提高审批通过率 通过贷前策略规则筛选白名单，协助调整贷前策略 业务中期：部分客户走特殊的贷前审批流程，满足特殊审批 要求 白名单筛选方式：有部分存量数据情况下 联合建模：缺乏特定业务场景预测变量，与外部机构建模 补充预测变量 内部数据探索：寻找与违约表现相关性较强的特征规则 类似场景、产品 纯粹凭借专家经验规则 引入外部数据匹配 黑名单 黑名单：还款能力、还款意愿不能满足正常客户标准 通常多个好客户才能覆盖坏客户的本金损失 通过黑名单客户全部拒绝，但是对于导流助贷机构，业务 核心是流量和客户质量，拒绝全部黑名单客群成本巨大， 可能会随机、结合评分放过部分 黑名单建立 建立黑名单参考维度 还款表现 渠道 利率 失信名单 黑名单主体 身份证 手机号 邮箱 银行卡 IP 三方黑名单 自建黑名单命中率不高（二次申请概率低），且需要长期 积累 不同三方黑名单往往会有其侧重点 团伙欺诈名单 公安、司法名单 被执行人名单 三方黑名单效果也有好有坏，对效果较差、但通过率影响 不大黑名单也可以考虑保留 黑名单一般是查得收费，外挂较多黑名单不会提升成本 黑名单可视为容错机制，黑名单不一定能所有样本上 表现优秀，保留其可防止欺诈团伙等集中攻击 同样值得注意的是，黑名单的质量需要考核 非公信黑名单定义各家不同 名单没有明确的退出机制 黑名单按查得收费，有些黑名单会掺沙子 有些名单提供商同时作为信贷放贷方，有动力将优质客户 截留，将其添加进名单","link":"/ML-Specification/FinTech/Risk-Control/rc_rules.html"},{"title":"风险管理","text":"互金风控 互金相对传统金融风控有更多挑战 模型迭代速度要求高 互金市场波动剧烈 长尾劣质客群更不稳定，容易导致样本波动 数据源采集种类更多 弱相关数据更多，处理难度更大 政策合规要求，数据采集和使用更规范 风控技术无关强弱，关键只在于“是否有效” 时机选择 制度安排及辅助 背后所驱动的支撑逻辑 风控领域，大数据等技术的应用场景和方向 自动化，尽量减少人工干预，减少主观臆断 实现“差异化”，客制化产品设计 补全客户画像 挖掘客户需求 精准度，需要模型驱动 交易成本评估 差异化定价 反欺诈 创新型评估 底层数据共享 风控策略 风控策略本质是规则集的逻辑组合 在贷前审批阶段减少风险事件发生 挽回风险事件发生的造成的损失 筛选用户：过滤高风险用户t保留低风险用户 对客群分级实行个性化审批流程，提高审批效率 广义看，策略也是一种模型 模型通过算法挖掘数据学习规律、构造特征；而策略则是 结合具体业务场景，依赖人工经验对客群细分，如决策树、 笛卡尔积分群 模型往往经过长时间稳定性验证，只有出现明显衰减时才会 触发迭代；策略上线、下线灵活，可以根据近期样本灵活 调整 模型需要在策略中应用才能发挥效果 风险控制 信用风险：侧重风险管理，在风险和收益之间寻求平衡，追求 利润最大化 通过金融属性数据识别客户还款能力、意愿 欺诈风险：侧重严防拒绝，属于欺诈必然拒绝 跟进欺诈风险事件，快速响应 反欺诈和信用顺序各有优劣，但是应该都做完之后得到综合授信 决策 反欺诈在后：欺诈后需要人工核验，处于成本考虑后置 信用在后：希望进入模型的数据更真实，否则会欺骗模型 造成错误决策 模型风险 模型：应用统计、经济、金融或数学理论、技术和假设将输入 数据处理为定量估计的量化方法、系统或途径 模型风险来源 模型自身错误：模型设计、开发以及IT实施时发生的错误 统计理论应用错误 目标变量错误 样本选择错误 变量挑选、衍生错误 算法错误 在信息系统中执行与开发不一致 模型被不恰当的使用 模型套用 市场环境、消费者行为习惯发生重大变化 美国监管部门围绕“有效挑战”指导原则，建立模型风险监管体系 动力：挑战者必须在组织上相对独立于模型开发者，有正向 激励挑战 胜任力：挑战者具备相关专业知识和技能 影响力：挑战者必须具备权威、组织内地位，来自更管理层 的承诺和支持，保障被挑战方对其意见有足够重视 https://mp.weixin.qq.com/s/95MVhXgyG9h5KqRphP14cA 风险监管体系框架 第一防线 模型开发者：开发、上线、使用、监控和维护模型，配合 模型验证部门的独立验证工作 管理维护者 使用者 第二防线 模型验证部门：独立验证模型 模型风险监管部门：草拟、执行模型风险管理政策 第三防线 内部审计：评估模型风险管理是否完整、严谨、有效 外部防线：政府监管 美联储 美国货币监理署 风险监管具体要求Model Inventory模型清单 模型状态 模型目的、设计的目的产品、预期和实际使用的场景、使用限制 输入数据、组件的类型和来源 输出及其预期用途 模型运行状态、更新时间、政策例外 开发、验证负责人 已完成和计划当中的验证目的 有效期 Model Development模型开发 明确模型目的 设计、理论、逻辑的研究支持 模型组件、算法的优缺点 与其他理论方法的比较 评估数据质量 证明数据、信息适合模型 替代数据需证明、记录 对必要的数据跟踪分析，尤其是外部数据、新客群、 新产品 测试确保符合预期 准确性 鲁棒性 稳定性 Model Implementatioin and Model Use 模型实施的需要有严谨的校验规范，保证上线模型与开发模型 一致 结果（包括中间结果）一致 底层数据一致 计算逻辑一致 模型使用可以进一步评估模型性能 模型使用者反馈模型使用情况、业务契合度 业务经理评估模型背后的方法、假设 其他利益不相关部门建议 模型的业务决策报表应清晰易懂 决策者和建模者知识背景可能不同 需要包含足够的输入、输出示例，充分展示模型各个维度 Model Validation 模型验证须由专业、独立的模型验证团队执行 有动力 有胜任力 有影响力 验证范围须包括模型所有组件 输入 处理 报告 验证的严格性、复杂性应与以下相适应 模型使用量 模型复杂性 模型重要性 业务规模和复杂性 模型验证分类 Initial Validation初始验证：首次使用前的验证 根据模型的缺陷选择是否接受 由于其他原因无法验证，应该记录在案，并通过其他补偿性 控制减轻模型不确定性 On-going Validation持续验证：模型投入使用后持续进行的 验证 跟踪已知问题并识别任何新的问题 确保市场、产品、风险敞口、活动、客户、业务实践不会 造成新的模型问题 Model Review定期复查 确定模型是否正常工作且现有的验证活动是否足够 验证框架要素 概念健全性评估：模型设计、构造的质量 审查相关文件与实践证据，确保模型设计、建造中使用的 方法、判断、变量选择有充分信息、经过仔细考虑，且与 已发表的研究和成功行业实践一致 结果分析，比较模型输出与实际结果，分析模型性能 各种量化、非量化的测试分析技术都有弱点，应根据模型 选择适当、一系列结果分析 量化结果有助于评估判断专家判断的质量、新旧模型性能 差距 结果分析应持续进行 除用保留样本（训练样本时间段内）分析模型性能外，还 需要使用训练样本时间段外样本进行back-testing 敏感性分析，检查模型的稳定性、鲁棒性 Model Monitoring 模型监控频率应与模型性质、新数据或建模方法的可用性，涉及 的风险程度相匹配 开发阶段发现的模型局限应在持续监控中定期评估 Processing Verification过程检验，检查所有模型组件是否 按设计运行 Benchmarking基准检验，与外部数据、模型进行比较 贷后管理 入催：当前逾期 忘记还款日逾期：轻微提醒即还款 习惯性逾期：轻微提醒、人工催收提醒即还款 资金困难，还款能力低：普遍回款率低 多头借贷高负债：还款意愿低，需要较强催收策略 暂时失去收入能力：还款意愿不差，但出催时间较久 有还款能力但不还：需较强催收策略提高还款意愿 欺诈：首逾，贷后没有解决办法 出催：结清逾期账单 AB-Test划分客户 步骤 为各类客户设置有针对性的特别催收策略 结合模型、规则初步初步设置筛选条件 筛选出该类型客户 将该类型客户分群A、B组 在A组应用一般催收策略、在B组应用针对性策略，比较策略 出催效果 针对性策略确定情况下，评估客户筛选条件 客户筛选条件给定的条件下，评估针对性策略 M1客户 对大部分公司的客群而言，M1阶段出催概率最大 此阶段较为重要，可设置多个模型重点学习不同客群规律 对不同客群施行不同催收策略，提高出催成功率 缓催响应人群：出于遗忘造成的逾期 在较短的缓催期内，简单的催收动作、或不催收即出催， 降低人力成本 不催 短信提醒 邮件提醒 机器人催收 对缓冲人群内部，可以通过不断AB-Test细分缓催人群 在不同时间段设置不同缓催方式 为不同人群设置不同缓催方式 非缓催人群 按出催难易程度，区分为普通案件、专家案件（难催用户） 难催客户入催早期还款概率远高于后期，在入催初期 即交由经验丰富 对还款能力、还款意愿分析，应用不同话术和催收策略 还款能力、还款意愿分析主要是根据特征变量设置 对还款能力差而还款意愿强的客户，可通过延期等方式 提升用户体验 对还款意愿弱的客户，通过催收动作提高还款意愿 对催收敏感程度分析 对催收动作敏感的人群，即催收动作越强，还款概率 越高，可以加强催收频率 M2+客户 M2+客户催出概率较低 若无特殊原因影响，发生过M2+用户需要重点关注 委外处理会损失资金 通过模型预测更易出催的客户，精细化人力管理 为精细化催收可以构建多个阶段模型 样本充足的情况下可以分别构建M2、M3模型 样本不够时，则可以构建M2+模型，不断积累决策、 建模样本 分析出催难易程度、催出敏感程度不同的客群，施行不同 催收策略","link":"/ML-Specification/FinTech/Risk-Control/risk_management.html"},{"title":"角点检测特征提取","text":"综述 corner point：角点，邻域各方向上灰度变化值足够高的点， 是图像边缘曲线上曲率极大值的点 分类 基于灰度图像的角点检测 基于梯度：计算边缘曲率判断角点 基于模板：考虑像素邻域点的灰度变化，将领域点亮度对比 足够大的点定义为角点 基于模板、梯度组合 基于二值图像的角点检测：将二值图像作为单独的检测目标， 可使用各种基于灰度图像的角点检测方法 基于轮廓曲线的角点检测：通过角点强度、曲线曲率提取角点 思想、步骤 使用角点检测算子，对图像每个像素计算 cornner response function值 E(u, v) = \\sum_{(x,y)} w(x,y)[I(x+u, y+v) - I(x,y)]^2 $w(x,y)$：window function，窗口函数 $I(x,y)$：图像梯度 $E(x,y)$：角点响应函数，体现灰度变化剧烈程度，变化 程度剧烈则窗口中心就是角点 阈值化角点响应函数值 根据实际情况选择阈值$T$ 小于阈值$T$者设置为0 在窗口范围内对角点响应函数值进行非极大值抑制 窗口内非响应函数值极大像素点置0 获取非零点作为角点 Moravectodo步骤 取偏移量$(\\Delta x, \\Delta y)$为 $(1,0), (1,1), (0,1), (-1,1)$，分别计算每个像素点灰度 变化 对每个像素点(x_i, y_i)$计算角点响应函数 $R(x) = min {E}$ 设定阈值$T$，小于阈值者置0 进行非极大值抑制，选择非0点作为角点检测结果 特点 二值窗口函数：角点响应函数不够光滑 只在4个方向（偏移量）上计算灰度值变化：角点响应函数会在 多处都有较大响应值 对每个点只考虑响应函数值最小值：算法对边缘敏感 HarrisGood Features to TrackFeature from Accelerated Segment TestFAST：加速分割测试获得特征","link":"/ML-Specification/Computer-Vision/corner_point_detection.html"},{"title":"边发现","text":"","link":"/ML-Specification/Graph-Analysis/link_prediction.html"},{"title":"台灯知识","text":"3种常见光源卤素灯（钨丝灯） 原理：真空中电阻（钨丝）通电发热发光 由爱迪生发明的钨丝灯改良而来 为了增加寿命，灯中添加碘（最好2000h） 光效：13lm/W（比较好的卤素灯） 色温：2700K（一般），颜色比较发黄 节能灯 原理：汞蒸气激发三基色荧光粉发光 工作时破碎有可能导致汞中毒 品质不好的节能灯有电磁辐射 光效：50-70lm/W 色温：5000~6000K，高色温居多 LED灯 原理 光效：100lm/W 色温：3000~6500K，台灯上一般4500~6000K 总结 卤素灯 节能灯 LED灯 安全性 发热、易碎 汞蒸气、易碎 安全 显色指数 99~100 80（一般） 80+ 能耗（800lm计） 17h 83h 125h 色温 2700K 5000~6000K 4500~6000K 价格 低 低 高 台灯国家标准GB 9473：台灯国家标准，引用以下标准 GB 7000：灯具通用安全标准 ZB K 74 003：螺口式灯座技术条件 ZB K 74 002：插口式灯座技术标准 GB 2313：管型荧光灯镇流器 SG 286：灯具油漆涂层 GB 7003：灯具电镀滑雪覆盖层 包括以下一些要求 台灯处于正常工作位置时，眼睛距台灯基座底平面垂直方向 400mm，离光源中心水平距离600mm处，水平方向应看不到灯罩 内壁及光源 台灯处于正常工作位置时，以光源为中心的垂直投影点为中心， 测量在中心前方1/3圆周上的照度 300mm处：不得&lt;250lx 500mm处：不得&lt;120lx 光照面照度比3.5以下（台灯要照得均匀） 其他常见问题频闪低频闪烁才有危害，此问题基本不用担心，基本是炒作；且使用手机 判断是否有频闪不可靠，取决于手机CMOS的工作方式 卤素灯：卤素灯发热发光，直接通220v交流电，因为靠发热， 有余晖效应，其亮度变化很小 节能灯： LED灯：需在直流电下工作，需要把交流电变为恒定直流，电流 大小不变则原则上没有闪烁问题（产品品质有保证） 但是带有调光功能（亮度、色温），LED可能有频闪，因为 其是通过调整LED的发光时间调整亮度（高频开光LED灯） 蓝光卤素灯蓝光很少，主要是红外部分，不会有蓝光危害问题 LED蓝光 单个LED只能发出单一颜色的光 为了得到白光（复合光），常用的办法是用蓝色LED芯片 产生蓝色光，然后激发荧光粉将部分蓝色光变为黄光，与 剩下的蓝光混合成白光 因此白光LED表面是黄色的。 且LED的色温越高，蓝光成分越高 国标国家新规GB7000.1-2015规定了蓝光问题： 带有整体式LED或LED模块的灯具应根据IEC/TR 62778进行蓝光 危害评估 对于儿童可移式灯具、小夜灯，在200mm距离处测得蓝光危害 等级不得超过RG1 蓝光危害 蓝光波长短、能量高，（过量情况下）对视网膜有害 影响褪黑素分泌，蓝光过多时，人容易兴奋睡不着 显色显色指数：光源对物体的显色能力，用太阳光作为参考，其显色指数 为100。显色指数越高，色彩还原能力越强越接近阳光。 台灯选择颜色要求高卤素灯，显色指数可以达到99-100，基本就是太阳光。影响卤素灯的 优劣的因素 亮度：国内已经禁止60W的卤素灯（白炽灯） 紫外线透出：材料不好，紫外线容易透出 寿命：冷态灯泡电阻小，瞬间电流很大，材料不好容易坏 欧司朗、飞利浦较好，不推荐国产 普通阅读LED，省电、美观。不适合的LED灯 LED可以看见：容易照成重影，导致视觉疲劳 亮度、色温可调：对频闪介意者不适合 色温高/低：睡觉/熬夜不适合，4500~5000K比较好","link":"/Daily-Life/lamp.html"},{"title":"NLP 总述","text":"文本挖掘 文本处理：将非结构化数据转换为结构化数据 预测建模 文本分类：根据观察到的对象特征值预测其他特征值 描述建模 文本聚类：对数据对象进行概括，以看到数据对象的最重要 特征 适应范围非常广 聚类分析 基于相似度方法 需要用户显式指定相似度函数 聚类算法根据相似度的计算结果将相似文本分在同一个组 每个文本只能属于一个组，因此也成为“硬聚类” 基于模型的方法 文本有多个标签，也成为“软聚类” 话题检测找出文档中的K个话题，计算每个文档对话题的覆盖率 话题表示方法基于单个词基于词分布问题描述 输入 N个文档构成的文本集C 话题个数K 词典V 输出 K个话题的分布 $(\\theta_1, \\theta2, \\cdots, \\theta_K)$ N个文档在K个话题上的概率分布 $(\\pi_1, \\pi_2, \\cdots, \\pi_N)$ 语言模型词向量：将向量表示词 1-of-N representation/one hot representation：one-hot 表示词 词向量维度为整个词汇表大小 简单、效率不高 distributed representation：embedding思想，通过训练， 将词映射到较短词向量中 词向量维度自定义 容易分析词之间关系 Continuous Bag-of-WordsCBOW：输入特征词上下文相关词对应词向量，输出特征词的词向量 CBOW使用词袋模型 特征词上下文相关从平等，不考虑和关注的词之间的距离 Skip-GramSkip-Gram：输入特征词词向量，输出softmax概率靠前的词向量 神经网络词向量神经网络词向量：使用神经网络训练词向量 一般包括三层：输入层、隐层、输出softmax层 从隐藏层到输出softmax层计算量很大 需要计算所有词的softmax概率，再去找概率最大值","link":"/ML-Specification/NLP/abstract.html"},{"title":"文本预处理","text":"文本预处理 去除噪声文档、文档中垃圾数据 停用词去除 词根还原（英文） 分词（中文） 词性标注 短语识别 词频统计 汉语分词分词：添加合适的显性词语边界标志，使所形成的词串反映句子本意 分词是正确处理中文信息的基础 文本基于单字 书面表达方式以汉字作为最小单位 词之间没有显性界限标志 用单个汉字作特征，不考虑词语含义，直接利用汉字在文本中 出现的统计特性对文本进行划分 直观明了 操作简单 对西语文本划分非常容易（使用空格划分） 使用词作为特征 词是中文语义的最小信息单位，可以更好的反映句子中信息 分析难度更高，中文文本中词之间没有分隔标记，正确分词 是关键 分词方法 基于词典 FMM：正向最大匹配分词 BMM：逆向最大匹配分词 BM法：双向扫描法 逐词遍历 基于统计模型 N-最短路径 HMM N元语法 由字构词的汉语分词方法 分词难点歧义切分 分词规范 分词单位 二字、三字以及结合紧密、使用稳定的 四字成语 四字词或结合紧密、使用稳定的四字词组 五字、五字以上谚语、格言等，分开后如不违背原有组合 意义，应切分 歧义切分 交集型切分歧义 组合型切分歧义 未登录词识别 词表词：记录在词表中的词 未登录词：词表中没有的词、或已有训练语料中未曾出现词 （此时也称为out of vocabulary） 真实文本切分中，未登录词总数大约9成是专有名词，其余为 新词 未登录词对分词精度影响是歧义词的10倍 命名实体识别：实体名词、专业名词 界定规则不存在太大分歧、构成形式有一定规律 在文本中只占8.7%，引起分词错误率59.2% 词性标注词性标注：在给定句子中判定每个词的语法范畴，确定词性并加以 标注的过程 POS作为特征可以更好的识别词语之间关系 词性标注计数为phrase chunking词组组块的界定、 entities and relationship实体与关系的识别打下良好 基础，有利于深入探索文本语义信息 词组的形式提高了特征向量的语义含量，使得向量更稀疏 难点 汉语缺乏词形态变化 常用词兼类现象严重：占11% 研究者主观原因：不同语料库有不同规定、划分方法 part of speech：POS，词性 Forward Maximum Matching MethodFMM：正向最大匹配分词 步骤 记词典中最长此表包含汉字数量为M 从材料中选取前$m = M$个汉字去作为匹配字段，查找分词 词典 若存在匹配词，则将其切分出 否则$m = m - 1$，重复 重复直至材料分词完毕 特点 对交叉歧义、组合歧义没有解决办法 错误切分率为$\\frac 1 {169}$ Backward Maximum Matching MethodBMM：逆向最大匹配分词 步骤：类似FMM，仅从材料/句子末尾开始处理 特点 错误切分率$\\frac 1 {245}$，较FMM更有效 Bi-direction Matching MethodBM法：双向扫描法 步骤：比较FMM、BMM法切分结果，决定正确切分 特点 可以识别分词中交叉语义 N-最短路径 思想 考虑待切分字串$S=c_1 c_2 \\cdots c_n$，其中$c_i$为 单个字、$n$为串长 建立节点数为$n+1$的切分有向无环图，各节点编号为 $V_0, V_1, \\cdots, V_n$ 相邻节点间存在边 若$w=ci c{i+1} \\cdots cj$是一个词，则节点 $v{i-1}, v_j$直接存在边 所有边距离均为1 求有图无环图中最短路径 特点 算法时间复杂度为$O(nNK)$ $n$：字串长度 $N$：最短路径数目 $k$：某个字作为词末端字的平均次数 改进—考虑噪声基于统计信息的粗分模型 考虑词串$W$经过信道传输，由于噪声干扰丢失词界切分标志， 到输出端为字串$C$ N-最短路径词语粗分模型可以改进为：求N个候选切分$W$，使得 概率$P(W|C)$为前N个最大值 P(W|C) = \\frac {P(W) P(C|W)} {P(C)} $P(C)$：字串概率，常数 $P(C|W)$：仅有 采用一元统计模型，设$W=w_1w_2\\cdots W_m$是字串 $S=c_1c_2\\cdots c_n$的切分结果，则其切分概率为 \\begin{align*} P(W) & = \\prod_{i=1}^m P(w_i) \\\\ P^{*}(W) = -ln P(w) = \\sum_{i=1}^m (-ln P(W_i)) \\end{align*} $P(w_i)$：词$w_i$出现概率，在大规模预料训练的基础上 通过极大似然方法得到 则$-lnP(w_i)$可看作是词$w_i$在切分有向无环图中对应距离， 改进N-最短路径方法 由字构词假设、背景 思想：将分词过程看作字分类问题，认为每个字在构造特定词语 时，占据确定的位置 中文词一般不超过4个字，字位数量很小 首部B 词中M 词尾E 单独成词S 部分汉字按一定方式分布，有规律 利用相对固定的字推断相对不定的字的位置问题 虽然无法将所有词列入词典，但字基本稳定 步骤 对所有字根据预定义的特征进行词位特征学习，获得概率 模型 在带待分字串上根据字与字之间的结合紧密程度得到词位的分类 结果 根据词位定义直接获得最终分词结果 Productivity能产度：词$c_i$在词位$t_j$的能产度定义为 P_{c_i}(t_j) = \\frac {count(c_i, t_j)} \\sum_{t_j \\in T} count(c_i, t_j) $T = {B, B_2, B_3, M, E, S}$ 主词位：给定字在其上能产度高于0.5的词位 |标记|B|B2|B3|M|E|S|总字量| |——-|——-|——-|——-|——-|——-|——-|——-| |字量|1634|156|27|33|1438|632|3920| |百分比|31.74|3.03|0.52|0.64|27.94|12.28|76.16| MSRA2005语料库中有主词位的字量分布 自由字：没有主词位的字 自由字是基于词位分类的分词操作得以有效进行的的基础 之一 字：不仅限于汉字，包括标点、外文字母、注音符号、数字等 任何可能文字符号 优势 能平衡词表词、未登录词 简化分词系统设计 无需强调词表词信息 无需设置特定未登录词识别模块 分词评价指标 正确率 召回率 F-测度值 Vector Space Model向量空间模型：自然语言处理常用模型 document：文档，句子、段落、整篇文章 term/feature：词根、词、短语、其他 weight：项的权重，每个特征项在文档中重要程度 相似度比较 内积 sim(D_1, D_2) = \\sum_{k=1}^n w_{1,k} w_{2,k} Cosine相似度 cos(D_1, D_2) = cos \\theta = \\frac {\\sum_{k=1}^n w_{1,k} w_{2,k}} {\\sqrt{\\sum_{k=1}^n w_{1,k}^2 \\sum_{k=1}^n w_{2,k}^2}} 权重 布尔权重：$bw_{t,d} = {0, 1}$ TF：绝对词频，$TF{t,d} = \\frac {n{t,d}} {n_d}$ IDF：倒排文档频度，$IDF_{t,d} = log \\frac M {m_t}$ TF-IDF：$TF-IDF{t,d} = TF{t,d} * IDF_{t,d}$ TF-IWF：$TFIWF{t,d}= TF{t,d} log \\frac {\\sum{t=1}^T \\sum{d=1}^N n{t,d}} {\\sum{t=1} n{t,d}}$ $t_{t,d}$：文档$d$中出现特征$t$的次数 $t_d$：文档$d$中出现总词数 $m_t$：训练集中出现特征$t$文档数 $M$：训练集中文档总数 $K$：特征总数量 特征加权 特征加权主要包括三个部分（层次） 局部加权：使用词语在文档中的统计量 全局加权：词语在整个数据集中的统计量 标准化 一般化特征加权表达式 L_d(w) G(w) N_d $L_d(w)$：词$w$在文档$d$中的局部权重 $G(w)$：词$w$在文档集合中的全局权重 $N_d$：文档d的标准化因子 Document FrequencyDF：文档频率，文本数据中包含某词条的文档数目 通过文档频率进行特征选择：按文档频率大小对词条进行排序 将DF小于某阈值的词删除 稀有词项全局影响力不大 文档若有稀有词向，通常也会有常见词项 和通常信息获取观念抵触：稀有更有代表性 将DF大于某阈值的词删除 太频繁词词项没有区分度 容易实现、可扩展性好 其他指标 信息增益/互信息 卡方统计量 Latent Semantic AnalysisLSA：潜在语义分析 文本分析中常用的降维技术 特征重构方法 很好解决了同义词、一词多义等现象给文本分析造成的困难 理论依据、假设 认为有潜在语义结构隐含在文档中词语的上下文使用模式中 而文档词频共现矩阵在一定程度可以反映词和不同主题之间 关系 以文档词频矩阵为基础进行分析 得到向量空间模型中文档、词的高维表示 并通过投影形成文档、词在潜在语义空间中的相对稠密的 低维表示，缩小问题规模 通过这种低维表示解释出“文档-语义-词语”之间的联系 数学描述 LSA将每个文本视为以词语/特征为维度的空间的点，包含 语义的文本出现在空间中分布服从某种语义结构 LSA将每个词视为以文档为维度的空间中点 文档由词语构成，词语需要放在文档中理解，体现词语和 文档之间的双重概率关系 应用SVD分解 词频共现矩阵$X=(x_{d,t})$：文档、词语的共现频率矩阵 其中每行代表文档向量 每列代表词语向量 元素$x_{d,t}$表示文档$d$中词$t$出现的频率 对词频共现矩阵$X$进行SVD分解得到$X=U \\Sigma V^T$ 仅保留$\\Sigma$中满足阈值要求的较大的前$r$特征值， 其余置为0，得到 $\\tilde X = \\tilde U \\tilde \\Sigma \\tilde V^T$，达到信息 过滤、去除噪声的目的 $A = \\tilde X$：矩阵特征分解后的文档词频矩阵近似 $T = \\tilde U$：文档和潜在语义的关系矩阵近似 $S = \\tilde V$：词语和潜在语义的关系矩阵近似 $D = \\tilde \\Sigma$：各潜在语义的重要程度 说明 从数据压缩角度：近似矩阵是秩为$K$的前提下，矩阵$X$的最小 二乘意义下最佳近似 r值过大会增加运算量，一般选择K使得贡献率满足 \\sum_{i=1}^r d_i / \\sum_{i=1}^K d_i \\geq \\theta $\\theta$：阈值 $K$：原始词频共现矩阵秩 LSA缺点 SVD的向量元素有正、有负，性质难以解释 SVD的实际意义不够明确，难以控制词义据类的效果 涉及高维矩阵运算 相似关系计算 潜在语义空间中存在：词-词、文本-文本、词-文本3种关系， 可以通过近似矩阵$T, S, D$计算 比较词汇两两相似度：“正向乘法” A A^T = T S D^T D S^T T^T = T S^2 T^T 比较文本两两相似度：“逆向乘法” A^T A = T^T S^T D D^T S T = T^T S^2 T 词汇、文本两两相似度：就是原始矩阵$X$的近似矩阵本身$A$ A = T * S * D^T","link":"/ML-Specification/NLP/features_extractions.html"},{"title":"RNN 语言模型","text":"","link":"/ML-Specification/NLP/rnn_language_models.html"},{"title":"Word2Vec","text":"Word2VecWord2Vec：word embeding的一种，使用层次化softmax、负采样 训练词向量 Hierarchical Softmax层次Softmax 对所有词向量求和取平均作为输入层到隐层的映射 （特指CBOW模型） 使用霍夫曼树代替从隐藏层到输出softmax层的映射 思想 softmax需要对$m$个类别求出softmax概率，参数多、计算复杂 考虑将$m$个类别划分为多个二分类sigmoid，即 将总类别划分为两组 依次判断数据点属于哪组 直至数据点所属组仅包含一个类别 则多个sigmoid划分构成一棵二叉树，树叶子节点即为$m$ 类别 二叉树结构可以由多种，最优二叉树应该使得对整个 数据集而言，sigmoid判断次数最少 即应该使用按照数据点频数构建的霍夫曼树 霍夫曼树 模型 输入$x^T$所属类别霍夫曼编码为$d={d_1,\\cdots,d_M}$， 则应最大化如下似然函数 \\begin{align*} \\prod_{i=1}^M P(d_i|x, w_{j_i}) & = \\prod_{i=1}^M [\\sigma(x^T w_{j_i} + b_{j_i})]^{d_i} [1 - \\sigma(x^T w_{j_i} + b_{j_i})]^{1-d_i} \\\\ P(d_i|x, w_{j_i}) & = \\left \\{ \\begin{array}{l} 1 - \\sigma(x^T w_{j_i} + b_{j_i}), & d_i = 0 \\\\ \\sigma(x^T w_{j_i} + b_{j_i}), & d_i = 1 \\end{array} \\right. \\\\ \\sigma(z) & = \\frac 1 {1 + e^z} \\end{align*} $w_j, b_j$：节点$j$对应sigmoid参数 $P(d_i)$：以sigmoid激活值作为正例概率 （也可以其作为负例概率，但似然函数需更改） 则对数似然函数为 L = log \\prod_{i=1}^M P(d_i|x, w_{j_i}) = \\sum_{i=1}^M d_i log [\\sigma(x^T w_{j_i} + b_{j_i})] {1-d_i} log [1 - \\sigma(x^T w_{j_i} + b_{j_i})] 梯度计算 则参数$w_{j_M}$梯度如下 \\begin{align*} \\frac {\\partial L} {\\partial w_{j_M}} & = d_M [1-\\sigma(x^T w_{j_M} + b_{j_M})] x - (1 - d_M) \\sigma(x^T w_{j_M} + b_{j_M}) x \\\\ & = (d_M - \\sigma(x^T w_{j_M} + b_{j_M})) x \\end{align*} 词向量$x$梯度如下 \\frac {\\partial L} {\\partial x} = \\sum_{i=1}^M (d_i - \\sigma(x^T w_{j_i} + b_{j_i})) w_{j_i} CBOW流程 特征词周围上下文词均使用梯度更新，更新输入 基于预料训练样本建立霍夫曼树 随机初始化模型参数$w$、词向量$w$ 对训练集中每个样本 $(context(x), x)$（$2C$个上下文）如下 计算，直至收敛 置：$e=0, xw=\\frac 1 {2C} \\sum{c=1}^{2C} x_c$ 对$x$的霍夫曼编码 $d={d_1, \\cdots, d_M}$ 中 $d_i$ 计算 \\begin{align*} \\sigma_i & = \\sigma(x_w^T w_{j_i} + b_{j_i}) \\\\ g & = (d_i - \\sigma_i) \\eta \\\\ e & = e + g w_{j_i} \\\\ w_{j_i} & = w_{j_i} + g x_w \\end{align*} 更新 $2C$ 上下文词对应词向量 x_i = x_i + e Skip-Gram流程 考虑上下文是相互的，则 $P(x{context}|x)$ 最大化时，$P(x|x{context})$ 也最大 为在迭代窗口（样本）内更新仅可能多词向量，应该最大化 $P(x|x_{context})$，使用梯度更新上下文 $2C$ 个词向量，更新输出（条件概率中更新条件） 基于预料训练样本建立霍夫曼树 随机初始化模型参数 $w$、词向量 $w$ 对训练集中每个样本 $(x, context(x))$、每个样本中上下文词向量 $x_c$（$2C$ 个上下文），训练直至收敛 置：$e=0$ 对 $x$ 的霍夫曼编码 $d={d_1, \\cdots, d_M}$ 中 $d_i$ 计算 \\begin{align*} \\sigma_i & = \\sigma(x_c^T w_{j_i} + b_{j_i}) \\\\ g & = (d_i - \\sigma_i) \\eta \\\\ e & = e + g w_{j_i} \\\\ w_{j_i} & = w_{j_i} + g x_c \\end{align*} 更新 $2C$ 上下文词对应词向量 x_c = x_c + e Negtive Sampling负采样 思想 通过负采样得到$neg$个负例 对正例、负采样负例建立二元逻辑回归 模型、梯度 对类别为$j$正例、负采样负例应有如下似然函数、对数似然 函数 \\begin{align*} P(context(x), x) & = \\sigma(x^T w_j) \\prod_{i=1}^{neg} (1 - \\sigma(x^T w_j)) \\\\ L & = log P(context(x), x) \\\\ & = \\sum_{i=0}^{neg} [y_i log(\\sigma(x^T w_j)) + (1 - y_i) log(\\sigma (x^T w_j))] \\end{align*} $y_i$：样本点标签，$y_0$为正例、其余负例 同普通LR二分类，得到参数、词向量梯度 \\begin{align*} \\frac {\\partial L} {\\partial w_j} & = (y_i - \\sigma(x^T w_j)) x \\\\ \\frac {\\partial L} {\\partial x} & = \\sum_{i=1}^{neg} (y_i - \\sigma(x^T w_j)) w_j \\end{align*} 负采样方法 每个词对应采样概率为词频取$3/4$次幂后加权 p(x_0) = \\frac {count(x_0)^{3/4}} {\\sum_{x \\in vocab} count(x)^{3/4}} CBOW流程 随机初始化所有模型参数、词向量 对每个训练样本$(context(x_0), x_0)$负采样$neg$个中心词 $x_i$，考虑$x_0$为类别$j$ 在以上训练集$context(x0), x_0, x_1, \\cdots, x{neg}$中 训练直至收敛 置：$e=0, xw=\\frac 1 {2C} \\sum{c=1}^{2C} x_c$ 对样本$x0, x_1, \\cdots, x{neg}$，计算 \\begin{align*} \\sigma_i & = \\sigma(x_w^T w_j + b_j) \\\\ g & = (y_i - \\sigma_i) \\eta \\\\ e & = e + g w_j \\\\ w_j & = w_j + g x_w \\end{align*} 更新$2C$上下文词对应词向量 x_i = x_i + e Skip-gram中心词 类似Hierarchical Softmax思想，更新输出$2C$个词向量 随机初始化所有模型参数、词向量 对每个训练样本$(context(x_0), x_0)$负采样$neg$个中心词 $x_i$，考虑$x_0$为类别$j$ 以上训练集$context(x0), x_0, x_1, \\cdots, x{neg}$中， 对每个上下文词向量$x_c$如下训练直至收敛 置：$e=0$ \\begin{align*} \\sigma_i & = \\sigma(x_c^T w_j + b_j) \\\\ g & = (y_i - \\sigma_i) \\eta \\\\ e & = e + g w_j \\\\ w_j & = w_j + g x_c \\end{align*} 更新$2C$上下文词对应词向量 x_c = x_c + e","link":"/ML-Specification/NLP/word2vec.html"},{"title":"CTR Stacking Models","text":"深度学习CTR Deep CrossingDeep Crossing：深度学习CTR模型最典型、基础性模型 multiple residual units：残差网络 Factorization Machine based Neural NetworkFNN：使用FM隐层作为embedding向量，避免完全从随机状态训练 embedding 输入特征为高维稀疏特征，embeddingd层与输入层连接数量大、 训练效率低、不稳定 提前训练embedding提高模型复杂度、不稳定性 Product-based Neural NetworkPNN：在embedding层、全连接层间加入product layer，完成 针对性特征交叉 product layer：在不同特征域间进行特征组合，定义有 inner、outer product以捕捉不同的交叉信息，提高表示能力 传统DNN中通过多层全连接层完成特征交叉组合，缺乏针对性 没有针对不同特征域进行交叉 不是直接针对交叉特征设计 Wide&amp;Deep NetworkWide&amp;Deep：结合深层网络、广度网络平衡记忆、泛化 deep models：基于稠密embedding前馈神经网络 wide models：基于稀疏特征、特征交叉、特征转换线性模型 基于记忆的推荐通常和用户已经执行直接相关；基于泛化的推荐 更有可能提供多样性的推荐 memorization：记忆，学习频繁出现的物品、特征，从历史 数据中探索相关性 generalization：泛化，基于相关性的transitivity，探索 较少出现的新特征组合 https://arxiv.org/pdf/1606.07792.pdf wide&amp;deep系模型应该都属于stacking集成 Google App Store实现 P(Y=1|x) = \\sigma(w_{wide}^T[x, \\phi(x)] + w_{deep}^T \\alpha^{l_f} + b) wide部分：cross product transformation 输入 已安装Apps impression Apps 特征工程交叉特征 优化器：带L1正则的FTRL Deep部分：左侧DNN 输入 类别特征embedding：32维 稠密特征 拼接：拼接后1200维 （多值类别应该需要将embedding向量平均、极大化） 优化器：AdaGrad 隐层结构 激活函数relu优于tanh 3层隐层效果最佳 隐层使用塔式结构 DeepFMDeepFM：用FM替代wide&amp;deep中wide部分，提升其表达能力 Dense Embeddings：FM中各特征隐向量，FM、DNN公用 FM Layer：FM內积、求和层 \\begin{align*} y_{FM} & = + \\sum_i \\sum_j x_i x_j + b \\\\ \\hat y_{DeepFM} & = \\sigma(y_{FM} + y_{DNN}) \\end{align*} 特点（和Wide&amp;Deep关键区别） wide部分为FM （deep&amp;wide中wide部分有特征交叉，但依靠特征工程实现） FM、DNN部分共享embedding层 同时组合wide、二阶交叉、deep三部分结构，增强模型表达能力 FM负责一阶特征、二阶特征交叉 DNN负责更高阶特征交叉、非线性 实现 DNN部分隐层 激活函数relu优于tanh 3层隐层效果最佳 神经元数目在200-400间为宜，略少于Wide&amp;Deep 在总神经元数目固定下，constant结构最佳 embedding层 实验中维度为10 Deep&amp;Cross NetworkDeep&amp;Cross：用cross网络替代wide&amp;deep中wide部分，提升其 表达能力 特点（和WDL、DeepFM区别） 使用交叉网络结构提取高阶交叉特征 无需特征工程（WDL） 不局限于二阶交叉特征（DeepFM） 交叉网络可以使用较少资源提取高阶交叉特征 https://arxiv.org/pdf/1708.05123.pdf 交叉网络交叉网络：以有效地方式应用显式特征交叉，由多个交叉层组成 \\begin{align*} x_{l+1} & = f(x_l, w_l, b_l) + x_l \\\\ & = x_0 x_l^T w_l + b_l + x_l \\end{align*} $x_l$：第$l$交叉层输出 $w_l, b_l$：第$l$交叉层参数 借鉴残差网络思想 交叉层完成特征交叉后，会再加上其输入 则映射函数$f(x_l, w_l, b_l)$即拟合残差 特征高阶交叉 每层$x_0 x_l^T$都是特征交叉 交叉特征的阶数随深度$l$增加而增加，最高阶为$l+1$ 复杂度（资源消耗） 随输入向量维度、深度、线性增加 受益于$x_l^T w$为标量，由结合律无需存储中间过程矩阵 Nueral Factorization MachineNFM：用带二阶交互池化层的DNN替换FM中二阶交叉项，提升FM的 非线性表达能力 \\begin{align*} \\hat y_{NFM}(x) & = w_0 + \\sum_{i=1}^m w_i x_i + f_{DNN}(x) \\\\ & = w_0 + \\sum_{i=1}^m + h^T f_{\\sigma}(f_{BI}(\\varepsilon_x)) \\end{align*} $f_{DNN}(x)$：多层前馈神经网络，包括Embedding Layer、 Bi-Interaction Layer、Hidden Layer、 Prediciton Layer $h^T$：DNN输出层权重 模型结构 Embedding Layer全连接网络：将每个特征映射为稠密向量表示 \\varepsilon_x = \\{x_1v_1, x_2v_2, \\cdots, x_mv_m\\} $v_i$：$k$维embedding向量 只需要考虑非0特征，得到一组特征向量 特征向量会乘以特征值以反映真实值特征 （一般embedding特征取0/1，等价于查表） Bi-Interaction LayerBI层：将一组embedding向量转换为单个向量 \\begin{align*} f_(BI)(\\varepsilon_x) & = \\sum_{i=1} \\sum_{j=i+1} x_i v_i \\odot x_j v_j \\\\ & = \\frac 1 2 (\\|\\sum_{i=1}^m x_i v_i\\|_2^2 - \\sum_{i=1}^m \\|x_i v_i\\|_2^2) \\end{align*} $\\odot$：逐元素乘积 没有引入额外参数，可在线性时间$\\in O(kM_x)$内计算 可以捕获在低层次二阶交互影响，较拼接操作更 informative，方便学习更高阶特征交互 将BI层替换为拼接、同时替换隐层为塔型MLP（残差网络） 则可以得到wide&amp;deep、DeepCross 拼接操作不涉及特征间交互影响，都交由后续深度网络学习 ，实际操作中比较难训练 Hidden Layer隐层：普通多层嵌套权重、激活函数 f_{\\sigma} = \\sigma_l(\\beta_l (\\cdot \\sigma_1(\\beta_l f_{BI}(\\varepsilon_X) + b_1)) + b_l) $l=0$没有隐层时，$f_{\\sigma}$原样输出，取$h^T$为 全1向量，即可得FM模型 Attentional Factorization MachinesAFM：引入Attention网络替换FM中二阶交互项，学习交互特征的 重要性，剔除无效的特征组合（交互项） \\begin{align*} \\hat y_{AFM} & = w_0 + \\sum_{i=1}^m w_i x_i + f_{AFM}(\\varepsilon) \\\\ & = w_0 + \\sum_{i=1}^m w_i x_i + p^T \\sum_{i=1}^m \\sum_{j=i+1}^m a_{i,j} (v_i \\odot v_j) x_i x_j \\end{align*} $\\varepsilon$：隐向量集，同上 $p^T$：Attention网络输出权重 模型结构 Pair-Wise Interaction Layer成对交互层：将m个embedding向量扩充为$m(m-1)/2$个交互向量 f_{PI}(\\varepsilon) = \\{(v_i \\odot v_j) x_i x_j\\}_{(i,j) \\in R_X} $R_X = {(i,j) | i \\in X, j \\in X, j &gt; i }$ $v_i$：$k$维embedding向量 Attention-based Pooling注意力池化层：压缩交互作用为单一表示时，给交互作用赋不同权重 \\begin{align*} f_{Att}(f_{PI}(\\varepsilon)) = \\sum_{(i,j) \\in R_X} a_{i,j} (v_i \\odot v_j) x_i x_j \\end{align*} $a{i,j}$：交互权重$w{i,j}$的注意力得分 $\\odot$：逐元素乘积 考虑到特征高维稀疏，注意力得分不能直接训练，使用MLP attention network参数化注意力得分 \\begin{align*} a_{i,j}^{'} & = h^T ReLU(W((v_i \\odot v_j) x_i x_j) + b) \\\\ a_{i,j} & = \\frac {exp(a_{i,j}^{'})} {\\sum_{(i,j) \\in R_X} exp(a_{i,j}^{'})} \\end{align*} $W \\in R^{t*k}, b \\in R^t, h \\in R^T$：模型参数 $t$：attention network隐层大小 Deep Interest NetworkDIN：融合Attention机制作用于DNN 模型结构 activation unit激活单元 \\begin{align*} v_U(A) & = f_{au}(v_A, e_1, e_2, \\cdots, e_H) \\\\ & = \\sum_{j=1}^H a(e_j, v_A) e_j \\\\ & = \\sum_{j=1}^H w_j e_j \\end{align*} 相较于上个结构仅多了直接拼接的用户、上下文特征 模型训练Mini-batch Aware Regularization 以Batch内参数平均近似$L_2$约束 \\begin{align*} L_2(W) & = \\sum_{i=1}^M \\sum_{j=1}^B \\sum_{(x,y) \\in B_j} \\frac {I(x_i \\neq 0)} {n_i} \\|W_i\\|_2^2 \\\\ & \\approx \\sum_{i=1}^M \\sum_{j=1}^B \\frac {\\alpha_{j,i}} {n_i} \\|W_i\\|_2^2 \\end{align*} $W \\in R^{K * M}, W_i$：embedding字典、第$i$embedding 向量 $K, M$：embedding向量维数、特征数量 $B, B_j$：batch数量、第$j$个batch 则参数迭代 W_i \\leftarrow w_j - \\eta[\\frac 1 {|B_j|} \\sum_{(x,y) \\in B_j} \\frac {\\partial L(p(x), y)} {\\partial W_j} + \\lambda \\frac {\\alpha_{j,i}} {n_i} W_i] Data Adaptive Activation Function\\begin{align*} f(x) & = \\left \\{ \\begin{array}{l} x, & x > 0 \\\\ \\alpha x, & x \\leq 0 \\end{array} \\right. \\\\ & = p(x) * x + (1 - p(x)) * x \\\\ p(x) & = I(x > 0) \\end{align*}PReLU在0点处硬修正，考虑使用其他对输入自适应的函数替代，以 适应不同层的不同输入分布 p(x) \\frac 1 {1 + exp(-\\frac {x - E[x]} {\\sqrt{Var[x] + \\epsilon}})}Deep Interest Evolution NetworkDIEN：引入序列模型AUGRU模拟行为进化过程 模型结构 Interest Extractor Layer：使用GRU单元建模历史行为依赖 关系 ? 关系","link":"/ML-Specification/Click-Through-Rate/Recommandation-System/ctr_stacking_models.html"},{"title":"视频推荐","text":"Matching基于用户行为离线协同过滤 根据用户行为日志，利用物品-based协同过滤生成离线的 物品2物品相似度矩阵、用户离线推荐结果 基于艾宾浩斯遗忘曲线按照时间进行降权 弱化热点影片的权重 矩阵分解 基于用户的playlog接口实时获取用户的短时间内的观看历史， 通过物品2物品相似度矩阵进行CF扩散，提取出与用户短时间内 观看历史相似的topN个物品用于召回 用户的CF离线推荐结果直接作为线上服务的召回渠道 W2V 全部影片作为预料库、观看历史按时序排列视为文档，计算所有 物品的词向量 根据词向量计算物品2物品相似度矩阵，用于线上playlog召回 数据 LDA 基于概率主题模型：文档-潜在主题-词三级关系，映射/类比到 用户行为数据：用户-潜在兴趣-资源 通过用户历史行为记录，提取LDA中间产物、用户的潜在兴趣 向量、资源潜在主题分布向量 基于物品的主题向量，进行物品2物品相似度计算，用于线上 playlog召回数据 SimRank 将用户、物品关系视为二部图，考虑相似关系可以在图上传播 思想，使用SimRank计算物品相似队列 基于内容基于标题 对影片文本简介使用doc2vector，计算资源的表示向量 使用资源的表示项集计算物品2物品相似度矩阵 基于Style基于Tag其他方向 RNN捕捉用户在点击序列中的模式，利用点击行为发生先后顺序 调整推荐展示顺序 Graph Embedding Ranking特征工程 低维稠密通用特征：泛化能力良好、记忆能力差 embedding特征 统计特征 高维稠密特征：记忆能力较好 视频ID 标签 主题 分类 按特征来源分类 物品特征：资源风格、低于、类型、标签、统计特征 用户特征：性别、年龄、婚姻状况、收入预测 context特征：网络状态、时间段、城市 交叉特征 按特征更新频率、获取方式 离线特征：变化缓慢，如：用户、物品基本特征、统计特征 近在线特征：分钟级、小时级需要更新的特征，如：ctr 在线特征：每次请求达到实时获取特征，如：网络状态、 请求时间 特征扩充 用户兴趣向量丰富用户维度上兴趣特征 LDA中间产物作为用户潜在兴趣向量 W2V词向量、用户行为历史统计出用户兴趣向量 资源embedding向量丰富物品维度特征 用户行为数据embedding得到W2V、LDA词向量 资源标题embedding得到doc2vector词向量 资源封面AutoEncode向量 基于资源封面采用自编码器训练，提取隐层向量作为资源 特征 统计特征细化 特征工程时间窗口细化：按不同时间窗口分别计算资源的统计 特征 丰富资源特征 融入时间衰减因素 在线特征交叉：交叉特征增加样本特征的区分度 连续特征离散化 目标：避免特征为长尾分布、大部分取值集中在小范围，对样本 区分度差 等频离散化：等频分桶、独热编码 对数转化 采样策略 负样本采样策略调整：基本曝光时间、顺序，过滤负样本 不平衡样本策略调整：离线A/B测试正负样本比例，择优调整 模型 一般使用stacking模型堆叠集成 参见ml_models/model_enhancement/ensemble_stacking 基学习器 GBDT：各树、各叶子节点对应一维特征 适合低维稠密通用特征，对输入特征分布没有要求 DNN 适合普通稠密特征、embedding特征 能抽取有良好分布数据的深层次特征，提高模型准确性、 泛化能力 元学习器 LR 适合低维稀疏特征，可对所有特征离散化以引入非线性 FM 适合低维稀疏特征 LR基础上自动组合二阶交叉项 Linear：训练模型、对训练结果线性加权 冷启动、EE冷启动Matching 冷启动用户召回 使用imbd算法计算资源得分，根据不同时间周期进行得分 融合、并ab测试，选取最优时间周期组合 按照imdb得分倒排，生成热点召回数据 冷启动资源召回 基于资源库，统计各资源点击、播放率，按一定比例召回 第点击、播放率物品 Ranking 通常使用强化学习算法 Thompson Sampling UCB算法 Epsilon-Greedy算法 朴素Bandit算法 LinUCB算法：较UCB算法加入特征信息 COFIBA算法：Bandit算法结合协同过滤 Exploration and Exploitation TradeoffMatching 调整不同召回渠道的配比方式保证多样性","link":"/ML-Specification/Click-Through-Rate/Recommandation-System/video_recsys.html"},{"title":"Recommendation System","text":"推荐系统架构 Matching召回算法Match：包含多个渠道的召回模型，希望从资源库中选取 多样性偏好内容，缩小排序目标 协同过滤 主题模型 内容召回 热点召回 Ranking排序：对多个召回渠道内容打分、排序、选出最优的少量结果 若召回结果仍包含大量数据，可以考虑分为两个阶段 粗排：进一步剔除召回结果 精排：对粗排结果再次打分、排序，得到最终推荐结果 Collaborative Filtering-Based Recommendation基于协同过滤推荐算法：推荐算法中主流 模型一般为n个物品、m个用户的表 只有部分用户、物品之间有评分数据 要用已有部分稀疏数据预测空白物品、数据之间评分关系， 推荐高评分物品 无需太多特定领域的知识，可通过基于统计的机器学习算法得到 较好推荐效果，可以分为 基于用户 基于物品 基于模型 现在指推荐算法一般指协同过滤，其他基于内容、规则、人口 统计信息等都被包含/忽略 User-based基于用户协同过滤：主要考虑用户之间相似度，找出相似用户、相似 用户喜欢的物品，预测目标用户对对应物品的评分，推荐高评分物品 特点：（相较于Item-Based）推荐更社会化 反映用户所在小型兴趣群体中物品热门程度 可帮助用户找到新类别、惊喜物品 适合场景 用户数量较少、变化慢场合，否则更新、计算用户相似度矩阵 代价大 时效性强、用户个性化兴趣不明显领域 无需给出推荐解释 示例 新闻推荐：注重热门、时效、item更新快 热点视频推荐 方法 基于规则：大众型推荐方法，如：最多用户点击、浏览 基于人口统计信息：简单根据用户基本信息发现用户相关 程度、推荐 混合推荐 结合多个推荐算法，集成算法推荐结果 复杂度高 Item-Based Collaborative Filtering基于项目协同过滤：考虑物品和物品之间的相似度，找到目标用户 对某些物品的评分，预测用户对相似度高的类似物品评分，推荐高 评分相似物品 特点：（相较于User-Based）推荐更个性化 反映用户自身的兴趣传承 可帮助用户深入挖掘自身兴趣 准确度一般 推荐多样性弱，难以带来惊喜 适合场景 物品数量较少、变化慢场合，否则更新、计算物品相似度 矩阵代价大 长尾物品丰富、个性化需求不明显 需要向用户给出推荐理由 示例 电商 电影：兴趣持久、更个性化 Model-Based Collaborative Filtering基于模型：目前最主流的协同过滤类型 关联算法：找出用户-物品数据里频繁出现的项集，作频繁集 挖掘，推荐频繁集、序列中其他物品 Apriori FPTree PrefixSpan 聚类算法：按照用户、物品基于一定距离度量聚类，推荐高评分 同类物品、同类人群 （类似于基于用户、物品协同过滤） K-means BIRCH DBSCAN Spectral Clustering 分类算法：使用分类模型划分物品 逻辑回归 朴素贝叶斯 回归算法：使用回归模型给物品预测打分，较分类更平滑 线性回归 决策树 SVM 矩阵分解：对用户-物品评分矩阵进行分解 FunkSVD BiasSVD SVD++ 还有基于图模型、神经网络等新模型 还有依赖于自然语言处理NLP，通过挖掘文本内容特征，得到 用户的偏好，进而做推荐，同样可以找到用户独特的小众喜好","link":"/ML-Specification/Click-Through-Rate/Recommandation-System/recommendation_system.html"},{"title":"卷积层","text":"Conv1D12345678910111213141516keras.layers.convolutional.Conv1D( filters(int), kernel_size(int), strides=1, padding='valid', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None) 一维卷积层（即时域卷积） 说明 用以在一维输入信号上进行邻域滤波 作为首层时，需要提供关键字参数input_shape 该层生成将输入信号与卷积核按照单一的空域（或时域） 方向进行卷积 可以将Convolution1D看作Convolution2D的快捷版 参数 filters：卷积核的数目（即输出的维度） kernel_size：整数或由单个整数构成的list/tuple， 卷积核的空域或时域窗长度 strides：整数或由单个整数构成的list/tuple，为卷积 步长 任何不为1的strides均与任何不为1的dilation_rate 均不兼容 padding：补0策略 activation：激活函数 dilation_rate：整数或由单个整数构成的list/tuple， 指定dilated convolution中的膨胀比例 任何不为1的dilation_rate均与任何不为1的strides 均不兼容 use_bias：布尔值，是否使用偏置项 kernel_initializer：权值初始化方法 预定义初始化方法名的字符串 用于初始化权重的初始化器（参考initializers） bias_initializer：偏置初始化方法 为预定义初始化方法名的字符串 用于初始化偏置的初始化器 kernel_regularizer：施加在权重上的正则项，为 Regularizer对象 bias_regularizer：施加在偏置向量上的正则项 activity_regularizer：施加在输出上的正则项 kernel_constraints：施加在权重上的约束项 bias_constraints：施加在偏置上的约束项 输入：形如(batch, steps, input_dim)的3D张量 输出：形如(batch, new_steps, filters)的3D张量 因为有向量填充的原因，steps的值会改变 Conv2D1234567891011121314151617keras.layers.convolutional.Conv2D( filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None) 二维卷积层，即对图像的空域卷积 说明 该层对二维输入进行滑动窗卷积 当使用该层作为第一层时，应提供 参数 filters：卷积核的数目（即输出的维度） kernel_size：单个整数或由两个整数构成的list/tuple， 卷积核的宽度和长度 如为单个整数，则表示在各个空间维度的相同长度 strides：单个整数或由两个整数构成的list/tuple， 卷积的步长 如为单个整数，则表示在各个空间维度的相同步长 任何不为1的strides均与任何不为1的dilation_rate 均不兼容 padding：补0策略 activation：激活函数 dilation_rate：单个或两个整数构成的list/tuple， 指定dilated convolution中的膨胀比例 任何不为1的dilation_rate均与任何不为1的strides 均不兼容 输入：(batch, channels, rows, cols) （”channels_first”）4D张量 输出：(batch, filters, new_rows, new_cols) （”channels_first”）4D张量 输出的行列数可能会因为填充方法而改变 SeparableConv2D1234567891011121314151617181920keras.layers.convolutional.SeparableConv2D( filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None) 该层是在深度方向上的可分离卷积。 说明 首先按深度方向进行卷积（对每个输入通道分别卷积） 然后逐点卷积，将上步卷积结果混合到输出通道中 直观来说，可分离卷积可以看做讲一个卷积核分解为两个小 卷积核，或看作Inception模块的一种极端情况 参数 depth_multiplier：按深度卷积的步骤中，每个输入通道 使用（产生）多少个输出通道 depthwise_regularizer：按深度卷积的权重上的正则项 pointwise_regularizer：按点卷积的权重上的正则项 depthwise_constraint：按深度卷积权重上的约束项 pointwise_constraint：在按点卷积权重的约束项 输入：(batch, channels, rows, cols)4DT （”channels_first”) 输出：(batch, filters, new_rows, new_cols)4DTK （”channels_first”） 输出的行列数可能会因为填充方法而改变 Conv2DTranspose1234567891011121314151617keras.layers.convolutional.Conv2DTranspose( filters, kernel_size, strides=(1, 1), padding=&quot;valid&quot;, output_padding=None/int/tuple, data_format=None, activation=None, use_bias=True, kernel_initializer=&quot;glorot_uniform&quot;, bias_initializer=&quot;zeros&quot;, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None) 该层是反卷积操作（转置卷积） 说明 通常发生在用户想要对普通卷积的结果做反方向的变换 参考文献 A guide to convolution arithmetic for deep learning Transposed convolution arithmetic Deconvolutional Networks 参数 output_padding：指定输出的长、宽padding 必须小于相应的stride 输入：(batch, rows, cols, channels)4DT （”channels_last”) 输出：(batch, new_rows, new_cols, filters)4DT （”channels_last”） 输出的行列数可能会因为填充方法而改变 Conv3D1234567891011121314151617keras.layers.convolutional.Conv3D( filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None) 三维卷积对三维的输入（视频）进行滑动窗卷积 输入：(batch, channels, conv_dim1, conv_dim2, conv_dim3) 5D张量（”channnels_first”） Cropping1D123keras.layers.convolutional.Cropping1D( cropping=(1, 1)/tuple/int) 在时间轴上对1D输入（即时间序列）进行裁剪 参数 cropping：指定在序列的首尾要裁剪掉多少个元素 单值表示首尾裁剪相同 输入：(batch, axis_to_crop, features)的3DT 输出：(batch, cropped_axis, features)的3DT Cropping2D1234keras.layers.convolutional.Cropping2D( cropping=((0, 0), (0, 0)), data_format=None) 对2D输入（图像）进行裁剪 说明 将在空域维度，即宽和高的方向上裁剪 参数 cropping：长为2的整数tuple，分别为宽和高方向上头部 与尾部需要裁剪掉的元素数 单值表示宽高、首尾相同 单元组类似 输入：(batch, rows, cols, channels)4DT（”channels_last”） 输出：(batch, cropped_rows, cropped_cols, channels) 12345678 # Crop the input 2D images or feature mapsmodel = Sequential()model.add(Cropping2D(cropping=((2, 2), (4, 4)), input_shape=(28, 28, 3))) # now model.output_shape == (None, 24, 20, 3)model.add(Conv2D(64, (3, 3), padding='same'))model.add(Cropping2D(cropping=((2, 2), (2, 2)))) # now model.output_shape == (None, 20, 16, 64) Cropping3D1234keras.layers.convolutional.Cropping3D( cropping=((1, 1), (1, 1), (1, 1)), data_format=None) 对3D输入（空间、时空）进行裁剪 参数 cropping：长为3的整数tuple，分别为三个方向上头部 与尾部需要裁剪掉的元素数 输入：(batch, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop) （”channels_first”） 输出：(batch, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis) UpSampling1D123keras.layers.convolutional.UpSampling1D( size=2/integer) 在时间轴上，将每个时间步重复size次 参数 size：轴上采样因子 输入：(batch, steps, features)的3D张量 输出：(batch, upsampled_steps, feature)的3D张量 UpSampling2D1234keras.layers.convolutional.UpSampling2D( size=(2, 2)/tuple/int, data_format=None) 将数据的行和列分别重复size[0]和size[1]次 参数 size：分别为行和列上采样因子 输入：(batch, channels, rows, cols)的4D张量 （”channels_first”） 输出：(batch, channels, upsampled_rows, upsampled_cols) UpSampling3D1234keras.layers.convolutional.UpSampling3D( size=(2, 2, 2)/tuple/int, data_format=None) 将数据的三个维度上分别重复size次 说明 本层目前只能在使用Theano为后端时可用 参数 size：代表在三个维度上的上采样因子 输入：(batch, dim1, dim2, dim3, channels)5DT （”channels_last”） 输出：(batch, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels) ZeroPadding1D123keras.layers.convolutional.ZeroPadding1D( padding=1/int) 对1D输入的首尾端（如时域序列）填充0 说明 以控制卷积以后向量的长度 参数 padding：整数，在axis 1起始和结束处填充0数目 输入：(batch, axis_to_pad, features)3DT 输出：(batch, paded_axis, features)3DT ZeroPadding2D1234keras.layers.convolutional.ZeroPadding2D( padding=(1, 1)/tuple/int, data_format=None) 对2D输入（如图片）的边界填充0 说明 以控制卷积以后特征图的大小 参数 padding：在要填充的轴的起始和结束处填充0的数目 ZeroPadding3D1234keras.layers.convolutional.ZeroPadding3D( padding=(1, 1, 1), data_format=None) 将数据的三个维度上填充0 说明 本层目前只能在使用Theano为后端时可用 结束处填充0的数目 ZeroPadding3D1234keras.layers.convolutional.ZeroPadding3D( padding=(1, 1, 1), data_format=None) 将数据的三个维度上填充0 说明 本层目前只能在使用Theano为后端时可用 ?时可用","link":"/Python/Keras/convolutional_layers.html"},{"title":"Layers 总述","text":"Layer方法所有的Keras层对象都有如下方法： layer.get_weights()：返回层的权重NDA layer.set_weights(weights)：从NDA中将权重加载到该层中 ，要求NDA的形状与layer.get_weights()的形状相同 layer.get_config()：返回当前层配置信息的字典，层也可以 借由配置信息重构 layer.from_config(config)：根据config配置信息重构层 123layer = Dense(32)config = layer.get_config()reconstructed_layer = Dense.from_config(config) 12345from keras import layersconfig = layer.get_config()layer = layers.deserialize({'class_name': layer.__class__.__name__, 'config': config}) 非共享层如果层仅有一个计算节点（即该层不是共享层），则可以通过下列 方法获得 输入张量：layer.input 输出张量：layer.output 输入数据的形状：layer.input_shape 输出数据的形状：layer.output_shape 共享层如果该层有多个计算节点（参考层计算节点和共享层） 输入张量：layer.get_input_at(node_index) 输出张量：layer.get_output_at(node_index) 输入数据形状：layer.get_input_shape_at(node_index) 输出数据形状：layer.get_output_shape_at(node_index) 参数shape类型 batch_size batch_size在实际数据输入中为首维（0维） shape类型参数传递的tuple中一般不包括batch_size维度 输出时使用None表示(batch_size,...) time_step 对时序数据，time_step在实际数据输入中第二维（1维） input_shape 是Layer的初始化参数，所有Layer子类都具有 如果Layer是首层，需要传递该参数指明输入数据形状，否则 无需传递该参数 有些子类有类似于input_dim等参数具有input_shape 部分功能 None：表示该维度变长 输入、输出 channels/depth/features：时间、空间单位上独立的数据， 卷积应该在每个channal分别“独立”进行 对1维时序（时间），channels就是每时刻的features 对2维图片（空间），channels就是色彩通道 对3维视频（时空），channels就是每帧色彩通道 中间数据，channnels就是每个filters的输出 1D：(batch, dim, channels)（channels_last） 2D：(batch, dim_1, dim_2, channels) （channels_last） 3D：(batch, dim_1, dim_2, dim_3, channels) （channels_last）","link":"/Python/Keras/about_layers.html"},{"title":"高级激活层","text":"LeakyReLU1keras.layers.LeakyReLU(alpha=0.3) 带泄漏的修正线性单元。 返回值：当神经元未激活时，它仍可以赋予其一个很小的梯度 x &lt; 0：alpha * x x &gt;= 0：x 输入尺寸 可以是任意的。如果将该层作为模型的第一层，需要指定 input_shape参数（整数元组，不包含样本数量的维度） 输出尺寸：与输入相同 参数 alpha：float &gt;= 0，负斜率系数。 参考文献 Rectifier Nonlinearities Improve Neural Network Acoustic Models PReLU123456keras.layers.PReLU( alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None) 参数化的修正线性单元。 返回值 x &lt; 0：alpha * x x &gt;= 0：x 参数 alpha_initializer: 权重的初始化函数。 alpha_regularizer: 权重的正则化方法。 alpha_constraint: 权重的约束。 shared_axes: 激活函数共享可学习参数的轴。 如果输入特征图来自输出形状为 (batch, height, width, channels) 的2D卷积层，而且你希望跨空间共享参数，以便每个滤波 器只有一组参数，可设置shared_axes=[1, 2] 参考文献 Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification ELU1keras.layers.ELU(alpha=1.0) 指数线性单元 返回值 x &lt; 0：alpha * (exp(x) - 1.) x &gt;= 0：x 参数 alpha：负因子的尺度。 参考文献 Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) ThresholdedReLU1keras.layers.ThresholdedReLU(theta=1.0) 带阈值的修正线性单元。 返回值 x &gt; theta：x x &lt;= theta：0 参数 theta：float &gt;= 0激活的阈值位。 参考文献 Zero-Bias Autoencoders and the Benefits of Co-Adapting Features Softmax1keras.layers.Softmax(axis=-1) Softmax激活函数 参数 axis: 整数，应用 softmax 标准化的轴。 ReLU1keras.layers.ReLU(max_value=None) ReLU激活函数 参数 max_value：浮点数，最大的输出值。","link":"/Python/Keras/advanced_activations_layers.html"},{"title":"常用层","text":"常用层对应于core模块，core内部定义了一系列常用的网络层，包括 全连接、激活层等 Dense层123456789101112keras.layers.core.Dense( units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None) Dense就是常用的全连接层 用途：实现运算$output = activation(dot(input, kernel)+bias)$ activation：是逐元素计算的激活函数 kernel：是本层的权值矩阵 bias：为偏置向量，只有当use_bias=True才会添加 参数 units：大于0的整数，代表该层的输出维度。 activation：激活函数 为预定义的激活函数名（参考激活函数） 逐元素（element-wise）的Theano函数 不指定该参数，将不会使用任何激活函数 （即使用线性激活函数：a(x)=x） use_bias: 布尔值，是否使用偏置项 kernel_initializer：权值初始化方法 预定义初始化方法名的字符串 用于初始化权重的初始化器（参考initializers） bias_initializer：偏置向量初始化方法 为预定义初始化方法名的字符串 用于初始化偏置向量的初始化器（参考initializers） kernel_regularizer：施加在权重上的正则项，为 Regularizer对象 bias_regularizer：施加在偏置向量上的正则项，为 Regularizer对象 activity_regularizer：施加在输出上的正则项，为 Regularizer对象 kernel_constraints：施加在权重上的约束项，为Constraints对象 bias_constraints：施加在偏置上的约束项，为 Constraints对象 输入 形如(batch_size, ..., input_dim)的NDT，最常见情况 为(batch_size, input_dim)的2DT 数据的维度大于2，则会先被压为与kernel相匹配的大小 输出 形如(batch_size, ..., units)的NDT，最常见的情况为 $(batch_size, units)$的2DT Activation层1234keras.layers.core.Activation( activation, input_shape) 激活层对一个层的输出施加激活函数 参数 activation：将要使用的激活函数 预定义激活函数名 Tensorflow/Theano的函数（参考激活函数） 输入：任意，使用激活层作为第一层时，要指定input_shape 输出：与输入shape相同 Dropout层12345keras.layers.core.Dropout( rate, noise_shape=None, seed=None) 为输入数据施加Dropout 说明 Dropout将在训练过程中每次更新参数时按一定概率rate 随机断开输入神经元 可以用于防止过拟合 参考文献：Dropout: A Simple Way to Prevent Neural Networks from Overfitting 参数 rate：0~1的浮点数，控制需要断开的神经元的比例 noise_shape：整数张量，为将要应用在输入上的二值 Dropout mask的shape seed：整数，使用的随机数种子 输入 例：(batch_size, timesteps, features)，希望在各个 时间步上Dropout mask都相同，则可传入 noise_shape=(batch_size, 1, features) Flatten层1keras.layers.core.Flatten() Flatten层用来将输入“压平”，把多维的输入一维化 常用在从卷积层到全连接层的过渡 Flatten不影响batch的大小。 12345678model = Sequential()model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 32, 32))) # now: model.output_shape == (None, 64, 32, 32)model.add(Flatten()) # now: model.output_shape == (None, 65536) Reshape层1234keras.layers.core.Reshape( target_shape, input_shape) Reshape层用来将输入shape转换为特定的shape 参数 target_shape：目标shape，为整数的tuple，不包含样本 数目的维度（batch大小） 包含-1表示推断该维度大小 输入：输入的shape必须固定（和target_shape积相同） 输出：(batch_size, *target_shape) 例 1234567891011model = Sequential()model.add(Reshape((3, 4), input_shape=(12,))) # now: model.output_shape == (None, 3, 4) # note: `None` is the batch dimensionmodel.add(Reshape((6, 2))) # now: model.output_shape == (None, 6, 2) # also supports shape inference using `-1` as dimensionmodel.add(Reshape((-1, 2, 2))) # now: model.output_shape == (None, 3, 2, 2) Permute层123keras.layers.core.Permute( dims(tuple)) Permute层将输入的维度按照给定模式进行重排 说明 当需要将RNN和CNN网络连接时，可能会用到该层。 参数 dims：指定重排的模式，不包含样本数的维度（即下标 从1开始） 输出shape 与输入相同，但是其维度按照指定的模式重新排列 例 123model = Sequential()model.add(Permute((2, 1), input_shape=(10, 64))) # now: model.output_shape == (None, 64, 10) RepeatVector层123keras.layers.core.RepeatVector( n(int)) RepeatVector层将输入重复n次 参数 n：整数，重复的次数 输入：形如(batch_size, features)的张量 输出：形如(bathc_size, n, features)的张量 例 123456model = Sequential()model.add(Dense(32, input_dim=32)) # now: model.output_shape == (None, 32)model.add(RepeatVector(3)) # now: model.output_shape == (None, 3, 32) Lambda层123456keras.layers.core.Lambda( function, output_shape=None, mask=None, arguments=None) 对上一层的输出施以任何Theano/TensorFlow表达式 参数 function：要实现的函数，该函数仅接受一个变量，即 上一层的输出 output_shape：函数应该返回的值的shape，可以是一个 tuple，也可以是一个根据输入shape计算输出shape的函数 mask: 掩膜 arguments：可选，字典，用来记录向函数中传递的其他 关键字参数 输出：output_shape参数指定的输出shape，使用TF时可自动 推断 例 12model.add(Lambda(lambda x: x ** 2)) # add a x -&gt; x^2 layer 12345678910111213141516171819# add a layer that returns the concatenation# of the positive part of the input and# the opposite of the negative partdef antirectifier(x): x -= K.mean(x, axis=1, keepdims=True) x = K.l2_normalize(x, axis=1) pos = K.relu(x) neg = K.relu(-x) return K.concatenate([pos, neg], axis=1)def antirectifier_output_shape(input_shape): shape = list(input_shape) assert len(shape) == 2 # only valid for 2D tensors shape[-1] *= 2 return tuple(shape)model.add(Lambda(antirectifier, output_shape=antirectifier_output_shape)) ActivityRegularizer层1234keras.layers.core.ActivityRegularization( l1=0.0, l2=0.0) 经过本层的数据不会有任何变化，但会基于其激活值更新损失函数值 参数 l1：1范数正则因子（正浮点数） l2：2范数正则因子（正浮点数） Masking层1keras.layers.core.Masking(mask_value=0.0) 使用给定的值对输入的序列信号进行“屏蔽” 说明 用以定位需要跳过的时间步 对于输入张量的时间步，如果输入张量在该时间步上都等于 mask_value，则该时间步将在模型接下来的所有层 （只要支持masking）被跳过（屏蔽）。 如果模型接下来的一些层不支持masking，却接受到masking 过的数据，则抛出异常 输入：形如(samples,timesteps,features)的张量 例：缺少时间步为3和5的信号，希望将其掩盖 方法：赋值x[:,3,:] = 0., x[:,5,:] = 0. 在LSTM层之前插入mask_value=0.的Masking层123model = Sequential()model.add(Masking(mask_value=0., input_shape=(timesteps, features)))model.add(LSTM(32)) .`的Masking层 123model = Sequential()model.add(Masking(mask_value=0., input_shape=(timesteps, features)))model.add(LSTM(32)) ```","link":"/Python/Keras/core_layers.html"},{"title":"LocallyConnceted 局部连接层","text":"LocallyConnnected和Conv差不多，只是Conv每层共享卷积核， 这里不同位置卷积核独立 LocallyConnected1D层12345678910111213141516keras.layers.local.LocallyConnected1D( filters, kernel_size, strides=1, padding=&quot;valid&quot;, data_format=None, activation=None, use_bias=True, kernel_initializer=&quot;glorot_uniform&quot;, bias_initializer=&quot;zeros&quot;, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None) 类似于Conv1D，单卷积核权重不共享 LocallyConnected2D层12345678910111213141516keras.layers.local.LocallyConnected2D( filters, kernel_size, strides=(1, 1), padding=&quot;valid&quot;, data_format=None, activation=None, use_bias=True, kernel_initializer=&quot;glorot_uniform&quot;, bias_initializer=&quot;zeros&quot;, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None) 类似Conv2D，区别是不进行权值共享 说明 输出的行列数可能会因为填充方法而改变 例12345678910model = Sequential()model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3))) # apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image # with `data_format=&quot;channels_last&quot;`: # now model.output_shape == (None, 30, 30, 64) # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64 parametersmodel.add(LocallyConnected2D(32, (3, 3))) # now model.output_shape == (None, 28, 28, 32) # add a 3x3 unshared weights convolution on top, with 32 output filters:","link":"/Python/Keras/locally_connected_layers.html"},{"title":"池化层","text":"MaxPooling1D123456keras.layers.pooling.MaxPooling1D( pool_size=2/int, strides=None/int, padding=&quot;valid&quot; data_format=None) 对时域1D信号进行最大值池化 参数 pool_size：整数，池化窗口大小 strides：整数或None，下采样因子，例如设2将会使得 输出shape为输入的一半，若为None则默认值为pool_size。 MaxPooling2D123456keras.layers.pooling.MaxPooling2D( pool_size=(2, 2), strides=None/int/(int), padding=&quot;valid&quot;/&quot;same&quot;, data_format=None) 为空域2D信号施加最大值池化 MaxPooling3D层123456keras.layers.pooling.MaxPooling3D( pool_size=(2, 2, 2), strides=None/int/(int), padding=&quot;valid&quot;/&quot;same&quot;, data_format=None) 为3D信号（空域或时空域）施加最大值池化 AveragePooling1D层123456keras.layers.pooling.AveragePooling1D( pool_size=2, strides=None, padding=&quot;valid&quot; data_format=None) 对1D信号（时域）进行平均值池化 AveragePooling2D层123456keras.layers.pooling.AveragePooling2D( pool_size=(2, 2), strides=None, padding=&quot;valid&quot;, data_format=None) 为2D（空域）信号施加平均值池化 AveragePooling3D层123456keras.layers.pooling.AveragePooling3D( pool_size=(2, 2, 2), strides=None, padding=&quot;valid&quot;, data_format=None) 为3D信号（空域或时空域）施加平均值池化 GlobalMaxPooling1D层123keras.layers.pooling.GlobalMaxPooling1D( data_format=&quot;channels_last&quot;) 对于1D（时间）信号的全局最大池化 GlobalAveragePooling1D层123keras.layers.pooling.GlobalAveragePooling1D( data_forma=&quot;channels_last&quot;) 为时域信号施加全局平均值池化 GlobalMaxPooling2D层123keras.layers.pooling.GlobalMaxPooling2D( data_format=None) 为空域信号施加全局最大值池化 GlobalAveragePooling2D层123keras.layers.pooling.GlobalAveragePooling2D( data_format=None) 为2D（空域）信号施加全局平均值池化","link":"/Python/Keras/pooling_layers.html"},{"title":"RNN","text":"RNN12345678keras.layers.RNN( cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False) 循环神经网络层基类：抽象类、无法实例化对象 参数 cell：RNN单元实例、列表，为RNN单元列表时，单元 堆叠放置，实现高效堆叠RNN return_sequences：返回输出序列最后值/全部序列 return_state：是否返回最后一个状态 go_backwards：是否向后处理输入序列并返回相反的序列。 stateful：批次中索引i处的每个样品的最后状态将 用作下一批次中索引i样品的初始状态 unroll：是否将网络展开（否则将使用符号循环） 展开可以加速 RNN，但它往往会占用更多的内存 展开只适用于短序列 input_dim：输入的维度（整数） 将此层用作模型中的第一层时，此参数是必需的 （或者关键字参数 input_shape） input_length： 输入序列的长度，在恒定时指定 如果你要在上游连接 Flatten 和 Dense 层，则 需要此参数（没有它，无法计算全连接输出的尺寸） 如果循环神经网络层不是模型中的第一层，则需要在 第一层的层级指定输入长度 （或通过关键字参数input_shape） 输入：(batch_size, timesteps, input_dim)3D张量 输出 return_state=True：则返回张量列表，第一个张量为 输出、剩余的张量为最后的状态，每个张量的尺寸为 (batch_size, units)。 return_state=False：(batch_size, units)2D张量 说明 屏蔽覆盖：支持以可变数量的时间步长对输入数据进行屏蔽覆盖 使用状态：可以将 RNN 层设置为 stateful（有状态的） 这意味着针对一批中的样本计算的状态将被重新用作下一批 样品的初始状态 这假定在不同连续批次的样品之间有一对一的映射。 为了使状态有效： 在层构造器中指定 stateful=True。 为模型指定一个固定的批次大小 顺序模型：为模型的第一层传递一个 batch_input_shape=(...) 参数 带有Input层的函数式模型，为的模型的所有i 第一层传递一个batch_shape=(...)，这是输入 预期尺寸，包括批量维度 在调用 fit() 是指定 shuffle=False。 要重置模型的状态，请在特定图层或整个模型上调用 .reset_states() 初始状态 通过使用关键字参数initial_state调用它们来符号化地 指定 RNN 层的初始状态（值应该是表示RNN层初始状态的 张量或张量列表） 通过调用带有关键字参数states的reset_states方法 来数字化地指定 RNN 层的初始状态（值应该是一个代表RNN 层初始状态的NDA/[NDA]） RNN单元对象需要具有 call(input_at_t, states_at_t)方法，它返回 (output_at_t, states_at_t_plus_1)，单元的调用 方法也可以采用可选参数 constants state_size属性 单个整数（单个状态）：在这种情况下，它是循环层 状态大小（应该与单元输出的大小相同） 整数的列表/元组（每个状态一个大小）：第一项应该 与单元输出的大小相同 传递外部常量 使用RNN.call以及RNN.call的constants关键字 参数将外部常量传递给单元 要求cell.call方法接受相同的关键字参数constants， 这些常数可用于调节附加静态输入（不随时间变化）上的 单元转换，也可用于注意力机制 例子 12345678910111213141516171819202122232425262728293031323334353637class MinimalRNNCell(keras.layers.Layer): # 定义RNN细胞单元（网络层子类） def init(self, units, **kwargs): self.units = units self.state_size = units super(MinimalRNNCell, self).init(**kwargs) def build(self, input_shape): self.kernel = self.add_weight( shape=(input_shape[-1], self.units), initializer=&quot;uniform&quot;, name=&quot;kernel&quot; ) self.recurrent_kernel = self.add_weight( shape=(self.units, self.units), initializer=&quot;uniform&quot;, name=&quot;recurrent_kernel&quot;) self.built = True def call(self, inputs, states): prev_output = states[0] h = K.dot(inputs, self.kernel) output = h + K.dot(prev_output, self.recurrent_kernel) return output, [output]cell = MinimalRNNCell(32) # 在RNN层使用这个单元：x = keras.Input((None, 5))layer = RNN(cell)y = layer(x)cells = [MinimalRNNCell(32), MinimalRNNCell(64)] # 用单元格构建堆叠的RNN的方法：x = keras.Input((None, 5))layer = RNN(cells)y = layer(x) SimpleRNN12345678910111213141516171819202122keras.layers.SimpleRNN( units, activation=&quot;tanh&quot;, use_bias=True, kernel_initializer=&quot;glorot_uniform&quot;, recurrent_initializer=&quot;orthogonal&quot;, bias_initializer=&quot;zeros&quot;, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False) 完全连接的RNN，其输出将被反馈到输入。 参数 units：正整数，输出空间的维度。 activation：要使用的激活函数 tanh：默认 None：则不使用激活函数，即线性激活：a(x) = x use_bias：布尔值，该层是否使用偏置向量。 kernel_initializer：kernel权值矩阵的初始化器 recurrent_initializer：recurrent_kernel权值矩阵 bias_initializer：偏置向量的初始化器 kernel_regularizer：运用到kernel权值矩阵的正则化 函数 recurrent_regularizer：运用到 recurrent_kernel 权值 矩阵的正则化函数 bias_regularizer：运用到偏置向量的正则化函数 activity_regularizer：运用到层输出（它的激活值）的 正则化函数 kernel_constraint：运用到kernel权值矩阵的约束函数 recurrent_constraint：运用到recurrent_kernel权值矩阵 的约束函数 bias_constraint： 运用到偏置向量的约束函数 dropout：单元的丢弃比例，用于输入的线性转换 在0-1之间的浮点数 recurrent_dropout：单元的丢弃比例，用于循环层状态线性 转换 return_sequences：返回输出序列中的全部序列 默认：返回最后最后一个输出 return_state：除输出之外是否返回最后一个状态 go_backwards：向后处理输入序列并返回相反的序列 stateful：批次中索引 i 处的每个样品的最后状态，将用作 下一批次中索引 i 样品的初始状态 unroll：展开网络 GRU12345678910111213141516171819202122232425keras.layers.GRU( units, activation=&quot;tanh&quot;, recurrent_activation=&quot;hard_sigmoid&quot;, use_bias=True, kernel_initializer=&quot;glorot_uniform&quot;, recurrent_initializer=&quot;orthogonal&quot;, bias_initializer=&quot;zeros&quot;, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, reset_after=False) 门限循环单元网络 说明：有两种变体 默认的基于1406.1078v3，并且在矩阵乘法之前将复位门 应用于隐藏状态 另一种基于1406.1078v1并且顺序倒置 兼容CuDNNGRU(GPU-only)，并且允许在 CPU 上进行 推理 对于kernel和recurrent_kernel有可分离偏置 reset_after=True和recurrent_activation=sigmoid 。 参数 recurrent_activation：用于循环时间步的激活函数 implementation：实现模式 1：将把它的操作结构化为更多的小的点积和加法操作 2：将把它们分批到更少，更大的操作中 这些模式在不同的硬件和不同的应用中具有不同的性能配置 文件 reset_after：GRU公约，在矩阵乘法之后使用重置门 参考文献 Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation On the Properties of Neural Machine Translation：Encoder-Decoder Approaches Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling A Theoretically Grounded Application of Dropout in Recurrent Neural Networks LSTM12345678910111213141516171819202122232425keras.layers.LSTM( units, activation=&quot;tanh&quot;, recurrent_activation=&quot;hard_sigmoid&quot;, use_bias=True, kernel_initializer=&quot;glorot_uniform&quot;, recurrent_initializer=&quot;orthogonal&quot;, bias_initializer=&quot;zeros&quot;, unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False) 长短期记忆网络层（Hochreiter 1997） 参数 unit_forget_bias True：初始化时，将忘记门的偏置加 1，同时还会强制 bias_initializer=&quot;zeros&quot;（这个建议来自 Jozefowicz et al.） 参考文献 Long short-term memory (original 1997 paper) Learning to forget：Continual prediction with LSTM Supervised sequence labeling with recurrent neural networks A Theoretically Grounded Application of Dropout in Recurrent Neural Networks ConvLSTM2D123456789101112131415161718192021222324252627keras.layers.ConvLSTM2D( filters(int), kernel_size(tuple(int, int)), strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, go_backwards=False, stateful=False, dropout=0.0, recurrent_dropout=0.0) 卷积LSTM：它类似于LSTM层，但输入变换和循环变换都是卷积的 说明 当前的实现不包括单元输出的反馈回路 参数 dilation_rate：用于膨胀卷积的膨胀率 stride!=1与dilation_rate!=1两者不兼容。 输入尺寸 data_format=&quot;channels_first&quot;：尺寸为 (batch, time, channels, rows, cols) data_format=&quot;channels_last&quot;：尺寸为 (batch, time, rows, cols, channels) 输出尺寸 return_sequences=True data_format=&quot;channels_first&quot;：返回尺寸为 (batch, time, filters, output_row, output_col) data_format=&quot;channels_last&quot;：返回尺寸为 (batch, time, output_row, output_col, filters) return_seqences=False data_format =&quot;channels_first&quot;：返回尺寸为 (batch, filters, output_row, output_col) data_format=&quot;channels_last&quot;：返回尺寸为 (batch, output_row, output_col, filters) 参考文献 Convolutional LSTM Network：A Machine Learning Approach for Precipitation Nowcasting SimpleRNNCell12345678910111213141516keras.layers.SimpleRNNCell( units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0) SimpleRNN的单元类 GRUCell123456789101112131415161718keras.layers.GRUCell( units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1) GRU层的单元类 LSTMCell12345678910111213141516171819keras.layers.LSTMCell( units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1) LSTM层的单元类 StackedRNNCells1keras.layers.StackedRNNCells(cells) 将一堆RNN单元表现为一个单元的封装器 说明 用于实现高效堆叠的 RNN。 参数 cells：RNN 单元实例的列表 例子 12345678cells = [ keras.layers.LSTMCell(output_dim), keras.layers.LSTMCell(output_dim), keras.layers.LSTMCell(output_dim),]inputs = keras.Input((timesteps, input_dim))x = keras.layers.RNN(cells)(inputs) CuDNNGRU12345678910111213141516keras.layers.CuDNNGRU( units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, return_state=False, stateful=False) 由 CuDNN 支持的快速GRU实现 说明 只能以TensorFlow后端运行在GPU上 CuDNNLSTM1234567891011121314151617keras.layers.CuDNNLSTM( units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, return_state=False, stateful=False) 由 CuDNN 支持的快速LSTM实现 说明 只能以TensorFlow后端运行在GPU上","link":"/Python/Keras/recurrent_layers.html"},{"title":"算法分析","text":"基础算法：一系列解决问题的明确指令，即对于符合一定规范的 输入，能够在有限时间内获得要求的输出 算法每步都必须没有歧义 必须确定算法所处理的输入的值域 同一算法可以用几种不同的形式描述 同一问题，可能存在几种不同的算法 同问题的不同算法，可能基于不同的解题思路，速度也会不同 算法正确性证明 对某些算法，正确性证明十分简单，对于另一些算法，可能十分 复杂 证明正确性的一般方法是使用数学归纳法，因为算法的迭代过程 本身就符合其所需的一系列步骤 根据特定输入追踪算法操作有意义，但是并不能证明算法的 正确性，只需要一个算法不能正确处理的输入实例就足够了 对于近似算法，常常试图证明算法所产生的误差，不超出预定义 的误差 算法分析方向 时间效率（time efficiency）：算法运行速度 空间效率（space efficiency）：算法需要多少额外的存储空间 简单性（simplicity）：取决于审视者的眼光 简单的算法更容易理解、实现 相应程序包含更少的bug 一般性（generality） 所解决问题的一般性 所接受输入的一般性 最优性（optimality）：与所解决问题的复杂度有关，与某算法 效率无关 是否每个问题都能够用算法的方法来解决 非确定性Deterministic Alogrithm确定算法：利用问题解析性质，产生确定的有限、无限序列使其收敛 于全局最优解 依某确定性策略搜索局部极小，试图跳跃已获得的局部极小而 达到某个全局最优点 能充分利用问题解析性质，从计算效率高 Nondeterministic Algorithm不确定算法，包括两个阶段，将判定问题的实例l作为其输入 猜测（非确定）阶段：生成任意串S作为l候选解 验证（确定）阶段：把l、S作为输入，，若S是l解输出是， 否则返回否或无法停止 当选仅当对问题每个真实例，不确定算法会在某次执行中 返回是时，称算法能求解此问题 即要求不确定算法对某个解至少能够猜中一次、验证正确性， 同时不应该将错误答案判定为是 Nondeterministic Polynominal Algorithm：验证阶段时间 效率是多项式级的不确定算法 分析框架 time complexity：算法运行速度 space complexity：算法需要的额外空间 算法需要的额外空间已经不是需要重点关注的问题 影响因素输入规模$n$ 几乎所有算法，对规模更大的输入需要运行更长时间，因此使用 输入规模作为参数很有价值 在有些情况下，选择不同的参数表示输入规模有差别 选择输入规模的度量单位还受到算法的操作细节影响 和数字特性相关的算法，倾向于使用$n$的二进制位数 $b=\\lfloor {log_{2}^{n}} \\rfloor + 1$ 其他因素有些算法的运行时间不仅取决于输入规模，还取决于特定输入的细节 worst-case efficiency：最坏情况下的效率 best-case efficiency：最优情况下的效率 average-case efficiency 平均效率的研究比最差、优效率研究困难很多 可以将输入划分为几种类型，使得对同类实例，算法基本 执行次数相同，推导各类输入的概率分布，得到平均次数 amortized efficiency：应用于算法对同样的数据结构所执行 的一系列操作 有些情况下，算法单次执行时间代价高，但是n次运行的 总运行时间明显优于单次执行最差效率 * n 衡量角度运行时间 使用时间标准的度量算法程序运行时间缺陷 计算机速度 程序实现质量 编译器 计时困难 找到basic operation并计算其运行次数 不依赖于其他无关因素 对总运行时间贡献最大，不需要统计算法每步操作执行次数 如：对排序基本操作为键比较，数学问题则是四则运算， 需要注意除法、乘法、加减法耗时依次减小 时间估计 $c_{op}$：特定计算一个基本操作的执行时间 $C(n)$：算法执行基本操作的次数 $T(n)=c_{op}C(n)$：可以用于估算算法的执行时间 需要小心使用 $C(n)$不包含非基本操作的信息，也只是估计的结果 $c_{op}$也是不可靠的估计值 Order of Growth小规模输入运行时间差别不足以将高效算法与低效算法相区别， 对大规模输入忽略乘法常量，仅关注执行次数的order of growth 及其常数倍，即算法的渐进效率 按照算法渐进效率进行分类的方法缺乏使用价值，因为没有指定 乘法常量的值 但是对于实际类型输入，除了少数算法，乘法常量之间不会相差 悬殊，作为规律，即使是中等规模的输入，属于较优渐进 效率类型的算法也会比来自较差类型的算法效果好 对数函数：增长慢，以至于可以认为，对数级操作次数的算法能 瞬间完成任何实际规模输入 指数级：指数函数、阶乘函数 需要指数级操作次数的算法只能用于解决规模非常小的问题 渐进效率渐进符号$O(g(n))$ 对于足够大的n，$t(n)$的上界由$g(n)$的常数倍确定，则 $t(n) \\in O(g(n))$ 即存在大于0的常数$c$、非负整数$n_{0}$，使得 n > n_{0} 时，t(n) \\leqslant cg(n) 增长次数小于等于$g(n) n \\rightarrow \\infty$ （及常数倍）的函数集合 $\\Omega (g(n))$ 对于足够大的n，$t(n)$的下界由$g(n)$的常数倍确定，则 $t(n) \\in \\Omega(g(n))$ 即存在大于0的常数$c$、非负整数$n_{0}$，使得 n > n_{0} 时，t(n) \\geqslant cg(n) 增长次数大于等于$g(n) n \\rightarrow \\infty$ （及常数倍）的函数集合 $\\Theta (g(n))$ 对于足够大的n，$t(n)$的上、下界由$g(n)$的常数倍确定，则 $t(n) \\in \\Theta(g(n))$ 即存在大于0的常数$c{1}, c{2}$、非负整数$n_{0}$，使得 n > n_{0} 时，c_{2}g(n) \\leqslant t(n) \\leqslant c_{1}g(n) 增长次数等于$g(n) n \\rightarrow \\infty$（及常数倍） 的函数集合 极限比较增长次数利用极限比较增长次数：比直接利用定义判断算法的增长次数方便， 可以使用微积分技术计算极限 \\lim_{n \\rightarrow \\infty} \\frac {t(n)} {g_n} \\left\\{ \\begin{array}\\\\ 0 & t(n)的增长次数比g(n)小，t(n) \\in O(g(n))\\\\ c>0 & t(n)的增长次数同g(n)，t(n) \\in \\Theta(g(n)) \\\\ \\infty & t(n)的增长次数比g(n)大，t(n) \\in \\Omega(g(n))\\\\ 不存在 \\\\ \\end{array} \\right.基本渐进效率类型 类型 名称 注释 $1$ 常量 很少，效率最高 $log_{n}$ 对数 算法的每次循环都会消去问题规模的常数因子，对数算法不可能关注输入的每个部分 $n$ 线性 能关注输入每个部分的算法至少是线性运行时间 $nlog_{n}$ 线性对数 许多分治算法都属于此类型 $n^{2}$ 平方 包含两重嵌套循环的典型效率 $n^{3}$ 立方 包含三重嵌套循环的典型效率 $2^{n}$ 指数 求n个元素的所有子集 $n!$ 阶乘 n个元素集合的全排列 算法的数学分析非递归算法分析通用方案 决定表示输入规模的参数 找出算法的基本操作：一般位于算法最内层循环 检查算法基本操作执行次数是否只依赖于输入规模，如果和其他 特性有关，需要分别研究最差、最优、平均效率 建立算法基本操作执行次数的求和表达式（或者是递推关系） 利用求和运算的标准公式、法则建立操作次数的闭合公式，或 至少确定其增长次数 递归算法用一个方程把squence的generic term和一个或多个其他项相关联， 并提供第一个项或前几项的精确值 \\begin{array}\\\\ x(n) = x(n-1) + n (n>0) \\\\ x(0) = 0 \\end{array} recurrence：递推式 initial condition：序列起始值、递归调用结束条件 求解：找到序列通项的精确公式满足递推式、初始条件，或者 证明序列不存在 general solution：满足递推方程所有解序列公式，通常 会包含参数 particular solution：满足给定递推方程的特定序列，通常 感兴趣的是满足初始条件的特解 递归求解方法 method of forward substituion：从序列初始项开始，使用 递推方程生成给面若干项，从中找出能用闭合公式表示的模式 带入递推方程、初始条件验证 数学归纳法证明 method of backward subsitution：从序列末尾开始，把序列 通项$x(n)$表示为$x(n-i)$的函数，使得i是初始条件之一， 再求和公式得到递推式的解 second-order linear recurrence with constant coefficients ：求解characteristic equation得到特征根得到通解 常见递推类型decrease-by-one减一法：利用规模为n、n-1的给定实例之间的关系求解问题 减常数法特例 \\begin{align*} T(n)& = T(n-1) + f(n) \\\\ & = T(n-2) + f(n-2) + f(n) \\\\ & = \\cdots \\\\ & = T(0) + \\sum_{j=1}^{n} f(j) \\\\ \\end{align*}decrease-by-a-constant-factor减常因子法：把规模为n的实例化简为规模为n/b的实例求解问题 \\begin{align*} T(b^{k}) &= T(b^{k-1}) + f(b^{k}) \\\\ &= T(b^{k-2}) + f(b^{k-1}) + f(b^{k}) \\\\ &= \\cdots \\\\ &= T(1) + \\sum_{j=1}^{k} f(b^{j}) \\end{align*}divide-and-conquer分治法：将给定实例划分为若干较小实例，对每个实例递归求解，如有必要， 再将较小实例的接合并为给定实例的一个解 \\begin{align*} T(b^{k}) &= aT(n/b) + f(n) \\\\ &= a[aT(b^{k-2} + f(b^{k-1})] + f(b^{k}) \\\\ &= a^{2}T(b^{k-2}) + af(b^{k-1}) + f(b^{k}) \\\\ &= a^{2}[aT(b^{k-3} + f(b^{k-2})] + af(b^{k-1}) + f(b^{k}) \\\\ &= a^{3}aT(b^{k-3} + a^{2}f(b^{k-2}) + af(b^{k-1}) + f(b^{k}) \\\\ &= \\cdots \\\\ &=a^{k}T(1) + a^{k-1}f(b^{1}) + a^{k-2}f(b^{2}) + \\cdots + a^{0}f(b^{k}) \\\\ &=a^{k} \\left[ T(1) + \\sum_{j=1}^{k} \\frac {f(b^{j})} {a^{j}} \\right] \\\\ n = b^{k} \\\\ T(n) &= n^{log_{b}^{a}} \\left[ T(1) + \\sum_{j=1}^{log_{b}^{n}} \\frac {f(b^{j})} {a^{j}} \\right] \\end{align*}平滑法则、主定理 eventually nondecreaing：$f(n)$在自然数上非负，若 $\\exists n{0}, \\forall n{2} &gt; n{1} \\geqslant n{0}, f(n{2}) &gt; f(n{1})$， 则为最终非递减 smooth：$f(n)$在自然数上非负、最终非递减，若 $f(2n) \\in \\Theta(f(n))$，则平滑 若$f(n)$平滑，则对任何整数b有$f(bn) \\in \\Theta(f(n))$ 平滑法则$T(n)$最终非递减，$f(n)$平滑，若$n=b^{k}(b&gt;2)$时有 $T(n) \\in \\Theta(f(n))$，则$T(n) \\in \\Theta(f(n))$ 主定理 方便对分治法、减常因子法效率进行分析 $T(n)$最终非递减，满足递推式 T(n) = aT(n/b) + f(n), \\quad n=b^{k}, k=1,2,3,\\cdots \\\\ T(1) = c \\\\ a \\geqslant 1, b \\geqslant 2, c > 0若$f(n) \\in \\Theta(n^{d}), d \\geqslant 0$，则 T(n) \\in \\left\\{ \\begin{array}\\\\ \\Theta(n^{d}) & ab^{d} \\\\ \\end{array} \\right.分析通用方案 决定衡量输入规模的参数 找出算法基本操作 检查算法基本操作执行次数是否只依赖于输入规模，如果和其他 特性有关，需要分别研究最差、最优、平均效率 建立算法基本操作执行次数的递推关系、相应初始条件 求解递推式，或至少确定其增长次数 算法时间效率极限确定已知、未知算法效率极限 算法下界算法下界是问题可能具有的最佳效率 可以用于评价某问题具体算法效率 不同问题算法直接比较无意义 寻找问题的更优算法时，可以根据算法下界确定期望获得的改进 若算法下界是紧密的，则改进至多不过是常数因子 若算法下界和算法仍有差距，则可能存在更快算法，或者是 证明更好的下界 Trivial Lower Bound平凡下界：任何算法只要要“读取”所有要处理的项、“写”全部 输出，对其计数即可得到平凡下界 往往过小，用处不大 确定问题中所有算法都必须要处理的输入也是个障碍 例 生成n个不同项所有排列的算法$\\in \\Omega(n!)$，且下界 是紧密的，因为好的排列算法在每个排列上时间为常数 计算n次多项式值算法至少必须要处理所有系数，否则改变 任意系数多项式值改变，任何算法$\\in \\Omega(n)$ 计算两个n阶方阵乘积算法$\\in Omega(n^2)$，因为任何 算法必须处理矩阵中$2n^2$个元素 Information-Theoretic Lower Bound信息论下界：试图通过算法必须处理的信息量（比特数）建立 效率下界 例 猜整数中，整数的不确定信息量就是 $\\lceil \\log_2 n \\rceil$（数字二进制位数）， n为整数上界 Adversary Lower Bound敌手下界：敌手基于恶意、一致的逻辑，迫使算法尽可能多执行， 从而确定的为了保证算法正确性的下界 恶意使得它不断把算法推向最消耗时间的路径 一致要求它必须和已经做出的选择保持一致（按照一定规则） 例 猜整数中，敌手把1~n个数字作为可选对象，每次做出判断 后，敌手保留数字较多集合，使得最消耗时间、不违背之前 选择 两个有序列表${a_i}, {b_j}$归并排序中，敌手使用规则： 当前仅当i &lt; j时，对$a_i &lt; b_j$返回真（设置列表值大小 可以达到），则任何算法必须比较2n-1次，否则交换未比较 元素归并错误 问题化简问题Q下界已知，考虑将问题Q转换为下界未知问题P，得到P下界 应该表明任意Q问题实例可以转换为P问题 即问题Q应该是问题P的子集，正确的算法至少应该能解决Q问题 许多问题复杂性不清楚，而对问题复杂度的直观判断和问题表现 形式相关，并不可靠 常在问题化简中使用的已知下界问题 |问题|下界|紧密性| |——-|——-|——-| |排序|$\\Omega(nlogn)$|是| |有序数组查找|$\\Omega(logn)$|是| |元素惟一性|$\\Omega(nlogn)$|是| |n位整数乘法|$\\Omega(n)$|未知| |n阶方程点乘|$\\Omega(n^2)$|未知| 例 欧几里得最小生成树：使用元素唯一性问题作为下界已知 问题 将n个实数映射为x轴上的n个点 设T为此点集最小生成树，T必然包含一条最短边??#todo 检查T是否包含长度为0的边即为元素惟一性 任意矩阵A、B乘法：使用方阵乘法作为下界已知问题 将A、B化成对称方阵进行计算 X = \\begin{bmatrix} 0 & A \\\\ A^T & 0 \\\\ \\end{bmatrix}, Y = \\begin{bmatrix} 0 & B^T \\\\ B & 0 \\\\ \\end{bmatrix} \\\\ XY = \\begin{bmatrix} AB & 0 \\\\ 0 & A^TB^T \\\\ \\end{bmatrix} 乘积AB可以方便提取，而翻倍的矩阵乘法不会影响复杂性 决策树（二叉）可以使用（二叉）决策树研究基于比较的算法性能 每个非叶子节点代表一次键值比较 叶子节点个数大于等于输出，不同叶子节点可以产生相同输出 对于特定规模为n的输入，算法操作沿着决策树一条从根到叶子 节点完成，所以最坏情况下比较次数等于算法决策树高度 如果树具有由输出数量确定叶子，则树必须由足够高度容纳叶子 ，即对于任何具有$l$个叶子，树高度 $h \\leqslant \\lceil log_2 l \\rceil$，这也就是 信息论下界 线性表排序任意n个元素列表排序输出数量等于$n!$，所以任何基于比较的排序 算法的二叉树高度，即最坏情况下比较次数 \\begin{align*} C_{worst} & \\geqslant \\lceil log_2 n! \\rceil \\\\ & \\approx log_2 \\sqrt {2\\pi n} (n/e)^n \\\\ & = nlog_2n - nlog_2e + \\frac {log_2n + log_22\\pi} 2 \\\\ & \\approx nlog_2n \\end{align*} 归并排序、堆排序在最坏情况下大约必须要做$nlog_2n$次比较 ，所以其渐进效率最优 也说明渐进下界$\\lceil log_2n! \\rceil$是紧密的 ，不能继续改进 但这个只是基于二叉决策树的渐进下界，对于具体值估计 可能不准 如$\\lceil log_2 12! \\rceil = 29$，而事实证明 12个元素排序30次比较是必要、充分的 也可以使用决策树分析基于比较的排序算法的平均性能，即 决策树叶子节点平均深度 基于排序的所有输出都不特殊的标准假设，可以证明平均 比较次数下界$C_{avg}(n) \\geqslant log_2n!$ 这个平均是建立在所有输出都不特殊假设上，所以这个其实 应该是不同算法平均比较次数下界的上界 对于单独排序算法，平均效率会明显好于最差效率 有序线性表查找有序线性表查找最主要算法是折半查找，其在最坏情况下下效率 $C{worst}^{bs} = \\lfloor log_2n \\rfloor + 1 = \\lceil log(n+1) \\rceil$ 折半查找使用的三路比较（小于、等于、大于），可以使用 三叉查找树表示 三叉查找树会有2n+1个节点：n个查找成功节点、n+1个查找 失败节点 所以在最坏情况下，比较次数下界 $C_{worst}(n) \\geqslant \\lceil log_3{2n+1} \\rceil$ 小于折半查找最坏情况下比较次数（渐进） 然而，事实上可以删除三叉查找树中间子树（等于分支），得到 一棵二叉树 非叶子节点同样表示三路比较，只是同时作为查找成功终点 可以得到一个新的下界 $C_{worst}(n) \\geqslant \\lceil log_2{n+1} \\rceil$ 更复杂的分析表明，标准查找假设下，折半查找平均情况比较 次数是最少的 查找成功时$log_2n - 1$ 查找失败时$log_2(n+1)$ P、NP、完全NP问题复杂性理论 如果算法的最差时间效率$\\in O(p(n))$，$p(n)$为问题输入 规模n的多项式函数，则称算法能在多项式时间内对问题求解 Tractable：易解的，可以在多项式时间内求解的问题 Intractable：难解的，不能在多项式内求解的问题 使用多项式函数理由 无法保证在合理时间内对难解问题所有实例求解，除非问题实例 非常小 对实用类型的算法而言，其多项式次数很少大于3，虽然多项式 次数相差很大时运行时间也会有巨大差别 多项式函数具有方便的特性 多项式加和、组合也为多项式 多项式类型可以发展出Computational Complexity利用 该理论试图对问题内在复杂性进行分类 只要使用一种主要计算模型描述问题，并用合理编码方案 描述输入，问题难解性都是相同的 Decision Problem判定问题：寻求一种可行的、机械的算法，能够对某类问题在有穷 步骤内确定是否具有某性质 Undecidable问题：不可判定问题，不能使用任何算法求解的 判定问题 停机问题：给定程序、输入，判断程序对于输入停止还是 无限运行下去 Decidable问题：可判定问题，能用算法求解的问题 可判定、难解问题存在，但非常少 很多判定问题（或者可以转化为等价判定问题），既没有 找到多项式类型算法，也没有证明这样算法不存在，即无法 判断是否难解 P、NP问题P问题Polynomial类型问题 非正式定义：易解的问题，即能够在多项式时间内求解的 问题（计算机范畴） 正式定义：能够用确定性算法在多项式时间内求解的 判定问题 多项式时间内求解：排除难解问题 判定问题：很多重要问题可以化简为更容易研究的判断问题 ，虽然原始表达形式不是判定问题 NP问题Nondeterministic Polynomial类型问题：可以用不确定多项式 算法求解的判定问题 NP问题虽然计算上对问题求解困难，但是在计算上判定待定结 是否解决问题是简单的：可以在多项式时间内完成 大多数判断问题都是属于NP类型的 $P \\subseteq NP$：如果问题属于P，在不确定算法验证 阶段忽略猜测 还包括以下没有找到多项式算法、也没有证明算法不存在 的组合优化问题的判定版本 哈密顿回路问题 旅行商问题 背包问题 划分问题 装箱问题 图着色问题 整数线性规划问题 $P \\overset ? = NP$：P和NP问题是否一致，计算机科学理论 中最重要的未解之谜 P = NP意味着虽然没有找到，但能够在多项式时间内求解 许多组合优化问题确实存在 NPC问题NP Complete问题 属于NP问题种，和该类型其他问题难度一致 证明问题属于NP问题比较简单 NP中其他任何问题（已知或未知）可以在多项式时间内化简为 NPC问题 直接证明任何NP问题都可以在多项式时间内化简为当前问题 比较困难 常常利用多项式规约特性，证明某个确定NPC问题可以 多项式规约为当前问题 判定问题相互转换例 哈密顿回路问题中图G映射加权图$G^{‘}$，G中存在边在 权重为1，不存在边权重为2，则哈密顿回路问题转换为$G^{‘}$ 是否存在长度不超过$|V|$的哈密顿回路，即旅行商问题的等价 NPC问题案例 CNF-Satisfied Problem：合取范式可满足性问题，首个 被发现NPC问题 前面提到的著名NP问题都是NPC问题 包括哈密顿回路问题？？？ 仅仅得到一个NPC问题的多项式确定算法，所有NP问题可以 在多项式时间内求解 则$P = NP$ 即对于所有类型判定问题而言，检验待定解、在多项式时间 内求解在复杂性商没有本质区别 而NPC问题可以被其他NP问题转换而来意味着，NPC问题目前不 存在对所有实例通用的多项式时间算法 NP-Hard问题NP-Hard问题：所有NP问题都可以通过多项式规约到其 不满足NPC问题第一个条件，可以不是NP问题 其范围包含NPC问题，前述组合优化问题最优版本也是NP-Hard 可以理解为：至少和NPC问题一样困难的问题 ReferencePolynomially Reducible判定问题$D_1$可以多项式规约为判定问题$D_2$，条件是存在 函数t可以把$D_1$的实例转换为$D_2$的实例，满足 t把$D_1$所有真实例映射为$D_2$真实例，把$D_1$所有假实例 映射为$D_2$假实例 t可以用多项式算法计算 CNF-Satisfied Problem合取范式满足性问题：能否设置合取范式类型的布尔表达式中布尔 变量值，使得整个表达式值为真 每个布尔表达式都可以表达为合取范式","link":"/Algorithm/alg_analysis.html"},{"title":"算法设计策略","text":"蛮力法Brute Force：简单直接解决问题的方法，常常直接基于问题的描述 和所涉及的概念定义 特点 蛮力法可以解决各种问题，实际上可能是唯一几乎可以解决所有 问题的方法 对某些重要问题，蛮力法可以产生合理算法，具备实用价值， 且不必限制实例规模 如果解决问题实例不多，蛮力法速度可接受，设计高效算法可能 不值得 蛮力法可以用于研究、教学目的，如：衡量同样问题其他更高效 算法 案例因为基本所有问题都可以使用蛮力得到理论可行的解决方法， 所以这里只包含实际可行、有价值算法 排序 选择排序 冒泡排序 查找 顺序查找 蛮力字符串匹配 几何 最近对问题 凸包问题 组合 背包问题 旅行商问题 分配问题 图处理 深度优先搜索 广度优先搜索 Recursion reduction：简化论，仅仅通过理解构成对象某一部分就可以 理解整个对象 holism：整体论，总体总比构成它的部分更为重要 递归：将大问题通过简化成相同形式的小问题来解决问题 递归的思考需要从整体角度考虑 需要习惯于采用递归的稳步跳跃理念 关键在于如何正确的将原始问题分解为有效的子问题 更加简单，且和原问题求解形式相同 最终能达到简单情况，并正确解决 能重新组合子问题的解得到原始问题的解 recursive leap of faith：递归的稳步跳跃理念，任何更 简单的递归调用将正确工作 Recursive Paradigm递归范型：递归函数体形式 1234567if(test for simple case){ // 非递归解决简单问题} else { // 将问题简化为某种形式的子问题（一个或多个） // 递归调用函数解决每个子问题 // 将子问题的解组合得到原问题的解} 返回值问题 无返回值：没有返回值回退过程、处理函数 全局变量、引用参数记录结果 参数传递结果，最末栈直接使用 有返回值：有返回值回退过程 可以完全类似无返回值函数调用，此时返回值无实际价值 也可以最终结果在初始主调函数中得到 不方便使用全局变量记录结果时，可以给真实递归调用函数 添加记录结果的引用参数，外层包装其、提供实参 是否有返回值不是递归调用的关键，关键是是否继续调用 减治法Decrease and Conquer：利用问题给定实的解和同样问题较小 实例解之间某种关系，可以自底向上、自底向上的运用该关系 自顶向下会自然导致递归算法，但是还是非递归实现较好 自底向上往往是迭代实现的，从求解问题较小实例开始 减治法有3种主要变化形式 Decrease-by-Constant减常量：每次算法迭代总是从实例中减去相同常量 新问题规模 = 原问题规模 - constant 一般来说这个常量为1 Decrease-by-A-Contant-Factor减去常量因子：在算法迭代过程中总是减去相同的常数因子 新问题规模 = 原问题规模 / constant-factor 常数因子一般为2 Variable-Size-Decrease减可变规模：算法每次迭代时，规模减小模式不同 案例 减常量法 数值计算 自顶向下递归计算指数 利用指数定义自底向上计算指数 排序 插入排序 希尔排序 图问题 拓扑排序 组合 生成排列 生成子集 减常因子法 数值计算 递归的计算$a^{n/2}$计算指数 俄式乘法 约瑟夫斯问题 查找 数值问题 减可变规模 数值计算 计算最大公约数的欧几里得算法gcd(m, n) = gcd(n, m mod n) 排序 顺序统计量 查找 差值查找 二叉查找树 组合 拈游戏 分治法Divide-and-Conquer 将问题划分为同一类型的若干子问题，子问题规模最好相同 对子问题求解 一般使用递归方法 规模足够小时，有时也会利用其他算法 有必要则合并子问题的解得到原始问题答案 案例 查找 求解二叉树高度 遍历二叉树 数值计算 大整数乘法 Strassen矩阵乘法 几何 最近对问题 凸包问题 变治法 输入增强 时空权衡 变治法分成两个阶段工作 “变”：出于某种原因，把问题实例变得容易求解 “治”：对实例问题进行求解 根据对问题的变换方式，可以分为3类 Instance Simplification实例化简：变换为同样问题的更简单、更方便的实例 预排序： Representation Change改变表现：变换为同样实例不同表现 problem reduction问题化简：变换为算法已知的另一个问题的实例 典例 排序 预排序（线性表） 比较计数排序 分布计数排序 查找 预排序 检验线性表唯一性 寻找线性表众数 查找线性表中元素 字符串模式增强 Horspool算法 Boyer-Moore算法 KMP算法 最长公共子串 数值 高斯消元法 前向消去法 部分选主元法 反向替换法 数值计算 霍纳法则 二进制（计算）幂 欧几里得算法 极大、极小值转换 极值转换为求导数为0点 线性规划：在极点求解 整数规划 图 把问题转换为状态图求解 Hash（散列） 动态规划Dynamic Programming：记录、再利用子问题结果 记录子问题解，试图避免不必要、重复子问题求解 否则就是普通递归，不能避免重复求解 或者说动态规划就是普通递归+子问题解记录 适合解决的问题特点 离散最优化问题：如递推关系中包含max、min、 sum等，递推式中 因变量待求解最优化问题 自变量则为问题中涉及的离散变量 交叠子问题构成复杂问题，需遍历比较 问题具有最优子结构，由最优解定理，最优解由 子问题最优解构成 求解空间求解空间：问题涉及的两个、多个取离散值变量，根据递推关系考虑 离散变量待求解问题可能组合 离散变量包括 明显离散列表 因变量限制条件 可利用变量间限制条件组合因变量 默认各变量组合是笛卡尔积 由于限制条件可以减少变量组合取值数量 某变量可能为其他变量提供搜索空间 即其每个取值均需和其他变量组合、搜索 此时可以不将其计入求解变量、动态规划表，而是遍历其 （如：找零问题中零钱） 递推式、递推关系递推式、递推关系：将原问题分解为较小、交叠子问题的方法 动态规划递推中包含重要思想有序组合 有序剔除遍历相关变量，一般单向剔除，有些变量需要 考虑双向，视为两个有约束条件的独立变量 （如：最优二叉树） 因为只需要求解全集最优解，所以只需要考虑 部分有序子集，直观类比矩阵可逆只需要判断 顺序主子式 原问题解可能无法直接得到递推关系 原始问题非求数值解 应该寻找数值中间解构建递推关系， 再利用动态规划表得到最终解（最长子序列） 原始问题是求宽松范围解即解不要求包含断点的解 以各个元素分别作为端点的解构建递推关系 以最优者即为宽松范围解（最长子序列） 递推式中应优先考虑限制条件：减少搜索空间 单个自变量限制条件 两端都需要变化的变量视为两个独立、相互约束变量 动态规划表动态规划表：存储已求解交叠子问题解，相同问题查表避免重复求解 动态规划表结构 n维结构化数据表（常用） n为自变量数量（组合变量视为单个变量） 每维对应某离散变量 字典：适合自顶向下动态规划 求解问题时 将问题分解为交叠子问题 先查动态规划表，尝试从表中得到问题解，否则求解问题， 记录于动态规划表 并用于求解更大规模问题，直至原问题求解完成 分类自底向上（经典）自底向上：求解给定问题所有较小子问题，最终得到的原始问题解 计算用所有小问题解、填充动态规划表格 常逐行、逐列填充动态表（求解子问题） 一般先填充初始化变量对应维度（即位于内部循环） 先初始化行，在初始化列过程中可以在循环中填充行 先初始化列，在初始化行过程中可以在循环中填充列 循环保证所需子问题已经求解完毕 特点 自底向上没有对问题整体的全局把握，必须求解全部子问题 无需递归栈空间 自顶向下自顶向下：整体把握原始问题，只计算对求解原问题的有必要子问题 用自顶向下方式求解给定问题 先将问题分解子问题 求解必要的子问题 先检查相应动态规划表中该问题是否已求解， 否则求解子问题，记录解于动态规划表 所有子问题求解完毕，回溯得到原问题解 特点 整体把握问题整体，避免求解不必要子问题 需要通过回溯（递归栈）得到问题最优解的构成 Principle of Optimality最优化法则：最优化问题的任一实例的最优解，都是由其子问题实例 的最优解构成 最优化法则在大多数情况下成立，但也存在少数例外：寻找图 中最长简单路径 在动态规划算法中，可以方便检查最优化法则是否适用 动态规划的大多数应用都是求解最优化问题 典例 组合问题 币值最大化问题 找零问题 硬币问题 背包问题 最优二叉查找树 最长公共子序列 查找问题 字符串 最长上升子序列 最长公共字串 编辑距离 贪婪技术贪婪法：通过一系列步骤构造问题的解，每步对目前构造的部分解 作扩展，直到得到问题的完整解 特点 只能应用于最优问题，但可以作为一种通用设计技术 贪婪法每步条件 feasible：必须可行，满足问题约束 locally optimal：是当前所有步骤中所有可行选择的 最佳局部选择 irrevocable：选择一旦做出不能更改 希望通过通过一系列局部最优选择产生全局最优解 有些问题能够通过贪婪算法获得最优解 对于无法通过贪婪算法获得最优解的问题，如果满足于、 关心近似解，那么贪婪算法依然有价值 正确性证明证明贪婪算法能够获得全局最优解方法 数学归纳法 证明在接近目标过程中，贪婪算法每步至少不比其他任何算法差 基于算法的输出、而不是算法操作证明贪婪算法能够获得最优解 拟阵典例 图 Prim算法 Kruskal算法 Dijkstra算法 组合 哈夫曼树（编码） 回溯法Backtracing：每次只构造解的一个满足约束分量，然后评估 此部分构造解 尝试对部分构造解进行进一步构造（构造下个分量），若 存在不违反问题约束的下个分量，则接受首个合法选择 若无法得到下个分量合法选择，则不必考虑之后分量，此时进行 回溯，将部分构造解最后一个分量替换为下个选择 回溯法核心就是对状态空间树进行剪枝，忽略无法产生解的分支 适合问题 适合处理含有约束条件、困难的组合问题 往往只需要求出feasible solution 问题往往有精确解，但是没有高效算法求解 回溯法目标是最终输出：n元组$(x_1, x_2, \\cdots, x_n)$ 其中元素$x_i$为有限线性集$S_i$的一个元素 元组可能需要满足额外约束 状态空间树 回溯法会显式、隐式的生成一棵空间状态树 树根表示查找解之前的初始状态 树的第$i$层节点表示对第$i$个分量的选择 应该、可以认为是经过$i$次可能选择后的由$i$个 元素组成的解分量整体$(x_1, x_2, \\cdots, x_i)$ 叶子节点 在完整树中为无希望解分量、完整解之一 构造中的树为无希望分量、未处理解分量之一 大部分情况下，回溯算法的状态空间树按照深度优先方式构造 如果当前节点（解分量）有希望，向解分量添加 下个分量下个选择得到新的节点，处理新节点 如果当前节点无希望，回溯到节点父母重新处理 算法123456789101112Backtrack(X[1..i]) // 回溯算法通用模板 // 输入：X[1..i]一个解的前i个有希望的分量 // 输出；代表问题解的所有元组 if X[1..i] 是一个解 write X[1..i] else for 满足约束的x \\in S_{i+1} do // 不符合约束的不处理，即回溯 // 符合约束则继续深度优先搜索 X[i+1] = x Backtrack(X[1..i+1]) Promising Promising：有希望，当前解分量（节点）仍然有可能导致 完整解，满足 当前解分量符合约束：新添加分量个体约束、解分量整体 约束 当前解分量节点仍有未处理的子女节点 Nonpromising：没希望，当前解分量不满足有希望两个条件 ，无法导致完整解 注意：有希望不能采用递归定义：是否有希望是当前状态的结果， 当时并不知道、不需要知道子女状态（是否有希望） 约束判断位置处理节点时，对子女的约束条件有两种说法 添加下个分量满足约束的选择：这里是将约束说法上提前 考虑 此说法可能适合约束只需要考虑最后分量的情况 此种情况下的有希望只需要满足：解分量节点有未处理、 合法子女 是这里回溯法部分的说法 添加下个分量下个选择：这里是将约束说法上延后考虑 此说法可能适合约束需要考虑解分量整体的情况 此种情况下的有希望就是前面条件 是这里状态空间树的说法 但其实两者是一样的，只是说法不同 前一个说法绘制状态空间树也同样需要 *绘制不满足约束的节点 后一个说法也不定会直接把元素添加解分量中 算法特点 回溯法时间效率不稳定，无法保证优良性能 回溯法对状态空间树剪枝，是对穷举法的改进，避免考虑 某些无效解 回溯法在最坏情况下必须生成指数、甚至更快增长的状态 空间中所有解 但回溯法至少可以期望在期望时间能，对规模不是很小的 问题在可接受时间内求解 即使回溯法没能消去状态空间中任何元素，其依然提供了 一种特定的解题方法，方法本身就有价值 回溯法状态空间树规模基本不能通过分析法求解 可以通过生成一条根到叶子的随机路径，按照生成路径中 不同选择的数量${c_i, i=1,2,\\cdots,n}$信息估计规模 树节点数量为:$1 + \\sum{i=1}^n \\prod{j=1}^i c_j$ 可以多做几次估计取平均值 有些技巧可以用于缩小状态空间规模 组合问题往往有对称性，如：n皇后问题中第个皇后只需要 考虑前一半位置 把值预先分配给解的分量 预排序 分支界限法分支界限法：类似于回溯法，但是用于求optimal solution 在回溯法的基础上，比较叶子节点边界值、目前最优解 叶子边界值：节点对应部分解向量衍生的解集合在目标函数 值上的最优边界 对最小化问题，边界值为下界；对最大化问题，边界值为 上界 类似于在回溯法的约束条件中增加：节点最优边界必须超越当前 最优值 随着深度增加，节点最优边界逐渐紧密，节点更容易被终止 分支界限法适合问题、算法特点类似回溯法 状态空间树分支界限空间树和节点生成顺序有关 best-first branch-and-bound：最佳优先分支边界策略， 在当前树未终止叶子中，选择拥有最佳边界的节点作为最有 希望节点，优先处理 最优边界比较范围是全局比较，不仅仅局限于 这种策略可能会得到较好的结果，消除更多分支，甚至有时 只需计算一个完整解元组就能消除其他所有分支 当然，最优解最终可能属于其他分支，这种策略也不一定 能够加速算法 顺序策略：类似于回溯法，优先处理最近、有希望节点 边界函数发现好的边界函数比较困难 希望函数容易计算，否则得不偿失 函数不能过于简单，否则无法得到紧密边界，尽可能削剪状态 空间树分支 需要对具体问题各个实例进行大量实验，才能在两个矛盾的要求 之间达到平衡 迭代策略迭代策略：从某些可行解出发，通过重复应用一些简单步骤不断改进 这些步骤会通过一些小的、局部的改变生成新可行解 并使得目标函数更加优化 当目标函数无法再优化时，把最后可行解返回 问题 需要一个初始可行解 平凡解 其他算法（贪婪算法）得到近似解 有些问题得到初始可行解也不简单 对可行解的改变需要考虑 局部极值问题 NP-Hard近似算法NP-Hard组合优化问题即使是分支界限法也不能保证优良性能，考虑 使用近似算法快速求解 近似算法往往是基于特定问题的启发式算法 有些应用不要求最优解，较优解可能足够 且实际应用中常常处理不精确的数据，这种情况近似解更合适 Heuristic Algorithm：启发式算法，来自于经验而不是数学 证明的经验规则 Perfermance Ratio算法性能比：$R_A = \\min{c|{r(s_a) \\leqslant c}$ $r(s_a) = \\frac {f(s_a} {f(s^{})}$：优化函数$f$在近似解 $s_a$下的accuracy ratio* 这里$f$为最小化问题 若$f$为最大化问题，则取倒数使得精确率总大于1 比值越接近1，近似解质量越高 $R_A$即为：问题所有实例中，最差（大）精确率 有些问题没有有限性能比的近似算法，如：旅行商问题 （除非$P = NP$） $R_A$是衡量近似算质量的主要指标 需要寻找的是$R_A$接近1的算法 某些简单算法性能比趋于$\\infty$，这些算法也可以使用， 只是需要注意其输出 算法也被称为$R_A$近似算法 旅行商问题无有限近似比算法 若存在有限近似比算法，则 $\\exists c, f(s_a) \\leqslant cf(s^{*})$ 将哈密顿回路问题图G变换为旅行商图$G^{‘}$，G中原有边距离 为1，不存在边距离为$cn+1$ 近似算法能在多项式时间内生成解 $s_a, f(s_a) \\leqslant cf(s^{*}) = cn$， 若存在哈密顿回路，则旅行商问题中最优解$s^{*} = n$ 否则，旅行商问题最优解$s^{*} &gt; cn+1$ 则近似算法能在多项式时间解决哈密顿回路问题，而哈密顿回路 问题为NPC问题，除非$P = NP$ 说明 虽然大多数NP-Hard问题的精确求解算法，对于可在多项式时间 相互转换问题难度级别相同，但是近似算法不是，某些问题的 求良好近似解比其他问题简单的多 因为近似算法是基于特定问题的，不具有普遍性 某些组合优化难题具有特殊的实例类型，这些类型在实际应用 中比较重要，而且也容易求解","link":"/Algorithm/basic_strategies.html"},{"title":"GDB","text":"概述GDB是GNU发布的UNIX程序调试工具，可以帮助完成 自定义运行程序 让程序在指定断点处停止 检查停止程序的内部状态 动态改变程序执行环境 调试准备 gdb会根据文件名后缀确认调试程序的语言，设置gdb自身语言 环境，并随之改变语言环境 如果程序由多种语言编译而成，gdb能根据不同语言自动 切换语言环境 可以使用info、show、set命令查看设置当前语言环境 可能会缺少glibc-debuginfo，无法显示全部调试信息 OpenSuse安装可能需要添加源 编译选项 调试C++/C程序时，要求在编译时就把调试信息添加到可执行 文件中 使用gcc/g++的-g参数添加源码信息 否则调试时将看不见函数名、变量名，而是全部以运行时 内存地址代替 关闭优化选项 否则优化器会删改程序，使得某些变量不能访问、取值错误 启动GDB调试 gdb &lt;exe&gt;：直接gdb启动可执行文件&lt;exe&gt; gdb &lt;exe&gt; core：用gdb同时调试可执行文件、core文件 gdb &lt;exe&gt; &lt;PID&gt;：给定进程PID，gdb自动attach该进程， 调试已经运行的程序 也可不指定PID，直接关联源码，在gdb中使用attach命令 手动挂接，调试已运行程序 配置调试环境源文件 gdb启动程序后，gdb会在PATH、当前目录中搜索程序的源文件 -directory/-d添加源文件搜索路径 在gdb交互中使用dir[rectory] &lt;dirname&gt;指定源文件搜索 路径 gdb中使用list/l检查gdb是否能列出源码 程序运行环境在gdb中run程序之前，可能需要设置、查看程序运行环境 程序运行参数 set &lt;args&gt;：设置程序运行时参数 show &lt;args&gt;：查看已设置参数 环境变量 path [&lt;dir&gt;]：查看、添加&lt;dir&gt;至PATH show paths：查看PATH set environment var [=value]：设置环境变量 show environment var：查看环境变量 工作目录 cd &lt;dir&gt;：等价于cd pwd：等价于pwd 输入输出 info terminal：显示程序所有终端模式 run &gt; outfile：重定向程序输出 tty /dev/：指定输入、输出设备 参数 -s &lt;file&gt;/-symbols &lt;file&gt;：从指定文件读取符号表 -se &lt;file&gt;：从指定文件读取符号表信息，并用于可执行文件 -c &lt;file&gt;/-core &lt;file&gt;：调试core dump产生的core文件 -d &lt;dir&gt;/-directory &lt;dir&gt;：添加源文件搜索路径 默认搜索路径是PATH 表达式 表达式语法应该是当前所调试语言的语法 gdb另外还支持一些通用操作符 @：指定存储在堆上、动态分配内存大小的长度 1234int *array = (int*)malloc(len * sizeof(int)); # 源码&gt; p *array@len # 打印数组`*array` ::：指定某个具体文件、函数中的变量 常用于取出被隐藏的全局变量 [(type)]&lt;addr&gt;：内存地址addr处为一个type类型 变量 停止点设置Breakpointbreakbreak：在某位置设置断点 12b[reak] [&lt;probe_modifier&gt;] [&lt;location&gt;] [thread &lt;threadno&gt;] [if &lt;condition&gt;] probo_modifier：命令处于probe point时需要 -probe：通用、自动推测探测类型 -probe-stap：SystemTap探测 -probe-dtrace：DTrace探测 location：设置断点位置 缺省：当前栈帧中的执行位置 linespecs：冒号分隔绝对位置参数（逐步精确） 其中可以包括：文件名、函数名、标签名、行号 +-[n]标识相对当前行位置 *addr：在程序运行的内存地址addr处 explicit：类似于linespecs，通过多个参数给出 threadno：设置断点的线程号 缺省断点设置在所有线程上 gdb分配的线程编号，通过info threads查询 多线程被gdb停止时，所有运行线程都被停止，方便 查看运行程序总体情况 if &lt;condition&gt;：满足条件condition时在断点处停止， 缺省立即停止程序 123456789&gt; break factorial.c:fact:the_top # factorial.c文件、fact函数、the_top标签&gt; break +2 # 当前行之后两行&gt; break *main + 4 # `main`函数4B之后&gt; break -source factorial.c -function fact -label the_top # explicit方式，同linespecs 标签：C++/C中配合goto使用（label_1:） &lt;tab&gt;：补全函数名称、函数原型（重载函数） 若指定函数名称不唯一，gdb会列出函数原型供选择 tbreaktbreak：设置一次性断点，生效后立刻被删除 rbreakrbreak：对匹配正则表达式的行均设置断点 conditioncondition：修改、设置断点n生效条件 12&gt; condition &lt;bpnum&gt; &lt;condition&gt; # 设置断点`bpnum`生效条件为`condition` ignoreignore：设置忽略断点n次数 12&gt; ignore &lt;bpnum&gt; &lt;count&gt;` # 忽略断点`bpnum` `count`次 设置Watchpointwatchwatch：为某个表达式设置观察点 观察某个表达式，其值发生变化时停止程序 12&gt; watch [-l|-location] &lt;expr&gt; [thread &lt;threadno&gt;] [mask &lt;maskvalue&gt;] -l：表示将expression视为地址，观察表达式指向的地址 中的值 expr：表达式、*开头表示的内地地址 threadno：同break maskvalue：观察值mask，只观察部分bit值 1234&gt; watch foo mask 0xffff00ff # 观察`foo`&gt; watch *0xdeadbeef 0xffffff00 # 观察内存地址`0xdeadbeef`处的值 取决于系统，观察点有可能以硬件、软件方式实现，大部分 PowerPC、X86支持硬件观察点 软件观察点通过逐步测试变量实现，程序执行速度慢得多 硬件观察点不会降低程序执行速度 mask参数需要架构支持 rwatchrwatch：为某表达式设置读观察点 当表达式值被读取时停止程序 12&gt; rwatch [-l|location] &lt;expression&gt; [thread &lt;threadno&gt;] [mask &lt;maskvalue&gt;] awatchawatch：为某表达式设置写观察点 当表达式值被修改时停止程序 12&gt; awatch [-l|-location] &lt;expression&gt; [thread &lt;threadno&gt;] [mask &lt;maskvalue&gt;] 设置Catchpointcatchcatch：设置捕捉点捕捉事件 1&gt; cat[ch] &lt;event&gt; 通用事件 catch：捕获异常 exec：调用系统调用exec（仅HP-UX下有用） fork：调用系统调用fork（仅HP-UX下有用） load [&lt;libname&gt;]：载入共享库（仅HP-UX下有用） unload [&lt;libname&gt;]：卸载共享库（仅HP-UX下有用） throw：抛出异常 rethrow：再次抛出异常 vfork：调用系统调用vfork时（仅HP-UX下有用） syscall：被系统调用 Ada assert：捕获Ada断言失败 exception [arg]：捕获Ada和参数匹配的异常 handlers：捕获Ada异常 捕捉点：捕捉程序运行时的一些事件，如：载入动态链接库、 异常事件&lt;event&gt;发生时停止程序 tcatchtcatch：设置一次性捕捉点，程序停止后自动删除 信号处理gdb可以在调试程序时处理任何信号，可以要求gdb在收到指定信号后 停止正在执行的程序以供调试 1&gt; handle &lt;signal&gt; &lt;keywords&gt; signal：需要处理的信号 信号可选使用SIG开头 可以定义需要处理的信号范围SIGIO-SIGKILL 可以使用all表示处理所有信号 keywords：被调试程序接收到信号后gdb的动作 nostop：不停止程序运行，打印消息告知收到信号 stop：停止程序运行 print：显示信息todo noprint：不显示信息 noigore：gdb处理信号，交给被调试程序处理 nopass/ignore：gdb截留信号，不交给被调试程序处理 维护停止点clearclear：清除指定位置断点 1&gt; clear [&lt;location&gt;] location：指定清除断点位置 缺省：清除当前栈帧中正在执行行断点 其余设置同break commandscommands：设置断点生效时自动执行命令 利于自动化调试 123&gt; commands [bpnum]&gt; ...command-list...&gt; end bpnum：断点序号 缺省：最近设置的断点 5-7：指定断点区间 执行文件listlist：打印源代码 1&gt; l[ist] [&lt;location&gt;] location：输入的源代码 缺省/+：显示当前行后源代码 -：显示当前行前源代码 [[start], [end]]：显示范围内源代码（缺省表当前行） 指定单行类似break中location参数 一般默认显示10行，可以通过set listsize &lt;count&gt;设置 forward-search/searchsearch/forward-search：从打印出最后行开始正则搜索源码 1&gt; search/forward-search &lt;regexp&gt; revserse-searchreverse-search：从打印出的最后行反向正则搜索源码 1&gt; reverse-search &lt;regexp&gt; directorydirectory：指定源文件搜索路径 1&gt; dir[rectory] &lt;dir&gt; dir：源文件路径 可以指定多个搜索路径，linux下:分隔，windows下; 缺省：清除自定义源文件搜索路径信息 show查看当前 继续执行runrun：启动程序开始调试 1&gt; r[un] [&lt;args&gt;] args 缺省：上次run、set args指定的参数 参数中包含的*、...将被用于执行的shell扩展 （需清除参数，使用set args置空） 允许输入、输出重定向 continuecontinue：继续执行直到之后断点、程序结束 1&gt; c[ontinue]/fg [&lt;ignore-count&gt;] ignore-count：执行直到之后第ingore-count个断点 （忽略ignore-count-1个断点） 缺省：1 step/nextstep/next：单步/单行跟踪 1&gt; s[tep]/[n]ext [&lt;count&gt;] count：执行代码行数 缺省：1 有函数调用，step进入函数（需要函数被编译有debug信息） ，next不进入函数调用，视为一代代码 stepi/nextistepi/nexti：单条intruction（机器指令、汇编语句）跟踪 1&gt; s[tep]i/n[ext]i [&lt;count&gt;] count：执行指令条数 缺省：1 finishfinish：运行直到当前栈帧/函数返回，并打印函数返回值、存入 值历史 returnreturn：强制函数忽未执行语句，并返回 1&gt; return [expr] expr：返回的表达式值 缺省：不返回值 utiluntil/u：运行程序直到退出循环体 jumpjump：修改程序执行顺序，跳转至程序其他执行处 1&gt; jump [&lt;location&gt;] location：同break jump不改变当前程序栈中内容，所以在函数间跳转时，函数 执行完毕返回时进行弹栈操作式必然发生错误、结果错误、 core dump，所以最好在同一个函数中跳转 事实上，jump就是改变了寄存器中保存当前代码所在的内存 地址，所以可以通过set $pc更改跳转执行地址 callcall：强制调用函数，并打印函数返回值（void不显示） 1&gt; call &lt;expr&gt; print也可以调用函数，但是如果函数返回void，print 显示并存储如历史数据中 查看信息print/inspect1&gt; p[rint] [/&lt;f&gt;]&lt;expr&gt;[=value] f：输出格式 x：16进制格式 d：10进制格式 u：16进制格式显示无符号整形 o：8进制格式 t：2进制 a：16进制 c：字符格式 f：浮点数格式 i：机制指令码 s： expr：输出表达式、gdb环境变量、寄存器值、函数 输出表达式：gdb中可以随时查看以下3种变量值 全局变量：所有文件可见 静态全局变量：当前文件可见 局部变量：当前scope可见 局部变量会隐藏全局变量，查找被隐藏变量可以使用 ::指定 编译程序时若开启优化选项，会删改程序，使得某些变量 不能访问 输出环境变量、寄存器变量时，需要使用$前缀 函数名称：强制调用函数，类似call value：修改被调试程序运行时变量值 缺省：打印变量值 =是C++/C语法，可以根据被调试程序改为相应程序赋值 语法 可以通过set var实现（当变量名为gdb参数时，必须 使用set var） 每个print输出的表达式都会被gdb记录，gdb会以$1、$2 等方式记录下来，可以使用此编号访问以前的表达式 examineexamine/x：查看内存地址中的值 1&gt; examine/x /[&lt;n/f/u&gt;] &lt;addr&gt; 输出参数：可以三者同时使用 n：查看内存的长度（单元数目） f：展示格式，同print u：内存单元长度 b：单字节 h：双字节 w：四字节，默认 g：八字节 addr：内存地址 12&gt; x/3uh 0x54320 # 从内存地址`0x54320`开始，16进制展示3个双字节单位 displaydisplay：设置自动显示变量，程序停止时变量会自动显示 1&gt; display/[&lt;fmt&gt;] [&lt;expr&gt;] [&lt;addr&gt;] fmt：显示格式 同print exprt：表达式 addr：内存地址 123&gt; display/i $pc # `$pc`：gdb环境变量，表示指令地址 # 单步跟踪会在打印程序代码时，同时打印出机器指令 undisplayundisplay：删除自动显示 1&gt; undisplay [&lt;num&gt;] num：自动显示编号 info查看 可以使用a-b表示范围 查看、设置GDB环境info停止点 locals：打印当前函数中所有局部变量名、值 args：打印当前函数参数名、值 b[reak][points] [n]：查看断点 watchpoints [n]：列出所有观察点 catch：打印当前函数中异常处理信息 line [&lt;location&gt;]：查看源代码在内存中地址 f[rame]：可以打印更详细当前栈帧信息 大部分为运行时内存地址 display：查看display设置的自动显示信息 线程 threads查看在正在运行程序中的线程信息 信号 info signals/handle：查看被gdb检测的信号 frame：查看当前函数语言 source：查看当前文件程序语言 其他 terminal：显示程序所有终端模式 registers [reg]：查看寄存器情况 缺省：除浮点寄存器外所有寄存器 还可以通过print实现 all-registers：查看所有寄存器情况（包括浮点寄存器） set停止点 step-mode [on] [off]：开启/关闭step-mode模式 程序不会因为没有debug信息而不停止，方便查看机器码 环境 language [lang]：设置当前语言环境 args [&lt;args&gt;]：设置被调试程序启动参数 environment var [=value]：设置环境变量 listsize &lt;count&gt;：设置最大打印源码行数 var &lt;var=value&gt;：修改被调试程序运行时变量值 还可以通过print变量修改 print address [on/off]：打开地址输出 即程序显示函数信息时，显示函数地址 默认打开 array [on/off]：打开数组显示 打开数组显示后，每个函数占一行，否则以逗号分隔 默认关闭 elements &lt;num-of-elements&gt;：设置数组显示最大长度 0：不限制数组显示 null-stop [on/off]：打开选项后，显示字符串时遇到结束符 则停止显示 默认关闭 pretty [on/off]：打开选项后，美化结构体输出 打开选项后，结构体成员单行显示，否则逗号分隔 sevenbit-strings [on/off]：字符是否按照/nnn格式显示 打开后字符串/字符按照/nnn显示todo union [on/off]：显示结构体时是否显示其内联合体数据 打开时联合体显示结构体各种值，否则显示... object [on/off]：打开选项时，若指针对象指向其派生类， gdb自动按照虚方法调用的规则显示输出，否则gdb忽略虚函数表 默认关闭 static-members [on/off]：是否对象中静态数据成员 默认打开 vtbl [on/off]：选项打开，gdb将用比较规则的格式输出 虚函数表 默认关闭 show执行 args：查看被调试程序启动参数 paths：查看gdb中PATH environtment [var]：查看环境变量 directories：显示源文件搜索路径 convenience：查看当前设置的所有环境变量 print address：查看是否打开地址输出 array：查看是否打开数组显示 element：查看再打数组显示最大长度 pretty：查看是否美化结构体输出 sevenbit-strings [on/off]：查看字符显示是否打开 union：查看联合体数据输出方式 object：查看对象选项设置 static-members：查看静态数据成员选项设置 vtbl：查看虚函数显示格式选项设置 shellshell：执行shell命令 1&gt; shell &lt;shell-cmd&gt; cd：等同&gt; shell cd pwd make &lt;make-args&gt; Linux：使用环境变量SHELL、/bin/sh执行命令 Windows：使用cmd.exe执行命令 pathpath：添加路径至gdb中PATH（不修改外部PAHT） 1&gt; path &lt;dir&gt; GDB环境环境变量可以在gdb调试环境中自定义环境变量保存调试程序中需要的数据 12345678&gt; set $foo = *object_ptr # 设置环境变量&gt; show convenience # 查看当前设置的所有环境变量&gt; set $i=0&gt; print bar[$i++] -&gt; contents # 环境变量、程序变量交互使用 # 只需要回车重复上条命令，环境变量自动累加，逐个输出变量 环境变量使用$开头（定义时也需要） gdb会在首次使用时创建该变量，在以后使用直接对其赋值 环境变量没有类型，可以定义任何类型，包括结构体、数组 寄存器寄存器：存放了程序运行时数据 ip：程序当前运行指令地址 sp：程序当前堆栈地址 123456&gt; info registers [&lt;reg-name&gt;] # 输出寄存器值，缺省除浮点外所有&gt; info all-registers # 输出所有寄存器值&gt; print $eip # 输出寄存器`eip`值 其他 disassemble：查看程序当前执行的机器码 此命令会dump当前内存中指令 si[gnal] &lt;signal&gt;：产生信号量发给被调试程序 signal：取值1-15，即Unix信号量 此命令直接发送信号给被调试程序，而系统信号则是发送给 被调试程序，但由gdb截获， 调试设置deletedelete：删除断点（缺省）、自动输出表达式等 12&gt; delete [breakpoints] [bookmark] [checkpoints] [display] [mem] [tracepoints] [tvariable] [num] breakpoints：删除断点 bookmark：从书签中删除书签 checkpoints：删除检查点 display：取消程序停止时某些输出信息 mem：删除存储区 tracepoint：删除指定追踪点 tvariable：删除追踪变量 num 缺省：删除所有断点/自动输出/书签等 指定的序号 info查看 可以使用a-b表示范围 disabledisable：禁用断点（缺省）、输出表达式等 123&gt; disable [breakpoints] [display] [frame-filter] [mem] [pretty-printer] [probes] [type-printer] [unwinder] [xmethod] [num] breakpoints禁用断点 1&gt; disable [breakpoints] [num] 缺省：禁用所有断点 仅指定的序号（info查看） display禁用程序停止时某些输出信息 frame-filter禁用某些帧过滤器 mem禁用存储区 pretty-printer禁用某些打印美化 probes禁用探测 type-printer禁用某些类型打印 unwinder禁用某些unwinder xmethod禁用某些xmethod enableenable：启用断点（缺省）、输出表达式等 123&gt; enable [breakpoints] [display] [frame-filter] [mem] [pretty-printer] [probes] [type-printer] [unwinder] [xmethod] [num] breakpoints启用断点 12&gt; enable [breakpoints] [num] [once] [delete]` - `[delete]`：启用断点，生效后自动被删除 num：断点序号 缺省：启用所有断点 once：启用断点一次 delete：启用生效后自动删除 count：启用断点count次 display启用程序停止时某些输出信息 frame-filter启用某些帧过滤器 mem启用存储区 pretty-printer启用某些打印美化 probes启用探测 type-printer启用某些类型打印 unwinder启用某些unwinder xmethod启用某些xmethod 栈backtracebacktrace：打印函数栈 1&gt; backtrace/bt [-][&lt;n&gt;] -：打印栈底信息 缺省：打印栈顶信息 n：打印栈数量 缺省：打印当前函数调用栈所有信息 一般而言，程序停止时，最顶层栈就是当前函数栈 frameframe：切换当前栈 1&gt; f[rame] [&lt;n&gt;] n：切换到第n个栈帧 缺省打印当前栈编号、断点信息（函数参数、行号等） upup：上移当前栈帧 1&gt; up [&lt;n&gt;] n：上移n层栈帧 缺省：上移1层 downdown：下移当前栈帧 1&gt; down [&lt;n&gt;] n：下移n层栈帧 缺省：下移1层 GDB命令大全aliasesbreakpointsdatafilesinternalsobscurerunningstackstatussupporttracepointsuser-defined1234567891011121314151617181920212223242526$ gdb tst # `gdb`启动可执行文件tst(gdb) l # `l`：list，列出源码(gdb) # 直接回车：重复上次命令(gdb) break 16 # `break [n]`：在第`n`行设置断点(gdb) break func # `break func`：在函数`func`入口处设置断点(gdb) info break # `info break`：查看断点信息(gdb) r # `r`：run，执行程序，会自动在断点处停止(gdb) n # `n`：next，单条语句执行(gdb) c # `c`：continue，继续执行（下个断点、程序结束为止）(gdb) p i # `p i`：print，打印变量i的值(gdb) bt # `bt`：查看函数栈(gdb) finish # `finish`：退出**函数**(gdb) 1 # `q`：quit，退出gdb","link":"/Linux/Tool/gdb.html"},{"title":"Hashing","text":"Hash Function hash：散列/哈希，将任意类型值转换为关键码值 hash function：哈希/散列函数，从任何数据中创建小的数字“指纹”的方法 hash value：哈希值，哈希函数产生关键码值 collision：冲突，不同两个数据得到相同哈希值 哈希函数应该尽可能使得哈希值均匀分布在目标空间中 降维：将高维数据映射到低维空间 数据应该低维空间中尽量均匀分布 数据相关性 Data Independent Hashing：数据无关哈希，无监督，哈希函数基于某种概率理论 对原始的特征空间作均匀划分 对分布不均、有趋向性的数据集时，可能会导致高密度区域哈希桶臃肿，降低索引效率 Data Dependent Hashing：数据依赖哈希，有监督，通过学习数据集的分布从而给出较好划分的哈希函数 得到针对数据密度动态划分的哈希索引 破坏了传统哈希函数的数据无关性，索引不具备普适性 应用 查找数据结构：cs_algorithm/data_structure/hash_table 哈希表 信息安全方向：cs_algorithm/specification/info_security 文件检验 数字签名 鉴权协议 哈希函数 简单哈希函数主要用于提升查找效率（构建哈希表） 要求哈希函数的降维、缩小查找空间性质 计算简单、效率高 复杂哈希函数主要用于信息提取 要求哈希函数的信息提取不可逆、非单调映射 查表哈希 CRC 系列算法：本身不是查表，但查表是其最快实现 Zobrist Hashing 混合哈希：利用以上各种方式 MD5 Tiger 单值输入 直接寻址法：取关键字、或其某个线性函数值 $hash(key) = (a * key + b) \\% prime$ $prime$：一般为质数，以使哈希值尽量均匀分布，常用的如：$2^{32}-5$ 数字分析法：寻找、利用数据规律构造冲突几率较小者 如：生日信息前 2、3 位大体相同，冲突概率较大，优先舍去 平方取中法：取关键字平方后中间几位 折叠法：将关键字分割为位数相同部分，取其叠加和 随机数法：以关键字作为随机数种子生成随机值 适合关键字长度不同场合 常用于之前哈希结果再次映射为更小范围的最终哈希值 序列输入加法哈希加法哈希：将输入元素相加得到哈希值 标准加法哈希 123456AddingHash(input): hash = 0 for ele in input: hash += ele # prime 为任意质数，常用 2^32 - 5 hash = hash % prime 最终哈希结果 $\\in [0, prime-1]$ 位运算哈希位运算哈希：利用位运算（移位、异或等）充分混合输入元素 标准旋转哈希 12345RotationHash(input): hash = 0 for ele in input: hash = (hash &lt;&lt; 4) ^ (hash &gt;&gt; 28) ^ ele return hash % prime 变形 1 1hash = (hash&lt;&lt; 5) ^ (hash &gt;&gt; 27) ^ ele 变形2 123hash += elehash ^= (hash &lt;&lt; 10)hash ^= (hash &gt;&gt; 6) 变形3 1234if (ele &amp; 1) == 0: hash ^= (hash &lt;&lt; 7) ^ ele ^ (hash &gt;&gt; 3)else: hash ^= ~((hash &lt;&lt; 11) ^ ele ^ (hash &gt;&gt; 5)) 变形4 1hash += (hash &lt;&lt; 5) + ele 变形5 1hash = ele + (hash &lt;&lt; 6) + (hash &gt;&gt; 16) - hash 变形6 1hash ^= (hash &lt;&lt; 5) + ele + (hash &gt;&gt; 2) 乘法哈希乘法哈希：利用乘法的不相关性 平方取头尾随机数生成法：效果不好 Bernstein 算法 12345Bernstein(input): hash = 0 for ele in input: hash = 33 * hash + ele return hash 其他常用乘数：31、131、1313、13131、131313 32位 FNV 算法 1234567M_SHIFT =M_MASK =FNVHash(input): hash = 2166136261; for ele in input: hash = (hash * 16777619) ^ ele return (hash ^ (hash &gt;&gt; M_SHIFT)) &amp; M_MASK 改进的 FNV 算法 12345678910FNVHash_2(input): hash = 2166136261; for ele in input: hash = (hash ^ ele) * 16777619 hash += hash &lt;&lt; 13 hash ^= hash &gt;&gt; 7 hash += hash &lt;&lt; 3 hash ^= hash &gt;&gt; 17 hash += hash &lt;&lt; 5 return hash 乘数不固定 1234567RSHash(input): hash = 0 a, b = 378551, 63689 for ele in input: hash = hash * a + ele a *= b return hash &amp; 0x7FFFFFFF 除法也类似乘法具有不相关性，但太慢 定长序列 两步随机数 123456main_rand_seq = randint(k)TwoHashing(input[0,...,k]): hash = 0 from i=0 to k: hash += input[i] * main_rand_seq[i] hash = hash mod prime Universal Hashing 全域哈希：键集合 $U$ 包含 $n$ 个键、哈希函数族 $H$ 中哈希函数 $h_i: U \\rightarrow 0..m$，若 $H$ 满足以下则为全域哈希 $$ \\forall x \\neq y \\in U, | \\{h|h \\in H, h(x) = h(y) \\} | = \\frac {|H|} m $$ $|H|$：哈希函数集合 $H$ 中函数数量 独立与键值随机从中选择哈希函数，避免发生最差情况 可利用全域哈希构建完美哈希 性质 全域哈希 $H$ 中任选哈希函数 $h_i$，对任意键 $x \\neq y \\in U$ 冲突概率小于 $\\frac 1 m$ 由全域哈希函数定义，显然 全域哈希 $H$ 中任选哈希函数 $hi$，对任意键 $x \\in U$，与其冲突键数目期望为 $\\frac n m$，即 $E{[collision_x]}=\\frac n m$ \\begin{align*} E(C_x) &= E[\\sum_{y \\in U - \\{x\\}} C_{xy}] \\\\ &= \\sum_{y \\in U - \\{x\\}} E[C_{xy}] \\\\ &= \\sum_{y \\in U - \\{x\\}} \\frac 1 m \\\\ &= \\frac {n-1} m \\end{align*} $C_x$：任选哈希函数，与 $x$ 冲突的键数量 $C_{xy} = \\left { \\begin{matrix} 1, &amp; h_i(x) = h_i(y) \\ 0, &amp; otherwise \\end{matrix} \\right.$：指示 $x,y$ 是否冲突的指示变量 $m = n^2$ 时，冲突期望小于 0.5 $n$ 个键两两组合数目为 $C_n^2$ 则 $E_{total} &lt; C_n^2 \\frac 1 n &lt; 0.5$ 例 以下构造 $[0,p-1] \\rightarrow [0,m-1]$ 全域哈希 $p$ 为足够大素数使得所有键值 $\\in [0,p-1]$ 记 $Z_p = { 0,1,\\cdots,p-1 }$ 记 $Z_p^{*}={ 1,2,\\cdots,p-1 }$ 且哈希函数映射上限（哈希表长度） $m &lt; max(U) &lt; p$ 记哈希函数 \\forall a \\in Z_p^{*}, b \\in Z_p, h_{a, b}(k) = ((a k + b) \\% p) \\% m 则以下哈希函数族即为全域哈希 H_{p,m} = {h_{a,b}|a \\in Z_p^{*}, b \\in Z_p} Locality Sensitive HashingLSH：局部敏感哈希 $(r_1,r_2,P_1,P_2)-sensitive$ 哈希函数族 $H$ 需满足如下条件 $$ \\begin{align*} Pr_{H}[h(v) = h(q)] \\geq P_1, &amp; \\forall q \\in B(v, r_1) \\\\ Pr_{H}[h(v) = h(q)] \\geq P_2, &amp; \\forall q \\notin B(v, r_2) \\\\ \\end{align*}$$ $h \\in H$ $r_1 &lt; r_2, P_1 &gt; P_2$：函数族有效的条件 $B(v, r)$：点 $v$ 的 $r$ 邻域 $r_1, r_2$：距离，强调比例时会表示为 $r_1 = R, r_2 = cR$ 此时 相似目标（距离小）有更大概率发生冲突 LSH查找思想 相似目标更有可能映射到相同哈希桶中 则只需要在目标所属的哈希桶中进行比较、查找即可 无需和全集数据比较，大大缩小查找空间 可视为降维查找方法 将高维空间数据映射到 1 维空间，寻找可能近邻的数据点 缩小范围后再进行精确比较 概率放大 期望放大局部敏感哈希函数族 $Pr_1, Pr_2$ 之间差距 增加哈希值长度（级联哈希函数中基本哈希函数数量） $k$ 每个哈希函数独立选择，则对每个级联哈希函数 $g_i$ 有 $Pr[g_i(v) = g_i(q)] \\geq P_1^k$ 虽然增加哈希键位长会减小目标和近邻碰撞的概率，但同时也更大程度上减少了和非近邻碰撞的概率、减少搜索空间 级联哈希函数返回向量，需要对其再做哈希映射为标量，方便查找 增加级联哈希函数数量（哈希表数量） $L$ $L$个哈希表中候选项包含真实近邻概率 至少 为 $1 - (1 - P_1^k)^L$ 增加哈希表数量能有效增加候选集包含近邻可能性 但同时也会增大搜索空间 搜索近似最近邻 使用 $L$ 个级联哈希函数分别处理待搜索目标 在 $L$ 个哈希表分别寻找落入相同哈希桶个体作为候选项 在所有候选项中线性搜索近邻 基于汉明距离的 LSH 在汉明距离空间中搜索近邻 要求数据为二进制表示 其他距离需要嵌入汉明距离空间才能使用 欧几里得距离没有直接嵌入汉明空间的方法 一般假设欧几里得距离和曼哈顿距离差别不大 直接使用对曼哈顿距离保距嵌入方式 设计哈希函数族 考虑哈希函数族 $H = { h_1, h_2, \\cdots, h_m }$ 其中函数 $h_i$ 为 ${0, 1}^d$ 到 ${0, 1}$ 的映射：随机返回特定比特位上的值 从 $H$ 中随机的选择哈希函数 $h_i$ 则 $Pr[h_i(v) = h_i(q)]$ 等于 $v, q$ 相同比特数比例，则 $Pr_1 = 1 - \\frac R d$ $Pr_2 = 1 - \\frac {cR} d$ 考虑到 $Pr_1 &gt; Pr_2$，即此哈希函数族是局部敏感的 基于 Jaccard 系数的 LSH 考虑 $M * N$ 矩阵 $A$，元素为 0、1 其中 $M$：集合元素数量 $N$：需要比较的集合数量 目标：寻找相似集合，即矩阵中相似列 用 Jaccard 系数代表集合间相似距离，用于搜索近邻 要求各数据向量元素仅包含 0、1：表示集合是否包含该元素 定义 Min-hashing 函数族 对矩阵 $A$ 进行 行随机重排 $\\pi$，定义 Min-hashing 如下 h_{\\pi}(C) = \\min \\pi(C) $C$：列，表示带比较集合 $\\min \\pi(C)$：$\\pi$ 重排矩阵中 $C$ 列中首个 1 所在行数 则不同列（集合） Min-hashing 相等概率等于二者 Jaccard 系数 \\begin{align*} Pr(h_{\\pi}(C_1) = h_{\\pi}(C_2)) & = \\frac a {a + b} \\\\ & = Jaccard_d(C_1, C_2) \\end{align*} $a$：列 $C_1, C_2$ 取值均为 1 的行数 $b$：列 $C_1, C_2$ 中仅有一者取值为 1 的行数 根据 Min-hashing 定义，不同列均取 0 行被忽略 Min-hashing 实现 数据量过大时，对行随机重排仍然非常耗时，考虑使用哈希函数模拟行随机重排 每个哈希函数对应一次随机重排 哈希函数视为线性变换 然后用哈希函数结果对总行数取模 原行号经过哈希函数映射即为新行号 为减少遍历数据次数，考虑使用迭代方法求解 123456for i from 0 to N-1: for j from 0 to M-1: if D[i][j] == 1: for k from 1 to K: # 更新随机重拍后，第 `j` 列首个 1 位置 DD[k][j] = min(h_k(i), DD[k][j]) $D$：原始数据特征矩阵 $DD$：$Min-hashing* 签名矩阵 $N$：特征数量，原始特征矩阵行数 $M$：集合数量，原始特征矩阵列数 $K$：模拟的随机重排次数，Min-hashing 签名矩阵行数 $h_k,k=1,…,K$：$K$ 个模拟随机重排的哈希函数，如 $h(x) = (2x + 7) mod N$ 初始化 Min-hashing 签名矩阵所有值为 $\\infty$ 遍历 $N$ 个特征、$M$ 个集合 查看每个对应元素是否为 1 若元素为 1，则分别使用 $K$ 个哈希函数计算模拟重排后对应的行数 若计算出行数小于当前 *Min-hash$ 签名矩阵相应哈希函数、集合对应行数，更新 遍历一遍原始数据之后即得到所有模拟重排的签名矩阵 Exact Euclidean LSH $E^2LSH$：欧式局部LSH，LSH Based-on P-stable Distribution 使用内积将向量随机映射到哈希值 p-stable 分布性质将欧式距离同哈希值相联系，实现局部敏感 $E^2LSH$ 特点 基于概率模型生成索引编码结果不稳定 随编码位数 $k$ 增加的，准确率提升缓慢 级联哈希函数数量 $L$ 较多时，需要大量存储空间，不适合大规模数据索引 p-stable 哈希函数族 h_{a, b}(v) = \\lfloor \\frac {av + b} r \\rfloor $v$：$n$ 维特征向量 $a = (X_1,X_2,\\cdots,X_n)$：其中分量为独立同 p-stable 分布的随机变量 $b \\in [0, r]$：均匀分布随机变量 p-stable 哈希函数碰撞概率 考虑$|v_1 - v_2|_p = c$的两个样本碰撞概率 显然，仅在 $|av1 - av_2| \\leq r$ 时，才存在合适的 $b$ 使得 $h{a,b}(v1) = h{a,b}(v_2)$ 即两个样本碰撞，不失一般性可设 $av_1 \\leq av_2$ 此 $r$ 即代表局部敏感的 局部范围 若 $(k-1)r \\leq av_1 \\leq av_2 &lt; kr$，即两个样本与 $a$ 内积在同一分段内 易得满足条件的 $b \\in [0,kr-av_2) \\cup [kr-av_1, r]$ 即随机变量 $b$ 取值合适的概率为 $1 - \\frac {av_2 - av_1} r$ 若 $(k-1)r \\leq av_1 \\leq kr \\leq av_2$，即两个样本 $a$ 在相邻分段内 易得满足条件的 $b \\in [kr-av_1, (k+1)r-av_2)$ 即随机变量 $b$ 取值合适的概率同样为 $1 - \\frac {av_2 - av_1} r$ 考虑 $av_2 - av_1$ 分布为 $cX$，则两样本碰撞概率为 \\begin{align*} p(c) & = Pr_{a,b}(h_{a,b}(v_1) = h_{a,b}(v_2)) \\\\ & = \\int_0^r \\frac 1 c f_p(\\frac t c)(1 - \\frac t r)dt \\end{align*} $c = |v_1 - v_2|_p$：特征向量之间$L_p$范数距离 $t = a(v_1 - v_2)$ $f$：p稳定分布的概率密度函数 $p=1$ 柯西分布 p(c) = 2 \\frac {tan^{-1}(r/c)} \\pi - \\frac 1 {\\pi(r/c)} ln(1 + (r/c)^2) $p=2$ 正态分布 p(c) = 1 - 2norm(-r/c) - \\frac 2 {\\sqrt{2\\pi} r/c} (1 - e^{-(r^2/2c^2)}) 性质、实现限制近邻碰撞概率 $r$ 最优值取决于数据集、查询点 根据文献，建议$r = 4$ 若要求近邻 $v \\in B(q,R)$以不小于$1-\\sigma$ 概率碰撞，则有 \\begin{align*} 1 - (1 - p(R)^k)^L & \\geq 1 - \\sigma \\\\ \\Rightarrow L & \\geq \\frac {log \\sigma} {log(1 - p(R)^k)} \\end{align*}则可取 L = \\lceil \\frac {log \\sigma} {log(1-p(R)^k)} \\rceil $k$ 最优值是使得 $T_g + T_c$ 最小者 $T_g = O(dkL)$：建表时间复杂度 $T_c = O(d |collisions|)$：精确搜索时间复杂度 $T_g$、$T_c$ 随着 $k$ 增大而增大、减小 具体实现参考https://www.mit.edu/~andoni/LSH/manual.pdf 限制搜索空间 哈希表数量 $L$ 较多时，所有碰撞样本数量可能非常大，考虑只选择 $3L$ 个样本点 此时每个哈希键位长 $k$、哈希表数量 $L$ 保证以下条件，则算法正确 若存在 $v^{ }$ 距离待检索点 $q$ 距离小于 $r_1$，则存在 $g_j(v^{ }) = g_j(q)$ 与 $q$ 距离大于 $r_2$、可能和 $q$ 碰撞的点的数量小于 $3L$ \\sum_{j=1}^L |(P-B(q,r_2)) \\cap g_j^{-1}(g_j(q))| < 3L 可以证明，$k, L$ 取以下值时，以上两个条件以常数概率成立 （此性质是局部敏感函数性质，不要求是 $E^2LSH$） \\begin{align*} k & = log_{1/p_2} n\\\\ L & = n^{\\rho} \\\\ \\rho & = \\frac {ln 1/p_1} {ln 1/p_2} \\end{align*} $\\rho$ 对算法效率起决定性作用，且有以下定理 距离尺度 $D$ 下，若 $H$ 为 $(R,cR,p1,p_2)$-敏感哈希函数族，则存在适合 (R,c)-NN 的算法，其空间复杂度为 $O(dn + n^{1+\\rho})$、查询时间为 $O(n^{\\rho})$ 倍距离计算、哈希函数计算为 $O(n^{\\rho} log{1/p_2}n)$， 其中 $\\rho = \\frac {ln 1/p_1} {ln 1/p_2}$ $r$ 足够大、充分远离 0 时，$\\rho$ 对其不是很敏感 $p1, p_2$ 随 $r$ 增大而增大，而 $k = log{1/p_2} n$ 也随之增大，所以 $r$ 不能取过大值 Scalable LSHScalable LSH：可扩展的 LSH 对动态变化的数据集，固定哈希编码的局部敏感哈希方法对数据 动态支持性有限，无法很好的适应数据集动态变化 受限于初始数据集分布特性，无法持续保证有效性 虽然在原理上支持数据集动态变化，但若数据集大小发生较大变化，则其相应哈希参数（如哈希编码长度）等需要随之调整，需要从新索引整个数据库 在 $E^2LSH$ 基础上通过 动态增强哈希键长，增强哈希函数区分能力，实现可扩展 LSH","link":"/Math-Mixin/func_hash.html"},{"title":"Parallel","text":"并发和并行 Parallel：并行，同时做多件事情，关于执行、实现 Concurrent：并发，能够处理多件事情，关于结构、逻辑 并发问题可以使用并行方式解决，也可以串行解决 100并发任务同时运行在4核CPU上，最多可能有4个并发任务 并行处理，其余只能是串行处理 并行角度：硬件技术的物理限制瓶颈 单计算核心能力不足，所以需要多核并行运算 进程、线程可认为是实现并行的基本逻辑实体 并发角度：程序执行的逻辑重用需求 程序要求重用一组逻辑，所以需要将一组指令集打包，重复 调用该组指令集 子程序、协程可认为是方便重用的基本逻辑实体，因此更 应是语言内建机制 子程序：无状态保存，同样重入得到同样结果 协程：有保存状态，重入会改变协程状态，结果可能 不同 线程作为任务执行的实体，可以认为是子程序、协程的具体执行 内核线程作为可以独立执行的实体，逻辑上更会被设计为 完成独立任务，即没有保存状态需求，因此多是子程序的 具体执行 用户线程则用程序负责调度，二者执行实例均可 某种意义上线程、子程序是对应的执行实体、逻辑实体 子程序、协程 子程序可以看作时协程的特例 只有一个状态，每次进入时局部状态重置 唯一入口点 协程可视为子程序的组成 维护自身状态，所以逻辑上不独立 ，应该是作为被 调用对象 对于每次返回部分结果值的协程（也称生成器迭代器）， 可以直接视为类似链表之类的数据结构 （在某些语言中可以所有数据都是类，从这个角度这也都是 统一的） 子程序 协程 生命周期 后进先出 完全取决于需要 入口点 起始处 起始处、yield返回出口点 返回值 调用结束后返回全部 可每次yield返回部分值 现代指令集通常提供对调用栈的指令支持，便于实现可递归 调用的子程序，在提供续体的语言环境（如Scheme），恰好 可用此抽象状态表示实现协程 Subroutine/Procedure/Function/Routine/Method子程序：打包为整体、用于执行特定任务的指令集序列 子程序是依赖可重入能力的弱化版本 一旦唤醒，于起始点开始执行 一旦退出，子程序结束 子程序实例只返回一次，两次激活间不保存状态 子程序中局部变量在每次调用/重入函数时都是相同的 相同输入得到相同输出 procedure：过程，有时特指无返回值、仅有副作用 线程安全线程安全：子程序在多线程环境调用时，能够正确处理多个线程之间 的共享变量，使程序功能能正确完成 线程安全函数应该为每个调用其的线程分配专门空间，存储需要 单独保存的状态 Atomicity：原子性，操作不会被线程调度机制打断，一旦 开始就会运行到结束，中间不会有任何线程切换 可以通过lock、synchronized确保原子性 Visibility：可见性，某线程修改变量值后，其他线程能够 立刻感知 一般可以通过volatile保证可见性，强制要求被修改值 从寄存器同步至主存 lock、synchronized也可以通过限制其他线程访问变量 的方式保证可见性 Ordering：有序性/一致性，程序按照代码顺序执行 可以通过volatile保证一定的有序性 也可通过lock、synchronized提供单线程执行环境保证 有序性 Instruction Reorder指令重排：编译器对无相互依赖的指令重新排序执行 as-if-serial语义：指令可以为优化而重排序，但是必须保证 最终执行结果不变 规则：重排序过程不破坏数据依赖关系 只能保证单线程执行结果有效，但不保证多线程并发执行 的正确性 happens-before原则：保证前后两个操作间不会被重排序， 程序次序规则：线程中每个操作happens-before该线程中 任意后续操作 锁定规则：锁的解锁happens-before加锁 volatile变量规则：volatile变量写操作happens-before 其读操作 传递规则：若A happens-before B、B happens-before C，则A happens-before C 线程启动规则：线程对象启动happens-before线程中每个 动作 线程中断规则：线程中断方法的调用happens-before被 中断线程代码检测到的中断事件的发生 线程终结规则：线程中所有操作happens-before线程的 终止检测 对象终结规则：对象的初始化happens-before其final 方法的开始 happens-before原则被JVM用于规定（跨线程）操作之间偏序 关系，若操作之间的关系可以由此原则退出，则两个操作有序 Reentrant A computer program or routine is described as reentrant if it can be safely executed concorrently; that is, the routine can be re-entered while it is already running 可重入函数：对于相同（合法）的函数参数，多次重复调用（包括 执行过程中被中断再重入）结果总是可预期的 可重入需要满足条件 不在函数内部使用静态或全局数据，所有数据都由函数 调用者提供 全局变量区 中断向量表 使用本地数据，或制作全局数据的本地拷贝保护全局数据 不返回静态或全局数据 不调用不可重入函数 不可重入后果主要体现在信号处理函数这样需要重入情况中， 若在信号处理函数中使用了不可重入函数，则可能导致程序错误 可重入函数总是线程安全的，反之不一定成立 线程安全可以通过“并发不冲突”实现 可重入则要求“并行不冲突” Coroutine协程：为非抢占式多任务产生子程序的程序组件，允许执行过程 中挂起、恢复 挂起、恢复：协程可以通过yield（让步）调用其他协程暂时 退出，之后可在退出位置恢复执行 从协程角度看，这是调用其他协程而不是退出 但实际是各协程之间是对称的，而不像子程序调用 中主调-被调关系 这即暗含 协程可包含多个入口点 允许在不同入口点暂停、开始执行程序 局部状态维护：协程实例保持上次退出时状态 则协程被唤醒时状态可能不同 可能同时有多个给定协程实例 协程将原在子程序外、输入状态管理工作交由自身逻辑维护 原生不支持协程的语言也可以使用循环等构建 经典状态机、对象已经具有协程特性 用途 协程可以简化异步代码的实现，使得需要使用异步+回调的代码 可以使用看似同步方式写出 协程本身只涉及状态保存、过程重入，和并发/异步无关系 但协程本身蕴含的状态保存使得状态切换几乎无成本，适合 高并发任务 协程在线程中调度完全由用户控制，可以视为用户态轻量级线程 避免陷入无效内核级别上下文切换造成的性能损失 较线程在IO密集任务上性能上更好 进程、线程 这里仅讨论理论上的异同，不考虑各平台具体实现 进程：具有独立功能的程序关于某数据集合的一次运行活动 线程/子程序：进程内某特定任务的执行活动 协程：推广协作式多任务的子程序 Process Thread Coroutine 调度、创建、切换、维护 内核（系统） 内核、自身 自身 切换开销、速度 大、慢 小、快 无 易用性 需要考虑进程退出、僵尸进程 只需要管理进程即可 无需管理 资源共享 独立 同进程内线程共享资源 除局部变量外均共享 通信 IPC较复杂：环境变量、文件、系统端口 较简单：共享内存 结果调用 移植性 差 好 好 健壮性 好，进程死亡不影响其他进程 差，线程死亡会导致进程（及线程）死亡 进程、线程、协程可以看作是控制权逐渐从系统已经移交到自身 的过程 这里的协程强调其在实现方面的资源、调度特点，其与子程序间 功能差异参加cs_program/parallel/implementation 通信：参见cs_program/parallel/#todo 移植性：基于进程分支多进程和windows模型有很大冲突，往往 不能在windows平台上使用 Process进程：具有独立功能的程序关于某数据集合的一次运行活动 进程是处于运行期的程序和相关资源的总称 程序：代码、指令 运行：对CPU的占用，逐渐发展为线程，标识进程中指令的执行 资源：执行上下文，由进程内线程共享 从系统调度方面看 进程是系统进行资源分配、调度的独立单位 在系统中有进程控制块（进程描述符）描述进程相关信息， 系统通过此控制块控制系统相关行为 从资源分配方面看 有独立的存储空间（虚拟寻址空间） 独享的用户空间 进程专用的“共享内核空间” 可执行的程序代码 线程可能对系统是可感知的，则进程不定是资源分配的基本 单位 Linux线程实现即类似进程，但不包含独立存储空间 调度角度 内核跟踪进程运行所需的状态信息（上下文） 主存、虚拟内存内容 寄存器文件值 栈 文件句柄 调度：分配CPU执行进程 内核决定CPU控制权在进程间的转移 上下文切换：进程状态的记录、恢复、切换 保存当前进程上下文、恢复新进程上下文 通过处理器在进程间切换，实现单个CPU“看似”并发执行 多个进程 上下文进程间切换开销比较大，但相对比较稳定安全 资源角度 独立内存空间/虚拟地址空间：每个进程“独占的”使用 内存、看到一致的存储器 用户空间 程序代码、数据：对所有进程，代码从同一固定位置开始， 直接按照可执行目标文件的内容初始化 （运行时）堆：可在运行时动态扩展、收缩 共享库：共享库代码和数据，如：C标准库、数学库 栈：用于实现函数调用，运行时动态扩展、收缩，位于虚拟 地址空间顶部 内核空间 内核虚拟存储器：内核总是驻留在内存中，为其保留地址 空间顶部 不允许程序读写区域内容或直接调用内核代码定义的函数 Thread线程：进程执行实体，进程中包含指令的执行活动 调度角度 线程是CPU调度、分派的基本单位，有时被称为轻量级进程 （在Linux系统中也是按照轻量级进程实现） 线程引入逻辑 进程内部可能存在多个不同task，task需要共享进程数据 同时task操作的数据具有独立性，多个task不需要按照时序 执行 task间需根据不同策略进行调度，因此产生了线程概念， 并被引入作为内核调度基本单位 线程：比进程更小的、能独立运行的基本单位 线程能/是“独立运行”，但不一定能被内核感知到，也一定由 内核调度 只能说线程是针对某个task的执行活动 资源角度 线程运行在进程的上下文中，共享同样代码和全局数据 进程代码段、公有数据 进程打开的文件描述符、信号的处理器 进程当前目录 进程用户ID、进程组ID 线程还独享某些个性以实现并发性 线程ID：进程中唯一标识 寄存器组值：线程间并发运行，线程有不同运行线索， 切换时需要保存当前线程的寄存器集合状态 线程堆栈：独立函数堆栈保证线程内函数调用可以正常 执行，不受其他线程影响 错误返回码：线程的系统调用错误可能未及时处理，独立 错误返回码避免其被其他线程修改 线程的信号屏蔽码：线程感兴趣的信号不同，因此信号 屏蔽码应由自己管理 线程优先级：线程需要像进程被调度，需要有相应的优先级 线程实现理论User-Level Thread用户级线程：由用户程序自身负责支持、调度 特点 相当于实现自己的线程调度内核，实现线程数据结构、 创建、销毁、调度维护 线程运行在内核（可感知的）进程内 优点 即使系统不支持线程，也可通过库函数支持在系统中实现 真实的多线程 线程只在用户态，减少内核态到用户态切换开销 缺点：线程对系统透明，对系统每个进程只有一个线程， 系统直接调用进程 当线程进行系统调用而阻塞时，系统会阻塞整个进程 用户空间没有时钟中断机制，若线程长时间不释放CPU， 会导致阻塞其他线程 Kernel-Level Thread内核级线程：系统内核支持的线程，通过内核完成线程切换 优点/特点：系统负责线程的创建、销毁、调度、维护 内核通过操纵调度器对线程进行调度，并负责将线程 的任务映射到各个处理器上 程序可以直接使用系统调用已实现线程，无需实现线程 调度、对CPU资源抢占使用 缺点：内核线程需要内核支持 创建、销毁、调度、维护往往都需要系统调用，代价较高 需要消耗内核资源，不能大量创建 线程调度模型 X对Y是指X task对应Y内核调度单位 N对1模型 N对1模型：线程库有实现用户级线程，内核未实现内核级线程 系统只负责调用进程 线程对系统透明，由进程自身负责调用 此模型中内核没有实现内核级线程，所以内核调度单位就是进程 S1对1模型 1对1模型：线程库未实现用户级线程，内核实现有内核线程 程序（逻辑）层面 创建执行独立task的线程 程序创建的线程直接由内核负责调度 内核（实现）层面 每次创建线程都是调用系统调用创建内核级线程 可视为每个“用户创建的线程”同内核级线程绑定，二者一一 对应 此模型中内核调度单位就是内核级线程 此模型中不存在上述定义的用户级线程，图中Thread实际上 应该就是Kernel Thread，仅拆分出来表示是程序创建的线程 M对N模型 M对N模型：线程库实现有用户级线程，系统也实现有内核级线程 程序（逻辑）层面 创建执行独立task的用户级线程 创建可独立被内核调度的内核级线程 将若干和用户线程同内核线程相关联，即task组总体由内核 负责调度，task组内task由程序自身负责调度 内核（实现）层面 调用系统调用创建内核级线程 内核线程执行指令中包含用户线程创建、调度指令 优点 用户级线程创建、切换、析构等均在用户空间中，依然 廉价，支持大规模用户线程并发 内核级线程作为用户线程在内核中调度、执行的桥梁， 降低整个进程被完全阻塞的风险 此模型中内核调度单位为内核级线程、task单位为用户线程， 二者比例不定 有的说法里面会使用Light Weighted Process表示内核级线程 通用调度算法 耗时相差不大的task队列总是比较好处理，难以调度的task是 耗时相差大 IO任务、计算任务混合 内核调度除考虑任务（线程）外，还会考虑进程因素 Gang Scheduling：尽量将同进程中线程同时调度，而非 随机从多个进程中挑选CPU数量线程调度 Space Sharing：将CPU划分，各进程仅允许占用部分CPU 执行并发 从任务角度，调度需要考虑 Responsiveness Schedule Overload Starvation-Freedom：饥饿避免 Fairness First-In-First-Out先进先出：按task在队列中的顺序依次调用，执行完task再执行下个 task，仅在task结束后才会切换task 优点 最少task切换开销 最大吞吐量（总处理效率） 朴实公平 缺点 平均相应时间高 Shortest task First/Shortest Remained Time task最短耗时task优先：有限调度耗时短task 优点 平均相应时间短：长耗时task不断推移，必然统计出较短 平均响应时间 缺点 不公平，长耗时task难被调度，容易饥饿 频繁task切换，调度额外开销大 Round Robin时间片轮转：给队列中每个task时间片，时间片结束之后task移至 队列末尾，切换到执行下个task 优点 每个task可以得到公平调度 耗时短task即使在耗时长task之后也可以较快得到执行 缺点 task切换引起的调度开销大，需要多次切换task上下文 时间片不好设置 时间片足够小则退化为SFJ 时间片足够大则退化为FIFO 需要知道task（剩余）执行时间 (Weighted) Max-Min Fairness（带权重的）最大最小公平：资源按照需求递增的顺序分配，不存在 需求得到资源超过自身需求，未得到满足得到需求等价分享资源 具体方案 每轮开始将资源按照权重分配 若需求大于被分配资源则推迟执行，进入下轮 若需求小于被分配资源则执行，并将多余资源继续按照权重 分配给无法执行资源 Multi-level Feedback Queue多级反馈队列：监控task处理耗时，若task未用尽分配资源则提高 优先级，否则降低其优先级 具体方案 task、分片时长具有相对应的不同优先级 分片时长越长优先级越低 高级优先级task可以抢占低优先级task 新task位于高优先级task 同一优先级task使用Round Robin （事实上仅有最低优先级task使用Round Robin算法， 其他优先级都是FIFO） 时间片用完后task结束则正常退出系统，否则优先级 下滑一等级 若是主动让出CPU（IO等），则停留在当前优先级或 提升 多核场景 应该为每个CPU分配单独MFQ，同时采用 Affinity Scheduling保证task尽量同一CPU核上执行， 避免CPU cache频繁失效 若共用MFQ，则容易出现 随CPU增长，对MFQ锁争抢严重 task每次执行位于的CPU不同，CPU Cache需要在不同 CPU间转移 同步问题生产者-消费者问题/缓存绑定问题 生产者生成数据放入缓存，消费者从缓存获取、移除、消费数据 ，问题核心在于保证不让生产者在缓存已满时放入数据、不让 消费者在缓存为空时读取数据 若缓存满：生产者者停止工作 若缓存空：消费者停止消费 消费者从缓存中取走数据，通知生产者工作 生产者向缓存中放入数据，通知消费者消费 不完善的解决方案会造成死锁：生产者、消费者均等待对方唤醒 信号量解决方案 mutex信号量：互斥信号量，确保只有一个生产者、消费者 操作缓存区，单一消费者、生产者可省略此信号量 fill_count信号量：已使用缓存区数量 empty_count信号量：空闲缓存区数量 123456789101112131415161718192021semaphore mutex = 1semaphore fill_count = 0semaphore empty_count = BUFFER_SIZEproducer(): while true: item = produce_item() down(empty_count) down(mutex) put_item_into_buffer(item) up(mutex) up(fillcount)consumer(): while true: down(fill_count) down(mutex) item = remove_item_from_buffer() up(mutex) up(empty_count) consume_item(item) 状态监控解决方案123456789101112131415161718192021222324252627282930313233item_count = 0condition fullcondition emptyadd(item): while item_count == BUFFER_SIZE: wait(full) item_count = item_count + 1 put_item_into_buffer(item) if item_count == 1: notify(empty)remove(): while item_count == 0: wait(empty) item_count = item_count - 1 item = remove_item_from_buffer() if item_count == BUFFER_SIZE - 1: notify(full)produer(): while true: item = produce_item() add(item)consumer(): while true: item = remove() consume_item(item) 互斥信号没有保护关键区，监控方法更好 其他 协调生产者、消费者的关闭 可在在队列中放置特殊的值，消费者读到时终止执行，结束 消费者线程 有多个消费者时，消费者读取特殊值之后可将特殊值放回 队列中继续传递，直至关闭所有消费者 哲学家就餐问题 哲学家围坐在圆桌旁，只能吃饭或者思考，每两个哲学家 之间只有一根筷子，只有同时拿到左右两根筷子才能正常吃饭 实际计算机问题中，筷子视为共享资源 服务生 引入服务生判断资源是否能被获取 引入服务生，哲学家必须经过其允许才能拿起筷子 服务生知道有哪些筷子正在被使用，能够判断是否会死锁 资源分级 为资源（筷子）分配偏序关系 约定所有资源都按此偏序获取、相反顺序释放 且保证不会有无关资源同时被同一工作获取 哲学家只能拿左右侧筷子：不会有无关资源被同一工作获取 将筷子按顺序编号：资源分配偏序关系 哲学家只能先拿左右筷子中编号较小者 哲学家需要先放下筷子中编号较大者 最实用的解法：为锁指定常量分级，强制获取顺序的顺序 策略不总是实用的，尤其是所需资源列表事先不知道，可能需要 先释放已获取资源、获取低编号资源、重新获取资源，效率不高 Chandy/Misra解法 标记资源，保留未使用资源、交出已使用资源，初始所以资源 已使用 每根筷子分为干净、脏，最初所有筷子都脏 对每对竞争同一筷子的哲学家，新拿筷子给编号较低者 当哲学家需要某筷子时 向其竞争对手发送请求 拥有筷子的哲学家收到请求 若筷子干净则保留 否则擦干净交出 哲学家吃完东西后，筷子变脏 若有哲学家之前请求过该筷子，擦干净交出 有很大并行性，适合任意大问题 读者-写者问题 多线程同时访问共享内存地址，线程写入时其他线程不能读取、 写入，多个线程可以同时读取 一般使用readers-writer lock解决问题 读者优先 若共享内存被读取，其他读者可以立即、同时读取 若一直有读者开始读取，则写者会一直被插队、无法修改 写者优先 如果写者在排队，应该尽快写入共享内存 若一直有写者准备写入，则读者会一直被插队、无法读取 限定时间 共享内存区的锁定权要在限定时间内结束 能避免读者、写者一直排队 熟睡的理发师问题 理发店只有一名理发师、一张理发时坐的椅子、若干普通椅子 供顾客等待 没有顾客时理发师在理发椅子上睡觉，顾客到达后离开、 或者叫醒理发师 有顾客时，理发师为别人立法，顾客达到后若有空闲普通 椅子则坐下休息、否则离开 理完发后，任选顾客开始理发 理发师等待顾客、顾客等待理发师，造成死锁 有顾客不按顺序等待，让某些顾客永远不能理发 3信标解决1234567891011121314151617181920212223242526272829semaphore customer = 0semaphore barber = 0semaphore mutex = 1empty_chairs = BUFFER_SIZEbarber(): while true: if empty_chairs == BUFFER_SIZE: sleep() down(mutex) item = get_customer_from_chairs() empty_chairs += 1 up(mutex) down(barber) cut_hair(item) up(barber)customer(): while true: down(mutex) if empty_chairs &gt; 0: empty_chairs -= 1 else: wait() or leave() up(mutex) 三个烟鬼问题 香烟需要：烟草、卷烟纸、火柴，三个烟鬼分别有无限各一种， 不吸烟协调人会随机安排两个烟鬼各拿出一份材料放在桌上， 另外一个烟鬼拿到材料卷烟、抽 桌上空了后，协调人就随机要求烟鬼拿出材料 烟鬼只会在抽完手中烟后才会卷另一只 若烟草、卷烟纸在桌上，有火柴的烟鬼在吸烟，直到该烟鬼 吸完烟拿走桌上材料才会继续 问题模拟程序中4种角色，展示信标方法作用有限","link":"/CS/Parallel/implementation.html"},{"title":"C++ 概述","text":"C++ 程序结构 C++ 是面向对象和过程的范式的集合 Comment注释：被编译器忽略的文本 /**/：允许多行注释 //：单行注释 Library库：提前编写的能执行有用操作工具集合 库引入 #include &lt;&gt;：头文件是C++标准中的系统库 #include &quot;.h&quot;：其他库、自行编写的头文件 Namespace命名空间：被切分为代码段的结构，为确保定义在大系统中各部分 程序的元素名称（如：变量名、函数名等）不会相互混淆 std：C++标准库的命名空间 需要告诉编译器定义所属的命名空间才能引用头文件中的名称 函数为方便理解，大多数程序被划分为几个较小的易于理解的函数 Prototype：函数原型，函数定义的首行加上分号结尾组成 主程序：每个C++程序必须有main函数，指明程序计算 的开始点，main函数结束时，程序执行也随之结束 Variable变量：一个命名的、能够存储特定类型值的一块内存区域 在变量生存期内，所有变量的名字、类型都是不改变的， 而变量的值一般会随着程序运行发生改变 可以将变量视为盒子 变量名：作为和盒子的标签在盒子外 变量值：在盒子里物品 C++/C中变量的解释是由变量类型而不是值决定， 存储值一样，可能会有不同的处理方式 引用、指针都存储地址，但是引用可以直接作为变量使用， 指针则需要解引用 initializer：初始化，初始值作为声明的一部分 变量类型、修饰符参见cs_cppc/basics/mem_ctl Scope变量作用域 Local Variable局部变量：声明在函数体内，作用域可以扩展到其 声明所在块 函数被调用时：为每个局部变量分配在整个函数调用时期 的存储空间 函数返回时：所有局部变量消亡 局部变量一般存储在函数栈中 Global Variable全局变量：声明在函数定义外，作用域为其声明所在文件 生命期为程序运行的整个运行期，可用于存储函数调用的值 可以被程序中任意函数操作，难以避免函数间相互干扰 除声明全局常量外，不采用全局变量易于管理程序 全局变量一般存储在静态区中 Declare声明：主要功能是将变量的名字和变量包含值类型相关联 在使用变量之前必须声明 变量声明在程序中的位置决定了变量的scope 事实上，函数、类等都可以提前声明，有些时候必须如此，以 使用forward reference（前向引用，定义之前声明指向其的 指针） Identifier标识符：变量、函数、类型、常量等名字的统称 必须以字母、_开始 所有字符必须是字母、数字、_，不允许空格或其他特殊字符 不能包含保留字 标识符中大小写字母是不同的 标识符可以取任意长度，但是C++编译器不会考虑任何超过31个 字符的两个名字是否相同 Shadowing遮蔽：程序代码内层块中变量隐藏外层块中同名变量的行为 隐式类型转换数值类型转换 提升型转换：通常不会造成数值差异 小整数char、short转换到int float转换到double 可能存在转换误差的转换 负数转换为无符号类型：二进制位不变，即为负数对应补码 正数 其他类型转换为bool类型 浮点数转换为整数：截断，若出现数值溢出，则出现未定义 行为 指针类型转换 空指针void *、任意指针类型类型之间相互转换 衍生类指针转换为基类指针，同时不改变const、volatile 属性 C风格数组隐式把数组转换为指向第一个元素的指针 容易出现错误123char * s = &quot;Help&quot; + 3; # ”Help&quot;被转换为指向数组指针，向后移3位 # `s`指向最后元素`p` 强制类型转换 上行转换：派生类指针、引用转换为基类表示 下行转换：基类指针、引用转化为派生类表示 const_castconst_cast：去掉原有类型的const、volatile属性，将常量 指针、引用转换为非常量 常量指针转化为非常量指针，仍来指向原来对象 常量引用转换为非常量引用，仍然指向原来对象 一般用于修改指针，如const char *p 要求期望去常量目标非常量，否则为未定义行为 1234567891011int ary[4] = {1, 2, 3, 4}; // 去常量化目标非常量const int * c_ptr = ary; // 常量化数组指针 // 不能直接数组中值int * ptr = const_cast&lt;int*&gt;(c_ptr); // 去`const`，强制转换为非常量化指针 // 可以修过数组中值for(int i = 0; i &lt; 4; i++){ ptr[i] += 1;} 未定义行例 堆区常量 123456789101112131415161718int con_cast(){ const int * c_val_ptr = new const int(1); // 常量值，非常量指针 int vec_before[*c_val_ptr]; // 常量声明数组 int &amp; ptr_val = const_cast&lt;int &amp;&gt;(*c_val_ptr); ptr_val += 1; // 可以正常给值加1 // 未定义行为？堆区不存在常量？ int vec_after[*c_val_ptr]; // 常量生命数组 cout &lt;&lt; sizeof(vec_before) &lt;&lt; endl &lt;&lt; sizeof(vec_after) &lt;&lt; after; // 二者长度均为`8`，即常量在`vec_before`创建前已处理 cout &lt;&lt; *c_val_ptr &lt;&lt; endl &lt;&lt; ptr_val &lt;&lt; endl &lt;&lt; c_val_ptr &lt;&lt; endl &lt;&lt; &amp;ptr_val; // 地址、值均相同} 栈区常量 1234567891011121314151617int con_cast(){ const int c_val= 1; // 常量值 int vec_before[c_val]; // 常量声明数组 int &amp; ptr_val = const_cast&lt;int &amp;&gt;(&amp;c_val); ptr_val += 1; // 可以正常给值加1 int vec_after[c_val]; // 常量生命数组 cout &lt;&lt; sizeof(vec_before) &lt;&lt; endl &lt;&lt; sizeof(vec_after) &lt;&lt; after; // 二者长度均为`4`，即常量值已处理，但没有改变 cout &lt;&lt; c_val &lt;&lt; endl &lt;&lt; ptr_val &lt;&lt; endl &lt;&lt; &amp;c_val&lt;&lt; endl &lt;&lt; &amp;ptr_val; // 地址保持相同、但二者值不同} 以上代码在g++4.8.5中测试 static_caststatic_cast：静态类型转换，无条件转换 类层次中基类、派生类之间指针、引用转换 上行转换：派生类完全包含基类所有成员，安全 下行转换：派生类包含独有成员，没有动态类型检查，对象 为派生类实例时转换不安全 基类、派生类之间转换建议使用dynamic_cast 基本类型转换：安全性需要开发者维护 int、char、enum、float之间相互转换 空指针转换为目标类型指针：不安全 任何类型表达式转换为void类型 不能进行无关类型指针（无继承关系、float与int等）之间 转换，而C风格强转可以 不能转换掉原有类型的const、volatile、__unaligned 属性 静态是相对于动态而言，只在编译时检查，编译时已经确定转换 方式，没有运行时类型检查保证转换安全性 123456789101112float f_pi = 3.141592fint i_pi = static_cast&lt;int&gt;(f_pi)Sub sub; // 衍生类Base * base_ptr = static_cast&lt;Base*&gt;(&amp;sub); // 上行转换，安全Base base; // 基类sub * sub_ptr = static_cast&lt;Sub*&gt;(&amp;base); // 下行转换，不安全 和C风格强转效果基本一致（使用范围较小），同样没有运行时 类型检查保证转换安全性，有安全隐患 C++中所有隐式转换都是使用static_cast实现 dynamic_castdynamic_cast：指针、引用动态类型转换，有条件转换 安全的基类、派生类之间转换 转型对象为指针：转型失败返回NULL 转型对象为引用：转型失败抛出异常 动用runtime type information进行类型安全检查，会有效率 损失 依赖虚函数表将基类指针转换为子类指针？？？ 检查对象实例类型，保证转换是安全的，不会出现 子类指针指向父类对象 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Base{public: void print(){ cout &lt;&lt; &quot;i' base&quot; &lt;&lt; endl; } virtual void virtual_foo() {};}class Sub: public Base{public: void print(){ cout &lt;&lt; &quot;i'm sub&quot; &lt;&lt; endl; } virtual void virtual_foo();}int main(){ cout &lt;&lt; &quot;Sub -&gt; Base&quot; &lt;&lt; endl; Sub * sub = new Sub(); sub -&gt; print(); // 打印：`i'm sub` Base * sub2base = dynamic_cast&lt;Base*&gt;(sub); if (sub2base != NULL)l{ sub2base-&gt;print(); // 打印：`i'm base` } cout &lt;&lt; &quot;sub2base val: &quot; &lt;&lt; sub2base &lt;&lt; endl; cout &lt;&lt; &quot;Base -&gt; Sub&quot; &lt;&lt; endl; Base * base = new Base(); base-&gt;print(); // 打印：`i'm base` Sub * base2sub = dynamic&lt;Sub*&gt;(base); if (base2sub != NULL){ base2sub -&gt; print(); // 未打印 } count &lt;&lt; &quot;base2sub val: &quot; &lt;&lt; base2sub &lt;&lt; endl; delete sub; delete base; return 0;} 涉及面向对象的多态性、程序运行时的状态，主要是用于虚类 类型上行转换 同编译器的属性设置有关，所以不能完全使用C语言的强制转换 替代，常用、不可缺少 reinterpret_castreinterpret_cast：仅仅是重新解释给出对象的比特模型 ，没有对值进行二进制转换 用于任意指针、引用之间的转换 指针、足够大的整数（无符号）之间的转换 123456int * ptr = new int(233);uint32_t ptr_addr = reinterpret_cast&lt;uint32_t&gt;(ptr);count &lt;&lt; &quot;ptr addr: &quot; &lt;&lt; hex &lt;&lt; ptr &lt;&lt; endl &lt;&lt; &quot;ptr_add val: &quot; &lt;&lt; hex &lt;&lt; ptr_addr &lt;&lt; endl; // 二者输出值相同delete ptr; 处理无关类型转换，通常为位运算提供较低层次重新解释 难以保证移植性 C风格12345678910Typename b = (Typename) a;float b = 1.0f;int c_i = (int)b;int &amp; c_j = (int&amp;)b; // C风格int cpp_i = static_cast&lt;int&gt;(b);int &amp; j = reinterpret_cast&lt;int&amp;&gt;(b); // 等价C++风格 没有运行时类型检查保证转换安全性，可能有安全隐患 Data Type数据类型：从形式上看，数据类型有两个属性定义 domain：值集，该类型值的集合 set of operation：操作集，定义类型的行为 C++每个数据值都有其相应数据类型 Primitive Type：基本类型，类型系统整体的建筑块 整型 浮点型 布尔型 字符 枚举类型 IntegerC++定义了3种整数类型：short、int、long 由值域大小相互区别 值域 C++中没有指定3种类型确切值域，其取决于机器、编译器，但是 设计者可以更确切的定义各整形值域 short、int、long类型内存不减 int类型最大值至少$2^{15}-1$ long类型最大值至少$2^{31}-1$ 一般的 short：2bytes int：4bytes long/long long：8bytes 若希望明确值域，尝试&lt;cstdint&gt;中自定义类型 unsigned 各整形均可以在其类型之前加上关键字unsigned，构建新的 非负整形 无符号整型可以提供有符号整型两倍正值域 16进制、8进制等都是无符号输出格式，有符号整形会被 隐式转换位无符号（若传入） 表示 整形常量一般写成十进制数字 数字以0开始：编译器将其视为八进制数字 数字以0x开始：编译器将其视为16进制数字 数字L结尾：显式指明整数常量的类型为long（表达式中） 数字U结尾：整形常数被认为时无符号整数（表达式中） Float-PointC++中定义了3种浮点类型：float、double、long double 值域C++同样没由指定这些类型的确切表示 float、double、long double占用内存不减、精度 不减 表示 通常使用带有小数点的十进制数字 支持科学计数法风格：浮点数乘以十的整数幂 Bool布尔类型：具有合法常量值true、false的数据类型 CharC++中表示字符的预定义基本类型：char C++标准库定义wchar_t类型表示宽字符以扩展ASCII编码范围 值域出现在屏幕、键盘上的字母、数字、空格、标点、回车等字符集合 在机器内部，这些字符被表示成计算机赋给每个字符的数字代码 多数C++实现中，表示字符的代码系统为ASCII 表示 ''：单引号括起的一个字符表示字符常量 escape sequence：转移序列，以\\开始的多个字符表示 特殊字符 对比整形 整形没有1byte大小类型，很多情况下使用char类型存储 整数值以节省空间 但C/C++某些[unsigned ]char、整形处理有区别 输入、输出 对[unsigned ]char类型总是输出字符，而不是数字串 输出流：关于整形的流操纵符对[unsigned ]char无效， 即使是无符号类型 格式化输出：指定输出格式得到数字串，包含隐式类型转换 String字符串：字符序列 C风格的字符串就是以\\0结尾的字符数组 \\0：null character，空字符，对应ASCII码为0 表示 &quot;&quot;：双引号括起的字符序列表示字符串常量 允许使用转移序列表示字符串中特殊字符 两个、两个以上字符串连续出现在程序中，编译器会自动将其 连接（即可以将字符串分行书写） Enumerated枚举类型：通过列举值域中元素定义的新的数据类型 1enum typename { namelist }; 值域 默认的，编译器按照常量名顺序，从0开始给每个常量赋值 允许给每个枚举类型常量显式的赋值 若只给部分常量名赋值，则编译器自动给未赋值常量赋最后一个 常量值后继整数值 复合类型基于已存在的类型创建的新类型 表达式C++中表达式由项、操作符构成 term：项，代表单个数据的值，必须是常量、变量、函数调用 operator：操作符，代表计算操作的字符（短字符序列） binary operator：二元操作符，要求两个操作数 unary operator：一元操作符，要求一个操作数 full expression：完整表达式，不是其他表达式子表达式 的表达式 表达式求值顺序C++没有规定表达式求值顺序（表达式求值顺序是指CPU计算 表达式的顺序，不同于优先级、结合律） sequenced before：若A按顺序先于B，A中任何计算都 先于B中任何计算 sequenced after：若A按顺序后于B，A中任何计算都晚于 B中任何计算 unsequenced：若A与B无顺序，则A、B中计算发生顺序 不确定，并且可能交叉 indeterminately sequenced：若A与B顺序不确定，则 A、B计算发生顺序不确定，但不能交叉 对无顺序、顺序不确定求值，不要求两次不同求值使用相同顺序 完整表达式的求值、副作用先于下个完整表达式的求值、 副作用 表达式中不同子表达式的求值无顺序 除非特殊说明，运算符的不同操作数求值是无顺序的 运算操作数值计算先于运算符结果值计算 对同一简单对象 两个不同副作用无顺序，则为无定义行为 副作用与需要此对象值的计算无顺序，则为无定义行为 123int i = 0;i++ + i++; // 两`i++`对i`均副作用、无顺序，未定义行为i + i++; // `i++`副作用、`+`计算无顺序，未定义行为 函数调用时：不仅限于显示函数调用，包括运算符重载、构造、 析构、类型转换函数 实参求值、副作用先于函数体任何语句、表达式求值 函数不同实参求值、副作用无顺序 123int func(int, int);int i = 0;func(i++, i++); // 参数计算`i++`对`i`均有副作用，无定义行为 主调函数中任何既不先于、也不后于被调函数的求值，其 与被调用函数都是顺序未指定，即主调函数中任何求值 与被掉函数不交叉 1234int foo(int);int i = 0, j = 0, k = 0;(i++ + k) + foo(j++);(i++ + k) + foo(i++); 不同形参初始化是顺序未指定 自增、自减 后缀形式：i++、i-- 值计算先于对变量的修改 与其顺序未指定函数调用不能插入值计算、变量修改 之间 前缀形式：++i、--i 返回被更新之后的操作数（左值） i非布尔值时，++i、--i等价于i+=1、i-=1 new 内存分配函数与初始化参数求值顺序未指定 新建对象初始化先于new表达式计算 逻辑与&amp;&amp;、或||为短路求值 左操作数计算先于右操作数计算 左操作数为false、true时，右操作数不会被求值 ?:中三个操作数只有两个会被求值 第一个操作数求值先于后两个操作数求值 第一个操作数值为true时，第二个操作数被求值，否则 第三个操作数被求值 赋值运算符= 左、右操作数求值先于赋值操作 赋值操作先于赋值表达式值计算 赋值表达式返回其左操作数的左值，此时左操作数必然被 赋值 复合赋值运算符e1 op= e2：+=、-=等 求值包括e1 op e2、结果赋给e1、返回e1 任何函数调用不能插入以上步骤 逗号,运算符（注意区分逗号分隔符） 左操作数值被丢弃 左操作数值计算、副作用先于右操作数值计算、副作用 被重载后的逗号运算符将生成函数调用，对操作数求值遵循 函数实参求值顺序 序列初始化：对{}存在的多个初始化参数求值 初始化参数值计算、副作用先于被逗号分隔的后初始化值 计算、副作用 即使初始化参数引起函数调用，列表每个值作为函数参数， 求值顺序仍然被保留 优先级、结合律 precedence：优先级，默认情况下（无括号）操作符在运算中 结合的方法 associativity：结合律，相同优先级的运算符运算顺序， 也即左右操作数的运算顺序 left-associative：左结合的，优先计算操作符左侧 表达式，大部分操作符时左结合的 right-assiciative：右结合的 优先级递减 结合性 ()、[]、-&gt;、. 左 一元操作符：-、+、--、++、!、&amp;、*、~、(类型)、sizeof 右 *、/、% 左 +、- 左 &gt;&gt;、&lt;&lt;（右、左移位） 左 &lt;、&lt;=、&gt;、&gt;= 左 ==、!= 左 &amp; 左 ^ 左 ` ` 左 &amp;&amp; 左 ` ` 左 ?: 右 =、op= 右 操作符只是语言的语法，其行为只是人为赋予的规则，其行为 可能符合逻辑，也可能不符合逻辑 混合类型对于具有不同操作数的操作符，编译器会将操作数转化为其中精度 最高的类型，计算结果也为精度最高的类型，保证计算结果尽可能 精确 整数除法、求余 两个整数除法运算：结果为整数，余数（小数）被舍去 含负数操作数的除法、求余：依赖硬件特征 求余一般返回同余正值 Type Cast（值/静态）类型转换：将一种类型明确的转换为另一种类型 1234type(expr) # C++风格转换(type)expr # C风格类型转换 转换目标类型精度增加不丢失信息，否则可能会丢失信息 符号整形转换无符号整形：依赖硬件特征，一般 符号位置于最高位 数值位根据精度 同精度：不变，即包括符号位在内无改变 低精度向高精度：高位用符号位补齐 高精度向低精度：截断、保留低位 无符号整形转符号整形 同精度、高精度向低精度：截断、保留低位 低精度向高精度：高位补0 即：有符号转为其他类型（有符号、无符号），优先保留符号位 赋值操作C++中，对变量的赋值是一种内置的表达式结构 赋值操作符=要求其左操作数必须是可变的，通常是变量名 首先计算赋值操作符右边表达式值，再赋给左边的变量 右操作数可能需要进行类型转换以使其与左操作数的类型 相匹配 赋值操作默认（未重载）是通过将源对象所有变量域（栈中 数据），复制到目标对象相应变量域实现的 返回值C++赋值表达式返回右边表达式的值 可以被组合进更大表达式中（但会影响阅读） multiple assignment：多重赋值，可以方便给多个变量赋 相同值 Shorthand Assignment将赋值操作符、二元操作符相结合产生形式 123var op= expr;var = var op expr; // 等价 自增、自减对变量进行+1、-1的更高级别的缩写形式 1234567891011121314x++; // 后缀形式 // 自增前将其原始值返回给临近表达式++x; // 前缀形式 // 自增后将新值返回给临近表达式x += 1;x = x+1; // 等价y--;--y;y -= 1;y = y-1; // 等价 布尔运算Relational Operator关系操作符 ==：等于，容易犯错 !=：不等于 &gt;：大于 &lt;：小于 &gt;=：大于等于 &lt;=：小于等于 Logical Operator逻辑操作符：采用布尔类型操作数，组合形成新的布尔值 !：逻辑非 &amp;&amp;：逻辑与 ||：逻辑或 Short-Circuit Evaluation短路求值：得到结果时就立刻结束计算表达式 依赖于：3种逻辑操作符优先级均不同，逻辑运算表达式总是 从左到右计算的 ?:三目操作符，需要3个操作数 123(condition) ? expr_1 : expr_2 // `()`不必须，只是用于强调边界 // 首先计算`condition`，条件为`true`则返回`expr_1` Bitwise Operator位运算符：读取任意标量类型值，将其翻译成与底层硬件相应的 比特序列表示 &amp;、|、^：位逻辑与、或、异或 ~：位逻辑非 &gt;&gt;、&lt;&lt;：右、左移位 无符号数：字尾被移动比特数消失，另一端补0 有符号数：行为依赖于硬件特征，一般保证乘除特性 右移：补1 左移：补0 语句 simple statement：简单语句，执行某些动作 表达式加分号组成 control statement：控制语句，控制程序流程 控制语句典型地应用在一条单一语句中 Block块：{}括起指明一组语句序列是连贯单元的一部分 编译器会将整个块当作一条语句对待，也被称为 compound statement 常用于使用特定控制语句控制一组语句 Conditional Execution条件执行：根据检测条件控制程序后续执行 if12if (condition) statementif (condition) statement else statement if中控制语句可以是一条简单语句，也可以是一个语句块 switch12345678910111213switch (e){ // `e`：*control expression* case c1: //`c1`必须是常量标量 statements break; case c2: statements break; default: statements break;} 程序计算控制表达式e的值，将结果同c1、c2相比较 case后的常量必须是标量类型，即底层采用整数表示 的类型，如：整形、字符、枚举类型 如果常量同控制表达式值相匹配，则跳转至相应case子句执行 执行到子句中break时跳出switch语句 若子句中无break，则接着执行之后case子句中语句， 直到遇到break/return跳出switch语句，这会带来很多 问题，除1234case 1:case 2: statement break; default可选，执行没有和控制表达式匹配值的操作 除非确定列举了所有可能情况，否则增加default子句是 好习惯 Iterative Statement迭代语句：以循环的方式多次执行程序中的一部分 while一般模式123while (condition-expression){ statements} 首先查看条件表达式值 若条件表达式值为true，整个循环体被执行，然后返回到循环 开始检查条件表达式值 若条件表达式值为false，则循环终止 每个循环周期，包括第一次循环，条件表达式都会被测试，且 仅在循环开始进行，循环中间条件表达式值改变不会被注意 Read-util-Sentinel Pattern读直到信号量模式：使用break语句在循环中结束最内层循环 12345while(true){ Prompt user and read in a value if (value == sentinel) { break; } Process the data value} for以特定的循环次数重复执行某个操作 基于条件的循环 1234567891011121314151617// 一般模式for (init; test; step){ statements}init;while(test){ statements step;} // 二者等价// 常用模式for(int var=start; var &lt;= finish; var++){ // `var`：*index variable* statement} // 循环`finish - start`次 range-based for loop：基于范围的循环，C++11开始支持 12345678910111213for(type var: collection){ statements}// `foreach.h`接口中的定义宏，提供类似功能foreach(type var in collection){}// C++编译器通过迭代器，将基于范围的循环转换为传统循环for(ctype::iterator it = collection.begin()); it != collection.end(); it++){ // `ctype`：集合类型} 编译、汇编、执行步骤Preprocess预处理：生成.i预处理文件 宏替换 注释的消除 寻找相关头文件/接口：除默认搜索路径，还可以通过环境变量设置 C_INCLUDE_PATH；C头文件搜索路径 CPLUS_INCLUDE_PATH：C++头文件搜索路径 CPATH：C/C++头文件搜索路径 12$ g++ -E src.cpp &gt; src.i // 激活预处理，输出重定向到文件中 Compile编译：将预处理后的文件编译为汇编语言，生成汇编文件.s 编译单位为文件 1$ g++ -S src.i -o src.s Assemble汇编：生成目标机器代码，二进制.o中间目标文件 .o通常仅解析了文件内部变量、函数，对于引用变量函数 还未解析，需要将其他目标文件引入 1$ g++ -C src.s -o src.o Windows下生成.obj文件 Link链接：链接目标代码，生成可执行程序 gcc通过调用ld进行链接 主要是链接函数、全局变量 链接器关注/链接二进制.o中间目标文件 Library File：若源文件太多，编译生成的中间目标文件 过多，把中间目标文件打包得到.lib/.a文件 1$ g++ src.o -o a.out 执行序列点 对C/C++表达式，执行表达式有两个类型动作 计算某个值 产生副作用：访问volatile对象、原子同步、修改文件","link":"/C-C/abstract.html"},{"title":"类","text":"class类：包含值、相应操作集的模板，将相关信息片段组织成复合值， 使得可以整体对其进行操作 概念实体 object：对象，属于一个类的所有值 instance：实例，单个对象 field/instance variable：域/实例变量，类的分量 method：应用于类实例的操作 C++中方法的使用和传统函数类似，新名称只是为强调其同 所属的类紧密联系 传统函数称为free function，不被约束于特定类 权限 private：私有，声明在private section中的域仅对该类 本身可见（默认） public：公有，声明在public section中的域对所有用户 可见 现代面向对编程不鼓励在类中声明public实例变量 protected：受限，声明在protected section中的成员对 所有子类都可以访问，但用户不能访问 类&amp;结构体C++中：结构类型和类基本上以同样方式实现，类是struct的扩展 结构体：默认访问权限是public，类默认为private 类：允许高级继承、方法，成员默认private 对一般成员变量，类和结构体在内存布局上完全一致，如： 顺序、内存布局 消息传递模型面向对象程序设计中，对象间通过信息发送、请求实现对象间通信， 将传递的这些信息称为消息 1receiver.name(arguments) 对象间消息发通常理解为一个对象调用另一个对象的方法 sender：发送方，初始化方法的对象 receiver：接收方，消息的目标对象 接口实现分离 C++中类接口、实现相分离时，类自身定义仅存在与其.h文件 实现放在.cpp中作为独立方法定义，需要以类名作为限定符、 ::作为分隔的方式表明自己所属的类 类继承123class subclass: public superclass{ ...code...} 子类subclass继承父类superclass所有public、 protected成员，private成员仍然保持私有特性 可以继承模板类 子类甚至可以不包含任何代码，仅为简化类型名12class StringMap: public Map&lt;string, string&gt;{} // 创建不包含代码的子类，简化代码 子类局限子类对象是其所属父类的实例，但是有其局限 将子类对象赋值给父类对象会导致子类特有实例变量值被丢弃 （因为父类对象在栈中空间较小） 常用解决方法是使用指针，指针变量大小相同 但使用指针会使内存管理变得复杂 为类定义析构函数可以管理内存，但是指针越界时，不能 保证析构函数会在合适的时间调用 最好方法是避免使用类继承，并创建独立的类管理自身堆内存， 否则 完全禁止拷贝：定义私有拷贝构造函数、重载赋值操作符， 但这会使得对象难以嵌入大型数据结构 执行深拷贝：用户需要承担内存管理，重载拷贝构造函数、 重载赋值操作符 Multiple Inheritance多重继承：类可以继承自多个父类 多重继承在实际编程过程中可能导致程序复杂、模糊不清 多重继承的多个父类可能拥有多个相同方法名、数据域名 C++中单继承已经足够复杂，最好避免使用多重继承 finalfinal：指定虚函数不能被派生类覆盖、类不能被继承 语法 虚函数：在声明符之后 类：紧跟类名后 1234567struct A final{}struct B{ virtual void foo();}struct C: B{ void foo() final;} overrideoverride：指定派生类虚方法覆盖基类虚方法 语法：在成员函数声明之后 （其他情况下override甚至不是关键字） 用途：有助于防止代码出现意外继承行为 即不是强制性关键字，是辅助性、可选 非虚函数可以通过类型转换调用基类方法，不算覆盖？？？ Iterator迭代器：指向集合中一个特定元素，每次可以通过单步递进方式访问 其他元素 迭代器使用*操作查找其指向的值 迭代器层次结构 InputIterator：允许读值 OutputIterator：允许给解析的迭代器赋新值 ForwardItertor：结合InputIterator、OutputIterator ，允许读写值 BidirectionIterator：在ForwardIterator基础上允许向后 迭代，增加--操作符 RandomAccessIterator：在BidirectionIterator基础上 允许向前、向后移动任意元素，包含全部关系符 指针作为迭代器 指针类型已经实现了RandomAccesIterator提供的所有操作符 ，所以可以使用指针作为迭代器 很多实现已经将iterator作为类中嵌套迭代器的类型，要用 typedef重命名指针类型为iterator 1typedef ValueType * iterator; 如：编译器内部利用迭代器，将基于范围for展开 编译器内部iterator类型指针变量参见 cppc/basics/intro 类方法Constructor构造函数：创建对象 构造函数名与类名完全一样 构造函数无法被子类继承，只能在初始化列表中调用 缺省编译器调用父类默认构造函数 若没有构造函数，则必须显式在初始化列表中初始化 执行阶段 初始化阶段：初始化列表 调用父类构造函数初始化父类成员变量 缺省调用默认构造函数 若父类没有默认构造函数，必须在初始化列表中显式 调用构造函数 初始化类自身数据域 对一般类型，缺省类似于普通未赋值初始化 对类类型成员变量，缺省没有显式初始化则调用默认 构造函数 计算阶段：执行构造函数体 在函数体中执行的都是赋值，不是初始化 Initializer List初始化列表：初始化父类、自身数据域 位于的构造函数体花括号前、参数列表之后，用:和参数列表 分隔 初始化父类 父类名后用括号括起来的参数列表，参数列表必须和父类 某一构造函数原型相匹配 1Foo(string name, int id):(name, id){}; 父类数据域后用括号括起的该数据域的初始化值（此方法 也可以用于初始化类自身数据域） 1Foo(string name, int id): name(name), id(id){}; 调用父类构造函数 1Derived(string name, int id):Base(name, id){}; 初始化自身数据域 类类型成员变量最好使用初始化列表初始化，可以避免 构造函数初始化阶段调用成员变量默认构造函数 必须放在初始化列表中成员变量 常量成员：常量只能初始化，不能赋值 引用类型：引用必须在定义时初始化，不能重新赋值 没有默认构造函数的类类型 成员变量按照其在类中声明顺序初始化，而不是在初始化 列表中的顺序 为避免因成员变量初始化依赖导致的未定义，应该按照成员 变量声明的顺序初始化 Default Constructor默认构造函数：没有参数的构造函数 若类没有默认构造函数，编译器会自行定义 Copy Constructor1Foo(const Foo &amp;f){}; 拷贝构造函数：使用同类实例初始化创建新对象 用途 复制对象 传值调用时，隐式调用拷贝构造函数构造新对象传参 类中没有定义拷贝构造函数时，编译器会自行定义一个 若类中有指针变量、并有动态内存分配，则必须定义拷贝 构造函数 explicitepxplicit关键字：声明为explicit构造函数不能在隐式转换中 使用 用途 希望函数参数只能是给定类型，可以禁止隐式类型转换 Destructor析构函数：类的对象消亡时，析构函数被自动调用 析构函数可以完成各种清理操作 最重要：释放对象所创建的所有堆内存 关闭对象打开的任何文件 析构函数名称：类名前加上~ 析构函数特点 没有返回类型 不能重载 每个类只有一个无参的析构函数 良好设计的C++应用中，每个类都需要堆其对内存负责 Operator Overloading操作符重载：扩展标准操作符以适应新的数据类型 编译器遇到操作符时，会根据操作符操作数的类型确定其 操作语义 重载操作符函数名由关键字operator后跟操作符构成 操作符的左右操作数类型、传值方式 操作符返回值123ostream &amp; operator&lt;&lt;(ostream &amp; os, Point pt); // 流对象不能拷贝，必须引用传递 // 返回依然是流引用 有些类型根本没有定义过某些操作符，虽然实际上是扩展该类型 操作符，但是也成为重载操作符 overload：重载，使用相同名字的不同版本类方法 重载方式C++提供两种机制用以重载内置操作符使得可以适用于新定义类 类方法：在类中用方法重载操作符 1234567891011// .hClass Point{Public: bool operator==(Point rhs); // 类中声明操作符重载方法}// .cbool Point::operator==(Point rhs){ // 实现中限定为`Point`方法} 左操作数为该类型对象（声明、实现省略） 右操作数作为形参传递 编译器把左操作数视为接收者，将右操作数作为形参传递 free function：在类外使用自由函数重载定义操作符 123456// .hbool operator==(Point pt1, Point pt2);// .cbool operator==(Point pt1, Point pt2){} 二元操作符的两个操作数都作为形参传递 操作符重载自由函数一般需要声明为类的友元函数，使其 能够访问类的私有实例变量 ++/--重载++/--时，必须指明是重载前缀还是后缀形式 额外传入无意义整形参数说明重载后缀形式 常用于枚举类型，方便遍历枚举类型 1234567891011121314Direction operator++(Direction &amp; dir){ // 重载前缀形式 dir = Direction(dir+1); return dir;}Direction operator++(Direction &amp; dir, int){ // 重载后缀形式 // 这也说明，C++中若不需要使用形参值，可以省略形参名， // 即使是在函数实现中 Direction old = dir; dir = Direction(dir + 1); return old;} = 赋值操作符被定义为返回其左值，所以重载赋值操作符时注意 返回值 赋值操作符开头往往检查左、右操作数地址是否一样 避免不必要拷贝操作、逻辑错误 () 重载函数调用操作符()将可以像函数一样调用对象 1234567891011class AddFunction{Public: AddFunction(int k){ this-&gt;k = k; } int operator(int x){ return x+k; }private: int k;} 重载此方法类称为function class（函数类），其实例称为 function object/functor（函数对象、函数子） const方法C++允许在方法参数表后增加关键字const指定方法，声明 其不改变其对象的状态 在接口原型、实现中都应该使用const关键字约束 1234567// .hint size() const;//.cppint CharStack::size() const{ return count;} Friend友元：允许访问类中私有实例变量的元素（不是类方法） 友元函数：允许访问类中私有变量的自由函数 12345friend prototype; // 在类定义中声明友元函数class Point{ friend bool operator==(Point p1, Point p2);} 友元类：允许访问类中私有实例变量的类 12friend class cls_name; // 在类中定义中声明友元类 友元类的声明不是双向的，需要两个类都显式声明另一个类 为友元类，才能相互对方私有变量 典型方法 Accessor/Getter：访问器/读取器：获取实例变量值的函数 为方便，读取器的命名通常以get为前缀 Mutator/Setter：设值方法/设值器，为特定实例变量 设置值的方法 为方便，设置器的命名通常以set为前缀 将实例变量设为私有就是为了阻止用户不受限制访问变量， 所以读取器的设置更为常见 事实上，immutable设计风格将类设置为完全不可变 类内存结构 类的方法地址不会存储在实例的内存空间中 非虚函数 编译时 编译器根据变量类型（指针、引用类型）在调用函数 处写入类方法的地址 编译时即确定执行的函数 可以认为是普通函数，只是默认包含参数this指针 运行时 访问方法相应内存地址，传入this指针调用方法 (Pure)Virtual Method 虚方法/虚函数：virtual修饰的方法，基类中有定义 纯虚方法：没有函数体的虚函数，基类中无定义，实现只能由 其子类提供 派生类中覆盖方法总为虚方法，无论是否有virtual关键字 建议后代虚函数加上virtual以提升可读性 1234virtual double getpay(); // `virtual`：普通虚函数virtual double getPay() = 0; // `=0`：纯虚函数，没有函数体 编译时 编译器根据类的声明创建虚表，每个类维护一张虚表 对象被构造时，虚表地址在实例内存的首个字中 编译器在调用函数处不直接写入函数地址（因为不确定 调用的函数） 执行时 从对象首读取虚表，在虚表中查询需要执行方法地址 访问相应方法地址，传入this指针调用方法 实现多态：subtyping polymorphism，同一语句具体调用 方法动态决定 多态：参见program/program_design/language_design vTable：虚表，存储一个类中所有虚函数地址 虚表是依次存储当前类中所有虚方法，不是继承序列 中同一个虚方法 Abstract Class抽象类：包含纯虚方法的类 抽象类主要作用 将有关类组织在继承层次结构中 刻画一组子类的操作接口的通用语义，只描述派生类共同 操作接口，完整实现留给子类 抽象类只能作为基类派生新类使用，不能创建抽象类对象 所以抽象类也不能做参数类型、函数返回类型、显式转换 类型 可以定义指向抽象类的指针、引用，可以指向其派生类， 进而实现多态 此特性本身就是为了解决基类生成对象不合理的问题， 抽象类就是为了抽象设计目的而建立 实际中，为了强调类是抽象类，可以将类的构造函数 放在protected区域 其派生类必须实现基类中所有纯虚函数，才能成为非抽象类 ，否则仍然是抽象类 构造/析构函数内不能使用纯虚函数（一般成员方法内可以） 因为派生类构造/析构函数内会调用基类构造/析构函数 纯虚函数没有函数体，不能被调用 Override覆盖/重置：在派生类中签名一样的方法会覆盖父类的方法 非虚方法：调用方法取决于指针、引用类型 将派生类对象赋给基类指针、引用后，调用方法是基类方法 ，表现父类的行为 虚方法：动态检查，调用方法取决于对象实际类型 将派生类对象赋给基类指针、引用后，调用方法是派生类 方法 即指针（引用）根据指向值决定行为，实现多态 Template模板：parameterized class参数化类，包含base type规格说明 的类 模板是C++多态的一种实现 编译器遇到函数模板调用，会自动生成相应版本函数拷贝 因此模板必须能实现，即不能将模板接口、实现分开， 否则编译器无法生成相应版本函数拷贝 （当然可以通过#include强行将接口、实现分开） 模板不能节省空间 模板使用在函数、类前添加 1template &lt;typename ValueType&gt; template关键字：表示此行后整个语法单位是模板模式一部分 ValueType：类型占位符，生成函数拷贝时被替换为相应类型 模板函数1234template &lt;typename ValueType&gt;ValueType max(ValueType x, ValueType y){ return (x &gt; y) ? x: y;} 模板类1234567891011// .htemplate &lt;typename T1, typename T2&gt;class Stack{ T1 d1; T2 d2;}template&lt;typename ValueType&gt;Stack&lt;ValueType&gt;::Stack(){} // 模板实现、接口在同一文件中 Template Specialization模板特化：指定一个或多个有具体模板参数的模板 全特化：给出所有模板参数 偏特化：给出部分模板参数 模板实例化时，优先使用模板参数最匹配的模板版本 通过特化模板，可以对特定模板参数集合自定义当前模板 最好特化模板的接口和普通模板一致 类模板特化类模板可以全特化、偏特化 特化的模板参数从模板参数列表中移除 在类名后给出完整参数列表 1234template &lt;typename T2&gt;class Stack&lt;int, T2&gt;{ ...} 函数模板特化函数模板只能全特化 若编译器可以通过返回值类型推断模板实参类型，可以省略 函数后模板参数列表，否则引起歧义报错 函数模板“偏特化”可以通过函数模板重载实现 1234template &lt;&gt;int max(int x, int y){ ...}","link":"/C-C/class.html"},{"title":"C++内存控制","text":"内存布局程序内存结构 static area：静态区，存储程序指令（按位存储）、 全局变量 位于地址编址号较小、接近地址空间开始处 该区域中分配的内存大小在程序整个执行期间不发生改变 正文段：CPU执行机器指令 每个程序只有一个副本 只读，避免程序因为意外事故而修改自身指令 初始化数据段：程序中所有赋初值全局变量 非初始化数据段（bss段）：程序中所有未初始化全局变量 内核将此段初始化为0 heap area：堆区，程序运行期间动态分配 程序中未分配的可用内存池 处于栈区、静态区之间 缺乏组织 需要寻址、操作速度慢 可以用于存储编译时未知大小、可变数据 stack area：栈区，存放函数栈帧 最高地址区 程序每调用函数、方法都会在此内存区域中创建新的栈帧， 函数返回所创建栈帧会被撤销，释放内存 操作迅速，不需要寻址 数据大小已知、固定 堆、栈以相反方向增长，方便任一区域都可以依照需要增长， 直到所有可用内存耗尽 内存分配 static allocation：静态分配，声明全局变量、常量时， 编译器为其在静态区中分配在整个程序生命周期内持久的内存 空间 automatic allocation：自动分配，调用函数时，编译器为 局部变量在栈帧分配存储空间，函数返回时空间自动释放 dynamical allocation：程序允许时，动态获得内存空间 stack frame：栈帧 栈帧随机为函数中局部变量分配内存、地址 栈帧中还包含额外信息，其结构取决于机器架构 变量：C++中声明变量时，编译器必须保证给声明变量分配足够 内存存储该类型变量值，分配内存大小取决于变量类型 Pointer C++设计原则：应该尽可能多的访问到有底层硬件提供的机制， 所以C++语言使得内存位置的地址对程序员可见 指针：值是内存中一个地址的数据项 指针允许以压缩方式引用大的数据结构 指针使得程序在运行时能够预订新的内存 指针可以用于记录数据项之间关系 Lvalue、Rvalue lvalue：左值，引用内存中能够存储数据的内存单元的表达式 rvalue：右值，非左值表达式 xvalue：返回右值引用的函数、表达式 gvalue：lvalue、xvalue总称 具体参见cs_program/program_design/language_design 左值引用左值引用：只能绑定左值，绑定有其他对象内存空间的变量 建立引用时是将内存空间绑定 使用的是对象在内存中位置 则被引用对象需要是左值 则不能将右值绑定到左值引用上 常量左值引用保证不能通过引用改变对应内存空间值 尝试绑定右值引用时，编译器会自动为右值分配空间 则可以将右值绑定在常量（左值）引用上 123456789int foo(42);int&amp; bar = foo; // OK：`foo`是左值，使用其在内存中位置int&amp; baz = 42; // Err：`42`是右值，不能将其绑定在左值引用上const int&amp; quz = 42; // OK：`42`是右值，但编译器可以为其开辟内存空间int&amp; garply = ++foo; // OK：前置自增运算符返回左值 右值引用右值引用&amp;&amp;：只能且必须绑定右值 考虑右值只能是字面常量、或临时对象，则右值引用 是临时的、即将销毁 不会在其他地方使用 则接受、使用右值引用的代码，可以自由的接管所引用对象 的资源，无需担心对其他代码逻辑造成数据破坏 move sematics：与右值引用交换成员 123456789int foo(42);int&amp;&amp; baz = foo; // Err：`foo`是左值，不能绑定在右值引用上int&amp;&amp; quz = 42; // OK：`42`是右值，可以绑定在右值引用上int&amp;&amp; quux = foo * 1; // OK：`foo * 1`结果是右值，可以绑定在右值引用上int&amp;&amp; waldo = foo--; // OK：后置自减运算符返回右值 Move Sematics 使用左值引用对类型X赋值操作流程如下 12345X&amp; X::operator=(X const &amp; rhs){ // make a clone of what rhs.m_pResource refers to // destruct the resource this.m_pResource refers to // attach the clone to this.m_pResource} m_pResource为X拥有某种资源 考虑如下代码中最后一行赋值的执行 123X foo();X x;x = foo(); 克隆foo()返回的临时对象中资源 析构x中资源，替换为foo()返回临时对象中资源副本 析构foo()返回临时对象 以上赋值流程效率低、没有必要，考虑交换x和foo()返回 临时对象资源副本，即move语义 123X&amp; x::operator=(X&amp;&amp; rhs){ // swap this-&gt;m_pResource and rhs.m_pResource} 执行同样x=foo() 此赋值操作只有由编译器自动析构foo()返回的临时 对象 x.m_pResource被转移给临时对象，在临时对象析构 时被析构 交换成员其实和右值引用没有必然联系 在其他方法中同样可以交换成员对象 但是只有在参为右值引用时，交换成员对象确保 不会对其他代码逻辑造成破坏 右值引用参数函数是对左值引用参数函数的重载 编译器优先为右值引用调用以右值引用为形参的函数 区分右值引用、左值引用可以尽量节省资源 Perfect Forwarding完美转发： 引用值类型 无论左值引用、右值引用 引用作为变量被保留，则其为左值 否则为右值 左值引用 123456789int foo(42);int &amp; bar = foo; // `bar`是对`foo`的左值引用int &amp; baz = bar; // `baz`是对`bar`的左值引用 // `bar`左值引用本身是左值int qux = ++foo; // 前置自增运算符返回左值引用 // 此时左值引用作为右值 右值引用 1234567class Type;void foo(Type&amp;&amp; bar){ Type baz(bar); // `bar`是左值}Type&amp;&amp; qux();quxx = qux(); 引用叠加 C++11中引用叠加规则如下 Type&amp; &amp; -&gt; Type&amp; Type&amp; &amp;&amp; -&gt; Type&amp; Type&amp;&amp; &amp; -&gt; Type&amp; Type&amp;&amp; &amp;&amp; -&gt; Type&amp;&amp; C++11之前不支持引用叠加，以下代码报错 12typedef int&amp; intR;typedef intR&amp; intRR; 指针使用声明指针1int *p1, *p2; 编译器需要知道指针base type，才能正确的解释指针地址 中的数据 *用于指明变量为指针变量 语法上属于变量名：声明时需要给每个指针变量标记* 但拥有基类型：是用于声明、定义的类型 base type：基类型，指针所指对象的类型 指针使用 &amp;：取地址 *：dereferencing，解析引用，取指针所指向对象的值 -&gt;：解析+选择操作符，取指针指向对象的成员 特殊指针 this：指向当前对象 解决二义性：引用当前对象的实例变量，即使其被形参、 局部变量覆盖 有建议：总是使用this引用当前实例变量使代码更具有 可读性 类方法调用都将this作为隐含参数，指向当前实例，即 主调函数中类实例 NULL：null pointer，空指针，不指向任何实际内存地址 在内部表示为0 在&lt;cstddef&gt;中已定义 使用*解释空指针不合法，但不总是能检测出来 引用调用C++内部通过指针实现引用调用 参数通过引用传递时，栈帧会在调用时存储一个指针指向该值 的内存单元 引用参数被声明为引用类型，编译器会自动解析其指针值 可以通过明确调用指针替代引用调用的效果 Pointer Arithmetic指针运算：对指针进行加减的运算 12345p + k // **定义**为：`&amp;array[k]`*p++ // 一元运算符右结合，等价于`*(p++)` // 检索数组当前元素，并将索引指向下个元素 只有+-运算有意义，且有约束 可以+-整数 不能指针相加 可以指针相减，返回两个指针之间数组元素数量 建议使用数组索引而不是指针运算提高可靠性 Array数组：较低级的多个数据值的集合 特性 有序 同质 约束 数组分配内存大小固定 数组大小不允许被获得 不支持插入、删除元素 不检查越界：重大安全隐患 C++提供的内置数组类型，基于从C语言继承而来的语言模型 考虑到Vector集合类更加灵活方便，没有什么理由继续使用 数组 数组使用12345678type name[size]; // 声明大小为`size`、类型为`type`的数组`name`name[idx]; // 选择数组`name`中`idx`处元素type static_arr [] = {}; // 数组静态初始化const int ARR_LEN = sizeof static_arr / sizeof static_arr[0]; // 获取数组长度 声明：多数情况下，应该使用符号常量而不是确定的整数值指定 数组大小，以便修改代码 selection：通过数组名+[idx]选择元素 静态初始化：可以忽略数组容量，编译器自动从初始化的元素 数目推断 获取数组分配容量：基于数组同质性 数组容量 allocated size：声明时指定的数组容量 effective size：实际使用到的元素数目 声明比需求大的数组 定义常量表示数组元素数目最大值，以此声明数组 指针&amp;数组数组名同时也用作一个指针值，表示数组中首个元素地址 如果编译器遇到数组变量名没带下标，则将其解释为指向数组 开始内存的指针变量 C++将数组视为指针最重要的原因：数组形参和实参共享 数组和指针作为形参声明函数完全相同 数组作为实参传递时，其值（首个元素地址）类似指针被 复制，调用函数中对数组的改变持久 应该使用能反映其用途的方式声明参数，打算用数组作为 参数就声明参数为数组 C++中指针、数组最关键区别：变量声明时内存分配 数组：连续的、可以存储数组元素的内存 指针：存储机器地址的一个字的内存，不能直接存储数据 指针作为数组使用 将已存在数组首地址赋给指针有严格限制 真正优势是程序运行时动态分配内存创建数组 动态内存管理分配内存 动态分配的内存在分配其的栈帧被释放后仍然保持 动态内存分配一定要手动及时释放 newnew：以某种类型，从堆中分配一块空间给所指定类型的变量 new操作符返回堆中预留的、存储某类型值的地址 123456789int *ip = new int; // 从堆中分配单个类型空间给指定指针变量int *array = new double[4]; // 从堆上给数组分配空间给指定指针变量 // 动态数组Point *p_1 = new Point; // 从堆上给对象、结构体分配空间，调用默认构造函数Point *p_2 = new Point(2, 3); // 类型名后提供参数，则`new`会调用相应构造函数 一旦在堆中分配了空间，可以通过解析指针来引用 xlloc释放内存deletedelete：取new操作符事先分配内存的指针，释放该指针指向 的内存空间 1234delete ip; // 释放单个类型空间指针变量delete[] array; // 释放动态数组 释放内存策略 garbage collection：垃圾回收，自动查找不再使用的内存， 然后释放 拷贝 shallow copying：浅拷贝，C++默认拷贝 如果值是指针，不会拷贝指针所指的值 可以通过重载赋值操作符、构造拷贝构造函数改变默认的 浅拷贝行为 deep copying：深拷贝 拷贝指针时，拷贝指针所指的值 关键字Global Variableconstconst：常量，初始化之后不能改变 优势 描述性常量名使得程序更易于阅读 大大简化程序日常中代码维护问题 const修饰经过依据优先级、其他关键字处理后的主体 指针、值、参数：其他关键字处理得到目标语义主体处 返回值：const置于函数签名头 函数主体：函数体{}前、函数签名后 C++中常量声明中字符应全部为大写 所以常量类成员必须在初始化列表中设置值 static非成员静态变量非成员静态变量：程序执行前既已在静态数据区分配内存 静态全局变量 未经初始化时会被自动初始化为0 internal属性，仅在声明文件内部可见，文件外不可见， 较一般全局变量不容易冲突 普通全局变量：默认external，可以通过extern关键字 被其他文件访问，随机值初始化 静态局部变量 仅会在首次声明时被初始化，之后重复声明不会初始化 具有static-storage duration/static extent，仅在 声明其的局部作用域中可见，但不会随函数栈退出而销毁， 适合函数重入需要保存局部状态场合 非成员静态函数非成员静态函数：作用域仅限于声明文件 仅在声明其的文件中可见，不能被其他文件使用，较一般函数 不容易发生冲突 函数定义、声明默认extern，可通过extern关键字在 其他文件中使用 静态成员变量静态成员变量：程序执行前既已在静态数据区分配内存 静态成员变量属于类 在内存中只有一份拷贝，所有类对象共享 可以通过类名直接访问&lt;cls&gt;::&lt;static_var&gt;，若访问 权限允许 只能在类中声明，在类外初始化 初始化：&lt;var_type&gt; &lt;cls&gt;::&lt;static_var&gt; = &lt;value&gt; 静态成员函数静态成员函数 静态成员函数属于类 没有this指针 只能访问静态成员变量、静态成员函数 可通过类名直接调用&lt;cls&gt;::&lt;static_func&gt;()，若访问 权限允许 类内声明静态成员函数需要static关键字，在类外定义时 无需static关键字 externextern：声明使用未定义（全局）变量、函数 extern修饰的变量可在当前文件、或其他文件中定义 当前文件extern声明处后定义：扩展（全局）变量作用 范围 在其他文件中定义：引用在其他文件中定义的（全局）变量 函数声明中extern：仅表示函数可能在其他源文件中定义， 即extern总是可以省略 因为函数声明默认无定义，而变量声明默认同时定义 extern声明要严格对应定义格式 extern char *a不能用于声明char a[6] extern不能用于访问其他文件中静态全局变量 编译器遇到extern函数、变量时在其他模块中寻找定义 external全局变量 全局变量默认为external 虽然作用域默认仅限于为当前文件，但是可以通过 external关键字在其他文件中声明访问 可以通过static关键字使变量internal，在其他文件 中不可见 程序中不能有多个同名非静态全局变量 编译时：C++以文件为单位进行编译，可以有多个文件定义 同名非静态全局变量 链接时：链接器将无法确定链接目标报错 头文件全局变量 引入头文件相当于直接复制头文件内容，若在头文件中定义 全局变量 头文件可以被多个源文件引入 相当于在多个文件中定义同名全局变量报错 头文件中不应定义非静态全局变量 定义静态全局变量：在多源文件中定义不共享、互相独立、 不可见全局变量 在头文件中声明extern全局变量：在某个源文件中仅定义 一次该全局变量，包含该头文件源文件共享该全局变量 extern &quot;C&quot;extern &quot;C&quot;：指定编译、链接规约，不影响语义 extern &quot;C&quot;是为C++编译器指定的 编译C++文件时：对extern &quot;C&quot;声明的函数按照C编译规约 翻译名称、编译 链接时：对extern &quot;C&quot;声明的函数按照C链接规约链接 &quot;C&quot;：是指编译、链接规约，不是指C语言 其他符合类C语言编译、链接规约的语言，如：Fortran、 Assembler，均可以使用extern &quot;C&quot;声明 C++支持重载，编译器会联合函数名、参数生成中间函数名， 在C++中使用C函数可能导致链接器无法到对应C函数 C++环境使用C函数C++可以直接使用C函数接口，只是需要指明使用C函数 使用extern &quot;C&quot;逐个声明C函数 1234extern &quot;C&quot; void func(int a);extern &quot;C&quot;{void func(int a);} 适合需要声明函数数量较少、分散在不同文件中 在头文件中设置宏编译编译条件 12345678910111213#ifdef __cplusplus#if __cplusplusextern &quot;C&quot;{#endif#endif/*...c code...*/#ifdef __cplusplus#if __cplusplus}#endif#endif 仅在C++源文件中有extern &quot;C&quot;声明，保证正常编译、 链接 适合C函数声明集中在同一头文件中 C环境使用C++函数C环境无法直接使用C++函数，必须转换为C函数接口才能使用 通过extern &quot;C&quot;将C++中函数声明为C函数 123extern &quot;C&quot; void func(int a);void func(int a);void func(int a, int b); 带有extern &quot;C&quot;、不带是两个中函数声明，可以共存 虽然C++中不能对重载函数声明extern &quot;C&quot;，但C不支持 函数重载，也没有必要对重载函数声明extern &quot;C&quot; 通过extern &quot;C&quot;创建包装C函数 可以类似C++翻译重载函数名，将重载函数包装为多个C函数 12345void f(int);void f(doubel);extern &quot;C&quot; void f_i(int i){ f(i); }extern &quot;C&quot; void f_d(double d){ f(d); } 可以包装类成员方法 1234567class C{ virtual doubel f(int);}extern &quot;C&quot; double call_C_f(C* p, int i){ return p-&gt;f(i);} registerregister：寄存器变量，将局部变量值放在运算器的寄存器中 存放在寄存器中的变量参与运算时，无需从内存中获取，节省 时间、提高效率 autoauto：要求编译器对变量类型进行自动推导 auto声明变量必须初始化，以使编译器能够推导变量类型 从此意义上说，auto是类型声明占位符，编译器在编译时 将auto替换变量实际类型 auto优势、用途 声明有初始化表达式的复杂类型变量时简化代码 避免声明变量类型时错误：编译器自动选择最合适类型 函数返回值类型不确定，使用auto代替 一定程度上支持泛型编程 修改函数返回值类型时，无需修改代码 auto可以结合模板使用，加强泛型能力 C++11前，auto指具有自动存储期的局部变量，而没有声明为 static变量总是具有自动存储期的变量，使用频率极低 具有自动存储期变量在进入声明该变量的程序块时被建立 存在于程序块存活时，退出程序块时被销毁 注意事项 auto可以联合volatile、*、&amp;、&amp;&amp;使用 auto需要被推导为类型 声明变量必须初始化 不能和其他类型联合使用 函数参数、模板参数不能被声明为auto auto只是占位符，不是独立类型，不能用于类型转换或其他 涉及具体类型操作，如：sizeof、typeid 定义在一个auto序列中变量必须推导为同一类型 但auto不会被自动推导为constant&amp;volatile qualifiers， 除非被声明为引用类型 123const int i = 99;auto j = i; // `j`为`int`类型，不是`const int`auto&amp; k = i; // `i`为`const int&amp;`类型 auto会退化为指向数组的指针，除非被声明为引用 1234567int a[9];auto j = a;count &lt;&lt; typeid(j).name() &lt;&lt; endl; // 输出`int*`auto&amp; k = a;count &lt;&lt; typeid(k).name() &lt;&lt; endl; // 输出`int[9]` decltypedecltype：要求编译器在编译时进行类型推导 以普通表达式作为参数，返回表达式类型 decltype不会对表达式进行求值 decltype用途、优势 推导表达式类型 与using/typedef联合使用，定义类型 重用匿名类型 结合auto，追踪函数返回值类型 推导规则 若e为无括号的标记符表达式、类成员访问表达式 则decltype(e)为e所命名的实体类型 若e为被重载函数、或实体不存在，将导致编译错误 设e类型为T 若e为将亡值，则decltype(e)为T&amp;&amp; 若e为左值，则decltype(e)为T&amp; 若e为纯右值，则decltype(e)为T volatile volatile: a situation that is likely to change suddenly and unexpectedly volatile：变量可能受到程序外因素影响，不应该对其做出 任何假设 C/C++中对volatile对象访问，有编译器优化上的副作用， 降低性能 对volatile对象访问必须与内存进行交互，不能直接 使用寄存器中已有值 volatile对象相关代码块不允许被优化消失 多个volatile对象访问保序：编译器不可交换 对volatile对象访问的执行次序 不能保证CPU乱序执行不交换执行次序 因此volatile无法解决多线程同步问题 X86、AMD64等常用架构CPU只允许store-load乱序， 不允许store-store乱序，此时volatile用于线程同步 是安全的，但是这依赖于硬件规范，且会降低执行效率 推荐使用原子操作、互斥量等实现 用途 信号处理相关场合 内存映射硬件相关场合 非本地跳转相关场合 错误线程同步123456789101112131415161718192021222324252627volatile bool flag = false;thread1(){ flag = false; volatile Type* value = new Type(); thread2(value); while(true){ if(flag == true){ // 希望`thread2`更新完`value`后继续执行 // `flag`为`volatile`保证此语句块不会被优化消失 apply(value); break; } } thread.join(); if(nullptr != value){ delete value; } return;}thread2(volatile Type* value){ value-&gt;update(); flag = true; // `flag`、`value`均为`volatile`保证两语句不会交换执行次序 return;} 以上代码即使对相关变量都设为volatile，也依赖CPU执行 规范才能保证安全 __unaligned","link":"/C-C/mem_ctl.html"},{"title":"Hadoop HDFS","text":"HDFS设计模式 数据读取、写入 HDFS一般存储不可更新的文件，只能对文件进行数据追加 ，也不支持多个写入者的操作 认为一次写入、多次读取是最高效的访问模式 namenode将metadata存储在内存中，所以文件系统所能 存储的文件总数受限于NameNode的内存 适合模式 每次分析都涉及数据集大部分数据甚至全部，因此读取整个 数据集的大部分数据、甚至全部，因此读取整个数据集的 时间比读取第一条记录时间延迟更重要 HDFS不适合要求地时间延迟的数据访问应用，HDFS是为 高数据吞吐量应用优化的，可能会提高时间延迟 硬件：HDFS无需高可靠硬件，HDFS被设计为即使节点故障也能 继续运行，且不让用户察觉 数据块和普通文件系统一样，HDFS同样也有块的概念，默认为64MB HDFS上的文件也被划分为块大小的多个chunk，作为独立的存储 单元，但是HDFS中小于块大小的文件不会占据整个块空间 对分布式文件系统块进行抽象的好处 文件大小可以大于网络中任意一个磁盘的容量 使用抽象块而非整个文件作为存储单元，简化了存储子系统 的设计 简化存储管理，块大小固定，计算磁盘能存储块数目 相对容易 消除了对元素见的顾虑，文件的元信息（权限等）， 不需要和块一起存储，可由其他系统单独管理 块非常适合用于数据备份，进而提供数据容错能力、提高可用性 NameNodeHDFS系统中的管理者 集中存储了HDFS的元信息Metadata 维护文件系统的文件树、全部的文件和文件夹的元数据 管理文件系统的Namespace：创建、删除、修改、列出所有 文件、目录 执行数据块的管理操作 把文件映射到所有的数据块 创建、删除数据块 管理副本的Placement、Replication 负责DataNode的成员管理 接受DataNode的Registration 接受DataNode周期性的Heart Beat Hadoop上层模块，根据NameNode上的元信息，就可以知道每个数据块 有多少副本、存放在哪些节点上，据此分配计算任务，通过 Move Computation to Data，而不是移动数据本身，减少数据 移动开销，加快计算过程 Metadata的保存为了支持高效的存取操作，NameNode把所有的元信息保存在主内存， 包括文件和数据块的命名空间、文件到数据块的映射、数据块副本 的位置信息。文件命名空间、文件到数据块的映射信息也会持久化 到NameNode本地文件系统 FsImage：命名空间镜像文件，保存整个文件系统命名空间、 文件到数据块的映射信息 EditLog：编辑日志文件，是一个Transaction Log文件，记录了 对文件系统元信息的所有更新操作：创建文件、改变文件的 Replication Factor NameNode启动时，读取FsImage、EditLog文件，把EditLog的所有 事务日志应用到从FsImage文件中装载的旧版本元信息上，生成新的 FsImage并保存，然后截短EditLog NameNode可恢复性多个文件系统备份备份文件系统元信息的持久化版本 在NameNode写入元信息的持久化版本时，同步、atomic写入多个 文件系统（一般是本地磁盘、mount为本地目录的NFS） Secondary NameNode运行Secondary NameNode：负责周期性的使用EditLog更新 FsImage，保持EditLog在一定规模内 Seconadary NameNode保存FsImage、EditLog文件副本， 每个一段时间从NameNode拷贝FsImage，和EditLog文件进行 合并，然后把更新后的FsImage复制回NameNode 若NameNode宕机，可以启动其他机器，从Secondary NameNode获得FsImage、EditLog，恢复宕机之前的最新的 元信息，当作新的NameNode，也可以直接作为主NameNode Secondary NameNode保存的出状态总是滞后于主节点，需要 从NFS获取NameNode部分丢失的metadata Secondary NameNode需要运行在另一台机器，需要和主 NameNode一样规模的CPU计算能力、内存，以便完成元信息 管理 想要从失效的NameNode恢复，需要启动一个拥有文件系统数据副本的 新NameNode，并配置DataNode和客户端以便使用新的NameNode 将namespace的映像导入内存中 重做编辑日志 接收到足够多的来自DataNode的数据块报告，并退出安全模式 DataNodeHDFS中保存数据的节点 数据被切割为多个数据块，以冗余备份的形式存储在多个 DataNode中，因此不需要再每个节点上安装RAID存储获得硬件上 可靠存储支持。DataNode之间可以拷贝数据副本，从而可以重新 平衡每个节点存储数据量、保证数据可靠性（保证副本数量） DotaNode定期向NameNode报告其存储的数据块列表，以备使用者 通过直接访问DataNode获得相应数据 所有NameNode和DataNode之间的通讯，包括DataNode的注册、 心跳信息、报告数据块元信息，都是由DataNode发起请求，由 NameNode被动应答和完成管理 HDFS高可用性对于大型集群，NN冷启动需要30min甚至更长，因此Hadoop2.x中添加 对高可用性HA（high-availability）的支持 配置Active-Standby NameNode ANN失效后，SNN就会接管任务并开始服务，没有明显中断 ANN、SNN应该具有相同的硬件配置 NN之间需要通过高可用的共享存储（JounalNode）实现 Editlog共享 JN进程轻量，可以和其他节点部署在同一台机器 JN至少为3个，最好为奇数个，这样JN失效$(n-1)/2$个时 仍然可以正常工作 SNN接管工作后，将通读共享编辑日志直到末尾，实现与ANN 状态同步 DN需要同时向两个NN发送数据块处理报告，因为数据块映射信息 存储在NN内存中 客户端需要使用特定机制处理NN失效问题，且机制对用户透明 如果两个namenode同时失效，同样可以冷启动其他namenode， 此时情况就和no-HA模式冷启动类似 注意：HA模式下，不应该再次配置Secondary NameNode Note that, in an HA cluster, the Standby NameNode also performs checkpoints of the namespace state, and thus it is not necessary to run a Secondary NameNode, CheckpointNode, or BackupNode in an HA cluster. In fact, to do so would be an error. This also allows one who is reconfiguring a non-HA-enabled HDFS cluster to be HA-enabled to reuse the hardware which they had previously dedicated to the Secondary NameNode. Failover Controller故障转移控制器系统中有一个新实体管理者管理namenode之间切换， Failover Controller最初实现基于Zookeeper，可插拔 每个namenode运行着一个Failover Controller，用于监视宿主 namenode是否失效（heart beat机制）， 并在失效时进行故障 切换 管理员也可以手动发起故障切换，称为平稳故障转移 在非平稳故障切换时，无法确切知道失效namenode是否已经停止 运行，如网速慢、网络切割均可能激发故障转移，引入fencing 机制 杀死namenode进程 收回对共享存储目录权限 屏蔽相应网络端口 STONITH：shoot the other node in the head，断电 联邦HDFSNameNode在内存中保存文件系统中每个文件、数据块的引用关系， 所以对于拥有大量文件的超大集群，内存将成为系统扩展的瓶颈， 2.x中引入的联邦HDFS可以添加NameNode实现扩展 每个NameNode维护一个namespace volume，包括命名空间的 元数据、命令空间下的文件的所有数据块、数据块池 namespace volume之间相互独立、不通信，其中一个NameNode 失效也不会影响其他NameNode维护的命名空间的可用性 数据块池不再切分，因此集群中的DataNode需要注册到每个 NameNode，并且存储来自多个数据块池的数据块 Hadoop文件系统Hadoop有一个抽象问的文件系统概念，HDFS只是其中的一个实现， Java抽象类org.apche.hadoop.fs.FileSystem定义了Hadoop中的 一个文件系统接口，包括以下具体实现 文件系统 URI方案 Java实现 描述 Local file fs.LocalFileSystem 使用客户端校验和本地磁盘文件系统，没有使用校验和文件系统RawLocalFileSystem HDFS hdfs hdfs.DistributedFileSystem HDFS设计为与MapReduce结合使用实现高性能 HFTP hftp hdfs.HftpFileSystem 在HTTP上提供对HDFS只读访问的文件系统，通常与distcp结合使用，以实现在运行不同版本HDFS集群之间复制数据 HSFTP hsftp hdfs.HsftpFileSystem 在HTTPS上同以上 WebHDFS Webhdfs hdfs.web.WebHdfsFileSystem 基于HTTP，对HDFS提供安全读写访问的文件系统，为了替代HFTP、HFSTP而构建 HAR har fs.HarFileSystem 构建于其他文件系统之上，用于文件存档的文件系统，通常用于需要将HDFS中的文件进行存档时，以减少对NN内存的使用 hfs kfs fs.kfs.kosmosFileSystem CloudStore（前身为Kosmos文件系统）类似于HDFS（GFS），C++编写 FTP ftp fs.ftp.FTPFileSystem 由FTP服务器支持的文件系统 S3（原生） S3n fs.s3native.NativeS3FileSystem 由Amazon S3支持的文件系统 S3（基于块） S3 fs.sa.S3FileSystem 由Amazon S3支持的文件系统，以块格式存储文件（类似于HDFS），以解决S3Native 5GB文件大小限制 分布式RAID hdfs hdfs.DistributedRaidFileSystem RAID版本的HDFS是为了存档而设计的。针对HDFS中每个文件，创建一个更小的检验文件，并允许数据副本变为2，同时数据丢失概率保持不变。需要在集群中运行一个RaidNode后台进程 View viewfs viewfs.ViewFileSystem 针对其他Hadoop文件系统挂载的客户端表，通常用于联邦NN创建挂载点 文件系统接口Hadoop对文件系统提供了许多接口，一般使用URI方案选择合适的 文件系统实例进行交互 命令行接口12345678$ hadoop fs -copyFromLocal file hdfs://localhost/user/xyy15926/file # 调用Hadoop文件系统的shell命令`fs` # `-copyFromLocalFile`则是`fs`子命令 # 事实上`hfds://localhost`可以省略，使用URI默认设置，即 # 在`core-site.xml`中的默认设置 # 类似的默认复制文件路径为HDFS中的`$HOME`$ hadoop fs -copyToLocal file file HTTP 直接访问：HDFS后台进程直接服务来自于客户端的请求 由NN内嵌的web服务器提供目录服务（默认50070端口） DN的web服务器提供文件数据（默认50075端口） 代理访问：依靠独立代理服务器通过HTTP访问HDFS 代理服务器可以使用更严格的防火墙策略、贷款限制策略 CHadoop提供libhdfs的C语言库，是Java FileSystem接口类的 镜像 被写成访问HDFS的C语言库，但其实可以访问全部的Hadoop文件 系统 使用Java原生接口（JNI）调用Java文件系统客户端 FUSEFilesystem in Userspace允许把按照用户空间实现的文件系统整合 成一个Unix文件系统 使用Hadoop Fuse-DFS功能模块，任何一个Hadoop文件系统可以 作为一个标准文件系统进行挂载 Fuse_DFS使用C语言实现，调用libhdfs作为访问HDFS的接口 然后可以使用Unix工具（ls、cat等）与文件系统交互 还可以使用任何编程语言调用POSIX库访问文件系统 读文件 客户端程序使用要读取的文件名、Read Range的开始偏移量、 读取范围的程度等信息，询问NameNode NameNode返回落在读取范围内的数据块的Location信息，根据 与客户端的临近性（Proximity）进行排序，客户端一般选择 最临近的DataNode发送读取请求 具体实现如下 客户端调用FileSystem对象open方法，打开文件，获得 DistributedFileSystem类的一个实例 DistributedFileSystem返回FSDataInputStream类的实例， 支持文件的定位、数据读取 DistributedFileSystem通过RPC调用NameNode，获得 文件首批若干数据块的位置信息（Locations of Blocks） 对每个数据块，NameNode会返回拥有其副本的所有DataNode 地址 其包含一个DFSInputStream对象，负责管理客户端对HDFS 中DataNode、NameNode存取 客户端从输入流调用函数read，读取文件第一个数据块，不断 调用read方法从DataNode获取数据 DFSInputStream保存了文件首批若干数据块所在的 DataNode地址，连接到closest DataNode 当达到数据块末尾时，DFSInputStream关闭到DataNode 的连接，创建到保存其他数据块DataNode的连接 首批数据块读取完毕之后，DFSInputStream向NameNode 询问、提取下一批数据块的DataNode的位置信息 客户端完成文件的读取，调用FSDataInputStream实例close 方法关闭文件 写文件 客户端询问NameNode，了解应该存取哪些DataNode，然后客户端 直接和DataNode进行通讯，使用Data Transfer协议传输数据， 这个流式数据传输协议可以提高数据传输效率 创建文件时，客户端把文件数据缓存在一个临时的本地文件上， 当本地文件累计超过一个数据块大小时，客户端程序联系 NameNode，NameNode更新文件系统的NameSpace，返回Newly Allocated数据块的位置信息，客户端根据此信息本文件数据块 从临时文件Flush到DataNode进行保存 具体实现如下： 客户端调用DistributedFileSystem的create方法 DistributedFileSystem通过发起RPC告诉NameNode在 其NameSpace创建一个新文件，此时新文件没有任何数据块 NameNode检查：文件是否存在、客户端权限等，检查通过 NameNode为新文件创建新记录、保存其信息，否则文件创建 失败 DistributedFileSystem返回FSDataOutputStream给客户端 其包括一个DFSOutputStream对象，负责和NameNode、 DataNode的通讯 客户端调用FSDataOutputStream对象write方法写入数据 DFSOutputStream把数据分解为数据包Packet，写入内部 Data Queue DataSteamer消费这个队列，写入本地临时文件中 当写入数据超过一个数据块大小时，DataStreamer请求 NameNode为新的数据块分配空间，即选择一系列合适的 DataNode存放各个数据块各个副本 存放各个副本的DataNode形成一个Pipeline，流水线上的 Replica Factor数量的DataNode接收到数据包之后转发给 下个DataNode DFSOutputStream同时维护数据包内部Ack Queue，用于 等待接受DataNode应答信息，只有某个数据包已经被流水线 上所有DataNode应答后，才会从Ack Queue上删除 客户端完成数据写入，调用FSDataOutputStream的close 方法 DFSOutputStream把所有的剩余的数据包发送到DataNode 流水线上，等待应答信息 最后通知NameNode文件结束 NameNode自身知道文件由哪些数据块构成，其等待数据块 复制完成，然后返回文件创建成功 Hadoop平台上的列存储列存储的优势 更少的IO操作：读取数据的时候，支持Prject Pushdown，甚至 是Predicate Pushdown，可大大减少IO操作 更大的压缩比：每列中数据类型相同，可以针对性的编码、压缩 更少缓存失效：每列数据相同，可以使用更适合的Cpu Pipline 编码方式，减少CPU cache miss RCFileRecord Columnar File Format：FB、Ohio州立、中科院计算所合作 研发的列存储文件格式，首次在Hadoop中引入列存储格式 允许按行查询，同时提供列存储的压缩效率的列存储格式 具备相当于行存储的数据加载速度、负载适应能力 读优化可以在扫描表格时，避免不必要的数据列读取 使用列维度压缩，有效提升存储空间利用率 具体存储格式 首先横向分割表格，生成多个Row Group，大小可以由用户 指定 在RowGroup内部，按照列存储一般做法，按列把数据分开， 分别连续保存 写盘时，RCFile针对每列数据，使用Zlib/LZO算法进行 压缩，减少空间占用 读盘时，RCFile采用Lazy Decompression策略，即用户 查询只涉及表中部分列时，会跳过不需要列的解压缩、 反序列化的过程 ORC存储格式Optimized Row Columnar File：对RCFile优化的存储格式 支持更加丰富的数据类型 包括Date Time、Decimal Hive的各种Complex Type，包括：Struct、List、Map、 Union Self Describing的列存储文件格式 为Streaming Read操作进行了优化 支持快速查找少数数据行 Type Aware的列存储文件格式 文件写入时，针对不同的列的数据类型，使用不同的编码器 进行编码，提高压缩比 整数类型：Variable Length Compression 字符串类型：Dictionary Encoding 引入轻量级索引、基本统计信息 包括各数据列的最大/小值、总和、记录数等信息 在查询过程中，通过谓词下推，可以忽略大量不符合查询 条件的记录 文件结构一个ORC文件由多个Stripe、一个包含辅助信息的FileFooter、以及 Postscript构成 Stripe每个stripe包含index data、row data、stripe footer stripe就是ORC File中划分的row group 默认大小为256MB，可扩展的长度只受HDFS约束 大尺寸的strip、对串行IO的优化，能提高数据吞吐量、 读取更少的文件，同时能把减轻NN负担 Index Data部分 包含每个列的极值 一系列Row Index Entry记录压缩模块的偏移量，用于跳转 到正确的压缩块的位置，实现数据的快速读取，缺省可以 跳过10000行 Row Data部分；包含每个列的数据，每列由若干Data Stream 构成 Stripe Footer部分 Data Stream位置信息 每列数据的编码方式 File Footer包含该ORCFile文件中所有stripe的元信息 每个Stripe的位置 每个Stripe的行数 每列的数据类型 还有一些列级别的聚集结果，如：记录数、极值、总和 Postscript 用来存储压缩参数 压缩过后的Footer的长度 Parquet灵感来自于Google关于Drenel系统的论文，其介绍了一种支持嵌套 结构的列存储格式，以提升查询性能 支持Parquet为hadoop生态系统中的所有项目，提供支持高压缩率的 列存储格式 兼容各种数据处理框架 MapReduce Spark Cascading Crunch Scalding Kite 支持多种对象模型 Avro Thrift Protocol Buffers 支持各种查询引擎 Hive Impala Presto Drill Tajo HAWQ IBM Big SQL Parquet组件 Storage Format：存储格式，定义了Parquet内部的数据类型、 存储格式 Object Model Converter：对象转换器，由Parquet-mr实现， 完成对象模型与Parquet数据类型的映射 如Parquet-pig子项目，负责把内存中的Pig Tuple序列化 并按存储格式保存为Parquet格式的文件，已经反过来， 把Parquet格式文件的数据反序列化为Pig Tuple Object Model：对象模型，可以理解为内存中的数据表示，包括 Avro、Thrift、Protocal Buffer、Hive Serde、Pig Tuple、 SparkSQL Internal Row等对象模型 Parquet数据schema数据schema（结构）可以用一个棵树表达 有一个根节点，根节点包含多个Feild（子节点），子节点可以 包含子节点 每个field包含三个属性 repetition：field出现的次数 required：必须出现1次 optional：出现0次或1次 repeated：出现0次或多次 type：数据类型 primitive：原生类惬 group：衍生类型 name：field名称 Parquet通过把多个schema结构按树结构组合，提供对复杂类型 支持 List、Set：repeated field Map：包含键值对的Repeated Group（key为Required） schema中有多少叶子节点，Parquet格式实际存储多少列， 父节点则是在表头组合成schema的结构 Parquet文件结构 HDFS文件：包含数据和元数据，数据存储在多个block中 HDFS Block：HDFS上最小的存储单位 Row Group：按照行将数据表格划分多个单元，每个行组包含 一定行数，行组包含该行数据各列对应的列块 一般建议采用更大的行组（512M-1G），此意味着更大的 列块，有毅力在磁盘上串行IO 由于可能依次需要读取整个行组，所以一般让一个行组刚好 在一个HDFS数据块中，HDFS Block需要设置得大于等于行组 大小 Column Chunk：每个行组中每列保存在一个列块中 行组中所有列连续的存储在行组中 不同列块使用不同压缩算法压缩 列块存储时保存相应统计信息，极值、空值数量，用于加快 查询处理 列块由多个页组成 Page：每个列块划分为多个Page Page是压缩、编码的单元 列块的不同页可以使用不同的编码方式 HDFS命令用户 HDFS的用户就是当前linux登陆的用户 Hadoop组件Hadoop Streaming","link":"/Database/Hadoop/hdfs.html"},{"title":"查找&#x2F;搜索树","text":"总述 二叉查找树：最基础的查找树，但是不平衡时效率很差 自平衡查找树：使用旋转技术得到平衡二叉树 多路查找树：使用多叉树达到平衡 树高度一般即决定其查找、插入、删除效率 以代码复杂性、插入节点时间代价，换取查询时$logN$性能 Self-Balancing Binary Tree自平衡查找树：如果节点插入、删除产生了一棵违背平衡要求的树， 就从称为旋转的一系列特定变换中选择一种，重新构造树使得 树满足平衡要求 不同的对平衡的定义产生了不同的实现 这种方案属于变治法中实例化简 Balance Factor平衡因子：节点左、右子树高度差（一般右树-左数） AVL树中平衡情况下节点平衡因子只能为-1、+1、0 更新节点后可能存在不平衡节点，其平衡因子可能变为-2、+2 平衡因子也可以被定义为左右子树叶子数 Rotation旋转需要使得二叉树平衡时，保证二叉树依然有序 左旋：节点平衡因子符号为正，即右子树高于左子树 节点T下沉为其右儿子R的左儿子 如果右儿子R本身有左子树RL，则左子树RL成为节点T 新右子树 右旋：节点平衡因子符号为负，即左子树高于右子树， 节点T下沉为其左儿子L的右儿子 如果左儿子L本身有右子树LR，则右子树LR成为节点T 新左子树 旋转只涉参与选择的至多3个节点指针变化，其余节点状态保持 “旋转”行为确实类似：节点绕其子节点旋转，子节点旋转后上浮 成为父节点 参与旋转的两个节点也称为轴 分类 AVL树 红黑树 分裂树 Multiway Search Tree多路查找树：允许查找树中单个节点中不止包含一个元素 二叉查找树的推广，用于磁盘超大数据集的高效存取 此方案属于变治法中改变表现 分类 2-3树 2-4树 B树 B+树 Binary Search Tree二叉查找树：分配给每个父母顶点的数字都比其左子树中数字大， 比右子树数字小 二叉树有序，保证二叉树能够快速找到中间元素，从而支持 二分查找 特点 对于n个顶点的二叉树，满足 $ \\lfloor {log_{2}^{n}} \\rfloor \\leq h \\leq n-1 $ 二叉查找树的查找算法效率取决于二叉树的高度 平均情况下，查找、插入、删除时间$\\in Theta(logn)$ 最差情况下（严重不平衡的树，接近链表结构），树高度 h接近节点数n，查找、插入、删除时间$\\in Theta(n)$ 包含n个键的二叉查找树总数量 $c(n) = \\frac 1 {n+1} C_{2n}^n, c(0)=1$ 应用 查找 操作查找在给定二叉查找树中查找给定键值K 如果树为空，查找失败 若树不为空，将查找键K和树根节点K(r)比较 相等则查找停止 $K &lt; K(r)$：在左子树中继续查找 $K &gt; K(r)$：在右子树中继续查找 特点 算法时间效率 最差情况下，二叉树完全偏斜，需要进行n次比较 随机情况下，查找n个随机键构造的二叉树比较次数$2logn$ 插入除非是空树，否则总是把新键K插入叶子节点中 通过查找K确定合适插入位置（叶子节点） 若K大于叶子节点键值，则作为右子女，否则作为左子女 最优二叉查找树对集合中元素确定的查找概率，成功查找的平均比较次数最小的 二叉查找树（可以扩展到包含不成功查找） $a_i, i=1,2,\\cdots,n$：从小到大互不相等的键 $p_i, i=1,2,\\cdots,n$：键查找概率 $T_i^j$：由键$a_i, \\cdots, a_j$构成的二叉树 $C(i, j)$：成功查找的最小平均查找次数 动态规划构造 根据最优化法则，最优二叉查找树左右子树均是最优排列的 二叉树$Ti^j$有序，设树根为$a_1$，$a_2,..,a{k-1}$构成 的左子树、$a_{k+1},..,a_j$构成右子树均是最优排列的 递推式如下 $1 \\leqslant i \\leqslant j \\leqslant n$ \\begin{align} C(i, j) & = \\min_{i \\leqslant k \\leqslant j} \\{p_k + \\sum_{s=i}^{k-1} p_s * (a_s在T_i^{k-1}中层数 + 1) + \\sum_{s=k+1}^j p_s * (a_s在T_{k+1}^j中层数 + 1) \\}\\\\ & = \\min_{i \\leqslant k \\leqslant j} \\{ \\sum_{s=i}^{k-1} p_s * a_s在T_i^{k-1}中层数 + \\sum_{s=k+1}^j p_s * a_s在T_{k+1}^j中层数 + \\sum_{s=i}^j p_s \\} \\\\ & = \\min_{i \\leqslant k \\leqslant j} \\{C(i, k-1) + C(k+1, j)\\} + \\sum_{s=i}^j p_s \\end{align} $1 \\leqslant i \\leqslant n+1, C(i, i-1)=0$：空树 $1 \\leqslant i \\leqslant n, C(i, i)=p_i$：单节点 123456789101112131415161718192021222324252627OptimalBST(P[1..n]) // 动态规划法构建最优二叉查找树 // 输入：P[1..n]n个键查找概率 // 输出：在最优BST中查找成功的平均比较次数，最优BST子树根表 for i = 1 to n do C[i, i-1] = 0 C[i, i] = P[i] R[i, i] = i C[n+1, n] = 0 // 初始化平均查找次数表、子树根表 for d = 1 to n-1 do // d为二叉树节点数 for i = 1 to n-d do // n-d是为了控制j的取值 j = i + d minval = \\infty for k = i to j do // 遍历设置二叉树根节点 if C[i, k-1] + C[k+1, j] &lt; minval minval = C[i, k-1] + C[k+1, j] kmin = k R[i, j] = kmin sum = P[i] for s=i+1 to j do sum += P[s] C[i, j] = minval + sum return C[1, n], R 算法特点 算法效率 算法时间效率为立方级 算法空间效率为平方级 AVL TreeAVL树：要求其节点在左右子树高度差不能超过1的平衡二叉树 基本思想：总能通过一次简单的节点重排使树达到平衡 如果树插入操作使得一棵AVL树失去平衡，利用旋转对树作 变换 若有多个这样的节点，找出最靠近新插入的叶子节点不平衡 结点，然后旋转以该节点为根的子树 AVL树高度h即为其查找、插入效率 包含n个节点AVL树高度h满足 $\\lfloor log_2 n \\rfloor \\leq h &lt; 1.4405log_2(n+2) - 1.3277$ 最差情况下，操作效率$\\in \\Theta(logn)$ 平均而言，在n不是太小时，高度h平均为 $1.01log_2 n + 0.1$（几乎同折半查找有序数组） AVL树缺点（平衡代价），阻碍AVL树成为实现字典的标准结构 需要频繁旋转 维护树的节点平衡 总体比较复杂 旋转按照节点平衡符号进行旋转：+左旋、-右旋 单旋：不平衡节点、不平衡子节点不平衡因子符号相同 全为+：不平衡节点左旋 全为-：不平衡节点右旋 双旋：不平衡节点、不平衡子节点不平衡因子符号不同 先旋转不平衡子节点 再旋转不平衡节点 优先考虑最底层、不平衡节点 插入节点AVL树插入关键：查找不平衡节点 节点中应有存储其平衡因子的实例变量 插入过程中经过每个节点返回当前节点子树深度是否变化 比较节点平衡因子、子节点深度变化返回值判断是否平衡 插入过程中查询的每个节点都有可能不平衡 自下而上返回深度变化情况，优先旋转最底层不平衡节点 4种插入情况根据插入情况的不同，对最靠近新插入叶子节点的不平衡点T LL插入T左儿子L的左子树LL：平衡因子全- 即T到最底层叶节点（只可能有一个）的路径为LL（中间省略） R-rotation：右单转，对T做一次右旋即可平衡 RR插入T右儿子R的右子树R：平衡因子全+ 即T到最底层叶节点（只可能有一个）的路径为RR（中间省略） L-rotation：左单转，对T做一次左旋即可平衡 LR插入T左儿子L的右子树R：平衡因子-+ 即T到最底层叶节点（只可能有一个）的路径为LR（中间省略） LR-rotation：左右双转 先对左儿子L做一次左旋，变成LL模式 在LL模式下，再对T做一次右旋 RL插入T右儿子R的左子树L：平衡因子+- 即T到最底层叶节点（只可能有一个）的路径为RL（中间省略） RL-rotation：右左双转 先对右儿子R做一次右旋，变成RR模式 在RR模式下，再对T做一次左旋 实现删除节点 在AVL树中删除键相对而言比较困难，但也是对数级的 实现Red-Black Tree红黑树：能够容忍同一节点的一棵子树高度是另一棵的2倍 Splay Tree分裂树： 2-3树2-3树：可以包含两种类型的节点2节点、3节点，树的所有叶子节点 必须位于同一层 2-3树的高度即决定其查找、插入、删除效率 节点数为n的2-3数高度h满足 $log_3(n+1)-1 \\leq h \\leq log_2(n+1) - 1$ 最差、平均情况下，操作效率$\\in \\Theta(logn)$ 2-3树总是高度平衡 所有叶子节点位于同一层，即树根到其路径长度相同 2-3树平衡代价 树中节点可以有1或2个键，需要处理2种节点类型 拆分3节点的情况有很多种 节点类型 2节点：只包含1个键K、2个子女 左子女：作为所有键都小于K的子树的根 右子女：作为所有键都大于K的子树的根 3节点：两个有序键$K_1 &lt; K_2$、3个子女 最左边子女：作为键值小于$K_1$的子树的根 中间子女：作为键值位于$[K_1, K_2]$之间子树的根 最右边子女：作为键值大于$K_2$的子树的根 类似的还有2-4树 查找 如果根是2节点，当作二叉树查找 若K等于根键值，停止 若K小、大于根键值，在左、右子树中查找 若根是3节点 和两个键值比较，有相等，停止 否则能确定应该在3棵子树中哪棵继续查找 插入节点除非是空树，否则总是把新键K插入叶子节点中 查找K确定合适的插入位置（叶子节点） 若叶子节点2节点，根据大小关系将K作为第一个键或第二个键 插入 若叶子节点3节点，把叶子分裂为两个节点：3个键中最小的放入 第一个叶子中，最大的放入第二个叶子中，中间的键提升到原 叶子节点父母中 若叶子就是根，则需要创建新根容纳中间键 中间键的提升可能会导致父母节点分裂，并引起祖先链条上 多个节点的分裂 删除节点B树B树：允许节点可以有$1~m-1$个键（$2~m$个子女） 1234567#define BTREE_Mtypedef struct BTNode{ unsigned int degree; // 节点实际包含键数 KeyType key_slots[BTREE_M-1]; // 节点存储键数组 struct BTNode ptr_slots[BTREE_M]; // 指向子女节点指针 struct BTNode * ptr_parent; // 父节点指针}BTNode, *BTNodePtr; $m$：B树阶数，节点允许最大子女数 节点最多允许有$m-1$个条目 $m=2$即为二叉树、$m=3$即为2-3树 键：用于构建树的关键字，和具体条目类似于键值对 根节点具有$2~m$个子女，除非为叶子节点 非根、非叶节点具有$[\\lceil m/2 \\rceil, m]$个子女 即具有$[\\lceil m/2 \\rceil - 1, m]$个有序键 其中子树$T_0$所有键小于$K_1$，子树$T_1$中所有键大于 等于$K_1$小于 $K_2$，以此类推 B树是完美平衡的：所有叶子节点在同一层上 查找算法 输入：B树、目标查找键 输出：查找键所属B树节点（若存在） 从根节点开始，比较查找键k和节点中键序列大小 节点中键有序，若B树阶数足够大，可考虑折半查找 若在节点键序列中找到匹配键，则查找成功、返回 否则根据比较结果选择合适分支，顺着指针链前进，在相应子女 节点中进行查找 1234567891011121314151617BTreeSearch(T, k): // 在B树中搜索键 // 输入：B树根节点T、目标查找键k // 输出：目标键所在节点、目标键在节点中序号 i = 0 cur = T // 遍历寻找目标键对应键、分支 while i &lt; cur.degree and k &gt; cur.key_slots[i]: i += 1 if i &lt; cur.degree and k == cur.key_slots[i]: return cur, i elif cur.is_leaf(): // 未找到目标键 return cur, -1 else: return BTreeSearch(cur.ptr_slots[i], k) 分裂算法 输入：待分裂节点父节点、待分裂节点序号 计算待分裂节点分裂中心 将分裂中心右侧数据移动至新节点 将节点分裂中心、新节点提升至父节点 123456789101112131415161718192021222324252627BTreeNodeSplit(T, ptr_idx): // 分裂B树中节点 // 输入：待分裂节点父节点`T`、待分裂节点序号`ptr_idx` nnode = BTreeNode() fnode = T.ptr_slots[ptr_idx] // 分裂中心 mid = fnode.degree // 2 // 复制右半部分键至新节点 nnode.key_slots[:fnode.degree - mid] = fnode.key_slots[mid:fnode.degree] fnode.key_slots[mid:fnode.degree] = NULL // 若原节点非叶子节点，复制右半部分指针至新节点 if not fnode.is_leaf(): nnode.ptr_slots[:fnode.degree + 1 - mid] = fnode.ptr_slots[mid: fnode.degree + 1] fnode.ptr_slots[mid: fnode.degree+1] = NULL // 修改两节点度 nnode.degree = fnode.degree - mid fnode.degree = mid // 将分裂中心提升至父节点 // 修改父节点指向子女节点指针 T.key_slots.insert(fnode.key_slots[mid], ptr_idx) T.ptr_slots.insert(nnode, ptr_idx+1) // 原节点指针不变 插入 输入：B树根T、待插入键K 假设B树中不存在键K，否则查找、更新对应值即可 根据需要插入键K，查找需要插入的叶子节点L 若叶子节点L键数小于m-1，直接插入结束 否则以叶子节点键值中位数mid为中心分裂 将mid插入叶子节点L父节点P中 将mid左子支指向分裂后左子树、右子支指向分裂后右子树 对父节点尝试操作 12345678910111213BTreeInsert(T, k) // 向B树中插入不存在键K // 输入：B树根T、待插入键k // 找到键`k`应该插入的叶子节点`L` L, _ = BTreeSearch(T, k) L.key_slots.insert_in_order(k) // 若节点已满、须分裂 while L.is_full(): BTreeNodeSplit(L.parent_ptr, L.get_index()) L = L.parent_ptr 此实现是考虑节点都有空位容纳新键，节点插入新键后再 判断是否需要分裂 删除#todo应用 类似一般查找树，把数据记录插入初始为空的树中构造B树 B+树B+树：B树的一种变形树 其中非叶节点只有索引作用，跟记录相关信息均存放在 叶结点中 B+树中所有叶结点构成有序链表，可以按照键次序遍历 查找算法 从根开始，比较查找键K和节点中键大小，选择合适指针，顺着 指针链前进 指针链指向可能包含查找键的叶子节点，在其中查找K 父母节点、叶子节点都是有序的，如果B树次数足够 大，可以考虑使用折半查找 算法效率以B树作索引存储大型数据文件为例 查找指定查找键访问B树节点数量为B树高度$h+1$ （即磁盘访问次数） 次数为m、高度为h的B树能够包含最少节点数为 $n \\geqslant 4 \\lceiling m/2 \\rceiling ^ {h-1} -1$， 即$h \\leqslant \\lfloor log_{[m/2]} \\frac {n+1} 4 \\rfloor + 1$ 所以在B树中查找，访问磁盘次数$\\in O(logn)$ 实际应用中，磁盘访问次数很少超过3，因为B树的根、甚至 是第一层节点会存储在内存中减少磁盘访问次数 插入算法 查找新记录键K对应的叶子节点 若叶子节点中还有空间存放此记录，在保持键有序的情况下插入 若节点中没有空间 将节点分裂，后半部分记录放在新节点中 新节点中最小键$K^{‘}$、指向其的指针插入原叶子节点 父母节点中（原叶子节点键、指针之后） 插入过程可以一直回溯到树根，甚至直到树根分裂 其他考虑 查找新记录对应叶子节点时就分裂满节点，可以避免递归分裂 将满叶子节点中部分键移动给兄弟节点，同时替换父母节点中的 键值（保证B树特点），增加少许复杂度以节约空间 算法特点 算法效率 算法时间效率$\\in O(logn)$ 应用 B+树是存储结构化记录数据集合最重要的索引结构 所有数据记录（键）按照升序存储在叶子节点中，其父母 节点作为索引 B+树中节点常常对应磁盘中页 考虑到访问磁盘页面是比较内存中键值比较时间多好几个 数量级，磁盘访问次数是衡量B树效率的主要指标 标","link":"/Algorithm/Data-Structure/tree_search.html"},{"title":"查找","text":"总述在给定的集合、多重集（允许多个元素具有相同的值）中找给定值 （查找键，search key） 顺序搜索 折半查找：效率高但应用受限 将原集合用另一种形式表示以方便查找 评价没有任何一种查找算法在任何情况下都是最优的 有些算法速度快，但是需要较多存储空间 有些算法速度快，但是只适合有序数组 查找算法没有稳定性问题，但会发生其他问题 如果应用里的数据相对于查找次数频繁变化，查找问题必须结合 添加、删除一起考虑 必须仔细选择数据结构、算法，以便在各种操作的需求间达到 平衡 无序线性表查找顺序查找算法 将给定列表中连续元素和给定元素查找键进行比较 直到遇到匹配元素：成功查找 匹配之前遍历完整个列表：失败查找 123456789101112SequentialSearch(A[0..n-1], K) // 顺序查找，使用**查找键作限位器** // 输入：n个元素数组A、查找键K // 输出：第一个值为K的元素位置，查找失败返回-1 A[n] = K i = 0 while A[i] != K do i = i + 1 if i &lt; n return i else return -1 改进 将查找键添加找列表末尾，查找一定会成功，循环时将不必每次 检查是否到列表末尾 如果给定数组有序：遇到等于（查找成功）、大于（查找失败） 查找键元素，算法即可停止 二叉查找树算法 对数组构建二叉查找树 在二叉查找树上进行查找 特点 算法效率：参见二叉查找树 构建二叉查找树（插入）和查找操作基本相同，效率特性也相同 减可变规模 + 输入增强 预排序查找对线性表预排序，有序表中查找速度快得多 算法1234567PreorderSearch(A[0..n-1]) // 对数组预排序然后查找 // 输入：可排序数组A[0..n-1] // 输出：元素在数组中的位置 对B[(数组元素, 索引)]进行预排序 使用折半查找寻找二元组 返回二元组中索引 特点 算法时间效率：取决于排序算法 查找算法在最差情况下总运行时间$\\in \\Theta(nlogn)$ 如果需要在统一列表上进行多次查找，预排序才值得 这种预排序思想可以用于众数、检验惟一性等， 此时算法执行时间都取决于排序算法 （优于蛮力法$\\in \\Theta(n^2)$） 变治法（输入增强） 预排序检验唯一性123456789PresortElementUniqueness(A[0..n-1]) // 先对数组排序，求解元素唯一性问题 // 输入：n个可排序元素构成数[0..n-1] // 输出：A中有相等元素，返回true，否则false 对数组排序 for i=0 to n-2 do if A[i] = A[i+1] return false return true 预排序求众数12345678910111213141516171819PresortMode(A[0..n-1]) // 对数组预排序来计算其模式（众数） // 输入：可排序数组A[0..n-1] // 输出：数组模式 对数组A排序 i = 0 modefrequency = 0 while i &lt;= n-1 do runlength = 1 runvalue = A[i] while i + runlength &lt;= n-1 and A[i+runlength] == runvalue // 相等数值邻接，只需要求出邻接次数最大即可 runlength = runlength+1 if runlength &gt; modefrequency modefrequency = runlength modevalue = runvalue i = i+runlength return modevalue 有序顺序表查找 有序顺序表的查找关键是利用有序减规模 但关键不是有序，而是减规模，即使顺序表不是完全有序， 信息足够减规模即可 折半查找/二分查找二分查找：利用数组的有序性，通过对查找区间中间元素进行判断， 缩小查找区间至一般大小 依赖数据结构，需能够快速找到中间元素，如数组、二叉搜索树 一般模板：比较中间元素和目标的大小关系、讨论 123456789left, right = ...while condition(search_space is not NULL): mid = (left + right) // 2 if nums[mid] == target: // do something elif nums[mid] &gt; target: // do something elif nums[mid] &lt; target: // do somthing 函数独立时，找到target可在循环内直接返回 函数体嵌入其他部分时，为方便找到target应break， 此时涉及跳出循环时target可能存在的位置 找到target中途break 未找到target直到循环终止条件 基本版123456789101112131415161718192021BinarySearchEndReturnV1(nums[0..n-1], target): // 非递归折半查找基本版，不直接返回，方便嵌入 // 输入：升序数组nums[0..n-1]、查找键target // 输出：存在返回数组元素下标m，否则返回-1 left, right = 0, n-1 while left &lt;= right: mid = (left + right) // 2 if nums[mid] == target: break elif nums[mid] &lt; target: left = mid+1 else: right = mid-1 else: assert(mid == right == left-1) # 仅最后返回，方便嵌入，下同 if nums[mid] == target: return mid else: return -1 输入判断：无需判断输入列表是否为空 终止条件保证不会进入，即不会越界 初始条件：left, right = 0, n-1 左、右均未检查、需检查 即代码中查找区间为闭区间$[left, right]$，此时 搜索区间非空 中点选择：mid = (left + right) // 2 向下取整 对此版本无影响，left、right总是移动，不会死循环 循环条件：left &lt;= right 搜索区间为闭区间，则相应检查条件为left &lt;= right， 否则有元素未被检查 在循环内left、right可能重合 更新方式：left=mid+1, right=mid-1 为保证搜索区间始终为闭区间，需剔除mid 终止情况：right=left-1、mid=left/right 循环条件、循环内部+1保证：上轮循环left==right 越界终止情况：左、右指针均剔除mid，两侧均可能越界 mid=right=n-1, left=n mid=left=0, right=-1 target位置 若存在target：必然在mid处，循环结束只需判断mid 若不存在target target位于[right, left]间 left=mid+1=right+1表示小于target元素数量 需要和左右邻居（查找结束后）、left、right比较 情况下，容易考虑失误，不适合扩展使用 高级版11234567891011121314151617BinarySearchV2(nums[0..n-1], target): left, right = 0, n while left &lt; right: mid = (left + right) // 2 if nums[mid] == target: break elif nums[mid] &lt; target: left = mid+1 else: right = mid else: assert(mid-1 == left == right) if nums[mid] == target: return mid else: return -1 输入判断：无需判断输入列表是否为空 终止条件保证不会进入，即不会越界 初始条件：left, right = 0, n 左未检查、需检查，右无需检查 即代码中查找区间为左闭右开区间$[left, right)$ 中点选择：mid = (left + right) // 2 向下取整 此处必须选择向下取整，否则left=right-1时进入死循环 即：循环内检查所有元素，取整一侧指针必须移动 循环条件：left &lt; right 搜索区间为左闭右开区间，则检查条件为left &lt; right， 此时搜索区间非空 在循环内left、right不会重合 更新方式：left=mid+1, right=mid 为保证搜索区间始终为左闭右开区间 移动左指针时需剔除mid 移动右指针时无需剔除mid 终止情况：right=left、mid=left/left-1 循环条件、循环内部+1保证：上轮循环 left+1=mid=right-1 left=mid=right-1 越界终止情况：仅左指针剔除mid，仅可能右侧越界 left=right=n=mid+1 target位置 若存在target：必然在mid处，循环结束只需判断mid 若不存在target left=mid=right：循环过程中target可能已不在 搜索区间中，最终位于(mid-1, mid) mid+1=left=right：(mid, left) left表示小于target元素数量 高级版2123456789101112131415161718BainarySearchEndReturnV3(nums[0..n-1], target): // 折半查找，保持左右指针顺序、不重合 // 输入：升序数组nums、查找键target // 输出：存在返回数组元素下标m，否则返回-1 left, right = -1, n while left &lt; right: mid = (left + right + 1) // 2 if nums[mid] == target: break elif nums[mid] &lt; target: right = mid-1 else: left = mid if nums[mid] == target: return mid else: return -1 输入判断：无需判断输入列表是否为空 终止条件保证不会进入，即不会越界 初始条件：left, right = -1, n-1 左无需检查，右未检查、需检查 即代码中查找区间为左开右闭区间$(left, right]$ 中点选择：mid = (left + right + 1) // 2 向上取整 此处必须选择向上取整，否则left=right-1时进入死循环 （或放宽循环条件，添加尾判断） 即：循环内检查所有元素，取整一侧指针必须移动 循环条件：left &lt; right 搜索区间为左开右闭区间，则检查条件为left &lt; right， 此时搜索区间非空 在循环内left、right不会重合 更新方式：left=mid, right=mid+1 为保证搜索区间始终为左闭右开区间 移动右指针时需剔除mid 移动左指针时无需剔除mid 终止情况：left=right、mid=left/left+1 循环条件、循环内部+1保证：上轮循环 left+1=mid=right-1 left+1=mid=right 越界终止情况：仅右指针剔除mid，仅可能左侧越界 left=right=-1=mid-1 target位置 若存在target：必然在mid处，循环结束只需判断mid 若不存在target left=mid=right：循环过程中target可能已不在 搜索区间中，最终位于(right, right+1) mid+1=left=right：(left, right) left+1表示小于target元素数量 高级版3123456789101112131415161718BinarySearchEndReturnV2(nums[0..n-1], target): // 折半查找，保持左右指针顺序、不重合 // 输入：升序数组nums、查找键target // 输出：存在返回数组元素下标m，否则返回-1 left, right = -1, n while left &lt; right-1: mid = (left + right) // 2 if nums[mid] == target: break elif nums[mid] &lt; target: left = mid else: right = mid if nums[mid] == target: return mid else: return -1 输入判断：无需判断输入列表是否为空 终止条件保证不会进入，即不会越界 初始条件：left, right = -1, n 左、右均无需检查 即代码中查找区间为开区间$(left, right)$ 中点选择：mid = (left + right) // 2 向下取整、向上取整均可 循环条件：left &lt; right-1 搜索区间为左开右闭区间，则检查条件为left &lt; right-1， 此时搜索区间非空 在循环内left、right不会重合 更新方式：left=mid, right=mid 循环终止条件足够宽泛，不会死循环 终止情况：left=right-1、mid=right/right-1 循环条件、循环内部+1保证：上轮循环 left+1=mid=right-1 越界终止情况：左右初始条件均越界，则左、右均可能越界 mid=left=n-1、right=n left=-1、mid=right=0 target位置 若存在target：必然在mid处，循环结束只需判断mid 若不存在target target始终在搜索区间(left, right)内 最终位于(left, right) 高级版1-原1234567891011121314151617181920212223242526BinarySearchKeep1(nums[0..n-1], target): // 折半查找，保持左右指针顺序、不重合 // 输入：升序数组nums、查找键target // 输出：存在返回数组元素下标m，否则返回-1 if n == 0: return -1 left, right = 0, n-1 while left &lt; right - 1: mid = floor((left + right) / 2) if nums[mid] == target: return mid elif nums[mid] &lt; target: right = mid else: left = mid // post-procesing if nums[left] == target: return left if nums[right] == target: return right return -1 初始条件：left = 0, right = n-1 终止情况：left = right - 1 指针移动：left = mid, right= mid 关键特点 n&gt;1时left、mid、right循环内不会重合 mid可以left、right任意比较，无需顾忌重合 需要和左右邻居、left、right比较时适合使用 扩展使用需要进行真后处理，对left、right进行判断 终止情况：left = right - 1 循环过程中会保证查找空间至少有3个元素，剩下两个 元素时，循环终止 循环终止后，left、right不会越界，可以直接检查 target位置 若存在target，可能位于mid、left、right mid：因为找到nums[mid]==target跳出 left：left=0，循环中未检查 right：right=n-1，循环中未检查 不存在target，则target位于(left, right)之间 适合访问目标在数组中索引、极其左右邻居 仅仅二分查找的话，后处理其实不能算是真正的后处理 nums[mid]都会被检查，普通left、right肯定不会 是target所在的位置 真正处理的情况：target在端点 left=0, right=1终止循环，left=0未检查 left=n-2, right=n-1终止循环，right=n-1未检查 即这个处理是可以放在循环之前进行处理 高级版2-原1234567891011121314151617181920212223BinarySearchKeep0(nums[0..n-1], target): // 折半查找，保证左右指针不交错 // 输入：升序数组nums、查找键target // 输出：存在返回数组元素下标m，否则返回-1 if n == 0: return -1 left, right = 0, n while left &lt; right: mid = floor((left + right) / 2) if nums[mid] == target: return mid elif nums[mid] &lt; target: left = mid + 1 else: right = mid // post-processing if left != len(nums) and nums[left] == target: return left return -1 初始条件：left = 0, right = n，保证n-1可以被正确处理 终止情况：left = right 指针移动：left = mid + 1, right = mid 中点选择对此有影响，指针移动行为非对称，取ceiling则 终止情况还有left = right + 1 关键特点 left、right循环内不会重合 由于floor的特性，mid可以right任意比较，无需 顾忌和right重合 需要和右邻居、right比较时适合使用 终止情况：left = right 循环过程中会保证查找空间至少有2个元素，否则循环 终止 循环终止条件导致退出循环时，可能left=right=n越界 target位置 若存在target，可能位于mid、left=right 若不存在target，则target位于(left-1, left) 适合访问目标在数组中索引、及其直接右邻居 仅二分查找，甚至无需后处理 判断nums长度在某些语言中也可以省略 高级版3-原1234567891011121314151617181920212223BinarySearchNoKeep(nums[0..n-1], target): // 折半查找，保证左右指针不交错 // 输入：升序数组nums、查找键target // 输出：存在返回数组元素下标m，否则返回-1 if n == 0: return -1 left, right = -1, n-1 while left &lt; right - 1: mid = floor((left + right) / 2) if nums[mid] == target: return mid elif nums[mid] &lt; target: left = mid else: right = mid - 1 // post-processing if right &gt;= 0 and nums[right] == target: return right return -1 初始条件：left = -1, right = n-1 终止情况：left = right、left = right + 1 指针移动：left = mid, right = mid - 1 中点选择对此有影响，指针移动行为非对称，取ceiling则 同高级版本2 终止条件：left = right、left = right - 1 循环过程中保证查找空间至少有3个元素，否则循环 终止 由于floor特性，必须在left &lt; right - 1时即终止 循环，否则可能死循环 循环终止后，left=right=-1可能越界 target位置 若存在target，可能位于mid、left=right 若不存在target，则target位于(left, left+1) 适合访问目标在数组中索引、及其直接左邻居 此版本仅想实现二分查找必须后处理 终止条件的原因，最后一次right=left + 1时未被检查 即退出循环 可能在任何位置发生，不是端点问题 特点 前两个版本比较常用，最后两个版本逻辑类似 折半查找时间效率 最坏情况下：$\\in \\Theta(log n)$ 平均情况下仅比最差稍好 就依赖键值比较的查找算法而言，折半查找已经是最优算法 ，但是插值算法、散列法等具有更优平均效率 减常因子因子法 插值查找Interpolation Search：查找有序数组，在折半查找的基础上考虑 查找键的值 算法 假设数组值是线性递增，即数字值~索引为一条直线，则根据 直线方程，可以估计查找键K在A[l..r]所在的位置 x = l + \\left \\lfloor \\frac {(K-A[l])(r-l)} {A[r] - A[l]} \\right \\rfloor 若k == A[x]，则算法停止，否则类似折半查找得到规模更小的 问题 特点 即使数组值不是线性递增，也不会影响算法正确性，只是每次 估计查找键位置不够准确，影响算法效率 统计考虑 折半插值类似于非参方法，只考虑秩（索引）方向 插值查找类似参数方法，构建了秩（索引）和数组值模型， 但是线性关系基于假设 如果模型错误可能会比折半查找效率更差，即在数据分布 分布偏差较大的情况下非参方法好于参数方法 所以是否可以考虑取样方法，先取5个点构建模型，然后估计 算法效率 对随机列表，算法比较次数小于$log_2log_n+1$ 最差情况，比较次数为线性，没有折半查找稳定 Robert Sedgewick的Algorithms中研究表明，对较小文件 折半查找更好，大文件、比较开销大插值查找更好 减可变规模 子串匹配蛮力字符串匹配算法 将pattern对齐文本前m个字符，从左向右匹配相应字符 m个字符全部匹配，匹配成功，算法停止 遇到不匹配字符则 模式右移1位，然后从模式首个字符开始重复以上匹配 在n-m位置无法匹配成功，则无足够匹配字符，算法停止 123456789101112BruteForceStringMatch(T[0..n-1], P[0..m-1]) // 蛮力字符串匹配 // 输入：文本T：n个字符的字符数组 // 模式：m个字符的字符数组 // 输出：查找成功返回文本第一个匹配子串中第一个字符位置 for i = 0 to m-m do j = 0 while j &lt; m and P[j] = T[i+j] do j = j + 1 if j = m return i return -1 特点 最坏情况下，算法比较次数属于$O(nm)$ 即在移动模式之前，算法需要做足m次比较 但是一般在自然语言中，算法平均效率比最差好得多 在随机文本中，有线性效率 Horspool算法算法从右往左匹配，在任意位置匹配不成功时只考虑 同模式最后字符匹配的文本字符c，确定安全移动距离，在 不会错过匹配子串的情况下移动最长距离 如果c在模式中出现，则模式移动到其最后c至同文本中c 匹配 否则移动模式长度m 特别的，如果c只在模式最后字符出现，则也应该移动m 算法 对给定长度m的模式及文本中用到的字母表，构造移动表t 将模式同文本开始对齐 重复以下过程直至发了了匹配子串或模式达到了文本字符外 从模式最后字符开始，比较模式、文本相应字符 若m个字符匹配，停止 遇到不匹配字符c，若为当前文本中和模式最后匹配字符 对齐的字符，将模式移动t(c)个字符 1234567891011ShiftTable(P[0..m-1]) // 用Horspool算法、Boyer-Moore算法填充移动表 // 输入：模式P[0..m-1]、可能出现字符表 // 输出：以字符表为为索引的数组Table[0..size-1] for i=0 to size-1 do Table[i] = m // 初始化所有字符对应移动距离为m for j=0 to m-2 do Table[P[j]] = m - 1 - j // 对模式中存在的字符重新计算移动距离 return Table 123456789101112131415HorspoolMatching(P[0..m-1], T[0..n-1]) // 实现Horspool字符串匹配算法 // 输入：模式P[0..m-1]、文本T[0..n-1] // 输出：第一个匹配子串最左端字符下标，未匹配返回-1 Table = ShiftTable(P[0..m-1]) i = m - 1 while i &lt;= n-1 do k = 0 while k &lt;= m-1 and P[m-1-k]=T[i-k] do k = k+1 if k == m return i-m+1 else i = i+Table[T[i]] return -1 特点 算法效率 最差情况下模式为相同字符，效率$\\in O(nm)$ 对随机文本效率$\\in O(n)$ 输入增强 Boyer-Moore算法 坏符号移动：模式、文本中相应不匹配字符确定的移动 （不是Horspool中简单根据最后字符确定移动） 好后缀移动：模式、文本匹配的后缀确定的移动 算法 对给定长度m的模式及文本用到的字母表，构造坏符号移动表t 对给定长度m的模式构造后缀移动表 将模式与文本开始处对齐 重复以下直到找到匹配子串或模式达到文本字符以外 从模式最后字符开始比较模式、文本相应字符 所有m个字符匹配，则停止 若c是不匹配字符，移动坏符号表、后缀移动表决定的 距离较大者 12345BadSymbolShift(P[0..m-1]) // 创建坏符号移动表 // 输入：模式P[0..m-1] // 输出：坏符号移动表 特点 算法效率 算法效率最差也是线性的 输入增强 KMP算法算法从左往右匹配，失败时不回溯指针，利用已经得到的 部分匹配结果尽可能将模式滑动一段距离，从模式中间next 字符开始比较 next[i] = \\left \\{ \\begin{array} {l} -1 & i=0 \\\\ Max\\{k|0","link":"/Algorithm/Problem/searching.html"},{"title":"排序","text":"总述 按照升序重新排列给定列表中的数据项 为了让问题有意义，列表中的数据项应该能够排序（数据之间 有一种全序关系） 键：在对记录排序时，需要选取的、作为排序的依据的一段信息 目的 排序可能是所求解的问题输出要求 排序能够更方便的求解和列表相关的问题 查找问题 在其他领域的重要算法中，排序也被作为辅助步骤 发展 排序领域已经有很多不错的算法，只需要做$nlog_{x}^{n}$次 比较就能完成长度为$n$的任意数组排序，且没有一种基于 键值比较（相较于比较键值部分内容而言）的排序算法能 在本质上操作其， 但是还是需要不断探寻新的算法虽然有些算法比其他的要好， 但是没有任何算法在任何情况下是最优的 有些算法比较简单，但速度较慢 有些算法适合随机排列的输入，而有些适合基本有序的列表 有些算法适合驻留在快速存储器中的列表，而有些适合存储 在磁盘上的大型文件排序 评价 稳定性：排序算法保留等值元素在输入中的相对顺序 一般来说，将相隔很远的键交换位置的算法虽然不稳定， 但往往很快 在位性：排序算法不需要额外的存储空间，除极个别存储单元外 线性表排序选择排序 每轮选择出剩余元素中最小值，放在对于位置上 顺序表算法12345678910SelectionSort(A[0..n-1]): // 选择排序排序数组 // 输入：可排序数组A[0..n-1] // 输出：升序排序数组A[0..n-1] for i = 0 to n-1 do min = i for j = i to n-1 do if A[j] &lt; A[min] min = j swap A[i] and A[min] 扫描整个列表找到最小元素，然后和首个元素交换，将其放在 最终位置上 从第2个元素开始寻找之后最小元素，和第2个元素交换，将其 放在最终位置上 重复n-1次，列表有序 链表算法1234567891011121314151617181920212223242526272829303132333435363738394041424344SelectionSort(linked): // 选择排序排序链表 // 输入：可排序链表linked头 // 输出：排序后链表头 if linked == NULL: return NULL linked_head = ListNode() // 为方便附设头结点 linked_head.next = linked unsorted_head = linked_head // 未排序头结点 // 后续过程中是链表中元素 while unsorted_head.next != NULL: cur_node = unsorted_head min_node = unsorted_head // 全是链表中元素 while cur_node.next != NULL: if cur_node.next.val &lt; min_node.next.val: min_node = cur_node cur_node = cur_node.next // 若`min_node.next`就是`unsorted_start.next`，以下 // 代码中的断开、重组链表操作会出现环 // 完全切开再重组链表，则需要判断`unsorted_start` // 是否为空 if unsorted_start.next != min_node.next: _tmp_node = unsorted_head.next // 记录原`unsorted_head.next` unsorted_head.next = min_node.next // `unsorted_head.next`断开、连接`min_node` min_node.next = min_node.next.next // `min_node.next`断开、跳过`min_node`重连 // 若`min_node.next`是`unsorted_start.next` // 会断开`unsorted_start`和`min_node` unsorted_head.next.next = _tmp_node // 原`min_node`重连原`unsorted_head.next` unsorted_start = unsorted_start.next return linked_head.next 特点 对任何输入，选择排序键值比较都是$\\Theta(n^2)$ 键交换次数仅为$\\Theta(n)$ 选择排序此特性优于许多其他排序算法 冒泡排序 比较表中相邻元素，如果逆序就交换位置 重复多次则最大元素被“沉到”列表最后位置 第2轮比较将第2大元素“沉到”其最终位置 重复比较n-1轮，列表有序 顺序表算法12345678BubbleSort(A[0..n-1]): // 冒泡排序排序数组 // 输入：可排序数组A[0..n-1] // 输出：升序排序数组A[0..n-1] for i = 0 to n-2 do for j = 0 to n-2-i do if A[j+i] &lt; A[j] swap A[j] and A[j+1] 链表算法1234BublleSort(head): // 冒泡排序排序链表 // 输入：可排序链表首个元素 // 输出：排序后列表首个元素 特点 对任何输入，冒泡排序键值比较都是$\\Theta(n^2)$ 其交换次数取决于特定输入 最坏情况是遇到降序排列数组，此时键交换次数同比较次数 冒泡排序看起来就像是选择排序的一直交换+最大优先版本 改进 如果对列表比较一轮后没有交换任何元素，说明列表有序，可以 结束算法 Insertion Sort插入排序：利用减一技术对数组$A[0..n-1]$进行排序 算法 假设对较小数组$A[0..i-2]$排序已经解决 从右至左（方便将将元素右移）扫描有序子数组，直到遇到首个 小于等于$A[i-1]$元素，将$A[i-1]$插入其后 123456789101112InsertionSort(A[0..n-1]) // 用插入排序对给定数组排序 // 输入：n个可排序元素构成数组 // 输出：非降序排序数组 for i = 1 to n-1 do v = A[i] j = i - 1 while j &gt;= 0 and A[j] &gt; v do A[j+1] = A[j] j = j - 1 A[j+1] = v // 上一步比较元素已经赋值给其后，所以应该覆盖其值 特点 插入排序是自顶向下基于递归思想，但是自底向上使用迭代实现 算法效率更高 算法时间效率 算法基本操作是键值比较，比较次数依赖于特定输入 最坏情况（递减数组）下：每轮比较次数都到达最大，此时 键值比较次数$\\in \\Theta(n^2)$ 最优情况（递增数组）下：每轮比较次数仅为1，此时键值 比较次数$\\in \\Theta(n)$ 对随机序列：比较次数$\\in \\Theta(n^2)$ 许多应用中都会遇到基本有序的文件，插入排序能保证良好 性能 减常量法 Shell Sort插入排序的扩展，Shell排序基于h有序 H有序数组中任意间隔为h的元素都是有序的，对应的数组称为h有序数组 h有序数组：就是h个互相独立的有序数组编织在一起数组 h有序数组具有分离、局部有序的特点 算法 使用插入排序对h子数组独立排序，每次交换相隔h的元素 h逐渐减小到1，shell排序退化（最后一轮）为插入排序 1234567891011121314151617ShellSort(A[0..n-1]) // 用插入排序对给定数组排序 // 输入：n个可排序元素构成数组 // 输出：非降序排序数组 h = 1 while h &lt; n/3 h = h*3 + 1 // 获取初始h值，之后每轮h变为1/3 while h &gt;= 1: for i = h to n-1: v = A[i] j = i - h while j &gt;= 0 and A[j] &gt; v do A[j] = A[j-h] j = j - h A[j+h] = v h = h/3 特点 Shell排序全衡量子数组规模、有序性，更加高效 h递增序列 子数组部分有序程度取决于h递增序列的选择 不同的h递增序列对算法效率有常数倍的变动，但是在实际 应用中效果不明显 Shell排序是唯一无法准确描述其对于乱序数组性能特征的排序 方法 减常量法 归并排序Mergesort 将需要排序的数组A[0..n-1]均分的 对两个子数组递归排序，然后把排序后的子数组合并为有序 数组 12345678910Mergesort(A[0..n-1]): // 递归调用MergeSort对数组排序 // 输入：可排序数组A[0..n-1] // 输出：非降序排列数组A[0..n-1] if n &gt; 1: copy A[0..floor(n/2)-1] to B[0..floor(n/2)-1] copy A[floor(n/2)..n-1] to C[0..ceiling(n/2)-1] Mergesort(B[0..floor(n/2)-1]) Mergesort(C[0..ceiling(n/2)-11]) Merge(B, C, A) Merge 初始两只指针指向待合并数组首个元素 比较两个元素大小，将较小元素添加到新数组中，被复制元素 的数组指针右移 重复直到某一数组处理完毕，将未处理完数组复制到新数组尾部 12345678910111213141516Merge(B[0..p-1], C[0..q-1], A[0..p+q-1]): // 将两个有序数组合并为新的有序数组 // 输入：有序数组B[0..p-1]、C[0..q-1] // 输出：存放有B、C中元素的有序数组A[0..p+q-1] while i &lt; p and j &lt; q: if B[i] &lt;= C[j] A[k] = B[i] i = i + 1 else: A[k] = C[j] j = j + 1 k = k + 1 if i == p: copy C[j..q-1] to A[k..p+q-1] else: copy B[i..p-1] to A[k..p+q-1] 特点 算法时间效率 最坏情况下比较次数$\\in \\Theta(nlogn)$，为 $nlog_2n-n+1$，十分接近基于比较的排序算法理论上能够 达到的最少次数 相较于快排、堆排序 合并排序比较稳定，缺点在于需要线性额外空间 虽然能做到在位，但是算法过于复杂，只具有理论上意义 算法可以自底向上合并数组的元素对，再合并有序对 这可以避免使用堆栈递归调用时时空开销 可以把数组划分为待排序的多个部分，再对其递归排序，最后 合并在一起 这尤其适合对存在二级存储空间的文件进行排序 也称为Multiway Mergesort 分治算法 快速排序相较于合并排序按照元素在数组中的位置进行划分，快速排序按照 元素值对其进行划分 Quicksort 对数组中元素重新排列，使得A[s]左边元素均小于A[s]，A[s] 右边元素都大于等于A[s] 此时A[s]已经位于它在有序数组中的最终位置 接下来对A[s]左右子数组进行排序 12345678Quicksort(A[l..]r) // 对给定可比较数组进行排序 // 输入：可比较数组A[0..n-1]子数组A[l..r] // 输出：非降序排序的子数组A[l..r] if l&lt;r s = partition(A[l..r]) Quicksort(A[l..s-1]) Quicksort(A[s+1..r]) 特点 需要选择合适的划分算法J LomutoPartition HoarePartition 算法效率 最优情况：分裂点都位于数组中点，算法比较次数为 $nlog_2n$ 最差情况：分裂点都趋于极端（逆序输入），算法比较 次数$\\in \\Theta(n^2)$ 平均：比较次数为$2nlnn \\approx 1.39nlog_2n$ 且算法内层循环效率非常高，在处理随机排列数组时，速度 比合并排序快 快速排序缺点 不稳定 需要堆栈存储未被排序的子数组参数，尽管可以先对较短 子数组排序使得堆栈大小降低到$O(logn)$，但是还是比 堆排序的$O(1)$差 仍然存在最差情况出现的可能性，即使有很多巧妙地中轴 选择办法 对随机数组排序性能的好坏，不仅与算法具体实现有关， 还和计算机系统结构、数据类型有关 分治算法 算法改良 更好的中轴选择方法 randomized quicksort：随机快速排序，使用随机元素作为 中轴 median-of-three method：三平均划分法，以数组最左边、 最右边、最中间的中位数作为中轴 子数组足够小时（5~15），改用插入排序；或者直接不对小数组 排序，而是在快速排序结束后使用插入排序对整个近似有序的 数组进行排序 改进划分方法 三路划分：将数组划分为3段，小于、等于、大于中轴元素 比较计数排序算法 遍历待排序列表中每个元素 计算、记录列表中小于该元素的元素个数 更新大于其的元素的小于元素的元素个数 1234567891011121314ComparisonCountingSort(A[0..n-1]) // 用比较计数法排序 // 输入：可排序数组A[0..n-1] // 输出：将A中可排序数组按照升序排列数组 for i = 0 to n-1 do count[i] = 0 for i = 0 to n-2 do for j = i+1 to n-1 do if A[i] &lt; A[j] count[j] += 1 else count[i] += 1 for i = 0 to n-1 do S[count[i]] = A[i] 特点 算法效率 算法比较次数为$n(n-1)/2$ 占用了线性数量的额外空间 算法使得键值的可能移动次数最小化，能够直接将键值放在在 有序数组最终位置 输入增强 分布计数排序 待排序元素来自于某个已知小集合$[l..u]$ 算法 扫描列表，计算、存储列表中元素出现频率于数组$F[l..u]$中 再次扫描列表，根据值填入相应位置 1234567891011121314151617DistributionCountingSort(A[0..n-1], l, u): // 分布计数法排序，对元素来自有限范围整数的数组排序 // 输入：数组[0..n-1]，数组中整数位于l、u间 // 输出：A中元素构成非降序数组S[0..n-1] for j = 0 to u-l do D[j] = 0 for i = 0 to n=1 do D[A[i]-l] += 1 for j = 1 to u-l do D[j] += D[j-1] // 存储各元素最后出现索引+1 for i = n-1 downto 0 do j = A[i] - l S[D[j]-1] = A[i] D[j] -= 1 // 更新应该存储的位置，类似于压栈 return S 特点 算法效率 如果元素值范围固定，效率为线性（不是基于比较的排序， $nlogn$没有限制） 用空间换时间，其实可以看作是hash 利用了输入列表独特自然属性 变治法（输入增强） 应用 判断线性表元素是否唯一 寻找线性表众数 快速查找 线性表顺序统计量寻找列表中第k小的元素 也即：求出给定列表中k个最小元素问题 采用partitioning的思路，需要将给定列表根据某个值先行划分 Lumuto划分算法 QuickSelect算法算法 对划分完后出数组，s为分割位置 若：s == k-1，则中轴p就是第k小元素 若：s &lt; k-1，则应该是数组右边划分第k-s小元素 若：s &gt; k-1，则应该是数组左边划分第k小元素 这样就得到规模更小的问题实例 1234567891011QuickSelect(A[l..r], k) // 用基于划分递归算法解决选择问题 // 输入：可排序数组A[0..n-1]的子数组A[l..r]、整数k // 输出：A[l..r]中第k小元素 s = Partition(A[l..r]) if s = l+k-1 return A[s] elif s &gt; l+k-1 QuickSelect(A[l..s-1], k) else QuickSelect(A[s+1..r], l+k-1-s) 特点 时间效率：和划分算法有关（对Lomuto算法） 最好情况下只需要划分一次即找到，需要比较$n-1$次 最坏情况下需要比较$n(n-1)/2$次，这比直接基于排序更差 数学分析表明，基于划分的算法平均情况下效率是线性的 已经找到复杂算法替代Lomuto算法用于在快速选择中选出 中轴，在最坏情况下仍保持线性时间效率 QuickSelect算法可以不用递归实现，且非递归版本中甚至 不需要调整参数k值，只需要最后s == k-1即可 减可变规模：Lomuto算法性质 线性表有序划分LomutoPartition算法 考虑子数组A[l..r]分为三段，按顺序排在中轴p之后 小于p的元素，最后元素索引记为s 大于等于p的元素，最后元素索引记为i 未同p比较过元素 从左至右扫描A[l..r]，比较其中元素和p大小 若A[i] &gt;= p，扩大大于等于p元素段 若A[i] &lt; p，需要扩大小于等于p元素段 123456789101112LomutoPartition(A[l..r]) // 采用Lomuto算法，用首个元素作中轴划分数组 // 输入：可排序数组A[0..n-1]的子数组A[l..r] // 输出：A[l..r]的划分、中轴位置 p = A[l] s = l for i = l+1 to r if A[i] &lt; p s = s+1 swap(A[s], A[i]) swap(A[l], A[s]) return s HoarePartition算法 选择一个元素p作为中轴（最简单的，首个元素p=A[l]） 从数组A[l..r]两端进行扫描，将扫描到的元素同中轴比较 从左至右的扫描忽略小于中轴元素，直到遇到大于等于中轴 元素停止（从第二个元素开始i=l+1） 从右至左的扫描忽略大于中轴元素，直到遇到小于等于中轴 元素停止(j=r-1) 若扫描停止后 两指针不相交i &lt; j，交换A[i]、A[j]，i=i+1、j=j-1， 继续扫描 若指针相交i &gt; j，把中轴和A[j]交换即得到数组一个划分 ，分裂点为s=j 如果指针重合i==j，此元素一定等于p，也得到数组的一个 划分，分裂点为s==i==j 12345678910111213141516171819202122HoarePartition(A[l..r]) // 以首元素为中轴，对数组进行划分 // 输入：可排序数组A[1..n]的子数组A[l..r] // 输出：A[l..r]的一个划分，返回分裂点位置 p = A[l] i = l j = r+1 repeat repeat i = i+1 until A[i] &gt;= p // 这里i有可能越界，可以添加一个限位器 repeat j = j-1 until j[i] &lt;= p // 从左右两端都是遇到等于p的元素就停止扫描 // 这样可以保证即使数组中有许多和p相等的元素 // 也能够将数组划分得比较均匀 swap(A[i], A[j]) // 这样写没有关系，不需要在这里给调整i、j // 因为循环下一步就是调整i、j until i &gt;= j swap(A[i], A[j]) // 撤销算法最后一次交换 swap(A[l], A[j]) return j 三路划分算法","link":"/Algorithm/Problem/sorting.html"},{"title":"Scala 基本实体","text":"Expression表达式：可计算的语句 value：常量，引用常量不会再次计算 不能被重新赋值 类型可以被推断、也可以显式声明类型 可以被声明为lazy，只有被真正使用时才被赋值 123val constant = 1lazy val lazy_constant = 1var variable = 1 variable：变量，除可重新赋值外类似常量 Unified Types Scala中所有值都有类型，包括数值、函数 类型层次结构 Any：顶级类型，所有类型超类 定义一些通用方法 equals hashCode toString AnyVal：值类型 有9个预定义非空值类型 Double Float Long Int Short Byte Char Boolean Unit：唯一单例值() 值类型可以按以下方向转换（非父子类之间） AnyRef：引用类型 所有非值类型都被定义为引用类型 用户自定义类型都是其子类型 若Scala被应用于Java运行环境中，AnyRef相当于 java.lang.object Nothing：底部类型，所有类型的子类型 没有值是Nothing类型 可以视为 不对值进行定义的表达式的类型 不能正常返回的方法 用途 给出非正常终止的信号：抛出异常、程序退出、死循环 NULL：所有引用类型的子类型 唯一单例值null 用途 使得Scala满足和其他JVM语言的互操作性，几乎不应该 在Scala代码中使用 基本数据类型 数据类型 取值范围 说明 Byte $[-2^7, 2^7-1]$ Short $[-2^{15}, 2^{15}-1]$ Int $[-2^{31}, 2^{31}-1]$ Long $[-2^{63}, 2^{63}]$ Char $[0, 2^{16}-1]$ String 连续字符串 按值比较 Float 32bits浮点 Double 64bits浮点 Boolean true、false Unit () 不带任何意义的值类型 1234567891011121314151617val x = 0x2F // 16进制val x = 41 // 10进制val x = 041 // 8进制val f = 3.14Fval f = 3.14f // `Float`浮点val d = 3.14val d = 0.314e1 // `Double`val c = 'A'val c = '\\u0022'val c = '\\&quot;' // `Char类型`val str = &quot;\\&quot;hello, world\\&quot;&quot; // 字符串val str = &quot;&quot;&quot;&quot;hello, world&quot;&quot;&quot;&quot; // 忽略转义var x = true Unit值()在概念上与Tuple0值()相同（均唯一单例值） （但Tuple0类型不存在？？？） Tuples元组：不同类型值的聚集，可将不同类型的值放在同一个变量中保存 元组包含一系列类：Tuple2、Tuple3直到Tuple22 创建包含n个元素的元组时，就是从中实例化相应类，用 组成元素的类型进行参数化 特点 比较：按值（内容）比较 输出：输出括号包括的内容 访问元素 &lt;tuple&gt;._&lt;n&gt;：访问元组中第n个元素（从1开始） 元组支持模式匹配[解构] 用途 需要从函数中返回多个值 12345678val t3 = (&quot;hello&quot;, 1, 3.14)val (str, i, d) = t3// 必须括号包裹，否则三个变量被赋同值println(t3._1)val t2 = (1, 3)val t22 = 1 -&gt; 3// `-&gt;`同样可以用于创建元组 基于内容的比较衍生出模式匹配提取 如果元素具有更多含义选择case class，否则选择元组 Symbol符号类型：起标识作用，在模式匹配、内容判断中常用 特点 比较：按内容比较 输出：原样输出 12val s: Symbol = 'startif (s == 'start) println(&quot;start......&quot;) 运算符号 任何具有单个参数的方法都可以用作中缀运算符，而运算符 （狭义）就是普通方法 可以使用点号调用 可以像普通方法一样定义运算符1234case class Vec(val x: Double, val y: Double){ def +(that: Vec) = new Vec(this.x + that.x, this.y + that.y)} 表达式中运算符优先级：根据运算符第一个字符评估优先级 其他未列出字符 *、/、% +、- : +! &lt;、&gt; &amp; ^ | 所有字母：[a-zA-Z] 数值运算 四则运算 + - * / % 按位 &amp;、|、^、~ &gt;&gt;/&lt;&lt;：有符号移位 &gt;&gt;&gt;/&lt;&lt;&lt;：无符号移位 比较运算 &gt;、&lt;、&lt;=、&gt;= ==/equals：基于内容比较 eq：基于引用比较 逻辑运算 ||、&amp;&amp; 字符串运算 Scala中String实际就是Java中java.lang.String类型 可调用Java中String所有方法 并定义有将String转换为StingOps类型的隐式转换函数 ，可用某某些额外方法 indexOf(&lt;idx&gt;) toUppercase、toLowercase reverse drop(&lt;idx&gt;) slice&lt;&lt;start&gt;,&lt;end&gt;&gt; .r：字符串转换为正则表达式对象 类型推断 编译器通常可以推断出 表达式类型：工作原理类似推断方法返回值类型 非递归方法的返回值类型 多态方法、泛型类中泛型参数类型 编译器不推断方法的形参类型 但某些情况下，编译器可以推断作为参数传递的匿名函数 形参类型 不应该依赖类型推断场合 公开可访问API成员应该具有显式类型声明以增加可读性 避免类型推断推断类型太具体 12var obj = null// 被推断为为`Null`类型仅有单例值，不能再分配其他值 类型别名类型别名：具体类型别名 12// 泛型参数必须指定具体类型type JHashMap = java.util.HashMap[String, String] Code Blocks代码块：使用{}包围的表达式组合 代码块中最后表达式的结果作为整个代码块的结果 Scala建议使用纯函数，函数不应该有副作用 所以其中基本应该没有语句概念，所有代码块均可视为 表达式，用于赋值语句 {}：允许换行的()，Scala中{}基本同() 控制表达式if语句1234567if(&lt;eva_expr&gt;){ // code-block if true}else if(&lt;eva_expr&gt;){ // code-block}else{ // code-block if false} 返回值：对应函数块返回值 while语句123while(&lt;eva_expr&gt;){ // code-block if true} Scala中while作用被弱化、不推荐使用 返回值：始终为Unit类型() for语句1234567for{ &lt;item1&gt; &lt;- &lt;iter1&gt; &lt;item2&gt; &lt;- &lt;iter2&gt; if &lt;filter_exp&gt; if &lt;filter_exp&gt;}{} 以上在同语句中多个迭代表达式等价于嵌套for 返回值 默认返回Unit类型() 配合yield返回值迭代器（元素会被消耗） 注意：迭代器中元素会被消耗，大部分情况不应该直接在嵌套 for语句中使用 match模式匹配 模式匹配的候选模式 常量 构造函数：解构对象 需伴生对象实现有unapply方法，如：case class 序列 需要类伴生对象实现有unapplySeq方法，如： Seq[+A]类、及其子类 元组 类型：适合需要对不同类型对象需要调用不同方法 一般使用类型首字母作为case标识符name 对密封类，无需匹配其他任意情况的case 不匹配可以隐式转换的类型 变量绑定 候选模式可以增加pattern guards以更灵活的控制程序 模式匹配可以视为解构已有值，将解构结果map至给定名称 可以用于普通赋值语句中用于解构模式 显然也适合于for语句中模式匹配 1234567891011121314151617&lt;target&gt; match { // 常量模式 + 守卫语句 case x if x % 2 == 0 =&gt; // 构造函数模式 case Dog(a, b) =&gt; // 序列模式 case Array(_, second) =&gt; // 元组模式 case (second, _*) =&gt; // 类型模式 case str: String =&gt; // 变量绑定 case all@Dog(name, _) =&gt;}// 普通赋值语句中模式匹配val all@Array(head, _*) = Array(1,3,3) 可在普通类伴生对象中实现unapply、unapplySeq实现模式 匹配，此单例对象称为extractor objects unapplyunapply方法：接受实例对象、返回创建其所用的参数 构造模式依靠类伴生对象中unapply实现 unapply方法返回值应该符合 若用于判断真假，可以返回Boolean类型值 若用于提取单个T类型的值，可以返回Option[T] 若需要提取多个类型的值，可以将其放在可选元组 Option[(T1, T2, ..., Tn)] case class默认实现有此方法 12345678class Dog(val name: String, val age: Int){// 伴生对象中定义`unapply`方法解构对象object Dog{ def unapply(dog: Dog): Option[(String, Int)]{ if (dog!=null) Some(dog.name, dog.age) else None }} unapplySequnapplySeq方法：接受实例对象、返回创建其所用的序列 序列模式依靠类伴生对象中unapplySeq实现 方法应返回Option[Seq[T]] Seq[A+]默认实现此方法 1234567891011121314151617181920212223242526// `scala.Array`伴生对象定义object Array extends FallbackArrayBuilding{ def apply[T: ClassTag](xs: T*): Array[T] = { val array = new Array[T](xs.length) var i = 0 for(x &lt;- xs.iterator) { array(i) = x i += 1 } array } def apply[x: Boolean, xs: Boolean*]: Array[Boolean] = { val array = new Array[Boolean](xs.length + 1) array(0) = x var i = 1 for(x &lt;- xs.iterator){ array(i) = x i += 1 } array } /* 省略其它`apply`方法 */ def unapplySeq[T](x: Array[T]): Option[IndexedSeq[T]] = if(x == null) None else Some(x.toIndexedSeq)} 正则表达式模式匹配12345678910111213141516import scala.util.matching.{Regex, MatchIterator}// `.r`方法将字符串转换为正则表达式val dateP = &quot;&quot;&quot;(\\d\\d\\d\\d)-(\\d\\d)-(\\d\\d)&quot;&quot;&quot;.rval dateP = new Regex(&quot;&quot;&quot;(\\d\\d\\d\\d)-(\\d\\d)-(\\d\\d)&quot;&quot;&quot;)// 利用`Regex`的`unapplySeq`实现模式匹配// 不过此应该是定义在`Regex`类而不是伴生对象中for(date &lt;- dateP.findAllIn(&quot;2015-12-31 2016-01-01&quot;)){ date match { case dateRegex(year, month, day) =&gt; case _ =&gt; }}// `for`语句中模式匹配for(dateP(year, month, day) &lt;- dateP.findAllIn(&quot;2015-12-31 2016-01-01&quot;)){} scala.util.matching具体参见cs_java/scala/stdlib Functions函数：带有参数的表达式 12345// 带一个参数的匿名函数，一般用作高阶函数参数Array(1,2,3).map((x: Int) =&gt; x + 1)Array(1,2,3).map(_+1) // 简化写法// 具名函数val fx: Float =&gt; Int = (x: Float) =&gt; x.toInt 函数结构 可以带有多个参数、不带参数 无法显式声明返回值类型 函数可以类似普通常量使用lazy修饰，当函数被使用时才会被 创建 作高阶函数参数时可简化 参数类型可推断、可被省略 仅有一个参数，可省略参数周围括号 仅有一个参数，可使用占位符_替代参数声明整体 Java：函数被编译为内部类，使用时被创建为对象、赋值给相应 变量 Scala中函数是“一等公民”，允许定义高阶函数、方法 可以传入对象方法作为高阶函数的参数，Scala编译器会将 方法强制转换为函数 使用高阶函数利于减少冗余代码 函数类型函数类型：Scala中有Funtion&lt;N&gt;[T1, T2, ..., TN+1]共22种函数 类型，最后泛型参数为返回值类型 12345// 实例化`Function2[T1, T2, T3]`创建函数val sum = new Function2[Int, Int, Int] { def apply(x: Int, y: Int): Int = x + y}val sum = (x: Int, y: Int) =&gt; x + y 偏函数偏函数：只处理参数定义域中子集，子集之外参数抛出异常 1234567891011// scala中定义trait PartialFunction[-A, +B] extends (A =&gt; B){ // 判断元素在偏函数处理范围内 def isDefinedAt(?ele: A) // 组合多个偏函数 def orElse(?pf: PartialFunction[A, B]) // 方法的连续调用 def addThen(?pf: PartialFunction[A, B]) // 匹配则调用、否则调用回调函数 def applyOrElse(?ele: A, ?callback: Function1[B, Any])} 偏函数实现了Function1特质 用途 适合作为map函数参数，利用模式匹配简化代码 12345val receive: PartialFunction[Any, Unit] = { case x: Int =&gt; println(&quot;Int type&quot;) case x: String =&gt; println(&quot;String type&quot;) case _ =&gt; println(&quot;other type&quot;)} Methods方法：表现、行为类似函数，但有关键差别 def定义方法，包括方法名、参数列表、返回类型、方法体 方法可以接受多个参数列表、没有参数列表 123def addThenMutltiply(x: Int, y: Int)(multiplier: Int): Int = (x+y) * multiplierdef name: String = System.getProperty(&quot;user.name&quot;) Scala中可以嵌套定义方法 Java中全在类内，确实都是方法 Currying柯里化：使用较少的参数列表调用多参数列表方法时会产生新函数， 该函数接受剩余参数列表作为其参数 多参数列表/参数分段有更复杂的调用语法，适用场景 给定部分参数列表 可以尽可能利用类型推断，简化代码 创建新函数，复用代码 指定参数列表中部分参数为implicit 12345678val number = List(1,2,3,4,5,6,7,8,9)numbers.foldLeft(0)(_ + _)// 柯里化生成新函数val numberFunc = numbers.foldLeft(List[Int]())_val square = numberFunc((xs, x) =&gt; xs:+ x*x)val cube = numberFunc((xs, x) =&gt; xs:+ x*x*x)def execute(arg: Int)(implicit ec: ExecutionContext) 隐式转换隐式转换：编译器发现类型不匹配时，在作用域范围内查找能够转换 类型的隐式转换 类型S到类型T的隐式转换由S =&gt; T类型函数的隐式值、 或可以转换为所需值的隐式方法定义 隐式转换只与源类型、目标类型有关 源类型到目标类型的隐式转换只会进行一次 若作用域中有多个隐式转换，编译器将报错 适用场合：以下情况将搜索隐式转换 隐式转换函数、类：表达式e的类型S不符合期望类型 T 隐式参数列表、值：表达式e类型S没有声明被访问的 成员m 隐式转换可能会导致陷阱，编译器会在编译隐式转换定义时发出 警告，可以如下关闭警告 import scala.language.implicitConversions到隐式 转换上下文范围内 启用编译器选项-language: implicitConversions 12345678import scala.language.implicitCoversions// `scala.Predef`中定义有// 隐式转换函数implicit def int2Integer(x: Int) = java.lang.Integer.valueOf(x)// 隐式参数列表@inline def implicitly[T](implicit e:T) = e 隐式转换函数、类1234567891011// 隐式转换函数implicit def float2int(x: Float) = x.toInt// 隐式类implicit class Dog(val name: String){ def bark = println(s&quot;$name is barking&quot;)}&quot;Tom&quot;.bark// 隐式类最终被翻译为implicit def string2Dog(name: String): Dog = new Dog(name) 隐式类通过隐式转换函数实现 其主构造函数参数有且只有一个 代码更简洁、晦涩，类和方法绑定 隐式值、参数列表 若参数列表中参数没正常传递，Scala将尝试自动传递 正确类型的隐式值 查找隐式参数的位置 调用包含隐式参数列表的方法时，首先查找可以直接访问、 无前缀的隐式定义、隐式参数 在伴生对象中查找与隐式候选类型相关的、有隐式标记的 成员 说明 隐式值不能是顶级值 implicit能且只能作用于最后参数列表 方法才能包含隐式参数列表，函数不可 包含隐式参数列表方法不可偏函数化 例1 12345678910111213141516171819202122232425abstract class Monoid[A]{ def add(x: A, y: A): A def unit: A}object ImplicitTest{ // `implicit`声明该匿名类对象为隐式值 implicit val stringMonoid: Monoid[String] = new Monoid[String]{ def add(x: String, y: String): Strinng = x concat y def unit: String = &quot;&quot; } implicit val intMonoid: Monoid[Int] = new Monoid[Int] { def add(x: Int, y: Int): Int = x + y def unit: Int = 0 } // 定义隐式参数列表 def sum[A](xs: List[A])(implicit m: Monoid[A]): A = if (xs.isEmpty) m.unit else m.add(xs.head, sum(xs.tail)) def main(args: Array[String]): Unit = { println(sum(List(1,2,3))) println(sum(List(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;))) }} 例2 123456789101112131415161718trait Multiplicable[T] { def multiply(x: T): T}// 定义隐式单例对象implicit object MultiplicableInt extends Multiplicable[Int]{ def multiply(x: Int) = x*x}implicit object MultiplicableString extends Mulitplicable[String]{ def multiply(x: String) = x*2}// `T: Multiplicable`限定作用域存在相应隐式对象、或隐式值def multiply[T: Multiplicable](x: T) = { // 调用`implicitly`返回隐式对象、或隐式值 val ev = implicitly[Multiplcable[T]] ev.multiply(x)}println(multiply(5))println(multiply(5)) 传名参数传名参数：仅在被使用时触发实际参数的求值运算 12def calculate(input: =&gt; Int) = input * 37// 在参数类型前加上`=&gt;`将普通（传值）参数变为传名参数 传名参数 若在函数体中未被使用，则不会对其求值 若参数是计算密集、长时运算的代码块，延迟计算能力可以 帮助提高性能 传值参数：仅被计算一次 传名参数实现while循环1234567891011def whileLoop(condition: =&gt; Boolean)(body: =&gt; Unit): Unit = if(condition){ body whileLoop(condition)(body) }var i = 2whileLoop(i &gt; 0){ println(i) i -= 1} 默认参数默认参数：调用时可以忽略具有默认值的参数 调用时忽略前置参数时，其他参数必须带名传递 跳过前置可选参数传参必须带名传参 Java中可以通过剔除可选参数的重载方法实现同样效果 Java代码中调用时，Scala中默认参数必须、不能使用命名参数 命名参数调用 调用方法时，实际参数可以通过其对应形参名标记 命名参数顺序可以打乱 未命名参数需要按照方法签名中形参顺序放在前面 Exception异常处理：try{throw...}catch{case...}抛出捕获异常 12345678910def main(args: Array[String]){ try{ val fp = new FileReader(&quot;Input&quot;) }catch{ case ex: FileNotFoundException =&gt; println(&quot;File Missing&quot;) case ex: IOException =&gt; println(&quot;IO Exception&quot;) }finally{ println(&quot;finally&quot;) }}","link":"/Java/Scala/entity_components.html"},{"title":"Scala 自定义实体","text":"Class Scala是纯面向对象语言，所有变量都是对象，所有操作都是 方法调用 class定义类，包括类名、主构造参数，其中成员可能包括 普通类可用new创建类实例 成员说明 常/变量：声明时必须初始化，否则需定义为抽象类， 相应成员也被称为抽象成员常/变量 可以使用占位符_初始化 AnyVal子类：0 AnyRef子类：null 抽象类型：type声明 方法、函数 内部类、单例对象：内部类、单例对象绑定至外部对象 内部类是路径依赖类型 不同类实例中的单例对象不同 Java：仍然会为匿名类生成相应字节码文件 Java：public类成员常/变量在编译后自动生成getter、 setter（仅变量）方法 即使是公有成员也会被编译为private 对其访问实际上是通过setter、getter方法（可显式调用） 内部类型投影类型投影：Outter#Inner类型Inner以Outter类型作为前缀， Outter不同实例中Inner均为此类型子类 123456789101112131415class Outter{ class Inner def test(i: Outter#Inner) = i}val o1 = new Outterval o2 = new Outter// 二者为不同类型val i1 = new o1.Innerval i2 = new o2.Inner// 类型投影父类作为参数类型o1.test(i2)o2.test(i1) 单例类型单例类型：所有对象都对应的类型，任意对象对应单例类型不同 123456import scla.reflect.runtime.universe.typeOfclass Dogval d1 = new Dogval d2 = new DogtypeOf[d1.type] == typeOf[d2.type] // `false`val d3: d1.type = d1 // 两者单例类型也不同 链式调用123456789101112131415161718192021222324class Pet{ var name: String = _ var age: Float = _ // 返回类型单例类型，保证类型不改变 def setName(name: String): this.type = { this.name = name this } def setAge(age: Float): this.age = { this.age = age this }}class Dog extends Pet{ var weight: Float = _ def setWeight(weight: Float): this.type = { this.weight = weight this }}// 若没有设置返回类型为单例类型`this.type`，`setAge`之后// 将返回`Pet`类型，没有`setWeight`方法，报错val d = new Dog().setAge(2).setWeight(2.3).setName(&quot;Tom&quot;) Constructor12345678// 带默认参数的、私有主构造方法class Person private(var name: String, var age: Int=10){ // 辅助构造方法 def this(age: Int) = { // 必须调用已定义构造方法 this(&quot;&quot;, age) }} 主构造方法：类签名中参数列表、类体 其参数（类签名中）被自动注册为类成员变、常量 其可变性同样由var、val声明 其访问控制类似类似类体中成员访问控制 但缺省继承父类可见性，否则为private[this] val 参数中私有成员变、常量没有被使用，则不会被生成 case class主构造方法中缺省为public val 其函数体为整个类体，创建对象时被执行 可类似普通方法 提供默认值来拥有可选参数 将主构造方法声明为私有 辅助构造方法：this方法 辅助构造方法必须以先前已定义的其他辅助构造方法、或 主构造方法的调用开始 主构造方法体现于其中参数被自动注册为类成员 类继承1234// `extends`指定类继承class Student(name: String, age: Int, var studentNo: Int) extends Person(name: String, age: Int){} 必须给出父类的构造方法（可以是辅助构造方法） 类似强制性C++中初始化列表 构造函数按以下规则、顺序执行 父类、特质构造函数 混入特质：多个特质按从左至右 当前类构造函数 可用override重写从父类继承的成员方法、常/变量 重写父类抽象成员（未初始化）可省略override java中方法都可以视为C++中虚函数，具有多态特性 提前定义、懒加载 由于构造方法的执行顺序问题，定义于trait中的抽象成员 常/变量可能会在初始化化之前被使用 可以考虑使用提前定义、懒加载避免 1234567891011121314151617import java.io.PrintWritertrait FileLogger{ // 抽象变量 val fileName: String // 抽象变量被使用 val fileOutput = new PrintWriter(fileName: String) // `lazy`懒加载，延迟变量创建 lazy val fileOutput = new PrintWriter(fileName: String)}class Personclass Student extends Person with FileLogger{ val fileName = &quot;file.log&quot;}val s = new { // 提前定义 override val fileName = &quot;file.log&quot;} with Student 访问控制 缺省：Scala没有public关键字，缺省即为public protected[&lt;X&gt;]：在X范围内的类、子类中可见 private[&lt;X&gt;]：在X范围内类可见 X可为包、类、单例对象等作用域 缺省为包含当前实体的上层包、类、单例对象，即类似Java 中对应关键字 特别的private[this]表示对象私有 只有对象本身能够访问该成员 类、伴生对象中也不能访问 12345678class Person{ private[this] age = 12 def visit() = { val p = new Person // 报错，`age`不是`Person`成员 println(p.age) }} 特殊类abstract class抽象类：不能被实例化的类 抽象类中可存在抽象成员常/变量、方法，需在子类中被具体化 1234567891011121314// 定义抽象类abstract class Person(var name: String, var age: Int){ // 抽象成员常量 val gender: String // 抽象方法 def print: Unit}// 抽象类、泛型、抽象类型常用于匿名类val p = new Person(&quot;Tom&quot;, 8){ override gender = &quot;male&quot; // 覆盖抽象成员可以省略`override` def print: Unit = println(&quot;hello&quot;)} case class样例类 和普通类相比具有以下默认实现 apply：工厂方法负责对象创建，无需new实例化样例类 unapply：解构方法负责对象解构，方便模式匹配 equals：案例类按值比较（而不是按引用比较） toString hashCode copy：创建案例类实例的浅拷贝，可以指定部分构造参数 修改部分值 类主构造函数参数缺省为val，即参数缺省不可变公开 用途 方便模式匹配 样例类一般实例化为不可变对象，不推荐实例化为可变 1234case class Message(sender: String, recipient: String, body: String)val message4 = Message(&quot;A&quot;, &quot;B&quot;, &quot;message&quot;)// 指定部分构造参数的拷贝val message5 = message.copy(sender=message4.recipient, recipient=&quot;C&quot;) Value ClassValue Class：通过继承AnyVal以避免运行时对象分配机制 1class Wrapper(val underlying: Int) extends AnyVal 特点 参数：仅有被用作运行时底层表示的公有val参数 成员：可包含def自定义方法，但不能定义额外val、 var、内嵌trait、class、object 继承：只能继承universal trait，自身不能再被继承 编译期类型为自定义类型，运行时类型为val参数类型 调用universal trait中方法会带来对象分配开销 用途 和隐式类联合获得免分配扩展方法 1234// 标准库中`RichInt`定义implicit class RichInt(val self Int) extends AnyVal{ def toHexString: String = java.lang.Integer.toHexString(self)} 不增加运行时开销同时保证数据类型安全 123class Meter(val value: Double) extends AnyVal{ def +(m: Meter): Meter = new Meter(value + m.value)} JVM不支持value class，Scala有时需实例化value class value class作为其他类型使用 value class被赋值给数组 执行运行时类型测试，如：模式匹配 Object单例对象：有且只有一个实例的特殊类，其中方法可以直接访问， 无需实例化 单例对象由自身定义，可以视为其自身类的单例 对象定义在顶层（没有包含在其他类中时），单例对象只有 一个实例 全局唯一 具有稳定路径，可以被import语句导入 对象定义在类、方法中时，单例对象表现类似惰性变量 不同实例中单例对象不同，依赖于包装其的实例 单例对象和普通类成员同样是路径相关的 单例对象是延迟创建的，在第一次使用时被创建 object定义 可以通过引用其名称访问对象 单例对象被编译为单例模式、静态类成员实现 Companion Object/Class 伴生对象：和某个类共享名称的单例对象 伴生类：和某个单例对象共享名称的类 伴生类和伴生对象之间可以互相访问私有成员 伴生类、伴生对象必须定义在同一个源文件中 用途：在伴生对象中定义在伴生类中不依赖于实例化对象而存在 的成员变量、方法 工厂方法 公共变量 Java中static成员对应于伴生对象的普通成员 静态转发：在Java中调用伴生对象时，其中成员被定义为伴生类 中static成员（当没有定义伴生类时） applyapply方法：像构造器接受参数、创建实例对象 1234567891011121314151617181920import scala.util.Randomobject CustomerID{ def apply(name: String) = s&quot;$name--${Random.nextLong}&quot; def unapply(customerID: String): Option[String] = { val stringArray:[String] = customer.ID.split(&quot;--&quot;) if (stringArray.tail.nonEmpty) Some(StringArray.head) else None }}val customer1ID = CustomerId(&quot;Tom&quot;)customer1ID match { case CustomerID(name) =&gt; println(name) case _ =&gt; println(&quot;could not extract a CustomerID&quot;)}val CustomerID(name) = customer1ID// 变量定义中可以使用模式引入变量名// 此处即使用提取器初始化变量，使用`unapply`方法生成值val name = CustomerID.unapply(customer2ID).get unapply、unapplySeq参见cs_java/scala/entity_components 应用程序对象应用程序对象：实现有main(args: Array[String])方法的对象 main(args: Array[String])方法必须定义在单例对象中 实际中可以通过extends App方式更简洁定义应用程序对象 ，trait App中同样是使用main函数作为程序入口 12345678910trait App{ def main(args: Array[String]) = { this._args = args for(proc &lt;- initCode) proc() if (util.Propertie.propIsSet(&quot;scala.time&quot;)){ val total = currentTime - executionStart Console.println(&quot;[total &quot; + total + &quot;ms&quot;) } }} 包中可以包含多个应用程序对象，但可指定主类以确定包程序 入口 case object样例对象：基本同case class 对于不需要定义成员的域的case class子类，可以定义为 case object以提升程序速度 case object可以直接使用，case class需先创建对象 case object只生成一个字节码文件，case class生成 两个 case object中不会自动生成apply、unapply方法 用途示例创建功能性方法1234567891011package loggingobject Logger{ def info(message: String): Unit = println(s&quot;IFNO: $message&quot;)}// `import`语句要求被导入标识具有“稳定路径”// 顶级单例对象全局唯一，具有稳定路径import logging.Logger.infoclass Test{ info(&quot;created projects&quot;)} Trait特质：包含某些字段、方法的类型 特点 特质的成员方法、常/变量可以是具体、或抽象 特质不能被实例化，因而也没有参数 特质可以extends自类 用途：在类之间共享程序接口、字段，尤其是作为泛型类型和 抽象方法 extend继承特质 with混入可以组合多个特质 override覆盖/实现特质默认实现 子类型：需要特质的地方都可以使用特质的子类型替换 Java：trait被编译为interface，包含具体方法、常/变量 还会生成相应抽象类 Mixin混入：特质被用于组合类 类只能有一个父类，但是可以有多个混入 混入和父类可能有相同父类 通过Mixin trait组合类实现多继承 多继承导致歧义时，使用最优深度优先确定相应方法 复合类型复合类型：多个类型的交集，指明对象类型是某几个类型的子类型 1&lt;traitA&gt; with &lt;traitB&gt; with ... {refinement} sealed trait/sealed class密封特质/密封类：子类确定的特质、类 1234sealed trait STcase class CC1(id: String) extends STcase object CC2 extends ST 密封类、特质只能在当前文件被继承 适合模式匹配中使用，编译器知晓所有模式，可提示缺少模式 自类型自类型：声明特质必须混入其他特质，尽管特质没有直接扩展 其他特质 特质可以直接使用已声明自类型的特质中成员 细分大类特质12345678910111213trait User{ def username: String}trait Tweeter{ // 声明自类型，表明需要混入`User`特质 this: User =&gt; def tweet(tweetText: String) = println(s&quot;$username: $tweetText&quot;)}class VerifiedTweeter(val username_: String) extends Tweeter with User{ def username = s&quot;real $username_&quot;} 定义this别名12345678910class OuterClass{ // 定义`this`别名，下面二者等价 outer =&gt; // outer: OuterClass =&gt; val v1 = &quot;here&quot; class Innerclass { // 方便在内部类中使用 println(outer.v1) }} Universal TraitUniversal Trait：继承自Any、只有def成员、不作任何 初始化的trait 继承自universal trait的value class同时继承该trait方法， 但是调用其会带来对象分配开销 泛型 泛型类、泛型trait 泛型类使用方括号[]接受类型参数 泛型方法：按类型、值进行参数化，语法和泛型类类似 类型参数在方括号[]中、值参数在圆括号()中 调用方法时，不总是需要显式提供类型参数，编译器 通常可以根据上下文、值参数类型推断 泛型类型的父子类型关系不可传导 可通过类型参数注释机制控制 或使用类型通配符（存在类型）“构建统一父类” 存在类型/类型通配符存在类型：&lt;type&gt;[T, U,...] forSome {type T; type U;...} ，可以视为所有&lt;type&gt;[]类型的父类 1234567891011121314// 可以使用通配符`_`简化语法// def printAll(x: Array[T] forSome {type T})def printAll(x: Array[_]) = { for (i &lt;- x) { print(i + &quot; &quot;) } println()}val a = Map(1 -&gt; 2, 3 -&gt; 3)match a { // 类型通配符语法可以用于模式匹配，但存在类型不可 case m: Map[_, _] =&gt; println(m)} 省略给方法添加泛型参数 类型边界约束 T &lt;: A/T &gt;: B：类型T应该是A的子类/B的父类 描述is a关系 T &lt;% S：T是S的子类型、或能经过隐式转换为S子类型 描述can be seen as关系 T : E：作用域中存在类型E[T]的隐式值 型变型变：复杂类型的子类型关系与其组件类型的子类型关系的相关性 型变允许在复杂类型中建立直观连接，利用重用类抽象 12345abstract class Animal{ def name: String}case class Cat(name: String) extends Animalcase class Cat(name: String) extends Animal Covariant协变：+A使得泛型类型参数A成为协变 类型List[+A]中A协变意味着：若A是B的子类型，则 List[A]是List[B]的子类型 使得可以使用泛型创建有效、直观的子类型关系 123456789101112def ConvarienceTest extends App{ def printAnimalNames(animals: List[Animal]): Unit = { animals.foreach{ animal =&gt; println(animal.name) } } val cats: List[Cat] = List(Cat(&quot;Winskers&quot;), Cat(&quot;Tom&quot;)) val dogs: List[Dog] = List(Dog(&quot;Fido&quot;), Dog(&quot;Rex&quot;)) printAnimalNames(cats) printAnimalNames(dogs)} Contravariant逆变：-A使得泛型类型参数A成为逆变 同协变相反：若A是B的子类型，则Writer[B]是 Writer[A]的子类型 12345678910111213141516171819202122abstract class Printer[-A] { def print(value: A): Unit}class AnimalPrinter extends Printer[Animal] { def print(animal: Animal): Unit = println(&quot;The animal's name is: &quot; + animal.name)}class CatPrinter extends Printer[Cat]{ def print(cat: Cat): Unit = println(&quot;The cat's name is: &quot; + cat.name)}val myCat: Cat = Cat(&quot;Boots&quot;)def printMyCat(printer: Printer[Cat]): Unit = { printer.print(myCat)}val catPrinter: Printer[Cat] = new CatPrinterval animalPrinter: Printer[Animal] = new AnimalPrinterprintMyCat(catPrinter)printMyCat(animalPrinter) 协变泛型 子类是父类的特化、父类是子类的抽象，子类实例总可以 替代父类实例 协变泛型作为成员 适合位于表示实体的类型中，方便泛化、组织成员 作为[部分]输出[成员] 注意：可变的协变泛型变量不安全 逆变泛型 子类方法是父类方法特化、父类方法是子类方法抽象，子类 方法总可以替代父类方法 逆变泛型提供行为、特征 适合位于表示行为的类型中，方便统一行为 仅作为输入 协变泛型、逆变泛型互补 对包含协变泛型的某类型的某方法，总可以将该方法扩展 为包含相应逆变泛型的类 12trait Function[-T, +R]// 具有一个参数的函数，`T`参数类型、`R`返回类型 Invariant不变：默认情况下，Scala中泛型类是不变的 可变的协变泛型变量不安全 12345678910111213class Container[A](value: A){ private var _value: A = value def getValue: A = _value def setValue(value: A): Unit = { _value = value }}// 若`A`协变val catContainer: Container[cat] = new Container(Cat(&quot;Felix&quot;))val animalContainer: Container[Animal] = catContanimalContainer.setValue(Dog(&quot;Spot&quot;))val cat: Cat = catContainer.getValue Type Erasure类型擦除：编译后删除所有泛型的类型信息 导致运行时无法区分泛型的具体扩展，均视为相同类型 类型擦除无法避免，但可以通过一些利用反射的类型标签解决 ClassTag TypeTag WeakTypeTag 参见cs_java/scala/stdlib中 Java：Java初始不支持泛型，JVM不接触泛型 为保持向后兼容，泛型中类型参数被替换为Object、或 类型上限 JVM执行时，不知道泛型类参数化的实际类 Scala、Java编译器执行过程都执行类型擦除 抽象类型抽象类型：由具体实现决定实际类型 特质、抽象类均可包括抽象类型 1234trait Buffer{ type T val element: T} 抽象类型可以添加类型边界 12345abstract class SeqBuffer extends Buffer{ type U type T &lt;: Seq[U] def length = element.length} 含有抽象类型的特质、类经常和匿名类的初始化同时使用 123456789abstract class IntSeqBuffer extends SeqBuffer{ type U = Int}def newIntSeqBuf(elem1: Int, elem2: Int): IntSeqBuffer = new IntSeqBuffer{ type T = List[U] val element = List(elem1, elem2) } // 所有泛型参数给定后，得到可以实例化的匿名类 抽象类型、类的泛型参数大部分可以相互转换，但以下情况无法 使用泛型参数替代抽象类型 12345678910abstract class Buffer[+T]{ val element: T}abstract class SeqBuffer[U, +T &lt;: Seq[U]] extends Buffer[T]{ def length = element.length}def newIntSeqBuf(e1: Int, e2: Int): SeqBuffer[Int, Seq[Int]] = new SeqBuffer[Int, List[Int]]{ val element = List(e1, e2) } 包和导入package Scala使用包创建命名空间，允许创建模块化程序 包命名方式 惯例是将包命名为与包含Scala文件目录名相同，但Scala 未对文件布局作任何限制 包名称应该全部为小写 包声明方式：同一个包可以定义在多个文件中 括号嵌套：使用大括号包括包内容 允许包嵌套，可以定义多个包内容 提供范围、封装的更好控制 文件顶部标记：在Scala文件头部声明一个、多个包名称 各包名按出现顺序逐层嵌套 只能定义一个包的内容 包作用域：相较于Java更加前后一致 和其他作用域一样支持嵌套 可以直接访问上层作用域中名称 行为类似Python作用域，优先级高于全局空间中导入 即使名称在不同文件中 包冲突方案：Java中包名总是绝对的，Scala中包名是相对的， 而包代码可能分散在多个文件中，导致冲突 绝对包名定位包：__root__.&lt;full_package_path&gt; 导入时：import __root__.&lt;package&gt; 使用时：val v = new __root__.&lt;class&gt; 串联式包语句隐藏包：包名为路径分段串，其中非结尾 包被隐藏 Scala文件顶部一定要package声明所属包，否则好像不会默认 导入scala.等包，出现非常奇怪的错误，如：没有该方法 import import语句用于导入其他包中成员，相同包中成员不需要 import语句 123456import users._import users.{User, UserPreferences}// 重命名import users.{UserPreferences =&gt; UPrefs}// 导入除`HashMap`以外其他类型import java.utils.{HashMap =&gt; _, _} 若存在命名冲突、且需要从项目根目录导入，可以使用 __root__表示从根目录开始 scala、java.lang、object Predef默认导入 相较于Java，Scala允许在任何地方使用导入语句 包对象包对象：作为在整个包中方便共享内容、使用的容器 12345678910111213141516// in file gardening/fruits/Fruit.scalapackage gardening.fruitscase class Fruit(name: String, color: String)object Apple extends Fruit(&quot;Appple&quot;, &quot;green&quot;)object Plum extends Fruit(&quot;Plum&quot;, &quot;blue&quot;)object Banana extends Fruit(&quot;Banana&quot;, &quot;yellow&quot;)// in file gardening/fruits/package.scalapackage gardeningpackage object fruits{ val planted = List(Apple, Plum, Banana) def showFruit(fruit: Fruit): Unit = { println(s&quot;${fruit.name}s are ${fruit.color}&quot;) }} 包对象中任何定义都认为时包自身的成员，其中可以定义 包作用域级任何内容 类型别名 隐式转换 包对象和其他对象类似，每个包都允许有一个包对象 可以继承Scala的类、特质 注意：包对象中不能进行方法重载 按照惯例，包对象代码通常放在文件package.scala中 Annotations注解：关联元信息、定义 注解作用于其后的首个定义、声明 定义、声明之前可以有多个注解，注解顺序不重要 确保编码正确性注解 此类注解条件不满足时，会导致编译失败 @tailrec@tailrec：确保方法尾递归 123456789import scala.annotations.tailrecdef factorial(x: Int): Int = { @tailrec def factorialHelper(x: Int, accumulator: Int): Int ={ if (x == 1) accumulator else factorialHelper(x - 1, accumulator * x) }} 影响代码生成注解 此类注解会影响生成字节码 @inline@inline：内联，在调用点插入被调用方法 生成字节码更长，但可能运行更快 不能确保方法内联，当且仅当满足某些生成代码大小的 启发式算法时，才会出发编译器执行此操作 @BeanProperty@BeanProperty：为成员常/变量同时生成Java风格getter、setter 方法get&lt;Var&gt;()、set&lt;Var&gt;() 对成员变/常量，类编译后会自动生成Scala风格getter、 setter方法：&lt;var&gt;()、&lt;var&gt;_$eq() Java注解 Java注解有用户自定义元数据形式 注解依赖于指定的name-value对来初始化其元素 @interface12345678910111213141516171819202122232425262728// 定义跟踪某个类的来源的注解@interface Source{ public String URL(); public String mail();}// Scala中注解应用类似构造函数调用// 必须使用命名参数实例化Java注解@Source(URL=&quot;http://coders.com&quot;, mail=&quot;support@coders.com&quot;)public class MyClass// 若注解中只有单个[无默认值]元素、名称为`value`// 则可以用类似构造函数的语法在Java、Scala中应用@interface SourceURL{ public String value(); public String mail() defualt &quot;&quot;;}@SourceURL(&quot;http://coders.com/&quot;)public class MyClass// 若需要给`mail`显式提供值，Java必须全部使用命名参数@Source(URL=&quot;http://coders.com&quot;, mail=&quot;support@coders.com&quot;)public class MyClass// Scala可以继续利用`value`特性@SourceURL(&quot;http://coders.com/&quot; mail = &quot;support@coders.com&quot;)public class MyClass","link":"/Java/Scala/diy_components.html"},{"title":"Keras 后端","text":"Keras后端Keras是一个模型级的库，提供了快速构建深度学习网络的模块 Keras并不处理如张量乘法、卷积等底层操作，而是依赖于某种 特定的、优化良好的张量操作库 Keras依赖于处理张量的库就称为“后端引擎” [Theano][Theano]：开源的符号主义张量操作框架，由 蒙特利尔大学LISA/MILA实验室开发 [Tensorflow][Tensorflow]：符号主义的张量操作框架， 由Google开发 [CNTK][CNTK]：由微软开发的商业级工具包 Keras将其函数统一封装，使得用户可以以同一个接口调用不同 后端引擎的函数 [Theano]: http://deeplearning.net/software/theano/ [TensorFlow]: http://www.tensorflow.org/ [CNTK]: https://www.microsoft.com/en-us/cognitive-toolkit/ 切换后端 修改Keras配置文件 定义环境变量KERAS_BACKEND覆盖配置文件中设置（见python 修改环境变量的3中方式） Keras后端抽象可以通过Keras后端接口来编写代码，使得Keras模块能够同时在 Theano和TensorFlow两个后端上使用 大多数张量操作都可以通过统一的Keras后端接口完成，不必 关心具体执行后端 12345678910111213from keras import backend as Kinput = K.placeholder(shape=(2, 4, 5))input = K.placeholder(shape=(None, 4, 5))input = K.placeholder(ndim=3) # 实例化输出占位符val = np.random.random((3, 4, 5))var = K.variable(value=val) # 实例化共享变量 # 等价于`tf.Variable`、`theano.shared`var = K.zeros(shape=(3, 4, 5))var = K.ones(shape=(3, 4, 5)) 配置相关函数backend返回当前后端 epsilon1K.epsilon() 返回数字表达式使用fuzz factor set_epsilon1K.set_epsilon(e(float)) 设置模糊因子的值 floatx1K.floatx() 返回默认的浮点数数据类型 float16 float32 float64 set_floatx123K.set_floatx( floatx=&quot;float16&quot;/&quot;float32&quot;/&quot;float64&quot;) 设置默认的浮点数数据类型（字符串表示） cast_to_floatx1K.cast_to_floatx(x) 将NDA转换为默认的Keras floatx类型（的NDA） 例子 12345678K.floatx() # &quot;float32&quot;arr = np.array([1.0, 2.0], dtype=&quot;flaot64&quot;)arr.dtype # &quot;float64&quot;new_arr = K.cast_to_float(arr)new_arr.dtype # &quot;float32&quot; image_data_format1K.image_data_format() 返回图像的默认维度顺序 channels_last channels_first set_image_data_format123K.set_image_data_format( data_format=&quot;channel_first&quot;/&quot;channel_last&quot;) 设置图像的默认维度顺序 辅助函数is_keras_tensor判断是否是Keras Tensor对象 1234567891011np_var = np.array([1, 2])K.is_keras_tensor(np_var) # Falsekeras_var = K.variable(np_var)K.is_keras_tensor(keras_var) # A variable is not a Tensor. # Falsekeras_placeholder = K.placeholder(shape=(2, 4, 5))K.is_keras_tensor(keras_placeholder) # A placeholder is a Tensor. # True get_uid1K.get_uid(prefix=''/str) 获得默认计算图的uid 说明 依据给定的前缀提供一个唯一的UID 参数 prefix：图的可选前缀 返回值：图的唯一标识符 reset_uids1K.reset_uids() 重置图的标识符 clear_session1K.clear_session() 结束当前的TF计算图，并创建新图 说明 有效的避免模型/网络层的混乱 manual_variable_initialization123K.manual_variable_initialization( value=False/True) 设置变量手动初始化标志 参数 value False：默认，变量在实例时出事的（由其默认值 初始化） True：用户自行初始化，如 tf.initialize_all_variables() learning_phase返回学习阶段标致 返回值：布尔张量 0：测试模式 1：训练模式 set_learning_phase123K.set_learning_phase( value=0/1) 设置学习阶段为固定值 参数 value：学习阶段值 0：测试模式 1：训练模式 OPs、Tensorsis_sparse判断一个Tensor是不是一个稀疏的Tensor 返回值：布尔值 稀不稀疏由Tensor的类型决定，而不是Tensor实际上有多稀疏 1234567from keras import backend as Ka = K.placeholder((2, 2), sparse=False)print(K.is_sparse(a)) # Falseb = K.placeholder((2, 2), sparse=True)print(K.is_sparse(b)) # True to_dense将一个稀疏tensor转换一个不稀疏的tensor并返回 variable12345def variable( value, dtype='float32'/str, name=None) 实例化一个张量，返回之 参数 value：用来初始化张量的值 dtype：张量数据类型 name：张量的名字（可选） placeholder123456def placeholder( shape=None, ndim=None, dtype='float32'/str, name=None) 实例化一个占位符 参数 shape：占位符的shape（整数tuple，可能包含None） ndim: 占位符张量的阶数 要初始化占位符，至少指定shape和ndim之一， 如果都指定则使用shape dtype: 占位符数据类型 name: 占位符名称（可选） shape1def shape(x) 返回张量的符号shape 返回值：OPs（需要执行才能得到值） 1234567891011121314from keras import backend as Ktf_session = K.get_session()val = np.array([[1, 2], [3, 4]])kvar = K.variable(value=val)input = keras.backend.placeholder(shape=(2, 4, 5))K.shape(kvar) # &lt;tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32&gt;K.shape(input) # &lt;tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32&gt; # To get integer shape (Instead, you can use K.int_shape(x))K.shape(kvar).eval(session=tf_session) # array([2, 2], dtype=int32)K.shape(input).eval(session=tf_session) # array([2, 4, 5], dtype=int32) int_shape1def int_shape(x) 返回张量shape 返回值：tuple(int)/None 12345678from keras import backend as Kinput = K.placeholder(shape=(2, 4, 5))K.int_shape(input) # (2, 4, 5)val = np.array([[1, 2], [3, 4]])kvar = K.variable(value=val)K.int_shape(kvar) # (2, 2) ndim1def ndim(x) 返回张量的阶数 返回值：int 12345678from keras import backend as Kinput = K.placeholder(shape=(2, 4, 5))val = np.array([[1, 2], [3, 4]])kvar = K.variable(value=val)K.ndim(input) # 3K.ndim(kvar) # 2 dtype1def dtype(x) 返回张量的数据类型 返回值：str float32 float32_ref 1234567891011121314from keras import backend as KK.dtype(K.placeholder(shape=(2,4,5))) # 'float32'K.dtype(K.placeholder(shape=(2,4,5), dtype='float32')) # 'float32'K.dtype(K.placeholder(shape=(2,4,5), dtype='float64')) # 'float64'__Keras variable__kvar = K.variable(np.array([[1, 2], [3, 4]]))K.dtype(kvar) # 'float32_ref'kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')K.dtype(kvar) # 'float32_ref' eval1def eval(x) 求得张量的值 返回值：NDA 12345from keras import backend as Kkvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')K.eval(kvar) # array([[ 1., 2.], # [ 3., 4.]], dtype=float32) `zeros12345def zeros( shape, dtype='float32', name=None) 生成shape大小的全0张量 123456from keras import backend as Kkvar = K.zeros((3,4))K.eval(kvar) # array([[ 0., 0., 0., 0.], # [ 0., 0., 0., 0.], # [ 0., 0., 0., 0.]], dtype=float32) ones12345def ones( shape, dtype='float32', name=None) 生成shape大小的全1张量 eye12345def eye( size, dtype='float32', name=None) 生成size大小的单位阵 zeros_like1234def zeros_like( x, name=None) 生成与x shape相同的全0张量 ones_like1234def ones_like( x, name=None) 生成与x shape相同的全1张量 随机常量OPsrandom_uniform_variable12345678def random_uniform_variable( shape, low, high, dtype=None, name=None, seed=None) 初始化均匀分布常量OPs 参数 low：浮点数，均匀分布之下界 high：浮点数，均匀分布之上界 dtype：数据类型 name：张量名 seed：随机数种子 count_params1def count_params(x) 返回张量中标量的个数 cast1def cast(x, dtype) 改变张量的数据类型 参数 dtype：float16/float32/float64 update1def update(x, new_x) 用new_x更新x update_add1def update_add(x, increment) 将x增加increment并更新x update_sub1def update_sub(x, decrement) 将x减少decrement并更新x moving_average_update12345def moving_average_update( x, value, momentum) 使用移动平均更新x dot1def dot(x, y) 求两个张量的点乘 12345x = K.placeholder(shape=(2, 3))y = K.placeholder(shape=(3, 4))xy = K.dot(x, y)xy # &lt;tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32&gt; 当试图计算两个N阶张量的乘积时，与Theano行为相同 (2, 3).(4, 3, 5) = (2, 4, 5)) 12345x = K.placeholder(shape=(32, 28, 3))y = K.placeholder(shape=(3, 4))xy = K.dot(x, y)xy # &lt;tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32&gt; 12345x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)y = K.ones((4, 3, 5))xy = K.dot(x, y)K.int_shape(xy) # (2, 4, 5) batch_dot1def batch_dot(x, y, axes=None) 按批进行张量x和y的点积 参数 x：按batch分块的数据 y；同x axes：指定进行点乘的轴 12345x_batch = K.ones(shape=(32, 20, 1))y_batch = K.ones(shape=(32, 30, 20))xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])K.int_shape(xy_batch_dot) # (32, 1, 30) transpose1def transpose(x) 张量转置 gather1def gather(reference, indices) 在给定的张量中检索给定下标的向量 参数 reference：张量 indices：整数张量，其元素为要查询的下标 返回值：同reference数据类型相同的张量 max12345def max( x, axis=None/int, keepdims=False) 求张量中的最大值 min1def min(x, axis=None, keepdims=False) 求张量中的最小值 sum1sum(x, axis=None, keepdims=False) 计算张量中元素之和 prod1prod(x, axis=None, keepdims=False) 计算张量中元素之积 cumsum1def cumsum(x, axis=0) 在给定轴上求张量的累积和 cumprod1cumprod(x, axis=0) 在给定轴上求张量的累积积 var1def var(x, axis=None, keepdims=False) 在给定轴上计算张量方差 std1def std(x, axis=None, keepdims=False) 在给定轴上求张量元素之标准差 mean1def mean(x, axis=None, keepdims=False) 在给定轴上求张量元素之均值 any1def any(x, axis=None, keepdims=False) 按位或，返回数据类型为uint8的张量（元素为0或1） all1def any(x, axis=None, keepdims=False) 按位与，返回类型为uint8de tensor argmax1def argmax(x, axis=-1) 在给定轴上求张量之最大元素下标 argmin1def argmin(x, axis=-1) 在给定轴上求张量之最小元素下标 Element-Wise OPssquare1def square(x) 逐元素平方 abs1def abs(x) 逐元素绝对值 sqrt1sqrt(x) 逐元素开方 exp1def exp(x) 逐元素求自然指数 log1def log(x) 逐元素求自然对数 logsumexp1def logsumexp(x, axis=None, keepdims=False) 在给定轴上计算log(sum(exp())) 该函数在数值稳定性上超过手动计算log(sum(exp()))，可以 避免由exp和log导致的上溢和下溢 round1def round(x) 逐元素四舍五入 sign1def sign(x) 逐元素求元素的符号 返回值 +1 -1 pow1def pow(x, a) 逐元素求x的a次方 clip12345def clip( x, min_value, max_value) 逐元素clip（将超出指定范围的数强制变为边界值） equal1def equal(x, y) 逐元素判相等关系 返回值：布尔张量OP not_equal1def not_equal(x, y) 逐元素判不等关系 greater1def greater(x,y) 逐元素判断x&gt;y关系 greater_equal1def greater_equal(x,y) 逐元素判断x&gt;=y关系 lesser1def lesser(x,y) 逐元素判断x&lt;y关系 lesser_equal1def lesser_equal(x,y) 逐元素判断x&lt;=y关系 maximum1def maximum(x, y) 逐元素取两个张量的最大值 minimum1def minimum(x, y) 逐元素取两个张量的最小值 sin1def sin(x) 逐元素求正弦值 cos1def cos(x) 逐元素求余弦值 变换OPsbatch_normalization12345678def batch_normalization( x, mean, var, beta, gamma, epsilon=0.0001) 对batch的数据进行batch_normalization，计算公式为： $output = (x-mean)/(\\sqrt(var)+\\epsilon)*\\gamma+\\beta$ 手动指定mean、var normalize_batch_in_training1234567def normalize_batch_in_training( x, gamma, beta, reduction_axes, epsilon=0.0001) 对batch数据先计算其均值和方差，然后再进行 batch_normalization concatenate1def concatenate(tensors, axis=-1) 在给定轴上将一个列表中的张量串联为一个张量 reshape1def reshape(x, shape) 将张量的shape变换为指定shape permute_dimensions1234def permute_dimensions( x, pattern(tuple(int))) 按照给定的模式重排一个张量的轴 参数 pattern：代表维度下标的tuple如(0, 2, 1) resize_images123456def resize_images( X, height_factor(uint), width_factor(uint), dim_ordering=None/'th'/'tf') 依据给定的缩放因子height_factor、width_factor，改变batch 数据（图片）的shape 参数 height_factor/width_factor：正整数 resize_volumes1234567def resize_volumes( X, depth_factor, height_factor, width_factor, dim_ordering) 依据给定的缩放因子，改变一个5D张量数据的shape repeat_elements1def repeat_elements(x, rep, axis) 在给定轴上重复张量元素rep次 与np.repeat类似 repeat1def repeat(x, n) 重复2D张量 arange123456def arange( start, stop=None, step=1, dtype=&quot;int32&quot;) 生成1D的整数序列张量 参数：同np.arange 如果只有一个参数被提供了，则0~stop 返回值：默认数据类型是int32的张量 tile1def tile(x, n) 将x在各个维度上重复n[i]次 batch_flatten1def batch_flatten(x) 将n阶张量转变为2阶张量，第一维度保留不变 expand_dims1def expand_dims(x, dim=-1) 在dim指定轴后增加一维（轴） squeeze1def squeeze(x, axis) 将axis指定的轴从张量中移除（保留轴上首组张量切片） temporal_padding1def temporal_padding(x, padding=1) 向3D张量中间那个维度的左右两端填充padding个0值 asymmetric_temporal_padding12345def asymmetric_temporal_padding( x, left_pad=1, right_pad=1) 向3D张量中间的那个维度的左右分别填充0值 spatial_2d_padding12345def spatial_2d_padding( x, padding=(1, 1), dim_ordering='th') 向4D张量高度、宽度左右两端填充padding[0]和padding[1] 个0值 spatial_3d_padding12345def spatial_3d_padding( x, padding=(1, 1, 1), dim_ordering='th') 向5D张量深度、高度、宽度三个维度上填充0值 stack1def stack(x, axis=0) 将列表x中张量堆积起来形成维度+1的新张量 one_hot1def one_hot(indices, nb_classes) 为张量indices进行one_hot编码 参数 indices：n维的整数张量 nb_classes：one_hot编码列表 输出：n+1维整数张量，最后维为编码 reverse1def reverse(x, axes) 将一个张量在给定轴上反转 get_value1def get_value(x) 以NDA的形式返回张量的值 batch_get_value1def batch_get_value(x) 以[NDA]的形式返回多个张量的值 set_value1def set_value(x, value) 从NDA将值载入张量中 batch_set_value1def batch_set_value(tuples) 将多个值载入多个张量变量中 print_tensor1def print_tensor(x, message='') 在求值时打印张量的信息，并返回原张量 function1def function(inputs, outputs, updates=[]) 实例化一个Keras函数 参数 inputs：列表，其元素为占位符或张量变量 outputs：输出张量的列表 updates：张量列表 gradients1def gradients(loss, variables) 返回loss函数关于variables的梯度 stop_gradient1def stop_gradient(variables) Returns variables but with zero gradient with respect to every other variables. rnn12345678910def rnn( step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None) 在张量的时间维上迭代 参数： inputs：时域信号的张量，阶数至少为3 step_function：每个时间步要执行的函数 参数 input：不含时间维张量，代表某时间步batch样本 states：张量列表 返回值 output：形如(samples, ...)的张量 new_states：张量列表，与states的长度相同 initial_states：包含step_function状态初始值 go_backwards：逆向迭代序列 mask：需要屏蔽的数据元素上值为1 constants：按时间步传递给函数的常数列表 unroll 当使用TF时，RNN总是展开的’ 当使用Theano时，设置该值为True将展开递归网络 input_length TF：不需要此值 Theano：如果要展开递归网络，必须指定输入序列 返回值：形如(last_output, outputs, new_states)的张量 last_output：RNN最后的输出 outputs：每个在[s,t]点的输出对应于样本s在t时间的输出 new_states: 每个样本的最后一个状态列表 switch12345def switch( condition, then_expression, else_expression) 依据给定condition（整数或布尔值）在两个表达式之间切换 参数 condition：标量张量 then_expression：TensorFlow表达式 else_expression: TensorFlow表达式 in_train_phase1def in_train_phase(x, alt) 如果处于训练模式，则选择x，否则选择alt 注意alt应该与x的shape相同 in_test_phase1def in_test_phase(x, alt) 如果处于测试模式，则选择x，否则选择alt 注意：alt应该与x的shape相同 预定义（激活）函数relu12345def relu( x, alpha=0.0, max_value=None) 修正线性单元 参数 alpha：负半区斜率 max_value: 饱和门限 elu1def elu(x, alpha=1.0) 指数线性单元 参数 x：输入张量 alpha: 标量 softmax1def softmax(x) 计算张量的softmax值 softplus1def softplus(x) 返回张量的softplus值 softsign1def softsign(x) 返回张量的softsign值 sigmoid1def sigmoid(x) 逐元素计算sigmoid值 hard_sigmoid1def hard_sigmoid(x) 分段线性近似的sigmoid，计算速度更快 tanh1def tanh(x) 逐元素计算tanh值 预定义目标函数categorical_crossentropy12345def categorical_crossentropy( output, target, from_logits=False) 计算output、target的Categorical Crossentropy（类别交叉熵） 参数 output/target：shape相等 sparse_categorical_crossentropy12345def sparse_categorical_crossentropy( output, target, from_logits=False) 计算output、target的Categorical Crossentropy（类别交叉熵） 参数 output target：同output shape相等，需为整形张量 binary_crossentropy12345def binary_crossentropy( output, target, from_logits=False) 计算输出张量和目标张量的交叉熵 dropout1def dropout(x, level, seed=None) 随机将x中一定比例的值设置为0，并放缩整个Tensor l2_normalize1def l2_normalize(x, axis) 在给定轴上对张量进行L2范数规范化 in_top_k1def in_top_k(predictions, targets, k) 判断目标是否在predictions的前k大值位置 参数 predictions：预测值张量 targets：真值张量 k：整数 conv1d12345678def conv1d( x, kernel, strides=1, border_mode=&quot;valid&quot;/&quot;same&quot;, image_shape=None, filter_shape=None) 1D卷积 参数 kernel：卷积核张量 strides：步长，整型 border_mode “same”： “valid”： conv2d123456789def conv2d( x, kernel, strides=(1, 1), border_mode=&quot;valid&quot;/&quot;same&quot;, dim_ordering=&quot;th&quot;/&quot;tf&quot;, image_shape=None, filter_shape=None) 2D卷积 参数 kernel：卷积核张量 strides：步长，长为2的tuple deconv2d12345678910def deconv2d( x, kernel, output_shape, strides=(1, 1), border_mode=&quot;valid&quot;/&quot;same&quot;, dim_ordering=&quot;th&quot;/&quot;tf&quot;, image_shape=None, filter_shape=None) 2D反卷积（转置卷积） 参数 x：输入张量 kernel：卷积核张量 output_shape: 输出shape的1D的整数张量 strides：步长，tuple类型 conv3d123456789def conv3d( x, kernel, strides=(1, 1, 1), border_mode=&quot;valid&quot;/&quot;same&quot;, dim_ordering=&quot;th&quot;/&quot;tf&quot;, volume_shape=None, filter_shape=None) 3D卷积 pool2d12345678def pool2d( x, pool_size, strides=(1, 1), border_mode=&quot;valid&quot;/&quot;same&quot;, dim_ordering=&quot;th&quot;/&quot;tf&quot;, pool_mode=&quot;max&quot;/&quot;avg&quot;) 2D池化 参数 pool_size：含有两个整数的tuple，池的大小 strides：含有两个整数的tuple，步长 pool_mode: “max”，“avg”之一，池化方式 pool3d12345678def pool3d( x, pool_size, strides=(1, 1, 1), border_mode=&quot;valid&quot;/&quot;same&quot;, dim_ordering=&quot;th&quot;/&quot;tf&quot;, pool_mode=&quot;max&quot;/&quot;avg&quot;) 3D池化 bias_add1def bias_add(x, bias, data_format=None) 为张量增加一个偏置项 random_normal1234567def random_normal( shape, mean=0.0, stddev=1.0, dtype=None, seed=None) 生成服从正态分布的张量 参数 mean：均值 stddev：标准差 random_uniform1234567def random_uniform( shape, minval=0.0, maxval=1.0, dtype=None, seed=None) 生成服从均匀分布值的张量 参数 minval：上界 maxval：上界 random_binomial123456def random_binomial( shape, p=0.0, dtype=None, seed=None) 返回具有二项分布值的张量 参数 p：二项分布参数 truncated_normall1234567def truncated_normal( shape, mean=0.0, stddev=1.0, dtype=None, seed=None) 生成服从截尾正态分布值的张量，即在距离均值两个标准差之外的 数据将会被截断并重新生成 ctc_label_dense_to_sparse1def ctc_label_dense_to_sparse(labels, label_lengths) 将ctc标签从稠密形式转换为稀疏形式 ctc_batch_cost123456def ctc_batch_cost( y_true, y_pred, input_length, label_length) 在batch上运行CTC损失算法 参数 y_true：包含标签的真值张量 y_pred：包含预测值或输出的softmax值的张量 input_length：包含y_pred中每个batch的序列长 label_length：包含y_true中每个batch的序列长张量 返回值：包含了每个元素的CTC损失的张量 ctc_decode12345678def ctc_decode( y_pred, input_length, greedy=True, beam_width=None, dict_seq_lens=None, dict_values=None) 使用贪婪算法或带约束的字典搜索算法解码softmax的输出 参数 y_pred：包含预测值或输出的softmax值的张量 input_length：包含y_pred中每个batch序列长的张量 greedy：使用贪婪算法 dict_seq_lens：dic_values列表中各元素的长度 dict_values：列表的列表，代表字典 返回值：包含了路径可能性（以softmax概率的形式）张量 注意仍然需要一个用来取出argmax和处理空白标签的函数 map_fn1def map_fn(fn, elems, name=None) 元素elems在函数fn上的映射，并返回结果 参数 fn：函数 elems：张量 name：节点的名字 返回值：张量的第一维度等于elems，第二维度取决于fn foldl123456def foldl( fn, elems, initializer=None, name=None) 用fn从左到右连接它们，以减少elems值 参数 fn：函数，例如：lambda acc, x: acc + x elems：张量 initializer：初始化的值(elems[0]) name：节点名 返回值：与initializer类型和形状一致 foldr123456def foldr( fn, elems, initializer=None, name=None) 减少elems，用fn从右到左连接它们 参数 fn：函数，例如：lambda acc, x: acc + x elems：张量 initializer：初始化的值（elems[-1]） name：节点名 返回值：与initializer类型和形状一致 _width=None, dict_seq_lens=None, dict_values=None ) 12345678910111213141516171819使用贪婪算法或带约束的字典搜索算法解码softmax的输出- 参数 - `y_pred`：包含预测值或输出的softmax值的张量 - `input_length`：包含`y_pred`中每个batch序列长的张量 - `greedy`：使用贪婪算法 - `dict_seq_lens`：`dic_values`列表中各元素的长度 - `dict_values`：列表的列表，代表字典- 返回值：包含了路径可能性（以softmax概率的形式）张量- 注意仍然需要一个用来取出argmax和处理空白标签的函数#### `map_fn````pythondef map_fn(fn, elems, name=None) 元素elems在函数fn上的映射，并返回结果 参数 fn：函数 elems：张量 name：节点的名字 返回值：张量的第一维度等于elems，第二维度取决于fn foldl123456def foldl( fn, elems, initializer=None, name=None) 用fn从左到右连接它们，以减少elems值 参数 fn：函数，例如：lambda acc, x: acc + x elems：张量 initializer：初始化的值(elems[0]) name：节点名 返回值：与initializer类型和形状一致 foldr123456def foldr( fn, elems, initializer=None, name=None) 减少elems，用fn从右到左连接它们 参数 fn：函数，例如：lambda acc, x: acc + x elems：张量 initializer：初始化的值（elems[-1]） name：节点名 返回值：与initializer类型和形状一致 name：节点名 返回值：与initializer类型和形状一致","link":"/Python/Keras/backend.html"},{"title":"NDArray Routine","text":"Array ManipulationShape Only Routine Function Version Method Version reshape(a,newshape[,order]) resize(a,new_shape) 大小可不同，重复a补不足 0补不足 ravel(a[,order]) 展平视图 .flatten([order]) 无 展平副本 shape(a) size(a) Order Alteration Routine Function Version Method Version transpose(a[,axes]) 调整轴顺序，缺省逆序即转置 moveaxis(a,source,destination) 移动数组轴到新位置 无 rollaxis(a,axis[,start]) 将指定后向插入至指定位置（缺省0） 无 swapaxes(a,axis1,axis2) 交换轴 flip(m[,axis]) 沿指定轴反向，缺省所有轴 无 fliplr(m) 左右反向（沿第2轴） 无 flipud(m) 上下反向（沿第1轴） 无 roll(a,shift[,axis]) 沿轴滚动shift 无 rot90(m[,k,axes]) 在axes指定的平面中旋转k次90度 无 lib.stride_tricks.as_strided(x[,shape,...]) 利用给定shape、stride在x上创建视图 维数改变 Routine Function Version Method Version atleast_1d(*arys) prepend维度直至维度至少维数至少1 无 atleast_2d(*arys) 无 atleatt_3d(*arys) 无 broadcast(*arys) 广播、打包输入对应元素的元组迭代器，类似zip 无 broadcast_to(array,shape[,subok]) 广播为指定shape 无 boradcast_arrays(*args,**kwargs) 输入的广播结果列表 无 expand_dims(a,axis) 在指定位置插入新轴 无 squeeze(a[,axis]) 删除大小为1维度 插入、删除元素 Routine Function Version delete(arr,obj[,axis]) 删除obj指定部分，缺省按展平数组删除 insert(arr,obj,values[,axis]) 缺省按展平数组插入 append(arr,values[,axis]) 缺省arr、values展平再添加 trim_zeros(filt[,trim]) trim前导、尾随0，缺省两边 改变类型 Routine Function Version Method Version asarray(a[,dtype,order]) 转换为数组 无 asarray_chkfinite(a[,dtype,order]) 检查NaN、inf 无 asanyarray(a[,dtype,order]) 转换为数组，数组子类则不变 无 ascalar(a) 将大小为1的数组转换为等效标量 require(a[,dtype,requirements]) 创建满足要求ndarray.flags数组 无 asfortranarray(a[,dtype]) 转换为Fortran-contiguous风格内存布局 无 ascontiguousarray(a[,dtype]) 转换为C-contiguous风格内存布局 无 asmatrix(data[,dtype]) 无 asfarray(a[,dtype]) 转换为浮点类型 无 .astype(dtype[,order,casting,...]) 无 转换为指定类型 numpy中数组不是仅有C、Fortran风格内存布局，对数组的形态 变换会导致内存布局不为任何风格内存布局 组合数组 Routine Function Version concatenate((a1,a2,...)[,axis,out]) 沿现有轴连接数组 stack(arrays[,axis,out]) 创建给定（新）轴堆叠数组 row_stack(tup)/vstack(tup) 沿第1（竖直）轴堆叠 column_stack(tup)/hstack(tup) 沿第2（水平）轴堆叠 dstack(tup) 沿第3轴堆叠 block(arrays) 按照arrays中给定数组块、位置组装 拆分数组 Routine Function Version split(ary,indices_or_sections[,axis]) 沿轴拆分成视图 array_split(ary,indices_or_sections[,axis]) 同split，但可处理不整除拆分 vsplit(ary,indices_or_sections) 沿第1（竖直）轴拆分 hsplit(ary,indices_or_sections) 沿第2（水平）轴拆分 dsplit(ary,indices_or_sections) 沿第3轴拆分 Padding Function Desc pad(array,pad_width[,mode]) Index Routine 结果数组shape考虑逻辑链 确定输出数组的维数ndim 确定参数数组原维度轴位置、补1轴位置，参数维度轴对齐 修正各维度大小 沿轴操作：保持不变 沿轴采样：采样数目 沿轴concate：维度相加 沿轴聚集：删除维度 沿轴切片聚集：删除其余维度 numpy中（多维）索引往往使用整数高级索引的方式返回 np.ndarray数组：首维度各分量分别表示各维度的高级 索引 list、tuple：各元素分别为各维度的高级索引 数组无关切片、高级索引 Routine Function Version 返回值类型 s_[] 支持多维切片生成，类slice() 切片、元组 index_exp[] 同s_，但总返回元组 元组 r_[] 沿第1轴concate切片、数组、标量 数组 c_[] 沿第-1轴concate切片、数组、标量（1维则被视为列向量） 数组 ravel_multi_index(multi_index,dims[,mode,order]) 计算高级索引multi_index在dims数组展平后的位置 数组 unravel_index(indices,shape[,order]) ravel_multi_index逆向 元组 np.r_[]、np.c_[]除可concate切片方便生成数组，还可以 传递两个参数修改行为 r/c字符被设置时，返回矩阵 1维数组，r被设置时返回1 N矩阵，c被设置时 返回N 1矩阵 2维数组，r、c被设置时，结果矩阵相同 &lt;axis&gt;[,&lt;ndim&gt;,&lt;ori_pos&gt;]三个整形，决定shape |参数|说明|np.r_[]缺省值|np.c_[]缺省值| |——-|——-|——-|——-| |&lt;axis&gt;|concate执行轴|0|-1| |&lt;ndim&gt;|目标维数，仅在其大于结果维数时才生效|1|2| |&lt;ori_pos&gt;|原数据轴所在的位置|-1，即prepend全1轴|0，即postpend全1轴| 相同参数时，两者结果相同，可根据不同数组设置合适的 参数相互实现 np.r_[]可视为参数缺省为0,1,-1 np.c_[]可视为参数缺省为-1,2,0 np.r_、np.c_分别是np.lib.index_tricks.RClass、 np.lib.index_tricks.CClass实例 np.s_、np.index_exp均是 np.lib.index_tricks.IndexExpression实例，仅初始化参数 不同 网格 Routine Function Version 返回值类型 ix_(*args) 以args为基点创建开网格（仅设置基点、维度） 元组 meshgrid(*xi,**kwargs) 以xi作为基点创建稠密网格（所有网格点高级索引） 列表 mgrid[] 根据切片创建稠密网格 数组 ogrid[] 根据切片创建开网格 列表 indices(dimensions[,dtype,sparse]) 以dimensions作为各维度长创建网格 数组、元组 开网格广播即可得到稠密网格 值相关索引 Routine Function Version Method Version nonzero(a) 非0元素整形高级索引 where(condition,[x,y]) condition对应整形高级索引，给出x,y时则从中抽取元素 无 flatnonzero(a) 展平非0位置 无 特殊位置索引 Routine Function Version diag_indices(n[,ndim]) ndim维长为n数组对角索引 diag_indices_from(arr) 获取arr对角索引 mask_indices(n,mask_func[,k]) 根据mask_func获取n * n数组索引 tril_indices(n[,k,m]) n * m的下三角索引 triu_indices(n[,k,m]) n * m的上三角索引 tril_indices_from(arr[,k]) arr的下三角索引 triu_indices_from(arr[,k]) arr的下三角索引 np.ndindex(*args) == np.broadcast(*np.indices(*args)) Searching 索引 Routine Function Version Method Version argwhere(a) 非0点坐标数组 无 argmax(a[,axis,out]) 展平后位置，存在NaN则返回0 argmin(a[,axis]) nanargmax(a[,axis]) 忽略NaN nanargmin(a[,axis]) searchsorted(a,v[,side,sorter]) 应插入（保持有序）位置 Value ManipulationValue Extraction Routine Function Version Method Version take(a,indices[,axis,out,mode]) 按indices沿给定轴获取超平面（缺省将数组展平） take_along_axis(arr,indices,axis) 将arr、indices沿axis匹配，选取元素 无 compress(condition,a[,axis,out]) 按bool数组condition沿给定轴axis选取超平面（缺省将数组展平） extract(condition,arr) 在展平数组上抽取元素 无 choose(a,choices[,out,mode]) 根据a广播后元素值选择choices中数组填充对应位置 select(condlist,choicelist[,default]) condlist中首个真值对应的choicelist数组填充对应位置 无 diag(v[,k]) 从2维v抽取对角、或以1维v作为对角 无 diagonal(a[,offset,axis1,axis2]) 返回给定对象 take：沿给定轴从数组中获取元素 axis为None时，按展平后获取indices指定元素， 非None时 函数行为同高级索引 指定axis可以简化通过高级索引获取指定轴的元素 基本元素为数组在该轴的切片 123456Ni, Nk = a.shape[:axis], a.shape[axis+1:]Nj = indices.shapefor ii in np.ndindex(Ni): for jj in np.ndindex(Nj): for kk in np.ndindex(Nk): out[ii+jj+kk] = a[ii+(indices[jj],)+kk] take_along_axis：匹配给定轴方向的1维索引、数据切片， 获取元素 基本元素为单个元素 将indices和arr对齐，除给定维度外，其余维度 大小均须相同 其余维度给定下，按照indices在超平面上给出的 位置获取对应的元素 即take以超平面为单位获取整个超平面的元素，而 take_along_axis按元素为单位，沿给定轴方向调整 元素顺序 np.argsort、np.argpartition等函数能够返回适合此 函数的索引 123456789N1, M, Nk = arr.shape[:axis], arr.shape[axis], arr.shape[axis+1:]J = indices.shape[axis]out = np.empty(Ni + (J,) + Nk)for ii in np.ndindex(Ni): for kk in np.ndindex(Nk): a_1d = arr[ii + np.s_[:,] + kk] indices_1d = indices[ii + np.s_[:,] +kk] out_1d = out[ii + np.s_[:,] + kk] out_1d = a_1d[indices_1d[j]] np.choose choices：数组序列，其中数组和a需广播兼容 若本身为数组，则其最外层被视为序列 逻辑 a、choices中数组共同广播 广播结果的shape即为结果shape，其中a取值为n 处用数组choices[n]填充 1np.choose(a,choices) == np.array([choices[a[I]][I] for I in np.ndindex(a.shape)]) np.select 使用各位置condlist首个真值出现的位序值构建a，则 等价于np.choose(a,choicelist) （不考虑缺省值） np.extract 等价于np.compress(np.ravel(condition), np.ravel(arr)) 若condition为bool数组，也等价于arr[condition] Value Modification Routine Function Version Method Version place(arr,mask,vals) 按照mask循环使用vals中值替换arr中元素 无 put(a,ind,v[,mode]) 同place，但根据展平索引ind替换 put_along_axis(arr,indices,values,axis) 匹配indices和arr沿axis分量，替换值 无 copyto(dst,src[,casting,where]) 根据bool数组where替换dst中元素 无 putmask(a,mask,values) 同copyto 无 fill_diagonal(a,val[,wrap]) 用val填充a的主对角 无 clip(a,a_min,a_max[,out=None,**kwargs]) 裁剪值 where、mask、condition缺省为、等价为bool数组 np.clip是ufunc Sorting Routine Function Version Method Version sort(a[,axis,kind,order,]) 在位排序 lexsort(keys[,axis]) 根据keys中多组键沿axis轴排序（靠后优先级高） 无 msort(a) 沿第1轴排序 无 argsort(a[,axis,kind,order]) 沿axis方向间接排序 sort_complex(a) 先实、后虚排序 partition(a,kth[,axis,kind,order]) 以第kth大小数划分 argpartition(a,kth[,axis,kind,order]) 间接分段 lexsort：按照axis方向、以keys中数组顺序作为权重 进行间接排序 keys：数组序列或2维以上数组 数组最高维视为序列 keys为数组时，最高维被省略 多个数组视为权重不同的排序依据，靠后优先级高 axis：排序所沿轴方向，缺省为-1，沿最低维轴排序 可视为按keys中数组逆序优先级，取用各数组沿轴 方向的间接排序结果 即对每个第1轴、axis构成平面，优先考虑第1轴末尾 axis方向数组进行排序，再依次考虑前序 lexsort、argsort排序方向相同时，lexsort结果中 最后子数组和argsort结果应差别不大 （排序方向相同而不是axis参数取值相同） Logical Test真值测试 Routine Function Version Method Version all(a[,axis,out,keepdims]) 给定轴方向所有元素为真 any(a[,axis,out,keepdims]) 给定轴方向存在元素为真 数组内容 Routine Function Version isfinite(x,/[,out,where,casting,order,...]) 逐元素是否有限 isinf(x,/[,out,where,casting,order,...]) isnan(x,/[,out,where,casting,order,...]) isnat(x,/[,out,where,casting,order,...]) 逐元素是否NaT isneginf(x,/[,out]) isposinf(x,/[,out]) isneginf、isposinf行为类似ufunc，但不是 类型测试 Routine Function Version iscomplex(x) iscomplexobj(x) 复数类型或复数值 isfortran(a) Fortran contiguous isreal(x) isrealobj(x) 实数类型或实数值 isscalar(x) Mathmatics 部分数学函数为ufunc UFunc初等运算 Function Desc add(x1,x2,/[out,where,casting,order,...]) subtract(x1,x2,/[,out,where,casting,...]) multiply(x1,x2,/[,out,where,casting,...]) divide(x1,x2,/[,out,where,casting,...]) true_devide(x1,x2,/[,out,where,casting,...]) floor_devide(x1,x2,/[,out,where,casting,...]) logaddexp(x1,x2,/[,out,where,casting,...]) ln(x1+x2) logaddexp2(x1,x2,/[,out,where,casting,...]) log_2 (x1+x2) negative(x,/[,out,where,casting,order,...]) positive(x,/[,out,where,casting,order,...]) power(x1,x2,/[,out,where,casting,order,...]) x1^x2 float_power(x1,x2,/[,out,where,casting,...]) x1^x2 remainder(x1,x2,/[,out,where,casting,...]) 求余/取模 mod(x1,x2,/[,out,where,casting,order,...]) 求余/取模 fmod(x1,x2,/[,out,where,casting,order,...]) 求余/取模 divmod(x1,x2,/[,out1,out2],/[out,...]) absolute(x,/[,out,where,casting,order,...])/abs rint(x,/[,out,where,casting,order,...]) sign(x,/[,out,where,casting,order,...]) heaviside(x1,x2,/[,out,where,casting,...]) 阶跃函数 conj(x,/[,out,where,casting,...]) 对偶 exp(x,/[,out,where,casting,order,...]) exp2(x,/[,out,where,casting,order,...]) log(x,/[,out,where,casting,order,...]) log2(x,/[,out,where,casting,order,...]) log10(x,/[,out,where,casting,order,...]) expm1(x,/[,out,where,casting,order,...]) 计算exp(x)-1 log1p(x,/[,out,where,casting,order,...]) 计算ln(x+1) sqrt(x,/[,out,where,casting,order,...]) 非负平方根 square(x,/[,out,where,casting,order,...]) cbrt(x,/[,out,where,casting,order,...]) 立方根 reciprocal(x,/[,out,where,casting,order,...]) 倒数 gcd(x,/[,out,where,casting,order,...]) 最大公约数 lcm(x,/[,out,where,casting,order,...]) 最小公倍数 out参数可用于节省内存，如：G=A*B+C 等价于：t1=A*B; G=t1+C; del t1; 可利用out节省中间过程内存：G=A*B; np.add(G,C,G) UFunc Floating函数 Routine Function Version fabs(x,/[,out,where,casting,order,...]) 不可用于复数 signbit(x,/[,out,where,casting,order,...]) signbit是否设置，即&lt;0 copysign(x1,x2,/[,out,where,casting,order,...]) 根据x1设置x2的signbit nextafter(x1,x2,/[,out,where,casting,order,...]) x1朝向x2的下个浮点数，即变动最小精度 spacing(x,/[,out,where,casting,order,...]) x和最近浮点数距离，即取值的最小精度 modf(x[,out1,out2],/[,out,where],...) 返回取值的整数、小数部分 ldexp(x1,x2,/[,out,where,casting,...]) 计算x1*2**x2，即还原2为底的科学计数 frexp(x[,out1,out2],/[,out,where],...) 返回2为底的科学计数的假数、指数 floor(x,/,out,*,where,...) ceil(x,/,out,*,where,...) trunc(x,/,out,*,where,...) rint(x,/[,out,where,casting,order,...]) 最近整数 around(a[,decimals,out])/round/round_ fix(x[,out]) 向零点取整 np.fix不是ufunc，但行为类似 比较函数 数值比较 np.equal()更多应用于整形比较，比较浮点使用 np.isclose()更合适 np.allclose()则是判断数组整体是否相同 array_equal(a1,a2)数组a1、a2相同 array_equiv(a1,a2)数组a1、a2广播后相同 逻辑运算符 &amp;、|、~：逐元素逻辑运算 优先级高于比较运算符 and、or、not：整个数组的逻辑运算 np.maximum()、np.minimum()函数 max()寻找最大值效率比np.maximum.reduce()低，同样 min()效率也较低 UFunc比较函数 Routine Function Version Method Version greater(x1,x2,/[,out,where,casting,...]) &gt; greater_equal(x1,x2,/[,out,where,casting,...]) &gt;= less(x1,x2,/[,out,where,casting,...]) &lt; less_equal(x1,x2,/[,out,where,casting,...]) &lt;= not_equal(x1,x2,/[,out,where,casting,...]) != equal(x1,x2,/[,out,where,casting,...]) == logical_and(x1,x2,/[,out,where,casting,...]) 逐元素and and logical_or(x1,x2,/[,out,where,casting,...]) or logical_xor(x1,x2,/[,out,where,casting,...]) 无 logical_not(x1,x2,/[,out,where,casting,...]) not maximum(x1,x2,/[,out,where,casting,...]) 逐元素选择较大者 minimum(x1,x2,/[,out,where,casting,...]) 逐元素选择较小者 fmax(x1,x2,/[,out,where,casting,...]) 逐元素选择较大者，忽略NaN fmin(x1,x2,/[,out,where,casting,...]) 逐元素选择较小者，忽略NaN 非UFunc Routine Function Version isclose(a,b[,rtol,atol,equal_nan]) 逐元素容忍度范围内相等 allclose(a,b[,rtol,atol,equal_nan]) all(isclose()) array_equal(a1,a2[,equal_nan]) 数组整体 array_equiv(a1,a2) 广播后相等 UFunc Bit-twiddling函数 Routine Function Version bitwise_and(x1,x2,/[,out,where,...]) bitwise_or(x1,x2,/[,out,where,...]) bitwise_xor(x1,x2,/[,out,where,...]) invert(x,/[,out,where,casting,...]) left_shift(x1,x2,/[,out,where,casting...]) left_shift(x1,x2,/[,out,where,casting...]) UFunc 三角函数 Routine Function Version sin(x,/[,out,where,casting,order,...]) cos(x,/[,out,where,casting,order,...]) tan(x,/[,out,where,casting,order,...]) arcsin(x,/[,out,where,casting,order,...]) arccos(x,/[,out,where,casting,order,...]) arctan(x,/[,out,where,casting,order,...]) arctan2(x1,x2,/[,out,where,casting,order,...]) 考虑象限下，arctan(x1/x2) hypot(x1,x2,/[,out,where,casting,order,...]) 计算斜边 sinh(x,/[,out,where,casting,order,...]) 双曲正弦 cosh(x,/[,out,where,casting,order,...]) tanh(x,/[,out,where,casting,order,...]) arcsinh(x,/[,out,where,casting,order,...]) arccosh(x,/[,out,where,casting,order,...]) arctanh(x,/[,out,where,casting,order,...]) deg2rad(x,/[,out,where,casting,order,...]) 角度转换为弧度 rad2deg/degrees(x,/[,out,where,casting,order,...]) 弧度转换为角度 基本数学 Routine Function Version Method Version prod(a[,axis,dtype,out,keepdims,...]) nanprod(a[,axis,dtype,out,keepdims,...]) 无 sum(a[,axis,dtype,out,keepdims,...]) nansum(a[,axis,dtype,out,keepdims,...]) 无 cumprod(a[,axis,dtype,out,keepdims,...]) 累乘（也可用ufunc.accumulate） cumsum(a[,axis,dtype,out,keepdims,...]) 累加 nancumprod(a[,axis,dtype,out,keepdims,...]) NaN视为1 无 nancumsum(a[,axis,dtype,out,keepdims,...]) NaN视为0 无 diff(a[,n,axis,prepend,append,...]) 沿给定轴1阶差分（保持类型不变，注意溢出） 无 ediff1d(ary[,to_end,to_begin] 沿展平顺序1阶差分 无 gradient(f,*varargs,**kwargs) 梯度 无 cross(a,b[,axisa,axisb,axisc,axis]) 向量叉积 无 trapz(y[,x,dx,axis]) 梯形法则定积分 无 复数运算 Routine Function Version Method Version angle(z[,deg]) 角度 无 real(val) 实部 imag(val) 虚部 conj/conjugate(x,/[,out,where,casting,order,...]) 复共轭 Miscellaneous Routine Function Version nan_to_num(x[,copy,nan,posinf,neginf]) 替换NaN、inf为数值 real_if_close(a[,to]) 虚部接近0则省略 interp(x,xp,fp[,left,right,period]) 1维线性插值 polyfit(x,y,deg[,rcond,full,w,cov]) 最小二乘多项式拟合 Statistics axis=None：默认值None，表示在整个数组上执行操作 Count Routine Function Version count_nonzero(a[,axis]) 顺序 Routine Function Version Method Version amin/min(a[,axis,out,keepdims,initial,where]) amax/max(a[,axis,out,keepdims,initial,where]) nanmin(a[,axis,out,keepdims,initial,where]) 忽略NaN nanmax(a[,axis,out,keepdims,initial,where]) ptp(a[,axis,out,keepdims]) 极差 percentile(a,q[,axis,out,...]) q取值[0-100] 无 nanpercentile(a,q[,axis,out,...]) 无 quantile(a,q[,axis,out,overwrite_input,...]) q取值[0,1] 无 nanquantile(a,q[,axis,out,...]) 无 均值、方差 Routine Function Version Method Version median(a[,axis,out,overwrite_input,keepdims]) 无 average(a[,axis,weights,returned]) 无 mean(a[,axis,dtype,out,keepdims]) std(a[,axis,dtype,out,ddof,keepdims]) 标准差 var(a[,axis,dtype,out,ddof,keepdims]) 方查 nanmedian(a[,axis,out,overwrite_input,...]) 无 nanmean(a[,axis,dtype,out,keepdims]) 无 nanstd(a[,axis,dtype,out,ddof,keepdims]) 无 nanvar(a[,axis,dtype,out,ddof,keepdims]) 无 相关系数 Routine Function Version corrcoef(x[,y,rowvar,bias,ddof]) Pearson积差相关系数 correlate(a,v[,mode]) 卷积 convolve(a,v[,mode]) 离散、线性卷积 cov(m[,y,rowvar,bias,ddof,fweights,...]) 方差 Array CreationOnes and Zeros Routine Function Version empty(shape[,dtype,order]) 无初始化 empty_like(prototype[,dtype,order,subok,...]) shape、类型同prototype eye(N[,M,k,dtype,order]) 对角为1的2D数组 identity(n[,dtype]) 单位矩阵数组 ones(shape[,dtype,order]) ones_like(a[,dtype,order,subok,shape]) zeros(shape[,dtype,order]) zeros_like(a[,dtype,order,subok,shape]) full(shape,fill_value[,dtype,order]) 全full_value数组 full_like(a,fill_value[,dtype,order,...]) Numerical Ranges Routine Function Version arange([start,]stop[,step][,dtpye]) 给定间距 linspace(start,stop[,num,endpoint]) 给定数量，等差均分 geomspace(start,stop[,num,endpoint,base,...]) 等比均分 logspace(start,stop[,num,endpoint,base,...]) 在log10尺度上均分，同np.power(10, np.linspace(start,stop)) Repetition Routine Function Version Method Version tile(A,reps) 重复A（可是数组）创建一维数组 无 repeat(a,repeats[,axis]) 沿已有轴重复a创建 Matrix-Relative Routine Function Version diag(v[,k]) 从2维v抽取对角、或以1维v作为对角 diagflat(v[,k]) tri(N[,M,k,dtype]) 对角线及以下为1、其余为0矩阵 tril(m[,k]) 下三角 triu(m[,k]) 上三角 vander(x[,N,increasing]) Vandermonde矩阵 From Existing Data Routine Function Version array(object[,dtype,copy,order,subok,ndmin]) copy(a[,order]) frombuffer(buffer[,dtype,count,offset] 从缓冲（如字节串）创建数组 fromfunction(function,shape,**kwargs) 以坐标为参数，从函数创建数组 fromiter(iterable,dtype[,count]) 改变数组数据类型也可以视为是创建新数组 转入、转出类型转出 Routine Method Version .item(*args) 根据args选择元素复制至标准python标量 .tolist() 转换为.ndim层嵌套python标量列表 .itemset(*args) 插入元素（尝试转换类型） .byteswap([inplace]) 反转字节序 .view([dtype,type]) 创建新视图 .getfield(dtype[,offset]) 设置数据类型为指定类型 .setflags([write,align,uic]) 设置标志 .fill(value) 使用标量填充 打包二进制 Function Desc packbits(a[,axis,bitorder]) 元素打包为标志位，0补足，返回uint8数组 upackbits(a[,axis,bitorder]) 输入、输出 Routine 格式 输入 输出 dump(file) pickle 无 文件 tofile(fid[,sep,format]) 内存内容（sep=&quot;&quot;）、分割符串 无 文件 fromfile(file[,dtype,count,sep,offset]) 字节串、分割符串 文件 数组 save(file,arr[,allow_pickle,fix_imports]) .npy 数组 文件 savez(file,*args,**kwds) 非压缩的.npz （多个）数组 文件 savez_compressed(file,*args,**kwds) 压缩的.npz （多个）数组 无 load(file[,mmap_mode,allow_pickle,...]) .npy、.npz、pickle 文件 数组 savetxt(fname,X[,fmt,delimiter,newline,...]) 分割符串 二维以下数组 文件 loadtxt(fname[,dtype,comments,delimiter,...]) 分割符串 文件 数组 genfromtxt(fname[,dtype,comments,...]) 分割符串 文件 数组 fromregex(file,regexp,dtype[,encoding]) 正则表达式结构 文件 数组 串 Routine Function Version Method Version array2string(a[,max_line_width,precision,...]) __str__ array_repr(arr[,max_line_width,precision,...]) __repr__ array_str(arr[,max_line_width,precision,...]) __str__ dumps() 无 pickle序列化 loads(*args,**kwargs) pickle 字节串 数组 tobytes([order])/tostring 内存内容字节串 fromstring(string[,dtype,count,sep]) 从字符串、字节串（sep=&quot;&quot;，且缺省）创建1维数组 np.loads即pickle.loads，不建议使用 np.fromstring sep=&quot;&quot;：从二进制字节串中创建数组，类frombuffer sep置为分割符时，只能指定一种元素分隔符，也只能 解析1维数组的字符串 字符串输出格式 Routine Function Version format_float_positional(x[,precision,...]) 格式化位置计数 format_float_scientific(x[,precision,...]) 格式化科学计数 set_printoptions([precision,threshold,...]) get_printoptions() set_string_function(f[,repr]) printoptions(*args,**kwargs) 设置打印选项的上下文管理器 binary_repr(num[,width]) 二进制字符串 base_repr(number[,base,padding]) Data Source Function Desc DataSource([destpath]) 通用数据源文件（file，http，ftp等）","link":"/Python/Numpy/ndarray_routines.html"},{"title":"Pandas函数目录","text":"“内容结构”变换合并merge123456789DF = pd.merge( left(DF), right(DF), on=col_name/[col_names], left_on=&quot;left_col_name&quot;, right_on=&quot;right_col_name&quot;, left_index=False/True, right_index=False/true, how=&quot;Inner&quot;/&quot;outer&quot;/&quot;left&quot;/&quot;right&quot;) 功能：合并操作，类似于sql的join操作 参数 on：merge合并基准列，可以是多个列名称的list，df1、 df2仅有一列名称相同时可省略，否则返回空DF对象 left_on、right_on：df1、df2合并基准列名称不同时 使用 left_index、right_index：默认为False，值为 True时使用索引作为基准进行合并（此时也可以使用 df1.join(df2)） how：合并方式，默认是inner join，参数取值：’outer’ 、’left’、’right’（不知道能不能取’inner’，这个应该 是默认取值，可以使用） 其他 df1、df2有多个列名相同且不全是合并基准列时，返回的 DF对象的重复列名称会改变 join1234567DF = df1.join( other(DF/Ser/[DF]), on=None/[col_names], how=&quot;Left/right/outer/inner&quot;, lsuffix=str, rsuffix=str, sort=False) 说明：和其他DF对象进行join操作 参数 other 参数为Ser时，必须设置field名称 on 默认None，按照index-on-index进行join 也可以按照col_name进行join how：同上 lsuffix：df1重名列使用的后缀 rsuffix：df2重名列使用的后缀 sort：按照join-key排序 concat1234567891011Df/Ser = pd.concat( objs=[Ser, DF, dict], axix=0/1/&quot;index&quot;/&quot;columns&quot;, join=&quot;Outer&quot;/&quot;inner&quot;, join_axes=None/[index], ignore_index=False/True, keys=None/[]/[()], levels=None/[], names=None/[index_names], verify_integrity=False, copy=True) 说明：以某个轴为方向将多个Series对象或DF对象拼接 参数 objs dict作为参数值传递，排序后的keys传递给keys join：处理其他轴的方式（其他轴长度、命名不同） join_axes：指定其他轴的index ingore_index：默认False，为True拼接后的DF的 Index将为RangeIndex keys：指定构建多级索引最外层Index levels：用于构建多重索引的具体层级，默认从keys 推断 names：返回DF对象索引名称 verify_integrity：默认False，不检查返回DF对象 是否含有重复index copy：默认拷贝数据 其他 pd.concat只涉及拼接方向，而merge只能沿列数增加的 方向“拼接” pd.concat()时即使有相同的列名称、index序号也不会 重命名 pd.concat(axis=1,...)和 pd.merge(left_index=True, right_index=True,...)的 作用应该是一样的，只是不会将相同的列名称重命名 pd.merge可以指定合并基准列，而pd.concat只能按 Index“合并”，且只能inner join或时outer join 注意事项 pd.concat默认会对索引进行排序，所以若索引包含不可 比较元素则会报错，尤其是在多重索引情况下 改变索引类型规避 1234# 改为categorical索引df.index.astype(&quot;categorical&quot;)# 改为str类型df.index.astype(str) reset索引规避 12df_new = pd.cancat([df1.reset_index(), df2.reset_index()])df_new = df_new.set_index(col_name) pd.concat连接会尝试转换数据类型，如： pd.Timestamp可能会被转换为int combine_first12Ser = ser1.combine_first(other(Ser))Df = df1.combine_first(other(DF)) 说明：和其他DF/Ser进行元素级别的combine，即填充NULL 元素 元素级别 返回对象包含所有的index 增、删drop12345678DF/None = df1.drop( labels=None/label/[labels], axis=0/1/&quot;index&quot;/&quot;columns&quot;, index=None/index_name/[index_names], columns=None/col_name/[col_names], level=None/int/level_name, inplace=False, errors==&quot;Raise/ignore&quot;) 说明：删除df1某轴上的labels 参数 columns/index：替代axis+label指定需要删除的 列/行 [new_col_name]12df1[new_col_name] = listdf1.loc[new_index_name] = list 说明：添加新列/行 .iloc[new_index_name]不可用 append1234DF = df1.append( other(DF/Ser/dict/[]), ignore_index=False, verify_integrity=False) 说明：将other行追加到df1 del12del df1[col_name] # python自身语法直接删除某列 形、态变换形状stack123DF/Ser = df1.stack( level=-1/int, dropna=True) 说明：旋转level级列索引 参数 dropna：默认剔除返回DF/Ser对象中NULL行 unstack123DF/Ser = df1.unstack( level=-1/int, fill_value=None) 说明：旋转level级行索引 参数 fill_value：替换NaN的值 其他 两个函数好像都有排序操作，df1.unstack().stack()会 合并层级索引 排序sort_index12345678DF = df1.sort_index( axis=0/1, level=None/int/str, ascending=True, inplace=False, kind=&quot;Quicksort&quot;/&quot;mergesort&quot;/&quot;heapsort&quot;, na_position=&quot;First&quot;/&quot;last&quot;, sort_remaining=True/False) 说明：按照labels排序 参数 kind：排序方法 na_position：默认将NaN放在开头 对多重索引无效 sort_remaining：默认依次对剩余层级排序 sort_value1234567DF = df1.sort_value( by(label/[labels]), axis=0/1, ascending=True/False, inplace=False, kind=&quot;Quicksort&quot;/&quot;mergesort&quot;/&quot;heapsort&quot;, na_position=&quot;Last&quot;/&quot;first&quot;) 说明：依某labels（行、列）值排列 rank1234567DF = df1.rank( axis=0/1, method=&quot;Average&quot;/&quot;min&quot;/&quot;max&quot;/&quot;first&quot;/&quot;dense&quot;, numeric_only=None/True/False, na_option=&quot;Keep&quot;/&quot;top&quot;/&quot;bottom&quot;, ascending=True, pct=False) 说明：沿轴计算数值型数据的rank rank值相同者取rank值平均 参数 method average：组（延轴分组）rank平均 min/max：组内最小/大 first：label出现顺序优先 dense：类似min，但是rank值总是增加1 numeric_only：默认不考虑含有非数值型数据label 但是文档上确实写默认值为None na_option keep：NaN值rank值不变 top：NaN作为“小”值 bottom：NaN作为“大”值 ascending：默认小值rank值小 pct：默认不计算rank值占比 take123456DF = df1.take( indices([indice]), axis=0/1, covert=True, is_copy=True, **kwargs) 说明：按照indices对应的labels顺序返回DF 参数 indices：指明返回indices、及其顺序 indices是指行数，不是labels 可以为负值indice，类似list convert：是否处理负值indice（将废除，均处理） is_copy：默认创建副本返回 reindex1234567891011DF = df1.reindex( labels=None/[labels]/Index, index=None/[labels]/Index, columns=None/[labels], axis=0/1/&quot;index&quot;/&quot;columns&quot;, method=None/&quot;backfill&quot;/&quot;bfill&quot;/&quot;pad&quot;/&quot;ffill&quot;/&quot;nearest&quot;, copy=True/False, level=None/int/level_name, fill_value=NaN/scalar, limit=None/limit, tolerance=scalar/array-like) 说明：将DF对象转换有其他Index的对象 可以包含之前没有的labels 类似于labels版本.take，是选择不是重命名 参数 labels：新Index，配合axis决定替换轴 index/columns：两根轴的Index method：新labels值填补方法 用于填补的值不一定会出现在返回DF对象中，可能是 使用原DF对象中未被选择labels copy：默认拷贝副本 fill_value：新labels值填补值 limit：允许最长连续使用method方法填补值 tolerance：使用method方法填补新labels值时，用于 填补labels和新labels的最大差距 超过tolerance则为默认NaN 数据处理简单统计12345678910111213141516171819202122232425Ser = df1.sum( level=None/0/1, axis=0/1)Ser = df1.mean( axis=0/1)Ser = df1.std( axis=0/1)DF = df1.describe()DF = df1.corr()DF = df1.cov()float = ser1.corr( ser1)Ser = df1.corwith( other(DF/Ser), axis=0/1, drop=False/True) # `other`为DF对象时计算相同名称相关系数 value_count1234567Ser = pd.value_counts( values(ndarray(1d)), sort=True/False, ascending=False/True, normalize=False/True, bins=None/int/[num], dropna=True/False) 说明：计算hisgram 参数 sort：默认按值排序 normalize：默认不正则化（计算相对histgram） bins：hisgrams划分bins 默认每个值划分为一个bins 给出int时表示数目，(min, max]均等分 给出[num]计算列表内数量（范围外不考虑） dropna：默认不计算NaN值个数 quantile12345Ser/DF = df1.quantile( q=0.5/float/[float], axis=0/1/&quot;index&quot;/&quot;columns&quot;, numeric_only=True, interpolation=&quot;linear&quot;) 说明：计算q分位数 参数 q：分位，可以是列表，计算多个分位数 interpolation：分位数计算方式（分位数位i、j间） linear：i+(j-i)*fraction（线性回归） low：i high：i+1 nearest：i、i+1中近者 midpoint：(i+j)/2 元素级Applyapply12345678DF/Ser = df1.apply( func(func/{label: func}), axis=0/1/&quot;index&quot;/&quot;columns&quot;, broadcast=False, raw=False, reduce=None/True/False, args=(), **kwargs) 说明：对df1沿轴方向labels应用func 可以用于DFGB对象 为聚合函数时返回DF对象Index为groupby键，类似于 agg 非聚合函数时返回DF对象为原Index，类似于 transform，但包含用于groupby的label 但是此时其他参数无法使用，func也仅能为单一 function，而agg可以使用各种 参数 broadcast：仅对aggregation（聚合）函数，默认不保持 原shape 0.23.0 deprecated raw：默认不是将label作为ndarray对象传递，而是保持 Series对象 如果函数处理nadarry对象，True性能更好 reduce：默认根据函数判断是否返回DF False：尽量返回DF对象 0.23.0 deprecated result_type expand：返回DF对象 reduce：尽量返回Ser对象 broadcast：保持原shape返回 0.23.0 new args：传递给func的VAR_POSITIONs kwargs：传递给func的VAR_KEYWORDs agg12345DF = df1.agg( func(callable/&quot;func_name&quot;(str)/{label:func}/[], axis=0/1/&quot;index&quot;/&quot;columns&quot;, *args, **kwargs) 说明：聚合 可以用于DFGB，必然返回DF，因此要求函数结果必须 聚合 如果分组结果都只有单个label，函数可以非聚合 如果分结果中由多label分组，函数必须聚合 参数 func dict键应为column labels，值为function transform1234DF = df1/dfgb1.transform( func(callable/&quot;func_name&quot;(str)/dict/[]), *args, **kwargs) 说明：返回应用func处理后DF 应用于DF对象时，等同于axis=0的agg、apply 应用于DFGB对象时，无价值，和应用于原DF对象结果一样， 仅剔除groupby label 替换replace1234567DF = df1.replace( to_replace=None/str/regex/num/[]/{}/Series, value=None/str/num/[]/{}, inplace=False, limit=None/int, regex=False, method=&quot;pad&quot;/&quot;ffill&quot;/&quot;bfill&quot;/&quot;backfill&quot;) 说明：替换 参数 to_replace：被替换对象 str/regex/num：匹配str/regex/num的值被替换为value [ ] value也为list时，长度必须相同 str元素可看作regex {} nested dict顶层键匹配列label，然后应用对应 子dict进行匹配（此时包含value功能） 非顶层键可以为regex None：此时regex必为str/[]/{}/Ser value：替换值 str/num：替换值 {}：键匹配列label然后替换值，无匹配保持原样 [ ]：长度必须和to_replace相同 limit：允许最长连续bfill、ffill替换 regex 为True时，to_replace、value将作为regex 代替to_replace作regex替换 method：to_replace为list时替换方法 说明 to_replace为{regex:str}时，只替换DF中str匹配的部分 ，如果需要替换整个str，需要^.*str.*$匹配整个str 但为{regex:int}时，不需要^.*str.*$也会匹配整个str 并替换为int where123456789df = df1.where( cond(df(bool)/callable/[]), other=num/df/callable, inplace=false, axis=none, level=none, errors=&quot;raise&quot;, try_cast=False, raise_on_error=None) 说明：mask True，替换False为other值，默认（other 中无法找到对应值）NaN cond、other是按照[index][col]对应位置，而不是 打印位置 参数 cond DF(bool)：True保持原值不变，False从other 替换 callable：应用在df1上，返回DF(bool)，不应改变 `df cond不提供位置视为被替换1` other num：替换为num DF：替换值 callable：应用在df1上，返回DF用于替换 axis：alignment axis if needed level：alignemnt level if needed errors raise：允许raise exceptions ignore：suppress exceptions，错误时返回原对象 try_cast：默认不尝试将结果cast为原输入 mask123456789DF = df1.mask( cond(DF(bool)/callable/[]), other=num/DF/callable, inplace=False, axis=None, level=None, errors=&quot;raise&quot;, try_cast=False, raise_on_error=None) 说明：True、False mask规则同where相反，其他同 筛选isin12DF = df1.isin( values(iterable/{}/DF)) 说明：判断元素是否存在于values中 参数 values iterable：元素在iterable中为True {}：df1元素在dict中对应键值中存在为True DF：df1元素在DF对应index、columns labels存在 才为True 类型转换to_numeric12345Ser = pd.to_numeric( arg([]/()/ndarray(1d)/Ser), errors=&quot;Raise&quot;/&quot;ingore&quot;/&quot;coerce&quot;, downcast=None/&quot;integer&quot;/&quot;signed&quot;/&quot;unsigned&quot;/&quot;float&quot;) 说明：转换为numeric类型 参数 errors raise：无效值将raise exception coerce：无效值设为NaN ignore：无效值保持原样 downcast：根据参数downcast值为“最小”类型 downcast过程中exception不受errors影响 to_datetime123456789101112Ser = pd.to_datetime( arg(int/float/str/datetime/[]/()/ndarray(1d)/Ser/DF, error=&quot;Raise&quot;/&quot;ignore&quot;/&quot;coerce&quot;, dayfirst=False, yearfirst=False, utc=None/True, box=True/False, format=None/str, exact=True, unit=&quot;ns&quot;/&quot;D&quot;/&quot;s&quot;/&quot;ms&quot;/&quot;us&quot;/&quot;ns&quot;, infer_datatime_format=False, origin=&quot;unit&quot;) 说明：转换为datetime 参数 dayfirst：处理类”10/11/12”，设置day在前 yearfirst：处理类”10/11/12”，设置year在前 utc：默认不返回UTC DatatimeIndex box True：返回DatetimeIndex False：返回ndarray值 format：parse格式，如”%d/%m/%y %H:%M:%S” exact：默认要求arg精确匹配format unit：arg传递数值时作为单位 infer_datatime_format：在format为None时，尝试 猜测格式，并选择最快的方式parse，耗时5~10倍 origin：决定参考（起始）时间 unix：起始时间：1970-01-01 julian：4714 BC 1.1（此时unit必须为D） infer_objects1DF = df1.infer_objects() 说明：soft转换数据类型，无法转换保持原样 astype12345DF = df.astype( dtype(dtype/{col_name:dtype}), copy=True, errors=&quot;raise&quot;/&quot;ingore&quot;, **kwargs) 说明：强制转换为dtype类型 参数 copy：默认返回拷贝 kwargs：传递给构造函数的参数 Sermap123Ser = ser1.map( arg={}/Ser/callable, na_action=None/&quot;ignore&quot;) 说明：对Ser中元素进行映射 map对无法配置（dict）返回None而不是保持不变 参数 arg {}：对Ser中值根据键值对映射 callable：对元素应用callable no_action：默认对NA也处理，否则忽略 其他 好像默认会应用类似于apply(convert_type=True)，如 直接取值是np.float64类型，传给函数就变成了float 类型 apply12345Ser = ser1.apply( func(callable/{}/[]), convert_type=True/False, args=(), **kwargs) 说明：在Ser上应用func 参数 func {}：返回多重索引Ser，键作为顶层索引，不是对 不同值应用不同方法 [ ]：返回DF对象，列labels根据list元素命令，list 元素不能聚合、非聚合混合 convert_type：默认转换为合适的类型，否则设为 dtype=object agg12345Ser = ser1.agg( func(callable/{}/[]), axis=0, args=(), **kwargs) 说明：好像和apply完全相同，只是参数不同，但axis没用 分组cut12345678Ser = pd.cut( x(array-like), bins(int/[num]/IntervalIndex), right=True, labels=None/[], retbins=False, precision=3/int, include_lowest=False) 说明：返回各个元素所属区间，同时也是对应indice 参数 bins：左开右闭 int：将x等分（事实上为了包含最小值，bins 左边界会扩展.1%） [num]：定义bins边界 right：默认包含right-most边界 labels：指定生成bins的labels retbins：默认不返回bins，设为True将返回tuple precision：bins labels显示精度 include_lowest：第一个bin是否应该包括最小值 应该仅对bins=[]有效 设为True仍然为左开右闭区间，但是左边界会小于 bins=[]中的最小值 qcut1234567Ser = pd.qcut( x(array-like), q=int/quantile_list, labels=None, retbins=False, precision=3, duplicates=&quot;Raise&quot;/&quot;drop&quot;) 说明：将x按照q划分分位数后进组（即按照数量分组） 参数 q int：划分int个等分位数 [num]：将x元素按照给出分位数分组 duplicates raise：bins边缘不唯一raise exception drop：bins边缘不唯一则丢弃不唯一值 groupby123456789DFGB = df1.groupby( by(col_name), axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs) 说明：根据by对DF分组 参数 by func：应用于DF的Index上，结果作分组依据 dict/Ser：对Index作映射，映射结果作分组依据 array-like：其值依顺序标记DF行，据此分组，因此 要求长度必须和DF行数相同 col_name/[col_name]：根据col_name分组 as_index：默认使用分组依据作为分组Index（labels） sort：默认组内各保持原DF顺序，可以关闭获得更好性能 group_keys：默认在calling apply时，添加group键用于 标识各组 squeeze：为True时尽可能减少返回值维度，否则返回 consistent type IndexIndex值pivot1234DF = df1.pivot( index=None/str, columns=None/str, values=None/str) 说明：根据某列值reshape数据（创建一个枢） 参数 index：用作Index的列名，默认Index columns：用作Column的列名 values：填充进新DF对象的列名，默认所有剩余所有列 （列索引为层级索引） 其他 但是如果选取的两列元素两两组合有重复回报错 set_index123456DF = df1.set_index( keys(col_name/[ ]/[col_names,[ ]]), drop=True, append=False, inplace=False, verify_integrity=False) 说明：用一列/多列作为新DF的Index（row labels） 参数 keys：列名，列名列表 drop：默认删除用作Index的列 append：默认不保留原Index（不以添加方式设置 Index） verify_integrity：默认不检查新Index是否唯一，直至 必要的时候 reset_index123456DF = df1.reset_index( level=None/int/str/[int, str], drop=False, inplace=False, col_level=0/int/str, col_fill='') 说明： 参数 level：默认所有层级 drop：默认将Index作为一列添加 col_level：Index作为列添加进的列索引层次，默认 最高层 col_fill：对于多级索引，Index作为列添加时其他层级 的命名，默认xtts 其他 Index作为新列的名称默认为”index”/“level_0”、 “level_1”等 Index属性swaplevel1234DF = df.swaplevel( i=-2/int/str, j=-1/int/str, axis=0) 说明：交换i、j两层索引 rename12345678DF = df.rename( mapper=None/dict/func, index=None/dict/func, columns=None/dict/func, axis=0/1/&quot;index&quot;/&quot;columns&quot;, copy=True, inplace=False, level=None/int/str) 说明：修改labels（行、列名） 参数 mapper：labels的重命名规则 index/columns：行、列labels重命名规则 mapper+axis index columns copy：默认复制数据 inplace为True时，此参数无效 level：默认重命名所有level add_prefix12DF = df.add_prefix( prefix(str)) 说明：为列labels添加前缀 特殊值重复unique1234bool = ser1.is_unique # 无重复元素**属性**为`True`Ser = ser1.unique() # 返回非重复元素 duplicated123Ser(bool) = df1.duplicated( subset=None/label/[labels], keep=&quot;First&quot;/&quot;last&quot;/False) 说明：返回标识“副本（元素相同）”行的Ser(bool) 参数 subset：默认检查所有列，否则检查指定列 keep first：重复者除第一个外标记为True last：重复者除最后一个外标记为True False：重复者均标记为True 1234DF = df1.drop_duplicates( subset=None/label/[labels], keep=&quot;First&quot;/&quot;last&quot;/False, inplace=False) 空null12DF(bool) = df1.isnull()DF(bool) = df1.notnull() dropna123456DF = df1.dropna( axis=0/1, how=&quot;Any&quot;/&quot;all&quot;, thresh=None/int, subset=None/label/[labels], inplace=False) 说明：剔除空labels（及其数据） 参数 how：默认any NaN值存在剔除label thresh：剔除label的NaN值阈值 subset：指定考虑的labels fillna12345678DF = df1.fillna( value=None/scalar/dict/Ser/DF, method=None/&quot;backfill&quot;/&quot;bfill&quot;/&quot;pad&quot;/&quot;ffill&quot;, axis=0/1/&quot;index&quot;/&quot;columns&quot;, inplace=False, limit=None/int, downcast=None/dict, **kwargs) 说明：填补NaN值 参数 value：用于填补NaN的值，dict-like时无法找到的NaN 不被填补 method “pad”/“ffill”：使用last（前一个）值填补 “bfill”/“backfill”：使用next（后一个）值填补 limit：填补允许的最大连续NaN值，超过部分保留NaN downcast：数据类型精度降级dict，或者&quot;infer&quot;由 自行推断 其他any123456Ser = df1(bool).any( axis=0/1/&quot;index&quot;/&quot;columns&quot;, bool_only=None, skipna=True, level=None/int/str, **kwargs) 说明：label（行、列）对应值存在真返回True 参数 skipna：默认skip NA，如果全label为NA则结果为NA level：默认考虑整个索引 bool_only：默认将所有转换为bool值再做判断","link":"/Python/Pandas/df_funcs.html"},{"title":"Python类用法实例","text":"延迟计算使用描述器类构造延迟计算属性 主要目的是为了提升性能 避免立即计算 缓存计算结果供下次使用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class lazyproperty: def __init__(self, func): self.func = func def __get__(self, instance, cls): if instance is None: return self else: value = self.func(instance) setattr(instance, self.func.__name__, value) # 计算完成之后，缓存计算结果于类实例中 return value # 描述器仅仅定义一个`__get__`方法，比通常具有更弱的绑定 # 这里，只有被访问属性不在**实例**底层字典`__dict__`中时 # `__get__`方法才会被触发 # 描述器属性是类属性，但优先级好像是高于实例属性？？？def lazyproperty_unchangable(func): # 这个版本的延迟计算，使用property属性限制对结果的修改 name = &quot;_lazy_&quot; + func.__name __ @property # 这里`@property`是在类外定义的 # 并且，这里实际上返回的是`property`类实例，也不需要 # `wraps(func)`保持原函数元信息 # 但此时所有的操作都定向到`getter`函数上，效率较低 def lazy(self): if hasattr(self, name): return getattr(self, name) else: value = func(self) setattr(self, name, value) return value return lazyimport mathclass Circle: def __init__(self, radiu): self.radius = radius @lazyproperty def area(self): print(&quot;computing area&quot;) return math.pi * self.radius ** 2 # 等价于`area = lazyproperty(area)` # 所以是真的把描述器类实例作为类属性 @lazyproperty def perimeter(self): print(&quot;computing perimeter&quot;) return 2 * math.pi * self.radius 数据模型类型约束使用描述器在对实例某些属性赋值时进行检查 类继承方案基础构建模块创建数据模型、类型系统的基础构建模块 123456789101112131415161718192021222324252627282930313233class Descriptor: def __init__(self, name=None, **opts): self.name = name for key, value in opts.items() setattr(self, key, value) def __set__(self, instance, value): if instance is None: return self instance.__dict__[self.name] = valueclass Typed(Descriptor): def __set__(self, instance, value): if value &lt; 0: raise ValueError(&quot;expected &gt;= 0&quot;) super().__set__(instance, value)class Unsigned(Descriptor): def __set__(self, instance, value): if value &lt; 0: raise ValueError(&quot;expect &gt;= 0&quot;) super().__set__(instance, value)class MaxSized(Descriptor): def __init__(self, name=None, **opts): if &quot;size&quot; not in opts: raise TypeError(&quot;missing size options&quot;) super.__init__(name, **opts) def __set__(self, instance, value): if len(value) &gt;= self.size: raise ValueError(&quot;size must be &lt;&quot; + str(self.size)) super().__set__(instance, value) 具体数据类型123456789101112131415161718class Integer(Typed): expected_type = intclass UsignedInteger(Integer, Unsigned): # 描述器类是基于混入实现的 passclass Float(Typed): expected_type = Floatclass UnsignedFloat(Float, Unsigned): passclass String(Typed): expected_type = strclass SizedString(String, MaxSized): pass 使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Stock: name = SizedString(&quot;name&quot;, size=8) shares = UnsignedInteger(&quot;shares&quot;) price = UnsignedFloat(&quot;price&quot;) def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = pricedef check_attributes(**kwargs): def decrator(cls): for key, value in kwargs.items(): if isinstance(value, Descriptor): value.name = key setattr(cls, key, value) else: setattr(cls, key, value(key)) return cls return decrator@check_attributes(name=SizedString(size=8), shares=UnsignedInteger, price=UnsignedFloat) # 使用类装饰器简化版本class Stock2: def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = priceclass checkmeta(type): def __new__(cls, clsname, bases, methods): for key, value in method.items(): if isinstance(value, Descriptor): value.name = key return type.__new__(cls, clsname, bases, methods)class Stock3(metaclass=checkdmeta): name = SizedString(size=8) shares = UnsignedInteger() price = UnsignedFloat() def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price 装饰器类替代mixin使用类装饰器、元类都可以简化代码，但类装饰器更加灵活 类装饰器不依赖其他任何新技术 类装饰器可以容易的添加、删除 类装饰器能做为mixin的替代技术实现同样的效果，而且速度 更快，设置一个简单的类型属性值，装饰器要快一倍 示例11234567891011121314151617181920212223242526272829def LoggedMapping(cls): cls_getitem = cls.__getitem__ cls_setitem = cls.__setitem__ cls_delitem = cls.__setitem__ # 获取原`cls`的方法，避免死循环调用 def __getitem__(self, key): print(&quot;getting&quot;, str(key)) return cls_getitem(self, key) # 这里使用之前获取的方法指针调用，而不直接使用 # `cls.__getitem__`避免死循环 def __setitem__(self, key, value): pritn(&quot;setting {} = {!r}&quot;, str(key)) return cls_set(self, key, value) def __delitem__(self, key): print(&quot;deleting&quot;, str(key)) return cls_delitem(self, key) cls.__getitem__ = __getitem__ cls.__setitem__ = __setitem__ cls.__delitem__ = __delitem__ return cls@LoggedMappingclass LoggedDict(dict): pass 示例212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667def Type(expected_type, cls=None): if cls is None: return lambda cls: Typerd(expected_type, cls) super_set = cls.__set__ def __set__(self, instance, value): if no instance(value, expected_type): raise TypeError(&quot;expect &quot; + str(expected_type)) super_set(self, instance, value) cls.__set__ = __set__ return clsdef Unsigned(cls): super_set = cls.__set__ def __set__(self, instance, value): if value &lt; 0: raise TypeError(&quot;missing size option&quot;) super_set(self, name, **opts) cls.__init__ = __set__ return clsdef MaxSized(cls): super_init = cls.__init__ def __init__(self, name=None, **opts): if &quot;size&quot; not in opts: raise TypeError(&quot;missing size option&quot;) super_init(self, name, **opts) cls.__init__ = __init__ super_set = cls.__set__ def __set__(self, instance, value): if len(value) &gt;= self.size: raise ValueError(&quot;size must be &lt;&quot; + str(self.size)) super_set(self, instance, value) cls.__set__ = __set__ return cls@Typed(int)class Integer(Descriptor): pass@Unsignedclass UnsignedInteger(Integer): pass@Typed(float)class Float(Descriptor): pass@Unsignedclass UnsignedFloat(Float): pass@Typed(str)class String(Descriptor): pass@MaxSizedclass SizedString(String): pass 自定义容器collections定义了很多抽象基类，可以用于定义自定义基类 collections.SequenceSequence需要实现的抽象方法有： __getitem__ __len__ add 继承自其的类，支持的常用操作：索引、迭代、包含判断、切片 1234567891011121314151617181920212223242526272829303132333435363738from collections import Sequenceimport collectionsclass SortedItems(Sequence): # 必须要实现所有抽象方法，否则报错 def __init__(self, initial=None): self._items = sorted(initial) if initial is not None else [ ] def __getitem__(self, index): return self._items[index] def __len__(self): return len(self._items) def add(self, item): bisect.insort(self._items, item) # `bisect`模块是用于在排序列表中高效插入元素 # 保证在元素插入之后仍然保持顺序 # `SortedItems`继承了`colllections.Sequence`，现在和 # 普通序列无差，支持常用操作：索引、迭代、包含判断、切片def test(): items = SortedItems([5, 1, 3]) print(list(items)) print(items[0], items[-1]) items.add(2) print(list(items)) if instance(items, collections.Iterable): pass if instance(items, collections.Sequence): pass if instance(items, collections.Container): pass if instance(items, collections.Sized): pass if instance(items, collections.Mapping): pass collections.MutableSequenceMutableSequence基类包括需要实现的抽象方法 __getitem__ __setitem__ __delitem__ __len__ insert 提供的可用方法包括； append count：统计某值出现的次数 remove：移除某值的元素 1234567891011121314151617181920212223242526272829303132333435363738394041from collections import MutableSequenceclass Item(collections.MutableSequence): def __init__(self, initial=None): self._items = list(initial) if initial is not None else [ ] def __getitem__(self, index): print(&quot;getting:&quot;, index) return self._items[index] def __setitem__(self, index): print(&quot;setting:&quot;, index) self._items[index] = value def __delitem__(self, index): print(&quot;deleting:&quot;, index) del self._items[index] def insert(self, index, value): print(&quot;inserting:&quot;, index, value) self._items.insert(index, value) def __len__(self): print(&quot;len&quot;) return len(self._items) # 基本支持几乎所有的核心列表方法：`append`、`remove`、 # `count`def count(): a = Items([1, 2, 3]) print(len(a)) a.append(4) # 在末尾添加元素 # 调用了`__len__`、`insert`方法 a.count(2) # 统计值为`2`出现的次数 # 调用`__getitem__`方法 a.remove(3) # 删除值为`3`的元素 # 调用`__getitem__`、`__delitem__`方法 属性的代理访问代理是一种编程模式，将某个操作转移给另一个对象来实现 需要代理多个方法时，可以使用__getattr__ __getattr__方法只在属性、方法不存在时才被调用， 所以代理类实例本身有该属性不会触发该方法，也不会代理 至被代理类 如果需要管理所有对方法、属性的访问，可以定义 __getattribute__，其在对类的所有属性、访问时均会 被触发，且优先级高于__getattr__ __setattr__、__delattr__需要约定是对代理类还是 被代理类操作，通常约定只代理_开头的属性，即代理类 只暴露被代理类公共属性 注意：对象的元信息直接访问能通过__getattr__代理， 但是对应的hook可能无法正常工作，如果需要，要单独为 代理类实现元信息代理方法 通过自定义属性访问方法，可以用不同方式自定义代理类行为， 如：日志功能、只读访问 代理有时候可以作为继承的替代方案：代理类相当于继承了被 代理类 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Proxy: # 这个类用于包装、代理其他类，修改其行为 def __init__(self, obj): self._obj = obj def __getattr__(self, name): print(&quot;getattr:&quot;, name) return getattr(self._obj, name) def __setattr__(self, name, value): if name.startwith(&quot;_&quot;): # 约定只代理不以`_`开头的属性 # 代理类只暴露被代理类的公共属性 super().__setattr__(name, value) else: print(&quot;setattr:&quot;, name, value) setattr(self._obj, name, value) def __delattr__(self, name): if name.startwith(&quot;_&quot;): super().__delattr__(&quot;name&quot;) else: print(&quot;delattr:&quot;, name) delattr(self._obj, name)class Spam: def __init__(self, x): self.x = x def bar(self, x): print(&quot;Spam.bar&quot;, self.x, y)def test(): s = Spam(2) p = Proxy(s) p.bar(3) p.x = 37 # 通过`p`代理`s` p = Porxy([1, 3, 5]) # len(p) # `len`函数直接使用会报错 p.__len__() # `p.__len__`可以正常代理，返回代理的列表长度 # 这说明python中的钩子函数有特殊的结构？ 状态机（状态模式）为不同的状态定义对象，而不是使用过多的条件判断 提高执行效率 提高代码可维护性、可读性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Connection: def __init__(self): self.new_state(ClosedConnectionState) def new_state(self, newstate): self._state = newstate def read(self): return self._state.read(self) def write(self, data): return self._state.write(self, data) def open(self): return self._state.close(self)class ConnectionState: @staticmethod def read(conn): raise NotImplementedError() @staticmethod def write(conn, data): raise NotImplementedError() @staticmethod def open(conn): raise NotImplementedError() @staticmethod def close(conn): raise NotImplementedError()class ClosedConnectionState(ConnectionState): @staticmethod def read(conn): raise RuntimeError(&quot;not open&quot;) @staticmethod def write(conn): raise RuntimeError(&quot;not open&quot;) @staticmethod def open(conn): conn.new_state(OpenConnectionState) @staticmethod def close(conn): raise RuntimeError(&quot;already closed&quot;)calss OpenConnectionState(ConnectionState): @staicmethod def read(conn): print(&quot;reading&quot;) @staticmethod def write(conn, data): print(&quot;writing&quot;, data) @staticmethod def open(conn): raise RuntimeError(&quot;already open&quot;) @staticmethod def close(conn): conn.new_state(ClosedConnectionState)def test(): c = Connection() c.open() c.read() c.write(&quot;hello&quot;) c.close() 访问者模式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Node: passclass UnaryOperator(Node): def __init__(self, operand): self.operand =operandclass BinaryOperator(Node): def __init__(self, left, right): self.left = left self.right = rightclass Add(BinaryOperator): passclass Sub(BinaryOperator): passclass Mul(BinaryOperator): passclass Div(BinaryOperator): passclass Nagate(UnaryOperator): passclass Number(Node): def __init__(self, value): self.value = valueclass NodeVsistor: def visit(self, node): methname = &quot;visit_&quot; + type(node).__name__ meth = getattr(self, methname, None) # 使用`getattr`获取相应方法，避免大量`switch` # 子类需要实现`visit_Node`一系列方法 if meth is None: meth = self.generic_visit return meth(node) def generic_visit(self, node): raise RuntimeError(&quot;No {} method&quot;.format(&quot;visit_&quot; + type(node).__name_))class Evaluator(NodeVisitor): def visit_Number(self, node): return node.value def visit_Add(self, node): return self.visit(node.left) + self.visit(node.right) # 递归调用`visit`计算结果 # 因此可能超过python递归嵌套层级限制而失败 def visit_Sub(self, node): return self.visit(node.left) - self.visit(node.right) def visit_Mul(self, node): return self.visit(node.left) * self.visit(node.right) def visit_Div(self, node): return self.visit(node.left) / self.visit(node.right) def visit_Negate(self, node): return -node.operanddef test(): t1 = Sub(Number(3), Number(4)) t2 = Mul(Number(2), t1) t3 = Div(t2, Number(5)) t4 = Add(Number(1), t3) e = Evaluator() e.visit(t4) yield消除递归消除递归一般是使用栈、队列，在python还可以使用yield得到 更加简洁的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import typesclass NodeVisitor: def visit(self, node): stack = [node] last_result = None while stack: try: last = stack[-1] if isinstance(last, types.GeneratorType): # 对`yield`实现 stack.append(last.send(last_result)) last_result = None elif isinstance(last, Node): # 对递归实现 stack.append(self._visit(stack.pop())) else: last_result = stack.pop() except StopIteration: stack.pop() return last_result def _visit(self, node): methname = &quot;visit&quot; + type(node).__name__ meth = getattr(self, methname, None) if meth is None: meth = self.generic_visit return meth(node) def generic_visit(self, node): raise RuntimeError(&quot;No {} method&quot;.format(&quot;visit_&quot;, type(node).__name__))class Evaluator(NodeVisitor): # `yield`版本不会多次递归，可以接受更多层级 def visit_Number(self, node): return node.value def visit_Add(self, node): yield (yield node.left) + (yield node.right) # 遇到`yield`，生成器返回一个数据并暂时挂起 def visit_Sub(self, node): yield (yield node.left) + (yield node.right) def visit_Mul(self, node): yield (yield node.left) * (yield node.right) def visit_Div(self, node): yield (yield node.left) * (yield node.right) def visit_Nagate(self, node): yield - (yield node.operand) 字符串调用方法 可以使用getattr(instance, name)通过字符串调用方法 也可以用operator.methodcaller operator.methodcaller创建可调用对象，同时提供所有 必要参数 调用时只需要将实例对象传递给其即可 123456789101112131415161718192021222324import mathfrom operator import methodcallerclass Point: def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return &quot;Point({!r}, {!r})&quot;.format(self.x, self.y) def distance(self, x, y): return math.hypot(self.x -x, self.y - y)def test(): points = [ Point(1, 2), Point(3, 0), Point(10, -3), Point(-5, -7) ] points.sort(key=methodcaller(&quot;distance', 0, 0)) # `methodcaller`创建可调用对象，并提供所有必要参数 缓存实例工厂函数12345678910111213141516171819202122class Spam: def __init__(self, name): self.name = nameimport weakref_spam_cache = weakref.WeakValueDictionary() # `WeakValueDictionary`实例只保存在其他地方还被使用的 # 实例，否则从字典移除def get_spam(name): # 使用工厂函数修改实例创建行为 if name not in _spam_cache: s = Spam(name) _spam_cache[name] = s else: s = _spam_cache[name] return sdef test(): a = get_spam(&quot;foo&quot;) b = get_spam(&quot;foo&quot;) print(a is b) 缓存管理器将缓存代码放到单独的缓存管理器中， 代码更清晰、灵活，可以增加更多的缓存管理机制 1234567891011121314151617181920212223242526272829import weakrefclass CachedSpamManager: def __init__(self): self._cache = weakref.WeakValueDictionary() def get_spam(self, name): if name not in self._cache: s = Spam(name) self._cache[name] = s else: s = self._cache[name] return s def clear(self): self._cache.clear()class Spam: manager = CacheSpamManager() def __init__(self, *args, **kwargs): # `__init__`方法抛出异常，防止用户直接初始化 # 也可以将类名加上`_`，提醒用户不要实例化 raise RuntimeError(&quot;can't instantiate directly&quot;) @classmethod def _new(cls, name): self = cls.__new__(cls) self.name = name return self __new__123456789101112131415161718import weakrefclas Spam: _spam_cache = weakref.WeakValueDictionary() def __new__(cls, name): if name in cls._spam_cache: return cls._spam_cache[name] else: self = super().__new__(cls) cls._spam_cache[name] = self return self def __init__(self, name): print(&quot;initializing Spam&quot;) self.name = name # 这种方式实际会多次调用`__init__`方法，即使已经结果已经 # 缓存，不是个好方法","link":"/Python/Py3Ref/cls_templates.html"},{"title":"数据模型--函数决定对象","text":"函数用户定义函数用户定义函数：通过函数定义创建，调用时附带参数列表 函数对象支持获取、设置任意属性 用于给函数附加元数据 使用属性点号.获取、设置此类属性 特殊属性 __defaults__：有默认值参数的默认值组成元组 没有具有默认值参数则为None __code__：编译后函数体代码对象 __globals__：存放函数中全局变量的字典的引用 即引用函数所属模块的全局命名空间 只读 __closure__：包含函数自由变量绑定单元的元组 没有则为None 只读 __annotations__：包含参数注释的字典 字典键为参数名、return（若包含返回值） 将变量名称（非私有）映射到标注值的特殊字典 若该属性可写、在类或模块体开始执行时，若静态地发现 标注则被自动创建 __kwdefaults__：keyword-only参数的默认值字典 大部分可写属性会检查赋值类型 自由变量：上层命名空间中变量，不包括顶级命名空间，即 全局变量不是自由变量 实例/绑定方法实例/绑定方法：使用属性表示法调用、定义在类命名空间 中的函数 实例方法用于将类、类实例同可调用对象结合起来 可调用对象：须为类属性，即定义在类命名空间中， 通常为用户定义函数、类方法对象 通过实例访问类命名空间定义函数时创建实例/绑定方法 通过示例、类访问的命名空间定义函数类型不同 wrapper_descriptor转换为method-wrapper function转换为method 通过类访问方法，得到是普通函数 绑定：此时会将self作为首个参数添加到参数列表 调用实例方法时，调用相应下层函数 函数对象到实例方法对象的转换每次获取实例该属性时都会发生 有时可将属性赋值给本地变量、调用实现性能优化 非用户定义函数、不可调用对象在被获取时不会发生转换 实例属性的用户定义函数不会被转换为绑定方法，仅在函数 是类的属性时才会发生 Py3中以上特性依赖于___getattribute__实现 属性 绑定方法对象支持只读获取底层函数对象任意属性 但方法属性实际保存在下层函数对象中 所以不能直接设置绑定方法的方法属性，必须在下层函数 对象中显式设置，否则raise AttributeError 绑定方法有两个特殊只读属性 m.__self__：操作该方法的类实例 m.__func__：底层实现该方法的函数 m(args,...)完全等价于m.__func__(m.__self__,args,...) 特殊元属性 __self__：类对象实例 __func__：函数对象实例 __doc__：方法文档，等同于__func__.__doc__ __name__：方法名，等同于__func__.__name__ __module__：定义方法所在模块名 Class Method Objects类方法：提供了始终将类绑定为函数对象首个参数的方式 对其他对象的封装，通常用于封装用户定义方法对象 会改变从类、类实例获取该对象的方式 用途 实现自定义、多个构造器，如 只调用__new__()、绕过__init__，创建未初始化 的实例 反序列化对象：从字节串反序列构造符合要求的对象 通过classmethod()构造器创建 Py3中以上特性依赖于___getattribute__实现 Static Method Objects静态方法：提供了避免将函数对象转换为方法对象的方式 对任意其他对象的封装，通常用于封装用户定义方法对象 从类、类实例获取静态方法对象时，实际返回的是封装的对象， 不会被进一步转换 静态方法对象自身不是可调用的，但其封装的对象通常可调用 通过内置staticmethod()构造器创建 Py3中以上特性依赖于___getattribute__实现 内置函数、方法 内置函数：对C函数的外部封装 内置方法：内置函数另一种形式，（类似实例方法）隐式传入 当前实例作为C函数额外参数 包括以下两种类型 builtin_function_or_method wrapper_descriptor 参数数量、类型由C函数决定 内置方法由支持其的类型描述 特殊元属性 __self__：&lt;module 'builtins' (built-in)&gt; __doc__：函数/方法文档 __name__：函数/方法名 __module__：所在模块名 说明 函数是描述器，函数类function实现有__get__方法 function.__get__即将函数首个参数进行绑定，返回绑定方法 参见cs_python/py3ref/cls_special_methods Generator Functions生成器函数：使用yield语句的函数、方法称为生成器函数 生成器函数调用时返回生成器迭代器对象，控制执行函数体 yield表达式参见cs_python/py3ref/expressions Generator-Iterator生成器迭代器：生成器函数执行得到的迭代器 实现有迭代器协议__next__的迭代器类实例不同于 生成器迭代器，其仅实现迭代 迭代执行过程即__next__函数调用，重入（状态维护） 由类负责 无不同迭代状态区别 不会自动获得.send、.throw、.close等方法 或者说生成器迭代器是：利用yield表达式对迭代器的的简化 实现，并预定义.send、.throw、.close方法 迭代器协议参见cs_python/py3ref/cls_special_methods 执行过程 其某方法被调用时，生成器函数开始执行 执行到第一个yield表达式被挂起，保留所有局部状态 局部变量当前绑定 指令指针 内部求值栈 任何异常处理状态 返回expression_list 调用生成器某方法，生成函数继续执行 执行return、函数体执行完毕将raise StopIteration 生成器表达式、yield表达式参见 cs_python/py3ref/expressions 生成器迭代器状态生成器在声明周期中有如下4中状态 &quot;GEN_CREATED&quot;：等待执行 &quot;GEN_RUNNING&quot;：正在执行，只有多线程中才能看到 &quot;GEN_SUSPENDED&quot;：在yield表达式处挂起状态 &quot;GEN_CLOSED&quot;：关闭状态 可通过inspect.getgeneratorstate()方法查看 __next__12def(pre) generator.__next__(): pass 用途：开始生成器函数执行、或从上次执行yield表达式处恢复 执行 生成器函数通过__next__方法恢复执行时，yield表达式 始终取值为None 执行至下个yield表达式 返回值：生成器迭代器产生的下个值 yield表达式中expression_list值 若生成器没有产生下个值就退出，raise StopIteration 此方法通常隐式通过for循环、next()函数调用 send12def(pre) generator.send(value): pass 用途：恢复生成器函数执行并向其“发送”值value value参数作为yield表达式的结果 执行至下个yield表达式 返回值：生成器迭代器产生的下个值 yield表达式中expression_list值 若生成器没有产生下个值就退出，raise StopIteration 说明 若生成器中包含子迭代器，send传参数值将被传递给 下层迭代器，若子迭代器没有合适接收方法、处理，将 raise AttributeError、raise TypeError .send方法参数为None时实际不会有传递参数行为 调用.send()启动生成器时，必须以None作为调用 参数，因为此时没有可以接收值的yield表达式 子迭代器中没有处理参数时，.send(None)也能正常 工作 throw12def(pre) generator.throw(type[, value[, traceback]]): pass 用途：在生成器暂停位置处引发type类型异常 若异常被处理：则执行直至下个yield表达式 若生成器函数没有捕获传入异常、或引发另一个异常：异常 会被传播给调用者 返回值：返回生成器产生的下个值（若异常被处理） 若生成器没有产生下个值就退出，raise StopIteration 说明 若生成器中包含子迭代器，throw传入异常将被传递给 子迭代器 调用throw启动生成器，会在生成器函数开头引发错误 close12def(pre) generator.close(): pass 用途：在生成器函数暂停处raise GeneratorExit 若之后生成器函数正常退出、关闭、引发GeneratorExit （生成器中未捕获该异常）：则关闭生成器并返回调用者 若生成器继续产生值：则raise RuntimeError 若生成器引发其他异常：则传播给调用者 若生成器由于异常、或正常而退出：则无操作 Yield表达式—调用外部函数 生成器函数执行yield表达式类似调用外部函数 当前函数栈保留当前状态、挂起 执行yield表达式“完毕”后，“返回”到调用处 yield表达式“返回值”取决于生成器恢复执行所调用方法 .__next__：for、next()调用，返回None .send()：返回.send()参数 此时整体类似于 主调函数调用生成器函数 生成器函数调用yield表达式 生成器函数—协程 生成器函数类似协程，也被称为semi-coroutine，是协程子集 相似点 可yield多次，有多个入口点 执行可以被挂起 可在恢复执行时传递参数控制执行 不同点 yield后控制权总是转移给生成器迭代器调用者，生成器 函数不能控制yield后继续执行的位置 （yield表达式仅仅传递值给父程序，并不是指定需要 跳转的、平等的协程） 生成器函数—try try结构中任何位置都允许yield表达式 若生成器在销毁之前没有恢复执行（引用计数为0、被垃圾 回收），try结构中的yield表达式挂起可能导致finally 子句执行失败 此时应由运行该异步生成器的事件循环、或任务调度器负责调用 生成器-迭代器close()方法，从而允许任何挂起的finally 子句得以执行 例123456789101112131415161718def echo(value=None): print(&quot;execution start&quot;) try: while True: try: value = (yield value) except Exception as e: value = e finally: print(&quot;clean up when gen.close() is called&quot;)if __name__ == &quot;__main__&quot;: gen = echo(1) print(next(gen)) # 1 print(next(gen)) # None print(gen.send(2)) # 2 print(gen.throw(TypeError, &quot;spam&quot;)) # TypeError('spam',) gen.close() # clean up... Coroutine Function协程函数：使用async def定义的函数、方法 调用时返回一个coroutine对象 可能包含await表达式、async with、async for语句 即协程函数能在执行过程中挂起、恢复 协程参见cs_program/#todo Coroutine Objects协程对象：属于awaitable对象 协程执行：调用__await__，迭代其返回值进行控制 协程结束执行、返回时，迭代器raise StopIteration， 异常的value属性将指向返回值 等待协程超过一次将raise RuntimeError 若协程引发异常，其会被迭代器传播 协程不应该直接引发未处理的StopIteration 可等待对象参见cs_python/py3ref/cls_special_methods send12def(pre) coroutine.send(value): pass 用途：开始、恢复协程执行 value is None：相当于等待__await__()返回迭代器 结果下一项 value is not None：此方法将委托给导致协程挂起的 迭代器的send()方法 返回值：返回值、异常等同对__await__()返回值迭代结果 throw12def(pre) coroutine.throw(type[, value[, traceback]]): pass 用途：在协程内引发指定异常 此方法将委托给导致协程内挂起的迭代器的throw()方法 ，若其存在 否则异常在挂起点被引发 返回值：返回值、异常等同对__await__()返回值迭代结果 若异常未在协程内被捕获，则传回给主调者 close12def(pre) coroutine.close(): pass 用途：清理自身并退出 若协程被挂起，此方法先被委托给导致该协程挂起的迭代器 的.close()方法，若其存在 然后在挂起点raise GeneratorExit，使得协程立即清理 自身 最后协程被标记为已结束执行，即使未被启动 协程对象将被销毁时，会被自动调用 Asynchronous Generator Functions异步生成器函数：包含yield语句、使用async def定义函数、 方法（即在协程中） 返回异步生成器迭代器对象，控制执行函数体 yield from表达式在异步生成器函数中使用将引发语法错误 Asynchronous Generator-Iterator异步生成器迭代器 异步体现：async def定义协程函数中可以使用异步代码 异步生成器迭代器方法返回的可等待对象们执行同一函数栈 可等待对象被await运行时才会执行异步函数体 类似普通生成器迭代器，执行到yield表达式挂起 则连续返回多个可等待对象可以乱序await 可以视为返回待执行函数体 异步生成器迭代器执行过程、yield表达式、try结构、同异步 迭代器协议关联， 均参见普通生成器迭代器 异步迭代器协议参见cs_python/py3ref/cls_special_methods 异步生成器函数使用yield from语句将引发语法错误 最终化处理#todo处理最终化：事件循环应该定义终结器函数 其接收异步生成器迭代器、且可能调用aclose()方法并执行 协程 终结器可以通过调用sys.set_asyncgen_hooks()注册 首次迭代时，异步生成器迭代器将保存已注册终结器以便最终化 时调用 __anext__12async def(pre) coroutine agen.__anext__(): pass 用途：返回可等待对象，可等待对象运行时开始、恢复异步 生成器函数执行 异步生成器函数通过__anext__方法恢复执行时，返回的 可等待对象中yield表达式始终取值为None 可等待对象返回值：返回异步生成器的下个值 执行至下个yield表达式，返回expression_list值 若异步生成器没有产生下个值就退出，则 raise StopAsyncIteration， 此方法通常由async for异步循环隐式调用 asend12async def(pre) coroutine agen.asend(value): pass 用途：返回可等待对象，可等待对象运行时开始、恢复异步 生成器函数执行，并向其“发送”值value value参数作为yield表达式的结果 执行至下个yield表达式 返回值：异步生成器产生的下个值 yield表达式中expression_list值 若生成器没有产生下个值就退出，则 raise StopAsyncIteration 说明 调用.asend()启动生成器时，必须以None作为调用参数 athrow12async def(pre) coroutine agen.athrow(type[, value[, traceback]]): pass 用途：返回可等待对象，可等待对象运行时将在异步生成器函数 暂停位置处引发type类型异常 若异常被处理：则执行直至下个yield表达式 若异步生成器函数没有捕获传入异常、或引发另一个异常： 可等待对象运行时异常会被传播给调用者 返回值：返回生成器产生的下个值（若异常被处理） 若生成器没有产生下个值就退出，则 raise StopAsyncIteration 说明 调用athrow启动异步生成器，会在函数开头引发错误 aclose12async def(pre) coroutine agen.aclose(): pass 用途：返回可等待对象，可等待对象运行时在异步生成器函数 暂停处raise GeneratorExit 若异步生成器函数正常退出、关闭、引发GeneratorExit （生成器中未捕获该异常）：则运行可等待对象将 raise StopIteration？？？ 后续调用异步生成器迭代器方法返回其他可等待对象：则 运行可等待对象将raise StopAsyncIteration 若异步生成器函数产生值：则运行可等待对象将 raise RuntimeError 若异步生成器迭代器已经异常、正常退出，则后续调用 aclose方法将返回无行为可等待对象","link":"/Python/Py3Ref/dm_gfuncs.html"},{"title":"数据模型--基本数据类型","text":"对象、值、类型对象：python中对数据的抽象 python中所有数据都是由对象、对象间关系表示 按冯诺依曼“存储程序计算机”，代码本身也是由对象表示 编号、类型、值每个对象都有各自编号、类型、值 编号：可以视为对象在内存中地址，对象创建后不变 id()函数：获取代表对象编号的整形 is算符：比较对象编号判断是否为同一对象 类型：决定对象支持的操作、可能取值 类型会影响对象行为几乎所有方面，甚至对象编号重要性 也受到影响，如：对于会得到新值的运算 不可变类型：可能返回同类型、同取值现有对象引用 a = b = 1：a、b可能指向相同对象1 （取决于具体实现） 可变类型：不允许返回已存在对象 c=[];d=[]：会保证c、d指向不同、单独 空列表（c=d=[]将同一对象赋给c、d） 对象创建后保持不变 type：返回对象类型 CPython：相同整形值都引用同一个对象 值：通过一些特征行为表征的抽象概念 对象值在python中是抽象概念 对象值没有规范的访问方法 不要求具有特定的构建方式，如：值由其全部数据 属性组成 对象值可变性由其类型决定 可变的：值可以改变的对象 不可变的：值（直接包含对象编号）不可改变的对象 比较运算符实现了特定对象值概念，可以认为是 通过实现对象比较间接定义对象值 CPython：id(x)返回存放x的地址 对象销毁对象不会被显式销毁（del仅是移除名称绑定） 无法访问时可能被作为垃圾回收 允许具体实现推迟垃圾回收或完全省略此机制 实现垃圾回收是质量问题，只要可访问对象不会被回收 即可 不要依赖不可访问对象的立即终结机制，应当总是显式 关闭外部资源引用 以下情况下，正常应该被回收的对象可能继续存活 使用实现的跟踪、调试功能 通过try...except...语句捕捉异常 CPython：使用带有（可选）延迟检测循环链接垃圾的 引用计数方案 对象不可访问时立即回收其中大部分，但不保证 回收包含循环引用的垃圾 标准类型层级结构 以下是python内置类型的列表，扩展模块可以定义更多类型 以下有些类型有特殊属性，这些特殊属性不应用作通常使用， 其定义在未来可能改变 NoneNoneType：只有一种取值，None是具有此值的唯一对象 通过内置名称None访问 多数情况表示空值，如 未显式指明返回值函数返回None 逻辑值：假 NotImplementedNotImplementedType：只有一种取值，NotImplemented是具有 此值的唯一对象 通过内置名称NotImplemented访问 数值、富比较方法在操作数没有该实现操作时应返回此值 返回NotImplemented前，解释器会依据运算符尝试反射 方法、委托回退方法 逻辑值：真 Ellipsisellipsis：只有一种取值，Ellipsis是具有此值的唯一对象 通过字面值...、内置名称Ellipsis访问 逻辑值：真 numbers.Numbernumber.Number：由数字字面值创建，被作为算法运算符、算数 内置函数返回结果 不可变：一旦创建其值不再改变 类似数学中数字，但也受限于计算机对数字的表示方法 numbers.Integralnumbers.Integral：表示数学中整数集合 int：整形，表示任意大小数字，仅受限于可用内存 变换、掩码运算中以二进制表示 负数以2的补码表示（类似符号位向左延伸补满空位） bool：布尔型，表示逻辑值真、假 True、False是唯二两个布尔对象 整形子类型：在各类场合中行为类似整形1、0，仅在 转换为字符串时返回&quot;True&quot;、&quot;False&quot; 方法、函数 int.bit_length()：不包括符号位、开头0位长 int.to_bytes(length, byteorder, *, signed=False) class int.from_bytes(bytes, byteorder, *, signed=False) 详细说明参见https://docs.python.org/zh-cn/3/library/stdtypes.html#additional-methods-on-integer-types numbers.Real(float)float：表示机器级双精度浮点数 接受的取值返回、溢出处理取决于底层结构、python实现 python不支持单精度浮点 没必要因为节省处理器、内存消耗而增加语言复杂度 特殊取值12345infty = float(&quot;inf&quot;)neg_infty = float(&quot;-inf&quot;) # 正/负无穷大nan = float(&quot;nan&quot;) # Not a Number 特殊取值根据定义==、is肯定返回False float.__eq__内部应该有做检查，保证==返回False 每次会创建“新”的nan/infty 连续执行id(float(&quot;nan&quot;))返回值可能相等，这是因为 每次生成的float(&quot;nan&quot;)对象被回收，不影响 np.nan is np.nan返回True，应该是numpy初始化的时候 创建了一个float(&quot;nan&quot;)，每次都是使用同一个nan 相关操作 详细参考https://docs.python.org/zh-cn/3/library/stdtypes.html#additional-methods-on-float 更多数字运算参考math、cmath模块 float.as_integer_ratio() float.is_integer() float.hex() classmethod float.fromhex(s) round(f[,n]) math.trunc(f) math.floor(f) math.ceil(f) numbers.Complex(complex)complex：以一对机器级双精度浮点数表示复数值 实部、虚部：可通过只读属性z.real、z.imag获取 Iterators迭代器类型 迭代器对象需要自身支持以下两个方法，其共同组成迭代器协议 iterator.__iter__() iterator.__next__() 方法详细参考cs_python/py3ref/cls_special_method Generator生成器类型：提供了实现迭代器协议的便捷形式 将容器对象的__iter__()方法实现为生成器，方便实现容器对 迭代器支持 创建、使用参见cs_python/py3ref/dm_gfuncs 序列序列：表示以非负整数作为索引的有限有序集 不可变序列类型：对象一旦创建不能改变 若包含其他可变对象引用，则可变对象“可改变” 但不可变对象所直接引用的对象集是不可变的 包括 str tuple bytes range：非基本序列类型 可变序列：创建后仍可被改变值 list bytesarray 通用序列操作 x in s、x not in s str、bytes、bytearray支持子序列检测 s + t：拼接 拼接不可变总会生成新对象 重复拼接构建序列的运行时开销将基于序列总长度乘方 s * n、n * s：s自身拼接n次 n&lt;0被当作0处理 s中项不会被复制，而是被多次引用 s[i]、s[i:j]、s[i:j:step] i&lt;0索引为负值：索引顺序相对于序列s末尾，等价于 对序列长度取模 序列切片：与序列类型相同的新序列 索引从0开始 左闭右开 某些序列支持a[i:j:step]扩展切片 s.index(x[, i[, j]]) 仅部分序列支持 类似s[i:j].index(x)，但返回值是相对序列开头 s.count(x)：序列中元素x数目 len(s)：返回序列条目数量 min(s)、max(s)：序列最小、最大值 序列比较运算默认实现参见cs_python/py3ref/expressions 以上运算自定义实现参见 cs_python/py3ref/cls_special_methods 不可变序列不可变序列普遍实现而可变序列未实现的操作 hash()内置函数 可变序列 s[i]=x、s[i:j]=t、s[i:j:k]=t：下标、切片被赋值 s[i:j:k]=t中t长度必须和被替换切片长度相同 del s[i:j]、del s[i:j:k]：移除元素 作为del语句的目标 等同于s[i:j]=[] s.append()：添加元素 等同于s[len(s):len(s)] = [x] s.clear()：移除所有项 等同于del s[:] s.copy()：浅拷贝 等同于s[:] s.extend(t)：扩展（合并）序列 基本上等于s += t s.insert(i, x)：向序列中插入元素 等同于s[i:i] = [x] s.pop(i=-1)：弹出序列中元素 s.remove(x)：删除序列中首个值为x的项 s.reverse()：反转序列 反转大尺寸序列时，会原地修改序列 为提醒用户此操作通过间接影响进行，不会返回反转后序列 array、collections模块提供额外可变序列类型 可利用collections.abc.MutableSequence抽象类简化自定义 序列操作 tuple元组 元组中条目可以是任意python对象 元组创建 一对圆括号创建空元组 逗号分隔 单项元组：后缀逗号a,、(a,) 多项元组：a,b,c、(a,b,c) 内置构建器：tuple、tuple(iterable) list列表 列表中条目可以是任意python对象 构建方式 方括号括起、项以逗号分隔：[]、[a]、[a,b] 列表推导式：[x for x in iterable] 类型构造器：list(iterable) 相关操作.sort12def list.sort(*, key=None, reverse=False): pass 用途：对列表原地排序 使用&lt;进行各项之间比较 不屏蔽异常：若有比较操作失败，整个排序操作将失败， 此时列表可能处于部分被修改状态 参数 key：带参数函数，遍历处理每个元素提取比较键 None：默认，直接使用列表项排序 说明 .sort保序，有利于多重排序 为提醒用户此方法原地修改序列保证空间经济性，其不返回 排序后序列（可考虑使用sorted显式请求） CPython：列表排序期间尝试改变、检测会造成未定义影响， CPython将列表排序期间显式为空，若列表排序期间被改变将 raise ValueError str12345class str(object=&quot;&quot;) # 返回`object.__str__()`、`object.__repr__()`class str(object=b&quot;&quot;, encoding=&quot;utf-8&quot;, errors=&quot;strict&quot;) # 给出`encoding`、`errors`之一，须为bytes-like对象 # 等价于`bytes.decode(encoding, errors)` 字符串：由Unicode码位值组成不可变序列（应该是UTF16-bl编码） 范围在U+0000~U+10FFFF内所有码位值均可在字符串中使用 不存在单个“字符”类型 字符串中单个字符为长度为1字符串 不存在可变字符串类型 可以用str.join()、io.StringIO高效连接多个字符串 片段 字符串构建 字符串字面值：cs_python/py3ref/lexical_analysis 内置构造器str() 相关操作 参见https://docs.python.org/zh-cn/3/library/stdtypes.html#string-methods ord()：转换单个字符字符串为（整形）码位 chr()：转换（整形）码位为单个字符字符串 判断 str.isalnum() str.isalpha() str.isascii() str.isdecimal() str.isdigit() str.isidentifier() str.islower() str.isnumeric() str.isprintable() str.isspace() str.istitle() str.isupper() 查找 str.rfind(sub[, start[, end]]) str.rindex(sub[, start[, end]]) str.startswith(prefix[, start[, end]]) str.endwith(suffix[, start[, end]]) str.count(sub[, start[, end]])：子串出现次数 str.find(sub[, start[, end]]) 仅检查sub是否为子串，应使用in 找不到子串时返回-1 str.index(sub[, start[, end]]) 类似str.find，但找不到子串时raise ValueError 分隔 str.partition(sep) str.rpartition(sep) str.rsplit(sep=None, maxsplit=-11) str.split(sep=None, maxsplit=-1) str.splitline([keepends]) 拼接 str.join(iterable) str.strip([chars]) str.lstrip([chars]) str.rstrip([chars]) str.rstrip([chars]) 转换 str.lower() str.upper() str.swapcase() str.translate(table) str.replace(old, new[, count]) static str.maketrans(x[, y[, z]]) str.encode(encoding=&quot;utf-8&quot;, errors=&quot;strict&quot;)：使用 指定编码方案编码为bytes str.expandtabs(tabsize=8) str.capitalize()：首字符大写副本 str.casefold()：消除大小写副本 str.center(width[, fillchar])：字符串位于中间的字符串 str.title() 格式化 str.ljust(width[, fillchar]) str.rjust(width[, fillchar]) str.zfill(width) str.format(*args, **kwargs) str.format_map(mapping) 类似str.format(**mapping)，但mapping不会被复制 到dict中1234class Default(dict): def __missing__(self, key): return key&quot;{name} was born in {country}&quot;.format_map(Default(name=&quot;Guido&quot;)) printf风格字符串格式化 format % values中：format中%转换标记符将被转换 为values中条目 效果类似于sprintf values为与format中指定转换符数量等长元组、或映射 对象，除非format要求单个参数 转换标记符按以下顺序构成 %字符：标记转换符起始 映射键：可选，圆括号()括起字符序列 values为映射时，映射键必须 转换旗标：可选，影响某些类型转换效果 #：值转换使用“替代形式” 0：为数字值填充0字符 -：转换值左对齐（覆盖0） ：符号位转换产生整数（空字符串）将留出空格 +：符号字符显示在开头（覆盖 ） 最小字段宽度：可选 *：从values读取下个元素 精度：可选，.之后加精度值 *：从values读取下个元素 长度修饰符：可选 转换类型 d/u/i：十进制整形 o：8进制整形 #替代形式，前端添加0o x/X：小/大写16进制整形 #替代形式，前端添加0x/0X e/E：小/大写浮点指数 #替代形式，总是包含小数点 f/`F：浮点10进制 #替代形式，总是包含小数点 g/G：指数小于-4、不小于精度使用指数格式 #替代形式，总是包含小数点，末尾0不移除 c：单个字符（接收整数、单个字符字符串） r/s/a：字符串（repr/str/ascii转换） 按输出精度截断 %：输出%字符 技巧 快速字符串拼接 构建包含字符串的列表，利用str.join()方法 写入io.StringIO实例，结束时获取值 bytes/bytearray1class bytes([source[, encoding[, errors]]]) 字节串：单个字节构成的不可变序列 字节数组：字节串可变对应版本，其他同不可变bytes 字节串构建 字节串字面值：cs_python/py3ref/lexical_analysis 内置构造器bytes() 指定长度零值填充：bytes(10) 整数组成可迭代对象：bytes(range(20)) 通过缓冲区协议复制现有二进制数据：bytes(obj) 字节数组构建 字节数组没有字面值语法，只能通过构造器构造 可变，构建空字节数组有意义 类似整数构成序列 每个条目都是8位字节 取值范围0~255，但只允许ASCII字符0~127 b[0]产生整数，切片返回bytes对象 可通过list(bytes)将bytes对象转换为整数构成列表 由memeoryview提供支持 相关函数、方法 bytes.decode：解码为相关字符串 classmethod bytes.fromhex(string) bytes.hex() 其他类似字符串，包括printf风格格式化 参见https://docs.python.org/zh-cn/3/library/stdtypes.html#bytes-and-bytearray-operations 技巧 快速字节串拼接 构建包含字节串的列表，利用bytes.join()方法 写入io.BytesIO实例，结束时获取值 使用betaarray对象进行原地拼接 memoryview1class memoryview(obj) 内存视图：允许python代码访问对象内部数据 若对象支持缓冲区协议，则无需拷贝 支持缓冲区协议的内置对象包括bytes、bytesarray 内存视图元素：原始对象obj处理的基本内存单元 对简单bytes、bytesarray对象，一个元素就是一字节 array.array等类型可能有更大元素 内存视图支持索引抽取、切片 若下层对象可选，则支持赋值，但切片赋值不允许改变大小 相关操作 参见https://docs.python.org/zh-cn/3/library/stdtypes.html#memory-views mv.__eq__(exporter) mv.__len__() mv.tobyte() mv.hex() mv.tolist() mv.release() mv.cast(format[, shape])：将内存视图转换新格式形状 可用属性以下属性均只读 mv.obj：内存视图的下层对象 mv.nbytes == product(shape) * itemsize = len(mv.tobytes()) mv.readonly mv.format：内存视图中元素格式 表示为struct模块格式 mv.itemsize mv.ndim mv.shape mv.strides mv.suboffsets mv.c_contiguous mv.f_contiguous mv.contiguous Slices Object切片对象：表示__getitem__()方法得到的切片 可以使用内置的slice()函数创建 a[start: stop]形式的调用被转换为 a[slice(start, stop, None)] 切片对象是内部类型，参见cs_python/py3ref/dm_exec，也 不是序列类型 特殊只读属性 start：下界 stop：上界 step：步长值 属性可以具有任意类型 方法 .indices(self, length)：计算切片对象被应用到length 长度序列时切片相关信息 返回值：(start, stop, step)三元组 索引号缺失、越界按照正规连续切片方式处理 rangerange：不可变数字序列类型（非不是基本序列类型） 12class range(stop)class range(start=0, stop[, step=1]) 参数：必须均为整数（int或实现__index__方法） step &gt; 0：对range对象r[i]=start + step * i，其中 i &gt;= 0, r[i] &lt; stop step &lt; 0：对range对象r[i]=start + step * i，其中 i &gt;= 0, r[i] &gt; stop step = 0：raise ValueError 说明 允许元素绝对值大于sys.maxsize，但是某些特性如： len()可能raise OverflowError range类型根据需要计算单项、切片值 相较于常规list、tuple占用内存较小，且和表示 范围大小无关 只能表示符合严格模式的序列 range类型实现了collections.abc.Sequence抽象类 基本实现序列所有操作：检测、索引查找、切片等 除拼接、重复：拼接、重复通常会违反严格模式 !=、==将range对象视为序列比较，即提供相同值即 认为相等 集合类型 表示不重复、不可变对象组成的无序、有限集合 不能通过下标索引 可以迭代 可以通过内置函数len返回集合中条目数量 常用于 快速成员检测、去除序列中重复项 进行交、并、差、对称差等数学运算 公用操作 参见https://docs.python.org/zh-cn/3/library/stdtypes.html#set-types-set-frozenset len(s) x [not ]in s s.isdisjoint(other) s.issubset(other)/s &lt;= other s &lt; other s.issuperset(other)/s &gt;= other s &gt; other s.union(*others)/s | other |... s.intersection(*others)/s &amp; other &amp;... s.difference(*other)/s - other - other s.symmetric_difference(other)/s ^ other s.copy() 集合比较仅定义偏序，集合列表排序无意义 可变集合独有 s.update(*others)/s |= other |... s.intersection_update(*others)/s &amp;= other &amp;... s.difference_udpate(*others)/s -= other |... s.symmetric_difference_update(other)/set ^= other s.add(elem) s.remove(elem) s.discard(elem) s.pop() s.clear() set/frozenset12class set([iterable])class frozenset([iterable]) 集合：由具有唯一性的hashable对象组成的多项无序集 冻结集合：不可变集合，可哈希，可以用作集合元素、字典键 创建集合 set()内置构造器 花括号包括、逗号分隔元组列表：{a, b} 创建冻结集合 frozenset()内置构造器 python中集合类似dict通过hash实现 集合元素须遵循同字典键的不可变规则 数字：相等的数字1==1.0，同一集合中只能包含一个 操作说明 .remove、.__contains__、discard等可以接收set类型 参数，其将被转换为临时frozenset对象 非运算符版本操作可以接受任意可迭代对象作为参数，运算符 版本只能接受集合类型作为参数 映射映射：表示任何索引集合所索引的对象的集合 通过下标a[k]可在映射a中选择索引为k的条目 可在表达式中使用 可以作为赋值语句、del语句的目标 dbm.ndbm、dbm.gnu、collections模块提供额外映射类型 通用操作 参见https://docs.python.org/zh-cn/3/library/stdtypes.html#mapping-types-dict len(d) d[key] key [not ]in d iter(d) d.keys()：返回字典视图对象 d.values()：返回字典视图对象 d.items()：返回字典视图对象 d.get(key[, default]) d.copy() classmethod fromkey(iterable[, value]) 可变映射独有 d[key]=value del d[key] d.clear() d.setdefault(key[, default]) d.pop() d.popitem() d.copy() d.update() dict123class dict(**kwargs)class dict(mapping, **kwargs)class dict(iterable, **kwargs) 字典：可由几乎任意值作为索引的有限个对象可变集合 字典的高效实现要求使用键hash值以保持一致性 不可作为键的值类型 包含列表、字典的值 其他通过对象编号而不是值比较的可变对象 数字：相等的数字1==1.0索引相同字典条目 创建字典 花括号括起、逗号分隔键值对：{key:value,} 内置字典构造器：dict() 字典视图对象字典视图对象：提供字典条目的动态视图，随字典改变而改变 len(dictview) iter(dictview) x in dictview 参见https://docs.python.org/zh-cn/3/library/stdtypes.html#dictionary-view-objects","link":"/Python/Py3Ref/dm_basics.html"},{"title":"表达式","text":"Atoms原子：表达式最基本元素 最简单原子 标识符 字面值 以圆括号、方括号、花括号包括的形式在语法上也被归为原子 12atom ::= identifier | literal | enclosureenclosure ::= parenth_form | list_display | dict_display | set_display | generator_expression | yield_atom Indentifiers/Names名称：作为原子出现的标识符 名称被绑定到对象时：对原子求值将返回相应对象 名称未绑定时：对原子求值将raise NameError Private Name Mangling 类的私有名称：文本形式出现在类定义中以两个、更多下划线 开头且不以两个、更多下划线结尾的标识符 私有名称转换：在为私有名称生成代码前，其被转换为更长形式 转换方式：在名称前插入类名、下划线 若转换后名称太长（超过255字符），某些实现中可能 发生截断 转换独立于标识符使用的句法 若类名仅由下划线组成，则不会进行转换 Literals字面值： 1literal ::= stringliteral | bytesliteral | integer | floatnumber | imagnumber 对字面值求值将返回改值对应类型的对象 对浮点数、复数，值可能为近似值 所有字面值都对应不可变数据类型 所以对象标识的重要性不如其实际值 多次对具有相同值的字面值求值，可能得到相同对象、或具有 相同值的不同对象 元组是不可变对象，适用字面值规则：两次出现的空元组 产生对象可能相同、也可能不同todo Parenthesized Forms带括号形式：包含在()的可选表达式列表 1parenth_form ::= &quot;(&quot; [starred_expression] &quot;)&quot; 带圆括号表达式列表将返回表达式所产生的任何东西 内容为空的圆括号返回空元组对象 列表包含至少一个逗号，产生元组 否则，产生表达式列表对应的单一表达式 元组不是由圆括号构建，实际是,逗号操作符起作用 空元组是例外，此时圆括号必须，因为表达式中不带圆括号 的“空”会导致歧义 List/Set/Dict/Generator-Tuple display：显式列出容器内容 comprehension：推导式，通过循环、筛选指令计算 1234comprehension ::= expression comp_forcomp_for ::= [&quot;async&quot;] &quot;for&quot; target_list &quot;in&quot; or_test [comp_iter]comp_iter ::= comp_for | comp_ifcomp_if ::= &quot;if&quot; expression_nocond [comp_iter] 推导式结构：单独表达式后加至少一个for子句以及零个、或 多个for或if子句 for、if子句视为代码块，按从左到右顺序嵌套 （类似for循环嵌套） 每次到达最内层代码块时对表达式求值以产生元素 除最左边for子句中可迭代表达式，推导式在另一个隐式嵌套 作用域内执行 确保赋给目标列表的名称不会“泄露”到外层作用域 最左边for子句中可迭代表达式直接在外层作用域中被 求值，然后作为参数传递给隐式嵌套作用域 后续for子句、最左侧for子句中任何筛选条件不能在 外层作用域中被求值，因为其可能依赖于从最左侧可迭代 对象中获得的值 为确保推导式总能得到类型正确的容器，隐式嵌套作用域内禁止 使用yield、yield from表达式，因为其会对外层作用域 造成附加影响 若推导式包含async for子句、await表达式，则为异步 推导式 List Displays列表显式：用[]方括号括起的、可能为空的表达式系列 1list_display ::= &quot;[&quot; [starred_list | comprehesion] &quot;]&quot; 列表显式会产生新的列表对象，内容通过表达式、推导式指定 提供逗号分隔的表达式时：元素从左至右求值，按此顺序放入 列表对象 提供推导式时：根据推导式产生结果元素进行构建 Set Displays集合显式：用{}花括号标明，与字典区别在于没有冒号分隔键值 1set_display ::= &quot;{&quot; (starred_list | comprehension) &quot;}&quot; 集合显式产生可变集合对象，内容通过表达式、推导式指定 提供逗号分隔的表达式时：元素从左至右求值，按此顺序放入 列表对象 提供推导式时：根据推导式产生结果元素进行构建 空集合不能使用{}构建，此构建的是空字典 Dict Displays字典显式：用{}花括号括起来的、可能为空的键值对 1234dict_display ::= &quot;{&quot; [key_datum_list | dict_comprehension] &quot;}&quot;key_datum_list ::= key_datum (&quot;,&quot; key_datum)* [&quot;,&quot;]key_datum ::= expression &quot;:&quot; expression | &quot;**&quot; or_exprdict_comprehension ::= expression &quot;:&quot; expression comp_for **：映射拆包，操作数必须是映射 字典显式产生新的字典对象 提供,分隔键值对序列 从左至右被求值以定义字典条目 可多次指定相同键，最终值由最后给出键值对决定 提供字典推导式 以冒号分隔的两个表达式，后者带上标准for、if子句 作为结果键值对按产生顺序被加入新字典 键类型需要为hashable Generator Expression生成器表达式：用圆括号括起来的紧凑形式生成器（迭代器）标注 1generator_expression ::= &quot;(&quot; expression comp_for &quot;)&quot; 生成器表达式会产生新的生成器（迭代器）对象 句法同推导式，但使用圆括号括起 圆括号在只附带一个参数（省略expression）的调用中 可以被省略 生成器表达式中使用的变量在生成器对象调用__next__方法 时以惰性方式被求值，同普通生成器 最左侧for子句内可迭代对象会被立即求值，则其造成的 错误会在生成器表达式被定义时被检测到 Yield Expressionyield表达式：将控制权交还给调度程序 12yield_atom ::= &quot;(&quot; yield_expression &quot;)&quot;yield_expression ::= &quot;yield&quot; [expression_list | &quot;from&quot; expression] yield：返回其后表达式求值 yield表达式是赋值语句右侧唯一表达式时，括号可以省略 在定义生成器函数、异步生成器函数时才会用到，也只能在函数 定义内部使用yield表达式，将函数变为（异步）生成器函数 yield表达式会对外层作用域造成附带影响，不允许作为实现 推导式、生成器表达式隐式作用域的一部分 生成器、异步生成器参见cs_python/py3ref/dm_gfuncs yield fromyield from：其后表达式视为子迭代器，将控制流委托给其 类似管道，迭代器参数、异常都被传递给子迭代器 子迭代器依次迭代结果被传递给生成器方法调用者 .send传递值、.throw生成异常被传递给子迭代器 .send传入值、.throw传入异常如果有适当方法将被传递给 下层迭代器，否则 send将raise AttributeError、raise TypeError throw将立即引发传入异常 子迭代器完成后引发的StopIteration实例的value属性将 作为yield表达式值 可以在引发StopIteration时被显式设置#todo 在子迭代器是生成器时通过从子生成器返回值自动设置 用途 展开嵌套序列 Primaries原型：代表编程语言中最紧密绑定的操作（优先级最高） 1primary ::= atom | attributeref | subscription | slicing | call Attributeref属性引用：后面带有句点加名称的原型 1attributeref ::= primary &quot;.&quot; identifier 要求值为支持属性引用类型的对象（多数对象支持） 对象会被要求产生以指定标识符为名称的属性 产生过程可以通过重载__getattr__()方法自定义 Subscriptions抽取：在序列（字符串、元组、列表）、映射（字典）对象中选择 一项 1subscription ::= primary &quot;[&quot; expression_list &quot;]&quot; 要求值必须为支持抽取操作的对象 可以定义__getitem__()方法支持抽取操作 映射：表达式列表求值须为键值 抽取操作选择映射中键对应值 表达式列表为元组，除非其中只有一项 序列：表达式列表求值须为整数、或切片 正式句法规则没有要求实现对负标号值处理，但内置序列 __getitem__()方法结合序列长度解析负标号 重载__getitem__的子类需要显式添加对负标号、切片 支持 Slicings切片：在序列对象（字符串、元组、列表）中选择某个范围内的项 1234567slicing ::= primary &quot;[&quot; slice_list &quot;]&quot;slice_list ::= slice_item (&quot;,&quot; slice_item)* [&quot;,&quot;]slice_item ::= expression | proper_sliceproper_slice ::= [lower_bound] &quot;:&quot; [upper_bound] [ &quot;:&quot; [stride] ]lower_bound ::= expressionupper_bound ::= expressionstride ::= expression 可以用作表达式赋值、del语句的目标 形似表达式列表的东西同样形似切片列表，所以任何抽取操作 都可以被解析为切片 通过定义将此情况解析为抽取优先于切片以消除歧义 原型使用__getitem__、根据切片列表构造的键进行索引 切片列表包含逗号：键将为包含切片项转换的元组 否则：键为单个切片项的转换 切片项若为表达式：切片的转换即为切片对象 Calling调用：附带可能为空的一系列参数来执行可调用对象 1234567891011call ::= primary &quot;(&quot; [argument_list [&quot;,&quot;] | comprehension] &quot;)&quot;argument_list ::= positional_arguments [&quot;,&quot; starred_and_keywords] [&quot;,&quot; keywords_arguments] | starred_and_keywords [&quot;,&quot; keywords_arguments] | keywords_argumentspositional_arguments ::= [&quot;*&quot;] expression (&quot;,&quot; [&quot;*&quot;] expression)*starred_and_keywords ::= (&quot;*&quot; expression | keyword_item) (&quot;,&quot; &quot;*&quot; expression | &quot;,&quot; keyword_item)*keywords_arguments ::= (keyword_item | &quot;**&quot; expression) (&quot;,&quot; keyword_item | &quot;,&quot; &quot;**&quot; expression)*keyword_item ::= identifier &quot;=&quot; expression 要求值为可调用对象 用户定义函数 内置函数 内置对象方法 类对象 类实例方法 任何具有__call__()方法的对象 调用流程 参数表达式在尝试调用前被求值 所有参数表达式被转换为参数列表 代码块将形参绑定到对应参数表达式值 除非引发异常，调用总有返回值 返回值可能为None 返回值计算方式取决于可调用类型 用户定义函数、实例方法、类实例：函数返回值 内置函数：依赖于编译器 内置对象方法：类新实例 在位置参数、关键字参数后加上括号不影响语义 关键字实参转位置实参若存在关键字实参，会通过以下操作被转换为位置参数 为正式参数创建未填充空位的列表 若有N个位置参数：将其放入前N个空位 对每个关键字参数 使用标识符确定对应的空位：若标识符与第k个正式 参数名相同，使用第k个空位 若空位已被填充：则raise TypeError 否则将参数值放入空位进行填充 所有参数处理完毕后，未填充空位使用默认值填充 若仍有未填充空位，则raise TypeError；否则填充完毕 列表被作为调用的参数列表 多余实参 若有关键字参数没有与之对应的正式参数名称，将 raise TypeError，除非有形参使用**indentifier句法 identifier将被初始化新的有序映射接收任何额外关键字 参数 若没有多余关键字实参，则为相同类型空映射 若位置实参数目多余位置形参数目，将raise TypeError， 除非有形参使用*identifier句法 identifier将初始化为元组接受任何额外位置参数 没有多余位置实参，则为空元组 实参解包 若实参中出现*expression句法 expression求值须为iterable 来自该可迭代对象的元素被当作额外位置实参 *expression可以放在关键字实参后而没有语法错误 expression会优先被迭代，元素用于填充参数列表 可能和关键字参数冲突，导致关键字参数对应空位被 填充 一般位置实参必须位于关键字实参前，否则有语法错误 若实参中出现**expresion句法 expression求值须为mapping 其内容被当作额外关键字参数 若关键字已存在，将raise TypeError 运算符 运算符优先级：从低到高 |运算符|描述| |——-|——-| |lambda|lambda表达式| |if--else|条件表达式| |or|布尔逻辑或| |and|布尔逻辑与| |not|布尔逻辑非| |in、not in、is、is not、&lt;、&lt;=、&gt;、=&gt;、!=、==|比较运算，包括成员检测、标识号检测| |||按位或| |^|按位异或| |&amp;|按位与| |&lt;&lt;、&gt;&gt;|移位| |+、-|加、减| |*、@、/、//、%|乘、矩阵乘、除、整除、取余（字符串格式化）| |+x、-x、~x|正、负、按位取反| |**|幂次| |await|await表达式| |x[index]、x[start:end]、x(arguments...)|抽取、切片、调用、属性调用| |(expression...)、[expressions...]、{key:value}、{expressions...}|绑定或元组、列表、字典、集合显示| 求值顺序：从左至右对表达式求值 但赋值操作时，右侧先于左侧求值 算术类型转换 若任意参数为复数，另一参数转换为复数 否则，若任意参数为浮点数，另一参数为浮点数 否则，二者均为整数，不需要转换 awaitawait：挂起coroutine执行以等待awaitable对象 1await_expr ::= &quot;await&quot; primary 只能在协程函数中使用 幂运算符幂运算符 1power ::= (await_expr | primary) [&quot;**&quot; u_expr] 优先级高于左侧一元运算符、低于右侧一元运算符 123-1 ** 2 == -10 ** 0 == 1 # 编程语言得普遍做法 语义同两个参数调用内置power函数 左参数进行右参数所指定的幂次乘方运算 数值参数会转换为相同类型，返回转换后类型 int类型做负数幂次：参数转换为float 0进行负数幂次：raise ZeroDivisionError 负数进行分数次幂次：返回complex类型 一元算术、位运算一元算术、位运算 1u_expr ::= power | &quot;-&quot; u_expr | &quot;+&quot; u_expr | &quot;~&quot; u_expr 一元算数、位运算具有相同优先级 若参数类型不正确将raise TypeError +：产生数值参数相同的值 -：产生数值参数的负值 ~：只作用于整数，对整数参数按位取反，返回-(x+1) （即负值使用补码存储） 二元算术运算符二元算术运算符 1234m_expr ::= u_expr | m_expr &quot;*&quot; u_expr | m_expr &quot;@&quot; m_expr | m_expr &quot;//&quot; u_expr | m_expr &quot;/&quot; u_expr | m_expr &quot;%&quot; u_expra_expr ::= m_expr | a_expr &quot;+&quot; m_expr | a_expr &quot;-&quot; m_expr 二元算术运算符遵循传统优先级，除幂运算符外只有两个优先 级别 乘法型 加法型 python支持混合算术，二元运算符可以用于不同类型操作数 精度较低者会被扩展为另一个操作数类型 算符说明 @：目标是用于矩阵乘法，没有内置类型实现此运算符 %：模，输出第1个参数除以第2个参数的余数 参数可以是浮点数 结果正负总是与第2个操作数一致、或为0 结果绝对值一定小于第2个操作数绝对值（数学上必然真， 但对浮点数而言由于舍入误差存在，数值上未必真） //：整除，结果就是floor函数处理算术除法/的结果 整除、模语义同内置函数divmod(x,y) == (x//y, x%y) 若x接近y的整数倍，由于舍入误差的存在，x//y可能 大于(x-x%y)//y，此时python返回后一个结果，保证 divmod(x,y)[0]*y + x % y尽量接近x 某些运算符也作用于特定非数字类型 *：两个参数分别为整数、序列，执行序列重复 %：被字符串对象重载，用于执行旧式字符串格式化/插值 +：两个参数为相同类型序列，执行序列拼接操作 移位运算移位运算 1shift_expr ::= a_expr | shift_expr (&quot;&lt;&lt;&quot; | &quot;&gt;&gt;&quot;) a_expr 优先级低于算术运算 运算符接受整数参数 将第一个参数左移、右移第二个参数指定的bit数 右移：x &gt;&gt; n == x // power(2, n) 左移：x &lt;&lt; n == x * power(2, n) 二元位运算二元位运算 123and_expr ::= shift_expr | and_expr &quot;&amp;&quot; shift_exprxor_expr ::= and_expr | xor_expr &quot;^&quot; and_expror_expr ::= xor_expr | or_expr &quot;|&quot; xor_expr 三种位运算符具有不同的优先级 两个参数须为整数 &amp;：对两个参数进行按位AND运算 ^：对两个参数进行按位XOR运算 |：对两个参数进行按位OR运算 比较运算比较运算 123comparison ::= or_expr (comp_operator or_expr)*comp_operator ::= &quot;&lt;&quot; | &quot;&gt;&quot; | &quot;==&quot; | &quot;&gt;=&quot; | &quot;&lt;=&quot; | &quot;!=&quot; | &quot;is&quot; [&quot;not&quot;] | [&quot;not&quot;] &quot;in&quot; 所有比较运算优先级相同（与C不同） 低于任何算术、移位、位运算 比较运算可以任意串联a op1 b op2 c ... y opN z等价于 a op1 b and b op2 c and ... and y opN z 只是后者中每个表达式最多只被求值一次 例：a &lt; b &gt;= c类似表达式会被按照传统比较法则解读 等价a &lt; b and b &gt;= c 仍具有短路求值特性，a &lt; b == false时，c不会 被求值 值比较 &gt;、&lt;、==、!=、&lt;=、&gt;=比较两个对象值 不要求两个对象为相同类型 比较运算符实现了特定对象值概念，可以认为是通过 实现对象比较间接定义对象值 所有类型继承于object，从其继承了默认比较行为 =、!=：一致性比较，基于对象标识id 具有相同标识的实例一致性比较结果相等 此默认行为动机：希望对象都应该是自反射，即 x is y就意味着x == y &lt;、&gt;、&lt;=、&gt;=：没有默认值提供 尝试比较raise TypeError 此默认行为动机：缺少一致性比较类似固定值 数字类型数字类型：int、float、complex以及标准库类型 fractions.Fraction、decimal.Decimal 可进行类型内部、跨类型比较 类型相关限制内按数学（算法）规则正确进行比较，且不会 有精度损失 复数不支持次序比较 非数字值float('NaN')、decimal.Decimal('NaN') 同任何其他数字值比较均返回False 不等于自身，但是是同一个对象（标识相同） 具体实现参见cs_python/py3ref/#todo 二进制码序列二进制码序列：bytes、bytearray 可以进行类型内部、跨类型比较 使用元素数字值按字典序进行比较 字符串字符串：str 使用字符的Unicode码位数字值、按字典序比较 字符串、二进制码序列不能直接比较 序列序列：tuple、list、range 只能进行类型内部比较 跨类型：一致性比较结果为否、次序比较将 raise TypeError range不支持次序比较 序列元素通过相应元素进行字典序比较 序列相等：相同类型、相同长度，每对相应元素必须 相等 对支持次序比较序列：排序同第一个不相等元素排序，若 对应元素不同，较短序列排序较小 强制规定元素自反射性：序列元素x，x==x总为真 即序列元素比较比较时：须首先比较元素标识，仅会对不同 元素执行==严格比较运算 若序列元素为自反射元素，结果与严格比较相同；若序列 元素为非自反射元素，结果与严格比较不同 1234nan = float(&quot;NaN&quot;)(nan is nan) == True(nan == nan) == False([nan] == [nan]) == True 映射映射：dict 映射相等：当且进行具有相同键值对 键、值一致性比较强制规定自反射性 集合集合：set、frozenset 可进行类型内部、跨类型比较 比较运算符定义为子集、超集检测 这类关系没有定义完全排序，如：{1,2}、{2,3}集合 不相等，也没有大小比较关系 所以，集合不应作为依赖完全排序的函数参数，如： min、max、sorted，将产生未定义结果 集合强制规定其元素自反射性 自定比较行为 其他内置类型没有实现比较方法，继承object默认比较行为 可以通过实现富比较方法自定义类型的比较行为，最好 遵守一些一致性规则（不强制） 自反射：相同对象比较应该相等 x is y有x == y 对称性 x == y有y == x x != y有y != x x &lt; y有y &gt; x x &lt;= y有y &gt;= x 可传递 x &gt; y and y &gt; z有x &gt; z x &lt; y and y &lt;= z有x &lt; z 反向比较应该导致布尔取反 x == y有not x != y x &lt; y有not x &gt;= y（对完全排序） x &gt; y有not x &lt;= y（对完全排序） 相等对象应该具有相同hash值，或标记为不可hash 具体实现参见cs_python/py3ref/#todo 成员检测in、not in：成员检测，后者为前者取反 对list、tuple、set、frozenset、dict、 collections.deque等内置容器类型 x in y同any(x is e or x == e for e in y) 映射检测是否有给定键 对字符串、字节串 当且进当x为y其子串时x in y返回True，空字符串 总被视为其他字符串子串 x in y等价于y.find(x) != -1 自定义类型可以自定义成员检测 __contains__方法返回值即为x in y返回值 未定义__contains__方法但定义__iter__，若迭代y 得到值z == x，则x in y == True，出现异常等同于 in引发异常 具体实现参见cs_python/py3ref/#todo 标识号比较is、is not：对象标识号检测，后者为前者取反 当且仅当x、y为同一对象x is y == True 布尔运算布尔运算 123or_test ::= and_test | or_test &quot;or&quot; and_testand_test ::= not_test | and_test &quot;and&quot; not_testnot_test ::= comparison | &quot;not&quot; not_test 执行布尔运算、表达式用于流程控制语句时，以下值被解析为 假值，其余值被解析为真值 False None 所有数值类型的数值0 空字符串 空容器 and、or返回最终求值参数而不是False、True x and y：首先对x求值 对x求值，若为假直接返回x求值 否则对y求值并返回 x or y：首先对x求值 对x求值，若为真直接返回x求值 否则对y求值并返回结果值 not必须创建新值，无论参数为和类型均范围布尔值True、 False 可以通过自定义__bool__方法定制逻辑值 具体实现参见cs_python/py3ref/#todo 条件表达式条件表达式：三元运算符 123conditional_expression ::= or_test [&quot;if&quot; or_test &quot;else&quot; expression]expression ::= conditional_expression | lambda_exprexpression_nocond ::= or_test | lambda_expr_nocond 在所有python运算中具有最低优先级 x if C else y 首先对条件C求值 若C为真，x被求值并返回 否则将对y求值并返回 lambda表达式lambda表达式：创建匿名函数 12lambda_expr ::= &quot;lambda&quot; [parameter_list] &quot;:&quot; expressionlambda_expr_nocond ::= &quot;lambda&quot; [parameter_list] &quot;:&quot; expression_nocond lambda parameters: expression返回函数对象，同 12def &lt;lambda&gt;(parameters): return expression lambda表达式只是简单函数定义的简单写法 表达式列表表达式列表：除作为列表、集合显示的一部分，包含至少一个逗号 的列表表达式将生成元组 1234expression_list ::= expression (&quot;,&quot; expression)* [&quot;,&quot;]starred_list ::= starred_item (&quot;,&quot; starred_item)* [&quot;,&quot;]starred_expression ::= expression | (starred_item &quot;,&quot;)* [starred_item]starred_item ::= expression | &quot;*&quot; or_expr 末尾逗号仅在创建单独元组时需要，在其他情况下可选 元组长度就是列表中表达式的数量 表达式将从左至右被求值 *表示可迭代拆包：操作数必须为iterable（同实参调用） 可迭代对象将被拆解为迭代项序列，并被包含于新建的元组 、列表、集合中","link":"/Python/Py3Ref/expressions.html"},{"title":"Python包、模块","text":"综述导入方式importing操作可以使得模块能够访问其他模块中代码 import：结合了以下两个操作，发起导入调机制最常用方式 搜索指定名称模块：对__import__()带有适当参数调用 将搜索结果绑定到当前作用域中名称：__import__返回值 被用于执行名称绑定操作 __import__()：只执行模块搜索、找到模块后创建module 可能产生某些副作用 导入父包 更新各种缓存：sys.modules importlib.import_module() 可能会选择绕过__import__，使用其自己的解决方案实现 导入机制 用于为动态模块导入提供支持 importlib模块参见标准库 子模块 任意机制加载子模块时，父模块命名空间中会添加对子模块对象 的绑定 Packages python只有一种模块对象类型：所有模块都属于该类型，C、 Python语言实现均是 包：为帮助组织模块、并提供名称层次结构引入 可将包视为文件系统中目录、模块视为目录中文件， 但包、模块不是必须来自文件系统 类似文件系统，包通过层次结构进行组织：包内包括模块、 子包 所有包都是模块，但并非所有模块都是包 包是一种特殊的模块 特别的，任何具有__path__属性的模块都被当作包 所有模块都有自己的名字 子包名与其父包名以.分隔，同python标准属性访问语法 Regular Packages正规包：通常以包含__init__.py文件的目录形式出现 __init__.py文件可以包含和其他模块中包含python模块相似 的代码 正规包被导入时 __init__.py文件会隐式被执行，其中定义对象被绑定到 该包命名空间中名称 python会为模块添加额外属性 Namespace Packages命名空间包：由多个部分构成，每个部分为父包增加一个子包 包各部分可以物理不相邻，不一定直接对应到文件系统对象， 可能是无实体表示的虚拟模块 可能处于文件系统不同位置 可能处于zip文件、网络上，或在导入期间其他可搜索位置 __path__属性不是普通列表，而是定制的可迭代类型 若父包、或最高层级包sys.path路径发生改变，对象会 在包内的下次导入尝试时，自动执行新的对包部分的搜索 命名空间包中没有__init__.py文件 毕竟可能有多个父目录提供包不同部分，彼此物理不相邻 python会在包、子包导入时为其创建命名空间包 导入相关模块属性 以下属性在加载时被设置，参见 cs_python/py3ref/import_system __name__：模块完整限定名称，唯一标识模块 __loader__：导入系统加载模块时使用的加载器对象 主要用于内省 也可用于额外加载器专用功能 __package__：取代__name__用于主模块计算显式相对 导入 模块为包：应设置为__name__ 模块非包：最高层级模块应设为空字符串，否则为父包名 预期同__spec__.parent值相同，未定义时，以 __spec__.parent作为回退项 python &lt;PYSCIRPT&gt;直接执行脚本时__name__被设置为 __main__、__package__设置为None，此时导入器无法 解释相对导入中.，相对导入报错 python -m &lt;PYSCIRPT&gt;则会按模块逻辑设置__name__、 __package__，相对导入可以正常执行 __spec____spec__：导入模块时要使用的模块规格说明 对__spec__正确设置将同时作用于解释器启动期间 初始化的模块 仅__main__某些情况下被设置为None __path__ 具有该属性模块即为包：包模块必须设置__path__属性， 非包模块不应设置 在导入子包期间被使用，在导入机制内部功能同sys.path， 即用于提供模块搜索位置列表 但受到更多限制，其必须为字符串组成可迭代对象，但若其 没有进一步用处可以设置为空 适用作用于sys.path的规则 sys.path_hooks会在遍历包的__path__时被查询 可在包的__init__.py中设置、更改 在PEP420引入之后，命名空间包不再需要提供仅包含操作 __path__代码的__init__.py文件，导入机制会自动为 命名空间包正确设置__path__ 在之前其为实现命名空间包的典型方式 __repr__ 若模块具有__spec__，导入机制将尝试使用其中规格信息生成 repr name loader origin has_location 若模块具有__file__属性，将被用作repr的一部分 否则若模块具有__loader__属性且非None，则加载器repr 将被用作模块repr的一部分 其他情况下，仅在repr中适用模块的__name__ 可以在模块规则说明中显式控制模块对象repr __file__/__cached__ __file__：模块对应的被加载文件的路径名 __cached__：编译版本代码（字节码文件）路径 __file__为可选项，须为字符串 可以在其无语法意义时不设置 对从共享库动态加载的扩展模块，应为共享库文件路径名 __cached__ 不要求编译文件已经存在，可以表示应该存放编译文件 的位置 不要求__file__已经设置 有时加载器可以从缓存加载模块但是无法从文件加载 加载静态链接至解释器内部的C模块 从.pyc文件加载缓存字节码前会检查其是否最新 默认通过比较缓存文件中保存的源文件修改时间戳实现 也支持基于哈希的缓冲文件，此时.pyc文件中保存源文件 哈希值 检查型：求源文件哈希值再和缓存文件中哈希值比较 非检查型：只要缓存文件存在就直接认为缓存文件有效 --check-hash-based-pycs命名行选项设置基于哈希的 .pyc文件有效性 执行相关模块属性 __doc__：模块文档字符串 __annotaion__：包含变量标注的字典 在模块体执行时获取 __dict__：以字典对象表示的模块命名空间 CPython：由于CPython清理模块字典的设定，模块离开作用域时 模块字典将被清理，即使字典还有活动引用，可以复制该字典、 保持模块状态以直接使用其字典 sys.modules模块缓存sys.modules映射：缓存之前导入的所有模块（包括中间路径） （即导入子模块会注册父模块条目） 其中每个键值对就是限定名称、模块对象 在其中查找模块名称 若存在需要导入模块，则导入完成 若名称对应值为None则raise ModuleNotFoundError 若找不到指定模块名称，python将继续搜索 映射可写，可删除其中键值对 不一定破坏关联模块，因为其他模块可能保留对其引用 但是会使命名模块缓存条目无效，导致下次导入时重新 搜索命名模块，得到两个不同的两个模块对象 importlib.reload将重用相同模块对象，通过重新运行 模块代码重新初始化模块内容 Finders And Loaders Finders：查找器，确定能否使用所知策略找到指定名称模块 Loaders：加载器，加载找到的指定模块 Importer：导入器，同时实现两种接口的对象，在确定能加载 所需模块时会返回自身 导入机制通过import hooks实现扩展 可以加入新的查找器以扩展模块搜索范围、作用域 工作流程：在sys.modules缓存中无法找到指定名称模块时 查找器若能找到指定名称模块，返回模块规格说明spec 加载器将利用查找器返回的模块规格说明加载模块 Import Path导入路径：文件系统路径、zip文件等path term组成的位置列表 其中元素不局限于文件系统位置，可扩展为字符串指定的任意 可定位资源 URL指定资源 数据库查询 位置条目来源 通常为sys.path 对次级包可能来自上级包的__path__属性 其中每个路径条目指定一个用于搜索模块的位置 path based finder将在其中查找导入目标 sys.pathsys.path：模块、包搜索位置的字符串列表 初始化自PYTHONPATH环境变量、特定安装和实现的默认设置、 执行脚本目录（或当前目录） 其中条目可以指定文件系统中目录、zip文件、可用于搜索模块 的潜在位置 只能出现字符串、字节串，其他数据类型被忽略 字节串条目使用的编码由导入路径钩子、 path entry finder确定 所以可以修改sys.path值定制导入路径，CPython实现参见 cs_python/py3ref/import_system sys.path_import_cachesys.path_importer_cache：存放路径条目到路径条目查找器映射 的缓存 减少查找路径条目对应路径条目查找器的消耗，对特定路径条目 查找对应路径条目查找只需进行一次 可从中移除缓存条目，以强制基于路径查找器执行路径条目搜索 Import Hooks meta hooks：元[路径]钩子 导入过程开始时被调用，此时仅sys.modules缓存查找 发生，其他导入过程未发生 所以允许元钩子重载sys.path过程、冻结模块甚至内置 模块 元钩子即导入器/元路径查找器 sys.meta_path为元路径查找器列表，可在其中注册定制 元钩子 path[ entry] hooks：导入路径钩子 是sys.path、package.__path__处理的一部分 基于路径的查找器调用其处理路径条目，以获取路径条目 查找器 导入路径钩子返回路径条目查找器 sys.path_hooks为导入路径钩子列表，可在其中注册 定制导入路径钩子 默认元路径查找器/导入器python默认实现sys.meta_path有以下导入器（元路径查找器） BuiltinImporter：定位、导入内置模块 FrozenImporter：定位、导入冻结模块 PathFinder：定位、导入来自import path中模块 尝试导入模块时，内置模块、冻结模块导入器优先级较高，所以 解释器首先搜索内置模块 Finder 指定名称模块在sys.modules找不到时，python继续搜索 sys.meta_path，按顺序调用其中元路径查找器 若sys.meta_path处理到列表末尾仍未返回说明对象，则 raise ModuleNotFoundError 导入过程中引发的任何异常直接向上传播，并放弃导入过程 对非最高层级模块的导入请求可能会多次遍历元路径 Meta Path Finders元路径查找器： 元路径查找器可使用任何策略确定其是否能处理给定名称模块 若知道如何处理指定名称的模块，将返回模块规格说明 否则返回None 模块规格协议：元路径查找器应实现find_spec()方法 接受名称、导入路径、目标模块作为参数 返回模块规格说明 Spec 模块规格[说明]：基于每个模块封装的模块导入相关信息 模块规格中大部分信息对所有模块是公用的 模块规格说明作为模块对象的__spec__属性对外公开 用途 允许状态在导入系统各组件间传递，如：查询器和加载器 允许导入机制执行加载的样板操作，否则该由加载器负责 find_spec12def finder.find_spec(fullname, path=None, target=None): pass fullname：被导入模块的完整限定名称 path：供模块搜索使用的路径条目 对最高层级模块应为None 对子模块、子包应为父包__path__属性值，若 相应__path__属性无法访问将 raise ModuleNotFoundError target：将被作为稍后加载目标的现有模块对象 导入系统仅在重加载期间传入目标模块 导入器的find_spec()返回模块规格说明中加载器为self 有些元路径查找器仅支持顶级导入，path参数不为None时 总返回None Loaders 模块规格说明被找到时，导入机制将在加载该模块时使用 其中包含的加载器将被使用，若存在 加载流程12345678910111213141516171819202122232425262728293031323334353637module = Noneif spec.loader is not None and hasattr(spec.loader, 'create_module'): # 模块说明中包含加载器，使用加载器创建模块 module = spec.loader.create_module(spec)if module is None: # 否则创建空模块 module = types.ModuleType(spec.name) # 设置模块导入相关属性_init_module_attrs(spec, module)if spec.loader is None: # 模块说明中不包含加载器 # 检查模块是否为为命名空间包 if spec.submodule_search_locations is not None: # 设置`sys.modules` sys.modules[spec.name] = module else: raise ImportErrorelif not hasattr(spec.loader, &quot;exec_module&quot;): # 向下兼容现有`load_module` module = spec.loader.load_module(spec.name)else: sys.modules[spec.name] = module try: # 模块执行 spec.loader.exec_module(module) except BaseException: try: # 加载模块失败则从`sys.modules`中移除 del sys.modules[spec.name] except KeyError: pass raisereturn sys.modules[spec.name] 创建模块对象 设置模块导入相关属性：在执行模块代码前设置 sys.modules注册模块 模块执行：模块导入关键，填充模块命名空间 create_module创建模块对象 模块加载器可以选择通过实现create_module方法在加载 期间创建模块对象 其应接受模块规格说明作为参数 否则导入机制使用types.ModuleType自行创建模块对象 sys.modules注册模块 在加载器执行代码前注册，避免模块代码导入自身导致无限 递归、多次加载 若模块为命名空间包，直接注册空模块对象 exec_module模块执行 导入机制调用importlib.abc.Loader.exec_module()方法执行 模块对象 CPython：exec_module不定返回传入模块，其返回值将被 忽略 importlib避免直接使用返回值，而是通过在 sys.modules中查找模块名称获取模块对象 可能会间接导致被导入模块可能在sys.modules中 替换其自身 加载器应该该满足 若模块是python模块（非内置、非动态加载），加载器应该 在模块全局命名空间module.__dict__中执行模块代码 若加载器无法执行指定模块，则应raise ImportError， 在exec_module期间引发的任何其他异常同样被传播 加载失败时作为附带影响被成功加载的模块仍然保留 重新加载模块会保留加载失败模块（最近成功版本） Path Based Finder—PathFinder基于路径的查找器：在特定path entry中查找、加载指定的python 模块、包 基于路径查找器只是遍历import path中的路径条目，将其 关联至处理特定类型路径的path entry finder 默认路径条目查找器集合实现了在文件系统中查找模块的所有 语义，可以处理多种文件类型 python源码.py python字节码.pyc 共享库.so zip包装的上述文件类型（需要zipimport模块支持） 作为元路径查找器 实现有find_spec协议 并提供额外的钩子、协议以便能扩展、定制可搜索路径条目 的类型，定制模块从import path的查找、加载 流程导入机制调用基于路径的查找器的find_spec()迭代搜索 import path的路径条目，查找对应路径条目查找器 先在sys.path_impporter_cache缓存中查找对应路径条目 查找器 若没有在缓存中找到，则迭代调用sys.path_hooks中 Path Entry Hook 迭代结束后若没有返回路径条目查找器，则 置sys.path_importer_cache对应值为None 返回None，表示此元路径查找器无法找到该模块 当前目录对空字符串表示的当前工作目录同sys.path中其他条目处理方式 有所不同 若当前工作目录不存在，则sys.path_importer_cache 中不存放任何值 模块查找回对当前工作目录进行全新查找 sys.path_importer_cache使用、 importlib.machinery.PathFinder.find_spec()返回路径将是 实际当前工作目录而非空字符串 Path Entry Hook路径条目钩子：根据路径条目查找对应路径条目查找器的可调用对象 参数：字符串、字节串，表示要搜索的目录条目 字节串的编码由钩子自行决定 若钩子无法解码参数，应raise ImportError 路径条目钩子返回值 可处理路径条目的路径条目查找器 raise ImportError：表示钩子无法找到与路径条目对应 路径条目查找器 该异常会被忽略，并继续对import path迭代 Path Entry Finder—PathEntryFinder路径条目查找器： 元路径查找器作用于导入过程的开始，遍历sys.meta_path时 路径条目查找器某种意义上是基于路径查找器的实现细节 find_spec12def PathEntryFinder.find_spec(fullname, target=None): pass 路径条目查找器协议：目录条目查找器需实现find_spec方法 以支持模块、已初始化包的导入 给命名空间包提供组成部分 参数 fullname：要导入模块的完整限定名称 target：目标模块 返回值：完全填充好的模块规格说明 模块规格说明总是包含加载器集合 但命名空间包的规格说明中loader会被设置为None， 并将submodule_search_locations设置为包含该部分的 列表，以告诉导入机制该规格说明为命名空间包的portion Portion：构成命名空间包的单个目录内文件集合 替代旧式find_loader()、find_module()方法 替换标准导入系统 替换sys.meta_path为自定义元路径钩子 替换整个导入系统最可靠机制 替换内置__import__()函数 仅改变导入语句行为而不影响访问导入系统其他接口 可以在某个模块层级替换，只改变某块内部导入语句行为 替换find_spec()，引发ModuleNotFoundError 选择性的防止在元路径钩子导入某些模块 __main__ __main__模块是在解释器启动时直接初始化，类似sys、 builtins，但是不被归类为内置模块，因为其初始化的方式 取决于启动解释器的旗标（命令行参数） __spec__根据__main__被初始化的方式，__main__.__spec__被设置为 None或相应值 -m选项启动：以脚本方式执行模块 此时__spec__被设置为相应模块、包规格说明 __spec__会在__main__模块作为执行某个目录、zip 文件、其他sys.path条目的一部分加载时被填充 此时__main__对应可导入模块和__main__被视为不同 模块 其余情况 __spec__被设置为None 因为用于填充__main__的代码不直接与可导入模块相对应 交互型提示 -c选项 从stdin运行 从源码、字节码文件运行 -m执行模块时sys.path首个值为空字符串，而直接执行脚本 时首个值为脚本所在目录 Import[ Search] Path定制动态增加路径123import syssys.path.insert(1, /path/to/fold/contains/module) # 临时生效，对不经常使用的模块较好 修改PYTHONPATH环境变量12 # .bashrcexport PYTHONPATH=$PYTHONPATH:/path/to/fold/contains/module 对许多程序都使用的模块可以采取此方式 会改变所有Python应用的搜索路径 增加.pth文件在/path/to/python/site-packages（或其他查找路径目录）下 添加.pth配置文件，内容为需要添加的路径 12 # extras.pth/path/to/fold/contains/module 简单、推荐 python在遍历已知库文件目录过程中，遇到.pth文件会将其中 路径加入sys.path中","link":"/Python/Py3Ref/import_system.html"},{"title":"Simple Statements","text":"简单语句：由单个逻辑行构成 多条简单语句可以在同一物理行内、并以分号分隔 12345678910111213141516simple_stmt ::= expression_stmt | assert_stmt | assignment_stmt | augmented_assignment_stmt | annotated_assignment_stmt | pass_stmt | del_stmt | return_stmt | yield_stmt | raise_stmt | break_stmt | continue_stmt | import_stmt | future_stmt | global_stmt | nonlocal_stmt Expression Statements表达式语句：用于计算、写入值（交互模式下），或调用过程（不 返回有意义结果的函数） 1expresssion_stmt ::= starred_expression 用途：表达式语句对指定表达式[列表]进行求值 交互模式下 若值不为None：通过内置repr()函数转换为字符串， 单独一行写入标准输出 值为None：不产生任何输出 Assignment Statements赋值语句：将名称[重]绑定到特定值、修改属性或可变对象成员项 123456789assignment_stmt ::= (target_list &quot;=&quot;)+ (starred_expression | yield_expression)target_list ::= target (&quot;,&quot; target)* [&quot;,&quot;]target ::= identifier | &quot;(&quot; [target_list] &quot;)&quot; | &quot;[&quot; [target_list] &quot;]&quot; | attributeref | subscription | slicing | &quot;*&quot; target 用途：对指定表达式列表求值，将单一结果对象从左至右逐个 赋值给目标列表 赋值根据目标列表的格式递归定义，目标为可变对象组成部分时 （属性引用、抽取、切片），可变对象赋值有效性会被检查， 赋值操作不可接受可能引发异常 赋值顺序：将赋值看作是左、右端项重叠 根据定义赋值语句内多个赋值是同时重叠，如：a,b=b,a 交换两变量值 但赋值语句左端项包含集合类型时，重叠从左到右依次执行 1234x = [0,1]i = 0i, x[i] = 1, 2 # `x`现在为`[0, 2]` LOAD_XXX指令将右端项从左到右依次压栈 ROT_N指令交换栈顶元素 STORE_XXX指令将栈顶元素弹出从左到右依次给 右端项赋值 以上语句中，计算表达式x[i]前i已经被赋新值 dis.dis()查看代码块指令 赋值目标为列表赋值目标（左端项）为列表（可选包含在圆括号、方括号内） 若目标列表为不带逗号、可以包含在圆括号内的单一目标，将 右端项赋值给该目标 否则：右端项须为与目标列表相同项数的可迭代对象，其中 元素将从左至右顺序被赋值给对应目标 若目标列表包含带*元素：则类似实参解包，其须为可迭代 对象，且右端项至少包含目标列表项数-1 加星目标前元素被右端项前段元素一一赋值 加星目标后元素被右端项后段元素一一赋值 加星目标被赋予剩余目标元素构成的列表 赋值目标为单个目标目标为标识符（名称） 名称未出现在当前代码块global、nonlocal语句中：名称 被绑定到/赋值为当前局部命名空间对象 否则：名称被分别绑定到/赋值为全局命名空间、或nonlocal 确定的外层命名空间中对象 若名称已经被绑定则被重新绑定，可能导致之前被绑定名称 对象引用计数变为0，对象进入释放过程并调用其析构器 目标为属性引用 引用中原型表达式被求值：应产生具有可赋值属性的对象， 否则raise TypeError 该对象指定属性将被赋值，若无法赋值将 raise AttributeError 目标为抽取项 引用中原型表达式被求值：应产生可变序列对象（列表）、 映射对象（字典） 引用中抽取表达式被求值 若原型表达式求值为可变序列对象 抽取表达式产生整数，包含负数则取模，结果只须为 小于序列长度非负整数 整数指定的索引号的项将被赋值 若索引超出范围将raise IndexError 若原型表达式求值为映射对象 抽取表达式须产生与该映射键类型兼容的类型 映射可以创建、更新抽取表达式指定键值对 对用户自定义对象，将调用__setitem__方法并附带适当参数 目标为切片 引用中原型表达式被求值：应当产生可变序列对象 右端项应当是相同类型的序列对象 上界、下界表达式若存在将被求值 其应为整数，若为负数将对原型表达式序列长度求模，最终 边界被裁剪至0、序列长度开区间中 默认值分别为零、序列长度 切片被赋值为右端项 若切片长度和右端项长度不同，将在目标序列允许情况下 改变目标序列长度 Augmented Assignment Statements增强赋值语句：在单个语句中将二元运算和赋值语句合为一体 1234augmented_assignment_stmt ::= augtarget augop (expression_list | yield_expression)augtarget ::= identifier | attributeref | subscription | slicingaugop ::= &quot;+=&quot; | &quot;-=&quot; | &quot;*=&quot; | &quot;@=&quot; | &quot;/=&quot; | &quot;//=&quot; | &quot;%=&quot; | &quot;**=&quot; | &quot;&gt;&gt;=&quot; | &quot;&lt;&lt;=&quot; | &quot;&amp;=&quot; | &quot;^=&quot; | &quot;|=&quot; 增强赋值语句不能类似普通赋值语句为可迭代对象拆包 赋值增强语句对目标和表达式列表求值 依据两操作数类型指定执行二元运算 将结果赋给原始目标 增强赋值语句可以被改写成类似、但非完全等价的普通赋值语句 增强赋值语句中目标仅会被求值一次 在可能情况下，运算是原地执行的，即直接修改原对象而 不是创建新对象并赋值给原对象 所以增强赋值先对左端项求值 其他增强赋值语句和普通赋值语句不同点 单条语句中对元组、多目标赋值赋值操作处理不同 Annotated Assignment Statements带标注的赋值语句：在单个语句中将变量、或属性标注同可选赋值 赋值语句合并 1annotated_assignment_stmt ::= augtarget &quot;:&quot; expression [&quot;=&quot; expression] 与普通赋值语句区别仅在于：仅有单个目标、且仅有单个右端项 才被允许 在类、模块作用域中 若赋值目标为简单名称，标注会被存入类、模块的 __annotations__属性中 若赋值目标为表达式，标注被求值但不会被保存 在函数作用域内，标注不会被求值、保存 若存在右端项，带标注赋值在对标注值求值前执行实际赋值； 否则仅对赋值目标求值，不执行__setitem__、__setattr__ 参见cs_python/py3ref/#todo 关键字语句assertassert语句：在程序中插入调试性断言的简便方式 1assert_stmt ::= &quot;assert&quot; expression [&quot;,&quot; expression] assert语句等价于 123456789if __debug__: if not expression: raise AssertionError # 等价于`assert expression`if __debug__: if not expression1: raise AssertionError(expression2) # 等价于`assert expression1, expression2` 无需再错误信息中包含失败表达式源码，其会被作为栈追踪 一部分被显示 假定__debug__、AssertionError指向具有特定名称的内置 变量，当前实现中 对__debug__赋值是非法的，其值在解释器启动时确定 默认内置变量__debug__=True 请求优化时__debug__置为False -0命令行参数开启 若编译时请求优化，代码生成器不会为assert语句生成 代码 passpass语句：空操作，被执行时无事情发生 1pass_stmt ::= &quot;pass&quot; 适合语法上需要语句、但不需要执行代码时临时占位 deldel语句：从局部、全局命名空间中移除名称的绑定，若名称未绑定 将raise NameError 1del_stmt ::= &quot;del&quot; target_list 删除是递归定义的 类似赋值的定义方式 从左至右递归的删除目标列表中每个目标 属性、抽取、切片的删除会被传递给相应原型对象 删除切片基本等价于赋值为目标类型的空切片？？？ returnreturn语句：离开当前函数调用，返回列表表达式值、None 在生成器函数中，return语句表示生成器已完成 并raise StopIteration 返回值作为参数构建StopIteration，并作为 StopIteration.value属性 异步生成器函数中，return语句表示异步生成器已完成 并raise StopAsyncIteration 非空return返回值在将导致语法错误 1return_stmt ::= &quot;return&quot; [expression_list] return语法上只会出现于函数定义代码块中，不会出现于 类定义所嵌套代码中 若提供表达式列表，其将被求值；否则缺省为None return将控制流传出带有finally子句的try语句时， finally子句会先被执行然后真正离开函数 yieldyield语句：语义上等于yield表达式 1yield_stmt ::= yield_expression 可用于省略在使用等效yield表达式必须的圆括号 123456yield &lt;expr&gt;yield from &lt;expr&gt; # 以上yield语句、以下yield表达式等价(yield &lt;expr&gt;)(yield from &lt;expr&gt;) yeild表达式、语句仅在定义[异步]生成器函数时使用，且仅 用于函数体内部，且函数体包含yield就使得该定义创建 生成器函数而非普通函数 yield表达式参见cs_python/py3ref/#todo raiseraise语句：引发异常 1raise_stmt ::= &quot;raise&quot; [expression [&quot;from&quot; expression]] 若不带表达式：raise将重新引发当前作用域最后一个激活 异常 若当前作用域内没有激活异常，将引发RuntimeError 提示错误 否则计算表达式作为异常对象 异常对象须为BaseException子类、实例 若其为类，则通过不带参数的实例化该类作为异常实例 异常被引发时会自动创建回溯对象，并被关联至可写 __traceback__属性 可以创建异常时同时使用.with_traceback()异常方法 自定义回溯对象 1raise Exception(&quot;foo occured&quot;).with_traceback(tbobj) 异常串联 from子句用于异常串联：其后表达式求值需要为另一个异常 其将作为可写__cause__属性被关联到引发的第一个异常 若引发异常未被处理，两个异常都将被打印 若异常在try语句中finally子句、其他子句后、先中引发， 类似机制发挥作用，之前异常被关联到新异常的__context__ 属性 异常串联可以通过在from子句中指定None显式抑制 breakbreak语句：终结最近外层循环、循环的可选else子句 1break_stmt ::= &quot;break&quot; break在语法上只出现在for、while所嵌套代码 不包括循环内函数定义、类定义所嵌套代码 若for循环被break终结，循环控制目标保持当前值 当break将控制流传出带有finally子句的try语句时， finally子句会先被执行，然后真正离开循环 continuecontinue语句：继续执行最近外层循环的下一伦茨 1continue_stmt ::= &quot;continue&quot; continue在语法上只出现在for、while所嵌套代码 不包括循环内函数定义、类定义、finally子句所嵌套 代码 当continue将控制流传出带有finally子句的try语句时， finally子句会先被执行，然后真正开始循环下一个轮次 importimport语句 12345678import_stmt ::= &quot;import&quot; module [&quot;as&quot; identifier] (&quot;,&quot; module [&quot;as&quot; identifier])* | &quot;from&quot; relative_module &quot;import&quot; identifier [&quot;as&quot; identifier] (&quot;,&quot; identifier [&quot;as&quot; identifier])* | &quot;from&quot; relative_module &quot;import&quot; &quot;(&quot; identifier [&quot;as&quot; identifier] (&quot;,&quot; identifier [&quot;as&quot; identifier])* [&quot;,&quot;] &quot;)&quot; | &quot;from&quot; module &quot;import&quot; &quot;*&quot;module ::= (identifier &quot;.&quot;)* identifierrelative_module ::= &quot;.&quot;* module | &quot;.&quot;+ 基本import子句执行步骤 查找模块，若有必要加载并初始化模块 为import所处作用域的局部命名空间定义名称 语句包含多个子句（逗号分隔）时，以上两个步骤将分别 对每个子句执行，如同子句被分成独立import语句 默认情况下，导入的父模块中命名空间中不包含子模块属性， 即导入父模块不能直接通过属性.引用子模块 有些包会在父模块中导入子模块，则初始化模块时父模块 中即有子模块属性 在当前模块手动导入子模块，子模块绑定至父模块命名空间 中同名属性 导入机制参见cs_python/py3ref/import_system 绑定 若模块名称后带有as，则在as之后名称将直接绑定到所导入 模块 若没有指定其他名称、且被导入模块为最高层级模块，则模块 名称被绑定到局部命名空间作为对所导入模块的引用 若被导入模块不是最高级模块，则包含该模块的最高层级包名将 被绑定到局部命名空间作为的该最高层级包的引用，所导入模块 必须使用完整限定名称访问而不能直接访问 from子句 查找from子句中指定模块，若有必要则加载并初始化模块 对import子句中指定的每个标识符 检查被导入模块是否有该名称属性 若没有，尝试导入具有该名称子模块，然后再次检查 被导入（上级）模块是否具有该属性 若未找到该属性，则raise ImportError 否则将对该值引用存入局部命名空间，若有as子句则 使用其指定名称，否则使用该属性名称 *通配符标识符列表为通配符*形式：模块中定义的全部公有名称都被绑定 至import语句作用域对应局部命名空间 模块命名空间中__all__属性：字符串列表，指定模块 定义的公有名称 其中字符串项为模块中定义、导入的名称 其中中所给出的名称被视为公有、应当存在 应该包含所有公有API、避免意外导出不属于API部分项 若__all__属性未定义：则公有名称集合将包括在模块 命名空间中找到的、所有不以_开头名称 通配符模式仅在模块层级允许使用，在类、函数中使用将 raise SyntaxError 相对导入相对导入：指定导入模块时，无需指定模块绝对名称 需要导入的模块、包被包含在同一包中时，可在相同顶级包中 进行相对导入，无需指明包名称 在from子句中指定的模块、包中使用前缀点号指明需要上溯 包层级数 一个前缀点号：执行导入的模块在当前包 两个前缀点号：上溯一个包层级 三个前缀点号：上溯两个包层级，依此类推 1form ...sub_sub_pkg import mod1 相对导入可以避免模块之间产生冲突，适合导入相关性强代码 脚本模式（在命令行中执行.py文件）不支持相对导入 要跨越多个文件层级导入，只需要使用多个.，但 PEP 328建议，相对导入层级不要超过两层 future语句future语句：指明莫格特定模块使用在特定、未来某个python发行版 中成为标准特性的语法、语义 12345future_stmt ::= &quot;from&quot; &quot;__future__&quot; &quot;import&quot; feature [&quot;as&quot; identifier] (&quot;,&quot; feature [&quot;as&quot; identifier])* | &quot;from&quot; &quot;__future__&quot; &quot;import&quot; &quot;(&quot; feature [&quot;as&quot; identifier] (&quot;,&quot; feature [&quot;as&quot; identifier])* [&quot;,&quot;] &quot;)&quot;feature ::= identifier import __future__ [as name]：不是future语句，只是没有 特殊语义、语法限制的普通import语句 用途 允许模块在包含新特性发行版前使用该特性 目的是使得在迁移至引入不兼容改变的python未来版本 更容易 future语句是针对编译器的指令 在编译时被识别并做特殊对待 改变核心构造语义常通过生成不同代码实现 新特性可能会引入不兼容语法，如：新关键字，编译器 可能需要以不同方式解析模块 编译器需要知道哪些特性名称已经定义 包含未知特性的future语句将引发编译时错误 直接运行时语义同其他import语句 相应运行时语义取决于future语句启用的指定特性 在包含future语句的环境中，通过exec()、compile() 调用代码会使用future语句关联的语法、语义，此行为 可以通过compile()可选参数加以控制 future语句必须在靠近模块开头位置处出现，可以出现在future 语句前的行 模块文档字符串 注释 空行 其他future语句 globalglobal语句：声明所列出标识符将被解读为全局变量 1global_stmt ::= &quot;global&quot; identifier (&quot;,&quot; identifier)* global语句是作用于整个当前代码块的声明 局部作用域中给全局变量赋值必须用到global关键字 仅仅是获取值无需global语句声明 但自由变量也可以指向全局变量而不必声明为全局变量 global语句中列出的名称 不能被定义为形参名 不能作为for循环控制目标 不能出现在类定义、函数定义、import语句、变量标注中 CPython：暂时未强制要求上述限制，未来可能更改 global是对解释器的指令，仅对与global语句同时被解析 的代码起作用 包含在作为exec()参数的字符串、代码对象中global 语句不会影响exec()所在代码块 反之exec()中代码也不会被调用其代码块影响 eval()、compile()等函数同 nonlocalnonlocal语句：使得列出的名称指向之前最近的包含作用域中 绑定的、除全局变量外的变量 1nonlocal_stmt ::= &quot;nonlocal&quot; indentifier (&quot;,&quot; identifier)* nonlocal语句允许被封装代码重新绑定局部作用域以外、且非 全局（模块）作用域当中变量 即nonlocal语句中列出名称，必须指向之前存在于 包含作用域中的绑定 nonlocal语句中列出名称不能与之前存在的局部作用域中 绑定冲突","link":"/Python/Py3Ref/simple_stmts.html"},{"title":"Rust 语法","text":"Rust是基于表达式的语言表达式返回一个值，而语句不返回，rust中除两种语句外，全是 表达式 let引入绑定 可变绑定赋值是表达式，返回空tuple 声明后初始化绑定？#todo 表达式语句：表达式后跟分号转换为语句 代码中rust希望语句后跟语句，使用分号分隔表达式，所以rust 看起来和其他大部分分号结尾语言相似 {}包裹的代码块内最后一“句”没有以”;”结尾，那么是表达式，且 返回该表达式的值，整个代码块可以看作是表达式，否则为语句， 没有返回值，函数同 模式匹配Refutability（可反驳性） refutable（可反驳的）：对某些可能值匹配失败的模式， if let、while let只能接受可反驳的模式，因为这就用于 处理可能的失败 irrefutable（不可反驳的）：能匹配任何传递的可能值，let 语句、函数参数、for循环只能接受不可反驳的模式，因为 通过不匹配值的程序无意义 可能值是指“类型”相同，可用于匹配的值 12345678let Some(x) = some_optiona_value; //`Some(x)`是refutable模式，若`some_optional_value`为 //None，则此时无法成功匹配，此语句可能无法正常工作if let x = 5 { //`x`是inrefutable模式，对所有可能值都可以匹配，此语句 //无意义 println!(&quot;{}&quot;, x);} Refutablematch控制流 各分支模式同值“类型”必须完全一致才能匹配 返回类型必须一致，如果有返回值 匹配必须是穷尽的，可以使用通配符_（匹配所有的值）代替 match是匹配到就退出，不像switch一样会继续下沉 通配符不总是需要的，对于枚举类型只要含有所有枚举 成员的分支即可 1234567891011let x = Some(5);let y = 10;match x{ Some(50) =&gt; println!(&quot;got 50&quot;), //`Some(50)`这个模式规定了“值” Some(y) =&gt; println!(&quot;matched, y = {:?}&quot;, y), //match表达式作用域中的`y`会覆盖周围环境的`y` _ =&gt; println!(&quot;default case, x = {:?}&quot;, x),}println!(&quot;at the end: x = {:?}, y = {:?}&quot;, x, y); if let[else]简洁控制流 只匹配关心的一个模式 可以添加else语句，类似match通配符匹配 if let、else if、else if let等相互组合可以提供更多 的灵活性 else if可以不是模式匹配 各if后的比较的值可以没有关联 没有穷尽性检查，可能会遗漏一些情况 123456789101112131415161718192021222324252627fn main(){ let favorite_color: Option&lt;&amp;str&gt; = None; let is_tuesday = false; let age: Result&lt;u8, _&gt; = &quot;34&quot;.parse(); if let Some(color) = favorite_color{ //模式匹配 //注意这里是`=`而不是一般值比较`==` //`while`同 println!(&quot;favorite color is {}&quot;, color}; }else if is_tuesday{ //普通`if`条件语句 println!(&quot;Tuesday is green day!&quot;); }else if let Ok(age) = age{ //`age`变量覆盖原变量 //此时`age`是`u8`类型 if age &gt; 30 { //因此此条件不能提出，因为两个`age`变量不同， //不能共存在同一条语句中 println!(&quot;Using purple as the background color&quot;); }else{ println!(&quot;Using orange as the background color&quot;); } }else{ println!(&quot;Using blue as the background color&quot;); }} Irrefutablewhile let条件循环和if let条件表达式类似，循环直到模式不匹配 123456789fn main(){ let mut stack = Vec::new(); stack.push(1); stack.push(2); stack.push(3); while let Some(top) = stack.pop(){ println!(&quot;{}&quot;, top); }} for解构1234567fn main(){ let v = vec!['a', 'b', 'c']; for (index, value) in v.iter().enumerate(){ //解构tuple println!(&quot;{} is at index {}&quot;, value, index); }} let解构let语句本“应该“看作是模式匹配 123456789let PARTTERN = EXPRESSION; //这样就和`if let`模式匹配中`=`一致 //应该可以把`=`看作是模式匹配的符号let x = 5; //这里`x`是一个模式“变量”let (x, y, z) = (1, 2, 4); //`(x, y, z)`是模式“3元元组“ //解构元组 函数参数类似于let语句，函数参数也“应该”看作是模式匹配 123456789fn foo(x: i32){ //`x`表示模式“变量”}fn print_coordinates(&amp;(x, y): &amp;(i32, i32)){ //这里`(x, y)`是模式“元组” //但是这里处于函数变量类型的要求，有点像元组结构体 //调用时使用元组即可 println!(&quot;Current location: ({}, {})&quot;, x, y);} 模式匹配用法|、...“或“ |“或”匹配多个模式 ...闭区间范围模式，仅适用于数值、char值 12345678910111213141516171819let x = 1;match x { 1 =&gt; println!(&quot;one&quot;), //`1`是模式“字面值” 2 | 3 =&gt; println!(&quot;two or three&quot;), //`|`分隔，匹配多个模式 5...10 =&gt; println!(&quot;through 5 to 10&quot;), //`...`表示匹配一个**闭区间**范围的值 //这个语法只能用于数字或者是`char`值，因为编译器会 //检查范围不为空，而只有数字、`char`值rust可以判断 _ =&gt; println!(&quot;anything&quot;),}let x = 'c';match x { 'a'...'j' =&gt; println!(&quot;early ASCII letter&quot;), 'k'...'z' =&gt; println!(&quot;late ASCII letter&quot;), _ =&gt; println!(&quot;something else&quot;),} _、..”忽略“ _忽略整个值 1234567891011121314151617181920fn foo(_: i32, y: i32){ //函数签名中忽略整个值 println!(&quot;this code only use the y parameter: {}&quot;, y);}fn main(){ foo(3, 4); let mut setting_value = Some(5); let new_setting_value = Some(10); match (setting_value, new_setting_value){ (Some(_), Some()) =&gt; { //嵌套`_`忽略部分值 //此时没有任何值所有权 println!(&quot;can't overwrite an exsiting customized value&quot;); } _ =&gt; { setting_value = new_setting_value; } } println!(&quot;setting is {:?}&quot;, setting_value);} _var变量名前添加下划线忽略未使用变量，此时值所有权 仍然会转移，只是相当于告诉编译器忽略该未使用变量 123456789101112fn main(){ let _x = 5; //两个变量未使用，但是编译时只有一个warning let y = 10; let s = Some(5); if let Some(_s) = s { //值所有权已转移，`s`不能继续使用 //编译器忽略未使用`_s`，不给出warning println!(&quot;get a integer&quot;); }} ..忽略剩余值 ..的使用必须无歧义 对于结构体即使只有一个field，需使用..忽略剩余值， 不能使用_12345678fn main(){ let numbers = (2, 4, 6, 8, 10); match numbers{ (first, .., last) =&gt; { println!(&quot;Some numbers: {}, {}&quot;, first, last); } }} 1234let (x, _, z) = (1, 2, 4); //`_`忽略模式中各一个值let (x, .., z) = (1, 2, 3, 4); //`..`忽略模式中多个值 解构结构体1234567891011121314151617181920212223242526struct Point{ x: i32, y: i32,}fn main(){ let p = Point{x: 0, y: 7}; let Point{x: a, y: b} = p; //`Point{x: a, y: b}`是模式”Point结构体“ //解构结构体 let p = Point{x: 0, y: 7}; let Point{x, y} = p; //模式匹配解构结构体简写 //只要列出结构体字段，模式创建相同名称的变量 let p = Point{x: 0, y: 7}; match p { Point {x, y: 0} =&gt; println!(&quot;on the x axis at {}&quot;, x), Point {x: 0, y} =&gt; println!(&quot;on the y axis at {}&quot;, y), Point {x, y} =&gt; println!(&quot;on neither axis: ({}, {})&quot;, x, y), //这里没有`_`通配符，因为`Point {x, y}`模式已经 //是irrefutable，不需要 }} 解构枚举12345678910111213141516171819202122232425262728293031enum Message{ Quit, Move{x: i32, y:i32}, Write(String), ChangeColor(i32, i32, i32),}fn main(){ let msg = Message::ChangeColor(0, 160, 255); let p = match msg{ //这里`match`返回值必须类型完全相同 Message::Move{x, y} if x == 0 =&gt; (x, y), //对于`Message`中的匿名结构体类型的成员，匿名 //结构体没有枚举类型外的定义、名称，无法、也 //不应该直接获取结构体 Message::Write(ref str) =&gt; { //`Message::Write`不是`Message`的一个枚举成员 //必须`Message::Write(str)`才是（能够匹配） println!(&quot;write {}&quot;, str); (1,1) }, Message::ChangeColor(..) =&gt; (1,0), //类似的，需要使用`..`忽略值，仅`ChangeColor` //不是`Message`成员 _ =&gt; { println!(&quot;quit&quot;); (0,0) }, };} &amp;、ref、ref mut”引用“ &amp;匹配引用，“获得”值 1234567891011let points = vec![ Point {x: 0, y: 0}, Point {x: 1, y: 5}, Point {x: 10, y: -3},}let sum_of_squares: i32 = points .iter() .map(|&amp;Point {x, y}| x * x + y * y) //`&amp;`匹配一个引用 .sum(); ref匹配值，“获得”不可变引用 12345678let robot_name = Some(String::from(&quot;Bors&quot;));match robot_name{ Some(ref name) =&gt; println!(&quot;found a name: {}&quot;, name), //使用`ref`获取不可变引用才能编译成功 //否则所有权转移，之后报错 None =&gt; (),}println!(&quot;robot_name is: {:?}&quot;, robot_name); ref mut匹配值，“获得”可变引用 123456let robot_name = Some(String::from(&quot;Bors&quot;));match robot_name{ Some(ref mut name) =&gt; *name = String::from(&quot;NewName&quot;), None =&gt; (),}println!(&quot;robot_name is: {:?}&quot;, robot_name); ifmatch guard匹配守卫match guard：放在=&gt;之前的if语句，match 分支的额外条件，条件为真才会继续执行分支代码 12345678910111213141516let num = Some(4);let y = 5;match num{ Some(x) if x &lt; y =&gt; println!(&quot;'less than y: {}&quot;, x), Some(x) =&gt; println!(&quot;{}&quot;, x), None =&gt; (),}let x = 4;let y = false;match x { 4 | 5 | 6 if y =&gt; println!(&quot;yes&quot;), //`4 | 5 | 6`整体作为一个模式，match guard作用于 //模式整体，而不是单独的`6` _ =&gt; println!(&quot;no&quot;),} @绑定@允许在创建存放值的变量时，同时测试值是否匹配模式 1234567891011121314151617181920enum Message{ Hello { id: i32},}let msg = Message::Hello { id: 5 };match msg{ Message::Hello{ id: id_variable @ 3...7 } =&gt; { //匹配结构体模式（值绑定`id_variable`）&amp;&amp;值在`3...7`范围 println!(&quot;Found an id in range: {}&quot;, id_variable) }, Message::Hello{ id: 10...12 } =&gt; { //此分支模式指定了值的范围，但是没有绑定值给变量`id` //结构体匹配简略写法不能应用与此 println!(&quot;Found an id in another range&quot;) } Message::Hello{ id } =&gt; { //此分支结构体匹配简略写法，值绑定于`id` println!(&quot;Found some other id: {}&quot;, id) },} 闭包closures和函数指针闭包是可以保存进变量或作为参数传递给其他函数的匿名函数， 可以在一个地方创建闭包，而在不同的上下文执行闭包。和函数 的区别在于，其可以捕获调用者作用域中的值，当然这会有性能 损失，如果不需要捕获调用者作用域中的值可以考虑使用函数 1234let closures = |param1, param2|{ ... expression} 闭包参数：调用者使用， 创建闭包赋值给变量，再通过变量调用闭包 创建闭包作为参数传递，其他函数调用 捕获环境变量：创建闭包作为参数传递，直接使用周围环境变量 闭包类型推断和注解闭包不要求像函数一样需要在参数和返回值上注明类型，函数需要 类型注解因为其是需要暴露给的显示接口的一部分，而闭包不用于 作为对外暴露的接口 作为匿名函数直接使用，或者存储在变量中 通常很短，使用场景上下文比较简单，编译器能够推断参数和 返回值类型 当然，闭包也可以添加注解增加明确性 12345fn add_one_v1 {x: u32} -&gt; u32 { x + 1 };let add_one_v2 = |x: u32| -&gt; u32 { x + 1 };let add_one_v3 = |x| { x + 1 };let add_one_v4 = |x| x + 1; //闭包体只有一行可以省略`{}` Rust会根据闭包出调用为每个参数和返回值推断类型，并将其锁定， 如果尝试对同一闭包使用不同类型的参数调用会报错 12345let example_closure = |x| x;let s = example_closure(String::from(&quot;hello&quot;)); //此时已经锁定闭包参数、返回值类型let n = example_closure(5); //尝试使用`i32`类型调用闭包会报错 Fntrait bound每个闭包实例有自己独有的匿名类型，即使两个闭包有相同的签名， 其类型依然不同。为了定义使用闭包的结构体、枚举、函数参数， （这些定义中都需要指定元素类型），需要使用泛型和trait bound FnOnce：获取从周围环境捕获的变量的所有权，因此只能调用 一次，即Once的含义 Fn：获取从周围环境捕获的变量的不可变引用 FnMut：获取从周围环境捕获的变量的可变引用 所有的闭包都实现了以上3个trait中的一个，Rust根据闭包如何 使用环境中的变量推断其如何捕获环境，及实现对应的trait 123456struct Cacher&lt;T&gt; where T: Fn(u32) -&gt; u32{ //`T`的类型中包括`Fn`、参数、返回值三个限定 calculation: T, value: Option&lt;u32&gt;,} Function Pointer fn1234567891011fn add_one(x: i32) -&gt; i32{ x + 1}fn do_twice(f: fn(i32) -&gt; i32, arg: i32) -&gt; i32{ //`f`是`fn`函数指针类型 f(arg) + f(arg)}fn main(){ let answer = do_twice(add_one, 5); println!(&quot;the anwser is: {}&quot;, anwser);} 函数指针类型实现了以上全部Fn、FnMut、FnOnce三个 trait，所以总是可以在调用期望闭包作为参数的函数时传递函数 指针，因此倾向于使用泛型和闭包trait bound的函数，这样可以 同时使用闭包、函数指针作为参数。 1234567891011121314let list_of_numbers = vec![1, 2, 3];let list_of_Strings: Vec&lt;String&gt; = list_of_numbers .iter() .map(|i| i.to_string()) //闭包作为参数传递 .collect();let list_of_strings: Vec&lt;String&gt; = list_of_numbers .iter() .map(ToString::to_string) //函数作为参数传递 //使用了完全限定语法，因为存在多个`to_string`函数 //标准库为所有实现了`Display`的类型实现了此trait .collect(); 与不存在闭包的外部代码（如C语言，只有函数没有闭包）交互时， 只能使用函数作为参数，不能使用闭包。 move关键字move关键字强制闭包获其捕获的环境变量的所有权，在将闭包 传递给新线程以便将数据移动到新线程时非常实用 1234567fn main(){ let x = vec![1, 2, 3] let equal_to_x = move |z| z == x; println!(&quot;can't use x here: {:?}&quot;, x); //此时`x`的所有权已经转移进闭包，不能在闭包外使用 let y = vec![1, 2, 3]; assert!(equal_to_x(y)); 返回闭包闭包表现为trait，没有确定的类型、大小，无法直接返回，也不 允许使用函数指针fn作为返回值类型，需要使用trait对象返回 闭包 1234fn return_closure() -&gt; Box&lt;Fn(i32) -&gt; i32&gt;{ //trait对象作为返回值 Box::new(|x| x + 1)} 迭代器Iterator迭代器负责遍历序列中的每一项和决定序列何时结束的逻辑。Rust 中迭代器时惰性的，直到调用方法”消费“迭代器之前都不会有效果 Iteratortrait迭代器都实现了标准库中Iteratortrait 12345678trait Iterator{ type Item; //定义`Iterator`的关联类型 fn next(&amp;mut self) -&gt; Option&lt;Self::Item); //参数是`&amp;mut self`，要求迭代器是`mut`类型 //`next`方法改变了迭代器中用来记录序列位置的状态 //methods with default implementation elided} next方法next是Iterator唯一要求被实现的方法，其返回迭代器中封装 在Some中的一项（消费迭代器中的一项），迭代器结束时， 返回None。 1234567891011121314#[test]fn iterator_demostration(){ let v1 = vec![1, 2, 3]; let mut v_iter = v1.iter(); //注意`v_iter`声明为`mut` //使用`for`循环时无需使`v1_iter`可变，`for`会获取其 //所有权并在后台使其可变 assert_eq!(v1_iter.next(), Some(&amp;1)); assert_eq!(v1_iter.next(), Some(&amp;2)); assert_eq!(v1_iter.next(), Some(&amp;3)); //真的很难理解，rust中&amp;integer是怎么比较的 assert_eq!(v1_iter.nett(), None));} 消费适配器Comsuming AdaptorsIteratortrait中定义，调用next方法，消耗迭代器 12345678#[test]fn iterator_sum(){ let v1 = vec![1, 2, 3]; let v1_iter = v1.iter(); let total:i32 = v1_iter.sum(); //`sum`获取迭代器所有权，`v1_iter`不能继续使用 assert_eq!(total, 6); 迭代器适配器Iterator AdaptorsIteratortrait中定义，将当前迭代器变为其他迭代器，同样是 惰性的，必须调用消费适配器以便获取迭代适配器的结果 123456let v1:Vec&lt;i32&gt; = vec![1, 2, 3];v1.iter().map(|x| x + 1); //这里因为没有调用消费适配器，其实没有做事let v2:Vec&lt;_&gt; = v1.iter().map(|x| x + 1).collect();assert_eq!(v2, vec![2, 3, 4]) 1234567891011121314151617181920212223242526272829303132#[derive(PartialEq, Debug)]struct Shoe{ size: u32, style: String,}fn shoes_in_my_size(shoes: Vec&lt;Shoe&gt;, show_size: u32) -&gt; Vec&lt;Shoe&gt;{ shoes.into_iter() //获取vector所有权的迭代器 .filter(|s| s.size == show_size) //这里使用闭包获取外部环境变量 .collect()}#[test]fn filter_by_size(){ let shoes = vec![ Shoe{size: 10, style: String::from(&quot;sneaker&quot;)}, Shoe{size: 13, style: String::from(&quot;sandal&quot;)}, Shoe{size: 10, style: String::from(&quot;boot&quot;)}, ]; let in_my_size = shoes_in_my_size(shoes, 10); assert_eq!( in_my_size, vec![ Shoe{size: 10, style: String::from(&quot;sneaker&quot;)}, Shoe{size: 10, style: String::from(&quot;boot&quot;)}, ] );} 实现Iterator12345678910111213141516171819202122232425262728293031struct Counter{ count: i32,}impl Counter{ fn new() -&gt; Counter{ Counter{count: 0} }}impl Iterator for Counter{ type Item = u32; //迭代器将返回`u32`值集合 fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;{ self.count += 1; if self.count &lt; 6{ Some(self.count) }else{ None } }}#[test]fn using_other_iterator_trait_methods(){ let sum: u32 = Counter::new().zip(Counter::new().skip(1)) .map(|(a, b)| a * b) .filter(|x| x % 3 == 0) .sum(); assert_eq!(18, sum); 并发（并行）多线程可以改善性能，但是也会增加复杂性 竞争状态Race Conditions：多个线程以不一致的顺序访问资源 死锁Dead Lock：线程互相等待资源释放，阻止继续运行 只会在特定情况出现、无法稳定重现的bug 线程模型 1:1模型：一个OS线程对应一个语言线程，语言调用操作系统 API创建线程，性能较好 M:N模型：语言有自己的线程实现，其提供的线程称为 绿色(green)线程，M个绿色线程对应N个OS线程，更好的 运行控制、更底的上下文切换成本 Rust为了更小的运行时（这里表示二进制文件中语言自身提供的 代码）考虑，标准库中只提供了1:1线程模式实现。可以通过一些 crate扩展M:N线程模式。 spawn创建新线程std::thread::spawn接受一个闭包作为参数，返回JoinHandle 类型的句柄。作为spawn参数的闭包和一般的闭包有些不同， 线程直接独立执行，所以此时闭包捕获外部环境变量不能按照默认 的获取不可变引用，因为此时捕获的变量值可能已经被丢弃，必须 使用move关键字获取所有权，而一般的闭包是顺序执行的，没有 特殊需要可以直接获取不可变引用，而能够保证值不被丢弃。 12345678910111213141516171819202122232425262728293031use std::thread;use std::time:Duration;fn main(){ let handle = thread::spawn(|| { //`thread::spawn`接受一个闭包作为参数，返回 //`JoinHandle`类型的值（不是引用） for i in 1..10{ println!(&quot;number {} from spwaned thread!&quot;, i); thread::sleep(Duration::from_millis(1)); } ); for i in 1..5{ println!(&quot;number{} from main thread!&quot;, i); thread::sleep(Duration::from_millis(1)); } handle.join().wrap(); //`JoinHandle.join()`将阻塞直到其对应的线程结束 //如果调用`join`，spawn线程可能无法执行完毕 //因为主线程执行完，整个进行结束 //注意`join`调用的位置决定阻塞的位置 let v = vec![1, 2 , 3]; let handle = thread::spawn(move || { //这里`move`关键字将捕获的外部环境中变量`v`所有权 //移入spawn线程，否则无法正常编译 prinln!(&quot;here's a vector: {:?}&quot;, v); }); handle.join().unwrap();} 消息传递Rust中实现消息传递并发的主要工具是通道（channel） mpsc::channelmpsc：multiple producer single consumer，多个生产者，单个 消费者，即Rust标准库实现通道的方式允许多个产生值的发送端，但 只能有一个消费这些值的接收端。发送端或接收端任一被丢弃时， 意味着通道被关闭 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859use std::thread;use std::sync:mpsc;use std::time:Duration;fn main(){ let (tx, rx) = mpsc::channel(); //`tx`表示发送端，`rx`表示接收端 let tx1 = mpsc::Sender::clone(&amp;tx); //clone发送端创建多个生产者 thread::spawn(move || { let vals = vec![ String::from(&quot;hi&quot;), String::from(&quot;from&quot;), String::from(&quot;the&quot;), String::from(&quot;thread&quot;), ]; for val in vals { tx1.send(val).unwrap(); //`send`会获取参数所有权归接收者所有，避免 //值被其他线程丢弃、修改导致意外结果 //`send`返回`Result&lt;T, E&gt;`，如果接收端被丢弃 //将没有发送值的目标，将返回`Err&lt;E&gt;` thread::sleep(Duration::from_secs(1)); } }); thread::spawn(move || {d let vals = vec![ String::from(&quot;move&quot;), String::from(&quot;messages&quot;), String::from(&quot;for&quot;), String::from(&quot;you&quot;), ]; for val in vals{ tx.send(val).unwrap(); thread::sleep(Duration::from_secs(1)); } }); let received = rx.recv().unwrap(); //`recv`将阻塞直到接收到一个值，返回`Result&lt;T, E&gt;` //通道发送端关闭时`recv`将返回`Err&lt;E&gt;`表明不会有新值 let received = rx.try_recv().unwrap(); //`try_recv`不阻塞，立刻返回`Result&lt;T, E&gt;`，`Err&lt;E&gt;` //表示当前没有消息 //可以再循环中多次调用`try_recv`，有消息进行处理， //否则进行其他工作直到下次调用`try_recv` for received in rx{ //将接收端`rx`当作迭代器使用，返回接收到值 println!(&quot;Got: {}&quot;, received); }} 共享状态（任何语言）通道都类似于单所有权，一旦值通过通道传送，将无法 再次使用，而共享内存类似于多所有权 Mutex&lt;T&gt;互斥器mutex：mutual exclusion，任意时刻只允许一个线程访问 数据 线程在访问数据之前需要获取互斥器的锁lock，lock是作为 互斥器一部分的数据结构，记录数据所有者的排他访问权 处理完互斥器保护的数据之后，需要解锁，这样才能允许其他 线程获取数据 Mutex&lt;T&gt;类似于线程安全版本的RefCell&lt;T&gt;（cell族）， 提供了内部可变性，Mutex&lt;T&gt;有可能造成死锁，如一个操作需要 两个锁，两个线程各持一个互相等待。 Arc&lt;T&gt;原子引用计数atomically reference counted，则是 线程安全版本的Rc&lt;T&gt;，而线程安全带有性能惩罚，如非必要， 使用单线程版本Rc&lt;T&gt;性能更好。 12345678910111213141516171819202122232425262728293031323334use std::sync::{Mutex, Arc};use std::thread;fn main(){ let counter = Arc::new(Mutex::new(0)); //因为需要在多个线程内引用，所以需要使用多所有权 //数据结构，而`Rc`不是线程安全的，需要使用线程安全 //`Arc` let mut handles = vec![]; for _ in 0..10{ let counter = Arc::clone(&amp;counter); let handle = thread::spawn(move || { let mut num = counter.lock().unwrap(); //`lock`返回一个`MutexGuard`类型的智能指针， //实现了`Deref`指向其内部数据，`Drop`当 //`MutexGuard`离开作用域时自动释放锁 //只有`lock`才能获取值，类型系统保证访问数据之前 //获取锁；而锁的释放自动发生，保证锁一定会释放 //这里发生了一次强制解引用多态，将`counter` //解引用为`Mutex&lt;T&gt;`类型 *num += 1; }); handles.push(handle); } for handle in handles{ handle.join().unwrap(); } println!(&quot;Result: {}&quot;, counter.lock.unwrap());} Synctrait、SendtraitRust的并发模型大部分属于标准库的实现，但是 std::marker::Send和std::marker::Sync时内嵌于语言的 Send：表明类型所有权可以在线程间传递，几乎所有类型都是 Send的，Rc&lt;T&gt;是其中的一个例外，因为Rc&lt;T&gt;clone之后 在两个线程间可能同时更新引用计数，trait bound保证无法将 不安全的Rc&lt;T&gt;在线程间传递。任何全部由Send组成的类型 会自动标记为Send Sync：表明类型可以安全的在多线程中拥有其值的引用，对于 任何类型，如果&amp;T是Send的，那么T就是Sync的。 Cell&lt;T&gt;系列不是Sync的，Mutex&lt;T&gt;是。基本类型是Sync 的，全部由Sync组成的类型也是Sync的 Send和Sync是标记trait，不需要实现任何方法，全部是Send 或Sync组成的类型就是Send或Sync，一般不需要手动实现 它们，而且手动实现这些标记trait涉及编写不安全代码","link":"/Rust/grammer.html"},{"title":"Rust 标准库数据类型","text":"通用集合类型Vec&lt;T&gt;vector允许在单独数据结构中存储多于一个的值，它们在内存中相邻 排列，vector被丢弃时，其中的数据也会被丢弃 存储不同类型vector只能存储相同类型的值，因为vector必须在编译前知道所有 存储元素所需内存、允许的元素类型，否则对vector进行操作可能 会出错。但是可以使用枚举类型存储”不同类型”（Message为例） 1vec![Message::Write(String::from(&quot;ab&quot;), Message::Move{x:5, y:6}] 常用方法1234567891011121314151617181920212223let mut v:Vec&lt;i32&gt; = Vec::new();let mut v = Vec::with_capacity(3); //为vector预先分配空间，比`new`稍有效率 //但是这个为啥不用指定类型啊，这样怎么分配空间let v = vec![1, 2, 3];v.push(5)let third:&amp;i32 = &amp;v[2] //尝试获取一个引用值，如果越界则报错let third:Option&lt;&amp;i32&gt; = v.get(2) //尝试获取Option&lt;&amp;i32&gt;，越界则返回Nonelet mut v = vec![100, 32, 57]for i in &amp;mut v{ *i += 50;}let iter = v.iter(); //不可变引用迭代器let iter_mut = v.iter_mut(); //可变引用迭代器let iter_owner = v.into_iter(); //所有权引用迭代器 使用enum+match就能保证处理所有类型，不会出错 字符串通常意义上的字符串往往是以下两种的”综合“ rust核心语言中的字符串slice&amp;str：存储在别处的utf-8 编码字节序列的引用 字符串slice是&amp;str类型，这个好像体现了rust引用更像 指针，字符串字面值应该是一系列字节序列（流）存储， 所以”返回值“应该是”首地址“，因此是引用类型 rust标准库中String类型，是Vec&lt;u8&gt;的封装 可增长 可变 有所有权 utf-8编码 索引字符串因此String类型不能索引获取字符，索引操作预期是常数时间， 而utf-8字列序列并不能保证在常数时间内获取“字符”，rust需要 从头检查。另外，字符串中可能有不可见字符（如发音字符）， 即字形簇和字符串不等价，此时索引的意义也不明确。 更加有价值的是使用[]和range创建一个字符串slice需要注意的是 如果字符串slice不是有效处utf-8编码序列，程序会在运行时 panic! 12345let len = String::from(&quot;Здравствуйте&quot;).len() //`len`返回的是utf-8编码序列的长度20，不是“字符”数目12let hello = &quot;Здравствуйте&quot;;let s = &amp;hello[0..4]; 遍历字符串 返回字符Unicode值char类型123for c in &quot;नमस्ते&quot;.chars() { println!(&quot;{}&quot;, c);} 将会打印出6个字符，两个不可见的发音字符123456नमस ्त े 返回字节byte值u8类型123for b in &quot;नमस्ते&quot;.bytes() { println!(&quot;{}&quot;, b);} String常用方法12345678910111213141516171819202122232425262728let mut s = String::new();let s = String::from(&quot;initial contet&quot;);let data = &quot;initial content&quot;;let s = data.to_string();let s = &quot;initial content&quot;.to_string();let mut s = String::from(&quot;foo&quot;);s.push_str(&quot;bar&quot;);let s2 = &quot;bar&quot;;s.push_str(&amp;s2);println!(s2); //此时，`s2`仍然可以打印出来，因为`push_str`的参数是它的 //一个引用，应该是方法中对`&amp;&amp;str`类型做了处理？s.push('l');let s1 = String::from(&quot;hello, &quot;);let s2 = String::from(&quot;world&quot;;let s3 = s1 + &amp;s2; //此时`s1`所有权被转移给`s3`不能再使用let s1 = String::from(&quot;tic&quot;);let s2 = String::from(&quot;tac&quot;);let s3 = string::from(&quot;toc&quot;);//let s = s1 + &quot;-&quot; + &amp;s2 + &quot;-&quot; + &amp;s3;let s = format!(&quot;{}-{}-{}&quot;, s1, s2, s3); //`format!`宏是更好地连接字符串的方法，且不会获取任何 //参数的所有权 HashMapHashMap键、值必须是同质的，相对来说使用频率较低，没有引入 prelude，使用之前需要用use关键字引入 HashMap默认使用一种密码学安全的哈希函数，它可以抵抗拒绝 服务（Denial of Service, DoS）攻击。然而这并不是可用的最快的 算法，不过为了更高的安全性值得付出一些性能的代价。可指定不同 hasher来切换为其它函数。hasher是一个实现了BuildHasher trait的类型 常用函数12345678910111213141516171819202122232425262728293031323334353637use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(&quot;Blue&quot;), 10);scores.insert(String::from(&quot;Yellow&quot;), 30); //对于没有实现`copy`trait的`string`类型，所有权将转移给 //HashMapscores.insert(String::from(&quot;Blue&quot;, 20); //之前存储的值被覆盖scores.entry(String::from(&quot;Yellow&quot;)).or_insert(90);scores.entry(String::from(&quot;Red&quot;)).or_insert(90); //`entry`以想要检查的键作为参数，返回`Entry`类型的枚举 //代表可能存在的值，`or_insert`方法在键对应的值存在时 //返回值`Entry`（实际上时值的可变引用），否则将参数作为 //新值插入，并返回修改后的`Entry`let text = &quot;hello world wonderful word&quot;;let mut map = HashMap::new();for word in text.split_whitespace(){ let count = map.entry(word).or_insert(0); *count += 1;} //这段将在`map`中存储`text`中个单词出现次数let teams = vec![String::from(&quot;Blue&quot;), String::from(&quot;Yello&quot;)];let initial_scores = vec![10, 30];let scores: HashMap&lt;_,_&gt; = teams.iter.zip(initial_scores.iter()).collect(); //`collect`可能返回很多不同的数据结构，需要显式指定`scores` //的类型`HashMap&lt;_,_&gt;`let team_name = String::from(&quot;Blue&quot;);let team_score = scores.get(&amp;team_name);for (key, val) in &amp;scores{ println!(&quot;{}:{}&quot;, key, val);} 智能指针 指针pointer：包含内存地址的变量，这个地址引用（指向） 其他数据 智能指针smart pointer：一类数据结构，表现类似于指针， 拥有额外的元数据和功能 Rust中最常见的指针是引用reference，除了引用数据没有其他 特殊功能，也没有任何额外开销。 智能指针通常由结构体实现，区别于常规结构体的特在于实现了 Deref和Droptrait 事实上，String和Vec&lt;T&gt;也是智能指针 Dereftrait、DerefMuttrait Dereftrait：重载解不可变引用运算符* DerefMuttrait：重载解可变引用引用运算符* 允许智能指针结构体实例表现得像引用，可以让代码兼容智能指针 和引用 12345678fn main(){ let x = 5; let y = &amp;x; let z = Box::new(5); assert_eq!(5, x); assert_eq!(5, *y); assert_eq!(5, *z); 自定义类型实现Dereftrait12345678910111213141516171819202122232425262728struct MyBox&lt;T&gt;(T); //`Box&lt;T&gt;`从本质上被定义为包含一个元素的元组结构体 //类似定义自定义类型`MyBox`impl&lt;T&gt; MyBox&lt;T&gt;{ fn new(x: T) -&gt; MyBox&lt;T&gt;{ MyBox(X) }}use::std::Deref;impl&lt;T&gt; Deref for MyBox&lt;T&gt;{ type Target = T; fn deref(&amp;self) -&gt; &amp;T{ &amp;sell.0 } //`deref`返回引用，因为大部分使用解引用时不希望获取 //`MyBox`内部值的所有权}//为`MyBox&lt;T&gt;`实现`Deref`traitfn main(){ let x = 5; let y = MyBox::new(x); println!(&quot;y = {}&quot;, *y); //对于`*y`Rust实际在底层`*(y.deref())`} DerefMuttrait类似 隐式解引用强制多态Deref Coercions将实现了Dereftrait或DerefMuttrait类型的引用转换为其他 类型的引用，通过多次的隐式转换使得实参和型参类型 一致，（这些解析发生在编译时，没有运行时损失)避免多次使用 &amp;和* 引用和解引用，也使得代码更容易兼容智能指针和引用。 1234567fn hello(name: &amp;str){ println!(&quot;hello, {}&quot;, name);}fn main(){ let m = MyBox::new(String::from(&quot;Rust&quot;)); hello(&amp;m);} 实参类型T和型参类型U满足（间接） T: Deref&lt;Target = U&gt;：&amp;T转换为&amp;U T: Deref&lt;Target = U&gt;：&amp;mut T转换为&amp;U T: DerefMut&lt;Target = U&gt;：&amp;mut T转换为&amp;mut U 相当于在引用外面添加任意层&amp;(*_)、&amp;mut(*_)，直到实参类型 和型参类型一致 DroptraitDroptrait要求实现drop方法（析构函数destructor），获取 &amp;mut self可变引用，智能指针离开作用域时运行drop方法中的 代码，用于释放类似于文件或网络连接的资源，编译器会自动插入 这些代码。 Droptrait会自动清理代码 所有权系统确drop只会在值不再使用时被调用一次 todo：获取&amp;mut self，那么之前不能获取可变引用了？ 123456789101112131415struct CustomSmartPointer{ data: String,}impl Drop for CustomSmartPointer{ fn drop(&amp;mut self){ println!(&quot;Dropping CustomSmartPointer with data `{}`!&quot;, self.data); }}fn main(){ let c = CustomSmartPointer{ data: String::from(&quot;pointer1&quot;)}; let d = CustomSmartPointer{ data: String::from(&quot;pointer2&quot;)}; println!(&quot;CustomSmartPointer created!&quot;);} 输出顺序如下，变量以被创建时相反的顺序丢弃 123CustomSmartPointer created!Dropping CustomSmartPointer with data `pointer1`!Dropping CustomSmartPointer with data `pointer2`! Rust不允许显示调用drop函数，因为Rust仍然会在值离开作用域时 调用drop函数导致double free的错误。如果需要提早清理， 可以使用std::mem::drop函数（已经位于prelude中）。 123456fn man(){ let c = CustomSmartPointer{ data: String::from(&quot;some data&quot;)}; println!(&quot;CumstomSmartPointer Created&quot;); drop(c); //调用`std::mem::drop`函数，不是`c.drop()`方法 println!(&quot;CustomSmartPointer dropped before the end of main&quot;); Box&lt;T&gt;在堆上存储数据，而栈上存放指向堆数据的指针，常用于 类型编译时大小未知，而想要在确切大小的上下文中使用 大量数据希望在拷贝时不转移所有权 只关心数据是否实现某个trait而不是其具体的类型 （trait对像） 1234let b = Box::new(5);println!(&quot;b = {}&quot;, b); //可以像数据存储在栈上一样访问数据 //box离开作用域时，栈上和指向的堆上的数据都被释放 创建递归类型Rust需要在编译时知道类型占用的空间，而递归类型（recursive type）中值的一部分可以时相同类型的另一个值，所以Rust无法知道 递归类型占用的空间。而box大小已知，可以在递归类型中插入box 创建递归类型 123456789101112131415enum List{ Cons(i32, Box&lt;list&gt;), Nil, //代表递归终止条件的规范名称，表示列表的终止 //不同于`null`或`nil`}use List::{Cons, Nil};fn main(){ let list = Cons(1, Box::new(Cons(2, Box::new(Cons(3, Box::new(Nil))))));} Rc&lt;T&gt;Rc：引用计数reference counting，记录一个值引用的数量判断 这个值是否仍然被使用，如果值只有0个引用，表示没有任何有效 引用，可以被清理。 Rc&lt;T&gt;允许多个不可变引用，让值有多个所有者共享数据， 引用计数确保任何所有者存在时值有效。用于在堆上分配内存供 程序多个部分读取，且在无法在编译时确定哪部分最后结束使用 （否则令其为所以者即可） Rc&lt;T&gt;只适合单线程场景 1234567891011121314151617181920212223242526272829303132enum List{ Cons(i32, Rc&lt;List&gt;), Nil,} //使用`Rc&lt;T&gt;`代替`Box&lt;T&gt;`，可以构造共享Listuse List::{Cons, Nil};use std::rc::Rc;fn main(){ let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil))))); println!(&quot;count after creating a = {}&quot;, Rc::strong_count(&amp;a)); //1 let b = Cons::(3, Rc::clone(&amp;a)); //`Rc::clone`并不像大多数`clone`方法一样对所有数据 //进行深拷贝，只会增加引用计数，允许`a`和`b`**共享** //`Rc`中数据的所有权 //这里可以调用`a.clone()`代替`Rc::clone(&amp;a)`，但是 //习惯上使用`Rc::cloen(&amp;a)` println!(&quot;count after creating b = {}&quot;, Rc::strong_count(&amp;a)); //2 { let c = Cons::(4, Rc::clone(&amp;a)); println!(&quot;count after creating c = {}&quot;, Rc::strong_count(&amp;a)); //3 } println!(&quot;count after c goes out of scope = {}&quot;, Rc::strong_count(&amp;a)); //2} RefCell&lt;T&gt;RefCell&lt;T&gt;是一个遵守内部可变性模式的类型，允许通过 不可变引用更改T值。实际上仍然是通过可变引用更改值， 只是获得的T的可变引用在RefCell&lt;T&gt;内部。 RefCell&lt;T&gt;同样只能应用于单线程场景 可以理解为，将Rust静态引用改成时分复用引用，Rust在 运行时进时引用检查，只要保证在运行时任意时刻满足引用规则 即可。 内部可变性interior mutabilityRust中的一个设计模式，允许在有不可变引用时改变数据，这违反 了引用规则，因此在该模式中使用unsafe代码模糊Rust通常的 可变性和引用规则。但是引用规则依然适用，只是在运行时检查， 会带来一定运行时损失。 在确保代码运行时遵守借用规则，即使编译器不能保证，可以选择 使用运用内部可变性模式的类型，涉及的unsafe代码被封装进 安全的API中，外部类型依然不可变 Ref、RefMut Ref = RefCell&lt;T&gt;.borrow()：获取T的不可变引用 RefMut = RefCell&lt;T&gt;.borrow_mut()：获取T的一个可变引用 Ref和RefMut均是实现Dereftrait的智能指针，RefCell&lt;T&gt; 记录当前活动的Ref和RefMut指针，调用borrow时，不可变 引用计数加1，Ref离开作用域时不可变引用计数减1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061pub trait Messenger{ fn send(&amp;self, msg: &amp;str);}pub struct LimitTracker&lt;'a, T:'a + Messenger&gt;{ Messenger:&amp;'a T, value: usize, max : usize,} //这个结构体有`‘a`和`T`两个泛型参数，且`T`还以生命周期 //注解作为trait boundimpl&lt;'a, T&gt; LimitTracker&lt;a', T&gt; where T: Messenger{ //这里的`T`就没有加上`‘a`作为trait bound pub fn new(messenger: &amp;T, max: usize) -&gt; LimitTracker&lt;T&gt;{ LimitTracker{ messenger, value: 0, max, } } pub fn set_value(&amp;mut self, value:usize){ self.value = value; let percentage_of_max = self.max as f64 / self.max as f64; if percentage_of_max &gt;= 0.75{ self.messenger.send(&quot;Warning: over 75% of quota has been used!&quot;); } }}#[cfg(test)]mod tests{ use supper::*; use std::cell:RefCell; struct MockMessenger{ sent_messages: RefCell&lt;Vec&lt;String&gt;&gt;, } impl MockMessenger{ fn new() -&gt; MockMessenger{ MockMessenger{ sent_messages: RefCell&lt;vec![]&gt; } } } impl Messenger for MockMessenger{ fn send(&amp;self, message: &amp;str){ self.sent_messages.borrow_mut().push(String::from(message)); } } #[test] fn it_send_an_over_75_percent_warning_message(){ let mock_messenger = MockMessenger::new(); let mut limit_tracker = LimitTracker::new(&amp;mock_messenger, 100); limit_tracker.set_value(80); assert_eq!(mock_messenger.sent_messages.borrow().len(), 1); }} Rc&lt;RefCell&lt;T&gt;&gt;T值可以修改，且可以被多个所有者拥有 123456789101112131415161718192021#[derive(Debug)]enum List{ Cons(Rc&lt;RefCell&lt;i32&gt;&gt;, Rc&lt;List&gt;), Nil}use List::{Cons, Nil};use std::rc::Rc;use std::cell::RefCell;fn main(){ let value = Rc::new(RefCell::new(5)); let a = Rc::new(Cons(Rc::clone(&amp;value), Rc::new(Nil))); let b = Cons(Rc::new(RefCell::new(6)), Rc::clone(&amp;a)); let c = Cons(Rc::new(RefCell::new(10)), Rc::clone(&amp;a)); *value.borrow_value += 10; println!(&quot;a after = {:?}&quot;, a); println!(&quot;b after = {:?}&quot;, b); println!(&quot;c after = {:?}&quot;, c);} RefCell&lt;Rc&lt;T&gt;&gt;T值不能改变，但是Rc&lt;T&gt;整体可以改变，此时可能出现引用循环 ，导致内存泄露。引用循环是程序逻辑上的bug，Rust无法捕获。 12345678910111213141516171819202122232425262728293031323334353637383940use List::{Cons, Nil};use std::rc::Rc;use std::cell::RefCell;enum List{ Cons(i32, RefCell&lt;Rc&lt;list&gt;&gt;), Nil,}impl List{ fn tail(&amp;self) -&gt; Option&lt;&amp;RefCell&lt;R&lt;List&gt;&gt;&gt;{ match *self{ Cons(_, ref item) =&gt; Some(item), Nil =&gt; None, } }}fn main(){ let a = Rc::new(Cons(5, RefCell::new(Rc::New(Nil)))); println!(&quot;a initial rc count ={}&quot;, Rc::strong_count(&amp;a)); //1 println!(&quot;a next item = {:?}&quot;, a.tail()); let b = Rc::new(Cons(10, RefCell::new(Rc::clone(&amp;a)))); println!(&quot;a rc count after b creating = {}&quot;, Rc::strong_count(&amp;a)); //2 println!(&quot;b initial rc count = {}&quot;, Rc::strong_count(&amp;b)); //1 println!(&quot;b next item = {:?}&quot;&lt;, b.tail()); if let Some(link) = a.tail(){ *link.borrow_mut() = Rc::clone(&amp;b); //此时`a`、`b`循环引用，离开作用域时，两个值的 //引用计数因为`a`、`b`被丢弃而减1，但是它们互相 //引用，引用计数保持在1，在堆上不会被丢弃 } println!(&quot;b rc count after changing a = {}&quot;, Rc::strong_count(&amp;b)); //2 println!(&quot;a rc count after changing a = {}&quot;, Rc::strong_count(&amp;a)); //2} Weak&lt;T&gt;强引用Rc&lt;T&gt;代表共享Rc实例的引用，代表所有权关系， 而弱引用Weak&lt;T&gt;不代表所有权关系，不同于Rc&lt;T&gt;使用 strong_count计数，Weak&lt;T&gt;使用weak_count计数，即使 weak_count无需为0，Rc实例也会被清理（只要strong_count 为0） Weak&lt;T&gt;指向的值可能已丢弃，不能像Rc&lt;T&gt;一样直接解引用 ，需要调用upgrade方法返回Option&lt;Rc&lt;T&gt;&gt; Weak&lt;T&gt;避免Rc&lt;T&gt;可能导致的引用循环 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859use std::rc::{Rc, Weak};use std::cell::RefCell;#[derive(Debug)]struct Node{ value: i32, parent: RefCell&lt;Weak&lt;Node&gt;&gt;, Children: RefCell&lt;Vec&lt;Rc&lt;Node&gt;&gt;&gt;,}fn main(){ let leaf = Rc::new(Node{ value: 3, parent: RefCell::new(Weak::new()), children: RefCell::new(vec![]), }); println!( &quot;leaf strong = {}, weak = {}&quot;, Rc::strong_count(&amp;leaf), Rc::weak_count(&amp;leaf), ); //strong = 1, weak = 0 { let branch = Rc::new(Node{ value: 5, parent: RefCell::new(Weak::new()), children: RefCell::new(vec![Rc::clone(&amp;leaf)), }); *leaf.parent.borrow_mut() = Rc::downgrade(&amp;branch); //`downgrade`返回`Weak&lt;T&gt;` println!( &quot;branch strong = {}, weak = {}&quot;, Rc::strong_count(&amp;branch), Rc::weak_count(&amp;branch), ); //strong = 1, weak = 1 println!( &quot;leaf strong = {}, weak = {}&quot;, Rc::strong_count(&amp;leaf), Rc::weak_count(&amp;leaf), ); //strong = 2, weak = 0 } println!(&quot;leaf parent = {:?}&quot;, leaf.parent.borrow().upgrade()); //`upgrade`返回`Option&lt;Rc&lt;T&gt;&gt;`，此例中因为`branch` //离开作用域已经丢弃，这里返回`None` println!( &quot;leaf strong = {}, weak = {}&quot;, Rc::strong_count(&amp;leaf), Rc::weak_count(&amp;leaf), ); //strong = 1, weak = 0 //如此不会造成引用循环导致内存泄露} 比较 智能指针 数据拥有者 引用检查 多线程 Box&lt;T&gt; 单一所有者 编译时执行可变（不可变）引用检查 是 Rc&lt;T&gt; 多个所有者 编译时执行不可变引用检查 否 RefCell&lt;T&gt; 单一所有者 运行时执行不可变（可变）引用检查 否 Weak&lt;T&gt; 不拥有数据 编译时执行可变（不可变）检查 否 常用枚举类型1234567891011121314Option&lt;T&gt;{ Some&lt;T&gt;, None,}some = Some(9);some.take(); //`take`获取`some`的值所有权作为返回值，并设置`some`为 //`None`Result&lt;T, U&gt;{ Ok&lt;T&gt;, Err&lt;U&gt;,}","link":"/Rust/std_var_types.html"},{"title":"Rust 自定义数据类型","text":"结构体structrust不允许只将特定字段标记为可变（很正常，因为结构体应当 作为一个整体考虑） 定义结构体时字段不能添加mut 声明结构体时，语法上也难以做到，字段不是单独声明 结构体中若有字段是引用类型，需要添加生命周期 普通结构体1234567891011121314151617struct stct{ field1: i32, field2: String,}let field1 = 1;let stct={ field1, field2: String::from(&quot;fy&quot;),}//变量字段同名时字段初始化简略写法let struct1 = stct{ field1: 1, ..struct2}//结构体更新语法 元组结构体结构体名称提供的含义，但只有字段类型没有字段名，用于命名 元组、指定类型，区别于其他相同（结构）的元组 1struct tuple_stct=(i32, i32, i32) 类单元结构体unit-like struct不定义任何字段，类似于()（()一般用于泛型中占位，表示 当前类型为空，比如T表示返回值泛型参数，无返回值就可以使用 ()代替，因为Rust中类似于typedef用于自定义类型），常用于 在某个类型上实现trait，但不需要在 类型内存储数据时发挥作用 枚举enumrust枚举更像C语言中enum+struct enum：定义了新的枚举类型，取值范围有限 struct：枚举成员可以关联数据类型，且可以定义方法 枚举类型12345678910111213141516171819enum IpArr{ V4, V6,} //基础版本enum IpArr{ V4(u8, u8, u8, u8}, V6(String),} //附加数据版本enum Message{ Quit, Move{x: i32, y:i32}, Write(String), ChangeColor(i32, i32, i32),} //含有匿名结构体版本 标准库中的枚举处理null值1234enum Option&lt;T&gt;{ Some&lt;T&gt;, None,} Option被包含在prelude中，包括其成员，rust标准库中唯一 支持创建任何类型枚举值的枚举类型。rust不允许像有效的T类型 数据一样处理Option&lt;T&gt;类型数据，要求在使用之前处理为None 的情况，此即能够保证在可能为空的值会被处理 处理潜在panic1234enum Result&lt;T, E&gt;{ Ok&lt;T&gt;, Err&lt;E&gt;,} 方法、关联函数1234567891011121314impl Message{ fn new() -&gt; Message{ } //关联函数associated functions，没有`self`作为参数 fn fn1(&amp;self) -&gt; ret_type{ } //在结构体（枚举、trait对像）的上下文中定义 //第一个参数总是`self`，代表调用方法的结构体实例 fn fn2(mut self) -&gt; ret_type{ }} 方法 Methods 定义方法的好处主要在于组织性，将某类型实例能做的事均放入 impl块 方法签名中self会由rust根据impl关键字后的“替换”为 相应类型（运行过程中是当前实例） 方法可以获取self（当前实例）所有权，常用于将self转换 为其他实例，防止调用者转换之后仍使用原始实例 方法是rust中少数几个可以“自动引用和解引用”的地方，因为 方法中self类型是明确的（调用者类型也明确），rust可以 根据方法签名自动为对象添加&amp;、&amp;mut或*以适应方法签名， 所以rust调用方法只有.，没有-&gt; 关联函数 Associated Functions与结构体相关联，不作用于一个结构体实例，常被用于返回一个 结构体新实例的构造函数 Trait将方法（关联函数）签名（可以有默认实现）组合起来、定义实现 某些目的所必需的行为的集合 12345678910111213141516171819202122pub trait Summarizable{ // 无默认实现 fn author_summary() -&gt; String; // 有默认实现 fn summary(&amp;self) -&gt; String{ String::from(&quot;Read more...{}&quot;, self.author_summary()) }}//定义traitimpl Summarizable for Message{ fn author_summary(&amp;self){ } fn summary(&amp;self) -&gt; String{ }}//为类型实现trait，之后就可以和普通非trait方法一样调用 默认实现 trait中有默认实现的方法可以不重载，实现trait就可直接 调用，没有默认实现的方法则需要全部实现 默认实现重载之后不可能被调用 默认实现可以调用同trait中的其他方法，包括没有默认 实现的方法，如此trait可以实现很多功能而只需要实现少部分 同trait：trait之间本就应该保持独立，这个是trait的 意义 因为实现trait一定要实现所有没有默认实现的方法，所以 默认实现总是“可以调用” 孤儿规则 Orphan Ruleorphan rule：父类型不存在 仅trait或类型位于（之一）本地crate才能实现trait， 如果没有此限制，可能出现两个crate同时对相同类型实现同一trait ，出现冲突 Box&lt;trait&gt; Trait对像trait对像指向一个实现了指定trait的类型实例，Rust类型系统在 编译时会确保，任何在此上下文中使用的值会实现其trait对像的 trait，如此无需在编译时知晓所有可能类型。 Trait对象、泛型Trait Bound对比 trait对像在运行时替代多种具体类型 编译时都是同质的Box&lt;trait&gt;类型 只关心值反映的信息而不是其具体类型，类似于动态语言中 鸭子类型 编译器无法知晓所有可能用于trait对象的类型，因此也 不知道应该调用哪个类型的哪个方法，因此Rust必须使用 动态分发 123456789101112131415161718192021222324pub trait Draw{ fn draw(&amp;self);}pub struct Screen{ pub components: Vec&lt;Box&lt;Draw&gt;&gt;, //`Box&lt;Draw&gt;`就是trait对像，可以代替任何实现了 //`Draw`trait的值}impl Screen{ pub fn run(&amp;self){ for component in self.components.iter(){ component.draw(); } }}pub struct Button{ pub width: u32, pub height: u32, pub label: String,}impl Draw for Button{ fn Draw{ }} 123456789101112131415161718192021222324252627282930313233343536// 外部crate使用时extern crate rust::gui;use rust_gui::{Screen, Button, Draw};struct SelectBox{ width: u32, height: u32, options: Vec&lt;String&gt;,} //此类型对于`Screen`是未知的，但是`components`中仍然能够 //包含此类型impl Draw for SelectBox{ fn draw(&amp;self){ }}fn main(){ let screen = Screen{ components: vec![ Box::new(SelectBox{ width: 75, height: 10, option: vec![ String::from(&quot;yes&quot;), String::from(&quot;maybe&quot;), ], }), Box::new(Button{ width: 50, height: 10, label: String::from(&quot;OK&quot;), }), ], }; screen.run();} trait bound泛型类型参数结构体在编译时单态化 一次只能替代一个具体类型，多个类型之间不同质 单态化产生的代码进行静态分发 12345678910111213pub struct Screen&lt;T: Draw&gt;{ pub components: Vec&lt;T&gt;, //trait bound泛型参数`T`只能替代一种类型 //不同的实现`Draw`trait类型不能放在同一个vector中}impl&lt;T&gt; Screen&lt;T&gt; where T: Draw{ pub fn run(&amp;self){ for component in self.components.iter(){ component.draw(); } }} 鸭子类型：如果它走起来像一只鸭子，叫起来像一只鸭子，那么 它就是一直鸭子 静态分发：编译器知晓调用何种方法 动态分发：编译器在编译时不知晓调用何种方法，生成在运行时 确定调用某种方法的代码。动态分发阻止编译器有选择的内联 方法代码，这会禁用部分优化，但获得了额外的灵活性 对象安全trait对象要求对象安全，只有对象安全的trait才能组成trait 对象，这有一些复杂的规则，但是实践中只涉及 返回值类型不为Self：如果trait中的方法返回Self类型， 而使用trait对象后就不再知晓具体的类型，那方法就不可能 使用已经忘却的原始具体类型（Clonetrait不是对象安全） 方法没有任何泛型类型参数：具体类型实现trait时会放入具体 类型单态化，但是使用trait对象时无法得知具体类型 状态模式（面向对象设计） 值某些内部状态，其行为随着内部状态而改变 内部状态由一系列集成了共享功能的对象表现，每个状态对象 负责自身行为和需要转变为另一个状态时的规则 值对不同状态的行为、何时状态转移不知情，需求改变时无需 改变值持有的状态、值实现代码，只需更新某个状态对象代码 或者是增加更多状态对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687pub struct Post{ state: Option&lt;Box&lt;State&gt;&gt;, content: String,}impl Post{ pub fn add_text(&amp;mut self, text: &amp;str){ self.content.push_str(&amp;str); } pub fn request_review(&amp;mut self){ if let Some(s) = self.state.take(){ //`Option&lt;T&gt;.take()`返回值，并设置为`None` self.state = Some(s.request_review()) } } pub fn approve(&amp;mut self){ if let Some(s) = self.state.take(){ self.state = Some(s.approve()) } } pub fn content(&amp;self) -&gt; &amp;str{ self.state.as_ref().unwrap().content(&amp;self) //`Option&lt;T&gt;.as_ref()`返回`Option&lt;&amp;T&gt;`，因为参数 //是`&amp;self`，只能获取不可变引用 }}trait State{ fn request_review(self: Box&lt;Self&gt;) -&gt; Box&lt;State&gt;; //`self: Box&lt;Self&gt;`意味着这个方法调用只对`Self` //类型的`Box`指针有效，这里`Self`表示值类型，因为 //值的类型到struct实现trait的时候才能确定，编译时 //应该会替换成具体类型 //这个方法会获取对象的所有权（消费） //返回值`Box&lt;State&gt;`是trait对象 fn approve(self: Box&lt;Self&gt;) -&gt; Box&lt;State&gt;; fn content&lt;'a&gt;(&amp;self, post:&amp;'a Post) -&gt; &amp;'a str{ &quot;&quot; }}struct Draft{}impl State for Draft{ fn request_review(self: Box&lt;Self&gt;) -&gt; Box&lt;State&gt;{ Box::new(PendingReview{}) } fn approve(self: Box&lt;Self&gt;) -&gt; Box&lt;State&gt;{ self }}struct PendingReview{}impl State for PendingReview{ fn request_review(self: Box&lt;Self&gt;) -&gt; Box&lt;State&gt;{ self } fn approve(self: Box&lt;Self&gt;) -&gt; Box&lt;State&gt;{ Box::new(Published{}) }}struct Published{}impl State for Published{ fn request_review(self: Box&lt;Self&gt;) -&gt; Box&lt;State&gt;{ self } fn approve(self: Box&lt;Self&gt;) -&gt; Box&lt;State&gt;{ self } fn content&lt;'a&gt;(&amp;self , post:&amp;'a Post) -&gt; &amp;'a str{ &amp;post.content }} 高级traitAssociated Type关联类型：将类型占位符和trait相关联的方式 可在trait方法中使用这些占位符类型 实现trait时需要指定为具体类型 123456pub trait Iterator{ type Item; //关联类型`Item`，实现时需要指定具体类型 fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;; //trait方法（签名）中使用关联类型} 关联类型可以看作时trait中“泛型”（弱化版）。只能实现一次 trait，因此关联类型也只能指定一次，保证了一定的抽象 默认泛型类型参数使用泛型类型参数时，可为泛型指定默认类型 &lt;PlaceholderType = ConcreteType&gt; 扩展类型而不破坏现有代码（普通trait改为泛型trait不需要 改变之前实现trait的代码） 在特殊情况下自定义trait及其中的方法 1234567891011121314151617181920212223242526272829use std::ops::Add;#[derive(Debug, PartialEq)]struct Point{ x: i32, y: i32,}impl Add for Point{ //`Add`是`+`运算符对应的trait //`Add`有默认类型参数，此时未指定泛型参数的具体类型， //`RHS`将是默认类型 type Output = Point; fn add(self, other: Point) -&gt; Point{ Point{ x: self.x + other.x, y: self.x + other.y, } }}trait Add&lt;RHS=Self&gt;{ //`Add`trait定义，包含有泛型参数，但是在实现该trait之前 //应该必须要为泛型指定具体类型 //`RHS=Self`就是*默认类型参数*语法，泛型参数`RHS`默认为 //`Self`类型（`+`左值类型） //RHS：right hand side type Output; fn add(self, rhs: RHS) -&gt; Self:Output;} 运算符重载Rust不允许创建自定义运算符、重载任意运算符，不过 std::ops中的运算符、相应的trait可以通过实现相关trait重载 123456789101112131415use std::ops::Add;#[derive(Debug, PartialEq)]struct Millimeters(u32);struct Meters(u32);impl Add&lt;Meters&gt; for Millimeters{ //`Add`trait中`RHS`不是默认类型`Self`，`Add&lt;Meters&gt;` //设置`RHS`为`Meters` //此运算符重载允许`Millmeters`类型和`Meters`类型能够 //直接相加 type Output = Millimeters; fn add(self, other: Meters) -&gt; Millimeters{ Millimters(self.0 + (other.0 * 1000)) }} 消歧义Rust无法避免两个trait具有相同名称的方法，也无法阻止某类型 同时实现两个这样的trait（或者是类型已经实现同名方法），此时 需要明确指定使用哪个方法 12345678910111213141516171819202122232425262728293031323334trait Pilot{ fn fly(&amp;self);}trait Wizard{ fn fly(&amp;self);}struct Human;impl Pilot for Human{ fn fly(&amp;self){ println!(&quot;this is your captain speaking&quot;); }}impl Wizard for Human{ fn fly(&amp;self){ println!(&quot;up!&quot;); }}impl Human{ fn fly(&amp;self){ println!(&quot;waving arms furiously!&quot;); }}fn main(){ let person = Human; Pilot::fly(&amp;person); //`Pilot`trait中方法的消歧义写法 Wizard::fly(&amp;person); person.fly(); //默认调用直接实现在**类型**上的方法 Person::fly(&amp;person); //`Person`类型中方法消歧义写法，一般不使用} Fully Qualified Syntax方法获取self参数 不同类型、同方法名，Rust根据self类型可以判断调用何函数 同类型、同方法名，消歧义语法可以指定调用何函数 而对于关联函数，没有self参数，某类型有同名的两个关联函数 时，无法使用消歧义语法指定调用何函数，需要使用完全限定语法 &lt;Type as Trait&gt;::function(receiver_if_method), next_args, ...) 当然，完全限定语法可以用于所有trait方法、关联函数场合，其中 recevier_if_method即表示方法中self参数 1234567891011121314151617181920trati Animal{ fn baby_name() -&gt; String;}struct Dog;impl Dog{ fn baby_name() -&gt; String{ String::from(&quot;Spot&quot;) }}impl Animal for Dog{ fn baby_name() -&gt; String{ String::from(&quot;puppy&quot;) }}fn main(){ println!(&quot;A baby dog is called a {}&quot;, Dog::baby_name()); //调用`Dog`的关联函数 println!(&quot;A baby dog-animal is called a {}&quot;, &lt;Dog as Animal&gt;::baby_name()); //完全限定语法} Super Trait有时某个trait可能需要使用另一个trait的功能，要求某类型实现 该trait之前实现被依赖的trait，此所需的trait就是超（父）trait 12345678910111213141516171819202122trait OutlinePrint: fmt::Display{ //`OutlinePrint`trait依赖于`fmt::Display`trait //在实现`OutlinePrint`之前，需要实现`fmt::Display` fn outline_print(&amp;self){ let output = self.to_string(); let len = output.len(); println!(&quot;{}&quot;, &quot;*&quot;.repeat(len + 4)); println!(&quot;* {} *&quot;, output); println!(&quot;{}&quot;, &quot;*&quot;.repeat(len+4)); }}struct Point{ x: i32, y: i32,}impl fmt::Display for Point{ fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result{ write!(f, &quot;({}, {})&quot;, self,x, self.y) }}impl OutlinePrint for Point{} //`OutlinePrint`中所有方法均有默认实现 高级类型Newtype Pattern孤儿规则限制了只有trait、类型其中只有位于当前crate时，才能对 类型实现trait，使用newtype模式可以“绕过”该限制，即创建新的 元组结构体类型，其中只包含该类型一个成员，此时封装类型对于 crate是本地的。newtype概念源自于Haskell，此模式没有运行时 性能损失，封装类型在编译器时已经省略了 1234567891011use std::fmt;struct Wrapper(Vec&lt;String&gt;);impl fmt::Display for Wrapper{ fn fmt(&amp;self, f: &amp;mut fmt:Formatter) -&gt; fmt:Result{ write!(f, &quot;[{}]&quot;, self.0.join(&quot;,&quot;)) }}fn main(){ let w = Wrapper(vec![String::from(&quot;hello&quot;), String::from(&quot;world&quot;)]); prinlnt!(&quot;w = {}&quot;, w);} 但是Newtype模式中Wrapper是一个新类型，其上没有定义方法， 需要手动实现self.0的所有方法。或者，为Wrapper实现 Dereftrait，并返回self.0，但是此方式下Wrapper会具有 所有self.0的所有方法，如果需要限制封装类型行为，只能自行 实现所需的方法。 Type创建类型别名type关键字可以给予现有类型别名 type不是创建新、单独类型，而是创建别名，而newtype模式 则是真正创建了新类型，也因此无法像newtype模式一样进行 类型检查 1234567type Kilometers = i32; //`type`不是创建新、单独的类型，而是赋予别名，两个类型 //将得到相同的对待let x: i32 = 5;let y: Kilometers = 10;println!(&quot;x + y = {}&quot;, x + y); //`Kilometers`类型和`i32`类型完全相同，直接进行运算 类型别名主要用途是避免重复 123456type Thunk = Box::&lt;Fn() + Send + `static&gt;;let f: Thunk = Box::new(|| println!(&quot;hi&quot;));fn takes_long_type(f: Thunk){}fn returns_long_type() -&gt; Thunk{} Never TypeRust中有一个特殊的类型!，被称为empty type（never type) !的正式说法：never type可以强转为其他任何类型 无法被创建 用于发散函数（diverging functions，从不返回的函数）的 返回值todo 这个和无返回值函数有何区别 123456789101112131415161718192021222324let guess: u32 = metch guess.trim().parse(){ Ok(num) =&gt; num, Err(_) =&gt; continue, //`continue`的值即为`!`，`match`分支的返回值必须相同 //而`!`没有值，因此确定`match`的返回值类型为`u32`};impl&lt;T&gt; Option&lt;T&gt;{ pub fn unwrap(self) -&gt; T{ // `Option::unwrap`定义 match self{ Some(val) =&gt; val, None =&gt; panic!(&quot;called `Option::unwrap()` on a `None` value&quot;), // `panic!`是`!`类型，不返回值而是终止程序 } }}println!(&quot;forever&quot;);loop{ // 循环永不结束，表达式值是`!` // 如果加上`break`就不再如此 println!(&quot;for ever&quot;);} Dynamically Sized Types动态大小类型：“DST”或者“uniszed type”，这些类型允许处理 在运行时才知道大小的类型。Rust需要知道特定类型值需要分配的 内存空间，同类型的值必须使用相同数量的内存，因此必须 将动态大小类型的值至于某种指针之后（此即动态大小类型的 黄金规则），并且使用某些额外的元信息存储动态信息的大小。 str就是动态大小类型，&amp;str则是两个值：str的地址和长度， 这样&amp;str就有了一个在编译时可以知道的大小，并且str可以和 所有类型的指针结合Box&lt;str&gt;或Rc&lt;str&gt;。同样的，trait也是 动态大小类型，为了使用trait对象，必须将将其放入指针之后。 Sized traitRust自动为编译器在编译时就知道大小的类型实现Sized trait， 且Rust隐式的为每个泛型增加了Sized bound 123456789101112fn generic&lt;T&gt;(t: T){}fn generic&lt;T: Sized&gt;(t: T){ //实际上按照此函数头处理 //即默认情况下，泛型参数不能是DST}fn generic&lt;T: ?Sized&gt;(t: &amp;T){ //`?Sized`是特殊的语法，只能用于`Sized` trait不能用于 //其他trait，表示泛型`T`可能不是`Sized`的，此时参数类型 //不能是`T`，必须是指针类型的} 泛型（generic）12345678910111213141516171819202122fn largest&lt;T&gt;(list: &amp;[T]) -&gt; T {}//函数签名中泛型struct Point&lt;T&gt;{ x: T, y: T,}struct Point&lt;T, U&gt;{ x: T, y: U,}//结构体定义中泛型enum Option&lt;T&gt;{ Some(T), None,}enum Result&lt;T, E&gt;{ Ok(T), Err(E),}//枚举定义中泛型 方法实现中泛型 impl后声明泛型impl&lt;T&gt;表示Point&lt;T&gt;中的T是泛型而 不是具体类型，是对所有的泛型结构体实现 1234impl&lt;T&gt; Point&lt;T&gt;{ fn x(&amp;self) -&gt; &amp;T{ }} impl后不声明泛型，则表示Point&lt;T&gt;中T为具体类型， 此时仅对Point&lt;T&gt;类型实现方法 12345impl Point&lt;f32&gt;{ fn x(&amp;self) -&gt; f32{ }}//仅`Point&lt;f32&gt;`实现此方法，其他`T`类型没有 结构体定义中的泛型和方法签名中泛型不一定一致 12345678impl&lt;T, U&gt; Point&lt;T, U&gt;{ fn mixup&lt;V,W&gt;(self, other:Point&lt;V,W&gt;) -&gt; Point&lt;T,W&gt;{ Point{ x: self.x, y: other.y, } }} trait实现中的泛型12345impl&lt;T:Display&gt; ToString for T{}// 这个时标准库中的一个例子，使用了trait bounds// 不使用trait bounds，那感觉有些恐怖。。。 trait定义中的没有泛型，但是其中可以包含泛型方法，同普通 函数 泛型代码的性能rust在编译时将代码单态化（monomorphization）保证效率，所以 rust使用泛型代码相比具体类型没有任何性能损失 单态化：将泛型代码转变为实际放入的具体类型 12345678910111213let integer = Some(5);let float = Some(5.0);//单态化enum Option_i32{ Some(i32), None,}enum Option_f64{ Some(f64), None,}let integer = Option_i32::Some(5);let float = Option_f64::Some(5.0); Trait Bounds指定泛型的trait bounds：限制泛型不再适合任何类型，编译器 确保其被限制为实现特定trait的类型 指定函数泛型trait bounds限制参数类型 1234567891011pub fn notify&lt;T: Summarizable&gt;(item:T){}// 一个trait boundpub fn some_fn&lt;T: Display+Clone, U: Debug+Clone&gt;(t:T, u:U) -&gt; 32{}// 多个trait boundspub fn some_fn&lt;T, U&gt;(t:T, u:U) -&gt; 32 where T:Display + Clone, U: Debug + Clone{}// where从句写法 指定方法泛型trait bounds有条件的为某些类型实现 1234impl&lt;T: Display+PartialOrd&gt; Point&lt;T&gt;{ fn cmp_display(&amp;self){ }} trait和泛型的比较trait和泛型都是抽象方法 trait从方法角度抽象 定义一组公共“行为” “标记（trait bounds）”特定类型（泛型） 泛型从类型的角度抽象 为一组（trait bounds）类型定义“项”struct、enum 为一组（trait bounds）类型实现函数、trait trait的定义中不应该出现泛型 trait本意应该是定义一组“行为”，需要特定类型实现其方法 （当然有的方法有默认实现），其对应的“对象”不是类型而 是方法，与泛型用途无关 trait中定义泛型无意义，trait只是一个“包裹”，真正实现 的是其中的方法，如有必要，定义含有泛型参数的方法即可 若trait中可以使用泛型，则有可能对不同的泛型具体 类型实现“相同”（函数签名没有泛型参数）函数 （在trait中有关联类型提供略弱与泛型的功能）","link":"/Rust/struct_enum.html"},{"title":"Linux System Call","text":"Kernel内核：提供硬件抽象层、磁盘及文件系统控制、多任务等功能的系统 软件 内核是操作系统的核心、基础，决定系统的性能、稳定性 内核单独不是完整的操作系统 内核为应用程序提供对硬件访问 应用程序对硬件访受限 内核决定程序何时、对何种硬件操作多长时间 内核提供硬件抽象的方法隐藏对硬件操作的复杂 为应用程序和硬件提供简洁、统一的接口 简化程序设计 内核功能 进程管理：实现了多个进程在CPU上的抽象 负责创建、销毁进程，处理它们和外部输入、输出 处理进程之间通讯 信号 管道 通讯原语 调度器控制进程如何共享CPU 内存管理：内存是主要资源，对其管理策略对性能影响非常重要 为所有进程在有限资源上建立虚拟寻址空间 内核不同部分与内存管理子系统通过函数调用交互，实现 malloc、free等功能 文件管理：Linux很大程度上基于文件系统概念，几乎任何东西 都可以视为是文件 在非结构化硬件上建立了结构化文件系统 支持多个文件系统，即物理介质上的不同数据组织方式 驱动管理 除CPU、内存和极少的硬件实体外，基本设备控制操作都由 特定的、需寻址的设备相关代码（设备驱动）进行 内核中必须嵌入系统中出现每个外设驱动 网络管理 网络必须由系统管理 大部分网络操作不是特定于某个进程：进入系统的报文 是异步事件 系统在进程接手报文前收集、识别、分发，在程序和 网络接口间递送数据报文，根据程序的网络活动控制 程序执行 路由、地址解析也在内核中实现 System Call系统调用：操作系统提供的实现系统功能的子程序、访问硬件资源 的唯一入口 系统调用是用户空间进程访问内核、硬件设备的唯一手段 用户空间进程不能直接访问内核、调用内核函数 对计算机硬件资源的必须经过操作系统控制 计算机系统硬件资源有限，多个进程都需要访问资源 系统调用与硬件体系结构紧密相关 在用户空间进程和硬件设备之间添加中间层，是二者沟通的 桥梁 是设备驱动程序中定义的函数最终被调用的一种方式 系统调用意义 用户程序通过系统调用使用硬件，简化开发、移植性 分离了用户程序和内核的开发 用户程序忽略API具体实现，仅借助其开发应用 内核忽略API被调用，只需关心系统调用API实现 为用户空间提供了统一硬件抽象接口，用户程序可以方便在 具有相同系统调用不同平台之间迁移 系统调用保证了系统稳定和安全 内核可以基于权限和其他规则对需要进行的访问进行 裁决 避免程序不正确的使用硬件设备、窃取其他进程资源、 危害系统安全 保证进程可以正常运行在虚拟寻址空间中 程序可以随意访问硬件、内核而对此没有足够了解， 则难以实现多任务、虚拟内存 无法实现良好的稳定性、安全性 通知内核 大部分情况下，程序通过API而不是直接调用系统调用 POSIX标准是Unix世界最流行的API接口规范，其中API和系统 调用之间有直接关系，但也不是一一对应 系统调用表系统调用表sys_call_table：其中元素是系统调用服务例程的 起始地址 12345// arch/x86/entry/syscall_64.casmlinkage const sys_call_ptr sys_call_table[__NR_syscall_max+1] ={ [0 ... __NR_syscall_max] = &amp;sys_ni_syscall,#include &lt;asm/syscalls_64.h&gt;}; ...是GCCDesignated Initializers插件功能，此插件允许 无序初始化元素值 sys_call_table是长为__NR_syscall_max+1的数组 __NR_syscall_max是给定系统架构所允许的最大系统调用 数目 12// include/generated/asm-offsets.h#define __NR_syscall_max 547 此数值必然和arch/x86/entry/syscalls/syscall_64.tbl 中最大系统调用数值相同 sys_call_ptr是指向系统调用表指针类型 1typedef void (*sys_call_ptr_t)(void); sys_ni_syscall是返回错误的函数 123asmlinkage long sys_ni_syscall(void){ return -ENOSYS;} 未在&lt;asm/syscalls_64.h&gt;定义系统调用号将会对应此 响应函数，返回ENOSYS专属错误 &lt;asm/syscalls_64.h&gt;由脚本 arch/x86/entry/syscalls/syscalltbl.sh从 arch/x86/entry/syscalls/syscall_64.tbl中生成 1234567// &lt;asm/syscalls_64.h&gt;__SYS_COMMON(0, sys_read, sys_read)__SYS_COMMON(0, sys_write, sys_write)// &lt;arch/x86/entry/syscall_64.c&gt;#define __SYSCALL_COMMON(nr, sym, compat) __SYSCALL_64(nr, sym, compat)#define __SYSCALL_64(nr, sym, compat) [nr] = sym 系统调用号1234567/* fs/xattr.c */#define __NR_setxattr 5__SYSCALL(__NR_setxattr, sys_setxattr)#define __NR_lsetxattr 6__SYSYCALL(__NR_lsetxattr, sys_lsetattr)#define __NR_fsetxattr 7__SYSYCALL(__NR_fsetxattr, sys_fsetattr) 系统调用号_NR_XXX：系统调用唯一标识 系统调用号一旦分配不能有任何变更，否则编译好的程序会崩溃 系统调用号定义在include/asm/unisted.h中 用户空间进程通过系统调用号指明需要执行的系统调用 系统调用号就是系统调用在sys_call_table中的偏移 根据系统调用号在sys_call_table中找到对应表项内容， 即可找到系统调用响应函数sys_NAME的入口地址 所有系统调用陷入内核的方式相同，所以必须把系统调用号一并 传给内核 X86机器上，系统调用号通过eax寄存器传递给内核 陷入内核态，用户空间进程已经把系统调用对应系统 调用号放入eax中 系统调用一旦运行，就可以从eax中得到数据 陷入指令 系统调用通过陷入指令进入内核态 然后内核根据存储在寄存器中的系统调用号在系统调用表 中找到相应例程函数的入口地址 根据入口地址调用例程函数 陷入指令是特殊指令，且依赖于机器架构，在X86机器中指令为 int 0x80 不应直接使用陷入指令 应实现系统调用库函数，以系统调用号为参数，执行陷入 指令陷入内核态，并执行系统调用例程函数，即 __syscall[N]系列宏 __syscall[N]_syscall[N]：方便用户程序访问系统调用的一系列宏 123456// linux/include/asm/unistd.h__syscall0(type, name)__syscall1(type, name, type1, args1)__syscall2(type, name, type1, arg1, type2, arg2)// 0-6共7个宏__syscall6(type, name, type1, arg1, type2, arg2, type3, arg3, type4, arg4, type5, arg5, type6, arg6) 12345678910#define _syscall2(type, name, type1, arg1, type2, arg2) \\type name(type1, arg1, type2, arg2) \\{ \\long _res; \\__asm__ volatile (&quot;int $0x80&quot; \\: &quot;=a&quot; (_res) \\: &quot;0&quot; (__NR##name), &quot;b&quot; ((long)(arg1)), &quot;c&quot; ((long)(arg2))); \\// some code__syscall_return(type, __res)} 7个宏分别可以适用于参数个数为0-6的系统调用 （超过6个参数的系统调用罕见） __syscall[N]宏根据系统调用名创建name同名函数，通过 该函数即可访问系统调用 大部分情况下用户程序都是通过库函数访问系统调用，调用 __syscall[N]系列宏通常由库函数完成 Linux2.6.19内核之后弃用 syscallsyscall：通过系统调用号相应参数访问系统调用 1234567891011int syscall(int number, ...);#include &lt;unistd.h&gt;#include &lt;sys/syscall.h&gt;#include &lt;sys/types.h&gt;int main(int argc, char *argv){ pid_t tid; // `SYS_[NAME]`是系统调用号常量 tid = syscall(SYS_getpid);} System Call Service Routine系统调用服务例程/响应函数：系统调用的实际处理逻辑 一般以sys_开头，后跟系统调用名 fork()的响应函数是sys_fork() exit()的响应函数是sys_exit() 系统调用可以看作是系统调用服务例程在内核中注册的 名，内核通过系统调用名寻找对应服务例程 1234// arch/x86/entry/syscalls/syscall_64.tbl0 common read sys_read1 common write sys_write2 common open sys_open 参数传递参数传递 除系统调用号外参数输入同样存放在寄存器中 X86机器上，ebx、ecx、edx、esi、edi按照顺序 存放前5个参数 需要6个以上参数情况不多，此时应该用单独的寄存器存放 指向所有参数在用户空间地址的指针 参数验证 系统调用需要检查参数是否合法有效、正确 文件IO相关系统调用需要检查文件描述符是否有效 进程相关函数需要检查PID是否有效 用户指针检查，内核必须保证 指针指向的内存区域属于用户空间：不能哄骗内核读取 内核空间数据 指针指向的内存区域在进程地址空间：不能哄骗内核读取 其他进程数据 进程不能绕过内存访问限制：内存读、写应被正确标记 访问系统调用系统调用初始化 系统调用初始化就是对陷入指令的初始化，在X86机器上就是 初始化INT 0x80指令 系统启动时 汇编子程序setup_idt()准备256项的idt表 由start_kernel()、trap_init()调用的C宏定义 set_system_gate(0x80, &amp;system_call)设置0x80号 软中断服务程序为system_call system_call就是所有系统调用总入口 系统调用上下文 内核在执行系统调用时处于进程上下文 current指针指向当前任务，即引发系统调用的进程 在进程上下文中，内可以休眠、被抢占 能够休眠：系统调用可以使用内核提供的绝大部分功能， 方便内核编程 能被抢占：新进程可以使用相同的系统调用 保证系统调用可重入 系统调用返回时，控制权依然在system_call()中，其会负责 切换到用户空间并让用户进程继续执行 系统调用返回值errno错误码 系统调用将错误码放入名为errno的全局变量中 为防止和正常返回值混淆，系统调用不直接返回错误码 errno值只在函数发生错误时设置，若函数不发生错误， errno值无定义，并不置为0 0值通常表示成功 负值表示系统调用失败 错误值对应错误消息定义在error.h中 可以通过perror()库函数翻译误码 处理errno前最好将其存入其他变量中，因为在错误处理 过程中errno值可能会被改变 系统调用具有明确的操作 ret_from_sys_call 以ret_from_sys_call为入口的汇编程序段在Linux进程管理中 起到重要作用 系统调用结束前、大部分中断服务返回前，都会跳转至此处 入口地址 还处理中断嵌套、CPU调度、信号等 给用户空间进程的返回值同样通过寄存器传递 X86机器上，存放在eax寄存器中 Linux系统调用、派生函数进程管理进程控制 fork：创建新进程 clone：按照指定条件创建子进程 execve：运行可执行文件 exit：终止进程 _exit：立即终止当前进程 getdtablesize：进程能打开的最大文件数 getpgid：获取指定进程组标识号 setpgid：设置指定进程组标识号 getpgrp：获取当前进程组标识号 setpgrp：设置当前进程组标识号 getpid：获取进程标识号 getppid：获取父进程标识号 getpriority：获取调度优先级 setpriority：设置调度优先级 modify_ldt：读写进程本地描述符 nanosleep：使指定进程睡眠 nice：改变分时进程的优先级 pause：挂起进程，等待信号 personality：设置进程运行域 prctl：对进程进行特定操作 ptrace：进程跟踪 sched_get_priority_max：取得静态优先级上限 sched_get_priority_min：取得静态优先级下限 sched_getparam：取得进程调度参数 sched_getscheduler：取得指定进程的调度策略 sched_rr_get_interval：取得按RR算法实调度的实时进程 时间片 sched_setparam：设置进程调度参数 sched_setscheduler：设置进程调度策略和参数 sched_yield：进程主动出让处理器，并添加到调度队列队尾 vfork：创建执行新程序的子进程 wait/wait3：等待子进程终止 watipid/wait4：等待指定子进程终止 capget：获取进程权限 capset：设置进程权限 getsid：获取会晤标识号 setsid：设置会晤标识号 进程间通信 ipc：进程间通信控制总控制调用 信号 sigaction：设置对指定信号的处理方法 sigprocmask：根据参数对信号集中的号执行阻塞、解除 阻塞等操作 sigpending：为指定被阻塞信号设置队列 sigsuspend：挂起进程等待特定信号 signal kill：向进程、进程组发信号 sigvec：为兼容BSD设置的信号处理函数，作用类似 sigaction ssetmask：ANSI C的信号处理函数，作用类似sigaction 消息 msgctl：消息控制操作 msgget：获取消息队列 msgsnd：发消息 msgrcv：取消息 管道 pipe：创建管道 信号量 semctl：信号量控制 semget：获取一组信号量 semop：信号量操作 内存管理内存管理 brk/sbrk：改变数据段空间分配 mlock：内存页面加锁 munlock：内存页面解锁 mlockall：进程所有内存页面加锁 munlockall：进程所有内存页面解锁 mmap：映射虚拟内存页 munmap：去除内存映射页 mremap：重新映射虚拟内存地址 msync：将映射内存中数据写回磁盘 mprotect：设置内存映像保护 getpagesize：获取页面大小 sync：将内存缓冲区数据写回磁盘 cacheflush：将指定缓冲区中内容写回磁盘 共享内存 shmctl：控制共享内存 shmget：获取共享内存 shmat：连接共享内存 shmdt：卸载共享内存 文件管理文件读写 tcntl：文件控制 open：打开文件 creat：创建新文件 close ：关闭文件描述字 read：读文件 write：写文件 readv：从文件读入数据到缓存区 writev：将缓冲区数据写入文件 pread：随机读文件 pwrite：随机写文件 lseek：移动文件指针 _llseek：64位地址空间中移动文件指针 dup：复制已打开的文件描述字 dup2：按指定条件复制文件描述字 flock：文件加/解锁 poll：IO多路切换 truncat/ftruncate：截断文件 vumask：设置文件权限掩码 fsync：将内存中文件数据写入磁盘 文件系统操作 access：确定文件可存取性 chdir/fchdir：改变当前工作目录 chmod/fchmod：改变文件模式 chown/fchown/lchown：改变文件属主、用户组 chroot：改变根目录 stat/lstat/fstat：获取文件状态信息 statfs/fstatfs：获取文件系统信息 ustat：读取文件系统信息 mount：安装文件系统 umount：卸载文件系统 readdir：读取目录项 getdents：读取目录项 mkdir：创建目录 mknod：创建索引节点 rmdir：删除目录 rename：文件改名 link：创建链接 symlink：创建符号链接 unlink：删除链接 readlink：读取符合链接值 utime/utimes：改变文件的访问修改时间 quotactl：控制磁盘配额 驱动管理系统控制 ioctl：IO总控制函数 _sysctl：读写系统参数 acct：启用或禁用进程记账 getrlimit：获取系统资源上限 setrlimit：设置系统资源上限 getrusage：获取系统资源使用情况 uselib：选择要使用的二进制库 ioperm：设置端口IO权限 iopl：改变进程IO权限级别 outb：低级端口操作 reboot：重启 swapon：开启交换文件和设备 swapoff：关闭交换文件和设备 bdflush：控制bdflush守护进程 sysfs：获取核心支持的文件系统类型 sysinfo：获取系统信息 adjtimex：调整系统时钟 getitimer：获取计时器值 setitimer：设置计时器值 gettimeofday：获取时间、时区 settimeofday：设置时间、时区 stime：设置系统日期和时间 time：获取系统时间 times：获取进程运行时间 uname：获取当前unix系统名称、版本、主机信息 vhangup：挂起当前终端 nfsservctl：控制NFS守护进程 vm86：进入模拟8086模式 create_module：创建可载入模块项 delete_module：删除可载入模块项 init_module：初始化模块 query_module：查询模型信息 网络管理网络管理 getdomainname：获取域名 setdomainname：设置域名 gethostid：获取主机标识号 sethostid：设置主机标识号 gethostname：获取主机名称 sethostname：设置主机名称 Socket控制 socketcall：socket系统调用 socket：建立socket bind：绑定socket到端口 connect：连接远程主机 accept：响应socket连接请求 send/sendmsg：通过socket发送信息 sendto：发送UDP信息 recv/recvmsg：通过socket接收信息 recvfrom：接收UDP信息 listen：监听socket端口 select：对多路同步IO进行轮询 shutdown：关闭socket上连接 getsockname：获取本地socket名称 getpeername：获取通信对方socket名称 getsockopt：获取端口设置 setsockopt：设置端口参数 sendfile：在文件端口间传输数据 socketpair：创建一对已连接的无名socket 用户管理 getuid：获取用户标识号 setuid：设置用户标识号 getgid：获取组标识号 setgid：设置组标识号 getegid：获取有效组标识号 setegid：设置有效组标识号 geteuid：获取有效用户标识号 seteuid：设置有效用户标识号 setregid：分别设置真实、有效的组标识号 setreuid：分别设置真实、有效的用户标识号 getresgid：分别获取真实、有效、保存过的组标识号 setresgid：分别设置真实、有效、保存过的组标识号 getresuid：分别获取真实、有效、保存过的用户标识号 setresuid：分别设置真实、有效、保存过的用户标识号 setfsgid：设置文件系统检查时使用的组标识号 setfsuid：设置文件系统检查时使用的用户标识号 getgroups：获取候补组标志清单 setgroups：设置候补组标志清单 通知内核 一般系统调用都是通过软件中断向内核发请求，实现内核提供的 某些服务 128号异常处理程序就是系统调用处理程序system_call() 用户空间进程不能直接执行内核代码，需要通过中断通知内核 需要执行系统调用，希望系统切换到内核态，让内核可以代表 应用程序执行系统调用 通知内核机制是靠软件中断实现，X86机器上软中断由int产生 用户程序为系统调用设置参数，其中一个参数是系统调用 编号 程序执行“系统调用”指令，该指令会导致异常 保存程序状态 处理器切换到内核态并跳转到新地址，并开始执行异常处理 程序，即系统调用处理程序 将控制权返还给用户程序 arch/i386/kernel/head.s init/main.c arhc/i386/kernel/traps.c include/asm/system.h 参数传递 _syscalN()用于系统调用的格式转换和参数传递 参数数量为N的系统调用由_syscallN()负责 N取值为0-5之间的整数 启动INT 0x80后，规定返回值送eax寄存器 定义于include/asm/unistd.h，用于系统调用的格式转换 和参数传递","link":"/Linux/Process-Schedual/ps_syscall.html"},{"title":"进程、线程、作业","text":"Linux进程、线程进程发展 Linux2.2内核 进程通过系统调用fork()创建，新进程是原进程子进程 不存在真正意义上的线程 只默认允许4096个进程/线程同时运行 Linux2.4内核 运行系统运行中动态调整进程数上限，进程数仅受制于物理 内存大小，最大16000 Linux2.6内核 进程调度重新编写，引入slab分配器动态生成 task_struct 最大进程数量提升至10亿 线程框架重写 引入tgid、线程组、线程各自的本地存储区 得以支持NPTL线程库 线程/轻量级进程 Linux未真正实现、区分线程，在内核层面是特殊进程，是 “真正的轻量级进程” “线程”和“进程”共享 相同调度策略，处于同一调度层次 相同数据结构进程标识符，位于相同进程标识符空间 “线程”与“进程”的区别在于 线程没有独立的存储空间 多线程即创建多个进程并分配相应的进程描述符 task_struct、指定其共享某些资源 创建线程不会复制某些内存空间，较进程创建快 在专门线程支持系统多线程中，系统会创建包含指向所有 线程的进程描述符，各线程再描述独占资源 尽管Linux支持轻量级进程，但不能说其支持核心级线程 则不可能在Linux上实现完全意义上的POSIX线程机制 所以Linux线程库只能尽可能实现POSIX绝大部分语义，尽量 逼近功能 线程在进程内共享某些资源 打开的文件 文件系统信息 地址空间 信号处理函数 这里讨论的线程都是内核线程，即内核可感知、调度线程，不 包括程序自建线程 内核守护线程 kthreads pthreads 资源 无用户空间 共享完整虚拟寻址空间 状态 只工作在内核态 可在内核态、用户态之间切换 目的 维护内核正常工作 用户分配任务 内核守护线程：内核为维护正常运行创建、仅工作在内核态线程 按作用可以分类 周期性间隔运行，检测特定资源的使用，在用量超出或低于 阈值时采取行动 启动后一直等待，直到系统调用请求执行某特定操作 执行以下任务 周期性将dirty内存页与页来源块设备同步：bpflush线程 将不频繁使用的内存写入交换区：kswapd线程 管理延时动作：kthreadd线程接手内核守护线程创建 实现文件系统的事务日志 内核守护线程只能工作在内核态 没有用户空间，和内核共用一张内核页表 只能使用大于PAGE_OFFSET部分的虚拟寻址空间，即进程 描述符中current-&gt;mm始终为空 对4G主存的X86_32机器，只能使用最后1G，而普通pthreads 可以使用完整虚拟寻址空间 内核守护线程名往往为k开头、d结尾 特殊内核守护线程 Linux内核启动的最后阶段，系统会创建两个内核线程 init：运行文件系统上一系列init脚本，并启动shell 进程 是所有用户进程的祖先，pid为1 kthreadd：内核启动完成之后接手内核守护线程的创建 内核正常工作时永不退出，是死循环，pid为2 载入内核模块时即需要调用其创建新内核守护线程 进程状态12345678// &lt;kernel/include/linux/sched.h&gt;#define TASK_RUNNING 0#define TASK_INTERRUPTIBLE 1#define TASK_UNINTERRUPTIBLE 2#define __TASK_STOPPED 4#define __TASK_TRACED 8#define EXIT_ZOMBIE 16#define TASK_DEAD 64 状态虽然有很多种，但总是TASK_RUNNING -&gt; 非， 即使进程在TASK_INTERRUPTIBLE状态被kill，也需要先唤醒 进入TASK_RUNNING状态再响应kill信号进入TASK_DEAD TASK_RUNNING：可执行，正在执行或在运行队列中等待执行 同一时刻可能有多个进程处于可执行态，位于运行队列中 等待进程调度器调度 TASK_INTERRUPTIBLE：正在阻塞，等待某些条件达成 条件达成后内核会把进程状态设置为运行 此状态进程也会因为接收到信号而提前唤醒准备运行 系统中大部分进程都此状态 TASK_UNINTERRUPTILBE：不响应异步信号，即使接收到信号 也不会被唤醒或准备投入运行 不可中断是指进程不响应异步信号，而不是指CPU不响应 中断 内核某些处理流程是不可被打断的，如：内核和硬件设备 交互被打断会导致设备进入不可控状态，因此需要此状态 __TASK_TRACED：被其他进程跟踪 开发中进程停留在断点状态就是此状态，如：通过ptrace 对调试程序进行跟踪 此状态进程只能等待调试进程通过ptrace系统调用执行 PTRACE_CONT、PTRACE_DETACH等操作才能恢复到 TASK_RUNNING状态 __TASK_STOPPED：停止执行，没有也不能投入运行 通常发生在接收到SIGSTOP、SIGSTP、SIGTTIN、 SIGTTOU等信号 向此状态进程发送SIGCONT信号可以让其恢复到 TASK_RUNNING状态 TASK_DEAD：退出状态，即将被销毁 EXIT_ZOMBIE/TASK_ZOMBIE：进程已结束但task_struct未 注销 进程退出过程中处于TASK_DEAD状态，进程占有的资源将 被回收，但父进程可能会关心进程的信息，所以 task_struct未被销毁 内核态、用户态 系统设计角度：为不同的操作赋予不同的执行等级，与系统相关 的特别关键的操作必须有最高特权程序来完成 运行于用户态：进程可执行操作、可访问资源受到限制 运行于内核态：进程可执行任何操作、使用资源无限制 内存使用角度（虚拟寻址空间，X86_32位系统，最大4GB主存） 内核空间：最高的1G，所有进程共享 包含系统堆栈：2页面，即8K内存，低地址中存放 task_struct值 进程运行于内核空间时使用系统堆栈、处于内核态 用户空间：剩余3G 包含用户堆栈 进程运行于用户空间时使用用户堆栈、处于用户态 内核态的逻辑 进程功能和内核密切相关，进程需要进入内核态才能实现 功能 应用程序在内核空间运行、内核运行于进程上下文、陷入 内核空间，这种交互方式是程序基本行为方式 用户态进入内核态的方式 系统调用，如：printf函数中就是调用write函数 软中断，如：系统发生异常 硬件中断，通常是外部设备的中断 进程或者CPU在任何指定时间点上活动必然为 运行于用户空间，执行用户进程 运行于内核空间，处于进程上下文，代表某特定进程执行 运行于内核空间，处于中断上下文，与任何进程无关，处理 特点中断 Linux进程数据结构task_struct12345678910111213// &lt;kernel/include/linux/sched.h&gt;struct task_struct{ volatile long state; // -1：不可运行，0：可运行，&gt;0：已中断 int lock_depth; // 锁深度 unsigned int policy; // 调度策略：FIFO，RR，CFS pid_t pid; // 线程ID pid_t tgid; // 线程组ID，2.6内核中引入 struct task_struct *parent; // 父进程 struct list_head children; // 子进程 struct list_head sibling; // 兄弟进程 struct task_struct *group_leader; struct list_head thread_group;} 内核使用任务队列（双向循环链表）维护进程（描述符） task_struct：进程描述符，包含进程的所有信息，包括 进程状态 打开的文件 挂起信号 父子进程 ID pid：字面意思为process id，但逻辑上为线程ID tgid：字面意思为thread group id，但逻辑上为 进程ID 1234567// &lt;kernel/timer.c&gt;asmlinkage long sys_getpid(void){ return current-&gt;tgid;}asmlinakge long sys_gettid(void){ return current-&gt;pid;} 线程关系12345678910111213141516171819202122232425262728293031323334353637// &lt;kernel/fork.c&gt;copy_process{ // some code p-&gt;tgid = p-&gt;pid; // 创建线程时 if (clone_flags &amp; CLONE_THREAD) // 从父进程获取`tgid`，归属同一线程组 p-&gt;tgid = current-&gt;tgid; // some code // 初始化`group_leader`、`thread_group` p-&gt;group_leader = p; INIT_LIST_HEAD(&amp;p-&gt;thread_group); // some code // 创建线程时 if (clone_flags &amp; CLONE_THREAD){ // `group_leader`设置为父进程`group_leader` // 即保证`group_leader`指向首个线程`task_struct` p-&gt;group_leader = current-&gt;group_leader; // 通过`thread_group`字段挂到首个线程的`thread_group`队列中 list_add_tail_rcu(&amp;p-&gt;thread_group, &amp;p-&gt;group_leader-&gt;thread_group); // some code } if(likely(p-&gt;pid)){ // some code // 仅首个线程才会通过`tasks`字段挂入`init_task`队列中 if(thread_group_leader(p)){ //... list_add_tail_rcu(&amp;p-&gt;tasks, &amp;init_task, tasks); } }} 线程组退出123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// &lt;kernel/exit.c&gt;NORET_TYPE void do_group_exit(int exit_code){ BUG_ON(exit_code &amp; 0x80); // `current-&gt;signal`由线程组中所有线程共享 // 若调用此方法线程`SIGNAL_GROUP_EXIT`标志已被设置，说明 // 其他线程已经执行过此方法，已通知线程组中所有线程 // 退出，则可以直接执行`do_exit` if(current-&gt;signal-&gt;flags &amp; SIGNAL_GROUP_EXIT) exit_code = current-&gt;signal-&gt;group_exit_code; // 否则通知线程组中所有线程退出 else if(!thread_gropu_empty(current)){ struct signal_struct * const sig = current-&gt;signal; struct sighand_struct * const sighand = current-&gt;sighand; spin_lock_irq(&amp;sighand-&gt;siglock); // another thread got here before we took the lock if(sig-&gt;flags &amp; SIGNAL_GROUP_EXIT) exit_code = sig-&gt;group_exit_code; else{ sig-&gt;group_exit_code = exit_code; zap_other_threads(current); } spin_unlock_irq(&amp;sighand-&gt;sigloc); } do_exit(exit_code);}// &lt;kernel/signal.c&gt;void zap_other_threads(struct task_struct *p){ struct task_struct *t; // 设置`SIGNAL_GROUP_EXTI`标志 p-&gt;signal-&gt;flags = SIGNAL_GROUP_EXIT; p-&gt;signal-&gt;group_stop_count = 0; if(thread_group_empty(p)) return; for (t=next_thread(p); t != p; t=next_thread(t)){ // don't bohter with already dead threads if (t-&gt;exit_state) continue; // 为每个线程设置`SIGKILL`信号 sigaddset(&amp;t-&gt;pending.signal, SIGKILL); signal_wake_up(t, 1); }}// &lt;include/linux/sched.h&gt;static inline struct task_struct *next_thread(const struct task_struct *p){ return list_entry(rcu_dereference(p-&gt;thread_group.next), struct task_struct, thread_group);} Slab分配器 slab分配器把不同对象类型划分为不同高速缓存组，如： task_struct、inode分别存放 高速缓存又会被划分为slab slab由一个或多个物理上连续的页组成 申请数据结构时 先从半满的slabs_partial中申请 若没有半满，就从空的slabs_empty中申请，直至填满 所有 最后申请新的空slab slab分配器策略优点 减少频繁的内存申请和内存释放的内存碎片 由于缓存，分配和释放迅速 thread_info12345678910// &lt;asm/thread_info.h&gt;struct thread_info{ struct task_struct *task; struct exec_domain *exec_domain; usigned long flags; __u32 cpu; int preempt_count; mm_segment_t addr_limit; struct restart_block restart_block;} 内核中对进程操作都需要获得进程描述符task_struct指针， 所以获取速度非常重要 寄存器富余的体系会拿出专门的寄存器存放当前 task_struct的指针 寄存器不富余的体系只能在栈尾创建thread_info结构， 通过计算间接查找 进程创建 继承于Unix，Linux进程创建使用两个函数分别完成，其他如Win 可能都是通过一个方法完成 fork函数：拷贝当前进程创建子进程 子进程、父进程区别仅在于PID、PPID和少量资源 exec函数（族）：载入可执行文件至地址空间开始运行 1234567891011121314151617181920212223242526SYSCALL_DEFINE0(fork){ return do_fork(SIGCHLD, 0, 0, NULL, NULL);}SYSCALL_DEFINE0(vfork){ return _do_fork(CLONE_VFORK | CLONE_VM | SIGCHLD, 0, 0, NULL, NULL, 0);}long do_fork(unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr){ return _do_fork(clone_flags, stack_start, stack_size, parent_tidptr, child_tidptr, 0);}long _do_fork(unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr, unsigned long tls){ // some code p = copy_process(clone_flags, stack_start, stack_size, child_tidptr, NULL, trace, tls); // some code} fork、vfork最终都是通过调用_do_fork实现，仅传参 不一致 首个参数为clone_flags，最终被copy_process用于 真正的拷贝执行 通过系统调用clone()创建线程 同创建进程系统调用fork()、vfork()一样，最终调用 do_fork方法，但传递和进程创建时不同的flag，指明 需要共享的资源 1CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGNAND forkfork()：子进程是父进程的完整副本，复制了父进程的资源， 包括内存内容、task_struct 子进程拷贝父进程的数据段、代码段 同一变量的虚拟地址相同（物理地址不同） 利用copy-on-write优化效率 内核创建子进程时不复制父进程的地址空间，而是只读共享 父进程空间数据 只有子进程需要写数据时才会拷贝到子进程 页表：存放给从逻辑页号到物理页帧/块号地址的映射 Unix傻瓜式进程创建 内核原样复制父进程整个地址空间，并分配给子进程，效率低 为子进程页表分配页帧 为子进程页分配页帧 初始化子进程页表 把父进程页复制到子进程相应页中 大部分情况下复制父进程页无意义 子进程会载入新的程序开始运行 丢弃所继承的地址空间 Copy-on-Writecopy-on-write思想简单：父进程、子进程共享页帧 共享页帧不能被修改，父进程、子进程试图写共享页帧时产生 page_fault异常中断 CPU执行异常处理函数do_wp_page()解决此异常 对导致异常中断的页帧取消共享操作 为写进程复制新的物理页帧，使父、子进程各自拥有内容 相同的物理页帧 原页帧仍然为写保护：其他进程试图写入时，内核检查进程 是否是页帧的唯一属主，如果是则将页帧标记为对此进程 可写 异常处理函数返回时，CPU重新执行导致异常的写入操作指令 copy-on-write：多个呼叫者同时要求相同资源时，会共同 取得相同指针指向相同资源，直到某个呼叫者尝试修改资源时， 系统才给出private copy，避免被修改资源被直接察觉，此 过程对其他呼叫者transparent vforkvfork()：子进程直接共享父进程的虚拟地址空间、物理空间 vfork被设计用以启动新程序 内核不创建子进程的虚拟寻址空间结构 进程创建后应立即执行exec族系统调用加载新程序，替换 当前进程 exec不创建新进程，仅用新程序替换当前进程正文、 数据、堆、栈 在子进程调用exec函数族、_exit()、exit()前，子进程 在父进程的地址空间中运行 二者共享数据段，子进程可能破坏父进程数据结构、栈 父进程地址空间被占用，因此内核会保证父进程被阻塞， 即vfork会保证子进程先运行 应确保一旦调用vfork后 子进程不应使用return返回调用处，否则父进程又会 vfork子进程 子进程不应依赖父进程进一步动作，否则会导致死锁 子进程需避免改变全局数据 若子进程改变了父进程数据结构就不能调用exit函数 cloneclone：可有选择地继承父进程资源 1int clone(int (fn)(void), void * child_stack, int flags, void * args); clone通过众多参数有选择地创建进程 创建LWP/线程 创建兄弟进程 类似vfork创建和父进程共享虚拟寻址空间 参数说明 fn：函数指针 child_stack：为子进程分配的系统堆栈空间 flags：描述需要从父进程继承的资源，如下 args：传给子进程的参数 Flags123456789101112131415161718192021222324#define CSIGNAL 0x000000ff // signal mask to be setn at exit#define CLONE_VM 0x00000100 // set if VM shared between process#define CLONE_FS 0x00000200 // set if fs info shared between processes#define CLONE_FILES 0x00000400 // set if open files shared between processes#define CLONE_SIGHAND 0x00000800 // set if signal handlers and blocked signals shared#define CLONE_PTRACE 0x00002000 // set if we want to let tracing continue on the child too#define CLONE_VFORK 0x00004000 // set if the parent wants the child to wake it up on mm_release#define CLONE_PARENT 0x00008000 // set if we want to have the same parent as the cloner#define CLONE_THREAD 0x00010000 // same thread group?#define CLONE_NEWS 0x00020000 // new namespace group?#define CLONE_SYSVSEM 0x00040000 // share system V SEM_UNDO semantics#define CLONE_SETTLS 0x00080000 // create a new TLS for the child#define CLONE_PARENT_SETTID 0x00100000 // set the TID in the parent#define CLONE_CHILD_CLEARTID 0x00200000 // clear TID in the child#define CLONE_DETEACHED 0x00400000 // unused#define CLONE_UNTRACED 0x00800000 // set if the tracing process can't force `CLONE_PTRACE` on this clone#define CLONE_CHILD_SETTID 0x01000000 // set the TID in the child#define CLONE_STOPPED 0x02000000 // start in stopped state#define CLONE_NEWUTS 0x04000000 // new utsname group#define CLONE_NEWIPC 0x08000000 // new ipcs#define CLONE_NEWUSER 0x10000000 // new user namespace#define CLONE_NEWPID 0x20000000 // new pid namespace#define CLONE_NEWNET 0x40000000 // new network namespace#define CLONE_IO 0x80000000 // clone into context 线程库 POSIX标准要求：线程不仅仅是共享资源即可，其需要被视为 整体 查看进程列表时，一组task_struct需要被展示为列表中 一个节点 发送给进程信号，将被一组task_struct共享，并被其中 任意一个线程处理 发送给线程信号，将只被对应task_struct接收、处理 进程被停止、继续时，一组task_struct状态发生改变 进程收到致命信号SIGSEGV，一组task_struct全部退出 LinuxThread线程库LinuxThread线程库：Linux2.6内核前，pthread线程库对应实现 特点 采用1对1线程模型 通过轻量级进程模拟线程 线程调用由内核完成，其他线程操作同步、取消等由核外 线程库完成 仅通过管理线程实现POSIX以上5点要求中最后一点 管理线程管理线程：为每个进程构造、负责处理线程相关管理工作 管理线程是主线程的首个子线程 进程首次调用pthread_create创建线程时会创建、启动 管理线程 管理线程负责创建、销毁除主线程外线程，成为LinuxThread 的性能瓶颈 从pipe接收命令创建线程 子线程退出时将收到SIGUSER1信号（clone时指定）， 若不是正常退出，则杀死所有子线程并自杀 主循环中不断检查父进程ID，若为1说明原父线程退出并 被托管给init线程，则杀死所有子进程并自杀 通过LWP模拟线程存在的问题 LWP不共享进程ID 某些缺省信号难以做到对所有线程有效，如：SIGSTOP、 SIGCONT无法将整个进程挂起 线程最大数量收到系统总进程数限制 管理线程是性能瓶颈，一旦死亡需要用户手动清理线程、 无人处理线程创建请求 同步效率低，通过复杂的信号处理机制进行同步 与POSIX兼容性差 Naive POSIX Thread LibraryNPTL：Linux2.6内核重写线程框架的基础上引入的pthread线程库 本质上还是利用LWP实现线程的1对1线程模型，但结合新的线程 框架实现了POSIX的全部5点要求 线程组tgid引入体现task_struct代表进程还是线程 task_struct维护两套signal_pending 线程组共享signal_pending：存放kill发送信号， 任意线程可以处理其中信号 线程独有signal_pending：存放pthread_kill发送 信号，只能由线程自身处理 收到致命信号时，内核会将处理动作施加到线程组/进程中 但也存在一些问题 kill未展示的LWP会杀死整个进程 RedHat开发，性能远高于LinuxThreads，需要内核支持 Next Generation Posix Threads for LinuxNGPT：基于GNU Portable Threads项目的实现多对多线程模型 IBM开发，性能介于LinuxThread、NPTL间，2003年终止开发","link":"/Linux/Process-Schedual/ps_proc_thrd.html"},{"title":"Support Vector Machine","text":"总述支持向量机是二分类模型 学习要素 基本模型：定义在特征空间上的间隔最大线性分类器 学习策略：间隔最大化 可形式化为求解凸二次规划问题，也等价于正则化的合页 损失函数最小化问题 间隔最大使其有别于感知机，训练数据线性可分时分离 超平面唯一 误分类最小策略（0-1损失）得到分离超平面的解无穷 多个 距离和最小策略（平方损失）得到分离超平面唯一， 但与此不同 学习算法：求解凸二次规划的最优化算法 数据在给定特征空间上的训练数据集 $T={(x_1,y_1), (x_2,y_2),\\cdots,(x_N,y_N)}$，其中 $x_i \\in \\mathcal{X} = R^n, y_i \\in {-1, +1}, i=1,2,…,N$ 输入空间：欧氏空间或离散集合 特征空间：希尔伯特空间 输出空间：离散集合 SVM假设输入空间、特征空间为两个不同空间，SVM在特征空间 上进行学习 线性（可分）支持向量机假设两个空间元素一一对应，并将 输入空间中的输入映射为特征空间中特征向量 非线性支持向量机利用，输入空间到特征空间的非线性映射 （核函数）将输入映射为特征向量 概念Linear Support Vector Machine in Linearly Separable Case线性可分支持向量机：硬间隔支持向量机，训练数据线性可分时， 通过硬间隔最大化策略学习 直观含义：不仅将正负实例分开，而且对于最难分的实例点 （离超平面最近的点），也有足够大的确信度将其分开，这样的 超平面对新实例预测能力较好 Hard-margin Maximization：硬间隔最大化，最大化超平面 $(w,b)$关于线性可分训练数据集的两类样本集几何间隔 原始问题策略 约束最优化问题表述 \\begin{align} \\max_{w,b} & \\gamma & \\\\ s.t. & \\frac {y_i} {\\|w\\|} (wx + b) \\geq \\gamma, i=1,2,\\cdots,N \\end{align} 考虑函数间隔、几何间隔关系得到问题 目标、约束中使用函数间隔表示几何间隔 就是普通等比缩放、分母移位，不用考虑太多 \\begin{align*} \\max_{w,b} & \\frac {\\hat{\\gamma}} {\\|w\\|} \\\\ s.t. & y_i(wx_i + b) \\geq \\hat{\\gamma}, i=1,2,\\cdots,N \\end{align*} 而函数间隔$\\hat{\\gamma}$大小会随着超平面参数变化 成比例变化，其取值对问题求解无影响，所以可取 $\\hat{\\gamma}=1$带入，得到最优化问题 \\begin{align*} \\min_{w,b} & \\frac 1 2 {\\|w\\|}^2 \\\\ s.t. & y_i(wx_i + b) - 1 \\geq 0, i=1,2,\\cdots,N \\end{align*} $\\max \\frac 1 {|w|}$和 $\\min \\frac 1 2 {|w|}^2$等价 这里确实没有通用变换技巧，因为这里的$\\hat \\gamma$ 是特殊的值，其取值与$w,b$相关，这是问题自然蕴含 ，可以视为还有以下一个依赖 当然也可以直接证明两个问题等价：先证明最优解在等式 成立时取到，然后目标函数中1替换为等式左边 最大间隔分离平面存在性 若训练数据集T线性可分，则可将训练数据集中样本点完全 正确分开的最大间隔分离超平面存在且唯一 存在性 训练数据集线性可分，所以以上中最优化问题一定存在可行解 又目标函数又下界，则最优化问题必有解todo 又训练数据集中正、负类点都有，所以$(0,b)$必不是最优化 可行解 唯一性 若以上最优化问题存在两个最优解$(w_1^{},b_1^{})$、 $w_2^{},b_2^{}$ 显然$|w_1^{}| = |w_2^{}| = c$， $(w=\\frac {w_1^{}+w_2^{}} 2,b=\\frac {b_1^{}+b_2^{}} 2)$ 使最优化问题的一个可行解，则有 c \\leq \\|w\\| \\leq \\frac 1 2 \\|w_1^{*}\\| + \\frac 1 2 \\|w_2^{*} = c 则有$|w|=\\frac 1 2 |w_1^{}|+\\frac 1 2 |w_2^{}|$ ，有$w_1^{} = \\lambda w_2^{}, |\\lambda|=1$ $\\lambda = -1$，不是可行解，矛盾 $\\lambda = 1$，则$w_1^{()} = w_2^{}$，两个最优解 写为$(w^{}, b_1^{})$、$(w^{}, b_2^{})$ 设$x_1^{+}, x_1^{-}, x_2^{+}, x_2^{-}$分别为对应以上两组 超平面，使得约束取等号、正/负类别的样本点，则有 \\begin{align*} b_1^{*} & = -\\frac 1 2 (w^{*} x_1^{+} + w^{*} x_1^{-}) \\\\ b_2^{*} & = -\\frac 1 2 (w^{*} x_2^{+} + w^{*} x_2^{-}) \\\\ \\end{align*}则有 b_1^{*} - b_2^{*} = -\\frac 1 2 [w^{*}(x_1^{+} - x_2^{+}) + w^{*} (x_1^{-} - x_2^{-})] 又因为以上支持向量的性质可得 \\begin{align*} w^{*}x_2^{+} + b_1^{*} & \\geq 1 = w^{*}x_1^{+} + b_1^{*} \\\\ w^{*}x_1^{+} + b_2^{*} & \\geq 1 = w^{*}x_2^{+} + b_2^{*} \\end{align*}则有$w^{}(x_1^{+} - x_2^{+})=0$，同理有 $w^{}(x_1^{-} - x_2^{-})=0$ 则$b_1^{} - b_2^{} = 0$ 概念Support Vector支持向量：训练数据集中与超平面距离最近的样本点实例 在线性可分支持向量机中即为使得约束条件取等号成立的点 在决定分离超平面时，只有支持向量起作用，其他实例点不起 作用 支持向量一般很少，所以支持向量机由很少的“重要”训练样本 决定 间隔边界间隔边界：超平面$wx + b = +/-1$ 支持向量位于其上 两个间隔边界之间距离称为间隔$=\\frac 2 {|w|}$ 算法 输入：线性可分训练数据集T 输出：最大间隔分离超平面、分类决策函数 构造并求解约束最优化问题 \\begin{align*} \\min_{w,b} & \\frac 1 2 {\\|w\\|}^2 \\\\ s.t. & y_i(wx_i + b) - 1 \\geq 0, i=1,2,\\cdots,N \\end{align*}得到最优解$w^{}, b^{}$ 得到分离超平面 w^{*}x + b^{*} = 0分类决策函数 f(x) = sign(w^{*}x + b^{*}) 多分类 1 vs n-1：对类$k=1,…,n$分别训练当前类对剩余类分类器 分类器数据量有偏，可以在负类样本中进行抽样 训练n个分类器 1 vs 1：对$k=1,…,n$类别两两训练分类器，预测时取各 分类器投票多数 需要训练$\\frac {n(n-1)} 2$给分类器 DAG：对$k=1,…,n$类别两两训练分类器，根据预先设计的、 可以使用DAG表示的分类器预测顺序依次预测 即排除法排除较为不可能类别 一旦某次预测失误，之后分类器无法弥补 但是错误率可控 设计DAG时可以每次选择相差最大的类别优先判别 Dual Algorithm对偶算法：求解对偶问题得到原始问题的最优解 对偶问题往往更容易求解 自然引入核函数，进而推广到非线性分类问题 对偶问题策略 Lagrange函数如下 L(w,b,\\alpha) = \\frac 1 2 \\|w\\|^2 - \\sum_{i=1}^N \\alpha_i y_i (wx_i + b) + \\sum_{i=1}^N \\alpha_i $\\alpha_i &gt; 0$：Lagrange multiplier 根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题 \\max_{\\alpha} \\min_{w,b} L(w,b,\\alpha) 求$\\min_{w,b} L(w,b,\\alpha)$，对拉格朗日函数求偏导置0 \\begin{align*} \\triangledown_w L(w,b,\\alpha) & = w - \\sum_{i=1}^N \\alpha_i y_i x_i = 0 \\\\ \\triangledown_b L(w,b,\\alpha) & = -\\sum_{i=1}^N \\alpha_i y_i = 0 \\end{align*}解得 \\begin{align*} w = \\sum_{i=1}^N \\alpha_i y_i x_i \\\\ \\sum_{i=1}^N \\alpha_i y_i = 0 \\end{align*} 将以上结果代理拉格朗日函数可得 \\begin{align*} L(w,b,\\alpha) & = \\frac 1 2 \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j (x_i x_j) - \\sum_{i=1}^N \\alpha_i y_i ((\\sum_{j=1}^N \\alpha_j y_j x_j)x_i + b) + \\sum_{i=1}^N \\alpha_i \\\\ & = -\\frac 1 2 \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_i (x_i x_j) + \\sum_{i=1}^N \\alpha_i \\end{align*} 以上函数对$\\alpha$极大即为对偶问题，为方便改成极小 \\begin{align*} \\min_{\\alpha} & \\frac 1 2 \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j (x_i x_j) - \\sum_{i=1}^N \\alpha_i \\\\ s.t. & \\sum_{i=1}^N \\alpha_i y_i = 0, \\\\ & \\alpha_i > 0, i = 1,2,\\cdots,N \\end{align*} 原始问题解 设$\\alpha^{} = (\\alpha_1^{}, \\cdots, \\alpha_N^{})$是 上述对偶优化问题的解，则存在$j \\in [1, N]$使得 $\\alpha_j^{} &gt; 0$，且原始最优化问题解如下\\begin{align*} w^{*} & = \\sum_{i=1}^N \\alpha_i^{*} y_i x_i \\\\ b^{*} & = y_j - \\sum_{i=1}^N \\alpha_i^{*} y_i (x_i x_j) \\end{align*} 由KKT条件成立有 \\begin{align*} & \\triangledown_w L(w^{*}, b^{*}, \\alpha^{*}) = w^{*} - \\sum_{i=1}^N \\alpha_i{*} y_i x_i = 0 \\\\ & \\triangledown_b L(w^{*}, b^{*}, \\alpha^{*}) = -\\sum_{i=1}^N \\alpha_i^{*} y_i = 0 \\\\ & \\alpha^{*}(y_i (w^{*} x_i + b^{*}) - 1) = 0, i = 1,2,\\cdots,N \\\\ & y_i(w^{*} x_i + b) - 1 \\geq 0, i = 1,2,\\cdots,N \\\\ & \\alpha_i^{*} \\geq 0, i = 1,2,\\cdots,N \\\\ \\end{align*} 可得 w^{*} = \\sum_i \\alpha_i^{*} y_i x_i 其中至少有一个$\\alpha_j &gt; 0$，否则$w^{*}=0$不是原问题解 ，且有 \\begin{align*} y_j(w^{*} x_j + b^{*}) - 1 = 0 \\end{align*}注意到$y_j \\in {-1, +1}$，则有 b^{*} = y_j - \\sum_{i=1}^N \\alpha_i^{*} y_i (x_i x_j) 分离超平面 则分离超平面为 \\sum_{i=1}^N \\alpha_i^{*} y_i (x x_i) + b^{*} = 0 分类决策函数为 f(x) = sgn(\\sum_{i=1}^N \\alpha_i^{*} y_i (x x_i) + b^{*})即分类决策函数只依赖输入$x$和训练样本的内积 支持向量 将对偶最优化问题中，训练数据集中对应$\\alpha_i^{*} &gt; 0$ 的样本点$(x_i, y_i)$称为支持向量 由KKT互补条件可知，对应$\\alpha_i^{*} &gt; 0$的实例$x_i$有 y_i(w^{*} x_i + b^{*}) - 1 = 0即$(x_i, y_i)$在间隔边界上，同原始问题中支持向量定义一致 算法 输入：线性可分数据集$T$ 输出：分离超平面、分类决策函数 构造并求解以上对偶约束最优化问题，求得最优解 $\\alpha^{} = (\\alpha_1^{},…,\\alpha_N^{*})^T$ 依据以上公式求$w^{}$，选取$\\alpha^{}$正分量 $\\alpha_j^{} &gt; 0$计算$b^{}$ 求出分类超平面、分类决策函数 Linear Support Vector Machine线性支持向量机：训练数据线性不可分时，通过软间隔最大化策略 学习 训练集线性不可分通常是由于存在一些outlier 这些特异点不能满足函数间隔大于等于1的约束条件 将这些特异点除去后，剩下大部分样本点组成的集合是 线性可分的 对每个样本点$(x_i,y_i)$引入松弛变量$\\xi_i \\geq 0$ 使得函数间隔加上松弛变量大于等于1 对每个松弛变量$\\xi_i$，支付一个代价$\\xi_i$ soft-margin maximization：软间隔最大化，最大化样本点 几何间隔时，尽量减少误分类点数量 策略线性不可分的线性支持向量机的学习变成如下凸二次规划，即 软间隔最大化 \\begin{align*} \\min_{w,b,\\xi} & \\frac 1 2 \\|w\\|^2 + C \\sum_{i=1}^N \\xi_i \\\\ s.t. & y_i(w x_i + b) \\geq 1 - \\xi_i, i=1,2,\\cdots,N \\\\ & \\xi_i \\geq 0, i=1,2,\\cdots,N \\end{align*} $\\xi_i$：松弛变量 $C &gt; 0$：惩罚参数，由应用问题决定，C越大对误分类惩罚越大 最小化目标函数包含两层含义 $\\frac 1 2 |w|^2$尽量小，间隔尽量大 误分类点个数尽量小 以上问题是凸二次规划问题，所以$(w,b,\\xi)$的解是存在的 $w$解唯一 $b$解可能不唯一，存在一个区间 对给定的线性不可分训练数据集，通过求解以上凸二次规划问题 得到的分类超平面w^{*} x + b^{*} = 0 以及相应的分类决策函数f(x) = sgn(w^{*} x + b^{*}) 称为线性支持向量机 线性支持向量包括线性可分支持向量机 现实中训练数据集往往线性不可分，线性支持向量机适用性更广 对偶问题策略原始问题的对偶问题 \\begin{align*} \\min_\\alpha & \\frac 1 2 \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j (x_i x_j) - \\sum_{i=1}^N \\alpha_i \\\\ s.t. & \\sum_{i=1}^N \\alpha_i y_i = 0 \\\\ & 0 \\leq \\alpha_i \\leq C, i=1,2,\\cdots,N \\end{align*} 类似线性可分支持向量机利用Lagrange对偶即可得 原始问题解 设$\\alpha^{} = (\\alpha_1^{}, \\cdots, \\alpha_N^{})$是 上述对偶优化问题的解，则存在$j \\in [1, N]$使得 $0 &lt; \\alpha_j^{} &lt; C$，且原始最优化问题解如下\\begin{align*} w^{*} & = \\sum_{i=1}^N \\alpha_i^{*} y_i x_i \\\\ b^{*} & = y_j - \\sum_{i=1}^N \\alpha_i^{*} y_i (x_i x_j) \\end{align*} 类似线性可分支持向量机利用KKT条件即可得 分离超平面 则分离超平面为 \\sum_{i=1}^N \\alpha_i^{*} y_i (x x_i) + b^{*} = 0 分类决策函数/线性支持向量机对偶形式 f(x) = sgn(\\sum_{i=1}^N \\alpha_i^{*} y_i (x x_i) + b^{*})即分类决策函数只依赖输入$x$和训练样本的内积 支持向量 将对偶最优化问题中，训练数据集中对应$\\alpha_i^{*} &gt; 0$ 的样本点$x_i$称为（软间隔）支持向量 $\\alpha_i^{*} &lt; C$：则$\\xi_i = 0$，恰好落在间隔边界上 $\\alpha_i^{*} = C, 0 &lt; \\xi_i &lt; 1$：间隔边界与分离超平面 之间 $\\alpha_i^{*} = C, \\xi=1$：分离超平面上 $\\alpha_i^{*} = C, \\xi&gt;1$：分离超平面误分一侧 Hinge Loss线性支持向量机策略还可以视为最小化以下目标函数 \\sum_{i=1}^N [1-y_i(w x_i + b)]_{+} + \\lambda \\|w\\|^2 第一项：经验风险，合页损失函数 第二项：正则化项 $w$模越大，间隔越小，合页损失越小，所以用这个作为 正则化项是合理的 参见data_science/loss 等价证明令 \\xi_i = [1 - y_i(w x_i + b)]_{+} 则有$\\xi_i \\geq 0$ 且 \\left \\{ \\begin{align*} & y_i(w x_i + b) = 1 - \\xi_i, & y_i(w x_i + b) \\leq 1 \\\\ & y_i(w x_i + b) > 1 - \\xi_i = 1, & y_i(w x_i + b) > 1 \\end{align*} \\right.所以有 y_i(w x_i + b) \\geq 1 - \\xi_i 则原问题两个约束条件均得到满足，此问题可写成 \\min_{w,b} \\sum_{i=1}^N \\xi_i + \\lambda \\|w\\|^2取$\\lambda = \\frac 1 {2C}$，即同原问题 Non-Linear Support Vector Machine非线性支持向量机 非线性问题：通过非线性模型才能很好进行分类的问题 通过非线性变换$\\phi(x)$，将输入空间映射到特征 空间（维数可能非常高） 原空间中非线性可分问题在特征空间可能变得线性可分， 在特征空间中学习分类模型 SVM求解非线性问题时 kernel trick：通过非线性变换将输入空间对应一个特征 空间，使得输入空间中超曲面对应于特征空间的超平面模型 软间隔最大化策略：在特征空间中求解线性支持向量机 Kernal Trick核技巧：线性SVM的对偶问题中，目标函数、决策函数均只涉及输入 实例、实例之间的内积 将内积使用核函数代替，等价进行复杂的非线性变换 映射函数是非线性函数时，学习的含有核函数的支持向量机 是非线性模型 学习是隐式地在特征空间中进行的，不需要显式定义特征 空间、映射函数 参见data_science/ref/functions 对偶问题目标函数 W(\\alpha) = \\frac 1 2 \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j K(x_i, x_j) - \\sum_{i=1}^N \\alpha_i原始问题解分类决策函数\\begin{align*} f(x) & = sgn(\\sum_{i=1}^{N_s} \\alpha_i^{*} y_i \\phi(x_i) \\phi(x) + b^{*}) \\\\ & = sgn(\\sum_{i=1}^{N_s} \\alpha_i^{*} y_i K(x_i, x) + b^{*}) \\end{align*}算法 输入：训练数据集$T$ 输出：分类决策函数 选取适当的核函数$K(x,z)$、适当参数C，构造求解最优化问题 \\begin{align*} \\min_\\alpha & \\frac 1 2 \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_1 \\alpha_j y_i y_j K(x_i, x_j) - \\sum_{i=1}^N \\alpha_i \\\\ s.t. & \\sum_{i=1}^N \\alpha_i y_i = 0 \\\\ & 0 \\leq \\alpha_i \\leq C, i=1,2,...,N \\end{align*}求得最优解 $\\alpha^{} = (\\alpha_1^{},\\alpha_2^{},\\cdots,\\alpha_N^{})$ 选择$\\alpha^{}$的一个正分量$0 &lt; \\alpha_j^{} &lt; C$，计算 b^{*} = y_j - \\sum_{i=1}^N \\alpha_i^{*} y_i K(x_i x_j) 构造决策函数 $K(x,z)$是正定核函数时，最优化问题是凸二次规划，有解 Sequential Minimal Optimization序列最小最优化算法，主要解如下凸二次规划的对偶问题 \\begin{align*} \\min_\\alpha & \\frac 1 2 \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_1 \\alpha_j y_i y_j K(x_i, x_j) - \\sum_{i=1}^N \\alpha_i \\\\ s.t. & \\sum_{i=1}^N \\alpha_i y_i = 0 \\\\ & 0 \\leq \\alpha_i \\leq C, i=1,2,...,N \\end{align*} 凸二次规划有很多算法可以求得全局最优解，但是在训练样本 容量较大时，算法会很低效 思想将原问题不断分解为子问题求解，进而求解原问题 如果所有变量的解都满足此优化问题的KKT条件，得到此最优化 问题的一个可能解 对凸二次规划就是最优解，因为凸二次规划只有一个稳定点 否则选择两个变量，固定其他变量，构建一个二次规划 目标是使得解符合KKT条件，但是因为等式约束的存在， 不可能单独改变一个变量而保持等式约束 子问题有解析解，求解速度快 二次规划问题关于两个变量的解会使得原始二次规划的目标 函数值变得更小，更接近原始二次规划的解 （这里SMO原始论文有证明，违反KKT条件的变量可以做到） 不失一般性，假设选择两个变量$\\alpha_1, \\alpha_2$，其他 变量$\\alpha_i(i=3,4,…,N)$是固定的，则SMO最优化子问题 \\begin{align*} \\min_{\\alpha_1, \\alpha_2} & W(\\alpha_1, \\alpha_2) = \\frac 1 2 K_{11} \\alpha_1^2 + \\frac 1 2 K_{22} \\alpha_2^2 + y_1 y_2 K_{12} \\alpha_1 \\alpha_2 - (\\alpha_1 + \\alpha_2) + y_1 \\alpha_1 \\sum_{i=3}^N y_i \\alpha_i K_{i1} + y_2 \\alpha_2 \\sum_{i=1}^N y_i \\alpha_i K{i2} \\\\ s.t. & \\alpha_1 y_1 + \\alpha_2 y_2 = -\\sum_{i=3}^N y_i \\alpha_i = \\zeta \\\\ & 0 \\leq \\alpha_i \\leq C, i=1,2 \\end{align*} $K_{ij} = K(x_i, x_j), i,j=1,2,\\cdots,N$ $\\zeta$：常数 两变量二次规划取值范围 由等式约束，$\\alpha_1, \\alpha_2$中仅一个自由变量， 不妨设为$\\alpha_2$ 设初始可行解为$\\alpha_1, \\alpha_2$ 设最优解为$\\alpha_1^{}, \\alpha_2^{}$ 未经剪辑（不考虑约束条件而来得取值范围）最优解为 $\\alpha_2^{**}$ 由不等式约束，可以得到$\\alpha_2$取值范围$[L, H]$ $y_1 = y_2 = +/-1$时 \\begin{align*} H & = \\min \\{C, \\alpha_1 + \\alpha_2 \\} \\\\ L & = \\max \\{0, \\alpha_2 + \\alpha_1 - C \\} \\end{align*} $y_1 \\neq y_2$时 \\begin{align*} L & = \\max \\{0, \\alpha_2 - \\alpha_1 \\} \\\\ L & = \\min \\{C, C + \\alpha_2 - \\alpha_1 \\} \\end{align*} 以上取值范围第二项都是应用等式约束情况下，考虑 不等式约束 两变量二次规划求解为叙述，记 \\begin{align*} g(x) & = \\sum_{i=1}^N \\alpha_i y_i K(x_i, x) + b \\\\ E_j & = g(x_j) - y_j \\\\ & = (\\sum_{i=1}^N \\alpha_i y_i K(x_i, x_j)) - y_j \\end{align*} $g(x)$：SVM预测函数（比分类器少了符号函数）（函数间隔） $E_j$：SVM对样本预测与真实值偏差 以上两变量二次规划问题，沿约束方向未经剪辑解是\\begin{align*} \\alpha_2^{**} & = \\alpha_2 + \\frac {y_2 (E_1 - E_2)} \\eta \\\\ \\eta & = K_{11} + K_{22} - 2K_{12} \\\\ & = \\|\\phi(x_1) - \\phi_(x_2)\\|^2 \\end{align*} 剪辑后的最优解是\\begin{align*} \\alpha_2^{*} & = \\left \\{ \\begin{array}{l} H, & \\alpha_2^{**} > H \\\\ \\alpha_2^{**}, & L \\leq \\alpha_2^{**} \\leq H \\\\ L, & \\alpha_2^{*} < L \\end{array} \\right. \\\\ \\alpha_1^{*} & = \\alpha_1 + y_1 y_2 (\\alpha_2 - \\alpha_2^{*}) \\end{align*} 记 \\begin{align*} v_i & = \\sum_{j=3}^N \\alpha_j y_j K(x_i, x_j) \\\\ & = g(x_i) - \\sum_{j=1}^2 \\alpha_j y_j K(x_i, x_j) - b i=1,2 \\end{align*}由等式约束$\\alpha_1 = (\\zeta - y_2 \\alpha_2) y_1$，均 带入目标函数有 \\begin{align*} W(\\alpha_1, \\alpha_2) = & \\frac 1 2 K_{11} (\\zeta - y_2 \\alpha_2)^2 + \\frac 1 2 K_{22} \\alpha_2^2 + y_2 K_{12} (\\zeta - y_2 \\alpha_2) \\alpha_2 - \\\\ & y_1 (\\zeta - \\alpha_2 y_2) - \\alpha_2 + v_1 (\\zeta - \\alpha_2 y_2) + y_2 v_2 \\alpha_2 \\end{align*} 对$\\alpha_2$求导置0可得 \\begin{align*} (K_{11} + K_{22} - 2K_{12}) \\alpha_2 & = y_2 (y_2 - y_1 + \\zeta K_{11} - \\zeta K_{12} + v_1 + v_2) \\\\ & = y_2 [y_2 - y_1 + \\zeta K_{11} - \\zeta K_{12} + (g(x_1) - \\sum_{j=1}^2 y_j \\alpha_j K_{1j} - b) - (g(x_2) - \\sum_{j=1}^2 y_j \\alpha_j K_{2j} -b )] \\end{align*}带入$\\zeta = \\alpha_1 y_1 + \\alpha_2 y2$，可得 \\begin{align*} (K_11 + K_22 - 2K_{12}) \\alpha_2^{**} & = y_2((K_{11} + K_{22} - 2K_{12}) \\alpha_2 y_2 + y_2 - y_1 + g(x_1) - g(x_1)) \\\\ & = (K_11 + K_{22} - 2K_{12}) \\alpha_2 + y_2 (E_1 - E_2) \\end{align*} 变量选择SMO算法每个子问题的两个优化变量，其中至少一个违反KKT条件 外层循环—首个变量选择在训练样本中选择违反KKT条件最严重的样本点，将对应的变量作为 第一个变量$\\alpha_1$ 检查样本点是否满足KKT条件 \\begin{align*} \\alpha_i = 0 \\Leftrightarrow y_i g(x_i) \\geq 1 \\\\ 0 < \\alpha_i < C \\Leftrightarrow y_i g(x_i) = 1 \\\\ \\alpha_i = C \\Leftrightarrow y_i g(x_i) \\leq 1 \\end{align*} 检验过程中 首先遍历所有满足条件的$0 &lt; \\alpha_i &lt; C$样本点，即 在间隔边界上的支持向量点 若没有找到违背KKT条件的样本点，则遍历整个训练集 内层循环第二个变量$\\alpha_2$选择标准是其自身有足够大的变化，以加快 计算速度 由以上推导知，$\\alpha_2^{*}$取值依赖于$|E_1 - E_2|$， 所以可以选择$\\alpha_2$使其对应的$|E_1 - E_2|$最大 $\\alpha_1$已经确定，$E_1$已经确定 $E_1 &gt; 0$：选最小的$E_2$ $E_1 &lt; 0$：选最大的$E_2$ 但以上方法可能不能使得目标函数值有足够下降，采用以下 启发式规则继续选择$\\alpha_2$ 遍历间隔边界上的点 遍历整个训练数据集 放弃$\\alpha_1$ 更新阈值 $0&lt; \\alpha_1^{*} &lt; C$时，由KKT条件可知 \\sum_{i=1}^N \\alpha_i y_i K_{i1} + b = y_1 则有 b_1^{*} = y_1 - \\sum_{i=3}^N \\alpha_i y_i K_{i1} - \\alpha_1^{*} y_1 K_{11} - \\alpha_2^{*} y_2 K_{21} 将$E_1$定义式带入有 b_1^{*} = -E_1 - y_1 K_{11} (\\alpha_1^{*} - \\alpha_1) - y_2 K_{21} (\\alpha_2^{*} - \\alpha_2) + b 类似的$0 &lt; \\alpha_2^{*} &lt; C$时 b_2^{*} = -E_2 - y_2 K_{22} (\\alpha_2^{*} - \\alpha_2) - y_1 K_{12} (\\alpha_1^{*} - \\alpha_1) + b 若 $0 &lt; \\alpha_1^{}, \\alpha_2^{} &lt; C$，则 $b_1{} = b_2^{}$ $\\alpha_1^{}, $\\alpha_2^{}$均为0、C，则 $[b_1^{}, b_2^{}]$中均为符合KKT条件的阈值，选择 中点作为新阈值$b^{*}$ 同时使用新阈值更新所有的$E_i$值 E_i^{*} = \\sum_S y_j \\alpha_j K(x_i, x_j) + b^{*} - y_i $S$：所有支持向量的集合 算法 输入：训练数据集$T$，精度$\\epsilon$ 输出：近似解$\\hat \\alpha$ 初值$\\alpha^{(0)}$，置k=0 选取优化变量$\\alpha_1^{(k)}, \\alpha_2^{(k)}$，解析求解 两变量最优化问题得$\\alpha_1^{(k+1)}, \\alpha_2^{(k+2)}$， 更新$\\alpha^{(k+1)}$ 若在精度范围内满足停机条件（KKT条件） \\begin{align*} & \\sum_{i=1}^N \\alpha_i y_i = 0 \\\\ & 0 \\leq \\alpha_i \\leq C, i=1,2,\\cdots,N \\\\ & y_i g(x_i) = \\left \\{ \\begin{array}{l} \\geq 1, & \\{x_i | \\alpha_i = 0\\} \\\\ = 1, & \\{x_i | 0 < \\alpha_i < C\\} \\\\ \\leq 1, & \\{x_i | \\alpha_i = C\\} \\end{array} \\right. \\\\ & g(x_i) = \\sum_{j=1}^N \\alpha_j y_j K(x_j, x_i) + b \\end{align*}则转4，否则置k=k+1，转2 取$\\hat \\alpha = \\alpha^{(k+1)}$","link":"/ML-Model/Linear-Model/support_vector_machine.html"},{"title":"Decision Tree","text":"决策树概述结构 决策树分析结论、展示方式类似一棵倒置的树 决策树由 node、directed edge 组成 internal node：内部节点，表示特征、属性 leaf node：叶子节点，表示一个类 对训练数据进行分类 从根节点开始，对实例某特征进行测试，根据测试结果将实例分配到其子节点，对应该特征一个取值 递归地对实例进行分配，直至到达叶子节点，将实例分到叶节点地类中 对新数据的预测 从决策树的树根到树叶搜索，确定数所的叶子节点 利用叶子节点中训练数据集预测 分类型：众数 数值型：均值 本质决策树：本质上是从训练数据中归纳出一组分类规则 与训练数据不矛盾的分类规则（即能对训练数据正确分类）可能有多个、没有，需要找到矛盾较小、泛化能力较好的 决策树学习也是由训练数据集估计条件概率模型，需要寻找对训练数据有很好拟合、对未知数据有很好预测的模型 分类规则集合 决策树可以看作是 if-then 规则的集合：体现输入、输出变量逻辑关系 决策树根节点到叶节点每条路径构成一条规则 路径上内部节点的特征对应规则的条件，叶节点对应规则结论 决策树的路径或其对应的 if-then 规则集合 互斥且完备，即每个实例有且仅有一条路径覆盖 条件概率分布 决策树可以表示定义在特征空间、类空间上的条件概率分布 此条件概率分布定义在特征空间的一个划分（有限）上 决策树中一条路径（叶节点）对应划分中一个单元 每个单元定义的概率分布就构成一个条件概率分布 条件概率分布由 各单元的给定条件下，各类的条件概率分布组成 $P(Y|X)$：$X$ 为表示特征的随机变量（取值各个单元），$Y$ 表示类的随机变量 各叶节点上的条件概率往往偏向于某类，决策树分类时将属于该节点实例分为该类 特点 优势 能有效处理分类型输入变量 能够实现非线性分割 模型具有可读性，分类速度块 问题 充分生长的决策有高方差，预测不稳定 剪枝可以提高预测稳健性，但是预测精度可能会下降 决策树构建 从所有可能决策树中选取最优决策树是NP完全问题 所以实际决策树算法通常采用 启发式 算法、贪心算法，近似求解最优化问题，得到 sub-optimal 决策树 从包含所有数据的根节点开始，递归的选择 当前 最优特征、分割点对训练数据进行分割，使得各子数据集有当前最好分类 此样本不断分组过程对应特征空间的划分、决策树的构建 原则：使节点/组内观测取值异质性下降最大，从而确定 最佳划分特征 特征的最佳分割点 算法 ID3 C4.5 CART CHAID 特征 分类 分类、连续 同左 同左 输出 分类 分类 分类、回归 分类 连续值处理 - 二分法 同左 等距分组 分叉 多叉 多叉 二叉 多叉 分裂指标 信息增益 信息增益比 GINI 不纯度 相关性 前剪枝 - 叶节点数量 树深度、节点样本数量 - 后剪枝 - 置信度、减少-误差法 MCCP - 异质性衡量：划分准则 信息增益 信息增益比：避免信息增益倾向于取值较多特征 若样本类别严格服从分布，则信息增益和信息增益比选择应完全相同 但由于偶然性、样本数量等原因，各特征取值的样本数量往往不完全符合分布 由信息增益定义可看出，各特征取值样本数量较小时，数量变动影响更大，而特征取值较多更可能出现各取值对应样本数量较小 GINI 指数 研究表明，不同决策树的划分准则对泛化性能影响有限，信息增益和 GINI 指数理念分析表明，其仅在 2% 情况下有所不同 特征变量处理 离散值处理 全分类：各类别分别独立作为分支，构建节点 切分二分：将类别分为的两组 是否二分：某取值作为一个分支，其余作为另一分支 连续值处理 二分法：选择阈值，按照阈值将连续值分为两部分 精确阈值选取：检查所有可能阈值点，即所有不同取值点的中间点 近似阈值选取 近似分裂算法：选取一组阈值，将特征划分至不同桶内，类似分类值处理 等频阈值：分位数 等距阈值：linespace 缺失值处理 缺失值处理需要解决：异质性衡量指标计算、特征缺失样本划分问题 异质性衡量指标计算：使用特征未缺失样本权重对指标加权（以信息增益为例） \\begin{align*} g(Y|X) &= \\rho * g(\\tilde Y | X) \\\\ & = \\rho * (H(\\tilde D) - \\sum_v^V \\tilde {r_v} H(\\tilde {D^v})) \\\\ H(\\tilde V) &= - \\sum_k^K \\tilde {p_k} log \\tilde {p_k} \\\\ \\rho &= \\frac {\\sum_{x \\in \\tilde D} w_x} {\\sum_{x \\in D} w_x}\\\\ \\tilde {p_x} &= \\frac {\\sum_{x \\in \\tilde {D_k}} w_x} {\\sum_{x \\in \\tilde D} w_x} \\\\ \\tilde {r_v} &= \\frac {\\sum_{x \\in \\tilde {D^v}} w_x} {\\sum_{x \\in \\tilde D} w_x} \\end{align*} $Y, X, w_x$：样本类别，特征，样本权重 $D, \\tilde D, \\tilde {D_k}, \\tilde {D^v}$：样本全集，在特征 $X$ 上无缺失样本子集，属于 $k$ 类样本子集，在特征 $X$ 上取 $v$ 样本子集 特征缺失样本划分 划分至所有节点，其权重设置为 $\\tilde {r_v} * w_x$ $\\tilde {r_v}$ 为节点 $v$ 的权重 即将特征缺失样本节点权重比例划分至各节点 剪枝树剪枝：在决策树的学习过程中，将已生成的树进行简化的过程 最小化 RSS、最大化置信目标下，会导致庞大的树 对训练数据拟合好 模型复杂度越高 推广能力差 比较难理解、解释 通过剪枝得到恰当的树，具备一定的预测精度、复杂程度恰当，代价（误差）和复杂度之间的权衡是必要的 Pre-pruning 预剪枝：在决策树分裂过程中，不分裂不满足分裂条件的节点，限制决策树充分生长 分裂条件 最大深度 叶节点数量 样本量最小值 异质性下降阈值 预剪枝基于“贪心”的禁止划分，可能降低过拟合、减少时间开销，但也可能导致欠拟合 Post-pruning 后剪枝：决策分裂完成后，根据一定规则剪去不具备普遍性的子树 比预剪枝决策保留更多分支，欠拟合风险小、泛化性能好 决策树生成局部模型，决策树剪枝学习整体模型 剪枝方法、程度对泛化性能影响显著，尤其是数据带有噪声 自底向上剪枝 自底向上剪去所有无法改善评价准则的非叶节点分支（转为叶节点） 最简单后剪枝策略 若已使用一定预剪策略，则该策略价值不大 特点 须在生成完全决策树之后自底向上逐个考察非叶节点，时间开销大 Minimal Cost Complexity Pruning\\begin{align*} C_\\alpha(T) & = C(T) + \\alpha |T| \\\\ & = \\sum_{t=1}^{|T|} N_t H_t(T) + \\alpha |T| \\\\ & = -\\sum_{t=1}^{|T|} \\sum_{k=1}^K \\frac {N_{t,k}} {N_t} log \\frac {N_{t,k}} {N_t} + \\alpha|T| \\\\ H_t(T) & = -\\sum_k (\\frac {N_{t,k}} {N_t} log \\frac {N_{t,k}} {N_t}) \\end{align*} $N_t$：树 $T$ 的第 $t$ 个叶子节点中样本点数量 $N_{t,k}$：树 $T$ 的第 $t$ 个叶子节点第 $k$ 类样本点数量 $H_t(T)$：树 $T$ 的第 $t$ 个叶子节点熵 $C(T)$：模型对训练数据的预测误差 $|T|$：用叶节点数量衡量的模型复杂度 $\\alpha \\geq 0$：控制模型复杂度对模型总损失影响，每个叶节点带来的复杂度 极小化损失复杂度剪枝 损失函数：正则化的极大似然函数 此策略即在给定 $\\alpha$ 的情况下，选择损失函数最小树 剪枝步骤 输入：生成算法产生的整个树 $T$，参数 $\\alpha$ 输出：修剪后的子数 $T_\\alpha$ 计算每个节点的经验熵 递归的从树的叶节点向上回缩 若 $C\\alpha(T{before}) \\geq C\\alpha(T{after})$，则剪枝 不断回缩直到根节点，选取损失函数最小的子树 $T_\\alpha$ 算法只需要比较节点、节点子树之间损失函数之差即可，计算可以在局部进行 算法可以由动态规划算法实现 超参选择 对给定超参 $\\alpha$，存在使损失函数 $C\\alpha(T)$ 最小子树 $T\\alpha$，且此最优子树唯一 $\\alpha$ 偏大时，最优子树 $T_\\alpha$ 偏小 $\\alpha=0$ 时完整树最优，$\\alpha \\rightarrow \\infty$ 时单节点树最优 对决策树种每个节点 $t$，通过以下策略生成 $g(t)$ $C_{\\alpha}(T^t) = C(T^t) + \\alpha|T^t|$：以 $t$ 为根节点的子树 $T^t$ 损失 $C_{\\alpha}(t) = C(t) + \\alpha$：对 $t$ 剪枝之后，仅包含单个节点 $t$ 的正则损失 则 $\\alpha=g(t) = \\frac {C(t)-C(T^t)} {|T^t|-1}$ 时，单节点 $t$ 和子树 $T^t$ 损失相同 考虑以上 $g(t)$ 序列 $\\alpha^t=g(t)$ 表示对 $T^{(0)}$ 中每个内部节点 $t$ 剪枝后，整体损失函数值减少程度 可以证明，对以上 $\\alpha &gt; 0$ 序列排序，按 $0, \\alpha^{(1)}, \\cdots, \\alpha^{(N)}$ 依次进行剪枝，对应最优子树序列 $T^{(0)}, T^{(1)},\\cdots, T^{(N)}$ 嵌套 通过交叉验证法在独立的验证数据集上对子树进行测试，选择最优决策树 完整剪枝+超参选择 输入：CART 算法生成决策树 $T^{(0)}$ 输出：最优决策树 $T_\\alpha$ 自下而上地计算各内部节点 $t$ 对应 $C(T^t), |T^t|, g(t)$，对 $g(t)$ 升序排列得到 $\\alpha^{(1)},\\cdots,\\alpha^{(N)}$ 置：$k=1, \\alpha=\\alpha^{(k)}, T=T^{(0)}$ 自上而下访问内部节点，若有 $g(t)=\\alpha$，剪枝并计算新叶节点 $t$ 取值，得到对应最优树 $T^{(k)}$ 对于节点 $t$，其子树 $T^t$ 最大有效 $\\alpha$ 也只是根节点对应 $g(t)$，更大没有价值 自上而下剪枝避免无效剪枝 置：$k+=1, \\alpha=\\alpha^{(k)}, T=T^{(k)}$ 若 $T$ 不是单节点树，则重复以上 采用交叉验证法在子树序列中选取最优子树 $T_\\alpha$ 也可从 $\\alpha \\leftarrow \\infty$ 开始，逐渐减少，添枝 得到子树序列 决策树构建算法 以下是一些经典的决策树（算法），但实际实现中往往不会严格按其构建决策树 决策树算法常用递归描述、构建，完全决策树中止条件如下 （往往不会应用，而是以预剪枝条件作为中止条件） 节点中样本属于同一类 所有特征利用完毕 无法找到满足划分阈值的特征、划分点 Iterative Dichotomiser 3步骤 输入：训练数据集 $D$，特征集 $A$，阈值 $\\epsilon$ 输出：决策树 $T$ 以下情况下 $T$ 为单节点树，以 $D$ 中实例数最大的类（众数） $C_k$ 作为该节点的类标记，返回 $T$ $D$ 中所有实例属于同一类 $C_k$ $A = \\varnothing$ 计算 $A$ 中各特征对 $D$ 的信息增益，选择信息增益最大的特征 $A_g$ 若 $A_g$ 的信息增益小于阈值 $\\epsilon$，则置 $T$ 为单节点树，并将 $D$ 中实例数最大的类 $C_k$ 作为节点类标记，返回 $T$ 否则，对 $A_g$ 每个可能值 $a_m$，将 $D$ 分割为若干非空子集 $D_i$ 将 $D_i$ 中实例数最多的类作为标记，构建子节点 对第 $i$ 个子节点，以 $D_i$ 为训练集，以 $A-{A_g}$ 为特征集，递归的构造子树 $T_i$ 并返回 特点 只允许分类型特征，且每个特征只会被用于划分一次 每次所有取值都会被用于建立子节点 ID3 树是多叉树，各个节点的分叉个数取决于使用特征 只有树的生成，容易产生过拟合 以信息增益作为划分训练数据集的特征，倾向于选择取值较多的特征进行划分 理论上若特征取值严格符合分布，取值数量多寡，对信息增益没有影响 由于各种误差的存在，样本不可能严格符合总体分布，取值数量较多特征，各取值对应样本数量较少，误差会使得条件经验熵倾向于偏小 （假设误差随机，可以大概证明） 相当于用 极大似然法 进行概率模型的选择 C4.5C4.5算法：ID3 算法继承者 与 ID3 差别 用信息增益比代替信息增益用于选择特征，并且也被用于 前剪枝 修正 ID3 倾向于使用取值较多的特征值分裂结点 兼容数值型特征，使用二分法处理 C4.5 算法还包含 C4.5Rules 将 C4.5 决策树转化为符号规则 - 各分支被重写为规则，并进行前件合并、删减 最终规则集泛化性能可能优于原决策树 Classification and Regression TreeCART 树：可用于分类和回归的二叉树 特点 二叉树 可以用于分类、回归 分类：众数代表节点，GINI 指数选择特征 回归：均值代表节点，MSE 选择特征 能较好的处理缺失值 CART 回归：平方误差最小化准则 f(x) = \\sum_{m=1} \\hat c_m I(x \\in R_m) $R_m$：空间划分出的第 $m$ 单元 $\\hat c_m=avg(y_i|x_i \\in R_m)$：第 $m$ 个单元上所有实例输出变量均值，此时平方误差最小 CART 分类：最小化基尼指数准则 Gini(D, X=a) = \\frac {|D_1|} {|D|} Gini(D_1) + \\frac {|D_2|} {|D|} Gini(D_2) $D_1 = {(x,y) \\in D, X = a}$ $D_2 = D - D_1$ CART 树是二叉树，对分类变量只选择是否 CART回归步骤 输入：训练数据集 $D$ 输出：回归树 $f(x)$ 选择最优切变量 $j$、切分点 $s$，即求解 \\arg\\min_{j,s} [\\min_{c_1} \\sum_{x_i \\in R_1(j,s)} (y_i - c_1)^2 + \\min_{c_2} \\sum_{x_i \\in R_2(j,s)} (y_i - c_2)^2 ] $R_1(j,s) = {x|x^{(j)} \\leq s}$ $R_2(j,s) = {x|x^{(j)} \\geq s}$ $c_m = avg(y_i|x_i \\in R_m)$：使得区域 $R_m$ 中平方误差最小，即其中样本点 $y_i$ 均值 这里通过 遍历 得到 对两个子区域 $R_1(j,s), R_2(j,s)$ 继续重复以上步骤，直至满足停止条件 将输入空间划分为 $M$ 个区域 $R_1, R_2, \\cdots, R_M$，生成决策 树 f(x) = \\sum_{m=1} \\hat c_m I(x \\in R_m) CART 分类步骤 输入：训练数据集 $D$，停止计算条件 输出：CART 决策树 选择最优切变量 $j$、切分点 $s$ Gini(D, X=a) = \\frac {|D_1|} {|D|} Gini(D_1) + \\frac {|D_2|} {|D|} Gini(D_2) 对每个特征 $X$，对其所有取值 $a$ 计算条件基尼指数 选择条件基尼指数最小的特征、对应的切分点，将训练数据依特征分配到两个子结点中 对生成两个子节点递归分裂，直至满足停止条件 生成 CART 决策树 Chi-squared Automatic Interaction DetectorCHAID 卡方自动交叉检验法：类似 ID3 算法，但利用卡方统计确定特征变量 https://wenku.baidu.com/view/bdd3e60abed5b9f3f90f1cd6.html https://sefiks.com/2020/03/18/a-step-by-step-chaid-decision-tree-example/ 特点 通过卡方统计量选择最显著特征变量作为划分特征 分类目标变量：列联分析，卡方检验 数值目标变量：回归分析，F检验 特征预处理 分类型特征变量：根据卡方统计量显著性、组数量等考虑拆分、合并分组 数值型特征变量：均分分组 是从相关性显著角度确定特征变量 对决策树分支优化明显 可用特征变量与目标相关性显著显著性作为停止分裂的标准 QUESTQuick Unbiased Efficient Statical Tree：类似 CHAID 算法，但对选择特征、划分点依据不同，仅能处理分类目标变量 特点 类似 CHAID，选择最显著（p 值）的特征变量作为划分特征 分类特征变量：连列分析，卡方检验 数值特征变量：方差分析，F检验 划分点选择 分类特征变量：映射为 one-hot 向量后，用判别分析求解划分向量，再映射回划分取值 目标变量多分类 为每个类别计算特征均值，使用均值聚类将其简化为二分类 只需要为节点内样本的、用待划分特征计算均值 运行速度快于 CART 树 http://www.mclover.cn/blog/index.php/archives/60.html http://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n41.pdf","link":"/ML-Model/Nolinear-Model/decision_tree.html"},{"title":"EM算法","text":"总述expectation maximization algorithm：含有隐变量的概率模型 参数的极大似然估计法、极大后验概率估计法 模型含有latent variable（潜在变量）、hidden variable （隐变量）似然函数将没有解析解 所以EM算法需要迭代求解，每次迭代由两步组成 E步：求期望expectation M步：求极大maximization 模型变量都是observable variable、给定数据情况下，可以 直接使用极大似然估计、贝叶斯估计 EM算法对含有隐变量的概率模型，目标是极大化观测数据（不完全数据） $Y$关于参数$\\theta$的对数似然函数，即极大化 \\begin{align*} L(\\theta) & = log P(Y|\\theta) \\\\ & = log \\sum_Z P(Y, Z|\\theta) \\\\ & = log \\left(\\sum_Z P(Y|Z,\\theta) P(Z|\\theta) \\right) \\end{align*} $Y$：观测变量数据 $Z$：隐随机变量数据（未知） $Y,Z$合在一起称为完全数据 $P(Y,Z|\\theta)$：联合分布 $P(Z|Y,\\theta)$：条件分布 但是极大化目标函数中包括未观测数据$Z$、求和（积分）的 对数，直接求极大化非常困难 EM算法通过迭代逐步近似极大化$L(\\theta)$ 推导 假设第i次迭代后$\\theta$的估计值是$\\theta^{(i)}$，希望 新估计值$\\theta$能使$L(\\theta)$增加，并逐步增加到极大值 ，考虑两者之差 L(\\theta) - L(\\theta^{(i)}) = log (\\sum_Z P(Y|Z,\\theta) P(Z|\\theta)) - log P(Y|\\theta^{(i)}) 利用Jensen不等式有 \\begin{align*} L(\\theta) - L(|\\theta^{(i)}) & = log(\\sum_Z P(Y|Z, \\theta^{(i)}) \\frac {P(Y|Z,\\theta) P(Z|\\theta)} {P(Y|Z,\\theta^{(i)})}) - log P(Y|\\theta^{(i)}) \\\\ & \\geq \\sum_Z P(Z|Y,\\theta^{(i)}) log \\frac {P(Y|Z,\\theta) P(Z|\\theta)} {P(Z|Y,\\theta^{(i)})} - log P(Y|\\theta^{(i)}) \\\\ & = \\sum_z P(Z|Y,\\theta^{(i)}) log \\frac {P(Y|Z,\\theta) P(Z|\\theta)} {P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})} \\end{align*} 令 B(\\theta, \\theta^{(i)}) = L(\\theta^{(i)}) + \\sum_Z P(Z|Y,\\theta^{(i)}) log \\frac {P(Y|Z,\\theta) P(Z|\\theta)} {P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}则$B(\\theta, \\theta^{(i)})$是$L(\\theta)$的一个下界，即 \\begin{align*} L(\\theta) & \\geq B(\\theta, \\theta^{(i)}) \\\\ \\end{align*}并根据$B(\\theta, \\theta^{(i)})$定义有 \\begin{align*} L(\\theta^{(i)}) = B(\\theta^{(i)}, \\theta^{(i)}) \\end{align*} 则任意$\\theta$满足 $B(\\theta,\\theta^{(i)}) &gt; B(\\theta^{(i)},\\theta^{(i)})$ ，将满足$L(\\theta) &gt; L(\\theta^{(i)})$，应选择 $\\theta^{(i+1)}$使得$B(\\theta,\\theta^{(i)})$达到极大 \\begin{align*} \\theta^{(i+1)} & = \\arg\\max_{\\theta} B(\\theta,\\theta^{(i)}) \\\\ & = \\arg\\max_{\\theta} L(\\theta^{(i)}) + \\sum_Z P(Z|Y,\\theta^{(i)}) log \\frac {P(Y|Z,\\theta) P(Z|\\theta)} {P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})} \\\\ & = \\arg\\max_{\\theta} (\\sum_Z P(Z|Y,\\theta^{(i)}) log(P(Y|Z,\\theta)P(Z|\\theta))) \\\\ & = \\arg\\max_{\\theta} (\\sum_Z P(Z|Y,\\theta^{(i)}) log P(Y,Z|\\theta)) \\\\ & = \\arg\\max_{\\theta} Q(\\theta, \\theta^{(i)}) \\end{align*} 和$\\theta$无关的常数项全部舍去 $Q(\\theta, \\theta^{(i)})$：Q函数，完全数据的对数似然函数 $logP(Y,Z|\\theta)$，关于在给定观测$Y$和当前参数 $\\theta^{(i)}$下，对未观测数据Z的条件概率分布 $P(Z|Y,\\theta^{(i)})$ Q(\\theta, \\theta^{(i)}) = E_z [logP(Y,Z|\\theta)|Y,\\theta^{(i)}] 算法 选择参数初值$\\theta^{0}$，开始迭代 E步：记$\\theta^{(i)}$为第$i$迭代时，参数$\\theta$的估计值 ，在第$i+1$步迭代的E步时，计算Q函数 $Q(\\theta, \\theta^{(i)})$ M步：求使得Q函数极大化$\\theta$作为第$i+1$次估计值 $\\theta^{(i+1)}$ \\theta^{(i+1)} = \\arg\\max_{\\theta} Q(\\theta, \\theta^{(i)}) 重复E步、M步直到待估参数收敛 算法初值可以任意选择，但EM算法对初值敏感 E步：参数值估计缺失值分布，计算Q函数（似然函数） M步：Q函数取极大得新参数估计值 收敛条件一般是对较小正数$\\epsilon$，满足 $|\\theta^{(i+1)} - \\theta^{(i)}| &lt; \\epsilon$或 $|Q(\\theta^{(i+1)},\\theta^{(i)}) - Q(\\theta^{(i)},\\theta^{(i)})| &lt; \\epsilon$ EM算法特点EM算法优点 EM算法可以用于估计含有隐变量的模型参数 非常简单，稳定上升的步骤能非常可靠的找到最优估计值 应用广泛，能应用在多个领域中 生成模型的非监督学习 EM算法缺点 EM算法计算复杂、受外较慢，不适合高维数据、大规模数据集 参数估计结果依赖初值，不够稳定，不能保证找到全局最优解 算法收敛性定理1 设$P(Y|\\theta)$为观测数据的似然函数，$\\theta^{(i)}$为 EM算法得到的参数估计序列，$P(Y|\\theta^{(i)}),i=1,2,…$ 为对应的似然函数序列，则$P(Y|\\theta^{(i)})$是单调递增的 P(Y|\\theta^{(i+1)}) \\geq P(Y|\\theta^{(i)}) 由条件概率 \\begin{align*} P(Y|\\theta) & = \\frac {P(Y,Z|\\theta)} {P(Z|Y,\\theta)} \\\\ logP(Y|\\theta) & = logP(Y,Z|\\theta) - logP(Z|Y,\\theta) \\end{align*} 则对数似然函数有 logP(Y|\\theta) = Q(\\theta, \\theta^{(i)}) - H(\\theta, \\theta^{(i)}) $H(\\theta, \\theta^{(i)}) = \\sum_Z log P(Z|Y,\\theta) P(Z|Y,\\theta)$ $Q(\\theta, \\theta^{(i)})$：前述Q函数 $logP(Y|\\theta)$和$Z$无关，可以直接提出 分别取$\\theta^{(i+1)}, \\theta^{(i)}$带入，做差 logP(Y|\\theta^{(i+1)}) - logP(Y|\\theta^{(i)}) = [Q(\\theta^{(i+1)}, \\theta^{(i)}) - Q(\\theta^{(i)}, \\theta^{(i)}] - [H(\\theta^{(i+1)}, \\theta^{(i)}) - H(\\theta^{(i)}, \\theta^{(i)})] $\\theta^{(i+1)}$使得$Q(\\theta, \\theta^{(i)})$取极大 又有 \\begin{align*} & H(\\theta^{(i+1)}, \\theta^{(i)}) - H(\\theta^{(i)}, \\theta^{(i)}) \\\\ = & \\sum_Z (log \\frac {P(Z|Y,\\theta^{(i+1)})} {P(Z|Y,\\theta^{(I)})}) P(Z|Y,\\theta^{(i)}) \\\\ \\leq & log (\\sum_Z \\frac {P(Z|Y,\\theta^{(i+1)})} {P(Z|Y,\\theta^{(I)})} P(Z|Y,\\theta^{(i)})) \\\\ = & log \\sum_Z P(Z|Y,\\theta^{(i+1)}) = 0 \\end{align*} 定理2 设$L(\\theta)=log P(Y|\\theta)$为观测数据的对数似然函数， $\\theta^{(i)},i=1,2,…$为EM算法得到的参数估计序列， $L(\\theta^{(i)}),i=1,2,…$为对应的对数似然函数序列 若$P(Y|\\theta)$有上界，则$L(\\theta^{(i)})$收敛到某 定值$L^{*}$ Q函数$Q(\\theta, \\theta^{‘})$与$L(\\theta)$满足一定 条件的情况下，由EM算法得到的参数估计序列 $\\theta^{(i)}$的收敛值$\\theta^{*}$是$L(\\theta)$的 稳定点 结论1由序列单调、有界显然 Q函数$Q(\\theta, \\theta^{‘})$与$L(\\theta)$的条件在大多数 情况下是满足的 EM算法收敛性包含对数似然序列$L(\\theta^{(i)})$、参数估计 序列$\\theta^{(i)}$的收敛性，前者不蕴含后者 此定理只能保证参数估计序列收敛到对数似然序列的稳定点， 不能保证收敛到极大点，可选取多个不同初值迭代，从多个结果 中选择最好的 Gaussion Mixture Model 高斯混合模型是指具有如下概率分布模型 P(y|\\theta) = \\sum_{k=1}^K \\alpha_k \\phi(y|\\theta_k) $\\alphak \\geq 0, \\sum{k=1}^K \\alpha_k=1$：系数 $\\phi(y|\\theta_k)$：高斯分布密度函数 $\\theta_k=(\\mu_k, \\sigma_k)$：第k个分模型参数 用EM算法估计高斯混合模型参数 $\\theta=(\\alpha_1,…,\\alpha_2,\\theta_1,…,\\theta_K)$ 推导明确隐变量明确隐变量，写出完全数据对数似然函数 反映观测数据$y_j$来自第k个分模型的数据是未知的 \\gamma_{j,k} = \\left \\{ \\begin{array}{l} 1, & 第j个观测来自第k个分模型 \\\\ 0, & 否则 \\end{array} \\right. $j=1,2,\\cdots,N$：观测编号 $k=1,2,\\cdots,K$：模型编号 则完全数据为 (y_j,\\gamma_{j,1},\\cdots,\\gamma_{j,K}), j=1,2,...,N 完全数据似然函数为 \\begin{align*} P(y,\\gamma|\\theta) & = \\prod_{j=1}^N P(y_j,\\gamma_{j,1},\\cdots,\\gamma_{j,N}|\\theta) \\\\ & = \\prod_{k=1}^{K} \\prod_{j=1}^N [\\alpha_k \\phi(y_j|\\theta_k)]^{\\gamma _{j,k}} \\\\ & = \\prod_{k=1}^{K} \\alpha_k^{n_k} \\prod_{j=1}^N [\\phi(y_j|\\theta_k)]^{\\gamma _{j,k}} \\\\ \\end{align*} $nk = \\sum{j=1}^{N} \\gamma_{j,k}$ $\\sum_{k=1}^K n_k = N$ 完全数据的对数似然函数为 logP(y, \\gamma|\\theta) = \\sum_{k=1}^K \\left \\{ n_k log \\alpha_k + \\sum_{j=1}^N \\gamma_{j,k} [log \\frac 1 {\\sqrt {2\\pi}} - log \\sigma_k - \\frac 1 {2\\sigma_k}(y_j - \\mu_k)^2] \\right \\} E步：确定Q函数\\begin{align*} Q(\\theta, \\theta^{(i)}) & = E_z[logP(y,\\gamma|\\theta)|Y,\\theta^{(i)}] \\\\ & = E \\sum_{k=1}^K \\left \\{ n_k log\\alpha_k + \\sum_{j=1}^N \\gamma_{j,k} [log \\frac 1 {\\sqrt {2\\pi}} - log \\sigma_k - \\frac 1 {2\\sigma_k}(y_j - \\mu_k)^2] \\right \\} \\\\ & = \\sum_{k=1}^K \\left \\{ \\sum_{k=1}^K (E\\gamma_{j,k}) log\\alpha_k + \\sum_{j=1}^N (E\\gamma_{j,k}) [log \\frac 1 {\\sqrt {2\\pi}} - log \\sigma_k - \\frac 1 {2\\sigma_k}(y_j - \\mu_k)^2] \\right \\} \\end{align*} $E\\gamma{j,k} = E(\\gamma{j,k}|y,\\theta)$：记为 $\\hat \\gamma_{j,k}$ \\begin{align*} \\hat \\gamma_{j,k} & = E(\\gamma_{j,k}|y,\\theta) = P(\\gamma_{j,k}|y,\\theta) \\\\ & = \\frac {P(\\gamma_{j,k}=1, y_j|\\theta)} {\\sum_{k=1}^K P(\\gamma_{j,k}=1,y_j|\\theta)} \\\\ & = \\frac {P(y_j|\\gamma_{j,k}=1,\\theta) P(\\gamma_{j,k}=1|\\theta)} {\\sum_{k=1}^K P(y_j|\\gamma_{j,k}=1,\\theta) P(\\gamma_{j,k}|\\theta)} \\\\ & = \\frac {\\alpha_k \\phi(y_j|\\theta _k)} {\\sum_{k=1}^K \\alpha_k \\phi(y_j|\\theta_k)} \\end{align*}带入可得 Q(\\theta, \\theta^{(i)}) = \\sum_{k=1}^K \\left\\{ n_k log\\alpha_k + \\sum_{k=1}^N \\hat \\gamma_{j,k} [log \\frac 1 {\\sqrt{2\\pi}} - log \\sigma_k - \\frac 1 {2\\sigma^2}(y_j - \\mu_k)^2] \\right \\}M步求新一轮模型参数 $\\theta^{(i+1)}=(\\hat \\alpha_1,…,\\hat \\alpha_2,\\hat \\theta_1,…,\\hat \\theta_K)$ \\begin{align*} \\theta^{(i+1)} & = \\arg\\max_{\\theta} Q(\\theta,\\theta^{(i)}) \\\\ \\hat \\mu_k & = \\frac {\\sum_{j=1}^N \\hat \\gamma_{j,k} y_j} {\\sum_{j=1}^N \\hat \\gamma_{j,k}} \\\\ \\hat \\sigma_k^2 & = \\frac {\\sum_{j=1}^N \\hat \\gamma_{j,k} (y_j - \\mu_p)^2} {\\sum_{j=1}^N \\hat \\gamma_{j,k}} \\\\ \\hat \\alpha_k & = \\frac {n_k} N = \\frac {\\sum_{j=1}^N \\hat \\gamma_{j,k}} N \\end{align*} $\\hat \\theta_k = (\\hat \\mu_k, \\hat \\sigma_k^2)$：直接求 偏导置0即可得 $\\hat \\alphak$：在$\\sum{k=1}^K \\alpha_k = 1$条件下求 偏导置0求得 算法 输入：观测数据$y_1, y_2,\\cdots, y_N$，N个高斯混合模型 输出：高斯混合模型参数 取参数初始值开始迭代 E步：依据当前模型参数，计算分模型k对观测数据$y_j$响应度 \\hat \\gamma_{j,k} = \\frac {\\alpha \\phi(y_k|\\theta_k)} {\\sum_{k=1}^N \\alpha_k \\phi(y_j|\\theta)} M步：计算新一轮迭代的模型参数 $\\hat mu_k, \\hat \\sigma_k^2, \\hat \\alpha_k$ 重复2、3直到收敛 GMM模型的参数估计的EM算法非常类似K-Means算法 E步类似于K-Means中计算各点和各聚类中心之间距离，不过 K-Means将点归类为离其最近类，而EM算法则是算期望 M步根据聚类结果更新聚类中心 GEMMaximization-Maximization AlgorithmFree Energy函数 假设隐变量数据Z的概率分布为$\\tilde P(Z)$，定义分布 $\\tilde P$与参数$\\theta$的函数$F(\\tilde P, \\theta)$如下 F(\\tilde P, \\theta) = E_{\\tilde P} [log P(Y,Z|\\theta)] + H(\\tilde P) $H(\\tilde P)=-E_{\\tilde P} log \\tilde P(Z)$：分布 $\\tilde P(Z)$的熵 通常假设$P(Y,Z|\\theta)$是$\\theta$的连续函数，则函数 $F(\\tilde P,\\theta)$是$\\tilde P, \\theta$的连续函数 定理1 对于固定$\\theta$，存在唯一分布$\\tilde P\\theta$，极大化 $F(\\tilde P, \\theta)$，这时$\\tilde P\\theta$由下式给出 \\tilde P_\\theta(Z) = P(Z|Y,\\theta) 并且$\\tilde P_{\\theta}$随$\\theta$连续变化 对于固定的$\\theta$，求使得$F(\\tilde P, \\theta)$的极大， 构造Lagrange函数 L(\\tilde P, \\lambda, \\mu) = F(\\tilde P, \\theta) + \\lambda(1 - \\sum_Z \\tilde P(Z)) - \\mu \\tilde P(Z)因为$\\tilde P(Z)$是概率密度，自然包含两个约束 \\left \\{ \\begin{array}{l} \\sum_Z \\tilde P(Z) = 1 \\\\ \\tilde P(Z) \\geq 0 \\end{array} \\right.即Lagrange方程中后两项 对$\\tilde P(Z)$求偏导，得 \\frac {\\partial L} {\\partial \\tilde P(Z)} = log P(Y,Z|\\theta) - log \\tilde P(Z) - \\lambda - \\mu令偏导为0，有 \\begin{align*} log P(Y,Z|\\theta) - log \\tilde P(Z) & = \\lambda + \\mu \\\\ \\frac {P(Y,Z|\\theta)} {\\tilde P(Z)} & = e^{\\lambda + \\mu} \\end{align*} 则使得$F(\\tilde P, \\theta)$极大的$\\tilde P_\\theta(Z)$ 应该和$P(Y,Z|\\theta)$成比例，由概率密度自然约束有 \\tilde P_\\theta(Z) = P(Y,Z|\\theta)而由假设条件，$P(Y,Z|\\theta)$是$\\theta$的连续函数 这里概率密度函数$\\tilde P(Z)$是作为自变量出现 理论上对$\\tilde P(Z)$和一般的复合函数求导没有区别， 但$E_{\\tilde P}, \\sum_Z$使得整体看起来非常不和谐 \\begin{align*} E_{\\tilde P} f(Z) & = \\sum_Z f(Z) \\tilde P(Z) \\\\ & = \\int f(Z) d(\\tilde P(Z)) \\end{align*} 定理2 若$\\tilde P_\\theta(Z) = P(Z|Y, \\theta)$，则 F(\\tilde P, \\theta) = log P(Y|\\theta) 定理3 设$L(\\theta)=log P(Y|\\theta)$为观测数据的对数似然函数， $\\theta^{(i)}, i=1,2,\\cdots$为EM算法得到的参数估计序列， 函数$F(\\tilde P,\\theta)$如上定义 若$F(\\tilde P,\\theta)$在$\\tilde P^{}, \\theta^{}$ 上有局部极大值，则$L(\\theta)$在$\\theta^{*}$也有局部 最大值 若$F(\\tilde P,\\theta)$在$\\tilde P^{}, \\theta^{}$ 达到全局最大，则$L(\\theta)$在$\\theta^{*}$也达到全局 最大 由定理1、定理2有 L(\\theta) = logP(Y|\\theta) = F(\\tilde P_\\theta, \\theta)特别的，对于使$F(\\tilde P,\\theta)$极大$\\theta^{8}$有 L(\\theta^{*}) = logP(Y|\\theta^{*}) = F(\\tilde P_\\theta^{*}, \\theta{*}) 由$\\tilde P_\\theta$关于$\\theta$连续，局部点域内不存在点 $\\theta^{}$使得$L(\\theta^{}) &gt; L(\\theta^{})$，否则 与$F(\\tilde P, \\theta^{})$矛盾 定理4 EM算法的依次迭代可由F函数的极大-极大算法实现 设$\\theta^{(i)}$为第i次迭代参数$\\theta$的估计， $\\tilde P^{(i)}$为第i次迭代参数$\\tilde P$的估计，在第 i+1次迭代的两步为 对固定的$\\theta^{(i)}$，求$\\tilde P^{(i)}$使得 $F(\\tilde P, \\theta^{(i)})$极大 对固定的$\\tilde P^{(i+1)}$，求$\\theta^{(i+1)}$使 $F(\\tilde P^{(t+1)}, \\theta)$极大化 固定$\\theta^{(i)}$ \\begin{align*} F(\\tilde P^{(i+1)}, \\theta^{(i)} & = E_{\\tilde P^{(t+1)}} [log P(Y,Z|\\theta)] + H(\\tilde P^{(i+1)}) \\\\ & = \\sum_Z log P(Y,Z|\\theta) P(Z|Y,\\theta^{(i)}) + H(\\tilde P^{(i+1)}) \\\\ & = Q(\\theta, \\theta^{(i)}) + H(\\tilde P^{(i+1)}) \\end{align*} 则固定$\\tilde P^{(i+1)}$求极大同EM算法M步 GEM算法 输入：观测数据，F函数 输出：模型参数 初始化$\\theta^{(0)}$，开始迭代 第i+1次迭代：记$\\theta^{(i)}$为参数$\\theta$的估计值， $\\tilde P^{(i)}$为函数$\\tilde P$的估计，求 $\\tilde P^{(t+1)}$使$\\tilde P$极大化$F(\\tilde P,\\theta)$ 求$\\theta^{(t+1)}$使$F(\\tilde P^{(t+1)l}, \\theta)$极大化 重复2、3直到收敛 次优解代替最优解 输入：观测数据，Q函数 输出：模型参数 初始化参数$\\theta^{(0)}$，开始迭代 第i+1次迭代，记$\\theta^{(i)}$为参数$\\theta$的估计值， 计算 \\begin{align*} Q(\\theta, \\theta^{(i)}) & = E_Z [ log P(Y,Z|\\theta)|Y,\\theta^{(i)}] \\\\ & = \\sum_Z P(Z|Y, \\theta^{(i)}) log P(Y,Z|\\theta) \\end{align*} 求$\\theta^{(i+1)}$使 Q(\\theta^{(i+1)}, \\theta^{(i)}) > Q(\\theta^{(i)}, \\theta^{(i)}) 重复2、3直到收敛 有时候极大化$Q(\\theta, \\theta^{(i)})$非常困难，此算法 仅寻找使目标函数值上升方向 ADMM求次优解 输入：观测数据，Q函数 输出：函数模型 初始化参数 $\\theta^{(0)} = (\\theta_1^{(0)},…,\\theta_d^{(0)})$， 开始迭代 第i次迭代，记 $\\theta^{(i)} = (\\theta_1^{(i)},…,\\theta_d^{(i)})$， 为参数$\\theta = (\\theta_1,…,\\theta_d)$的估计值，计算 \\begin{align*} Q(\\theta, \\theta^{(i)}) & = E_Z [ log P(Y,Z|\\theta)|Y,\\theta^{(i)}] \\\\ & = \\sum_Z P(Z|Y, \\theta^{(i)}) log P(Y,Z|\\theta) \\end{align*} 进行d次条件极大化 在$\\theta1^{(i)},…,\\theta{j-1}^{(i)},\\theta_{j+1}^{(i)},…,\\theta_d^{(i)}$ 保持不变条件下 ，求使$Q(\\theta, \\theta^{(i)})$达到极大的 $\\theta_j^{(i+1)}$ j从1到d，进行d次条件极大化的，得到 $\\theta^{(i+1)} = (\\theta_1^{(i+1)},…,\\theta_d^{(i+1)})$ 使得 Q(\\theta^{(i+1)}, \\theta^{(i)}) > Q(\\theta^{(i)}, \\theta^{(i)}) 重复2、3直到收敛","link":"/ML-Model/Unsupervised-Model/expectation_maximization.html"},{"title":"Boosting","text":"Gredient BoostingGB：（利用）梯度提升，将提升问题视为优化问题，前向分步算法 利用最速下降思想实现 一阶展开拟合损失函数，沿负梯度方向迭代更新 损失函数中，模型的样本预测值$f(x)$是因变量 即$f(x)$应该沿着损失函数负梯度方向变化 即下个基学习器应该以负梯度方向作为优化目标，即负梯度 作为伪残差 类似复合函数求导 对基学习器预测值求解最优加权系数 最速下降法中求解更新步长体现 前向分布算法中求解基学习器权重 损失函数基学习器拟合目标：损失函数的负梯度在当前模型的值 -\\left [ \\frac {\\partial L(y, \\hat y_i)} {\\partial y_i} \\right ]_{\\hat y_i=\\hat y_i^{(t-1)}}平方损失平方损失：$L(y, f(x)) = \\frac 1 2 (y - f(x))^2$（回归） 第m-1个基学习器伪残差为 r_{m,i} = y_i - f_{m-1}(x_i), i=1,2,\\cdots,N $N$：样本数量 第m个基学习器为 \\begin{align*} h_m & = \\arg\\min_h \\sum_{i=1}^N \\frac 1 2 (y_i - (f_{m-1}(x_i) + h(x)))^2 \\\\ & = \\arg\\min_h \\sum_{i=1}^N \\frac 1 2 (C_{m,i} - h(x))^2 \\\\ C_{m,i} & = y_i - f_{m-1}(x_i) \\end{align*} 第m轮学习器组合为 f_m = f_{m-1} + \\alpha_m h_m $\\alpha_m$：学习率，留给之后基模型学习空间 这里只是形式上表示模型叠加，实际上树模型等不可加， 应该是模型预测结果叠加 指数损失指数损失：$L(y, f(x)) = e^{-y f(x)}$（分类） 第m-1个基学习器伪残差 r_{m,i} = -y_i e^{-y_i f_{m-1}(x_i)}, i=1,2,\\cdots,N 基学习器、权重为 \\begin{align*} h_m & = \\arg\\min_h \\sum_{i=1}^N exp(-y_i(f_{m-1}(x_i) + \\alpha f(x_i))) \\\\ & = \\arg\\min_h \\sum_{i=1}^N C_{m,i} exp(-y_i \\alpha f(x_i)) \\\\ C_{m,i} & = exp(-y_i f_{m-1}(x_i)) \\end{align*} 第m轮学习器组合为 f_m = f_{m-1} + \\alpha_m h_m 步骤 输入：训练数据集$T={(x_1, y_1), \\cdots, (x_N, y_N)}$， 损失函数$L(y, f(x))$ $x_i \\in \\mathcal{X \\subset R^n}$ $y_i \\in \\mathcal{Y} = {-1, +1 }$ 输出：回归树$\\hat f(x)$ 初始化模型 \\hat y_i^{(0)} = \\arg\\min_{\\hat y} \\sum_{i=1}^N L(y_i, \\hat y) 对$m=1,2,\\cdots,M$（即训练M个若分类器） 计算伪残差 r_i^{(t)} = -\\left [ \\frac {\\partial L(y, \\hat y_i)} {\\partial y_i} \\right ]_{\\hat y_i=\\hat y_i^{(t-1)}} 基于${(x_i, r_i^{(t)})}$生成基学习器$h_t(x)$ 计算最优系数 \\gamma = \\arg\\min_\\gamma \\sum_{i=1}^N L(y_i, \\hat y_i^{(t-1)} + \\gamma h_t(x_i)) 更新预测值 \\hat y_i^{(t)} = \\hat y_i^{(t-1)} + \\gamma_t h_t (x) 得到最终模型 \\hat f(x) = f_M(x) = \\sum_{t=1}^M \\gamma_t h_t(x) Gradient Boosted Desicion TreeGBDT：梯度提升树，以回归树为基学习器的梯度提升方法 GBDT会累加所有树的结果，本质上是回归模型（毕竟梯度） 所以一般使用CART回归树做基学习器 当然可以实现分类效果 损失函数为平方损失（毕竟回归），则相应伪损失/残差 r_{t,i} = y_i - f_{t-1}(x_i), i=1,2,\\cdots,N 特点 准确率、效率相较于RF有一定提升 能够灵活的处理多类型数据 Boosting类算法固有的基学习器之间存在依赖，难以并行训练 数据，比较可行的并行方案是在每轮选取最优特征切分时，并行 处理特征 XGBoostExtreme Gradient Boost/Newton Boosting：前向分步算法利用 Newton法思想实现 二阶展开拟合损失函数 损失函数中，模型的样本预测值$\\hat y_i$是因变量 将损失函数对$\\hat y_i$二阶展开拟合 求解使得损失函数最小参数 对基学习器预测值求解最优加权系数 阻尼Newton法求解更新步长体现 前向分布算法中求解基学习器权重 削弱单个基学习器影响，让后续基学习器有更大学习空间 损失函数 第t个基分类器损失函数 \\begin{align*} obj^{(t)} & = \\sum_{i=1}^N l(y_i, \\hat y_i^{(t)}) + \\Omega(f_t) \\\\ & = \\sum_i^N l(y_i, \\hat y_i^{(t-1)} + f_t(x_i)) + \\Omega(f_t) \\\\ & \\approx \\sum_{i=1}^N [l(y_i, \\hat y^{(t-1)}) + g_i f_t(x_i) + \\frac 1 2 h_i f_t^2(x_i)] + \\Omega(f_t) \\\\ & = \\sum_{i=1}^N [l(y_i, \\hat y^{(t-1)}) + g_i f_t(x_i) + \\frac 1 2 h_i f_t^2(x_i)] + \\gamma T_t + \\frac 1 2 \\lambda \\sum_{j=1}^T {w_j^{(t)}}^2 \\\\ \\Omega(f_t) & = \\gamma T_t + \\frac 1 2 \\lambda \\sum_{j=1}^T {w_j^{(t)}}^2 \\end{align*} $f_t$：第t个基学习器 $f_t(x_i)$：第t个基学习器对样本$x_i$的取值 $gi = \\partial{\\hat y} l(y_i, \\hat y^{t-1})$ $hi = \\partial^2{\\hat y} l(y_i, \\hat y^{t-1})$ $\\Omega(f_t)$：单个基学习器的复杂度罚 $T_t$：第t个基学习器参数数量，即$L_0$罚 线性回归基学习器：回归系数数量 回归树基学习器：叶子节点数目 $\\gamma$：基学习器$L_0$罚系数，模型复杂度惩罚系数 $w_j = f_t$：第t个基学习器参数值，即$L_2$罚 线性回归基学习器：回归系数值 回归树基学习器：叶子节点 $\\lambda$：基学习器$L_2$罚系数，模型贡献惩罚系数 $\\approx$：由二阶泰勒展开近似 对损失函数进行二阶泰勒展开（类似牛顿法）拟合原损失函数， 同时利用一阶、二阶导数求解下个迭代点 正则项以控制模型复杂度 降低模型估计误差，避免过拟合 $L_2$正则项也控制基学习器的学习量，给后续学习器留下 学习空间 树基学习器XGBoost Tree：以回归树为基学习器的XGBoost模型 模型结构说明 基学习器类型：CART 叶子节点取值作惩罚：各叶子节点取值差别不应过大，否则 说明模型不稳定，稍微改变输入值即导致输出剧烈变化 树复杂度惩罚：叶子结点数量 XGBoost最终损失（结构风险）有 \\begin{align*} R_{srm} & = \\sum_{i=1}^N l(y_i, \\hat y_i) + \\sum_{t=1}^M \\Omega(f_t) \\end{align*} $N, M$：样本量、基学习器数量 $\\hat y_i$：样本$i$最终预测结果 损失函数 以树作基学习器时，第$t$基学习器损失函数为 \\begin{align*} obj^{(t)} & = \\sum_{i=1}^N l(y_i, \\hat y_i^{(t)}) + \\Omega(f_t) \\\\ & \\approx \\sum_{i=1}^N [l(y_i, \\hat y^{(t-1)}) + g_i f_t(x_i) + \\frac 1 2 h_i f_t^2(x_i)] + \\gamma T_t + \\frac 1 2 \\lambda \\sum_{j=1}^T {w_j^{(t)}}^2 \\\\ & = \\sum_{j=1}^{T_t} [(\\sum_{i \\in I_j} g_i) w_j^{(t)} + \\frac 1 2 (\\sum_{i \\in I_j} h_i + \\lambda) {w_j^{(t)}}^2] + \\gamma T_t + \\sum_{i=1}^N l(y_i, \\hat y^{(t)}) \\\\ & = \\sum_{j=1}^{T_t} [G_i w_j^{(t)} + \\frac 1 2 (H_j + \\lambda){w_j^{(t)}}^2] + \\gamma T_t + \\sum_{i=1}^N l(y_i, \\hat y^{(t)}) \\\\ & = \\sum_{j=1}^{T_t} [G_i w_j^{(t)} + \\frac 1 2 (H_j + \\lambda)(w_j^{(t)})^2] + \\gamma T_t + \\sum_{i=1}^N l(y_i, \\hat y^{(t)}) \\\\ \\end{align*} $f_t, T_t$：第t棵回归树、树叶子节点 $f_t(x_i)$：第t棵回归树对样本$x_i$的预测得分 $w_j^{(t)} = f_t(x)$：第t棵树中第j叶子节点预测得分 $gi = \\partial{\\hat y} l(y_i, \\hat y^{t-1})$ $hi = \\partial^2{\\hat y} l(y_i, \\hat y^{t-1})$ $I_j$：第j个叶结点集合 $Gj = \\sum{i \\in I_j} g_i$ $Hj = \\sum{i \\in I_j} h_i$ 对回归树，正则项中含有$(w_j^{(t)})^2$作为惩罚，能够 和损失函数二阶导合并，不影响计算 模型复杂度惩罚项惩罚项是针对树的，定义在叶子节点上， 而平方损失是定义在样本上，合并时将其改写 第t棵树的整体损失等于其各叶子结点损失加和，且 各叶子结点取值之间独立 则第t棵树各叶子结点使得损失最小的最优取值如下 （$G_j, H_j$是之前所有树的预测得分和的梯度取值，在 当前整棵树的构建中是定值，所以节点包含样本确定后， 最优取值即可确定） w_j^{(*)} = -\\frac {\\sum_{i \\in I_j} g_i} {\\sum_{i \\in I_j} h_i + \\lambda} = -\\frac {G_j} {H_j + \\lambda} 整棵树结构分数（最小损失）带入即可得 obj^{(t)} = -\\frac 1 2 \\sum_{j=i}^M \\frac {G_j^2} {H_j + \\lambda} + \\gamma T 则在结点分裂为新节点时，树损失变化量为 l_{split} = \\frac 1 2 \\left [ \\frac {(\\sum_{i \\in I_L} g_i)^2} {\\sum_{i \\in I_L h_i} + \\lambda} + \\frac {(\\sum_{i \\in I_R} g_i)^2} {\\sum_{i \\in I_R h_i} + \\lambda} - \\frac {(\\sum_{i \\in I} g_i)^2} {\\sum_{i \\in I h_i} + \\lambda} \\right ] - \\gamma $I_L, I_R$：结点分裂出的左、右结点 则最后应根据树损失变化量确定分裂节点、完成树的分裂，精确 贪心分裂算法如下 !xgb_exact_greedy_algorithm_for_split_finding 对于连续型特征需遍历所有可能切分点 对特征排序 遍历数据，计算上式给出的梯度统计量、损失变化 不适合数据量非常大、或分布式场景 模型细节 shrinkage：对新学习的树使用系数$\\eta$收缩权重 类似SGD中学习率，降低单棵树的影响，给后续基模型留下 学习空间 column subsampling：列抽样 效果较传统的行抽样防止过拟合效果更好 （XGB也支持行抽样） 加速计算速度 XGB树分裂算法 线性回归作为基学习器时，XGB相当于L0、L2正则化的 Logistic回归、线性回归 近似分割算法XGB近似分割算法：根据特征分布选取分位数作为候选集，将连续 特征映射至候选点划分桶中，统计其中梯度值、计算最优分割点 !xgb_approximate_algorithm_for_split_finding 全局算法：在树构建初始阶段即计算出所有候选分割点，之后 所有构建过程均使用同样候选分割点 每棵树只需计算一次分割点的，步骤少 需要计算更多候选节点才能保证精度 局部算法：每次分裂都需要重新计算候选分割点 计算步骤多 总的需要计算的候选节点更少 适合构建较深的树 分位点采样算法参见 ml_model/model_enhancement/gradient_boost Sparsity-aware Split Finding稀疏特点分裂算法：为每个树节点指定默认分裂方向，缺失值对应 样本归为该方向 仅处理非缺失值，算法复杂度和随无缺失数据集大小线性增加， 减少计算量 按照升许、降序分别扫描样本两轮，以便将缺失值样本分别归为 两子节点，确定最优默认分裂方向 XGB系统设计Column Block for Parallel Learning 建树过程中最耗时的部分为寻找最优切分点，而其中最耗时部分 为数据排序 XGB对每列使用block结构存储数据 每列block内数据为CSC压缩格式 特征排序一次，之后所有树构建可以复用（忽略缺失值） 存储样本索引，以便计算样本梯度 方便并行访问、处理所有列，寻找分裂点 精确贪心算法：将所有数据（某特征）放在同一block中 可同时对所有叶子分裂点进行计算 一次扫描即可得到所有叶子节点的分割特征点候选者统计 数据 近似算法：可以使用多个block、分布式存储数据子集 对local策略提升更大，因为local策略需要多次生成分位点 候选集 Cache-aware Access 列block结构通过索引获取数据、计算梯度，会导致非连续内存 访问，降低CPU cache命中率 精确贪心算法：使用cache-aware prefetching 对每个线程分配连续缓冲区，读取梯度信息存储其中，再 统计梯度信息 对样本数量较大时更有效 近似算法：合理设置block大小为block中最多的样本数 过大容易导致命中率低、过小导致并行化效率不高 Blocks for Out-of-core Computation 数据量过大不能全部存放在主存时，将数据划分为多个block 存放在磁盘上，使用独立线程将block读入主存 （这个是指数据划分为块存储、读取，不是列block） 磁盘IO提升 block compression：将block按列压缩，读取后使用额外 线程解压 block sharding：将数据分配至不同磁盘，分别使用线程 读取至内存缓冲区 分位点采样算法—XGBQuantile Sketch样本点权重 根据已经建立的$t-1$棵树可以得到数据集在已有模型上误差， 采样时根据误差对样本分配权重，对误差大样本采样粒度更大 将树按样本点计算损失改写如下 \\sum_{i=1}^N \\frac 1 2 h_i(f_t(x_i) - \\frac {g_i} {h_i})^2 + \\Omega(f_t) + constant 则对各样本，其损失为$f_t(x_i) - \\frac {g_i} {h_i}$ 平方和$h_i$乘积，考虑到$f_t(x_i)$为样本点在当前树预测 得分，则可以 将样本点损失视为“二次损失” 将$\\frac {g_i} {h_i}$视为样本点“当前标签” 相应将$h_i$视为样本点权重 样本权重取值示例 二次损失：$h_i$总为2，相当于不带权 交叉熵损失：$h_i=\\hat y(1-\\hat y)$为二次函数， 则$\\hat y$接近0.5时权重取值大，此时该样本预测值 也确实不准确，符合预期 Rank函数 记集合$D={(x_1, h_1), \\cdots, (x_n, h_n)}$ 定义rank函数$r_D: R \\rightarrow [0, +\\infty)$如下 r_D(z) = \\frac 1 {\\sum_{(x, h) \\in D} h} \\sum_{(x, h) \\in D, x < z} h 即集合$D$中权重分布中给定取值分位数 即取值小于给定值样本加权占比，可视为加权秩 分位点抽样序列 分位点抽样即为从集合$D$特征值中抽样，找到升序点序列 $S = {s_1, \\cdots, s_l}$满足 |r_D(s_j - r_D(s_{j+1})| < \\epsilon $\\epsilon$：采样率，序列长度$l = 1/\\epsilon$ $s1 = \\min{i} x_i$：特征最小值 $sl = \\max{i} x_i$：特征最大值 各样本等权分位点抽样已有成熟方法，加权分位点抽样方法 为XGB创新，如下 Weighted Quantile SketchFormalization 记$Dk={(x{1,k}, h1), \\cdots, (x{n,k}, h_n)}$为各 训练样本第$k$维特征、对应二阶导数 考虑到数据点可能具有相同$x, h$取值，$D_k$为可能包含 重复值的multi-set 对于多重集$D$，额外定义两个rank函数 \\begin{align*} r_D^{-}(y) & = \\sum_{(x,h) \\in D, x","link":"/ML-Theory/Model-Enhencement/gradient_boosting.html"},{"title":"风控中数据分析","text":"数据质量特征数据挖掘 确定分析目标 假设分析 对问题提出可能的假设 评估假设的分析过程 特征获取、关联分析 找出信息片段之间直接、间接联系 已知信息片段，寻找直接、间接联系的信息片段 假设验证、模式归纳 根据分析结论评估假设 归纳规律特点 统计类特征构造 RFM 特征框架思想是构造统计类特征的基础 Recency：最近一次间隔 Frequency：最近一段时间次数 Monetary：最近一段时间金额 结合业务统计、分析数据 了解数据采集逻辑 定义观察期有效性 不同用户的数据厚薄程度（实际观察期长短）可能不同 统计类特征构造方式 数量统计类特征 占比统计类特征 去除量纲影响 衡量用户行为偏好：时间偏好、类别偏好 趋势统计类特征 一般通过斜率衡量变化趋势 稳定性衍生特征 变异系数 特征变量评估 compliant 合规性 法律允许 来源可靠 stable 稳定性 数据采集稳定性 特征变量稳定性 数据源采集稳定是变量稳定性的基本前提 变量是模型的基础，数据不稳定必然导致模型稳定性差 available 可得性 数据未来是否可以继续采集、计算 涉及产品设计流程、用户授权协议、合规需求、模型应用环节 业务流程更改导致埋点数据弃用、数据采集后移 RFM特征时间窗口支持 interpretable 可解释性 数据是否具有明确、清晰的业务含义，便于理解 logical 逻辑性 不容易绕过，逻辑上应该被采用 外部数据业务指标 外部数据：三方平台根据自身业务场景所积累的数据，经脱敏 加工后对外输出，主要包括上述的信贷类数据、消费类数据 性价比 结合技术、业务效果、数据价格，综合计算性价比 计价方式 覆盖范围 覆盖率 查得率：能匹配用户数/总用户数 名单类数据 自身效果评估 混淆矩阵 TPR、FPR 准确率/误拒率 提升度 拒绝样本中坏样本提升度 通过样本中好样本提升度 通过率、拒绝率 对比/增量效果评估：和其他数据源比较 有效差异率：查得命中 / 其他通过且为坏样本 无效差异率：查得命中 / 其他拒绝 线下带标签场景的评估 数据描述 Exploratory Data Distribution 数据分布 样本与总体分布应大致相同，则样本分布应保持稳定，因此 各特征统计值更应保持稳定 按照自然月、特征维度，分析特征统计值变动 Missing Rate 缺失率 缺失成因：随机缺失、系统性缺失 缺失变动：特征缺失率持续升高，则预期未来数据采集率 下降 Unique Value 若某固定值占比过高，则变量区别度往往很低 特殊值检查 缺失值如何表示 零值的业务含义 稳定性 PSI：测试集、训练集间 比较训练集、测试集变量的波动性 无法反应细节原因，还需要 EDD 上分析 信息量 Coefficient of Variation 变异系数 过小则区分度差 过大可能不稳定 IV 值 评估变量预测能力 IV值过高时注意信息泄露问题 RF/XGB 特征重要性 适合快速筛选特征 此重要性只有全局可解释性，无法对单个案例做出解释 信息重复 Variable Cluster 变量聚类：评估聚类意义上变量的“接近”程度 层次聚类 Linear Correlation 线性相关性：评估变量间的线性相关性 Pearson Correlation Coefficient 变量若通过WOE方式参与建模，则可以使用WOE值计算相关系数 Multicollinearity 多重共线性 VIF 变量显著性 p-value 建模（线性）中应该避免是参与建模的变量之间过强的线性相关，所以应该检查的是参与建模变量之间的线性相关 变量衍生值、原始值相关性不一致是衍生非线性导致，不应减弱使用衍生值变量检查的合理性 样本数据质量 代表性（狭义） 数理统计最基本逻辑链是通过样本推断总体，因此样本对总体代表性决定推断上限 根据标目标客群、好坏比例采样、赋权 简单随机抽样，保持内部真实客群、好坏比例 客群分层抽样，适应不同客群 好坏不等比抽样，建模之后再按权重还原，充分捕捉 坏样本特征 稳定性 可用各 Vintage 内坏占比、lift 值、odds 等指标 PSI 衡量 样本稳定性决定推断结果稳定性 样本客群应该足够稳定，受节假日、周期影响小 连续性 样本时间连续便于建模中划分训练集、测试集（避免数据穿越） 特征分类 还款能力 收入：自填、三方 负债：内部负债、外部负债、多头借贷 学历：自填、三方 还款意愿 申贷行为：申贷记录、贷前贷后申贷行为变化 履约行为：还款记录、逾期记录 催记行为：催收记录 贷前数据 主动数据/表填信息：客户主动提供 被动数据：主动采集 资质、标签类数据 客观数据：无第三方欺诈情况下可信 性别 年龄 身份证号 手机号 手机号在多少个平台用户的通讯录中有存储 手机号归属地 户籍地址 户籍地址是否来自非城市：除一线城市外，用身份证 地址是否包含“村”判断 银行卡号 银行卡发卡行 签发机关 主观数据：不可信，可对这部分数据做交叉验证，检查是否前后矛盾 紧急联系人号码 紧急联系人消息 紧急联系人是否为平台用户 学历 工作 月收入 公司 负债 地址 紧急联系人手机号归属地是否和账户手机号归属地一致 手机联系人手机号归属地是否和申请人户籍地一致 信贷类数据 人行征信报告 三方征信数据：通过各机构贷前审批、贷后管理等记录 收入数据 负债数据 多头负债 共债 多头借贷数据 黑名单 信用评分 原始数据（极少） 生活行为类数据 消费行为：资金用途，是否专款专用、不良用途 信用卡、借记卡账单和流水 电商消费记录数据 收入能力：收入直接影响还款能力 流动资产：工资、公积金 固定资产 出行行为数据 短信通道：识别内容，提取放款、逾期、催收等特征 支付通道：通过支付代扣记录，提取用户收入、支出等 现金流 手机输入法：识别内容，提取全方位信息 设备行为类数据/埋点数据 埋点数据量庞大而杂乱 需要结合业务逻辑分析，从账户角度思考，挖掘有用的特征 行为类数据为弱金融属性数据，多用于交叉验证 GPS与手机号归属地一致 IP与GPS所在城市是否一致 IP与手机号归属地是否一致 工作时间的LBS是否与公司地址一致 非工作时间的LBS是否与家庭地址一致 埋点数据：在有需要的位置采集相应的信息 https://zhuanlan.zhihu.com/p/53812343 设备特征 设备恒定特征 是否root 是否hook 是否为实体手机 是否为一键新机 是否为二手手机：欺诈更倾向于使用二手手机 系统文件 是否恢复出厂设置 品牌 价格 操作系统 设备迁移方向 设备易变特征 传感器参数：在互联网反欺诈中，常用于侦测非实体手机， 而金融场景中更多是真机 角度传感器 压力传感器 电压、电量：手机电压、电量呈上升趋势，表示账户资金 需求更急迫 行为数据 活动轨迹：取决于埋点的精细程度 夜间申请 User-agent 点击次数 申请前次数低于大盘：账户对产品了解，意图明显 授信后点击次数过高：账户对产品有犹豫 激活+粘贴 正常申请流程中较少存在中途退出申请的必要 而中介更可以多次切换应用，复制粘贴 截图 中介更有可能截图制作教程、展示流程等 时间间隔：更适合作为欺诈模型参数 注册到申请 登录到申请 各申请步骤 申请到完成 授信到用信 上次申请与本次申请时间间隔 切换设备登陆 身份证提交次数 内容偏好 环境信息 LBS信息：可以提高观察粒度保证容错率 GPS所在城市 LBS是否在非城市 同LBS是否多个申请 LBS周围是否多个申请 网络信息 网络类型：Wifi/4g/3g 相同Wifi MAC的申请人数 Wifi名称是否命中风险关键词 IP地址 相同IP的申请人数 IP所在城市 IP是否来自数据中心 贷中、贷后指标贷中数据维度 内部信贷行为数据 申贷行为 历史申贷记录 贷前、贷后申贷行为 还款 分期期数 首期逾期天数 当前月正常拆分扣款总次数 当前3个月内还款最大金额 历史最大逾期天数 首次成功还款时间距离当前时间 催收 催收记录 履约历史 提前还款：资金充足、重视信用记录 习惯性逾期：手头紧张、不够重视信用记录 活跃行为 失联 用户登录 账户特征 授信额度使用率 代偿余额 时间窗口 Observation Point观察点：账户申请的时间段，该时间段内 客户可能用于建模 从风控应用角度，观察点即对账户授信审核的时点，此时 能够获得所有信息只能在观察点前的观察期 Observation Window观察期：构造特征的事件窗口 观察期选择依赖用户数据的厚薄程度，数据越厚，可提取 信息越全面、可靠 Performance Window表现期：定义好坏标签的时间窗口 风险需通过一定时间窗口才能表现，即信贷风险具有滞后性 表现期越长 信用风险暴露越彻底 也意味着观察期离当前越远，用以提取样本特征的历史 数据越陈旧，建模样本和未来样本差异越大 应当选择合适的表现期以覆盖足够多的坏客户 说明 表现期的选择 对信用卡场景的稳定客群、长期限产品，可用滚动率、账龄 分析确定表现期、好坏 但对小额信贷产品，实务中一般结合产品期限，沿用常用 指标，如：表现期设置为产品期限一半 建模样本窗口选择 特征覆盖度：保证数据厚薄程度相同 客群没有大幅变动 特征 标签：逾期、出催等 Month on Book/MOB：账龄 统一观察点账龄：统计信息为观察点实时信息，但会导致 订单表现期不同 MOB0：放款日至当月月底 MOB1：放款后第二个完整月份 MOB2：放款后第三个完整月份 统一表现期账龄：保证订单表现期相同 MOB1：放款日开始30天 MOB2：放款日开始30天至60天 逾期、不良 Payment Delinquency：逾期 First Payment Delinquency/FPDx：首期逾期（天数） Current Payment Delinquency/CPDx：当前逾期 Historical Payment Delinquency/HPDx：历史逾期 Day Past Due/DPDx：逾期天数 逾期期数 C/M0：当前未逾期 M1：DPD1 - DPD30 M6：逾期151-180日 M7/Bad Debts：逾期180日以上 对信用卡场景而言，M0为账单日到还款日之前，而对信贷 场景，M0没有对应时间段 逾期率 两种计算口径 逾期率 = 逾期订单数 / 总订单数 逾期率 = 逾期订单金额 / 总订单金额 逾期口径调整 逾期统计时间窗口：历史、当年 逾期后还上 担保、代偿 多期逾期是否计算剩余未还 总数调整 统计时间窗口：历史、当年 已发放还是余额 客观反映风控、资产质量的观察期选择 Coincidental Delinquency：固定观察时点，以截至 观察时点前逾期金额、余额计算 Lagged Deliquency：按照账龄分析方法，将各月份 逾期金额、金额计算真实逾期率 不良率 不良率 = （次级+可疑+损失）/ 总 次级、可疑、损失在银行内有明确规定，但不完全按照逾期 天数划分 同体系内内比较不良可行，但和不同体系间没有可比较性 Expected Loss EL = PD * LGD * EAD Expected Loss预期损失 Probabilty of Default违约概率 资产质量越差，违约概率越高 可以把对应逾期状态至呆账状态，各状态间迁移率链式相乘 得到违约概率 Loss Given Default违约损失率：账户违约后，能够回收的 本金比例 Bad Debt Reserve坏账准备金/拨备 把未偿清金额按照一定准备金比例储备，用于覆盖预期的 未来呆账损失 应该等于预期损失 资产质量分析 资产质量：根据逾期天数将资产划分为不同等级 账龄分析 滚动率分析 迁移率分析 观察点 多个观察点 单个观察点 多个观察点 观察窗口 观察点后各期 观察点前后一段期限 观察点后各期 工具 Vintage曲线 迁移矩阵 迁移率 分析要素 各观察点、各期逾期情况 各逾期状态间迁移情况 各期、各逾期状态下沉情况 Vintage Analysis账龄分析：对不同时点资产分别跟踪，按照账龄长短对齐后对比， 分析不同时点贷款贷后质量 用途 确定账户成熟期/稳定期 以逾期率趋于稳定所需时间作为判断客户好、坏区分 所需时间 辅助定义表现期/成熟期 确定资产质量 以曲线平缓处对应逾期率衡量资产质量 分析变化规律：分析逾期率变化情况 前几期逾期率上升快：短期风险未能控制，欺诈风险高 曲线一直上升：信用风险识别能差 分析影响因素（资产质量），指导风控策略调整 风控策略收紧放松 客群变化 市场环境 政策法规等 vintage起源于葡萄酒品质分析，vintage即指代葡萄酒的 批次标签，每年对各批次抽样、记录即得到vintage曲线 Roll Rate Analysis滚动率分析：利用观察期、表现期违约程度的状态转移矩阵分析 违约程度变化情况 滚动率分析步骤 准备 确定数据源：一般为还款计划表 定义逾期状态 统计观察期：以观察点为截至时间，统计客户在观察期最长 逾期期数，并据此对用户分级C、M1、M2等 统计表现期：以观察点起始，统计客户在表现期内最长逾期 数，并据此对用户分级C、M1、M2等 根据以上数据绘制列联表、计算频率 为排除观察点选择影响，选择多个观察点重复以上 滚动率分析用途 分析客户好坏程度、变化情况，确定客户好坏界限 Flow Rate Analysis迁移率分析：利用违约程度变化计算迁移率，分析违约程度变化规律 Flow Rate迁移率：资产等级下滑的比例 迁移率 = 前等级逾期金额到下一等级逾期金额的转化率 M0-M1 = 当月进入M1余额 / 上月末M0余额 核心假设 处于某一逾期状态的账户，一个月之后，必然从良为非逾期 账户，或恶化为下一级逾期账户 状态不会有跃迁，所以一期仅有一组下沉迁移率 迁移率分析步骤 准备 确定数据源：一般为还款计划表 定义逾期状态 计算各月份、各逾期状态之间迁移率 计算不同月份平均迁移率 根据平均迁移率和不良资产回收率，计算净坏账损失率 作用 展示账户整个生命周的变化轨迹 预测未来坏账损失：各级迁移率乘积得到最终损失率 计算坏账计提标准、资产拨备 观察迁移率发展轨迹 分析贷款催收率、催收力度 监控坏账发展倾向和催收效果 确定好坏客户标准 即选择迁移率较高的状态作为划分点","link":"/ML-Specification/FinTech/Risk-Control/data_analysis.html"},{"title":"社交网络","text":"网络结构 node/vertex：人 link/edge：人与人之间的relation，可以有标签、权重、 方向 graph/network：社交网络，表示个体之间的相互关系 图、网络参见cs_algorithm/data_structure/graph 基本统计指标、特性 subnetwork/subgraph singleton：单点集，没有边的子图 clique：派系，任意两个节点间均有连边的子图 degree： 对有向图可以分为out-degree、in-degree average degree：网络平均度，所有节点度的算术平均 degree distribution：网络度分布，概率分布函数 $P(k)$ Path path length：路径长度 shortest path：节点间最短路径 distance：节点距离，节点间最短路径长度 diameter：网络直径，任意两个节点间距离最大值 对规模（节点数量）为$N$大多数现实网络（尤其是社交网络） 小直径：与六度分离实验相符 存在巨大连通分支 高聚类特性：具有较大点聚类系数 明显的模块结构 giant connected component：巨大连通分支，即规模达到 $O(N)$的连通分支 node clustering coefficient：点聚类系数 \\begin{align*} NC_i & = \\frac {triange_i} {triple_i} \\\\ NC & = \\frac {\\sum_i NC_i} N \\end{align*} $triangle_i$：包含节点$i$三角形数量 $triple_i$：与节点$i$相连三元组：包含节点$i$的三个 节点，且至少存在节点$i$ 到其他两个节点的两条边 $NC_i$：节点$i$聚类系数 $NC$：整个网络聚类系数 edge clustering coefficient：边聚类系数 EC_{ij} = \\frac {|包含边三角形|} {min\\{(d_i-1), (d_j-1)\\}} $d_i$：节点$i$度，即分母为边$$最大可能存在于 的三角形数量 edge betweenness：边介数，从源节点$v$出发、通过该边 的最短路径数目 边介数的计算 从源节点$i$出发，为每个节点$j$维护距离源节点最短路径 $d_j$、从源节点出发经过其到达其他节点最短路径数目$w_j$ 定义源节点$i$距离$d_i=0$、权值$w_i=1$ 对源节点$i$的邻接节点$j$，定义其距离$d_j=d_i+1$、 权值$w_j=w_i=1$ 对节点$j$的任意邻接节点$k$ 若$k$未被指定距离，则指定其距离$d_k=d_j+1$、 权值$w_k=w_j$ 若$k$被指定距离且$d_k=d_j+1$，则原权值增加1， 即$w_k=w_k+1$ 若$k$被指定距离且$d_k&lt;d_j+1$，则跳过 重复以上直至网络中包含节点的连通子图中节点均被指定 距离、权重 从节点$k$经过节点$j$到达源节点$i$的最短路径数目、与节点 $k$到达源节点$i$的最短路径数目之比为$w_i/w_j$ 从叶子节点$l$开始，若叶子节点$l$节点$i$相邻，则将 权值$w_i/w_l$赋给边$(i,l)$ 从底至上，边$(i,j)$赋值为该边之下的邻边权值之和加1 乘以$w_i/w_j$ 重复直至遍历图中所有节点 叶子节点：广度优先搜索叶子节点，即不被任何从源节点出发到 其他节点的最短路径经过 此边介数计算方式与节点介数中心性计算，都是寻找通过边、 节点的最短路径数目，但是具体计算方式不同 最短路径唯一 考虑从任何节点间最短路径只有一条，则某节点到其他节点 的最短路径构成一棵最短路径树 找到最短路径树的叶子节点，为每条与叶子节点相连的边赋值 为1 自下而上为树中其他边赋值：边之下所有临边值之和加1 处理所有节点直至树根源节点时，各边相对于树根源节点的介数 即为其权重 对各节点分别重复以上即可得到各边对各节点介数，相总即可得 各边总边介数 Node Centrality节点中心性：采用某种定量方法对每个节点处于网络中心地位的程度 进行刻画 描述整个网络是否存在核心、核心的状态 基于度 Degree Centrality：度中心性 DC_i = \\frac {d_i} {N-1} $d_i$：节点$i$的度 衡量节点对促进网络传播过程发挥的作用 eigenvector centrality：特征向量中心性 $$ EC_i = $ subgraph centrality：子图中心性 $$ SC_i = $ 基于路径数 Betweenness Centrality：介数中心性 BC_i = \\frac 2 {(N-1)(N-2)} \\sum_{j \\sigma(G) > \\sigma_{out}(S) 强弱社区 强社区结构 |E_{in}(S, i)| > |E_{out}(S, i)|, \\forall i \\in S $E_{in}(S, i)$：节点$i$和子图$S$内节点连边 $E_{out}(S, i)$：节点$i$和子图$S$内节点连边 弱社区结构 \\sum_{i \\in S} |E_{in}(S, i)| > \\sum_{i \\in S} |E_{out}(S, i)|, \\forall i \\in S 最弱社区结构 \\forall i \\in S_j, |E_{in}(S_j, i)| > |E(S_j, i, S_k)|, j \\neq k, k=1,2,\\cdots,M 社区$S_1,S_2,\\cdots,S_M$是网络$G$中社区 $E(S_j, i, S_k)$：子图$S_j$中节点$i$与子图$S_k$之间 连边数 改进的弱社区结构：同时满足弱社区结构、最弱社区结构 LS集LS集：任何真子集与集合内部连边数都多于与集合外部连边数 的节点集合 Clique 派系：节点数大于等于3的全连通子图 n派系：任意两个顶点最多可以通过n-1个中介点连接 对派系定义的弱化 允许两社团的重叠 全连通子图：任意两个节点间均有连边 模块度函数Q\\begina{align*} Q & = \\sum_{i} (e_{i,i} - \\hat e_{i,i}) \\\\ & = \\sum_{i} (e_{i,i} - a_i^2) \\\\ & = \\sum_{i} (e_{i,i} - \\sum_j e_{i,j}^2) & = Tre - \\sum_{i,j} e_{i,j}^2 \\end{align*} $\\hat e_{i,i}$：随机网络中社区$i$内连边数占比期望 $e_{i,j}$：社区$i,j$中节点间连边数在所有边中所占比例 $ai = \\sum_j e{i,j}$：与社区$i$中节点连边数比例 思想：随机网络不会具有明显社团结构 不考虑节点所属社区在节点对间直接连边，则应有 $\\hat e{i,j} = a_i a_j$，特别的 $\\hat e{i,i} = a_i^2$ 比较社区实际覆盖度、随机连接覆盖度差异评估对社区结构 的划分 划分对应Q值越大，划分效果越好 $0&lt; Q &lt;1$：一般以$Q=0.3$作为网络具有明显社团结构的 下限 实际网络中$Q{max} \\in [0.3, 0.7]$，$Q{max}$越大 网络分裂（聚类）性质越强，社区结构越明显 缺点 采用完全随机形式，无法避免重边、自环的存在，而现实 网络研究常采用简单图，所以Q值存在局限 Q值分辨能力有限，网络中规模较大社区会掩盖小社区， 即使其内部连接紧密 覆盖度：社区内部连接数占总连接数比例 模块密度D\\begin{align*} D & = \\sum_{i=1}^M d(S_i) \\\\ & = \\sum_{i=1}^K \\frac {|E_{in}(S_i)| - |E_{out}(S_i)|} {|V_{in}(S_i)} \\begin{align*} 模块密度D表示社区内部连边、社区间连边之差与社区节点总数 之比 值越大表示划分结果越好 考虑社区总节点数，克服模块度Q无法探测小社区的缺陷 社区度C C = \\frac 1 M \\sum_{i=1}^M [\\frac {|E_{in}(S_i)|} {|V(S_i)|(|V(S_i)| - 1) / 2} - \\frac {|E_{out}(S_i)|} {|V(S_i)| (|V| - V(S_i)|}] $\\frac {|E_{in}(S_i)} {|V(S_i)||(|V(S_i)-1)/2}$：社区 $S_i$的簇内密度 $\\frac {|E_{out}(S_i)} {|V(S_i)||(|V|-|V(S_i))}$：社区 $S_i$的簇内密度 Fitness函数\\begin{align*} f_i & = \\frac {d_{in}(S_i)} {d_{in}(S_i) + d_{out}(S_i)} \\\\ & = \\frac {2 * E_{in}(S_i)} {2 * E_{in}(S_i) + E_{out}(S_i)} \\\\ \\bar f = \\frac 1 M \\sum_{i=1}^M f_i \\end{align*} $f_i$：社区$S_i$的fitness函数 $d{in}(S_i) = 2 * E{in}(S_i)$：社区$S_i$内部度 $d{out}(S_i) = E{out}(S_i)$：社区$S_i$外部度 $\\bar f$：整个网络社区划分的fitness函数 fitness函数使用直接的方式避开了模块度Q函数的弊端 应用结果显示其为网络社区结构的有效度量标准 Modularity Q = \\frac 1 {2|E|} \\sum_{i,j}社区发现算法网络测试集 Girvan、Newman人工构造网络 网络包含128个节点、平均分为4组 每组内部连边、组间连边概率分别记为$p{in}, p{out}$ 要求每个节点度期望为16 Lancichinet ti人工构造网络 测试集中节点度、社区大小服从幂律分布 混淆参数$\\mu$控制社区结构显著程度 小规模、社区结构已知真实网络 Zachary空手道俱乐部 海豚社会关系网络 美国大学生足球俱乐部网络 社区发现算法 Agglomerative Method：凝聚算法 NF算法 Walk Trap Division Method：分裂算法 Girvan-Newman算法 边聚类探测算法 凝聚算法流程 最初每个节点各自成为独立社区 按某种方法计算各社区之间相似性，选择相似性最高的社区 合并 相关系数 路径长度 矩阵方法 不断重复直至整个网络成为一个社区 算法流程可以的用世系图表示 可以在任意合并步骤后停止，此时节点聚合情况即为网络中 社区结构 但应该在度量标准值最大时停止 分裂算法流程同凝聚算法相反 Girvan-Newman算法GN算法 流程 计算网络中各边相对于可能源节点的边介数 删除网络中边介数较大的边，每当分裂出新社区 （即产生新连通分支） 计算网络的社区结构评价指标 记录对应网络结构 重复直到网络中边都被删除，每个节点为单独社区，选择 最优评价指标的网络结构作为网络最终分裂状态 缺点：计算速度满，边介数计算开销大，只适合处理中小规模 网络 Newman Fast AlgorithmNF快速算法： 流程 初始化网络中各个节点为独立社区、矩阵$E={e_{i,j}}$ \\begin{align*} e_{i,j} & = \\left \\{ \\begin{array}{l} \\frac 1 {2M}, & 边(i,j)存在 \\\\ 0, & 节点间不存在边 \\end{array} \\right. \\\\ a_i & = \\frac {d_i} {2M} \\end{align*} $M$：网络中边总数 $e_{i,j}$：网络中社区$i,j$节点边在所有边中占比 $a_i$：与社区$i$中节点相连边在所有边中占比 依次合并有边相连的社区对，计算合并后模块度增量 \\Delta Q = e_{i,j} + e_{j,i} = 2(e_{i,j}-a_i a_j) 根据贪婪思想，每次沿使得$Q$增加最多、减少最小 方向进行 每次合并后更新元素$e_{i,j}$，将合并社区相关行、 列相加 计算网络社区结构评价指标、网络结构 重复直至整个网络合并成为一个社区，选择最优评价指标 对应网络社区结构 基于贪婪思想的凝聚算法 GN算法、NF算法大多使用无权网络，一个可行的方案是计算无权 情况下各边介数，加权网络中各边介数为无权情况下个边介数 除以边权重 此时，边权重越大介数越小，被移除概率越小，符合社区 结构划分定义 Edge-Clustering Detection Algorithm边聚类探测算法： 流程： 计算网络中尚存的边聚类系数值 移除边聚类系数值最小者$(i,j)$，每当分裂出新社区 （即产生新连通分支） 计算网络社区评价指标fitness、modularity 记录对应网络结构 重复直到网络中边都被删除，每个节点为单独社区，选择 最优评价指标的网络结构作为网络最终分裂状态 Walk Trap随机游走算法： Label Propagation标签扩散算法： Self-Similar（网络结构）自相似性：局部在某种意义上与整体相似 fractal分形的重要性质 Random Walk（网络）随机游走： 游走形式 unbiased random walks：无偏随机游走，等概率游走 biased random walks：有偏随机游走，正比于节点度 self-avoid walks：自规避随机游走 quantum walks：量子游走 研究内容 first-passage time：平均首达时间 F(s,t) mean commute time：平均转移时间 C(t,s) = F(s,t) + F(t,s) mean return time：平均返回时间 T(s,s) 用途 community detection：社区探测 recommendation systems：推荐系统 electrical networks：电力系统 spanning trees：生成树 infomation retrieval：信息检索 natural language proessing：自然语言处理 graph partitioning：图像分割 random walk hypothesis：随机游走假设（经济学） pagerank algorithm：PageRank算法 网络可视化Graph Layout图布局：无实际意义但是影响网络直观效果 random layout：随机布局，节点、边随机放置 circular layout：节点放在圆环上 grid layout：网格布局 force-directed layout：力导向布局 最常用 动态、由节点相互连接决定布局 点距离较近节点在放置在较近位置 YiFan Hu layout Harel-Koren Fast Multiscale Layout NodeXL：节点以box形式被展示，边放置在box内、间 Visualizing Network Features网络特征可视化：边权、节点特性、标签、团结构 标签：只显示感兴趣标签 度、中心性、权重等量化特征：借助大小、形状、颜色体现 节点分类信息：节点节点颜色、形状体现 Scale Issue网络可视化：是否对所有网络均有可视化必要 网络密度太小、太大，无可视化必要 现实网络 网络科学：现实世界的任何问题都可以用复杂关系网络近似模拟 节点：研究问题中主体 边：模拟主体间的某种相互关系 现实网络大多为无标度网络，且幂指数$\\gamma \\in [2, 3]$ 网络中大部分节点度很小，小部分hub节点有很大的度 对随机攻击稳健，但对目的攻击脆弱 triangle power law：网络中三角形数量服从幂律分布 eigenvalue power law：网络邻接矩阵的特征值服从 幂律分布 绝大多数现实网络、网络结构模型虽然不能只管看出自相性， 但是在某种length-scale下确实具有自相似性 万维网 社会网络 蛋白质交互作用网络 细胞网络 个体社会影响力：社交网络中节点中心性 power-law distribution：幂律分布 scale-free network：无标度网络，度分布服从幂律分布的 复杂网络，具有无标度特性 heavy-tailed distribution：厚尾分布 社交网络 人、人与人之间的关系确定，则网络结构固定 有人类行为存在的任何领域都可以转化为社交网络形式 offline social networks：线下社交网络，现实面对面 接触中的人类行为产生，人类起源时即出现 online social networks/social webs：在线社交网络 social media websites：多媒体网社交网 由于社交网络中人类主观因素的存在，定性特征可以用于社交 网络分析 关系强弱 信任值 对网络结构的分析的数量化指标可以分析社交网络的基本特征 度、度分布 聚类系数 路径长度 网络直径 数据分析类型 Content Data：内容数据分析，文本、图像、其他多媒体 数据 Linkage Data：链接数据分析，网络的动力学行为：网络 结构、个体之间沟通交流 社交网络中社区发现 现实世界网络普遍具有模块/社区结构特性 内部联系紧密、外部连接稀疏 提取社区/模块结构，研究其特性有助于在网络动态演化 过程中理解、预测其自然出现的、关键的、具有因果关系的 本质特性 挑战 现实问题对应的关系网络 拓扑结构类型未知 大部分为随时间变化网络 规模庞大 现有技术方法应用受到限制 多数方法适用静态无向图，研究有向网络、随时间动态 演化网络形式技术方法较少 传统算法可能不适用超大规模网络 社区发现/探测重要性 社区结构刻画了网络中连边关系的局部聚集特性，体现了 连边的分布不均匀性 社区通常由功能相近、性质相似的网络节点组成 有助于揭示网络结构和功能之间的关系 有助于更加有效的理解、开发网络","link":"/ML-Specification/Graph-Analysis/social_network.html"},{"title":"Make","text":"Make基础Make：根据指定的Makefile文件构建新文件 12$ make [-f makefile] [&lt;target&gt;] # 指定使用某文件中的规则，默认`makefile`/`Makefile` make默认寻找当前目中GNUmakefile/makefile/Makefile 文件作为配置 文件 默认用makefile中首个目标文件作为最终目标文件，否则 使用&lt;target&gt;作为目标文件 Make参数 -b/-m：忽略和其他版本make兼容性 -B/--always-make：总是更新/重编译所有目标 -C &lt;dir&gt;/--directory=&lt;dir&gt;：指定读取makefile的目录， 相当于$ cd &lt;dir&gt; &amp;&amp; make 指定多个-C &lt;dir&gt;，make将按次序合并为最终目录 -C时，-w选项自动打开 --debug[=&lt;options&gt;]：输出make调试信息 a：all，输出所有调试信息 b：basic，基本信息 v：verbose，基本信息之上 i：implicit，所有隐含规则 j：jobs，执行规则中命令的详细信息，如：PID、返回码 m：makefile，make读取、更新、执行makefile的信息 -d：等价于--debug=a -e/--environment-overrides：环境变量覆盖makefile中值 -f &lt;file&gt;/--file=&lt;file&gt;/--makefile=&lt;file&gt;：指定 makefile 可以多次传递参数-f &lt;filename&gt;，所有makefile合并 传递给make -h/--help：帮助 -i/--ignore-errors：忽略执行时所有错误 -I &lt;dir&gt;/--include-dir=&lt;dir&gt;：搜索includemakefile 路径 可以多个-I &lt;dir&gt;指定多个目录 -j [&lt;jobsum&gt;]/-jobs[=&lt;jobsum&gt;]：指定同时运行命令数 进程数 默认同时运行尽量多命令 多个-j时最后者生效 -k/--keep-going：出错不停止运行 若目标生成失败，依赖于其上目标不会继续执行 -l &lt;load&gt;/--load-average[=&lt;load&gt;] --max-load[=&lt;load&gt;]：make命令负载 -n/--just-print/--dry-run/--recon：仅输出执行 过程中命令序列，不执行 -o &lt;file&gt;/--old-file=&lt;file&gt;/--assume-old=&lt;file&gt;： 不重新生成指定的&lt;file&gt;，即使目标依赖其 -p/--print-data-base：输出makefile中所有数据：规则、 变量等 1234$ make -qp # 只想输出信息，不执行makefile$ make -p -f /dev/null # 查看执行makefile前的预设变量、规则 -q/--question：不执行命令、不输出，仅检查指定目标 是否需要更新 0：需要更新 2：有错误发生 -r/--no-builtin-rules：禁用make任何隐含规则 -R/--no-builtin-variables：禁用make任何作用于变量上 的隐含规则 -s/--silent/quiet：禁止显示所有命令输出 -S/--no-keep-going/--stop：取消-k作用 -t/--touch：修改目标日期为最新，即组织生成目标的命令 执行 -v/--version：版本 -w/--print-directory：输出运行makefile之前、之后信息 对跟踪嵌套式调用make有用 --no-print-directory：禁止-w选项 -W &lt;file&gt;/--what-if=&lt;file&gt;/--new-file=&lt;file&gt;/--assume-file=&lt;file&gt; 联合-n选项，输出目标更新时的运行动作 没有-n，修改&lt;file&gt;为当前时间 --warn-undefined-variables：有未定义变量是输出警告信息 步骤 读入所有makefile 读入被include其他makefile 初始化（展开）文件中变量、函数，计算条件表达式 展开模式规则%、推导隐式规则、分析所并规则 为所有目标文件创建依赖关系链 根据依赖关系，决定需要重新生成的目标 执行生成命令 相关环境变量 MAKEFILES：make会将此环境变量中的文件自动include 不建议使用，会影响所有的make动作 其中文件缺失不会报错 MAKEFLAGS：make命令行参数，自动作为make参数 Makefile基本语法控制符号 #：注释 @：消除echoing，默认make会打印每条命令 -：忽略命令出错 通配符同bash *：任意字符 ?：单个字符 [...]：候选字符 ~：用户目录 ~：当前用户目录 ~xxx：用户xx目录 %：模式匹配 12%.o: %.c # 匹配所有c文件，目标为`.o`文件 $：引用、展开变量，执行函数 引用其他Makefile1include &lt;filename&gt; &lt;filename&gt;可以是默认shell的文件模式，包含通配符、路径 include之前可以有空格，但是不能有&lt;tab&gt;（命令提示） make寻找其他makefile，将其内容放当前位置 若文件没有明确指明为绝对路径、相对路径，make会在以下目录 中寻找 -I、--include-dir参数 /usr/local/bin/include、/usr/include make会include环境变量MAKEFILES中文件 不建议使用环境变量MAKEFILES，会影响所有make 文件未找到，make会生成一条警告信息，但继续载入其他文件， 完成makefile读取之后，make会重试寻找文件，失败报错 可以使用-include/sinclude代替，忽略include过程 中的任何错误 Makefile显式规则12&lt;target&gt;: &lt;prerequisite&gt;[tab]&lt;commands&gt; &lt;target&gt;：目标 &lt;prerequisites&gt;：前置条件 &lt;commands&gt;：命令，和前置条件至少存在一个 12a.txt: b.txt c.txt cat b.txt c.txt &gt; a.txt makefile中规则是生成目标的规则 make自顶向下寻找可以用于生成目标的规则，生成最终目标类似 调用函数栈 前置条件/依赖类似于被调用函数 命令类似于函数体 目标类似于函数返回值 Target目标：make的目标 目标通常是文件名，指明需要构建的对象 文件名可以是多个，之间使用空格分隔 不是文件名的目标称为伪目标，视为某种操作 多目标多目标规则意义是多个目标共享规则依赖、声明命令，并 不是需要同时生成多个目标 需要多目标中的任何一个时，多目标规则就会被应用，其中 命令被执行 每次只生成单独目标的多目标规则，目标之间只是单纯的 可以合并简化规则中的命令 123456789bigoutput littleoutput: text.g generate text.g -$(subst output,,$@) &gt; $@ # 等价于bigoutput: text.g generate text.g -big &gt; bigoutputlittleoutput: text.g generate text.g -little &gt; littleoutput 同时生成多个目标的多目标规则，多个目标应该满足 需要同时生成、不能单独修改，否则没有必要定义为多目标 ，当然这其实也是合并简化规则中的命令 12%.tab.c %.tab.h: %.y bison -d $&lt; Phony Targettodo伪目标：目标是某个操作的名字，每次执行都会执行命令 1234.PHONY: clean # 明确声明是*伪目标*，可省略clean: rm *.o 若省略.PYHONY，要求当前目中不存在同名文件，否则make 认为目标已存在，不会执行命令 GNU规范GNU推荐makefile中包含的伪目标、命名 all：编译所有目标 clean：删除所有被make创建的文件 install：安装已编译好程序，即将目标执行文件拷贝到指定 目标中 print：列出改变过的源文件 tar：打包源程序备份 dist：创建压缩文件 tags：更新所有目标，以备完整地编译使用 check/test：测试makefile流程 静态库目标archive(member)：指定静态库文件、及其组成 这种定义目标的方法就是方便ar命令 12345678910111213foolib(hack.o kludge.o): hack.o kludge.o ar cr foolib hack.o kludge.ofoolib(hack.o): hack.o ar cr foolib hack.l kudge.ofoolib(kludge.o): kludge.o ar cr foolib kludge.o # 确实等价，但是这个看起来有点不对劲，只要传了任何一个 # 静态库的构成，就执行命令???foolib(*.o): hack.o kludge.o # 这样更好??? Prerequisites前置条件/依赖：生成目标的依赖 通常是一组空格分隔的文件名，为空则说明目标的生成和其他 文件无关 指定目标是否重新构建的判断标准，只要有一个前置文件不存在 、有过更新（时间戳比较），目标就需要更新 若前置文件不存在，则需要建立以其作为目标的规则用于生成， make target时会自动调用 12source: file1 file2 file3 # 利用伪目标+前置条件，同时构建多个文件 Commands命令：更新、构建文件的方法 在linux下默认使用环境变量SHELL（/bin/sh）执行命令， 在MS-DOS下没有SHELL环境变量，会在PATH环境变量中寻找 ，并自动加上.exe、.bat、.sh等后缀 &lt;tab&gt;每行命令前必须有一个&lt;tab&gt;，否则需要使用提前声明 123.RECIPEPREFIX=&gt;all:&gt; echo Hello, world Shell进程每行命令在单独的shell进程中执行，其间没有继承关系 （即使是同一个规则中） 多条命令可以使用;分隔 12var-kept: export foo=bar; echo &quot;foo=[$$foo]&quot; 可类似python\\换行 123var-kept: export foo=bar; \\ echo &quot;foo=[$$foo]&quot; 使用.ONESHELL命令 1234.ONESHELLvar-kept: export foo=bar echo &quot;foo=[$$foo]&quot; 嵌套执行Make大工程中不同模块、功能源文件一般存放在不同目录，可以为每个 目录单独建立makefile 利于维护makefile，使得其更简洁 利于分块/分段编译 最顶层、调用make执行其他makefile的makefile称为总控 12345678910subsystem: cd subdir &amp;&amp; $(MAKE) # 等价subsystem: $(MAKE) -C subdirsubsystem: cd subdir &amp;&amp; $(MAKE) -w MAKEFLAGS= # 将命令行参数`MAKEFLAGS`置空，实现其不向下级传递 # 指定`-w`参数输出make开始前、后信息 搜索路径VPATHVPATH：makefile中定义的特殊环境变量，指明寻找依赖文件、 目标文件的路径 1VPATH = src:../src :分隔路径 当前目录优先级依旧最高 vpathvpath：make关键字，指定不同模式文件不同搜索目录 1234567vpath &lt;pattern&gt; &lt;directories&gt;vpath %.h ../headers # 指明`&lt;pattern&gt;`模式文件搜索目录vpath &lt;pattern&gt; # 清除`&lt;pattern&gt;`模式文件搜索目录设置vpath # 清除所有`vapth`设置 &lt;pattern&gt;中使用%匹配0或若干字符 vpath可以重复为某个模式指定不同搜索策略，按照出现顺序 先后执行搜索 隐含规则 隐含规则是一种惯例，在makefile中没有书写相关规则时自动 照其运行 隐含规则中优先级越高的约经常被使用 甚至有些时候，显式指明的目标依赖都会被make忽略1234foo.o: foo.p # Pascal规则出现在C规则之后 # 若当前目录下存在foo.c文件，C隐含规则生效，生成 # foo.o，显式依赖被忽略 很多规则使用后缀规则定义，即使使用-r参数，其 仍会生效 隐含规则会使用系统变量 CPPFLAGS/CFLAGS：C++/C编译时参数 可以通过模式规则自定义隐含规则，更智能、清晰 后缀规则有更好的兼容性，但限制更多 常用隐含规则编译C 目标：&lt;n&gt;.o 依赖包含：&lt;n&gt;.c 生成命令 1$(CC) -c $(CPPFLAGS) $(CFLAGS) 编译CPP 目标：&lt;n&gt;.o 依赖包含&lt;n&gt;.cc/&lt;n&gt;.c 生成命令 1$(CXX) -c $(CPPFLAGS) $(CFLAGS) 编译Pascal 目标：&lt;n&gt;.p 依赖包含：&lt;n&gt;.p 生成命令 1$(PC) -c $(PFLAGS) 编译Fortran/Ratfor 目标：&lt;n&gt;.o 依赖包含：&lt;n&gt;.f/&lt;n&gt;.r 生成命令 123456$(FC) -c $(FFLAGS) # `.f`$(FC) -c $(FFLAGS) $(CPPFLAGS) # `.F`$(FC) -c $(FFLAGS) $(RFLAGS) # `.r` 预处理Fortran/Ratfor 目标：&lt;n&gt;.f 依赖包含：&lt;r&gt;.r/&lt;n&gt;.F 生成命令 1234$(FC) -F $(CPPFLAGS) $(FFLAGS) # `.F`$(FC) -F $(FFLAGS) $(RFLAGS) # `.r` 转换Ratfor、有预处理的Fortran至标准Fortran 编译Modula-2 目标：&lt;n&gt;.sym/&lt;n&gt;.o 依赖包含：&lt;n&gt;.def/&lt;n&gt;.mod 生成命令1234$(M2C) $(M2FLAGS) $(DEFFLAGS) # `.def`$(M2C) $(M2FLAGS) $(MODFLAGS) # `.mod` 汇编汇编 目标：&lt;n&gt;.o 依赖包含：&lt;n&gt;.s 生成命令：默认使用编译器as 12$(AS) $(ASFLAGS) # `.s` 预处理 目标：&lt;n&gt;.s 依赖包含：&lt;n&gt;.S 生成命令：默认使用预处理器cpp 12$(CPP) $(ASFLAGS) # `.S` 链接object 目标：&lt;n&gt; 依赖包含：&lt;n&gt;.o 生成命令：默认使用C工具链中链接程序ld 1$(CC) &lt;n&gt;.o $(LOADLIBS) $(LDLIBS) Yacc C 目标：&lt;n&gt;.c 依赖包含：&lt;n&gt;.y 生成命令 1$(YACC) $(YFALGS) Lex C 目标：&lt;n&gt;.c 依赖包含：&lt;n&gt;.c 生成命令 1$(LEX) $(LFLAGS) Lex Ratfor 目标：&lt;n&gt;.r 依赖包含：&lt;n&gt;.l 生成命令 1$(LEX) $(LFLAGS) 创建Lint库 目标：&lt;n&gt;.ln 依赖包含：&lt;n&gt;.c/&lt;n&gt;.y/&lt;n&gt;.l 生成命令 1$(LINT) $(LINTFLAGS) $(CPPFLAGS) -i 创建静态链接库 目标：&lt;archive&gt;(member.o) 依赖包含：member 生成命令 1ar cr &lt;archive&gt; member.o 即使目标传递多个memeber.o，隐含规则也只会解析出把首个 .o文件添加进静态链接库中的命令 1234(%.o): %.o $(AR) rv $@ $*.o # 此命令可以得到添加所有`member.o`的命令 # 但是此时`$*=member.o member` 隐含规则使用变量隐含规则使用的变量基本都是预先设置的变量 makefile中改变 make命令环境变量传入 设置环境变量 -R/--no-builtin-variable参数取消变量对隐含规则作用 命令 AR：函数打包程序，默认ar AS：汇编语言编译程序，默认as CC：C语言编译程序，默认cc CXX：C++语言编译程序，默认c++/g++ CPP：C程序预处理器，默认$(CC) -E/cpp FC：Fortran、Ratfor编译器、预处理程序，默认f77 PC：Pascal语言编译程序，默认pc LEX：Lex文法分析器程序（针对C、Ratfor），默认lex YACC：Yacc文法分析器程序（针对C、Ratfor），默认 yacc -r GET：从SCCS文件中扩展文件程序，默认get CO：从RCS文件中扩展文件程序，默认co MAKEINFO：转换Texinfo .texi到Info程序，默认 makeinfo TEX：转换TeX至Tex DVI程序，默认tex TEXI2DVI：转换Texinfo至Tex DVI程序，默认texi2dvi WEAVE：转换Web至TeX程序，默认weave TANGLE：转换Web至Pascal程序，默认tangle CTANGEL：转换C Web至C，默认ctangle RM：删除文件命令，默认rm -f 命令参数未指明默认值则为空 ARFLAGS：静态链接库打包程序AR参数，默认rv ASFLAGS：汇编语言汇编器参数 CFLAGS：C编译器参数 CXXFLAGS：C++编译器参数 CPPFLAGS：C预处理参数 LDFLAGS：链接器参数 FFLAGS：Fortran编译器参数 RFLAGS：Fatfor的Fortran编译器参数 LFLAGS：Lex文法分析器参数 YFLAGS：Yacc文法分析器参数 COFLAGS：RCS命令参数 GFLAGS：SCCS get参数 隐含规则链make会努力自动推导生成目标的一切方法，无论中间目标 数量，都会将显式规则、隐含规则结合分析以生成目标 中间目标不存在才会引发中间规则 目标成功产生后，中间目标文件被删除 可以使用.SECONDARY强制声明阻止make删除该中间目标 指定某模式为伪目标.PRECIOUS的依赖目标，以保存被 隐含规则生成的符合该模式中间文件 通常makefile中指定成目标、依赖目标的文件不被当作中间目标 ，可以用.INTERMEDIATE强制声明目标（文件）是中间目标 make会优化特殊的隐含规则从而不生成中间文件，如从文件 foo.c直接生成可执行文件foo 模式规则模式规则：隐式规则可以看作内置模式规则 目标定义包含%，表示任意长度非空字符串 依赖中同样可以使用%，但是其取值取决于目标 命令中不使用模式%，使用自动化变量 模式规则没有确定目标，不能作为最终make目标 但是符合模式规则的某个具体文件可以作为最终目标 不需要作为显式规则的目标，如：archive(member)作为 静态库隐含规则目标 模式的启用取决于其目标，%的解析同样取决于目标 （因为根据目标查找、应用模式规则） 模式规则类似于隐含规则，给出符合某个模式的某类目标 的依赖、生成命令 %的展开发生在变量、函数展开后，发生在运行时 静态模式静态模式：给定目标候选范围的模式，限制规则只能应用在以 给定范围文件作为目标的情况 12&lt;target&gt;: &lt;target-pattern&gt;: &lt;prereq-patterns&gt; &lt;commands&gt; &lt;target&gt;：目标候选范围，可含有通配符 &lt;target-pattern&gt;：所有目标文件满足的模式 &lt;prereq-pattern&gt;：目标相应依赖 简单例子 1234567891011objects = foo.o bar.oall: $(objects)$(objects): %.o: %.c $(CC) -c $(CFLAGS) $&lt; -o $@ # 等价于foo.o: foo.c $(CC) -c $(CFLAGS) foo.c -o foo.obar.o: bar.c $(CC) -c $(CFLAGS) bar.c -o bar.o 静态模式+filter函数筛选范围 12345files = foo.elc bar.o lose.o$(filter %.o,$(files)): %.o: %.c $(CC) -c $(CFLAGS) $&lt; -o $@$(filter %.elc,$(files)): %.elc: %.el emacs -f batch-byte-compile $&lt; 重载内建隐含规则12345%.o: %c $(CC) -c $(CPPFLAGS) $(CFLAGS) -D $(date) # 重载内建隐含规则%o: %c # 命令置空，取消内建隐含规则 后缀规则 双后缀规则：定义一对目标文件后缀、依赖后缀 单后缀规则：定义一个依赖后缀 123456.c.o: # 等价于`%.o: %c` $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt;.c: # 等价于`%: %.c` $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt; 后缀规则中不能有任何依赖文件，否则不是后缀规则，后缀被 认为是目标文件 后缀规则中必须有命令，否则没有任何意义，这不会移去内建 的隐含规则 后缀规则定义中的后缀需要是make所认识的，可以使用伪目标 .SUFFIXES修改make认识的后缀 1234.SUFFIXES: # 删除默认后缀.SUFFIXES: .c .o .h # 添加自定义后缀 变量$SUFFIXE用于定义默认后缀列表，不应该修改 -r/--no-builtin-rules同样会清空默认后缀列表 后缀规则是老式定义隐含规则的方法，会被逐步取代，事实上 后缀规则在makefile载入后会被转换为模式规则 模式规则搜索算法设目标为src/foo.o 将目标目录部分、文件名部分分离，得到src/、foo.o 搜索所有模式规则列表，创建目标和src/foo.o匹配的模式 规则列表 若模式规则列表中有目标匹配所有文件的模式（如%）， 则从列表中移除其他模式 移除列表中没有命令的规则 对列表中首个模式规则 将src/foo.o或foo.o匹配目标，推断%匹配非空部分 茎S 把依赖中%替换为茎S，如果依赖项中没有包含目录， 尝试将src添加在其前 检查所有依赖文件存在、理当存在（文件被定义为其他规则 的目标文件、显式规则的依赖文件） 若有依赖文件存在、理当存在或没有依赖文件，此规则被 采用，退出算法 若没有找到合适模式规则，则检查列表中下个规则是否可行 若没有模式规则可以使用，检查.DEFAULT规则存在性，存在 则应用 变量、赋值Makefile中定义的变量类似C++/C中的宏 代表一个字符串，在makefile中执行的时候展开在所在位置 &quot;&quot;会被作为字符串一部分 默认空格、逗号分隔列表 12345empty:=space:=$(empty) # 后面有空格，就得到了空格comma:=,foo:=a,b,cbar:=$(substr $(comma), $(space), $(foo)) # 得到字符串`a b c` 变量可以改变值 在shell中需要$$处应使用两个$$$，一个$被escape，则 shell解释时仍然保留一个$，如：变量、函数等都需要 赋值Makefile内自定义变量 1234567txt = Hello World # 自定义变量test: @echo $(txt) echo ${txt} # 调用变量，`()`、`{}`含义相同 # 若变量名为单个字符，可以省略括号，但不建议省略 =：lazy set，在执行时扩展 可以使用任意位置定义（可能还未定义）的变量赋值 允许递归扩展，make报错 :=：immediate set，在定义/赋值时扩展完毕 只允许使用之前已定义变量赋值（否则为空） ?=：set if absent，只有变量为空时才设置值 +=：append，将值追加到变量的尾部 若前面变量有定义，+=会继承前一次操作符:=/= 对于=定义变量，make自动处理“递归” definedefine可以换行定义变量 变量类似宏的行为、可换行定义变量，方便定义命令包 12345678910define run-yacc # `define`后跟变量名作为命令包名称 yacc $(firstword $^); \\ mv y.tab.c $@endef # 结束定义foo.c: foo.y $(run-yacc) # 使用命令包 override 若变量由make命令行参数-e设置，makefile中默认忽略对其 赋值 需要显式使用override关键字设置 123override &lt;variable&gt; = &lt;value&gt;override &lt;variable&gt; := &lt;value&gt;override define &lt;variable&gt; export上级makefile中变量可以显式export传递到下层makefile中， 但是不会覆盖下层中定义的变量（除指定-e参数） 123456789export &lt;variable&gt;[=value] # 传递变量至下级makefile中unexport &lt;variable&gt; # 禁止变量传递至下级makefile中export variable = value # 等价variable = valueexport variable export后面不指定具体传递变量，表示传递所有变量 MAKEFLAGS、SHELL两个变量总是会传递到下级makefile中 系统环境变量make运行时系统环境变量、命令行环境变量可以被载入makefile 默认makefile中定义变量覆盖系统环境变量 -e参数则表示makefile中变量被覆盖 123test: @echo $$HOME # 传递给shell的变量，需要`$$` escape Target-Specific Variable目标/局部变量：作用范围局限于规则、连带规则中 1234567891011121314&lt;target ...&gt;: [override] &lt;variable-assignment&gt;prog: CFLAGS = -gprog: prog.o foo.o bar.o $(CC) $(CFLAGS) prog.o foo.o bar.oprog.o: prog.c $(CC) $(CFLAGS) prog.cfoo.o: foo.c $(CC) $(CFLAGS) foo.cbar.o: bar.c $(CC) $(CFLAGS) bar.c Pattern-Specific Variable模式变量：给定模式，变量定义在符合模式的所有目标上 123&lt;pattern ...&gt;: [override]&lt;variable-assignment&gt;%.o: CFLAGS = -o Implicit Variables内置变量：主要是为了跨平台的兼容性 $(CC)：当前使用的编译器 12output: $(CC) -o output input.c $(MAKE)：当前使用的Make工具 $(MAKECMDGOLA)：make目标列表 Automatic Variables自动化变量：应用规则时被自动赋予相应值（一般是文件）的变量 $@：当前需要生成的目标文件 多目标规则中，$@也只表示被需要目标 $*：匹配符%匹配部分 若目标中没有%模式符，$*不能被推导出，为空 GNU make中，目标中没有%，$*被推导为除后缀部分， 但是很可能不兼容其他版本，谨慎使用 $&lt;：首个前置条件 $%：仅当目标是函数库文件，表示目标成员名，否则为空 目标为foo.a(bar.o)：$%为bar.o、$@为foo.a $?：比目标更新的前置条件，空格分隔 $^：所有前置条件，会取出其中重复项 $+：类似于$^，但是剔除重复依赖项 自动化变量只应出现在规则的命令中 自动化变量值与当前规则有关 其中$@、$*、$&lt;、$%扩展后只会为单个文件，$?、 $^、$+扩展后可能是多个文件 123dest/%.txt: src/%.txt @[ -d test ] || mkdir dest cp $&lt; $@ D、F 7个自动化变量可以搭配D、F取得相应路径中目录名、 文件名 新版本GNU make可以使用函数dir、notdir代替D/F D/dir：目录带有最后/，若为当前目录则为./ F/nodir：文件名 对可能会扩展为多文件的$?、$^、$+，D/F处理后 返回同样是多个目录/文件 12345678910111213$(@D)$(dir $@) # `$@`的目录名$(@F)$(nodir $@) # `$@`的文件名$(?D)$(dir $?) # `$?`中所有目录，空格分隔$(?F)$(nodir $?) # `$?`中所有文件，空格分隔 控制语句if12345678&lt;conditional-directive&gt;&lt;text-if-true&gt;[else&lt;text-if-false&gt;]endif ifeq：比较参数是否相等 ifneq：比较参数是否不等 123456ifeq ($(CC), gcc) # 也可以用单/双引号括起，省略括号 libs=$(libs_for_gcc)else libs=$(normal_libs)endif ifdef 123456789101112131415161718bar =foo = $(bar)# `foo`有定义ifdef foo frobozz = yes # 此分支else frobozz = noendiffoo =# `foo`未定义ifdef foo frobozz = yeselse frobozz = no # 此分支endif ifndef &lt;conditional-directive&gt;, else, endif行可以有多余空格， 但是不能以&lt;tab&gt;开头，否则被认为是命令 make在读取makefile时就计算表达式值、选择语句，所以最好 别把自动化变量放入条件表达式中 make不允许把条件语句分拆放入两个文件中 for1234567891011LIST = one two threeall: for i in $(LIST); do \\ echo $$i; // 这里传递给shell的变量，需要`$$` escape doneall: for i in one two three; do echo $$i; done 内建函数12$(function parameters)${function paremeters} Make控制函数提供一些函数控制make执行 检测运行makefile的运行时信息，根据信息决定make继续执行 、停止 error产生错误并退出make，错误信息&lt;text&gt; 12345678910$(error &lt;text...&gt;)ifdef ERROR_001$(error error is $(ERROR_001))endifERR = $(error found an error).PHONY: errerr: err: ; $(ERR) warning类似error函数，输出警告信息，继续make 其他函数shell执行shell命令的输出作为函数返回值 1srcfiles := $(shell echo src/{00..99}.txt) 函数会创建新shell执行命令，大量使用函数可能造成性能下降 ，尤其makefile的隐晦规则可能让shell函数执行次数过多 wildcard在变量中展开通配符* 123srcfiles := $(wildcard src/*.txt) # 若不展开，则`srcfiles`就只是字符串 # 展开后则表示所有`src/*.txt`文件集合 字符串处理函数subst文本替换 12345$(subst &lt;from&gt;,&lt;to&gt;,&lt;text&gt;) # `subst`函数头$(subst ee,EE,feet on the street) # 替换成*fEEt on the strEET* patsubst模式匹配的替换 123456789101112131415$(patsubst &lt;pattern&gt;,&lt;replacement&gt;,&lt;text&gt;) # 函数头文件$(patsubst %.c,%o,x.c.c bar.c) # 替换为`x.c.o bar.o`foo := a.o b.o c.o$(variable: &lt;pattern&gt;=&lt;replacement&gt;) # `patsubst`函数的简写形式bar := $(foo:%.o=%.c) # `$(bar)`变为`a.c b.c c.c`$(variable: &lt;suffix&gt;=&lt;replacement&gt;) # 没有模式匹配符`%`则替换结尾bar := $(foo:.o=.c) # `$(bar)`变为`a.c b.c c.c` strip去字符串头、尾空格 12$(strip &lt;string&gt;)$(strip a b c) findstring在&lt;in&gt;中查找&lt;find&gt;，找到返回&lt;find&gt;，否则返回空串 12$(findstring &lt;find&gt;,&lt;in&gt;)$(findstring a,a b c) filter以&lt;pattern&gt;模式过滤&lt;text&gt;字符串中单词，返回符合模式的 单词 123456$(filter &lt;pattern..&gt;,&lt;text&gt;)sources := foo.c bar.c baz.s ugh.hfoo: $(sources) cc $(filter %.c %.s, $(sources)) -o foo # 返回`foo.c bar.c baz.s` filter-out以&lt;pattern&gt;模式过滤&lt;text&gt;字符串中单词，返回不符合模式的 单词 1234objects := main1.o foo.o main2.o bar.omains=main1.o main2.o$(filter-out $(mains), $(objects)) # 返回`foo.o bar.o` sort对&lt;list&gt;中单词升序排序 1234$(sort &lt;list&gt;)$(sort foo bar lose) # 返回`bar foo lose` word取字符串&lt;text&gt;中第&lt;n&gt;个单词 1234$(word &lt;n&gt;,&lt;text&gt;)$(word 2, foo bar baz) # 返回`bar` wordlist从&lt;text&gt;中取&lt;s&gt;-&lt;e&gt;单词（闭区间） 1234$(wordlist &lt;s&gt;,&lt;e&gt;,&lt;text&gt;)$(wordlist 2, 3, foo bar baz) # 返回`bar baz` words统计&lt;text&gt;中单词个数 1234$(word &lt;text&gt;)$(word, foo bar baz) # 返回3 firstword取&lt;text&gt;中首个单词 1234$(firstword &lt;text&gt;)$(firstword foo bar) # 返回`foo` 文件名操作函数dir从文件名序列中取出目录部分 最后/之前部分 若没有/则返回./ 1234$(dir &lt;names...&gt;)$(dir src/foo.c hacks) # 返回`src/ ./` notdir从文件名序列中取出非目录部分（最后/之后部分） 1234$(notdir &lt;names...&gt;)$(notdir src/foo.c hacks) # 返回`foo.c hacks` suffix从文件名序列中取出各文件名后缀 1234$(suffix &lt;names...&gt;)$(suffix src/foo.c src-1.0/bar.c hacks) # 返回`.c .c` basename从文件名序列中取出各文件名“前缀”（除后缀外部分） 1234$(basename &lt;names...&gt;)$(basename src/foo.c src-1.0/bar.c hacks) # 返回`src/foo src-1.o/bar hacks` addsuffix把后缀&lt;suffix&gt;添加到文件名序列中每个单词后 1234$(addsuffix &lt;suffix&gt;,&lt;names...&gt;)$(addsuffix .c, foo bar) # 返回`foo.c bar.c` addprefix把后缀&lt;prefix&gt;添加到文件名序列中每个单词后 1234$(addprefix &lt;prefix&gt;,&lt;names...&gt;)$(addprefix src/, foo bar) # 返回`src/foo src/bar` join把&lt;list2&gt;中单词对应添加到&lt;list1&gt;中单词后 较多者剩余单词保留 1234$(join &lt;list1&gt;,&lt;list2&gt;)$(join aaa bbb, 111 222 333) # 返回`aaa111 bbb222 333` 控制函数foreach循环函数，类似于Bash中的for语句 把&lt;list&gt;中单词逐一取出放到参数&lt;var&gt;所指定的变量中 再执行&lt;text&gt;所包含的表达式，每次返回一个字符串 循环结束时，返回空格分隔的整个字符串 12345$(foreach &lt;var&gt;,&lt;list&gt;,&lt;text&gt;)names := a b c dfiles := $(foreach n,$(names),$(n).o) # 返回`a.o b.o c.o d.o` &lt;var&gt;是临时局部变，函数执行完后将不再作用 if类似于make中的ifeq &lt;condition&gt;为真（非空字符串），计算&lt;then-part&gt;返回值 &lt;condition&gt;为假（空字符串），计算&lt;else-part&gt;、返回空 字符串 1$(if &lt;condition&gt;,&lt;then-part&gt;,[&lt;else-part&gt;]) call创建新的参数化函数的函数 创建表达式&lt;expression&gt;，其中可以定义很多参数 用call函数向其中传递参数，&lt;expression&gt;返回值即call 返回值 12345678$(call &lt;expression&gt;,&lt;param1&gt;,&lt;param2&gt;,...&gt;reverse = $(1) $(2)foo = $(call reverse,a,b) # 返回`a b`reverse = $(2) $(1)foo = $(call reverse,a,b) # 返回`b a` &lt;expression&gt;要先创建为变量，然后不带$传递 origin返回变量的来源 undefined：&lt;variable&gt;未定义 default：make默认定义变量 environment：环境变量，且-e选项未开 file：定义在makefile中 command line：命令行定义环境变量 override：override关键字定义 atomatic：命令运行中自动化变量 1234567$(origin &lt;variable&gt;)ifdef bletchifeq &quot;$(origin bletch)&quot; &quot;environment&quot;bletch = barf, gag, etcendifendif &lt;variable&gt;不操作变量值，不带$传递 Makefile技巧案例12345678910111213141516171819202122232425262728edit: main.o kdd.o command.o display.o \\ insert.o search.o files.o utils.o cc -o edit main.o kbd.o command.o dispaly.o\\ insert.o search.o files.o utils.omain: main.c defs.h cc -c main.ckbd.o: kbd.c defs.h cc -c kbd.ccommand.o: command.c defs.h command.h cc -c command.cdisplay.o: display.o defs.h buffer.h cc -c display.cinsert.o: insert.c defs.h buffer.h cc -c insert.csearch.o: search.c defs.h buffer.h cc -c search.cfiles.o: files.c defs.h buffer.h command.h cc -c files.cutils.o utils.c defs.h cc -c utils.cclean: rm edit main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o.PHONY: edit clean # 设置`edit`、`clean`为伪目标 利用变量简化目标123456objects = main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.oedit: $(objects) cc -o edit $(objects) # 以下同上 隐式模式自动推导1234567891011121314151617objects = main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.oedit: $(objects) cc -o edit $(objects)main.o: defs.hkbd.o: defs.h command.hcommand.o: defs.h command.hdisplay: defs.h buffer.hinsert.o: defs.h buffer.hsearch.o: defs.h buffer.hfiles.o: defs.h buffer.h command.hutils.o: defs.hclean: rm edit $(objects).PHONY: clean 利用隐式模式自动推导文件、文件依赖关系 利用变量提取依赖12345678910111213objects = main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.oedit: $(objects) cc -o edit $(objects)$(objects): defs.hkbd.o command.o files.o: command.hdisplay.o insert.o search.o files.o: buffer.hclean: rm edit $(objects).PHONY: clean 文件变得简单，但是依赖关系不再清晰 自动生成依赖 大部分C++/C编译器支持-M选项，自动寻找源文件中包含的 头文件，生成依赖关系 GNU建议为每个源文件自动生成依赖关系，存放在一个文件中， 可以让make自动更新依赖关系文件.d，并包含在makefile中 12345678910111213%.d: %.c @set -e; rm -f $@; \\ $(cc) -M $(CPPFLAGS) $&lt; &gt; $@.$$$$; \\ # 生成中间文件 # `$$$$`表示4位随机数 sed 's,/($*/)/.o[ :]*,/1.o $@ : ,g' &lt; $@.$$$$ &gt; $@; \\ # 用`sed`替换中间文件target # `xxx.o` -&gt; `xxx.o xxx.d` rm -f $@.$$$$ # 删除中间文件source = foo.c bar.cinclude $(sources: .c=.d)","link":"/Linux/Tool/make.html"},{"title":"Hadoop安装配置","text":"Hadoop安装依赖 Java 具体版本http://wiki.apache.org/hadoop/HadoopJavaVersions 需要配置好java环境（~/.bashrc） ssh：必须安装且保证sshd一直运行，以便使用hadoop脚本管理 远端hadoop守护进程 pdsh：建议安装获得更好的ssh资源管理 要设置免密登陆 机器环境配置~/.bashrc这里所有的设置都只是设置环境变量 所以这里所有环境变量都可以放在hadoop-env.sh中 放在.bashrc中不是基于用户隔离的考虑 因为hadoop中配置信息大部分放在.xml，放在这里无法 实现用户隔离 更多的考虑是给hive等依赖hadoop的应用提供hadoop配置 1234567891011121314151617181920export HADOOP_PREFIX=/opt/hadoop # 自定义部分 # 此处是直接解压放在`/opt`目录下export HADOOP_HOME=$HADOOP_PREFIXexport HADOOP_COMMON_HOME=$HADOOP_PREFIX # hadoop commonexport HADOOP_HDFS_HOME=$HADOOP_PREFIX # hdfsexport HADOOP_MAPRED_HOME=$HADOOP_PREFIX # mapreduceexport HADOOP_YARN_HOME=$HADOOP_PREFIX # YARNexport HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoopexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.library.path=$HADOOP_COMMON_LIB_NATIVE_DIR&quot; # 这里`-Djava`间不能有空格export CLASSPATH=$CLASS_PATH:$HADOOP_PREFIX/lib/*export PATH=$PATH:$HADOOP_PREFIX/sbin:$HADOOP_PREFIX/bin /etc/hosts1234192.168.31.129 hd-master192.168.31.130 hd-slave1192.168.31.131 hd-slave2127.0.0.1 localhost 这里配置的ip地址是各个主机的ip，需要自行配置 hd-master、hd-slave1等就是主机ip-主机名映射 todo?一定需要在/etc/hostname中设置各个主机名称 firewalld必须关闭所有节点的防火墙 12$ sudo systemctl stop firewalld.service$ sudo systemctl disable firewalld.service 文件夹建立 所有节点都需要建立 12$ mkdir tmp$ mkdir -p hdfs/data hdfs/name Hadoop配置Hadoop全系列（包括hive、tez等）配置取决于以下两类配置文件 只读默认配置文件 core-defualt.xml hdfs-default.xml mapred-default.xml 随站点变化的配置文件 etc/hadoop/core-site.xml etc/hadoop/hdfs-site.xml etc/hadoop/mapred-site.xml etc/hadoop/yarn-env.xml 环境设置文件：设置随站点变化的值，从而控制bin/中的 hadoop脚本行为 etc/hadoop/hadoop-env.sh、 etc/hadoop/yarn-env.sh etc/hadoop/mapred-env.sh 中一般是环境变量配置，补充在shell中未设置的环境变量 注意 .xml配置信息可在不同应用的配置文件中继承使用， 如在tez的配置中可以使用core-site.xml中 ${fs.defaultFS}变量 应用会读取/执行相应的*_CONF_DIR目录下所有 .xml/.sh文件，所以理论上可以在etc/hadoop中存放 所以配置文件，因为hadoop是最底层应用，在其他所有应用 启动前把环境均已设置完毕？？？ Hadoop集群有三种运行模式 Standalone Operation Pseudo-Distributed Operation Fully-Distributed Operation 针对不同的运行模式有，hadoop有三种不同的配置方式 Standalone Operationhadoop被配置为以非分布模式运行的一个独立Java进程，对调试有 帮助 默认为单机模式，无需配置 测试12345$ cd /path/to/hadoop$ mkdir input$ cp etc/hadoop/*.xml input$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar grep input output 'dfs[a-z.]+'$ cat output/* Pseudo-Distributed Operation在单节点（服务器）上以所谓的伪分布式模式运行，此时每个Hadoop 守护进程作为独立的Java进程运行 core-site.xml123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml12345678910111213&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configruration&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt;$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt; &lt;/preperty&gt;&lt;/configruation&gt; yarn-site.xml12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; Fully-Distributed Operation 单节点配置完hadoop之后，需要将其同步到其余节点 core-site.xml模板：core-site.xml 1234567891011121314151617181920212223242526&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hd-master:9000&lt;/value&gt; &lt;description&gt;namenode address&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:///opt/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131702&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;!-- 为将用户`root`设置为超级代理，代理所有用户，如果是其他用户需要相应的将root修改为其用户名 --&gt; &lt;!-- 是为hive的JDBCServer远程访问而设置，应该有其他情况也需要 --&gt;&lt;/configuration&gt; hdfs-site.xml模板：hdfs-site.xml 12345678910111213141516171819202122232425262728293031&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hd-master:9001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///opt/hadoop/hdfs/name&lt;/value&gt; &lt;description&gt;namenode data directory&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///opt/hadoop/hdfs/data&lt;/value&gt; &lt;description&gt;datanode data directory&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;description&gt;replication number&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.directoryscan.throttle.limit.ms.per.sec&lt;/name&gt; &lt;value&gt;1000&lt;/value&gt; &lt;/property&gt; &lt;!--bug--&gt;&lt;/configuration&gt; yarn-site.xml 模板：yarn-site.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hd-master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;hd-master:9032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;hd-master:9030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;hd-master:9031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;hd-master:9033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;hd-master:9099&lt;/value&gt; &lt;/property&gt; &lt;!-- container --&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;512&lt;/value&gt; &lt;description&gt;maximum memory allocation per container&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;256&lt;/value&gt; &lt;description&gt;minimum memory allocation per container&lt;/description&gt; &lt;/property&gt; &lt;!-- container --&gt; &lt;!-- node --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt; &lt;description&gt;maximium memory allocation per node&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;8&lt;/value&gt; &lt;description&gt;virtual memmory ratio&lt;/description&gt; &lt;/property&gt; &lt;!-- node --&gt; &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.resource.mb&lt;/name&gt; &lt;value&gt;384&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.command-opts&lt;/name&gt; &lt;value&gt;-Xms128m -Xmx256m&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml 模板：mapred-site.xml.template 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;!-- &lt;value&gt;yarn-tez&lt;/value&gt; 设置整个hadoop运行在Tez上，需要配置好Tez --&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hd-master:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hd-master:19888&lt;/value&gt; &lt;/property&gt; &lt;!-- mapreduce --&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt; &lt;value&gt;256&lt;/value&gt; &lt;description&gt;memory allocation for map task, which should between minimum container and maximum&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt; &lt;value&gt;256&lt;/value&gt; &lt;description&gt;memory allocation for reduce task, which should between minimum container and maximum&lt;/description&gt; &lt;/property&gt; &lt;!-- mapreduce --&gt; &lt;!-- java heap size options --&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt; &lt;value&gt;-Xms128m -Xmx256m&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.java.opts&lt;/name&gt; &lt;value&gt;-Xms128m -Xmx256m&lt;/value&gt; &lt;/property&gt; &lt;!-- java heap size options --&gt;&lt;/configuration&gt; 参数说明 yarn.scheduler.minimum-allocation-mb：container内存 单位，也是container分配的内存最小值 yarn.scheduler.maximum-allocation-mb：container内存 最大值，应该为最小值整数倍 mapreduce.map.memeory.mb：map task的内存分配 hadoop2x中mapreduce构建于YARN之上，资源由YARN统一管理 所以maptask任务的内存应设置container最小值、最大值间 否则分配一个单位，即最小值container mapreduce.reduce.memeory.mb：reduce task的内存分配 设置一般为map task的两倍 *.java.opts：JVM进程参数设置 每个container（其中执行task）中都会运行JVM进程 -Xmx...m：heap size最大值设置，所以此参数应该小于 task（map、reduce）对应的container分配内存的最大值， 如果超出会出现physical memory溢出 -Xms...m：heap size最小值？#todo yarn.nodemanager.vmem-pmem-ratio：虚拟内存比例 以上所有配置都按照此参数放缩 所以在信息中会有physical memory、virtual memory区分 yarn.nodemanager.resource.memory-mb：节点内存设置 整个节点被设置的最大内存，剩余内存共操作系统使用 yarn.app.mapreduce.am.resource.mb：每个Application Manager分配的内存大小 主从文件masters 设置主节点地址，根据需要设置 1hd-master slaves 设置从节点地址，根据需要设置 12hd-slave1hd-slave2 环境设置文件 这里环境设置只是起补充作用，在~/.bashrc已经设置的 环境变量可以不设置 但是在这里设置环境变量，然后把整个目录同步到其他节点， 可以保证在其余节点也能同样的设置环境变量 hadoop-env.sh设置JAVA_HOME为Java安装根路径 1JAVA_HOME=/opt/java/jdk hdfs-env.sh设置JAVA_HOME为Java安装根路径 1JAVA_HOME=/opt/java/jdk yarn-env.sh设置JAVA_HOME为Java安装根路径 12JAVA_HOME=/opt/java/jdkJAVA_HEAP_MAX=Xmx3072m 初始化、启动、测试HDFS 格式化、启动 123456$ hdfs namenode -format # 格式化文件系统$ start-dfs.sh # 启动NameNode和DataNode # 此时已可访问NameNode，默认http://localhost:9870/$ stop-dfs.sh 测试 1234567891011121314151617181920212223242526272829$ hdfs dfsadmin -report # 应该输出3个节点的情况$ hdfs dfs -mkdir /user$ hdfs dfs -mkdir /user/&lt;username&gt; # 创建执行MapReduce任务所需的HDFS文件夹$ hdfs dfs -mkdir input$ hdfs dfs -put etc/hadoop/*.xml input # 复制文件至分布式文件系统$ hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar grep input output 'dfs[a-z]+' # 执行自带样例 # 样例名称取决于版本$ hdfs dfs -get output outut$ cat output/* # 检查输出文件：将所有的输出文件从分布式文件系统复制 # 至本地文件系统，并检查$ hdfs dfs -cat output/* # 或者之间查看分布式文件系统上的输出文件$ hadoop jar /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.7.jar \\ -input /path/to/hdfs_file \\ -output /path/to/hdfs_dir \\ -mapper &quot;/bin/cat&quot; \\ -reducer &quot;/user/bin/wc&quot; \\ -file /path/to/local_file \\ -numReduceTasks 1 YARN12345$ sbin/start-yarn.sh # 启动ResourceManger守护进程、NodeManager守护进程 # 即可访问ResourceManager的web接口，默认：http://localhost:8088/$ sbin/stop-yarn.sh # 关闭守护进程 其他注意事项 hdfs namenode -format甚至可以在datanode节点没有java时 成功格式化 没有关闭防火墙时，整个集群可以正常启动，甚至可以在hdfs里 正常建立文件夹，但是无法写入文件，尝试写入文件时报错 可能错误节点启动不全 原因 服务未正常关闭，节点状态不一致 关闭服务、删除存储数据的文件夹dfs/data、格式化namenode 文件无法写入 could only be replicated to 0 nodes instead of minReplication (=1). There are 2 datanode(s) running and 2 node(s) are excluded in this operation. 原因 未关闭防火墙 存储空间不够 节点状态不一致、启动不全 在log里面甚至可能会出现一个连接超时1000ms的ERROR 处理 关闭服务、删除存储数据的文件夹dfs/data、格式化 namenode 这样处理会丢失数据，不能用于生产环境 尝试修改节点状态信息文件VERSION一致 ${hadoop.tmp.dir} ${dfs.namenode.name.dir} ${dfs.datanode.data.dir} Unhealthy Node 1/1 local-dirs are bad: /opt/hadoop/tmp/nm-local-dir; 1/1 log-dirs are bad: /opt/hadoop/logs/userlogs 原因：磁盘占用超过90% 常用命令1234567891011121314151617181920scp -r /opt/hadoop/etc/hadoop centos2:/opt/hadoop/etcscp -r /opt/hadoop/etc/hadoop centos3:/opt/hadoop/etc # 同步配置scp /root/.bashrc centos2:/rootscp /root/.bashrc centos3:/root # 同步环境rm -r /opt/hadoop/tmp /opt/hadoop/hdfsmkdir -p /opt/hadoop/tmp /opt/hadoop/hdfsssh centos2 rm -r /opt/hadoop/tmp /opt/hadoop/hdfsssh centos2 mkdir -p /opt/hadoop/tmp /opt/hadoop/hdfs/name /opt/hadoop/hdfs/datassh centos3 rm -r /opt/hadoop/tmp /opt/hadoop/hdfs/name /opt/hadoop/datassh centos3 mkdir -p /opt/hadoop/tmp /opt/hadoop/hdfs/name /opt/hadoop/hdfs/data # 同步清除数据rm -r /opt/hadoop/logs/*ssh centos2 rm -r /opt/hadoop/logs/*ssh centos3 rm -r /opt/hadoop/logs/* # 同步清除log Hive依赖 hadoop：配置完成hadoop，则相应java等也配置完成 关系型数据库：mysql、derby等 机器环境配置~/.bashrc12345export HIVE_HOME=/opt/hive # self designedexport HIVE_CONF_DIR=$HIVE_HOME/confexport PATH=$PATH:$HIVE_HOME/binexport CLASSPATH=$CLASS_PATH:$HIVE_HOME/lib/* 文件夹建立HDFS1234$ hdfs dfs -rm -r /user/hive$ hdfs dfs -mkdir -p /user/hive/warehouse /user/hive/tmp /user/hive/logs # 这三个目录与配置文件中对应$ hdfs dfs -chmod 777 /user/hive/warehouse /user/hive/tmp /user/hive/logs FS123456$ mkdir data$ chmod 777 data # hive数据存储文件夹$ mkdir logs$ chmod 777 logs # log目录 Hive配置XML参数conf/hive-site.xml 模板：conf/hive-default.xml.template 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://hd-master:3306/metastore_db?createDatabaseIfNotExist=true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;org.mariadb.jdbc.Driver&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;/value&gt;hive&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;1234&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.exec.scratchdir&lt;/name&gt; &lt;value&gt;/user/hive/tmp&lt;/value&gt;&lt;/property&gt;&lt;!--&lt;property&gt; &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt; &lt;value&gt;${system:java.io.tmpdir}/${system:user.name}&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt; &lt;valeu&gt;${system:java.io.tmpdir}/${hive.session.id}_resources&lt;/value&gt;&lt;/property&gt;&lt;property&gt;« &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt;« &lt;value&gt;${system:java.io.tmpdir}/${system:user.name}/operation_logs&lt;/value&gt;« &lt;description&gt;Top level directory where operation logs are stored if logging functionality is enabled&lt;/description&gt;«&lt;/property&gt;«所有`${system.java.io.tmpdir}`都要被替换为相应的`/opt/hive/tmp`，可以通过设置这两个变量即可，基本是用于设置路径--&gt;&lt;property&gt; &lt;name&gt;system:java.io.tmpdir&lt;/name&gt; &lt;value&gt;/opt/hive/tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;system:user.name&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt;&lt;property&gt;&lt;!--&lt;property&gt; &lt;name&gt;hive.querylog.location&lt;/name&gt; &lt;value&gt;/user/hive/logs&lt;/value&gt; &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;&lt;/property&gt;这里应该不用设置，log放在本地文件系统更合适吧--&gt;&lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://192.168.31.129:19083&lt;/value&gt;&lt;/property&gt;&lt;!--这个是配置metastore，如果配置此选项，每次启动hive必须先启动metastore，否则hive实可直接启动--&gt;&lt;property&gt; &lt;name&gt;hive.server2.logging.operation.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 使用JDBCServer时需要配置，否则无法自行建立log文件夹，然后报错，手动创建可行，但是每次查询都会删除文件夹，必须查一次建一次 --&gt; /user开头的路径一般表示hdfs中的路径，而${}变量开头 的路径一般表示本地文件系统路径 变量system:java.io.tmpdir、system:user.name在 文件中需要自己设置，这样就避免需要手动更改出现这些 变量的地方 hive.querylog.location设置在本地更好，这个日志好像 只在hive启动时存在，只是查询日志，不是hive运行日志， hive结束运行时会被删除，并不是没有生成日志、${}表示 HDFS路径 配置中出现的目录（HDFS、locaL）有些手动建立 HDFS的目录手动建立？ local不用 hive.metastore.uris若配置，则hive会通过metastore服务 访问元信息 使用hive前需要启动metastore服务 并且端口要和配置文件中一样，否则hive无法访问 环境设置文件conf/hive-env.sh 模板：conf/hive-env.sh.template 12345export JAVA_HOME=/opt/java/jdkexport HADOOP_HOME=/opt/hadoopexport HIVE_CONF_DIR=/opt/hive/conf # 以上3者若在`~/.bashrc`中设置，则无需再次设置export HIVE_AUX_JARS_PATH=/opt/hive/lib conf/hive-exec-log4j2.properties 模板：hive-exec-log4j2.properties.template 123property.hive.log.dir=/opt/hive/logs # 原为`${sys:java.io.tmpdir}/${sys:user.name}` # 即`/tmp/root`（root用户执行） conf/hive-log4j2.properties 模板：hive-log4j2.properties.template MetaStoreMariaDB 安装MariaDB 修改MariaDB配置 1$ cp /user/share/mysql/my-huge.cnf /etc/my.cnf 创建用户，注意新创建用户可能无效，见mysql配置 需要注意用户权限：创建数据库权限、修改表权限 初始化时Hive要自己创建数据库（hive-site中配置）， 所以对权限比较严格的环境下，可能需要先行创建同名 数据库、赋权、删库 下载mariadb-java-client-x.x.x-jar包，复制到lib中 初始化数据库1$ schematool -initSchema -dbType mysql 这个命令要在所有配置完成之后执行 服务设置1234567891011$ hive --service metastore -p 19083 &amp; # 启动metastore服务，端口要和hive中的配置相同 # 否则hive无法连接metastore服务，无法使用 # 终止metastore服务只能根据进程号`kill`$ hive --service hiveserver2 --hiveconf hive.server2.thrift.port =10011 &amp; # 启动JDBC Server # 此时可以通过JDBC Client（如beeline）连接JDBC Server对 # Hive中数据进行操作$ hive --service hiveserver2 --stop # 停止JDBC Server # 或者直接kill 测试Hive可用性需要先启动hdfs、YARN、metastore database（mysql），如果有 设置独立metastore server，还需要在正确端口启动 123456hive&gt; create table if not exists words(id INT, word STRING) row format delimited fields terminated by &quot; &quot; lines terminated by &quot;\\n&quot;;hive&gt; load data local inpath &quot;/opt/hive-test.txt&quot; overwrite into table words;hive&gt; select * from words; JDBCServer可用性 命令行连接 1$ beeline -u jdbc:hive2://localhost:10011 -n hive -p 1234 beeline中连接 123$ beelinebeeline&gt; !connect jdbc:hive2://localhost:10011 # 然后输入用户名、密码（metastore数据库用户名密码） 其他可能错误 Failed with exception Unable to move source file linux用户权限问题，无法操作原文件 hdfs用户权限问题，无法写入目标文件 hdfs配置问题，根本无法向hdfs写入：参见hdfs问题 org.apache.hive.service.cli.HiveSQLException: Couldn’t find log associated with operation handle: 原因：hiveserver2查询日志文件夹不存在 可以在hive中通过 1$ set hive.server2.logging.operation.log.location; 查询日志文件夹，建立即可，默认为 ${system:java.io.tmpdir}/${system:user.name}/operation_logs ，并设置权限为777 好像如果不设置权限为777，每次查询文件夹被删除，每 查询一次建立一次文件夹？#todo 在hive-sitex.xml中配置允许自行创建？ User: root is not allowed to impersonate hive 原因：当前用户（不一定是root）不被允许通过代理操作 hadoop用户、用户组、主机 hadoop引入安全伪装机制，不允许上层系统直接将实际用户 传递给超级代理，此代理在hadoop上执行操作，避免客户端 随意操作hadoop 配置hadoop的core-site.xml，使得当前用户作为超级代理 Tez依赖 hadoop 机器环境配置.bashrc1234567891011121314export TEZ_HOME=/opt/tezexport TEZ_CONF_DIR=$TEZ_HOME/conffor jar in `ls $TEZ_HOME | grep jar`; do export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/$jardonefor jar in `ls $TEZ_HOME/lib`; do export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/lib/$jardone # this part could be replaced with line bellowexport HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/*:$TEZ_HOME/lib/* # `hadoop-env.sh`中说`HADOOP_CLASSPATH`是Extra Java CLASSPATH # elements # 这意味着hadoop组件只需要把其jar包加到`HADOOP_CLASSPATH`中既可 HDFS 上传$TEZ_HOME/share/tez.tar.gz至HDFS中 12$ hdfs dfs -mkdir /apps$ hdfs dfs -copyFromLocal tez.tar.gz /apps HadoopOnTez在hadoop中配置Tez 侵入性较强，对已有的hadoop集群全体均有影响 所有hadoop集群执行的MapReduce任务都通过tez执行 这里所有的任务应该是指直接在hadoop上执行、能在 webRM上看到的任务 hive这样的独立组件需要独立配置 XML参数tez-site.xml 模板：conf/tez-default-tmplate.xml 好像还是需要复制到hadoop的配置文件夹中 1234567891011&lt;property&gt; &lt;name&gt;tez.lib.uris&lt;/name&gt; &lt;value&gt;${fs.defaultFS}/apps/tez.tar.gz&lt;/value&gt; &lt;!--设置tez安装包位置--&gt;&lt;/property&gt;&lt;!--&lt;property&gt; &lt;name&gt;tez.container.max.java.heap.fraction&lt;/name&gt; &lt;value&gt;0.2&lt;/value&gt;&lt;property&gt;内存不足时--&gt; mapred-site.xml 修改mapred-site.xml文件：配置mapreduce基于yarn-tez， （配置修改在hadoop部分也有） 1234&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn-tez&lt;/value&gt;&lt;/property&gt; 环境参数HiveOnTez 此模式下Hive可以在mapreduce、tez计算模型下自由切换？ 12345hive&gt; set hive.execution.engine=tez; # 切换查询引擎为tezhive&gt; set hive.execution.engine=mr; # 切换查询引擎为mapreduce # 这些命令好像没用，只能更改值，不能更改实际查询模型 只有Hive会受到影响，其他基于hadoop平台的mapreduce作业 仍然使用tez计算模型 Hive设置 若已经修改了mapred-site.xml设置全局基于tez，则无需复制 jar包，直接修改hive-site.xml即可 Jar包复制复制$TEZ_HOME、$TEZ_HOME/lib下的jar包到$HIVE_HOME/lib 下即可 hive-site.xml1234&lt;property&gt; &lt;name&gt;hive.execution.engine&lt;/name&gt; &lt;value&gt;tez&lt;/value&gt;&lt;/property&gt; 其他可能错误 SLF4J: Class path contains multiple SLF4J bindings. 原因：包冲突的 解决方案：根据提示冲突包删除即可 Spark依赖 java scala python：一般安装anaconda，需要额外配置12export PYTHON_HOME=/opt/anaconda3export PATH=$PYTHON_HOME/bin:$PATH 相应资源管理框架，如果不以standalone模式运行 机器环境配置~/.bashrc1234567export SPARK_HOME=/opt/sparkexport PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbinexport PYTHON_PATH=$PYTHON_PATH:$SPARK_HOME/python:$SPARK_HOME/python/lib/* # 把`pyshark`、`py4j`模块对应的zip文件添加进路径 # 这里用的是`*`通配符应该也可以，手动添加所有zip肯定可以 # 否则无法在一般的python中对spark进行操作 # 似乎只要master节点有设置`/lib/*`添加`pyspark`、`py4j`就行 Standalone环境设置文件conf/spark-env.sh 模板：conf/spark-env.sh.template 这里应该有些配置可以省略、移除#todo 12345678910111213141516171819202122232425262728293031export JAVA_HOME=/opt/jdkexport HADOOP_HOME=/opt/hadoopexport hADOOP_CONF_DIR=/opt/hadoop/etc/hadoopexport HIVE_HOME=/opt/hiveexport SCALA_HOME=/opt/scalaexport SCALA_LIBRARY=$SPARK_HOME/lib # `~/.bashrc`设置完成之后，前面这段应该就这个需要设置export SPARK_HOME=/opt/sparkexport SPARK_DIST_CLASSPATH=$(hadoop classpath) # 这里是执行命令获取classpath # todo # 这里看文档的意思，应该也是类似于`$HADOOP_CLASSPATH` # 可以直接添加进`$CLASSPATH`而不必设置此变量export SPARK_LIBRARY_PATH=$SPARK_HOME/libexport SPARK_MASTER_HOST=hd-masterexport SPARK_MASTER_PORT=7077export SPARK_MASTER_WEBUI_PORT=8080export SPARK_WORKER_WEBUI_PORT=8081export SPARK_WORKER_MEMORY=1024m # spark能在一个container内执行多个taskexport SPARK_LOCAL_DIRS=$SPARK_HOME/data # 需要手动创建export SPARK_MASTER_OPTS=export SPARK_WORKER_OPTS=export SPARK_DAEMON_JAVA_OPTS=export SPARK_DAEMON_MEMORY=export SPARK_DAEMON_JAVA_OPTS= 文件夹建立12$ mkdir /opt/spark/spark_data # for `$SPARK_LOCAL_DIRS` Spark配置conf/slaves文件不存在，则在当前主机单节点运行 模板：conf/slaves.template 12hd-slave1hd-slave2 conf/hive-site.xml这里只是配置Spark，让Spark作为“thrift客户端”能正确连上 metastore server 模板：/opt/hive/conf/hive-site.xml 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://192.168.31.129:19083&lt;/value&gt; &lt;description&gt;Thrift URI for the remote metastor. Used by metastore client to connect to remote metastore&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.port&lt;/name&gt; &lt;value&gt;10011&lt;/value&gt; &lt;/property&gt; &lt;!--配置spark对外界thrift服务，以便可通过JDBC客户端存取spark--&gt; &lt;!--这里启动端口同hive的配置，所以两者不能默认同时启动--&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt; &lt;value&gt;hd-master&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 测试启动Spark服务需要启动hdfs、正确端口启动的metastore server 12345678910$ start-master.sh # 在执行**此命令**机器上启动master实例$ start-slaves.sh # 在`conf/slaves`中的机器上启动worker实例$ start-slave.sh # 在执行**此命令**机器上启动worker实例$ stop-master.sh$ stop-slaves.sh$ stop-slave.sh 启动Spark Thrift Server1234567$ start-thriftserver.sh --master spark://hd-master:7077 \\ --hiveconf hive.server2.thrift.bind.host hd-master \\ --hiveconf hive.server2.thrift.port 10011 # 这里在命令行启动thrift server时动态指定host、port # 如果在`conf/hive-site.xml`有配置，应该不需要 # 然后使用beeline连接thrift server，同hive Spark-Sql测试123456$ spark-sql --master spark://hd-master:7077 # 在含有配置文件的节点上启动时，配置文件中已经指定`MASTER` # 因此不需要指定后面配置spark-sql&gt; set spark.sql.shuffle.partitions=20;spark-sql&gt; select id, count(*) from words group by id order by id; pyspark测试1234567891011121314$ MASTER=spark://hd-master:7077 pyspark # 这里应该是调用`$PATH`中第一个python，如果未默认指定from pyspark.sql import HiveContextsql_ctxt = HiveContext(sc) # 此`sc`是pyspark启动时自带的，是`SparkContext`类型实例 # 每个连接只能有一个此实例，不能再次创建此实例ret = sql_ctxt.sql(&quot;show tables&quot;).collect() # 这里语句结尾不能加`;` file = sc.textFile(&quot;hdfs://hd-master:9000/user/root/input/capacity-scheduler.xml&quot;)file.count()file.first() Scala测试1234567891011121314151617$ MASTER=spark://hd-master:7077 spark-shell \\ executor-memory 1024m \\ --total-executor-cores 2 \\ --excutor-cores 1 \\ # 添加参数启动`spark-shell`import org.apache.spark.sql.SQLContextval sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)sqlContext.sql(&quot;select * from words&quot;).collect().foreach(println)sqlContext.sql(&quot;select id, word from words order by id&quot;).collect().foreach(println)sqlContext.sql(&quot;insert into words values(7, \\&quot;jd\\&quot;)&quot;)val df = sqlContext.sql(&quot;select * from words&quot;);df.show()var df = spark.read.json(&quot;file:///opt/spark/example/src/main/resources/people.json&quot;)df.show() Spark on YARN其他可能错误 Initial job has not accepted any resources; 原因：内存不足，spark提交application时内存超过分配给 worker节点内存 说明 根据结果来看，pyspark、spark-sql需要内存比 spark-shell少？ （设置worker内存512m，前两者可以正常运行） 但是前两者的内存分配和scala不同，scala应该是提交任务 、指定内存大小的方式，这也可以从web-ui中看出来，只有 spark-shell开启时才算是application 解决方式 修改conf/spark-env.sh中SPARK_WORKER_MEMORY更大， （spark默认提交application内存为1024m） 添加启动参数--executor-memory XXXm不超过分配值 ERROR KeyProviderCache:87 - Could not find uri with key [dfs.encryption.key.provider.uri] to create a keyProvider 无影响 HBase依赖 java hadoop zookeeper：建议，否则日志不好管理 机器环境~/.bashrc123export HBASE_HOME=/opt/hbaseexport PATH=$PAHT:$HBASE_HOME/binexport HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$HBASE_HOME/lib/* 建立目录1$ mkdir /tmp/hbase/tmpdir HBase配置环境变量conf/hbase-env.sh12export HBASE_MANAGES_ZK=false # 不使用自带zookeeper conf/zoo.cfg若设置使用独立zookeeper，需要复制zookeeper配置至HBase配置 文件夹中 1$ cp /opt/zookeeper/conf/zoo.cfg /opt/hbase/conf Standalone模式conf/hbase-site.xml12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;file://${HBASE_HOME}/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/tmp/zookeeper/zkdata&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; Pseudo-Distributed模式conf/hbase-site.xml 在Standalone配置上修改 12345678&lt;proeperty&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://hd-master:9000/hbase&lt;/value&gt;&lt;/property&gt; Fully-Distributed模式conf/hbase-site.xml12345678910111213141516&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://hd-master:9000/hbase&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/name&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hd-master,hd-slave1,hd-slave2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/tmp/zookeeper/zkdata&lt;/value&gt;&lt;/property&gt; 测试 需要首先启动HDFS、YARN 使用独立zookeeper还需要先行在每个节点启动zookeeper 123456789101112131415161718$ start-hbase.sh # 启动HBase服务$ local-regionservers.sh start 2 3 4 5 # 启动额外的4个RegionServer$ hbase shellhbase&gt; create 'test', 'cf'hbase&gt; list 'test'hbase&gt; put 'test', 'row7', 'cf:a', 'value7a' put 'test', 'row7', 'cf:b', 'value7b' put 'test', 'row7', 'cf:c', 'value7c' put 'test', 'row8', 'cf:b', 'value8b', put 'test', 'row9', 'cf:c', 'value9c'hbase&gt; scan 'test'hbase&gt; get 'test', 'row7'hbase&gt; disable 'test'hbase&gt; enable 'test'hbaee&gt; drop 'test'hbase&gt; quit Zookeeper依赖 java 注意：zookeeper集群中工作超过半数才能对外提供服务，所以 一般配置服务器数量为奇数 机器环境~/.bashrc123export ZOOKEEPER_HOME=/opt/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/binexport HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$ZOOKEEPER_HOME/lib 创建文件夹 在所有节点都需要创建相应文件夹、myid文件 1234567mkdir -p /tmp/zookeeper/zkdata /tmp/zookeeper/zkdatalogecho 0 &gt; /tmp/zookeeper/zkdatalog/myidssh centos2 mkdir -p /tmp/zookeeper/zkdata /tmp/zookeeper/zkdatalogssh centos3 mkdir -p /tmp/zookeeper/zkdata /tmp/zookeeper/zkdatalogssh centos2 &quot;echo 2 &gt; /tmp/zookeeper/zkdata/myid&quot;ssh centos3 &quot;echo 3 &gt; /tmp/zookeeper/zkdata/myid&quot; Zookeeper配置Confconf/zoo.cfg1234567891011121314151617181920212223242526272829303132tickTime=2000 # The number of milliseconds of each tickinitLimit=10 # The number of ticks that the initial # synchronization phase can takesyncLimit=5 # The number of ticks that can pass between # sending a request and getting an acknowledgementdataDir=/tmp/zookeeper/zkdatadataLogDir=/tmp/zookeeper/zkdatalog # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes.clientPort=2181 # the port at which the clients will connectautopurge.snapRetainCount=3 # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # The number of snapshots to retain in dataDirautopurge.purgeInterval=1 # Purge task interval in hours # Set to &quot;0&quot; to disable auto purge featureserver.0=hd-master:2888:3888server.1=hd-slave1:2888:3888server.2=hd-slave2:2888:3888 # Determine the zookeeper servers # fromation: server.NO=HOST:PORT1:PORT2 # PORT1: port used to communicate with leader # PORT2: port used to reelect leader when current leader fail $dataDir/myid $dataDir是conf/zoo.cfg中指定目录 myid文件里就一个id，指明当前zookeeper server的id，服务 启动时读取文件确定其id，需要自行创建 10 启动、测试、清理启动zookeeper 123456789$ zkServer.sh start # 开启zookeeper服务 # zookeeper服务要在各个节点分别手动启动$ zkServer.sh status # 查看服务状态$ zkCleanup.sh # 清理旧的快照、日志文件 Flume依赖 java 机器环境配置~/.bashrc1export PATH=$PATH:/opt/flume/bin Flume配置环境设置文件conf/flume-env.sh 模板：conf/flume-env.sh.template 1JAVA_HOME=/opt/jdk Conf文件conf/flume.conf 模板：conf/flume-conf.properties.template 1234567891011121314agent1.channels.ch1.type=memory # define a memory channel called `ch1` on `agent1`agent1.sources.avro-source1.channels=ch1agent1.sources.avro-source1.type=avroagent1.sources.avro-source1.bind=0.0.0.0agent1.sources.avro-source1.prot=41414 # define an Avro source called `avro-source1` on `agent1` and tell itagent1.sink.log-sink1.channels=ch1agent1.sink.log-sink1.type=logger # define a logger sink that simply logs all events it receivesagent1.channels=ch1agent1.sources=avro-source1agent1.sinks=log-sink1 # Finally, all components have been defined, tell `agent1` which one to activate 启动、测试1234567891011$ flume-ng agent --conf /opt/flume/conf \\ -f /conf/flume.conf \\ -D flume.root.logger=DEBUG,console \\ -n agent1 # the agent name specified by -n agent1` must match an agent name in `-f /conf/flume.conf`$ flume-ng avro-client --conf /opt/flume/conf \\ -H localhost -p 41414 \\ -F /opt/hive-test.txt \\ -D flume.root.logger=DEBUG, Console # 测试flume 其他Kafka依赖 java zookeeper 机器环境变量~/.bashrc12export PATH=$PATH:/opt/kafka/binexport KAFKA_HOME=/opt/kafka 多brokers配置Confconfig/server-1.properties 模板：config/server.properties 不同节点broker.id不能相同 可以多编写几个配置文件，在不同节点使用不同配置文件启动 123broker.id=0listeners=PLAINTEXT://:9093zookeeper.connect=hd-master:2181, hd-slave1:2181, hd-slave2:2181 测试 启动zookeeper 123456789101112131415161718192021222324252627282930$ kafka-server-start.sh /opt/kafka/config/server.properties &amp; # 开启kafka服务（broker） # 这里是指定使用单个默认配置文件启动broker # 启动多个broker需要分别使用多个配置启动多次$ kafka-server-stop.sh /opt/kafka/config/server.properties$ kafka-topics.sh --create --zookeeper localhost:2181 \\ --replication-factor 1 \\ --partitions 1 \\ --topic test1 # 开启话题$ kafka-topics.sh --list zookeeper localhost:2181 # $ kafka-topics.shd --delete --zookeeper localhost:2181 --topic test1 # 关闭话题$ kafka-console-producer.sh --broker-list localhost:9092 \\ --topic test1 # 新终端开启producer，可以开始发送消息$ kafka-console-consumer.sh --bootstrap-server localhost:9092 \\ --topic test1 \\ --from-beginning$ kafka-console-consumer.sh --zookeeper localhost:2181 \\ --topic test1 \\ --from beginning # 新终端开启consumer，可以开始接收信息 # 这个好像是错的 其他Storm依赖 java zookeeper python2.6+ ZeroMQ、JZMQ 机器环境配置~/.bashrc12export STORM_HOME=/opt/stormexport PAT=$PATH:$STORM_HOME/bin Storm配置配置文件conf/storm.yaml 模板：conf/storm.yarml 1234567891011121314storm.zookeeper.servers: -hd-master -hd-slave1 -hd-slave2storm.zookeeper.port: 2181nimbus.seeds: [hd-master]storm.local.dir: /tmp/storm/tmpnimbus.host: hd-mastersupervisor.slots.ports: -6700 -6701 -6702 -6703 启动、测试1234567891011121314storm nimbus &amp;&gt; /dev/null &amp;storm logviewer &amp;&gt; /dev/null &amp;storm ui &amp;&gt; /dev/null &amp; # master节点启动nimbusstorm sueprvisor &amp;&gt; /dev/null &amp;storm logviewer &amp;&gt; /dev/nulla &amp; # worker节点启动storm jar /opt/storm/example/..../storm-start.jar \\ storm.starter.WordCountTopology # 测试用例stom kill WordCountTopology http://hadoop.apache.org/docs/r3.1.1","link":"/Database/Hadoop/hadoop_inset.html"},{"title":"图算法","text":"总述 图的遍历算法：如何一次访问到网络中所有节点 最短路线算法：两个城市间最佳路线 有向图拓扑排序：课程、预备课程是否有矛盾 All-Pairs Shortest-Paths Problem：完全最短路径问题，找到 每个顶点到其他所有顶点的距离 遍历算法Depth-First Search深度优先查找（DFS） 算法 从任意顶点开始访问图顶点，然后标记为已访问 每次迭代时，紧接着处理与当前顶点邻接的未访问顶点， 直到遇到终点，该顶点所有邻接顶点均已访问过 在终点上，算法沿着来路后退一条边，继续从那里访问未 访问顶点 后退到起始点，且起始点也是终点时，算法停止，这样 起始点所在的连通分量的所有顶点均已访问过 若存在未访问顶点，则必须从其中任一顶点开始重复上述 1234567891011121314151617count = 0 // 全局变量：访问次序（次数）DFS(G) // 对给定图的深度优先查找遍历 // 输入：图G=&lt;V, E&gt; // 输出：图G顶点按照DFS遍历第一次访问到的先后次序， // 未访问到标记未0 for each vertex v in V do if v is marked with 0 dfs(v)dfs(v) // 递归访问所有和v相连接的未访问顶点，赋予count值 count = count+1 mark v with count for each vertex w in V adjecnt to v do if w is marked with 0 dfs(w) 特点 算法效率非常高效，消耗时间和表示图的数据结构规模成正比 邻接矩阵：遍历时间效率$\\in \\Theta(|V|^2)$ 邻接链表：遍历时间效率$\\in \\Theta(|V|+|E|)$ 可以方便地用栈跟踪深度优先查找 首次访问顶点，将顶点入栈 当顶点成为终点时，将其出栈 运行时就是实际上就是栈，所以深度优先可以直接利用递归 实现 Depth-First Search Foreat：参见 algorithm/data_structure/graph DFS产生两种节点排列顺序性质不同，有不同应用 入栈（首次访问顶点）次序 出栈（顶点成为终点）次序 应用 检查图连通性：算法第一次停止后，是否所有顶点已经访问 检查图无环性：DFS是否包含回边 拓扑排序：见键值法 DFS节点出栈逆序就是拓扑排序的一个解（图中无回边， 即为有向无环图） DAG中顶点v出栈前，不存在顶点u拥有到v的边，否则存在 回边，图不是DAG Broad-First Search广度优先查找（BFS） 算法 首先访问所有和初始顶点邻接的顶点 然后是离它两条边的所有未访问顶点 以此类推，直到所有与初始顶点在同一连通分类顶点均已访问 若存在未访问顶点，从图其他连通分量任意顶点开始 1234567891011121314151617181920count = 0 // 全局变量：访问次序（次数）BFS(G) // 给定图广度优先查找变量 // 输入：图G=&lt;V, E&gt; // 输出：图G的顶点按照被BFS遍历第一次访问到次序， // 未访问顶点标记未0 for each vertax v in V do if v is marked with 0 bfs(v)bfs(v) // 访问所有和v相连接的顶点，赋count值 count = count+1 whilte queue is not empty do for each vertex w in V adjcent to the front vertex do if w is marked with 0 count = count+1 mark w with count add w to the queue remove the front vertex from the queue 特点 算法效率同DFS 邻接矩阵：遍历时间效率$\\in \\Theta(|V|^2)$ 邻接链表：遍历时间效率$\\in \\Theta(|V|+|E|)$ 使用队列可以方便地跟踪广度优先查找操作 从遍历初始顶点开始，标记、入队 每次迭代时，算法查找所有和队头顶点邻接未访问，标记 、入队、将队头顶点出队 Breadth-First Search Forest：参见 algorithm/data_struture/graph BFS只产生顶点的一种排序，因为队列时FIFO结构，顶点入队、 出队次序相同 应用 和DFS一样可以检查图的连通性、无环性，但是无法用于比较 复杂的应用 求给定两个顶点间最短路径：从一顶点开始BFS遍历，访问到 另一节点结束（难以证明？） 有向图强连通分量Kosaraju算法考虑有向图中强连通分量之间不连通的情况 强连通分量之间没有边 在任意连通分量中任意结点开始深度优先遍历 访问完所有结点需要DFS次数就是强连通分量数量，每轮 DFS访问的点就是强连通分量中的顶点 强连通分量之间只有单向边 将强连通分量视为单个结点，则整个图可以视为一个 靠连通分量间单向边连接的有向无环图 从最底层强连通分量中任选结点开始进行DFS，则此轮DFS 只能访问当前连通分量中结点 逆序依次在各强连通分量中选择结点进行DFS，则每轮DFS只 访问当前连通分量中结点（其下层连通分量已访问） 直至所有结点访问完毕，则得到所有强连通分量，即每轮 进行DFS访问的结点 以下图为例，从图中连通分量B中任意结点开始进行DFS， 则经过两轮DFS即能找所有强连通分量 由以上分析 只需要保证底层强连通分量进行DFS优先搜索 也即在结点搜索优先级中，底层强连通分量中至少有一个结点 在其上层连通分量所有结点之前 可以利用原图的反向的DFS逆后序排列得到满足条件 的结点优先级序列 若从反向图中最底层强连通分量某结点开始，则只能遍历 自身，反向图中其余连通分量位于其所有结点之前 若从反向图中非最底层强连通分量某结点开始，则能依次 遍历其底层所有强连通分量中结点，且至少该结点位于其余 连通分量所有结点之前 逆后序排列参见algorithm/data_structure/graph 算法 对原图G每条路径求反，得到反向图$G^R$ 对反向图$G^R$求解逆后序序列 按照逆序序列优先级，对原图G进行DFS，每棵DFS生成树就是 一个强连通分量 特点 算法效率 时间效率$\\in O(|V| + |E|)$ 算法需要对图进行两次DFS，速度较Tanjar算法更慢 Tarjan算法Tarjan算法：基于图深度优先搜索的算法 为每个结点维护两个标记，通过此标记确定是否存在回路 DFN：深度优先搜索中搜索到次序 Low：通过回边能访问到的前驱被搜索到的次序 还可以维护一个Flag，判断结点是否仍在DFS栈中 对图进行深度优先搜索 未处理结点入栈，设置其DFN、Low被搜索到的次序 对已处理结点，考虑到深度优先的搜索、退栈方式 仍然在栈中，则肯定是栈顶元素前驱，连接边为回边， 存在栈顶节点到该前驱结点的回路 不在栈中，该节点不是祖先结点，连接边为交叉边， 该结点已经在其他连通分量中出栈 使用栈中前驱结点Low/DFN次序更新当前（栈顶）结点， 并递归更新，即使用子节点访问先驱次序更新父节点 DFS回溯、退栈，考虑栈中每个结点DFN、Low 若DFN[u] &gt; Low[u]：结点u和其前驱之间有回路， 即其属于同一个强连通分量 若DFN[u] == Low[u]：结点u和其前驱之间没有通路， 没有更多结点属于其所属强连通分量，以结点u为根子树 是一个强连通分量 则从栈顶元素开始退栈直至结点u退栈，退栈的所有 元素构成强连通分量 每个强连通分量为深度优先搜索树中一个子树 Low[v] = \\min\\{DFN[v], Low[w], DFN[k]\\} $w, (w, v) \\in E$：顶点v的直接前驱 $k, (v, k) \\in E$：顶点v的祖先（即栈中结点） 算法123456789101112131415161718192021222324252627S = initStack()DFN[MAX_VERTAX], Low[MAX_VERTEX]index = 0QList = InitList(Queue())tarjan(u, E): // 比较DFS搜索次序、回边到达次序判断强连通分量 // 输入：结点u，边集合E // 输出：强连通分量队列列表 DFN[u] = Low[u] = ++ index S.push(u) for each (u, v) in E: if (v is not visited): tarjan(v) Low[u] = min(Low[u], Low[v]) // 使用v找到的前驱更新u能找到前驱，递归更新 else if (v in S): // 判断边是否为回边 Low[u] = min(Low[u], DFN[v]) // Low[u] = min(Low[u], Low[v]) // 应该也行 if(DFN[u] == Low[u]): Q = QList.next() repeat v = S.pop() Q.push(v) until (u == v) 特点 算法效率 时间效率$\\in O(|V|+|E|)$ 关节点类Tarjan算法 类似Tarjan算法为每个节点维护DFN、Low两个次序 对非根结点v，存在其直接后继w有Low[w] &gt;= DFN[v] ，则v为关节点 对根节点，有两棵以上子树则为关节点 算法此算法具体实现和Tarjan算法细节有差异 此算法中不需要使用栈保存访问过顶点中是前驱者 连通无向图DFS只会有回边，已访问点必然是前驱结点 需要对根结点额外判断是否为关节点 12345678910111213141516171819202122232425262728293031323334DFN[MAX_VERTAX], Low[MAX_VERTEX]index = 0Q = InitQueue()FindArticul(G): // 输入：无向连通图G // 输出：关节点队列 vroot = G.V.pop() TarjanArticul(vroot, G) for(v in G.V if v not visited) // 根节点有两棵及以上子树 TarjanAricul(vroot, G) Q.push(vroot) // 根节点也是关节点 return QTarjanArticul(u, G): // 比较DFS搜索次序、回边到达次序判断关节点 // 输入：结点u，无向连通图G // 输出：关节点队列 DFN[u] = Low[u] = ++ index for each (u, v) in G.E: if (v is not visited): tarjan(v) Low[u] = min(Low[u], Low[v]) // 使用v找到的前驱更新u能找到前驱，递归更新 else: Low[u] = min(Low[u], DFN[v]) // Low[u] = min(Low[u], Low[v]) // 应该也行 for(v connected by u) if(Low[v] &lt;= DFN[u]) Q.push(u) return Q 无权路径路径数量图中顶点i到顶点j之间长度为k的不同路径数量为$A^k[i, j]$ A为图的邻接矩阵 可以使用数学归纳法证明 对无向、有向图均适用 Warshall算法Warshall算法：生成有向图传递闭包 构造n+1个n阶布尔矩阵$R^{(k)}, k=0,1,\\cdots, n$ $R^{(k)}_{ij}=1$：顶点i、j直接存在中间顶点编号 不大于k的有效路径 $R^{(0)}$：邻接矩阵，顶点直接连接 $R^{(k)}, 0&lt;k&lt;n$：路径中间顶点编号最大为k $R^{(n)}$：传递闭包，允许所有类型路径 后继矩阵相对前趋，允许作为路径上顶点增加，可能包含 1数量更多 考虑$R^{(k)}$通过直接前趋$R^{(k-1)}$计算得到 $R^{(k-1)}$中已有路径在$R^{(k)}$保留 考虑$R^{(k)}$相较于$R^{(k-1)}$新增$r_{ij}=1$ 表示顶点i、j之间存在包含k的路径 若k在路径中出现多次，则将删除回路，得到新路径 则存在ik和kj之间路径满足中间顶点编号小于k，即在 $R^{(k-1)}$中有$r{ik}=1, r{kj}=1$ 算法 若元素$r_{ij}$在$R^{(k-1)}$中为1，则在$R^{(k)}$也是1 若元素$r{ij}$在$R^{(k-1)}$中为0，当且仅当存在v使得 $R^{(k-1)}$中$r{iv}=1, r_{vj}=1$ 123456789101112Warshall(A[1..n, 1..n]) // 计算传递闭包的Warshall算法 // 输入：A[1..n, 1..n]包含n个顶点的有向图的邻接矩阵 // 输出：A的传递闭包 R^0 = A for i = 1 to n do for i = 1 to n do for j = 1 to n do if R^(k-1)[i, j] == 1 or (R^(k-1)[i, k] == 0 and R^(k-1)[k, j] == 0) R^k[i, j] = 1 return R^n 算法特点 算法效率 时间效率$\\in \\Theta(n^3)$ 重新构造最内层循环，可以提高对某些输入的处理速度 将矩阵行视为位串，使用或运算也可以加速 空间效率取决于如何处理布尔矩阵 蛮力法：所有点分别作为起点作一次搜索，记录能够访问的顶点 对有向图遍历多次 使用邻接链表表示稀疏图，蛮力法渐进效率好于Warshall算法 最小生成树Prim算法Prim算法：求解最小图最小生成树算法 每次添加距离当前树距离最近顶点进树 不断迭代构造最小生成树 算法 从图顶点集V中任选单顶点作为序列中初始子树 对图中顶点维护两个标记：树中最近顶点、相应距离 与树不直接相连顶点置：NULL、$\\infty$ 每次添加新节点更新两个标记 可使用优先队列维护提高效率 以贪婪的方式扩张当前生成树，添加不在树中的最近顶点 更新顶点和树距离最近的顶点、相应距离 只需考察与新添加顶点直接相连顶点即可 不断迭代直到所有点都在树中 12345678910111213141516171819202122232425262728293031Prim(G): // 构造最小生成树Prim算法 // 输入：加权连通图G=&lt;V, E&gt; // 输出：E_T, 组成G最小生成树的边集合 V_T = {v_0} // 使用任意顶点初始化树顶点集合 E_T = NULL // 初始化生成树边为空集 for i = 1 to |V| if i connect V_T connect_V[i] = 0 connect_D[i] = e(0, i) else connect_V[i] = NULL connect_D[i] = \\infty // 初始化节点和树最近节点列表、节点与树距离列表 for i = 1 to |V|-1 do // 重复n-1次，直到树包含所有顶点 edge = min(connect_D) // 寻找距离树最近的点 v = vertex(edge) V_T = V_T union {v} E_T = E_T union {edge} connect_V[v] = NULL connect_D[v] = \\infty 更新和v相连的顶点两个标记值 return E_T 算法特点 算法时间效率依赖实现优先队列、存储图数据结构 图权重矩阵、优先队列无序数组$\\in \\Theta(|V|^2)$ 图邻接链表、二叉最小堆$\\in O(|E|log|V|)$ 图邻接链表、Fibonacci Heap $\\in O(|E| + |V|log|V|)$ 对树进行扩展时用到的边的集合表示算法生成树 穷举查找构造生成树，生成树数量呈指数增长，且构造生成树 不容易 Kruskal算法Kruskal算法：把最小生成树看作是具有$|V|-1$条边、且边权重最小 的无环子图，通过对子图不断扩展构造最小生成树 算法 按照权重非递减顺序对图中边排序 从空子图开始扫描有序列表，试图把列表中下条边加到当前子图 中，如果添加边导致回路则跳过 不断添加边直到达到$|V|-1$ 1234567891011121314151617Kruskal(G) // 构造最小生成树的Kruskal算法 // 输入：G=&lt;V, E&gt;加权连通图 // 输出：E_T，组成G的最小生成树边集 reverse_sort([w(e_i)]) // 按照边权非递减顺序对边集排序 E_T = NULL ecounter = 0 k = 0 while ecounter &lt; |V|-1 do k += 1 if E_T union {e_k} 无回路 // 常用并查算法检查`e_k`连接的两个顶点是否在 // 同一棵树（并查集）中 E_T = E_T union {e_k} ecounter += 1 return E_T 算法特点 Kruskal每次迭代都需要检查添加新边是否会导致回路，其实 效率不一定比Prim算法高 Kruskal算法中间阶段会生成一系列无环子图（树） 子图不总是联通的 可以看作是对包含给定图所有顶点、部分边的森林所作的 连续动作 初始森林由|V|棵普通树构成，包含单独顶点 最终森林为单棵树，包含图中所有顶点 每次迭代从图的边有序列表中取出下条边，找到包含其端点 的树，若不是同一棵树，则加入边生成一棵更大的树 算法效率 如果检查顶点是否位于同一棵树算法高效，则算法运行时间 取决于排序算法，时间效率$\\in O(|E|log|E|)$ Sollin算法Sollin算法：Prim算法、Kruskal算法的结合，将图每个顶点视为 子树，每次添加多条边合并子树直至得到最小生成树 算法 将图中每个顶点视为一棵树，整个图表示森林$F^{(0)}$ 为森林$F$中每棵树选择最小代价边合并两棵树 重复以上，直至所有树合并为一棵树 123456789101112Sollin(G): // 无向图最小生成树Sollin算法 // 输入：无向图G // 输出：最小生成树边集 MST_E = NULL Forest = G.V while |MST_E| &lt; |G.V|: for tree in Forest: e = find_min(G.E) tree_b = get_tree(e) MET_E.add(e) tree.union(tree_b) todo算法特点 算法效率 每轮子树数量减少一半，则最多重复log|V|轮算法终止 时间效率$\\in O(|E|log|V|)$ 最短路径Dijkstra算法Dijkstra算法：求解单起点、权值非负最短路径算法 按照从给定起点到图中各顶点的距离，顺序求出离起始点 最近的顶点、相应最短路径 第i次迭代前，算法已经确定了i-1条连接起点、离起点前i-1近 顶点的最短路径 这些构成了给定图的一棵子树$T_i$ 可以在同$T_i$顶点邻接的顶点中找到和起点最接近的顶点 （边权非负） 算法类似于Prim算法，两个对代价评价标准不同 Dijkstra算法是各条路径长度：有重复边，考虑整个路径 Prim算法是评价各边总和：无重复边，只考虑一条边 算法 对顶点维护两个标记：起点到该顶点最短路径长度d、路径上 前个顶点pre_v 一般使用优先队列维护最短路径长度 对所有顶点维护：$\\infty$、NULL标记不在树中、不与树 邻接顶点 仅对生成树中顶点、邻接顶点维护：每次迭代更新列表 根据标记选择邻接顶点中和起始点距离d最小顶点，添加进树 更新顶点标记 因为生成树只新添加一个顶点，只需要考虑与新添加顶点 直接相连、未在树中顶点 比较与起始点距离是否改变 不断迭代直至所有点均在树中 12345678910111213141516171819202122232425Dijkstra(G, s) // 单起点最短路径Dijkstra算法 // 输入：G=&lt;V, E&gt;非负权重加权连通图，顶点s起始点 // 输出：对V中每个顶点，从s到v的最短路径长度d_v Initialize(Q) // 将顶点优先队列初始化为空 for v in V d_v = \\infty p_v = NULL Insert(Q, s, d_s) // 初始化有限队列中顶点优先级 d_s = 0 Decrease(Q, s, d_s) // 更新s优先级为d_s V_T = NULL for i = 0 to |V|-1 do u* = DeleteMin(Q) // 删除优先级最小元素 V_T = V_T \\union {u*} for v in V-V_T 中与u*邻接顶点 do if d_u* + w(u*, u) &lt; d_u d_u = d_u* + w(u*, u) p_u = u* Decrease(Q, u, d_u) 算法特点 算法时间效率同Prim算法 Bellman-Ford算法Bellman-Ford算法：求解单节点、权值正负无限制最短距离 权值正负无限制意味着贪心策略不再有效 要求路径中不存在负权值回路 对n个顶点图，路径最长为n-1，否则删除回路路径长度不增加 算法考虑使用动态规划算法 令$dist^{(l)}[u]$表示从起点v到节点u边数不超过l的最短 路径长度 在不允许出现负权值回路的前提下，构造最短路算法过程 最多只需要考虑n-1条边 即$dist^{(n-1)}$是从v到u不限制路径中边数目的最短路径 长度 Floyd算法Floyd算法：求解完全最短路径问题，有向、无向、加权图均适用 （边距离不为负，否则距离可以任意小） 构造n+1个距离矩阵$D^{(k)}, k=0,1,\\cdots,n$ $D^{(k)}$中元素$d_{ij}$表示顶点i、j之间由编号小于k的 顶点作为中间顶点的距离 $D^{(0)}$：初始权重矩阵 $D^{(k)}, 0&lt;i&lt;n$：路径中顶点编号最大为k $D^{(n)}$：目标距离矩阵 后继矩阵相对前趋，允许作为路径上顶点增加，各顶点间 距离可能缩短 考虑$D^{(k)}$通过直接前趋$D^{(k-1)}$计算得到，其中距离 （路径）分为两类 $d^{(k)}{ij} = d^{(k-1)}{ij}$：不包含顶点k作为中间 节点的路径 $d^{(k)}{ij} = d^{(k-1)}{ik} + d^{(k-1)}{kj} &lt; d^{(k-1)}{ij}$： 包含顶点k作为中间节点的路径 算法 d^{(k)}_{ij} = \\min \\{ d^{(k-1)}_{ik} + d^{(k-1)}_{kj}, d^{(k-1)}_{ij}, d^{(k-1)}_{ij} \\}12345678910Floyd(W[1..n, 1..n]) // 计算完全最短路径的Floyd算法 // 输入：W不包含负距离的距离矩阵 // 输出：包含最短距离的距离矩阵 D^0 = W for k = 1 to n do for i = 1 to n do for j = 1 to n do D[i, j] = min(D[i, j], D[i, k] + D[k, j]) return D 算法特点 算法效率 时间效率同Warshall算法为立方级 如上伪码的空间效率为平方级（没有创建n+1距离矩阵） Floyd算法类似于Warshall算法 Floyd算法利用最优性原理，即最短路径中子路径也是最短 最大流量问题Augmenting-Path MethodShortest-Augmented-Path算法最短增益路径法（first-labeled first-scanned algorithm） 对网络中顶点维护两个标记 从源点到被标记顶点能增加流量数 路径中前个顶点名称 +：从前向边访问到当前顶点 -：从后向边访问到当前顶点 对网络的每条边$(i, j)$，初始化流量为$x_{ij}=0$ 从源点开始同时沿着前向边、后向边进行广度优先搜索 先更新前向边 只有有增益空间边（顶点）才能被访问 更新搜索到顶点标记 源点被标记表明得到一条增量路径，沿着标记反向更新边流量 若广度优先搜索无法达到源点，表明不存在流量增益路径，当前 流量值作为最大值返回 12345678910111213141516171819202122232425262728293031323334353637383940ShortestAugmentingPath(G) // 最短增量路径算法 // 输入：流量网络G // 输出：最大流量x 对网络中每条边，设置x[i, j] = 0 把源点标记为(\\infty, -)，加入空队列Q中 // 使用队列实现广度优先搜索 while not Empty(Q) do i = Front(Q) Dequeue(Q) for 从i到j的每条边 do // 遍历从i出发的边，前向边 if j未被标记 r[i, j] = = u[i, j] - x[i, j] if r[i, j] &gt; 0 l[j] = min{l[i], r[i, j]} /// 更新从源点到顶点j能增加的流量数 用l[j], i+标记j Enqueue(Q, j) for 从j到i的每条边 do // 遍历到达i的边，后向边 if j未被标记 if x[j, i] &gt; 0 l[j] = min{l[i], x[j, i]} // 更新源点到顶点j能增加的流量数 用l[j], i-标记j Enqueue(Q, j) if 汇点被标记 // 沿着找的增益路径进行增益 j = n while j != 1 // 反向更新到源点为止 if 顶点j前个节点为i+ // 通过前向边访问到顶点j x[i, j] = x[i, j] + l[n] else x[j, i] -= l[n] j = i 去除除源点外所有顶点标记 重新初始化化队列Q 算法特点 算法正确性可以（联合）最大流-最小割定理证明 算法时间效率 可以证明最短增益路径算法用到的增益路径数量不超过 $|V||E|/2$ 对使用邻接列表表示的网络，用广度优先查找找到一条增益 路径的时间$\\int O(|V|+|E|)$ 所有算法时间效率$\\in O(|V||E|^2)$ 迭代算法 Preflow推进算法预流：满足容量约束，但是不满足流量守恒约束 把过剩流量向汇点处移动，直到网络所有中间顶点都满足流量 守恒约束为止 算法特点 算法时间效率 这类算法中较快者最差效率可以接近$O(|V||E|)$ Dinitz算法Karzanov算法Malhotra-Kamar-Maheshweari算法Goldberg-Tarjan算法单纯形法此问题仍然是线性规划问题，可以使用单纯形法等通用解法求解 最大匹配（二分图）匈牙利算法算法 对U中每个顶点维护一个标记：与其匹配的对偶顶点 从V中的一个自由顶点v出发，按广度优先搜索找到U中自由 顶点u，寻找增益路径，搜索过程中 V中顶点：按照广度优先搜索，得到不在匹配M中的边 搜索到U中自由顶点，则停止得到增益路径 搜索到U中被标记顶点，则连接上已有匹配 U中顶点：直接找到其在V中的对偶顶点，得到在M中边 得到一个增益路径，沿着增益路径回溯，奇数边加入匹配 未找到自由顶点时，则无法得到增益路径 1234567891011121314151617181920212223242526272829303132333435363738394041MaximumBipartiteMatching(G) // 用类似广度优先算法遍历求二分图的一个最大匹配 // 输入：二分图G=&lt;V, U, E&gt; // 输出：输入图中一个最大基数匹配 初始边集合M包含某些合法的匹配（例如空集合） 初始队列Q包含V的所有自由顶点（任意序） while not Empty(Q) do w = Front(Q) Dequeue(Q) if w \\in V for 邻接w的每个顶点u do // 二分图性质保证u一定在U中 if u是自由顶点 // 增益 M = M \\union (w, u) // 首边进匹配 v = w while v已经被标记 do // 从增益路径回溯生成匹配 u = 以v标记的点 M -= (v, u) // 偶数边出匹配 v = 以u标记的点 M += (v, u) // 奇数边进匹配 删除所以顶点标记 用V中所有自由顶点重新初始化Q break // 增益后，重新搜索 else // u已经匹配 if (w, u) not \\in M and u未标记 用w标记u Enqueue(Q, u) else // w \\in U，此时w必然已经匹配 用w标记w的对偶v // 将已有匹配添加进增益路径中 Enqueue(Q, v) return M // 当前匹配已经是最大匹配 算法特点 注意：从自由顶点开始寻求匹配时，无论是否找到增益路径， 路径中中U中节点标记已经更新，匹配仅在得到增益路径才更新 算法时间效率 每次迭代花费时间$\\in O(|E|+|V|)$，迭代次数 $\\in O(|V|/2 + 1)$ 若每个顶点的信息（自由、匹配、对偶）能在常数时间内 得到（如存储在数组中） 则算法时间效率$\\in O(|V|(|V| + |E|))$ 算法正确性参见图graph_undirected关于增益路径-最大匹配 迭代算法 霍普克罗夫-卡普算法算法特点 对匈牙利算法的改进，把多次迭代在一个阶段完成，然后用一次 查找把最大数量边添加到匹配中 算法时间效率：$\\in O(\\sqrt {|V|}(|V| + |E|))$ 稳定婚姻问题婚姻稳定算法存在自由男士，任选求婚、回应之一执行，直至不存在自由男士 求婚：自由男士m向女士w求婚，w为其优先级最大、之前未拒绝 过其女士（可以是已匹配） 回应：若女士w自由则接受男士m求婚，与之配对；女士w不自由 则把m同当前配偶匹配，选择其中优先级较高者 算法算法特点 算法会在$n^2$次迭代内终止：至多每位男士向所有女士求婚 性别倾向：总是生成man-optimal的稳定匹配，优先满足 男士偏好 在任何稳定婚姻中，总是尽可能把优先级最高的女士分配给 男性 使用女士进行求婚也只会把性别偏见反向，而不能消除 对给定的参与者优先选择集合而言，男士（女士）最优匹配唯一 由性别性别倾向容易证明 所以算法的输出不取决于自由男士（女士）求婚顺序，可以 使用任何数据结构表示参与者集合而不影响结果 算法最终输出匹配M为稳定婚姻匹配证明参见graph 分配问题（二分图）n个任务分配给n个人执行（一人一个），将任务j分配个人i的成本为 $C_{ijd}$，求最小成本分配方案 类似问题：最大权重匹配问题 蛮力算法算法 生成整数n的全部排列 根据成本矩阵计算每个分配方案总成本 选择和最小的方案 特点 算法排列次数为$n!$ 分支界限法 第i层节点下界可取：$lb = c + \\sum_{k=i+1}^n min{c_k}$ $c$：当前成本 $min{c_k}$：成本矩阵第k行最小值 算法特点匈牙利算法算法特点Topological Sorting拓扑排序：按照次序列出有向图的顶点，使得对图中每条边，其 起始顶点总在结束顶点之前 删点法算法 在有向图中求出源（没有输出边的顶点），然后把删除其和所有 从它出发的边 不断重复，直到不存在源，如果此时图中还有顶点，则图中存在 环，无解 则删除节点顺序即为拓扑排序可行解 12345678910111213141516171819202122232425TopologicalSort(G): // 从有向图中不断删除入度为0的点、入栈，判断有向图G是否 // 为DAG，并给出拓扑排序栈 // 输入：有向图G // 输出：拓扑排序栈T InitStack(S) indgree = [v.indegree for v in G] for v in G: if v.indgree == 0 S.push(v) // 存储0入度结点栈 count = 0 // 删除结点计数 while(!S.empty()) v = S.pop() T.push(v) count++ for(u connected to v) if --indgree.u == 0 S.push(u) if count &lt; |G.V| // 结点未删除完毕，但无0入度结点 // G中有回路，报错 return ERROR return T 特点 算法效率 时间效率$\\in O(|V|+|E|)$ 减常数法 DFS逆后序遍历图中无环时，由某点出发进行DFS 最先退出DFS的为出度为0的点，即拓扑有序序列中最后顶点 按照DFS退出先后次序得到序列即为逆向拓扑有序序列 使用逆后序方式存储DFS访问顶点，判断是否有环、出栈 次序即为正向拓扑有序序列 应用 判断庞大项目中相互关联任务不矛盾，然后才能合理安排，使得 项目整体完成时间最短（需要CPM、PERT算法支持） Cirtical Path问题找出使用AOE网表示的工程的中关键路径 关键路径由关键活动构成 即耗费时间变动对工程整体完成时间有影响的活动 拓扑排序求解 最早、最晚开始时间检查是否为关键活动 建立活动（边）、事件（顶点）发生事时间关系 拓扑排序求解事件发生最早、最晚时间 具体参见algorithm/data_structure/graphdi_specials 算法12345678910111213141516171819202122232425262728293031323334353637383940414243444546TopologicalOrder(G): // 从有向图中不断删除入度为0的点、入栈，判断有向图G是否 // 为DAG，并给出拓扑排序栈 // 输入：有向图G // 输出：拓扑排序栈T、顶点事件最早发生事件ve InitStack(S) indgree = [v.indegree for v in G] ve[0..|G.V|] = 0 for v in G: if v.indgree == 0 S.push(v) // 存储0入度结点栈 count = 0 // 删除结点计数 while(!S.empty()) v = S.pop() T.push(v) count++ for(u connected by v) ve[u] = max{ve[u], ve[v] + len(v, u)} // 若有更长路径，更新 if --indgree[u] == 0 S.push(u) if count &lt; |G.V| // 结点未删除完毕，但无0入度结点 // G中有回路，报错 return ERROR return T, veCriticalPath(G, T, ve): // 逆序求顶点事件最晚发生时间，求出关键活动 // 输入：有向无环图G，G拓扑排序 // 输出：关键活动队列Q vl[0..|G.V|] = ve Q = InitQueue() while(!T.empty()) v = T.pop() for (u connect to v) vl[u] = min{vl[u], vl[v] - len(u, v)} for(v in G.V) for (u connected by v) ee = ve[v] el = vl[u] - len(v) if(el == ee) Q.push(G.edge(v, u)) return Q 以上算法中在生成拓扑排序栈时同时得到各顶点事件最早发生 时间 可以只获取拓扑排序栈，然后处理其获得顶点事件最早发生时间 ，将两个功能分离，只是处理一遍顶点而已 也可以使用其他算法获得拓扑排序栈 DFS遍历甚至可以遍历顶点一遍，同时获得顶点事件最早、 最晚发生时间 特点 算法效率 时间效率$\\in O(|V|+|E|)$ 哈密顿回路问题确定给定图中是否在包含一条哈密顿回路 回溯算法算法 对所有节点维护标记：是否位于当前路径中 选择某节点a作为哈密顿回路起点顶点，即回溯状态空间树根 从根节点开始处理 若节点周围还有未标记节点，选择下个加入路径、标记 若节点周围没有未标记节点，回溯到之前节点重新处理 直到所有节点都被标记，且当前节点和根节点相邻 特点旅商问题Traveling Salesman Problem：对相互之间距离已知为正整数的n座 城市，求最短漫游路径，使得在回到出发城市之前，对每个城市只 访问一次 即：对权重为正整数的无向完全图寻找最短哈密顿回路 蛮力算法算法 生成n-1个中间城市的组合得到所有旅行线路 计算线路长度，求得最短路径 特点 算法排序次数为$(n-1)!/2$ 改进 线路成对出现，只是方向相反，可考虑任意两个相邻顶点，只 考虑包含其某个排序的线路 分支界限法 第i层下界可取$lb = \\sum{k=i+1}^n d{k1}$ 更紧密、也不复杂的下界 $lb = \\lceil \\frac {\\sum{k=i+1}^n (d{k1} + d_{k2})} 2 \\rceil$ $d{k1}, d{k2}$：城市$i+1$到最近的两个城市距离 最短路径为两个端点共享，至多只能有一个端点能够成为 该边起点 若要求所有哈密顿回路中必须包括某些边，则在考虑相应 边端点城市时，使用必须边（若不是节点最短边）替换其中 次短边 只需要生成某对节点有序的路径：可以消去状态空间树中部分 分支 算法特点旅商问题非精确算法以下均是讨论TSP问题的欧几里得实例，不对称实例等已经证明更难 解决，对精确算法、启发式算法都是如此 贪婪算法Nearest-Neighbor算法 任意选择城市开始 每次访问和当前城市k最接近的城市，直到访问完所有城市 回到开始城市 Multifregment-Heuristic算法求给定加权完全图的最小权重边集合，且每个顶点连通度均为2 将边按权重升序排列，将要构造的旅途边集合开始时空集合 不断尝试将排序列表中下条边加入旅途边集合 边加入不会使得某节点连通度大于2 不会产生长度小于n的回路 否则忽略这条边 返回旅途集合 算法特点对属于欧几里得类型的旅商问题实例（大部分） 此时虽然两个算法的精确性能比无法界定，但是满足 $\\frac {f(s_a)} {f(s^{*})} \\leqslant \\frac 1 2 (\\lceil log_2 n \\rceil + 1)$ Minimum-Spaning-Tree-Based Algorithm基于最小生成树的算法 哈密顿回路中去掉一条边就能得到一棵生成树$T_h$ 可以先构造一棵最小生成数$T^{*}$，然后在其基础上构造近似 最短路径 Twice-Around-The-Tree算法 对给定实例构造最小生成树$T^{}$（Prim, Kruskal*） 从任意顶点开始，（利用深度优先遍历）绕树散步一周，记录 经过顶点 扫描顶点列表，消去重复出现顶点（走捷径，直接去新城市）， 除列表尾部重复起点，得到一条哈密顿回路 可能是考虑到最小生成树能够选出部分最短路径？？？ 特点对属于欧几里得类型的旅商问题 绕树两周算法是2近似算法：$2f(s^{*}) &gt; f(s_a)$ $f(s^{} &gt; w(T_h) \\geqslant w(T^{})$：最优哈密顿 回路去掉一条边后长度大于等于最小生成树长度 $f(s^{}) &lt; 2w(T^{})$：第二次扫描走捷径距离小于绕树 一周距离 这里限定了特点类型实例，并没有找到对所有旅商问题的 优先近似算法 Christofides算法同样利用问题与最小生成树的出关系，但更复杂 算法 对给定实例构造最小生成树$T^{*}$ 构造包含包含$T^{*}$的欧拉回路 找出最小生成树中所有连通度为奇数的顶点 求出这些顶点的最小权重匹配（匈牙利算法） 将最小权重匹配边加入树中得到多重图欧拉回路 使用走捷径方法将欧拉回路转换为哈密顿回路 特点对属于欧几里得类型的旅商问题 绕最小生成树一周得到的路径是多重图的一条欧拉回路，其中 多重图为将当前图每条边重复一遍得到 绕树两周算法：直接原始欧拉回路上走捷径 Christofides算法：重新构建更短的欧拉回路，在此基础 上走捷径 Christofides算法是1.5近似算法 实际应用中，Christofides算法近似解明显好于绕树两周 可以对连通度大于2顶点尝试不同访问次序，即将回路 中邻接顶点分别两两组合，找到访问其的最佳路径 迭代改进算法Local Search Heuristics：本地查找启发法 这类算法从某个初始旅途（随机或简单近似算法生成）开始 每次迭代把当前旅途一些边用其他边代替，试图得到和当前旅途 稍有差别的旅途 若能得到优于当前旅途的新旅途，则替换当前旅途，继续 寻找 否则，返回当前旅途，停止 2选算法删除旅途中2条非临边，把两条边端点用另一对边重新连接 此操作称为2改变 为保证重连后得到合法哈密顿回路，重连方法只有一种 3选算法删除3条非临边后重连 重连方法有3种 事实上可以推广到k选，但是只有3改变被证明有意义 Lin-Kernighan算法变选算法算法的一种 可以视为在3选操作后进行一系列2选操作 算法特点 迭代改进算法求得的近似解效果质量非常好 Lin-Kernighan算法是公认的求解高质量近似解的最佳算法 Held-Karp BoundHeld-Karp下界 将TSP描述为线性规划问题求解（忽略整数约束）得到，计算 速度快 一般和最优旅途长度非常接近，误差不超过1% 可使用其代替最短旅途估计近似算法的精确度 模拟 10000个随机点：坐标、距离取整 Comqaq ES40：500MHz的Alpha处理器、2GB内存 启发式算法 超过Held-Karp下界的% 运行时间 最近邻居 24.79 0.28 多片段 16.42 0.20 Christofides 9.81 1.04 2选 4.70 1.41 3选 2.88 1.50 Lin-Kernighan 2.00 2.06","link":"/Algorithm/Problem/graph.html"},{"title":"Special Methods","text":"综述特殊方法：python类中具有特殊名称的方法，实现由特殊语法 所引发的特定操作 python实现操作符重载的方式 允许每个类自行定义基于操作符的特定行为 特定操作包括python内置的钩子函数 钩子函数不能简单的看作直接调用特殊方法 尝试调用备用实现：iter、reversed 修改方法返回值：dir 大部分情况下，若没有定义适当方法，尝试执行操作将 raise AttributeError、raise TypeError 但__hash__、__iter__、__reversed__、 __contains__等方法即使未定义，其对应钩子函数 实现会尝试调用可能的其他方法完成操作 （直接obj.__xxx__调用方法仍然报错） 将特殊方法设为None表示对应操作不可用，此时即使以上 hash、iter、reversed、in等操作也不会尝试调用 备用方法 实例创建、销毁调用类时，元属性方法执行顺序 __prepare__()：创建命名空间 依次执行类定义语句 __new__()：创建类实例 __init__()：初始化类 __new__返回的新实例的__init__方法将被调用 用户定义__new__返回对象不一定期望类实例，调用的 __init__随之不一定是期望方法 返回__new__返回类实例 __prepare__ 在所有类定义开始执行前被调用，用于创建类命名空间 一般这个方法只是简单的返回一个字典或其他映射对象 __new__12classmethod object.__new__(cls[, *args, **kwargs]): pass 用途：创建、返回cls类新实例 super().__new__(cls[,...])调用超类方法创建类实例， 然后根据需要修改新创建实例再返回 参数 cls：待实例化类 其余参数：类构造器表达式参数 返回值：cls类新实例 __new__返回值就是类构造器的返回值，有绝对控制权 说明 __new__：builtin_function_or_method __new__是静态方法：以需实例化类作为第一个参数 __new__方法绑定当前类对象 特例，不需要显式声明为静态方法 原生有两个__new__函数，二者C实现不同 type.__new__：元类继承，用于创建类对象 object.__new__：其他类继承，用于创建实例 __init__12def object.__init__(self[, *args, *kwargs]): pass 用途：初始化类实例 类构造器中__new__返回类实例调用此方法初始化 若基类有用户定义__init__方法，则其派生类__init__ 应该显式调用基类__init__保证基类部分正确初始化 参数 self：当前类实例 其余参数：类构造器表达式参数 返回值：None，否则raise TypeError __del__1def object.__del__(self) 用途：实例销毁时（引用计数变为0）被调用 若基类有__del__方法，则其派生类__del__方法中 需要显式调用基类__del__保证基类部分正确清除 对象重生：在其中创建该实例的新引用推迟其销毁 不推荐 重生对象被销毁时__del__是否会被再次调用取决于 具体实现 当前CPython实现中只会调用一次 说明 解释器退出时不会确保为仍然存在的对象调用__del__方法 “钩子函数”：del del x不直接调用x.__del__() del x仅将x的引用计数减一 输出属性__repr__12def object.__repr__(self): pass 用途：输出对象的“官方”字符串表示 如果可能，应类似有效的python表达式，可以用于重建具有 相同取值的对象（适当环境下） 若不可能，返回形如&lt;...some useful description...&gt; 的字符串 常用于调试，确保内容丰富、信息无歧义很重要 返回值：字符对象 内置钩子函数：repr 交互环境下直接“执行”变量的结果 __str__12def object.__str__(self): pass 用途：生成对象“非正式”、格式良好的字符串表示 返回较方便、准确的描述信息 返回值：字符串对象 内置钩子函数：str 说明 object.__str__方法默认实现调用object.__repr__ 所以若未定义__str__，需要实例“非正式”字符串表示时 也会使用__repr__ format、print函数会隐式调用对象__str__方法 此时若__str__返回非字符串会raise TypeError __bytes__12def object.__bytes__(self): pass 用途：生成对象的字节串表示 返回值：bytes对象 内置钩子函数：bytes __format__1def object.__format__(self, format_spec) 用途：生成对象的“格式化”字符串表示 内部常调用format、str.format实现格式化 object.__format__(x, '')等同于str(x) 参数 fomrat_spec：包含所需格式选项描述的字符串 参数解读由实现__format__的类型决定 大多数类将格式化委托给内置类型、或使用相似格式化 语法 返回值：字符串对象 内置钩子函数：format __hash__12def object.__hash__(self): pass 用途：计算对象hash值返回 相等的对象（即使类型不同）理应具有相同hash值 建议把参与比较的对象的全部组件的hash值打包为元组， 对元组做hash运算12def __hash__(self): return hash((self.name, self.nick, self.color)) 返回值：整数 内置钩子函数：hash() 说明 hash()会从对象自定义的__hash__()方法返回值中截断为 Py_ssize_t大小 64bits编译平台通常为8bytes、32bits为4bytes 若对象__hash__()需要在不同位大小的平台上互操作， 需要检查支持的平台位宽 查看sys.hash_info.width set、frozenset、dict这3个hash集类型中成员的操作 会调用相应__hash__() 类的__hash__方法设置为None时 尝试获取实例hash值时将raise TypeError isinstance(obj, collecitons.abc.Hashable)返回 False 单纯在__hash__中显式raise TypeError会被错误 认为是可hash 关联__eq__hash绝大部分应用场景是比较是否相等，所以__hash__、__eq__ 密切相关 类未定义__eq__ 也不应该定义__hash__，单独hash结果无法保证比较结果 类实现__eq__ 未定义__hash__：其实例将不可被用作hash集类型的项 类中定义了可变对象：不应该实现__hash__，因为hash集 实现要求键hash值不可变 类重载__eq__方法 默认其__hash__被隐式设为None 否则须设置__has__ = &lt;ParentClass&gt;.__hash__显式保留 来自父类__hash__实现 默认实现 float、integer、decimal.Decimal等数字类型hash运算 是基于为任意有理数定义的统一数学函数 详细参考https://docs.python.org/zh-cn/3/library/stdtypes.html#hashing-of-numeric-types str、bytes、datetime对象__hash__值会使用不可预知 值随机加盐 盐在单独python进程中保持不变，但在重复执行的python 进程之间是不可预测的 目的是为了防止某种形式的DDos服务攻击 改变hash值会影响集合迭代次序 python也不保证次序不会改变 __bool__12def object.__bool__(self): pass 用途：返回True、False实现真值检测 未定义：调用__len__返回非0值时对象逻辑为真 __len__、__bool__均未定义：所有实例逻辑为真 返回值：False、True 内置构造函数：bool() 例1234567891011121314151617181920212223class Pair: def __init__(self, x, y): self.x = x self.y = y def __repr__(self): # 返回实例代码表示形式 # 通常用于重新构造实例 return &quot;Pair({0.x!r}, {0.y!r})&quot;.format(self) # 格式化代码`!r`指明输出使用`__repr__`而不是默认 # 的`__str___` # 格式化代码`0.x`表示第一个参数`x`属性 def __str__(self): return &quot;({0.x!s}, {0.y!s})&quot;.format(self) # 格式化代码`!s`指明使用默认`__str__` def __format__(self): if self.x == 0: return self.y elif self.y == 0: return self.x return &quot;{0.x!r}, {0.y!r}&quot;.format(self) Rich Comparison Methods富比较方法 123456789101112def object.__lt__(self, other): passdef object.__le__(self, other): passdef object.__eq__(self, other): passdef object.__ne__(self, other): passdef object.__gt__(self, other): passdef object.__ge__(self, other): pass 用途：比较运算符重载 x &lt; y：调用x.__lt__(y) x &lt;= y：调用x.__le__(y) x == y：调用x.__eq__(y) x != y：调用x.__ne__(y) 返回值 成功比较返回False、True 若指定方法没有相应实现，富比较方法会返回单例对象 NotImplemented 比较运算默认实现参见cs_python/py3ref/expressions 说明 默认情况下，__ne__会委托给__eq__，并将结果取反，除非 结果为NotImplemented 比较运算符之间没有其他隐含关系 x &lt; y or x == y为真不意味着x &lt;= y 要根据单个运算自动生成排序操作可以利用 functools.total_ordering()装饰器简化实现 以上方法没有对调参数版本（左边参数不支持该操作，右边参数 支持该操作） 若两个操作数类型不同、且右操作数是左操作数直接或间接 子类，优先选择右操作数的反射方法，否则左操作数 方法（不考虑虚拟子类） 反射方法 __lt__、__gt__互为反射 __le__、__ge__互为反射 __eq__、__ne__各为自身反射 内部信息__dict__ 钩子函数：vars、dir（部分） vars是真正对应的钩子函数，返回键值对 dir执行过程中会访问__dict__、__class__，而且 只返回keys 对象底层字典，存储对象属性、方法 注意区分开：实例属性、类属性、基类属性，__dict__ 只包括当前实例属性、方法 返回结果是dir结果的子集 调用实例obj的属性时，按照以下顺序查找 obj.__dict__：当前实例的__dict__中 type(obj).__dict__：实例所属类的__dict__中 type(obj).mro().__dict__：基类的__dict__中 在大部分情况下__dict__会自动更新，如setattr函数时， 或说实例的属性、方法更新就是__dict__的变动 一般情况下不要直接访问__dict__，除非真的清楚所有 细节，如果类使用了cls.__slots__、@property、 描述器类等高级技术时代码可能会被破坏 尽量使用setattr函数，让python控制其更新 __class__ 用途：返回实例所属类 返回值：实例（狭义）返回类、类返回元类 钩子函数：type __objclass__ 用途：被inspect模块解读为指定实例所在的类 合适的设置可以有助于动态类属性的运行时检查 对于可调用对象：指明第一个位置参数应为特定类型的 实例、子类 描述器类：instance参数todo __slots__ 用途：显式声明数据成员、特征属性，限制实例添加属性 可赋值为：字符串、可迭代对象、实例使用的变量名构成的 字符串序列 可迭代对象中元素可以是任何类型 还可以映射类型，未来可能会分别赋给每个键特殊含义 的值 __slots__会为已声明变量保留空间 直接访问将raise AttributeError dir可以找到__slots__中声明的变量 阻止默认为每个实例创建__dict__、__weakref__的 行为，除非在__slots__中显式声明、或在父类中可用 无__dict__属性实例无法给未在__slots__中列出 的新变量赋值 但是python很多特性依赖于普通的依赖字典实现，定义 __slots__的类不再支持普通类某些特性 大多数情况下，应该只在经常使用到作为数据结构的 类上定义__slots__ 不应该把__slots__作为防止用户给实例增加新属性 的封装工具 无__weakref__属性实例不支持对实例的弱引用 是阻止给实例创建__dict__，类本身仍然有__dict__属性 （dir返回值中无__dict__，__dir__返回值中有） 说明 __slots__声明的行为不只限于定义其的类 父类中声明__slots__可以在子类中使用，但子类将获得 __dict__、__weakref__，除非其也定义了__slots__ 子类__slots__中定义的slot将覆盖父类中同名slot 需要直接从基类直接获取描述器才能访问 这会导致程序未定义，以后增加检查避免 多重继承中只允许一个父类具有非空__slots__，否则 raise TypeError __slots__是在类层次上的实现：为每个变量创建描述器 类属性不能被用于给在__slots__中定义变量设置默认值 否则类属性会覆盖描述器赋值，变成只读属性 非空的__slots__不适用于派生自“可变长度”内置类型，如 int、bytes、tuple 定义类属性__slots__后，python会为实例属性使用紧凑内部 表示 实例属性使用固定大小、很小的数组构建，而不是为每个 实例定义字典 在__slots__列出的属性名在内部映射到数组指定下标上 类似于R中factor类型、C中enum类型 相比__dict__可以显著节省空间、提升属性查找速度 123456class Date: __slots__ = [&quot;year&quot;, &quot;month&quot;, &quot;day&quot;] def __init__(self, year, month, day): self.year = year self.month = month self.day = day 继承自未定义__slots__类时，实例中__dict__、 __weakref__属性将总是可访问的 __class__赋值仅在两个类具有相同__slots__值时才有用 自定义属性访问__getattr__12def object.__getattr__(self, name): pass 用途：.默认属性访问引发AttributeError而失败时调用 如果属性通过正常机制找到，__getattr__不会被调用 在__getattr__、__setattr__之间故意设置的 不对称性 出于效率考虑 对实例变量而言，无需在实例属性字典中插入值，就可以 模拟对其的完全控制 返回值：计算后的属性值、或raise AttributeError 说明 可能引发AttributeError 调用__getattribute__时因为name不是实例属性、 或是类关系树中属性 对调用__get__获取name描述器 调用__getattr__是.运算符中逻辑 __getattribute__显式调用raise AtttributeError 不会调用__getattr__ __getattr__甚至不是object具有的 &lt;wrapper_descriptor&gt; 相较于__getattribute__其实更常用，因为修改所有对 对对象的访问逻辑没啥价值 __getattribute__123456def __getattribute__(self, key): &quot;Emulate type_getattro() in Objects/typeobject.c&quot; v = object.__getattribute__(self, key) if hasattr(v, &quot;__get__&quot;): return v.__get__(None, self) return v 用途：访问对象属性时无条件被调用 判断访问属性类型、做对应操作 描述器：调用描述器方法 实例方法：为类中函数绑定实例 类方法：为类中函数绑定类 静态方法：不绑定 普通属性 作为通过特定语法、内置函数隐式调用的结果情况下， 查找特殊方法时仍可能被跳过 返回值：找到的属性值、或raise AttributeError __getattribute__仅对继承自object的新式类实例可用 说明 内置类型均有各自__getattribute__函数实例 其均为wrapper_descriptor类型（C实现的函数） 各函数实例标识符不同，若其均“继承自object”，其 应为同一个函数实例 自定义类真继承自object类，其__getattribute__同 object.__getattribute__ 自定义实现 为避免方法中无限递归，实现总应该调用具有相同名称 基类方法访问所需要的属性 钩子函数 .运算符：首先调用__getattribute__，若无访问结果， 调用__getattr__ .运算符说明参见cs_python/py3ref/cls_basics getattr：基本同.运算符，除可捕获异常，设置默认返回值 hasattr：内部调用getattr，根据raise Exception判断 属性是否存在 可以通过@property.getter中raise AttributeError 使得属性看起来不存在 内部有更多boilerplate相较于getattr更慢 则按照字面意思使用不需要考虑过多 __setattr__12def object.__setattr__(self, name, value): pass 用途：属性被尝试赋值时被调用 默认实现：将值保存到实例字典 若__setattr__要赋值给实例属性，应该调用同名基类 方法 返回指：None 钩子函数：setattr __delattr__12def object.__delattr__(self, name): pass 用途：删除实例属性时被调用 默认实现：从实例字典中删除对应项 应该在del obj.name对该对象有意义时才实现 返回值：None 内置钩子函数：delattr、del __dir__12def object.__dir__(self): pass 用途：返回实例中“可访问”名称的字符串列表 默认实现：返回实例、类、祖先类所有属性 交互式解释器就是在__dir__/dir返回列表中进行查询 进行补全 返回值：序列 内置钩子函数：dir dir()获取__dir__返回序列，转换为列表、排序 dir()会剔除__dir__返回值中部分值 若__dir__返回值不可迭代，报错 自定义模块属性访问 __getattr__、__dir__可以用于自定义对模块属性的访问 模块层次__getattr__类似普通类 接受属性名作为参数 返回计算后结果、或raise AttributeError 若正常查找__getattribute__无法在模块中找到某个 属性，调用__getattr__ 模块层次__dir__类似普通类 不接受参数 返回模块中可访问名称的字符串列表 可以将模块的__class__属性设置为types.ModuleType子类 1234567891011import sysimport types import ModuleTypeclass VersboseModule(ModuleType): def __repr__(self): return f&quot;verbose {self.__name__}&quot; def __setattr__(self, attr, value): print(f&quot;settting {attr}&quot;) super().__setattr__(attr, value)sys.modules[__name__].__class__ = VerboseModule 设置模块__getattr__、__class__只影响使用属性访问 语法进行查找，直接访问模块全局变量（通过模块内代码、对 模块全局字典引用）不受影响 描述器类描述器：具有“绑定行为”的对象属性 类中定义其中任意一个方法，则其实例被称为描述器 __set__ __get__ __delete__ 所有对描述器属性的访问会被__get__、__set__、 __delete__方法捕获/重载 如果只是想简单的自定义某个类的属性处理逻辑，使用 @porperty装饰器简化实现 @property参见cs_python/py3ref/cls_basics 描述器协议 以下方法仅包含其的类的实例出现在类属性中才有效 即以下方法必须在（祖先）类__dict__中出现，而不是 实例__dict__中 即描述器只能定义为类属性，不能定义为实例属性 __get__12def object.__get__(self, instance, owner=None): pass 用途：访问描述器属性时调用，重载实例属性访问 若描述器未定义__get__，则访问属性会返回描述器对象 自身，除非实例字典__dict__中有同名属性 若仅仅只是从底层实例字典中获取属性值，__get__方法 不用实现 参数 instance：用于方法属性的实例 owner：实例所属类，若通过类获取属性则为None 返回值：计算后属性值、或raise AttributeError 示例 123456789101112def __get__(self, instance, cls): if instance is None: # 装饰器类一般作为类属性，需要考虑通过类直接访问 # 描述器类属性，此时`instance is None` # 常用操作是返回当前实例 return self else: return instance.__dict__[self.name] # self：描述器类当前实例 # instance：定义描述器作为类属性的类的实例 # cls：定义描述器作为类属性的类 __set__12def object.__set__(self, instance, name, value): pass 用途：设置实例instance的“描述器属性”值为value，重载 实例属性赋值 常用实现：操作实例instance.__dict__存储值，使得 看起来是设置普通实例属性 示例 12345678910def __set__(self, instance, name, value): if instance is None: pass else: if not instance(value, int): raise TypeError(&quot;expect an int&quot;) instance.__dict__[self.name] = value # 操作实例底层`__dict__` # `value`：赋给描述器类属性的值 __delete__12def object.__delete__(self, instance): pass 用于：“删除”实例instance的“描述器属性”，重载实例属性 删除 具体实现应取决于__set__实现 示例 123456def __delete__(self, instance): if instance is None: pass else: del instance.__dict__[self.name] # 操作实例底层`__dict__` __set_name__12def object.__set_name__(self, owner, name): pass 用途：类owner被创建时调用，描述器被赋给name 实现原理 描述器的实现依赖于object.__getattribute__()方法 可以通过重写类的__getattribute__方法改变、关闭 描述器行为 描述器调用：描述器x定义在类A中、a = A() 直接调用：x.__get__(a) 实例绑定：a.x 转换为：type(a).__dict__['x'].__get__(a) 类绑定：A.x 转换为：A.__dict__['x'].__get__(None,A) 超绑定：super(a, A).x 实例绑定—资料描述器 资料描述器：定义了__set__、__delete__方法 非资料描述器：只定义了__get__方法 访问对象属性时，描述器调用的优先级取决于描述器定义的方法 优先级：资料描述器 &gt; 实例字典属性 &gt; 非资料描述器 实例属性会重载非资料描述器 实例属性和资料描述器同名时，优先访问描述器，否则优先 访问属性 只读资料描述器：__set__中raise AttributeError得到 描述器调用todoPython设计 function类中定义有__get__方法，则其实例（即函数） 都为非资料描述器 所以实例可以覆盖、重载方法 __getattribute__会根据不同方法类型选择绑定对象 staticmethod：静态方法 classmethod：类方法 实例方法 super类中定义有__get__方法，则其实例也为描述器 @property方法被实现为资料描述器 特殊描述器类todo wrapper_descripter：&lt;slot wrapper&gt;，封装C实现的函数 等价于CPython3中函数 调用__get__绑定后得到&lt;method-wrapper&gt; object的方法全是&lt;slot wrapper&gt; method-wrapper：&lt;method-wrapper&gt;，封装C实现的绑定方法 等价于CPython3中绑定方法 function描述器类function描述器类：实例化即得到函数 123456789class function: function(code, globals[, name[, argdefs[, closure]]]) def __call__(self, /, *args, **kwargs): # 作为一个函数调用自身 def __get__(self, instance, owner, /): # 返回`owner`类型实例`instance`的属性 # 即返回绑定方法 method描述器类method描述器类：实例化即得到(bound )method，绑定方法 12345678class method: method(function, instance) def __call__(self, /, *args, **kwargs): # 作为函数调用自身 def __get__(self, instance, owner, /): # 返回自身 (bound )method：绑定方法，（首个参数）绑定为具体实例 的函数，即实例属性 XXmethod描述类 代码是C实现，这里是python模拟，和help结果不同 1234567891011121314class classmethod: def __init__(self, method): self.method = method def __get__(self, obj, cls): return lambda *args, **kw: self.method(cls,*args,**kw)class staticmethod: def __init__(self, callable): self.f = callable def __get__(self, obj, cls=None): return self.f @property def __func__(self): return self.f 类中静态方法、类方法就是以上类型的描述器 静态方法：不自动传入第一个参数 类方法：默认传递类作为第一个参数 描述器用途就是避免默认传入实例为第一个参数的行为 静态方法、类方法均是非资料描述器，所以和实例属性重名时 会被覆盖 所以类静态方法、类方法不能直接通过__dict__获取、调用， 需要调用__get__方法返回绑定方法才能调用 直接访问属性则由__getattribute__方法代劳 例12345678910111213141516171819202122232425262728293031323334353637383940class Integer: # 描述器类 def __init__(self, name): self.name = name def __get__(self, instance, cls): # 描述器的每个方法会接受一个操作实例`instance` if instance is None: # 描述器只能定义为类属性，在这里处理直接使用类 # 访问描述器类的逻辑 return self else: return instance.__dict__(self.name) def __set__(self, instance, value): if not instance(value, int): rasie TypeError(&quot;expect an int&quot;) instance.__dict__[self.name] = value # 描述器方法会操作实例底层`__dict__`属性 def __delete__(self, instance): del instance.__dict__[self.name]class Point: x = Integer(&quot;x&quot;) y = Integer(&quot;y&quot;) # 需要将描述器的实例作为类属性放在类的定义中使用 def __init__(self, x, y): self.x = x self.y = ydef test(): p = Point(2, 3) print(p.x) # 调用`Point.x.__get__(p, Point)` print(Point.x) # 调用`Point.x.__get__(None, Point)` p.y = 5 # 调用`Point.y.__set__(p, 5)` 自定义类创建__init_subclass__12classmethod object.__init_subclass__(cls): pass 用途：派生类继承父类时，基类的__init_subclas__被调用 可以用于编写能够改变子类行为的类 类似类装饰器，但是类装饰其影响其应用的类，而 __init_subclass__影响基类所有派生子类 默认实现：无行为、只有一个参数cls 方法默认、隐式为类方法，不需要classmethod封装 参数 cls：指向新的子类 默认实现无参数，可以覆盖为自定义参数 1234567class Philosopher: def __init_subclass__(self, default_name, **kwargs): super().__init_subclass__(**kwrags) cls.default_name = default_nameclass AstraliaPhilosopher(Philosopher, default_name=&quot;Bruce&quot;): pass 定义派生类时需要注意传递参数 元类参数metaclass会被其他类型机制消耗，不会被传递 给__init_subclass__ 元类 默认情况下，类使用type构建 类体在新的命名空间中执行，类名被局部绑定到 元类创建结果type(name, bases, namespace) 可在类定义部分传递metaclass关键字参数，自定义类创建 过程 类继承同样继承父类元类参数 其他类定义过程中的其他关键字参数会在以下元类操作中 进行传递 解析MRO条目 确定适当元类 准备类命名空间__prepare__ 执行类主体 创建类对象 解释MRO条目12def type.__mro_entries__(): pass 用途：若类定义中基类不是type的实例，则使用此方法对 基类进行搜索 找到结果时，以原始基类元组作为参数进行调用 返回值：类的元组替代基类被使用 元组可以为空，此时原始基类将被忽略 元类确定 若没有显式给出基类、或元类，使用type() 若显式给出的元类不是type()的实例，直接用其作为元类 若显式给出type()实例作为元类、或定义有基类，则选取 “最派生”元类 最派生元类从显式指定的元类、基类中元类中选取 最派生元类应为所有候选元类的子类型 若没有满足条件的候选元类则raise TypeError 准备类命名空间12def type.__prepare__(name, bases, **kwds): pass 用途：确定合适的元类之后，准备类命名空间 若元类没有__prepare__属性，类命名空间将被初始化为 空ordered mapping 参数：来自于类定义中的关键字参数 执行类定义主体12exec(body, globals(), namespace) # 执行类主体类似于 普通调用和exec()区别 类定义在函数内部时 词法作用域允许类主体、方法引用来自当前、外部 作用域名称 但内部方法仍然无法看到在类作用域层次上名称 类变量必须通过实例的第一个形参、类方法方法 创建类对象12metaclass(name, base, namespace, **kwds): pass 用途：执行类主体填充类命名空间后，将通过调用 metaclass(name, base, namespace, **kwds)创建类对象 参数：来自类定义中的关键字参数 说明 若类主体中有方法中引用__class__、super，则__class__ 将被编译器创建为隐式闭包引用 这使得无参数调用super可以能基于词法作用域正确 定位类 而被用于进行当前调用的类、实例则是基于传递给方法 的第一个参数来标识 自定义实例、子类检查 以下方法应该的定义在元类中，不能在类中定义为类方法 类似于实例从类中查找方法 元类abc.ABCMeta实现了以下方法以便允许将抽象基类ABC 作为“虚拟基类”添加到任何类、类型（包括内置类型）中 __instancecheck__12def class.__instancecheck__(self, instance): pass 用途：若instance被视为class直接、间接实例则返回真值 重载instance内置函数行为 返回：布尔值 内置钩子函数：isintance(instance, class) __subclasscheck__12class.__subclasscheck__(self, subclass): pass 用途：若subclass被视为class的直接、间解子类则返回 真值 重载issubclass内置函数行为 返回：布尔值 内置钩子函数：issubclass(subclass, class) 模拟范型类型__class_getitem__12classmethod object.__class_getitem__(cls, key): pass 用途：按照key指定类型返回表示泛型类的专门化对象 实现PEP 484规定的泛型类语法 查找基于对象自身 主要被保留用于静态类型提示，不鼓励其他尝试使用 方法默认、隐式为类方法，不需要classmethod封装 参数 cls：当前类 key：类型 模拟可调用对象__call__12def object.__call__(self[,args...]): pass 用途：实例作为函数被调用时被调用 若定义此方法x(arg1, arg2, ...)等价于 x.__call__(arg1, args2, ...) 模拟容器类型 collections.abc.MutableMapping为抽象基类 其实现基本方法集__getitem__、__setitem__、 __delitem__、keys() 可以方法继承、扩展、实现自定义映射类 __len__12def object.__len__(self): pass 用途：计算、返回实例长度 若对象未定义__bool__，以__len__是否返回非0作为 布尔运算结果 返回值：非负整形 钩子函数：len() CPython：要求长度最大为sys.maxsize，否则某些特征可能 会raise OverflowError __length_hint__12def object.__length_hist__(self): pass 用途：返回对象长度估计值 存粹为优化性能，不要求正确无误 返回值：非负整形 钩子函数：operator.length_hint() __getitem__12def object.__getitem__(self, key): pass 用途：实现根据索引取值 参数 序列key：整数、切片对象 key类型不正确将raise TypeError key在实例有效范围外将raise IndexError 映射key：可hash对象 key不存在将raise KeyError 返回值：self[key] __setitem__12def object.__setitem__(self, key, value): pass 用途：实现根据索引赋值 参数：同__geitem__ __delitem__12def object.__delitem(self, key): pass 用途：实现删除索引对应项 参数：同__getitem__ __missing__12def object.__missing__(self, key): pass 用途：__getitem__无法找到映射中键时调用 __reversed__12def object.__iter__(self): pass 用途：为容器类创建逆向迭代器 返回值：逆向迭代对象 内置钩子函数：reversed() 说明 若未提供__reversed__方法，reversed函数将回退到使用 序列协议：__len__、__getitem__ 支持序列协议的对象应该仅在能够提供比reversed更高效实现 时才提供__reversed__方法 __contains__12def object.__contains__(self, item): pass 用途：实现成员检测 若item是self成员则返回True、否则返回False 对映射应检查键 返回值：布尔值 钩子运算：in 说明 若未提供__contains__方法，成员检测将依次尝试 通过__iter__进行迭代 使用__getitem__旧式序列迭代协议 容器对象可以提供更有效率的实现 模拟数字数字运算定义以下方法即可模拟数字类型 特定类型数值类型不支持的运算应保持未定义状态 若不支持与提供的参数进行运算，应返回NotImplemented 123456789101112131415161718192021222324252627282930def object.__add__(self, other): # `+`def object.__sub__(self, other): # `-`def object.__mul__(self, other): # `*`def object.__matmul__(self, other): # `@`def object.__truediv__(self, other): # `/`def object.__floordiv__(self, other): # `//`def object.__mod__(self, other): # `%`def object.__divmod__(self, other): # `divmod()`def object.__pow__(self, other[, modulo=1]): # `pow()`/`**` # 若要支持三元版本内置`pow()`函数，应该接受可选的第三个 # 参数def object.__lshift__(self, other): # `&lt;&lt;`def object.__rshift__(self, other): # `&gt;&gt;`def object.__and__(self, other): # `&amp;`def object.__or__(self, other): # `|`def object.__xor__(self, other): # `~` 反射二进制算术运算以下成员函数仅在左操作数不支持相应运算、 且两操作数类型不同时被调用 实例作为作为相应运算的右操作数 若右操作数类型为左操作数类型子类，且字类提供如下反射方法 右操作数反射方法优先于左操作数非反射方法被调用 允许子类覆盖祖先类运算符 三元版pow()不会尝试调用__rpow__（转换规则太复杂） 123456789101112131415161718192021222324252627282930def object.__radd__(self, other): # `+`def object.__rsub__(self, other): # `-`def object.__rmul__(self, other): # `*`def object.__rmatmul__(self, other): # `@`def object.__rtruediv__(self, other): # `/`def object.__rfloordiv__(self, other): # `//`def object.__rmod__(self, other): # `%`def object.__rdivmod__(self, other): # `divmod()`def object.__rpow__(self, other[, modulo=1]): # `pow()`/`**` # 若要支持三元版本内置`pow()`函数，应该接受可选的第三个 # 参数def object.__rlshift__(self, other): # `&lt;&lt;`def object.__rrshift__(self, other): # `&gt;&gt;`def object.__rand__(self, other): # `&amp;`def object.__ror__(self, other): # `|`def object.__rxor__(self, other): # `~` 扩展算术赋值实现以下方法实现扩展算数赋值 以下方法应该尝试对自身进行操作 修改self、返回结果（不一定为self） 若方法未定义，相应扩展算数赋值将回退到普通方法中 某些情况下，扩展赋值可导致未预期错误 1234567891011121314151617181920212223242526def object.__iadd__(self, other): # `+=`def object.__isub__(self, other): # `-=`def object.__imul__(self, other): # `*=`def object.__imatmul__(self, other): # `@=`def object.__itruediv__(self, other): # `/=`def object.__ifloordiv__(self, other): # `//=`def object.__imod__(self, other): # `%=`def object.__ipow__(self, other[, modulo=1]): # `**=`def object.__ilshift__(self, other): # `&lt;&lt;=`def object.__irshift__(self, other): # `&gt;&gt;=`def object.__iand__(self, other): # `&amp;=`def object.__ior__(self, other): # `|=`def object.__ixor__(self, other): # `~=` 一元算术运算12345678def object.__neg__(self): # `-`def object.__pos__(self): # `+`def object.__abs__(self): # `abs()`def object.__invert__(self): # `~` 类型转换运算123456def object.__complex__(self): # `complex()`def object.__int__(self): # `int()`def object.__float__(self): # `float()` 整数12def object.__index__(self): pass 存在此方法表明对象属于整数类型 必须返回整数 为保证以一致性，同时也应该定义__int__()，两者返回 相同值 调用此方法以实现operator.index()、或需要无损的转换为 整数对象 作为索引、切片参数 作为bin()、hex()、oct()函数参数 精度运算12345678def object.__round__(self[, ndigits]): # `round()`def object.__trunc__(self): # `math.trunc()`def object.__floor__(self): # `math.floor()`def object.__ceil__(self): # `math.ceil()` 返回值：除__round__中给出ndigits参数外，都应该为 原对象截断为Integral（通常为int） 若未定义__int__，则int回退到__trunc__ 元属性查找 元属性查找通常会绕过__getattribute__方法，甚至包括元类 1234567891011121314151617181920212223class Meta(type): def __getattribute__(*args): print(&quot;Metaclass getattribute invoked&quot;) return type.__getattribute__(*args)class C(object, metaclass=Meta): def __len__(self): return 10 def __getattribute__(*args): print(&quot;Class getattribute invoked&quot;) return object.__geattribute__(*args)if __name__ == &quot;__main__&quot;: c = C() c.__len__() # 通过实例显式调用 # 输出`Class getattribute invoked\\n10&quot; type(c).__len__(c) # 通过类型显式调用 # 输出`Metaclass getattribute invoked\\n10&quot; len(c) # 隐式查找 # 输出`10` 为解释器内部速度优化提供了显著空间 但是牺牲了处理特殊元属性时的灵活性 特殊元属性必须设置在类对象本身上以便始终一致地 由解释器发起调用 隐式调用元属性仅保证元属性定义在对象类型中能正确发挥 作用 12345678class C: passif __name__ == &quot;__main__&quot;: c = C() c.__len__() = lambda: 5 len(c) # `rasie TypeError` 元属性定义在实例字典中会引发异常 若元属性的隐式查找过程使用了传统查找过程，会在对类型 对象本身发起调用时失败 可以通过在查找元属性时绕过实例避免 12&gt;&gt;&gt; type(1).__hash__(1) == hash(1)&gt;&gt;&gt; type(int).__hash__(int) == hash(int) 上下文管理器协议上下文管理器：定义了在执行with语句时要建立的运行时上下文 的对象 上下文管理器为执行代码块，处理进入、退出运行时所需上下文 通常使用with语句调用 也可以直接调用协议中方法方法 典型用法 保存、恢复各种全局状态 锁、解锁资源：避免死锁 关闭打开的文件：自动控制资源释放 可利用contextlib模块方便实现上下文管理器协议 __enter__12def contextmanager.__enter__(self): pass 用途：创建、进入与当前对象相关的运行时上下文 在执行with语句块前设置运行时上下文 返回值 with子句绑定方法返回值到as子句中指定的目标，如果 方法返回值 __exit__12def contextmanger.__exit__(self, exc_type, exc_value, traceback): pass 用途：销毁、退出关联到此对象的运行时上下文 with语句块结束后，__exit__方法触发进行清理工作 不论with代码块中发生什么，即使是出现异常， __exit__控制流也会执行完 参数：描述了导致上下文退出的异常，正常退出则各参数为 None exc_type exc_value traceback 返回值：布尔值 若上下文因异常退出 希望方法屏蔽此异常（避免传播），应该返回真值， 异常被清空 否则异常在退出此方法时将按照正常流程处理 方法中不应该重新引发被传入的异常，这是调用者的责任 例12345678910111213141516171819202122232425262728293031323334from socket import socket, AF_INET, SOCK_STREAMclass LazyConnection: def __init__(self, address, family=AF_INET, type=SOCK_STREAM): self.address = address self.family = family self.type = type self.connections = [] def __enter__(self): sock = socket(self.family, self.type) sock.connect(self.address) self.connections.append(sock) return self.sock def __exit__(self, exc_ty, exc_val, tb): self.connections.pop().close()from functools import partialdef test(): conn = LazyConnection(&quot;www.python.org&quot;, 80)) with conn as s1: # `conn.__enter___()` executes: connection opened s.send(b&quot;GET /index.html HTTP/1.0\\r\\n&quot;) s.send(b&quot;Host: www.python.org\\r\\n&quot;) s.send(b&quot;\\r\\n&quot;) resp = b&quot;&quot;.join(iter(partial(s.recv, 8192), b&quot;&quot;)) # `conn.__exit__()` executes: connection closed with conn as s2: # 此版本`LasyConnection`可以看作是连接工厂 # 使用列表构造栈管理连接，允许嵌套使用 pass 迭代器协议 可迭代对象：实现__iter__方法的对象 迭代器对象：同时实现__next__方法的可迭代对象 使用collections.abc模块判断对象类型 __iter__12def object.__iter__(self): pass 用途：创建迭代器对象，不负责产生、返回迭代器元素 容器对象要提供迭代须实现此方法 容器支持不同迭代类型，可以提供额外方法专门请求 不同迭代类型迭代器 迭代对象本身需要实现此方法，返回对象自身 允许容器、迭代器均可配合for...in...语句使用 返回值：迭代器对象 映射类型应该逐个迭代容器中键 内置钩子函数：iter() 此方法对应Python/C API中python对象类型结构体中 tp_iter槽位 __next__12def object.__next__(): pass 用途：从迭代器中返回下一项 若没有项可以返回，则raise StopIteration 一旦引发raise StopIteration，对后续调用必须一直 引发同样的异常，否则此行为特性无法正常使用 返回值：迭代器对象中下个元素 映射类型返回容器中键 内置钩子函数：next() 此方法对应Python/C API中python对象类型结构体中 tp_iternext槽位 协程/异步__await__12def object.__await__(self): pass 用途：用于实现可等待对象 返回值：迭代器 钩子运算：await asyncio.Future实现此方法以与await表达式兼容 Awaitable Objects可等待对象：异步调用句柄，等待结果应为迭代器 主要是实现__await__方法对象 从async def函数返回的协程对象 type.coroutine()、asyncio.coroutine()装饰的生成器 返回的生成器迭代器对象也属于可等待对象，但其未实现 __await__ 协程对象参见cs_python/py3ref/dm_gfuncs py3.7前多次await可等待对象返回None，之后报错 异步迭代器协议 异步迭代器常用于async for语句中 其他参见迭代器协议 __aiter__12def object.__aiter__(self): pass 用途：返回异步迭代器对象，不负责产生、返回迭代器元素 返回其他任何对象都将raise TypeError 其他参见__iter__方法 __anext__12async def object.__anext__(self): pass 返回：从异步迭代器返回下个结果值 迭代结束时应该raise StopAsyncIteration 用途 在其中调用异步代码 其他参见__next__方法 例12345678910class Reader: async def readline(self): pass def __aiter__(self): return self async def __anext__(self): val = await self.readline() if val == &quot;b&quot;: raise StopAsyncIteration return val 异步上下文管理器协议 异步上下文管理器常用于async with异步语句中 其他参见上下文管理器协议 __aenter__12async def object.__aenter__(self): pass 用途：异步创建、进入关联当前对象的上下文执行环境 由async def定义为协程函数，即在创建上下文执行环境 时可以被挂起 返回：可等待对象 其他参见__enter__ __aexit__12async def object.__aexit__(self): pass 用途：异步销毁、退出关联当前对象的上下文执行环境 由async def定义为协程函数，即在销毁上下文执行环境 时可以被挂起 返回：可等待对象 其他参见__exit__函数","link":"/Python/Py3Ref/cls_special_methods.html"},{"title":"并行开发","text":"综述python并行多任务均依赖操作系统底层服务并行执行python代码 线程派生：基本所有主流平台均支持 多进程 shell命令进程 子python进程 跨平台多进程实现 创建子python进程 类Unix：fork系统调用实现进程分支，分支进程运行时 环境同主进程完全一致 Win：创建python进程，import当前调用代码得到类似 主进程运行时环境 pickle序列化被调函数，传递给子进程执行 因为Win下分支进程需要导入当前调用，所以多进程代码必须 在__main__内，否则无限循环创建新进程 进程池调用函数要声明在进程池创建之前，否则启动进程会报错 进程通信 python进程间数据传递基本都是通过pickle序列化传递，所以 需要传递的数据要支持pickle序列化 multiprocessing等模块派生进程需要传递被调函数，所以 不支持 lambda匿名函数 绑定对象方法 其他相关模块、包 多进程：pathos、pp 进程通信：signal 注意事项 子进程报错直接死亡，错误信息默认不会输出到任何地方，所以 子进程中，多使用try catch os模块派生进程123456os.startfile(filename) # 调用系统默认程序打开文件，类似于鼠标双击 # linux下没有实现int = os.system(command(str)) # 运行shell命令，返回命令执行退出状态 # 和普通shell命令一样默认阻塞，除非后台运算符`&amp;` os.popen12pipe = os.popen(cmd(str), mode=&quot;r&quot;/&quot;w&quot;, buffering=-1) # 运行shell命令并重定向其输出、输入流到管道开放 用途：运行shell命令并重定向其输出、输入流到管道开放 返回值：返回管道流对象 类似shell中管道语法 管道流对象类似普通文件流，支持一般读、写、迭代 （但是文档中只有close方法） 1234567891011# `r`模式执行，读取子进程标准输出pipe.readlines()pipe.readline()pipe.read()for i in pipe: # 迭代器语法# `w`模式执行，写入子进程标准输入pipe.write()pipe.close() # 返回退出状态 # 历史原因，退出状态为0时返回None os.popen一般不会阻塞，但是python执行需要整个命令行程序 完成的语句时仍然会阻塞 关闭管道对象 一次性读取所有输出流 subprocess模块可以实现与os.system、os.popen相同的 效果，使用更复杂，但是对流的连接、使用提供更完善的控制 os.fork进程分支是构建平行任务的传统做法，是Unix工具集的基本组成部分 分支是开始独立程序的直接做法，无论调用程序是否相同 分支想法基于复制 程序调用分支例行程序时，操作系统会创建在该进程副本 和进程并行的运行副本 有些系统实现并不真的复制原有程序，以减少资源消耗， 但是新副本会像真实副本一样运行 1234567891011121314151617import osdef child(): print(&quot;hello from child&quot;, os.getpid()) os._exit(0)def parent(): while True: newpid = os.fork() # 子进程返回0值 # 父进程返回子进程进程号 if newpid == 0: child() else: print(&quot;hello from parent&quot;, os.getpid(), newpid) if input() == &quot;q&quot;: break 返回值：据此区分父、子进程，执行不同任务 子进程中返回0 父进程中返回子进程ID os.fork仅仅是系统代码库中标准进程分支调用简单封装 和C共用代码库 在win下标准python版本中无法运行，和win模型冲突过多 Cygwin中python可以运行，虽然行为同真正Unix分支不完全 相同，但是足够接近 os.fork实际复制整个python解释器 除非python脚本被编译为二进制机器码 os.exec123456789101112131415161718def execv(path, args=tuple/list)def execl(path, *args=*list/*tuple) # 以参数执行指定可执行文件，**代替**当前进程def execvp(file, args)def execlp(file, *args) # `p` for `$PATH` # 在系统搜索路径`$PATH`中定位可执行程序def execve(path, args=tuple/list, env=dict)def execle(path, args=*tuple/*list, env=dict) # `e` for `environ` # 将`env`字典作为环境环境变量传递def execvpe(path, args=tuple/list, env=dict)def execlpe(path, args=*tuple/*list, env=dict) # 在系统搜索路径`$PATH`中定位可执行程序 # 将`env`字典作为环境环境变量传递 os.exec族的函数会覆盖当前进程 所以该语句的代码都不会执行 不会更改进程号 123456789101112import osparam = 0while True: param += 1 newpid = os.fork() if newpid == 0: os.execlp(&quot;python&quot;, &quot;child.py&quot;, str(param)) assert False, &quot;starting new program error&quot; # 上句正常执行，这句永远无法被调用 else: print(&quot;child is&quot;, pid) if input() == &quot;q&quot;: break multiprocessing模块的进程派生模型+os.exec配合使用 可以在win下实现类似os.fork的效果 spawn12os.spawn # 启动带有底层控制的新程序 进程通信123456read_fd, write_fd = os.pipe() # 创建管道，返回管道写入、读取描述符 # 可以使用`os.fdopen()`封装管道描述符，方便读、写os.mkfifo(path, mode=438, *, dir_fd=None) # 创建命名管道，win不支持 # 仅创建外部文件，使用需要像普通文件一样打开、处理 subprocess模块Popen12345678910111213141516171819202122class Popen: def __init__(self, args(str,[str]), bufsize=-1/0/1/int, executable=None/str, stdin=None/stream, stdout=None/stream, stderr=None/stream, preexec_fn=None/callable, close_fd=obj, shell=False/True, cwd=None/path, env=None/dict, universal_newlines=False/True, startupinfo=None, creationflags=0, restore_signals=True/False, start_new_session=False/True, pass_fds=(), encoding=None/str, errors=None ) 用途 参数 args：需要执行的命令 executable：备选执行命令 stdin/stdout/stderr：执行程序标准输入、输出、 错误流连接对象 默认：当前进程标准输入、输出、错误 subprocess.PIPE=-1：当前管道对象标准… preexec_fn：子进程执行前在子进程中调用的对象 POSIX only close_fds：控制关闭、继承文件描述符 shell：是否通过shell执行命令 执行shell内置命令则必须置True win：type linux：set Linux下False：由os.execvp运行 cwd：子进程执行目录 env：子进程环境变量 universal_newlines：是否在3个标准流中使用行结尾符 即是否按照文本处理3个标准流 startupinfo：windows only restore_signals：POSIX only start_new_session：POSIX only pass_fds：POSIX only .communicate1(stdout, stderr) = communicate(self, input=None, timeout=None) 用途：和子进程交互，阻塞直到子进程终止 input传递给子进程标准输入 返回标准输出、错误输出 universal_newlines为True时，input参数、返回值 应该为str，否则为bytes 其他方法1234567891011121314151617181920212223def kill(self): # kill进程通过*SIGKILL*信号def terminate(self): # 终止进程通过*ISGTERM*信号def send_signal(self, sig): # 向进程传递信号def poll(self): # 检查子进程是否终止，设置、返回`.returncode`属性def wait(self, timeout=None, endtime=None): # 等待直到子进程终止，返回`.returncode`属性pipe.stdinpipe.stdoutpipe.stderr # 管道标准输入、输出、错误流 # 创建子进程时，可以选择和子进程相应流连接 # 支持读、写、迭代pipe.returncode # 子进程退出状态 Popen创建对象对象之后会立刻执行 同时指定stdout、stdin参数可以实现管道双工工作 需要注意，读写时交替发送缓冲数据流可能导致死锁 call1234subprocess.call( &quot;type hello.py&quot;, shell=True/False) _thread 为系统平台上的各种线程系统提供了可移植的接口 在安装了pthreads POSIX线程功能的系统上，接口工作方式 一致，无需修改源码即可正常工作 基本可以完全被threading模块替代了 start_new_thread1234567def start_new_thread( callable, args=tuple/list, kwargs=dict)def start_new(): # deprecated，同上 用途：开启新线程，以参数调用callable 返回值：应该是线程起始地址 派生线程在函数返回后退出 若在线程中函数抛出未捕捉异常，打印堆栈跟踪记录、退出 线程 程序其他部分继续运行 大多数系统平台上，整个程序主线程退出时，子线程随之退出 需要一些处理避免子线程意外退出 其他方法123456789101112131415Lock = _thread.alloacate_lock() # 获取一个`Lock`锁 # 等价于`threading.Lock()`Lock = _thread.allocate() # deprecated，同上RLock = _thread.RLock() # 获取一个`RLock`可重入锁 # 等价于`threading.RLock()`def _thread.exit() # 退出当前线程，可捕捉 # 等价于显式`raise SystemExit`、`sys.exit()`def _thread.exit_thread() # 同上 例子例1 全局线程锁保护对输出流写入 全局线程锁实现主线程、子线程间通信，保证主线程在子线程 之后退出 123456789101112131415161718192021222324252627282930313233343536import _thread as threadstdoutmutex = thread.allocate_lock() # 创建全局标准输出锁锁对象exitmutexes = [thread.allocate_lock() for _ in range(10)] # 为每个线程创建锁exitmutexes_bool = [False] * 10 # 线程共享内存，同样可以使用全局变量作为信号量，而不用 # 额外开销def counter(myId, count): for i in range(count): stdoutmutex.acquire() # 线程向标准输出流写入时，获得锁 print(&quot;[%s] =&gt; %s&quot; % (myId, i)) stdoutmutex.release() # 向标准输出流写入完毕后，释放锁 with stdoutmutex: # 线程锁同样支持`with`上下文管理器 print(&quot;[%s] =&gt; %s again&quot; % (myId, i)) exitmutexes[myID].acquire() # 线程执行完毕后获取对应自身id的锁，通知主线程for i in range(10): thread.start_new_thread(counter, (i, 100)) # 创建、启动新线程for mutex in existmutexes: # 检查所有信号锁 while not mutex.locked(): # 直到信号锁被获取，结束死循环 passprint(&quot;main thread exiting&quot;) 例2 with上下文管理器使用锁 全局变量实现主线程、子线程通信，避免主线程在子线程之前 退出 1234567891011121314151617181920import _thread as threadimport timestdoutmutex = thread.allocate_lock()exitmutexes_bool = [False] * 10def counter(myId, count): for i in range(count): with stdoutmutex: # 线程锁同样支持`with`上下文管理器 print(&quot;[%s] =&gt; %s again&quot; % (myId, i)) exitmutexes[myID] = Truefor i in range(10): thread.start_new_thread(counter, (i, 100))while not all(exitmutexes): time.sleep(0.25) # 暂停主线程，减少占用CPU进行无价值循环print(&quot;main thread exiting&quot;) threadingThread12345678910class Thread: def __init__(self, group=None, target=callable, name=None/str, args=(), kwargs={}, *, daemon=None/True/daemon): pass 用途：可控线程类，有两种方法使用 传递callable参数创建新对象 继承、覆盖run方法：代码和Thread深耦合，可能 不方便代码复用，如multiprocessing模块 参数 group：保留参数用于未来扩展 target：可执行对象，将被run invoke name：线程名，缺省Thread-N args：用于invoke target参数tuple kwargs：用于invoke target keyword参数dict daemon：是否是守护线程 默认情况下，主进程（线程）会等待子进程、线程退出 后退出 主进程（线程）不等待守护进程、线程退出后再退出 注意：主进程退出之前，守护进程、线程会自动终止 若衍生类覆盖此构造器方法，务必首先调用此方法 .run12def run(self): pass 用途：代表线程活动 原run用于invoke target 覆盖此方法设置线程活动 .start12def start(self): pass 用途：开始线程活动 线程创建完成后不会立即执行，需要手动调用.start启动 多次调用raise RuntimeError .join123def join(self, timeout=None/float): pass 用途：等待直到线程结束 join：将线程加入当前线程 可以多次调用 试图导致死锁时，将会raise RuntimeError 参数 timeout：指定超时时间，单位秒 缺省否则阻塞直到线程结束 其他方法12345678910bool = is_alive(self): # 返回线程是否存活def setDaemon(self, daemonic): # 设置守护进程bool = isDaemon(self):def setName(self, name): # 设置线程名def getName(self): Event1234567891011121314class Event(): def set(self): # 设置信标值为`True`，发送信号 bool = is_set(self): # 查看信标是否被设置 bool = wait(self, timeout): # 阻塞，直到超时、信标被设置为`True` # 返回信标值，即因超时返回时返回`False` def clear(): # 重置Event对象，设置信标值为`False` 用途 发送信号：is_set触发事件 接收信号：wait阻塞直到事件发生 Event中包含信标，可在线程中设置、接收，实现线程 间同步 Event对象信标默认设置为False，等待Event对象线程 会阻塞直到信标设置为真 若有线程设置信标为真，则将唤醒所有等待该Event 对象线程 若只想唤醒单个线程，用信号量、Condition代替 .clear.clear可以重置Event对象 难以确保安全清理、重新赋值Event对象，可能导致错过事件 、死锁 且无法保证重置Event对象的代码能在线程再次等待此Event 信号之前执行 所以Event对象最好单次使用，即其信标设置为真应立刻丢弃 若线程需不停重复使用Event对象，使用Condition代替 Condition1234567891011121314151617181920212223class Condition(): def __init__(self, lock=None) # `lock`：`Lock`、`RLock`对象，被用作底层锁 # 缺省创建新`RLock`对象作为底层锁 bool accquire(): # 获取一次condition内部锁 bool release(): # 释放一次condition内部锁 def notify(self, n=1): # 唤醒至多`n`个on this condition的线程 def notify_all(self): # 唤醒所有on this condition的线程 bool = wait(self, timeout=None): # 释放底层锁，阻塞 # 直到被唤醒再次获取底层锁、超时，返回 bool = wait_for(self, predicate(callable), timeout=None): # `wait`直到`predicate`返回`True` 用途：Condition对象wait等待信号、notify唤醒一定 数量线程实现线程同步 说明 以上所有方法执行前均需要已获得底层锁，否则 raise RuntimeError 因此以上方法一般都需要放在with代码块中，保证已经 获取了内部锁 with上下文管理器12345with c: c.wait()with c: c.notify() with进入：获取condition底层锁，保证调用方法前已经获得 底层锁 with退出：释放condition底层锁 Condition支持with上下文管理器，而且非常必须， 在help里面看不到.acquire、.release方法，但是是有 而且可以调用的，应该是官方不建议使用 .wait 用途 方法先释放底层锁，阻塞，使得其他等待 获取此对象底层锁获得锁 等待被notify唤醒，再次获取锁，继续执行 底层锁是RLock时 .wait不是调用其.release()方法，而是调用RLock 内部方法确保真正释放锁，即使RLock被递归的获取多次 再次获取锁时，调用另一个内部接口恢复递归层次，即 RLock内部计数 RLock本身性质：在没有被持有时，其内部计数被重置 为1，其他线程可以自由获取 .notify .notify并不释放condition底层锁 只是控制能够获取底层锁的线程数量 Semaphore123456789class Semaphore(builtins.object): def __init__(self, value): # `value`：起始许可证数量（最多允许同时执行线程数目） bool = acquire(self, blocking=True, timeout=None): # 获取信号量，内部计数（许可证）减1 def release(): # 释放信号量，内部计数（许可证）加1 用途：Semaphore对象release方法生产、acquire方法 消耗信号量，实现线程通信 可以像标准锁一样使用信号量作线程同步，但会增加复杂性 影响性能 更适用于需要在线程间引入信号、限制的程序，如限制代码 的并发访问量 信号量对象是建立在共享计数器基础上的同步原语 .acquire 用途：获取信号量，内部计数（许可证）大于0则立刻减1 内部计数&gt;0，-1立即返回True 内部计数=0，阻塞、等待，直到其他线程调用release 返回值：成功获取许可证则返回True，否则返回False .release 用途：释放信号量，内部计数（许可证）加1 内部计数=0，表明有线程阻塞，随机唤醒线程 BoundedSemaphore1234class BoundedSemaphore(Semaphore): def release(self): # 释放信号量，内部计数加1 # 当信号量总数超过初始化值时`raise ValueError` Lock Threading.Lock等价于_thread.allocate_lock，二者 都是工厂方法，返回lock类的实例 123456789101112131415class lock: bool = acquire(blocking=True/False, timeout=-1) # 尝试获得锁，返回是否获得锁 bool = acquire_lock # deprecated，同`acquire` bool = locked() # 返回锁状态 bool = lockec_lock() # deprecated，同`lock` bool = release() # 释放锁，若锁本身未获取`raise RuntimeError` bool = release_lock() # deprected，同`release` 用途：同步原语，排他性使用某资源 说明 支持with上下文语法，代码块执行前自动获取锁，执行 结束后自动释放 为了避免出现死锁，每个线程应该一次只允许获取一个锁， 否则应该使用更高级死锁避免机制 适合简单的锁定可变对象 lock对象应该是C实现，里面的方法是没有self参数的 其他Lock锁可以视为使用更加方便的全局变量 可以用于线程之间的通信：给每个子线程分配单独一个锁， 主线程、子线程可以通过锁状态通信 很大程度上可以被全局变量“替换” 获得锁：不断检查全局变量状态，阻塞直到全局变量 状态代表锁可获得，修改全局变量状态代表锁被获取 释放锁：修改全局变量状态代表锁可获得 不断检查变量状态会无意义占用CPU时间，可以在检查 间隙使用time.sleep()暂停线程 RLock 工厂方法，返回RLock实例 1234567class RLock: bool = acquire(block=True): # 尝试获取锁，返回是否获取锁 # 每次获取锁，内部计数器加1 bool = release() # 释放锁，若锁本身未获取`raise RuntimeError` # 每次释放锁，内部计数器减1 用途：可重入锁，可以被同一线程多次获取 若锁被当前线程获取多次，则需要被释放同样次数才能被 其他线程获取 即只有内部计数器回到初始状态才能被任意线程获取 没有线程持有锁时，RLock内部计数被重置为1 应该是RLock就是通过内部计数记录被获取次数 常用于给类整体上锁 类内部每个方法都获取锁 类内部方法之间相互调用 这样类实例方法每次只能有一个线程完整调用 1234567891011121314151617import Threadingclass SharedCounter: _lock = threading.RLock() # 被所有实例共享的类级锁 # 需要大量使用计数器时，内存效率更高 def __init__(self, intial_value=0): self._value = initial_value def incr(self, delta=1): with ShareCounter: self._value += delta def decr(self, deta=1): with SharedCounter: # 获取锁之后，调用也需要获取锁的`.incr`方法 self.incr(-delta) local 用途：创建本地线程存储对象，该对象属性保存、读取操作只对 当前线程可见 可以用于保存当前运行线程状态，隔离不同线程间数据 锁 套接字对象 例子提前终止线程轮询方法 将函数封装在类中，在类中设置成员变量作为轮询点 方法terminate改变轮询点状态，用于外部调用结束线程 线程方法run检查轮询点状态判断是否结束自身 线程执行类似IO的阻塞操作时，无法返回自身、无法检查 轮询点，通过轮询终止线程难以协调 1234567891011121314151617181920212223242526from threading import Threadimport timeclass CountDownTask: def __init__(self): self._running = True def terminate(self): self._runing = False def run(self, n): while self._running and n &gt; 0: # 设置轮询点，告诉线程何时应该终止 print(&quot;T-minus&quot;, n) n -= 1 time.sleep(5)def test(): c = CountdownTask() t = Thread(karget=c.run, args=(10,0)) # 创建Thread t.start() # 启动线程 c.terminate() c.join() 超时循环 设置任务超时，超时自动返回 任务只要超时就会返回，不会出现线程阻塞 12345678910111213141516class IOTask: def terminate(self): self._running = False def run(self, sock): sock.settimeout(5) # 设置超时 while self._running: try: data = sock.recv(8192) break except socket.timeout: continue ...continued processing... ...terminated... return 线程同步、通信Event方式123456789101112from threading import Event, Threadingdef send_signal(start_evt): start_evt.set() # 设置事件def recv_signal(): start_evt = Event() # 创建新事件 t = Thread.threading(target=send_signal, start_evt) start_evt.wait() # 阻塞直到接收到信号 Condition实现queue.Queue 自定义数据类型，封装Condition实例进行线程间同步 put方法生产，notify通知消费者 get方法消费，阻塞直到被唤醒 1234567891011121314151617181920212223import heapqfrom threading import Conditionclass PriortyQueue: def __init__(self): self._queue = [ ] self._count = 0 self._cv = Condition() # 封装`Condition`实例实现线程间同步 def put(self, item, priority): with self._cv: heapq.heappush(self._queue, (-priority, self._count, item)) self._count += 1 self._cv.notify() def get(self): with self._cv: # 阻塞，直到空闲 while len(self._queue) == 0: self._cv.wait() # `Condition`默认使用`RLock`，可重入 return heapq.heappop(self._queue)[-1] 防死锁机制严格升序使用锁 local保存当前线程状态，隔离不同线程锁数据 1234567891011121314151617181920212223242526272829303132333435from threading import localfrom contextlib import contextmanager_local = local()@contextmanager # 使支持`with`上下文管理器语法def acquire(*locks): locks = sorted(locks, key=lambda x: id(x)) # 根据*object identifier*对locks排序 # 之后根据此list请求锁都会按照固定顺序获取 acquired = getattr(_local, &quot;acquired&quot;, [ ]) # 为每个线程创建独立属性保存锁 if acquired and max(id(lock)) for lock in acquired &gt;= id(locks[0]): # `_local`中已有锁不能比新锁`id`大，否则有顺序问题 raise RuntimeError(&quot;lock order violation&quot;) acquired.extend(locks) _local.acquired = acquired # 更新线程环境中锁 try: for lock in locks: # 只允许升序获取锁 lock.acquire() yield # `with`语句进入处 finally: # `with`语句退出处 for lock in reversed(locks): # 只允许降序释放锁 lock.release() del acquired[-len(locks):] 123456789101112131415161718192021def thread_1(x_lock, y_lock): while True: with acquire(y_xlock, y_lock): print(&quot;Thread_1&quot;)def thread_2(x_lock, y_lock): while True: with acquire(y_lock, x_lock): print(&quot;Thread_2&quot;)def test(): x_lock = threading.Lock() y_lock = threading.Lock() t1 = threading.Thread(target=thread_1, args=(x_lock, y_lock)): t1.daemon = True t1.start() t1 = threading.Thread(target=thread_2, args=(x_lock, y_lock)) t2.daemon = True t2.start() queue模块Queue123class Queue(builtins.object): def __init__(self, maxsize=0): # `maxsize`；限制可以添加到队列中的元素数量 queue.Queue：创建被多个线程共享的Queue对象 线程安全的数据交换方式，基于collections.deque Queue对象已经包含必要的锁，可以在多个线程间安全的 共享数据 Queue实际上是在线程间传递对象引用，不会复制 数据项，如果担心对象共享状态，可以传递不可修改数据 结构、深拷贝 还可以使用Condition变量包装数据结构，实现线程线程中 间通信 get123456obj = get(self, block=True, timeout=None/num)obj = get_nowait(self): # 等同于`get(block=False)` 用途：从队列中移除、返回一个元素 参数 block False：没有空闲slot立即raise Empty exception .task_done1234def task_done(self): # 指示前一个队列“任务”完成def join(self): # 阻塞直到队列中所有元素被获取（消费）、**处理** 说明 .join阻塞时，要所有队列中元素都被告知task_done， 才能解除阻塞 即队列消费者每次get元素、处理后，要手动调用 task_done告知队列任务已完成 也可以将Event和队列元素封装，用Event对象告知队列元素 处理完成 .put12345678def put(self, item, block=True, timeout=None/num): passdef put_nowait(self, item): # 等价于`put(self, item, block=False)` 用途：向队列中追加元素 参数 block False：没有空闲slot立即raise Full exception .qsize12345678910int = qsize(self): # 返回队列大概大小（不可靠） # 非线程安全，在其使用结果时队列状态可能已经改变bool = empty(self): # deprecated，使用`qsize() == 0`替代 # 和`qsize()`一样非线程安全bool = full(self): # deprecated，使用`qsize() &gt; n`替代，非线程安全 例子队列元素消费通知Event进队列1234567891011121314151617from queue import Queuefrom threading import Thread, Eventdef producer(out_q): while running: evt = Event() out_q.put((data, evt)) # 将`Event`实例放入队列 evt.wait() # 阻塞直到收到消费者信号 # A thread that consumes datadef consumer(in_q): while True: data, evt = in_q.get() evt.set() # 告知生产者消费完成 协调生产、消费线程终止队列中添加特殊值123456789101112131415_sentinel = object()def producer(out_q): while running: out_q.put(data) out_q.put(_sentinel) # 将特殊值放入队列，结束生产、通知消费者def consumer(in_q): while True: data = in_q.get() if data is _sentinel: # 消费者接收到特殊值，结束生产 in_q.put(_sentinel) # 特殊信号放回队列，继续传递 break Queue实现线程池12345678910111213141516171819202122232425from socket import socket, AF_INET, SOCK_STREAMfrom threading import Threadfrom queue import Queuedef echo_client(q): sock, client_addr = q.get() while True: msg = sock.recv(65536) if not msg: break sock.sendall(msg) print(&quot;closed&quot;)def echo_server(addr, nworkers): q = Queue() for n in range(nworkers): t = Thread(target=echo_client, args=(q,)) t.daemon = True t.start() socket = socket(AF_INET, SOCK_STREAM) socket.bind(addr) sock.listen(5) while True: client_sock, client_addr = sock.accept() q.put((client_sock, client_addr)) multiprocessing模块 multiprocessing支持一个基本与平台无关的进程派生模型， 在Unix、Windows下均可正常工作 实现方式 启动一个新的Python进程，import当前模块 pickle序列化需要调用的函数，传递至新进程执行 其中Pool、Queue、Pipe等实际都是其封装其子模块类 的工厂方法 Process123456789101112131415161718192021222324252627282930class Process(): def __init__(self, group=None, target=None/callable, name=None/str, args=()/list, kwargs={}/dict, daemon=None ): self.authkey self.daemon self.exitcode self.name self.pid def is_alive(self): def join(self, timeout=None/num ): def start(self): # 启动进程 def run(self): # `start`方法调用`run`方法，若进程实例未传入`target`， # `start`默认执行`run`方法 def terminate(): # 立即结束进程 用途：Multiprocessing核心，类似于Thread，实现多进程 创建、启动、关闭 成员方法基本类似Thread 1234567891011from multiprocessing import Processimport osdef test(name): print(&quot;Process ID: %s&quot; % (os.getpid()) print(&quot;Parent Process ID: %s&quot; % (os.getppid()))if __name__ == &quot;__main__&quot;: proc = Process(target=test, args=(&quot;nmask&quot;,)) proc.start() proc.join() Pool12345678class Pool: def __init__(self, processes=None/int, initializer=None, initargs=(), maxstacksperchild=None/int, context=None ): 用途：创建管理进程池，提供指定数量进程供用户调用 新请求提交到pool中时 若进程池没有满，将创建新进程执行请求 否则请求等待直到池中有进程结束，然后创建新进程 适合子进程多且需要控制子进程数量时 apply_async12345678def apply(self, func, args=(), kwds={}): # 分配进程执行`func(*args, **kwds)`，阻塞 # 返回值：`func(item)`返回值def apply_async(self, func, args=(), kwds={}, callback=None, error_callback=None) # 异步分配进程执行调用，非阻塞 # 返回值：`ApplyResult`对象 返回值：异步非阻塞调用返回结果操作句柄ApplyResult 回调函数要有返回值，否则ApplyResult.ready()=False， 回调函数永远无法完成 ApplyResult1234567891011class ApplyResult: def __init__(self, cache, chunksize, length, callback, error_callback): def get(self, timeout=None): bool = ready(self): bool = successful(self): bool = wait(self, timeout=None): map_async1234567891011121314151617181920def map(self, func, iterable, chunksize=None): # 同步多进程`map(func, iterable)`，阻塞直到全部完成 # 返回值：结果列表，结果按调用顺序def map_async(self, func, iterable, chunksize=None, callback=None, error_callback=None): # 异步多进程`map`，非阻塞 # 返回值：`MapResult(ApplyResult)`对象def imap(self, func, iterable, chunksize=1): # 迭代器版`map`，更慢、耗内存更少def imap_unordered(self, func, iterable, chunksize=1): # 返回结果无序版`imap`def starmap(self, func, iterable, chunksize=1): # 同步`map`，参数被解构`func(*item)`，阻塞def starmap_async(self, func, iterable, chuncksize=None, callback=None, error_callback=None): # 异步`startmap`，阻塞 终止123456789def close(self): # 关闭进程池，不允许添加新进程def join(self): # 阻塞，直至进程池中所有进程执行完毕 # 必须先`.close`进程池def terminate(self): # 终止进程池 Queue1234567891011121314151617181920212223class SimpleQueue(): bool empty(self): def get(self): def put(self):class Queue: def __init__(self, maxsize=0, *, ctx): def join_thread(self): # join feeder线程 def cancel_join_thread(self): # 控制在进程退出时，不自动join feeder线程 # 有可能导致部分数据在feeder中未被写入pipe而丢失 def close(self): # 关闭feeder线程 def qsize(self): def empty(self): def full(self): def get(self, block=True, timeout=None): def get_nowait(self): def put(self, obj, block=True, timeout=None): def put(self):class JoinableQueue(Queue): def task_done(): def join(): 用途：进程安全队列 multiprocessing.Queue基于multiprocessing.Pipe构建 数据传递时不是直接写入Pipe，而是写入本地buffer， 通过feeder线程写入底层Pipe，从而实现超时控制、 非阻塞put/get 所以提供了.join_thread、cancel_join_thread、 close函数控制feeder流行为 相当于线程安全的queue.Queue的多进程克隆版 multiprocessing.SimpleQueue：简化队列 没有Queue中的buffer，没有使用Queue可能有的问题， 但是put/get方法都是阻塞的、没有超时控制 Pipe mltiprocessing.Pipe()返回两个用管道相连的、读写双工 Connection对象 12345678910111213141516171819202122class Connection(): def __init__(self, handle, readable=True, writable=True): def close(self): def fileno(self): # 返回描述符或连接处理器 bool = poll(self, timeout=0): # 是否有输入可以读取 obj = recv(self): # 接收pickable对象 # 若接收字节流不能被pickle解析则报错 bytes = recv_bytes(self, maxlength=None): # 接收字节流作为`bytes` int = recv_bytes_into(self, buf, offset=0): # 接收字节流存入可写`buf` # 返回读取的字节数量 def send(self, obj): # 发送对象 def send_bytes(self, buf, offset=0, size=None): # 发送bytes-like对象中字节数据 对象会在每条信息前添加标志字节串，可以自动处理多条信息 堆叠 可以通过os.read(connect.fileno())获取 共享内存12345678class SynchronizedBase: def __init__(self, obj, lock=None, ctx=None): def get_lock(self): # 获取`multiprocessing.synchronize.RLock` def get_obj(self): # 获取数据对象，C数据结构`ctypes.` Value1234def Value(typecode_or_type, *args, lock=True): # 返回同步共享对象class Synchronized(SynchronizedBase): value Array123456789def Array(typecode_or_type, size_or_initializer, *, lock=True)def SynchronizedArray(SynchronizedBase): def __getitem__(self, i): def __getslice__(self, start, stop): def __len__(self): def __setitem(self, i, value): def __setslice__(self, start, stop, values): Manager常与Pool模块一起使用，共享资源，不能使用Queue、Array 其他方法123456789101112131415import multiprocessing as mltpl1 = mltp.Lock() # 获取进程锁rl1 = mltp.RLock() # 获取可重入锁s1 = mltp.Semaphore(value=int) # 获取信号量对象bs1 = mltp.BoundedSemaphore(value=int) # 获取有上限信号量对象e1 = mltp.Event() # 获取事件对象cv1 = mltp.Condition(lock=None) # 获取Condition对象cp = mltp.current_process() # 获取当前Process对象 concurrent.futures 异步并发模块 ThreadPoolExecutor1234567891011121314151617class ThreadPoolExecutor: def __init__(self, max_workers=None, thread_name_prefix=''): def shutdown(self, wait=True): # 清理和该执行器相关资源 def submit(self, fn(callable), *args, **kwargs): # 以指定参数执行`fn` # 返回：代表调用的future，可以用于获取结果 def map(self, fn, *iterables, timeout=None, chunksize=1/int) # 并行`map(fn, iterables)` # 返回：按调用顺序的结果迭代器 用途：创建线程池 .shutdown 用途：关闭执行器，清理和该执行器相关的资源 可以多次调用，调用之后不能进行其他操作 参数 wait：阻塞，直到所有运行futures执行完毕，所有 资源被释放 ProcessPoolExecutor1234567891011121314151617class ProcessPoolExecutor: def __init__(self, max_workers=None): def shutdown(self, wait=True): # 清理和该执行器相关资源 def submit(self, fn(callable), *args, **kwargs): # 以指定参数执行`fn` # 返回：代表调用的`Future`实例，可以用于后续处理 def map(self, fn, *iterables, timeout=None, chunksize=1/int) # 并行`map(fn, iterables)` # 返回：按调用顺序的结果迭代器 用途：创建进程池 参考ThreadPoolExecutor，.map方法支持chunksize 参数 常使用with语句使用 1with ProcessPoolExecutor() as Pool: 处理池执行完with语句块中后，处理池被关闭 程序会一直等待直到所有提交工作被完成 注意事项 被提交的任务必须是简单函数形式，不支持方法、闭包和 其他类型可执行 函数参数、返回值必须兼容pickle模块，因为进程间通信 交换数据使用其序列化 函数不要修改环境 被提交的任务函数出打印日志之类等简单行为外，不应该 有保留状态、副作用 混合使用进程池、多线程时 创建任何线程之前先创建、激活进程池 然后线程使用同样的进程池进行计算密集型工作 Future1234567891011121314151617181920class Future: def add_done_callback(self, fn): # 添加future完成的回调函数 # 多次调用添加的回调函数按添加顺序执行 bool = cancel(self): # 尝试取消当前future，返回是否成功取消 # 正在运行、执行完成的future不能被取消 bool = cancelled(self): # 查看当前future是否被取消 bool = done(self): # 查看当前future是否被取消、完成 def exception(self, timeout=None): # 返回当前future代表的调用的exception def result(self, timeout=None): # 返回当前future代表调用的返回值 用途：代表一个异步计算的结果 直接创建对象无价值 socket模块","link":"/Python/Cookbook/parallel.html"},{"title":"设计模式简介","text":"设计默认（design pattern） 软件开发过程中面临的一般问题的解决方案 反复使用的、多数人知晓的、经过分类编目、代码设计经验的 总结 利于重用代码、提高代码可读性、可靠性 设计模式原则设计模式主要基于以下面向对象设计原则 对接口编程而不是对实现编程 优先使用对象组合而不是继承 六大原则 开闭原则（open close principle） 对扩展开放、修改关闭。 程序需要扩展时，不能修改原有代码以实现热拔插效果， 易于扩展和升级 里氏代换原则（Liskov Substitution Principle） 任何基类可以出现的地方，子类一定可以出现 此为继承复用的基石，只有派生类了可以替换掉基类，且 软件功能不受到影响，基类才能真正被复用 对开闭原则的补充，实现开闭原则的关键步骤就是 抽象化，基类与子类的继承关系就是抽象化的具体实现， LSP就是对实现抽象化的具体步骤的规范 依赖倒转原则（Dependence Inversion Principle） 针对接口编程，以来抽象而不是具体 开闭原则的基础 接口隔离原则（Interface Segregation Principle) 使用多个隔离的接口优于单个接口 降低类之间的耦合度 迪特米法则（最小知道原则，Demeter Principle） 一个尸体应尽量少与其他实体发生相互作用 使得系统功能模块相对独立 合成复用原则（Composite Reuse Principle） 尽量使用合成、聚合方式，而不是继承 创建型模式在创建对象的同时隐藏创建逻辑的方式，而不是直接使用new 运算符直接实例化对象，这使得程序在判断针对某个给定实例需要 创建哪些对象时更加灵活 工厂模式 Factory Pattern创建对象时不会对客户端暴露创建逻辑，而是通过共同的接口指向 新创建的对象 意图：定义创建对象的接口，让其子类决定实例化何种工厂类， 工厂模式使其创建过程延迟到子类进行 解决问题：接口选择问题 使用场景：明确地计划不同条件下创建不同实例时 解决方案：子类实现工厂接口，同时返回抽象产品 关键：创建过程在子类中进行 优点 只需要名称就可以创建对象 扩展性高，需要增加产品，只需要增加工厂类 屏蔽产品具体实现，调用者只关心产品接口 缺点 每次增加产品，都需要增加具体类和对象实现工厂，系统中 类个数增长快，增加复杂度 增加了系统具体类的依赖 注意 在任何需要生成复杂对象的地方，都可以使用工厂模式 但简单对象，使用工厂模式需要引入工厂类，增加系统 复杂度 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// step1: create interfacepublic interface Shape{ void draw();}// step2: create concrete class implementing interfacepublic class Rectangle implements Shape{ @Override public void draw(){ System.out.println('Inside Rectangle::draw() method.&quot;); }}public class Square implements Shape{ @Override public void draw(){ System.out.println(&quot;Inside Square::draw() method.&quot;); }}public class Circle implements Shape{ @Override public void draw(){ System.out.println(&quot;Inside Circle::draw() method.&quot;); }}// step3: create factory class generating concrete classes// according to given infopublic class ShapeFactory{ public Shape getShape(String shapeType){ if (shapeType == null){ return null; } if (shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;)){ return new Circle(); } if (shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;)){ return new Rectangle(); } if (shapeType.equalsIgnoreCase(&quot;SQUARE&quot;)){ return new Square(); } return null; }}// usage demopublic class FactoryPatternDemo{ public static void main(String[] args){ ShapeFactory shapeFactory = new ShapeFactory(); Shape circle = shapeFactory.getShape(&quot;CIRCLE&quot;); circle.draw(); Shape rectangle = shapeFactory.getShape(&quot;Rectangle&quot;); rectangle.draw(); Shape square = shapeFactory.getShape(&quot;square&quot;); square.draw(); }} 抽象工厂模式 Abstract Factory Pattern围绕一个超级工厂创建其他工厂，超级工厂又称为其他工厂的工厂， 其中接口是负责创建相关对象的工厂，不需要显式指定他们的类， 每个生成的工厂都能按照工厂模式提供对象 意图：提供创建一系列相关或相互依赖对象的接口，且无需指定 其具体类型 解决问题：端口选择问题 使用场景：系统的产品有多个产品族，而系统只需要消费其中 一族的产品 解决方案：在一个产品族中定义多个产品 优点：当一个产品族中多个对象被设计为一起工作时，能够保证 客户端始终只使用同一个产品族中的对象 缺点：产品族扩展困难，需要同时修改具体类、抽象工厂类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142// step1: create interfacepublic interface Shape{ void draw();}public interface Color{ void fill();}// step2: create concrete class implementing interface// shape classespublic class Rectangle implements Shape{ @Override public void draw(){ System.out.println(&quot;Inside Rectangle::draw() method.&quot;); }}public class Square implements Shape{ @Override public void draw(){ System.out.println(&quot;Inside Square::draw() method.&quot;); }}public class Circle implements Shape{ @Override public void draw(){ System.out.println(&quot;Inside Circle::draw() method.&quot;); }}// color classespublic Red implements Color{ @Override public void fill(){ System.out.println(&quot;Inside Red::fill() method.&quot;); }}public Green implements Color{ @Override public void fill(){ System.out.println(&quot;Inside Green::fill() method.&quot;); }}public Blue implements Color{ @Override public void fill(){ System.out.println(&quot;Inside Blue::fill() method.&quot;); }}// step3: create abstract class to get factory classespublic abstract class AbstractFactory{ public abstract Color getColor(String color); public abstract Shape getShape(String shape);}// step4: create factory classes extending abstract factory// classpublic class ShapeFactory extends AbstractFactory{ @Override public Shape getShape(String shapeType){ if (shapeType == null){ return null } if (shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;){ return new Circle(); } if (shapeType.equalsIgnoreCase(&quot;Rectangle&quot;){ return new Rectangle(); } if (shapeType.equalsIgnoreCase(&quot;square&quot;){ return new Square(); } return null; } @Override public Color getColor(String Color){ return null; }}public class ColorFactory extends AbstractFactory{ @Override public Shape getShape(String shapeType){ return null; } @Override public getColor(String color){ if (color == null){ return null; } if (color.equalsIgnoreCase(&quot;RED&quot;){ return new Red(); } if (color.equalsIgnoreCase(&quot;Green&quot;){ return new Green(); } if (color.equalsIgnoreCase(&quot;blue&quot;){ return new Blue(); } return null; }}// step5: create factory producerpublic class FactoryProducer{ public static AbstractFactory getFactory(String choice){ if(choice.equalsIgnoreCase(&quot;SHAPE&quot;){ return new ShapeFactory(); }else if(choice.equalsIgnoreCase(&quot;COLOR&quot;){ return new ColorFactory(); } return null; }}// step6: demopublic class AbstractFactoryPatternDemo{ public static void main(String[] args){ // use shape cluster only AbstractFactory shapeFactory = FactoryProducer.getFactory(&quot;SHPAE&quot;); Shape circle = shapeFactory.getShape(&quot;CIRCLE&quot;); circle.draw(); Shape rectangle = shapeFactory.getShape(&quot;RECTANGLE&quot;); rectangle.draw(); Shape square = shapeFactory.getShape(&quot;SQUARE&quot;); square.draw(); //use color cluster only AbstractFactory colorFactory = FactoryProducer.getFactory(&quot;color&quot;); Color red = colorFactory.getColor(&quot;RED&quot;); red.fill(); Color green = colorFactory.getColor(&quot;green&quot;); green.fill(); Color blue = colorFactory.getColor(&quot;blue&quot;); blue.fill(); }} 单例模式 Singleton Pattern涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个 对象被创建，提供一种访问其唯一对象的方式，不需要实例化该类 的对象，可以直接访问 意图：保证类只有一个实例，并提供一个访问其的全局访问点 解决问题：一个全局使用的类频繁创建与销毁 使用场景：控制实例数据，节省系统资源 解决方法：判断系统是否已有实例，若有则返回，否则创建 优点 内存仅有一个实例，减少内存开销 避免对资源的多重占用（如文件读写） 缺点 没有接口、无法继承，与单一职责冲突 类应该只关心内部逻辑，而不设计外部如何实例化 123456789101112131415161718192021222324252627282930// step1: create singleton classpublic class SingleObject{ // create object as soon as class is loaded. It's okay // to move creating to `getInstance()` private static SingleObject instance = new SingleObject(); // private construction method, so this class won't be // instantiated private SingleObject(){}; public static SingleObject getInstance(){ return instance; } public void showMessage(){ System.out.println(&quot;hello world&quot;); }}// step2: test demopublic class SingletonPatternDemo{ public static void main(String[] args){ // private construction method, so `new SingleObject()` // is illegal SingleObject object = SingleObject.getInstance(); object.showMessage(); }} 建造者模式 Builder Pattern使用多个简单对象一步步构建成复杂对象 意图：将复杂的构建与其表示相分离，使得同样的构建过程可以 创建不同的表示 解决问题：对于由负责多个子对象组成复杂对象，其各个组成 部分可能随着需求而变化，而构建复杂对象的算法相对稳定 使用场景：基本部件不变，而其组合经常变化 解决方案：将变、不变分开考虑 优点 建造者独立，容易扩展 便于控制细节风险 缺点 产品必须有共同点，范围有限制 如果内部变化复杂，会有很多建造类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140// step1public interface Item{ public String name(); public Packing packing(); public float price();}public interface Packing{ public String pack();}// step2public class Wrapper implements Packing{ @Override public String pack(){ return &quot;Wrapper&quot;; }}public class Bottle implements Packing{ @Override public String pack(){ return &quot;Bottle&quot;; }}// step3public abstract class Burger implements Item(){ @Override public Packing packing(){ return new Wrapper(); } @Override public abstract float price();}public abstract class ColdDrink implements Item{ @Override public Packing packing(){ return new Bottle(); } @Override public abstract float price();}// step4public class VegBurger extends Buger{ @Override public float price(){ return 25.0f; } @Override public String name(){ return &quot;Veg Burger&quot;; }}public class ChickenBurger extends Burger{ @Override public float price(){ return 50.5f; } @Override public String name(){ return &quot;Chicken Burger&quot;; }}public class Coke extends ColdDrink{ @Override public float price(){ return 30.0f; } @Override public String name(){ return &quot;Coke&quot;; }}public class Pepsi extends ColdDrink{ @Override public float price(){ return 35.0f; } @Override public String name(){ return &quot;Pepsi&quot;; }}// step5import java.util.ArrayList;import java.util.List;public class Meal{ private List&lt;Item&gt; items = new ArrayList&lt;Item&gt;(); public void addItem(Item item){ items.add(item); } public float getCost(){ float cost = 0.0f; for (Item item: items){ cost += item.price(); } return cost; } public void showItem(){ for (Item item: items){ System.out.print(&quot;Item: &quot; + item.name()); System.out.print(&quot;, Packing: &quot; + item.packing().pack()); System.out.println(&quot;, Price: &quot; + item.price()); } }}// step6public class MealBuilder{ public Meal prepareVegMeal(){ Meal meal = new Meal(); meal.addItem(new VegBurger()); meal.addItem(new Coke()); return meal; } public Meal parpareNonVegMeal(){ Meal meal = new Meal(); meal.addItem(new ChickenBuger()); meal.addItem(new Pepsi()); return meal; }}// step7public class BuilderPatternDemo{ public static void main(String[] args){ MealBuilder mealBuilder = new MealBuilder(); Meal vegMeal = mealBuilder.prepareVegMeal(); System.out.println(&quot;Veg Meal&quot;); vegMeal.showItems(); System.out.println(&quot;Total Cost: &quot; + vegMeal.getCost()); Meal.nonVegMeal = mealBuilder.prepareNonVegMeal(); System.out.println(&quot;\\n\\nNon-Veg Meal&quot;); nonVegMeal.showItems(); System.out.println(&quot;Total Cost: &quot; + nonVegMeal.getCost()); }} 原型模式 Prototype Pattern实现一个原型接口，用于创建重复对象，同时又能保证性能 意图：用原型实例指定创建对象的种类，并通过拷贝这些原型 创建新的对象 解决问题：在运行时建立和删除原型 使用场景 类的初始化代价大 系统应该独立其产品的创建、构成、表示 要实例化的类是在运行时指定 避免创建与产品类层次平行的工厂类 类的实例只能有几个不同的状态组合中的一种时，建立相应 数目的原型并克隆可能比每次用合适的状态手工实例化更 方便 实际上原型模式很少单独出现，一般和工厂模式一起出现， 通过clone方法创建对象返回给调用者 优点 性能提高，尤其是直接创建对象代价比较大 （如对象需要在高代价的数据库操作后被创建） 逃避构造函数的约束 缺点 配备克隆方法需要对类的功能全盘考虑，对已有类可能比较 难，尤其是类引用不支持串行化的间接对象 注意：原型模式时通过拷贝现有对象生成新对象，要主要区分 浅拷贝和深拷贝 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899// step1: create an abstract class implementing Cloneable// interfacepublic abstract class Shape implements Cloneable{ // Java中已经同原型模式融为一体 // 实现`Cloneable`接口实现浅拷贝，深拷贝则是通过实现 // `Serializable`读取二进制流 private String id; protected String type; abstract void draw(); public String getType(){ return type; } public String getId(){ return id; } public void setId(String id){ this.id = id; } public Object clone(){ Object clone = null; try{ clone = super.clone(); } catch (CloneNotSupportedException e){ e.printStackTrace(); } return clone; }}// step2: create a concrete class extending the abstract// classpublic class Rectangle extends Shape{ public Rectangle(){ tpye = &quot;Rectangle&quot;; } @Override public void draw(){ System.out.println(&quot;Inside Rectangle::draw() method.&quot;); }}public class Square extends SHape{ public Square(){ type = &quot;Sqaure&quot;; } @Override public void draw(){ System.out.println(&quot;Inside Square::draw() method.&quot;); }}public class Circle extends Shape{ public Circle(){ type = &quot;Circle&quot;; } @Override public void draw(){ System.out.println(&quot;Inside Circle::draw() method.&quot;); }}// step3: creat a class to store the implementsimport java.util.Hashtable;public class ShapeCache{ private static Hashtable&lt;String, Shape&gt; shapeMap = new Hashtable&lt;String, Shape&gt;(); public static Shape getShape(String shapeId){ Shape cachedShape = shapeMap.get(shapeId); return (Shape)cachedShape.clone(); } public static void loadCache(){ Circle circle = new Circle(); circle.setId(&quot;1&quot;); shapeMap.put(circle.getId(), circle); Square square = new Square(); square.setId(&quot;2&quot;); shapeMap.put(square.getId(), square); Rectangle rectangle = new Rectangle(); rectangle.setId(&quot;3&quot;); shapeMap.put(rectangle.getId(), rectangle); }}// step4: test demopublic class PrototypePatternDemo{ public static void main(String[] args){ ShapeCache.loadCache(); Shape clonedShape = (Shape)ShapeCache.getShape(&quot;1&quot;); System.out.println(&quot;shape: &quot; + clonedShape.getType()); Shape clonedShape2 = (Shape)ShapeCache.getShape(&quot;2&quot;); System.out.println(&quot;shape: &quot; + clonedShape2.getType()); Shape clonedShape3 = (Shape)ShapeCache.getShape(&quot;2&quot;); System.out.println(&quot;shape: &quot; + clonedShape3.getType()); }} 结构型模式关注类和对象的；组合，继承的概念被用来组合接口和定义组合对象 获得新功能的方式 适配器模式 Adaptor Pattern不兼容的接口之间的桥梁，负责加入独立的或不兼容的接口功能 意图：将一个类的接口转换为客户希望的另一个接口，使得原本 由于接口不兼容的类可以一起工作 解决问题：“现存对象”无法满足新环境要求 使用场景 系统需要使用现有类，现有类不符合系统需要 想要建立可以重复使用的类，用于与一次彼此之间没有太大 关联的类（包括可能未来引进的类） 通过接口转换将一个类插入另一个类 解决方法：继承或以来 优点 可以让任何两个没有关联的类一起运行 提高类类的复用 增加了类的透明度 灵活性好 缺点 过多的使用适配器可能会导致系统凌乱，不易把握整体 对于单继承语言，至多只能适配一个适配器类 注意事项：适配器模式用于解决正在服役的项目问题，而不是 详细设计时 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// step1: create interfacespublic interface MediaPlayer{ public void play(String audioType, String fileName);}public interface AdvancedMediaPlayer{ public void playVlc(String fileName); public void playMp4(String fileName);}// step2:public class VlcPlayer implements AdvancedMediaPlayer{ @Override public void playVlc(String fileName){ System.out.println(&quot;Playing vlc file. Name: &quot; + fileName); } @Override public void playMp4(String fileName){ }}public class Mp4Player implements AdvancedMediaPlayer{ @Override public void playVlc(String fileName){ } @Override public void playMp4(String fileName){ System.out.println(&quot;Playing mp4 file. Name: &quot; + fileName); }}// step3: create adapter classpublic class MediaAdapter implements MediaPlayer{ AdvancedMediaPlayer advancedMusicPlayer; // construction method public MediaAdapter(String audioType){ if(audioType.equalsIgnoreCase(&quot;vlc&quot;)){ advancedMusicPlayer = new VlcPlayer(); }else if (audioType.equalsIgnoreCase(&quot;mp4&quot;)){ advancedMusicPlayer = new Mp4Player(); } } @Override public void play(String audioType, String fileName){ if(audioType.equalsIgnoreCase(&quot;vlc&quot;)){ advancedMusicPlayer.playVlc(fileName); }else if(audioType.equalsIgnoreCase(&quot;mp4&quot;)){ advancedMusciPlayer.playMp4(fileName); } }}// step4:public class AudioPlayer implements MediaPlayer{ MediaPlayer mediaAdapter; @Override public void play(String audioType, String fileName){ if(audioType.equalsIgnoreCase(&quot;mp3&quot;)){ System.out.println(&quot;Playing mp3 file. Name: &quot; + fileName); }else if(audioType.equalsIgnoreCase(&quot;vlc&quot;) || audioType.equalsIgnoreCase(&quot;mp4&quot;)){ mediaAdapter = new MediaAdatper(audioType); mediaAdapter.play(audioType, fileName); }else{ System.out.println(&quot;Invalid media. &quot; + audioType + &quot; format not supported.&quot;); } }}// step5: test demopublic class AdapterPatternDemo{ public static void main(String[] args){ AudioPlayer audioPlayer = new AudioPlayer(); audioPlayer.play(&quot;mp3&quot;, &quot;beyond the horizon.mp3&quot;); audioPlayer.play(&quot;mp4&quot;, &quot;alone.mp4&quot;); audioPlayer.play(&quot;vlc&quot;, &quot;far far away.vlc&quot;); audioPlayer.play(&quot;avi&quot;, &quot;mind me.avi&quot;); }} 桥接模式 Bridge Pattern把抽象化与现实化解耦，使得二者可以独立变化，涉及一个作为桥接 的接口，使得实体类的功能能独立与接口实现类 意图：将抽象部分与实现部分分离，使得其可以独立变化 解决问题：在有多种可能会变化的情况下，用继承会造成类爆炸 问题，扩展起来不灵活 使用场景：实现系统可能有多个角度分类，每种角度都可能变化 解决方法：把多角度分类分离出来，让其独立变化，减少其间 耦合 优点 抽象和实现的分离 优秀的扩展能力 实现细节对客户透明 缺点：照成系统的理解与设计难度，由于聚合关联关系建立在 抽象层，要求开发者针对抽象进行设计、编程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// step1public interface DrawAPI{ public void drawCircle(int radius, int x, int y);}// step2public class RecCircle implements DrawAPI{ @Override public void drawCircle(int radius, int x, int y){ System.out.println(&quot;Drawing Circle[color: red, radius: &quot; + radius + &quot;, x: &quot; + x +&quot;, y: &quot; + y + &quot;]&quot;); }}public class GreenCircle implements DrawAPI{ @Override public void drawCircle(int radius, int x, int y){ System.out.println(&quot;Drawing Circle[color: Green, radius: &quot; + radius + &quot;, x: &quot; + x +&quot;, y: &quot; + y + &quot;]&quot;); }}// step3public abstract class Shape{ protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI){ this.drawAPI = drawAPI; } public abstract void draw();}// step4public class Circle extends Shape{ private int x, y, radius; public Circle(int x, int y, int radius, DrawAPI drawAPI){ super(drawAPI); this.x = x; this.y = y; this.radius = radius; } public void draw(){ drawAPI.drawCircle(radius, x, y); }}// step5: test demopublic class BridgePatternDemo{ public static void main(String[] args){ Shape redCircle = new Circle(100, 100, 10, new RedCircle()); Shape greenCircle = new Circle(100, 100, 10, new GreenCircle()); redCircle.draw(); greenCircle.draw(); }} 过滤器（标准）模式 Filter、Criteria Pattern使用多种不同的标准过滤一组对象，通过逻辑运算以解耦的方式将其 连接起来，结合多个标准或者单一标准 意图： 解决问题： 适用场景： 解决方法： 优点 缺点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144// step1: create a class which will be impose criteria onpublic class Person{ private String name; private String gender; pirvate String maritalStatus; public Person(String name, String gender, String maritalStatus){ this.name = name; this.gender = gender; this.maritalStatus = maritalStatus; } public String getName(){ return name; } public String getGender(){ return gender; } public String getMaritalStatus(){ return maritalStatus; }}// step2: create an interface for criteriaimport java.util.List;public interface Criteria{ public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons);}// step3: creat import java.util.ArrayList;import java.util.List;public class CriteriaMale implements Criteria{ @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons){ List&lt;Person&gt; malePersons = new ArrayList&lt;Peron&gt;(); for(Person person : persons){ if(person.getGender().equalsIgnoreCase(&quot;MALE&quot;){ malePersons.add(Person); } } return malePersons; }}public class CriteriaFemale implements Criteria{ @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons){ List&lt;Person&gt; femalePerson = new ArrayList&lt;Person&gt;(); for(Person person: persons){ if(person.getGender.equalsIgnoreCase(&quot;Female&quot;){ femalePersons.add(person); } } return femalePersons; }}public class CriteriaSingle implements Criteria{ @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons){ List&lt;Person&gt; singlePersons = new ArrayList&lt;Person&gt;(); for(Person person: persons){ if(person.getMaritalStatus().equalsIgnoreCase(&quot;Single&quot;)){ singlePerson.add(person); } } return singlePersons; }}public class AndCriteria implements Criteria{ pirvate Criteria criteria; private Criteria otherCriteria; public AndCriteria(Criteria criteria, Criteria otherCriteria){ this.criteria = criteria; this.otherCriteria = otherCriteria; } @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons){ List&lt;Person&gt; firstCriteriaPersons = criteria.meetCriteria(persons); return otherCriteria.meetCriteria(firstCriteriaPersons); }}public class OrCriteria implements Criteria{ pirvate Criteria criteria; private Criteria otherCriteria; public Criteria(Criteria criteria, Criteria otherCriteria){ this.criteria = criteria; this.otherCriteria = otherCriteria; } @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons){ List&lt;Person&gt; firstCriteriaItems = criteria.meetCriteria(persons); List&lt;Person&gt; otherCriteriaItems = criteria.meetCriteria(persons); for(Person person: otherCriteriaItems){ if(!firstCriteriaItems.contains(person)){ firstCriteriaItems.add(person); } } return firstCriteriaItems; }}// step4: test demoimport java.util.ArrayList;import java.util.List;public class CriteriaPatternDemo{ public static void main(String[] args) { List&lt;Person&gt; persons = new ArrayList&lt;Person&gt;(); persons.add(new Person(&quot;Robert&quot;,&quot;Male&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;John&quot;,&quot;Male&quot;, &quot;Married&quot;)); persons.add(new Person(&quot;Laura&quot;,&quot;Female&quot;, &quot;Married&quot;)); persons.add(new Person(&quot;Diana&quot;,&quot;Female&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;Mike&quot;,&quot;Male&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;Bobby&quot;,&quot;Male&quot;, &quot;Single&quot;)); Criteria male = new CriteriaMale(); Criteria female = new CriteriaFemale(); Criteria single = new CriteriaSingle(); Criteria singleMale = new AndCriteria(single, male); Criteria singleOrFemale = new OrCriteria(single, female); System.out.println(&quot;Males: &quot;); printPersons(male.meetCriteria(persons)); System.out.println(&quot;\\nFemales: &quot;); printPersons(female.meetCriteria(persons)); System.out.println(&quot;\\nSingle Males: &quot;); printPersons(singleMale.meetCriteria(persons)); System.out.println(&quot;\\nSingle Or Females: &quot;); printPersons(singleOrFemale.meetCriteria(persons)); } public static void printPersons(List&lt;Person&gt; persons){ for (Person person : persons) { System.out.println(&quot;Person : [ Name : &quot; + person.getName() +&quot;, Gender : &quot; + person.getGender() +&quot;, Marital Status : &quot; + person.getMaritalStatus() +&quot; ]&quot;); } }} 组合模式 Composite Pattern把一组相似的对象当作一个单一的对象，依据树形结构来组合对象， 用来表示部分和整体层次，亦称部分整体模式 意图：将对象组合成树形结构以表示“部分-整体”层次结构， 使得用户对单个对象和组合对象的使用具有一致性 解决问题：模糊树形结构问题中简单元素和复杂元素的概念， 客户程序可以像处理简单元素一样处理复杂元素，使得客户程序 与复杂元素的内部结构解耦 使用场景 表示对象的“部分-整体”层次结构（树形结构） 希望用户忽略组合对象与单个对象的不同，统一地使用组合 结构中所有对象 解决方法：树枝和叶子实现统一接口，树枝内部组合该接口 优点 高层模块调用简单 节点自由度增加 缺点：叶子和树枝的声明都是实现类，而不是接口，违反了依赖 倒置原则 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// step1: create a class containing a list of Selfimport java.util.ArrayList;import java.util.List;public class Employee{ pirvate String name; pirvate String dept; private int salary' private List&lt;Employee&gt; subordinates; public Employee(String name, String dept, int sal){ this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;Employee&gt;(); } public void add(Employee e){ subordinates.add(e); } public void remove(Employee e){ subordinates.remove(e); } public List&lt;Employee&gt; getSubordinates(){ return subordinates; } public String toString(){ return (&quot;Employee: [Name: &quot; + name + &quot;, dept: &quot; + dept + &quot;, salary: &quot; + salary + &quot;]&quot;); }}// step2: test demopublic class CompositePatternDemo{ public static void main(String[] args){ Employee CEO = new Employee(&quot;John&quot;, &quot;CEO&quot;, 30000); Employee headSales = new Employee(&quot;Robert&quot;, &quot;Head Sales&quot;, 20000); Employee headMarketing = new Employee(&quot;Michel&quot;, &quot;Head Marketing&quot;, 20000); Employee clerk1 = new Employee(&quot;Laura&quot;, &quot;Marketing&quot;, 10000); Employee clerk2 = new Employee(&quot;Bob&quot;, &quot;Marketing&quot;, 10000); Employee saleExecutive1 = new Employee(&quot;Richard&quot;, &quot;Sales&quot;, 10000); Employee saleExecutive2 = new Employee(&quot;Rob&quot;, &quot;Sales&quot;, 10000); CEO.add(headSales); CEO.add(headMarketing); headSales.add(saleExecutive1) headSales.add(saleExecutive2); headMarketing.add(clerk1); headMarketing.add(clerk2); System.out.println(CEO); for(Employee headEmployee: CEO.getSubordinates()){ System.out.println(headEmployee); for(Employee employee: headEmployee.getSubordinates()){ System.out.println(employee); } } }} 组合模式：在对象中包含其他对象，就是树，类似于叶子节点等等 装饰器模式 Decorator Pattern创建一个新类用于包装原始类，向其添加新功能，同时不改变其结构 意图：动态的给对象添加额外的职责，比生成子类更灵活 解决问题：为扩展类而使用继承的方式，会为类引入静态特征， 随着扩展功能的增多，子类会膨胀 使用场景：不增加很多子类的情况下扩展类 解决方法：将具体功能职责划分，同时继承装饰者模式 优点：装饰类和被装饰类可以独立发展，不会相互耦合，替代 继承从而动态的扩展实现类的功能 缺点：多层装饰复杂 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// step1public interface Shape{ void draw();}// step2public class Rectangle implements Shape{ @Override public void draw(){ System.out.println(&quot;Shape: Rectangle&quot;); }}public class Circle implements Shape{ @Override public void draw(){ System.out.println(&quot;Shape: Cirlce&quot;); }}// step3public abstract class ShapeDecorator implements Shape{ protected Shape decoratedShape; public ShapeDecorator(Shape decoratedShape){ this.decoratedShape = decoratedShape; } public void draw(){ decoratedShape.draw(); }}// step4public class RedShapeDecorator extends ShapeDecorator{ public RedShapeDecorator(Shape decoratedShape){ super(decoratedShape); } @Override public void draw(){ decoratedShape.draw(); setRedBorder(decoratedShape); } private void setRedBorder(Shape decoratedShape){ System.out.println(&quot;Border Color: Red&quot;); }}// step5: demopublic class DecoratorPatternDemo{ public static void main(String[] args){ Shape circle = new Circle(); Shape redCircle = new RedShapeDecorator(new Circle()); Shape redRectangle = new RedShapeDecorator(new Rectangle()); System.out.println(&quot;Circle with normal border&quot;); circle.draw(); System.out.println(&quot;\\nCircle of red border&quot;); redCircle.draw(); System.out.println(&quot;\\nRectangle of red border&quot;); redRectangle.draw(); }} 外观模式 Facade Pattern隐藏系统的复杂性，想客户端提供访问系统的接口，简化客户端请求 方法和对象系统类方法的委托调用 意图：定义一个高级接口，使得子系统更加容易使用 解决问题：降低访问复杂系统内部子系统时的复杂度 使用场景 客户端不需要知道复杂系统内部的复杂联系，系统只需要 提供“接待员” 定义系统的入口 解决方法：客户端不与系统耦合，外观类与系统耦合 优点 减少系统相互依赖 提高灵活性 提高安全性 缺点：不符合开闭原则，修改时麻烦 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// step1public interface Shape{ void draw();}// step2public class Rectangle implements Shape{ @Override public void draw(){ System.out.println(&quot;Rectangle::draw()&quot;); }}public class Square implements Shape{ @Override public void draw(){ System.out.println(&quot;Square::draw()&quot;); }}public class Circle implements Shape{ @Override public void draw(){ System.out.println(&quot;Circle::draw()&quot;); }}// step3public class ShapeMaker{ private Shape circle; private Shape rectangle; private Shape square; public ShapeMaker(){ circle = new Circle(); rectangle = new Rectangle(); square = new Square(); } public void drawCircle(){ circle.draw(); } public void drawRectangle(){ rectangle.draw(); } public void drawSquare(){ square.draw(); }}// step4public class FacadePatternDemo{ public static void main(String[] args){ ShapeMaker shapeMaker = new ShapeMaker(); shapeMaker.drawCircle(); shapeMaker.drawRectangle(); shapeMaker.drawSquare(); }} 享元模式 Flyweight Pattern尝试重用现有的同类对象，仅在找不到匹配对象才创建新对象， 减少创建对象的数量、内存占用，提高性能 意图：运用共享技术有效地支持大量细粒度的对象 解决问题：大量对象时，抽象出其中共同部分，相同的业务请求 时，直接返回内存中已有对象 使用场景 系统中有大量对象，消耗大量内存 对象的状态大部分可以外部化 对象可以按照内蕴状态分组，将外蕴状态剔除后可以每组 对象只使用一个对象代替 系统不依赖这些对象的身份，对象是“不可分辨的” 解决方法：用唯一标识码判断，如果内存中存在，则返回唯一 标识码所标识的对象 优点：减少对象创建、内存消耗 缺点：增加系统复杂度，需要分离内蕴、外蕴状态，而且外蕴 状态具有固有化相知，不应该随着内部状态变化而变化，否则会 照成系统混乱 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// step1public interface Shape{ void draw();}// step2public class Circle implements Shape{ private String color; private int x; private int y; private int radius; public Circle(String color){ this.color = color; } public void setX(int x){ this.x = x; } public vodi setY(int y){ this.y = y; } public void setRadius(int radius){ this.radius = radius; } @Override public void draw(){ System.out.println(&quot;Circle: Draw() [Color: &quot; + color + &quot;,x: &quot; + x + &quot;,y: &quot; + y + &quot;,radius: &quot; + radius); }}// step3import java.util.HashMap;public class ShapeFactory{ private static final HashMap&lt;String, Shape&gt; circleMap = new HashMap&lt;&gt;(); public static Shape getCircle(String color){ Circle circle = (Circle)circleMap.get(Color); if(circle == null){ circle = new Circle(color); circleMap.put(color, circle); System.out.println(&quot;Creating circle of color: &quot; + color); } return cirle; }}// step4public class FlyweightPatternDemo{ pirvate static final String colors[] = {&quot;Red&quot;, &quot;Green&quot;, &quot;Blue&quot;, &quot;White&quot;, &quot;Black&quot;}; public static void main(String[] args){ for (int i = 0; i &lt; 20; ++i){ Circle circle = (Circle)ShapeFactory.getCircle(getRamdonColor()); circle.setX(getRandomX()); circle.setY(getRandomY()); circle.setRadius(100); circle.draw(); } } private static String getRandomColor(){ return colors[(int)(Math.random()*colors.length))]; } private static int getRandomX(){ return (int)(Math.random()*100) } private static int getRandomY(){ return (int)(Math.random()*100); }} 代理模式 Proxy Pattern创建具有现有对象的对象，向外界提供功能接口，一个类代表另 一个类的功能， 意图：为其他对象提供一种代理以控制对这个对象的访问 解决问题：直接访问对象会给使用者、系统结构代理问题 使用场景：在访问类时做一些控制 解决方法：增加中间层 优点 职责清晰 高扩展性 智能化 缺点 在客户端和真实端之间增加了代理对象，可能降低效率 代理模式需要额外工作，实现可能非常复杂 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// step1public interface Image{ void dispaly();}// step2publi class RealImage implements Image{ private String fileName; public RealImage(String fileName){ this.filName = fileName; loadFromDisk(fileName); } @Ovrride public void display(){ System.out.println(&quot;Displaying &quot; + fileName); } private void loadFromDisk(String fileName){ System.out.println(&quot;Loading &quot; + fileName); }}// step3public class ProxyImage implements Image{ private RealImage realImage; private String fileName; public ProxyImage(String fileName){ this.fileName = fileName; // it won't load image until display-method is // called } @Override public void display(){ if(realImage = Null){ realImage = new RealImage(fileName); } realImage.display(); }}// step4public class ProxyPatternDemo{ public static void main(String[] args){ Image image = new ProxyImage(&quot;test_10mb.jpg&quot;); image.display(); }} 行为型模式特别关注对象之间的通信 责任链模式 Chain of Responsibility Pattern为请求创建接收者对象的链，对请求的发送者和接收者进行解耦， 通常每个接着者都包含对另一个接收者的引用 意图：避免请求发送者与接收者耦合，让多个对象都有可能接受 请求，将这些对象连接成职责链，并且沿着这条链传递请求， 直到有对象处理 解决问题：职责链上处理者负责处理请求，客户只要将请求发送 到职责链上即可，无需关心请求的处理细节和请求的传递，所以 职责链将请求的发送者和请求的处理者解耦 使用场景：在处理时已过滤多次 解决方法：拦截的类都实现统一接口 优点 降低耦合度 简化对象，发送者不需要知道链的结构 增强接收者的灵活性，通过改变、排序职责链内成员，允许 动态的增删责任 增加新的请求处理类方便 缺点 不能保证请求一定被接收 系统性能将受到影响，调试代码时不方便，可能造成循环 调用 不容易观察运行时特征，有碍于除错 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// step1public abstract class AbstractLogger{ public static int INFO = 1; public static int DEBUG = 2; public static int ERROR = 3' protected int level; protected AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger){ this.nextLogger = nextLogger; } public void logMessage(int level, String Message){ if(this.level &lt;= level){ write(message); } if(nextLogger != null){ nextLogger.logMessage(level, message); } } abstract protected void write(String message);}// step2public class ConsoleLogger extends AbstractLogger{ public consoleLogger(int level){ this.level = level; } @Override protected void write(String message){ System.out.println(&quot;Standard Console::Logger: &quot; + message); }}public class ErrorLogger extends AbstractLogger{ public ErrorLogger(int level){ this.level = level; } @Override protected void write(String message){ System.out.println(&quot;Error Console::Logger: &quot; + message); }}public class FileLogger extends AbstractLogger{ public FileLogger(int level){ this.level = level; } @Override protected void write(String message){ System.out.println(&quot;File::Logger: &quot; + message); }}// step3public class ChainPatternDemo{ private static AbstractLogger getChainOfLogger(){ AbstractLogger errorLogger = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger fileLogger = new FileLogger(AbstractLogger.DEBUG): AbstractLogger console.Logger = new ConsoleLogger(AbstractLogger.INFO0; errorLogger.setNextLogger(fileLogger); fileLogger.setNextLogger(consoleLogger); return errorLogger; } public static void main(String[] args){ AbstractLogger loggerChain = getChainLoggers(); loggerChain.logMessage(AbstractLogger.INFO, &quot;this is an information&quot;); loggerChain.logMessage(AbstractLogger.DEBUG, &quot;this is a debug level infomation&quot;); loggerChain.logMessage(AbstractLogger.ERROR, &quot;this is an error infomation&quot;); }} 命令模式 Command Pattern请求以命令的形式包裹对象中，并传给调用对象，调用对象寻找可以 处理该命令的合适的对象，是一种数据驱动的设计模式 意图：将请求封装成一个对象，用不同的请求对客户进行参数化 解决问题：行为请求者、实现者通常是紧耦合关系， 使用场景：需要对行为进行记录、撤销、重做、事务等处理时， 紧耦合关系无法抵御变化 解决方法：通过调用者调用接收者执行命令 优点 降低系统耦合度 容易添加新命令至系统 缺点：使用命令模式可能会导致系统有过多具体命令类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// step1public interface Order{ void execute();}// step2public class Stock{ private String name = &quot;ABC&quot;; private int quantity = 10; public void buy(){ System.out.println(&quot;Stock [Name: &quot; + name + &quot;, Quantity: &quot; + quantity + &quot;] bought&quot;); } public void seel(){ System.out.println(&quot;Stock [Name: &quot; + name + &quot;, Quantity: &quot; + quantity + &quot;] sold&quot;); }}// step2public class BuyStock implements Order{ private Stock abcStock; public BuyStock(Stock abcStock){ this.abcStock = abcStock; } public void execute（）{ abcStock.but(); }}public class SellStock implements Order{ private Stock abcStock; public SellStock(Stock abcStock){ this.abcStock = abcStock; } pubic void execute(){ abcStock.sell(); }}// step3import java.util.ArrayList;import java.util.List;public class Broker{ private List&lt;Order&gt; orderList = new ArrayList&lt;Order&gt;(); public void takeOrder(Order order){ orderList.add(order); } public void placeOrders(){ for(Order order: orderList){ order.execute(); } orderList.clear(); }}// step4public class CommandPatternDemo{ public static void main(String[] args){ Stock abcStock = new Stock(); BuyStock buyStockOrder = new BuyStock(abcStock); SellStock sellStockOrder = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStockOrder); broker.takeOrder(sellStockOrder); broker.placeOrders(); }} 解释器模式 Interpreter Pattern实现一个表达式接口用于解释特定上下文，提供了评估语言的语法 或表达式的方式 意图：定义给定语言的文法表示、解释器 解决问题：为固定文法构建解释句子的解释器 使用场景：若特定类型问题发生频率足够高，可能值得将其各 实例表述为监督语言的句子，便可构建解释器解释这些句子来 解决问题 解决方法；构建语法树，定义终结符、非终结符 优点 扩展性好，灵活 增加了新的解释表达式的方式 容易实现简单文法 缺点 适用场景少 对于复杂文法维护难度大 解释器模式会引起类膨胀 解释器模式采用递归调用方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// step1public interface Expression{ public boolean interpret(String context);}// step2public class TerminalExpression implements Expression{ private String data; public TerminalExpression(String data){ this.data = data; } @Overide public boolean interpret(String context){ if(context.contain(data)){ return true; } return false; }}public class OrExpression implements Expression{ private Expression expr1 = null; private Expression expr2 = null; public OrExpression(Expression expr1, Expression expr2){ this.expr1 = expr1; this.expr2 = expr2; } @Override public boolean interpret(String context){ return expr1.interpret((context) || expr2.interpret(context); }}public class AndExpression implements Expression{ private Expression expr1 = null; private Expression expr2 = null; public AndExpression(Expression expr1, Expression expr2){ this.expr1 = expr1; this.expr2 = expr2; } @Override public boolean interpret(String context){ return expr1.interpret(context) &amp;&amp; expr2.interpret(context); }}// step3public class InterpreterPatternDemo{ public static Expression getMaleExpression(){ Expression robert = new TerminalExpression(&quot;Robert&quot;); Expression john = new TerminalExpression(&quot;John&quot;); return new OrExpression(robert, john); } public static Expression getMarriedWomanExpression(){ Expression julie = new TerminalExpression(&quot;Julie&quot;); Expression married = new TerminalExpression(&quot;Married&quot;); return new AndExpression(julie, married); } public static void main(String[] args){ Expression isMale = getMaleExpression(); Expression isMarriedWoman = getMarriedWomanExpression(); System.out.println(&quot;John is male?&quot; + isMale.interpret(&quot;John&quot;); System.out.println(&quot;Julie is a married women?&quot; + is MarriedWoman.interpret(&quot;Married Julie&quot;)); }} 迭代器模式 Iterator Pattern用于访问顺序访问剂盒对象的元素，不需要知道集合对象的底层表示 意图：提供方法用于顺序访问聚合对象中的各个元素，又无须 暴露该对象的内部表示 解决问题：不同方式遍历整个整合对象 使用场景：遍历聚合对象 解决方法：把在元素中游走的责任交给迭代器 优点 支持以不同的方式遍历对象 迭代器简化了聚合类 增加新的聚合类、迭代器类方便 缺点：会将存储数据和遍历数据的职责分离，增加新的聚合类 需要增加新的迭代器类，类数目成对增加，增加系统复杂性 123456789101112131415161718192021222324252627282930313233343536373839404142434445// step1public interface Iterator{ public boolean hasNext(); public Object next();}public interface Container{ public Iterator getIterator();}// step2public class NameRepository implements Container{ public String names[] = {&quot;Robert&quot;, &quot;John&quot;, &quot;Julie&quot;, &quot;Lora&quot;}; @Override public Iterator getIterator(){ return new NameIterator(); } private class NameIterator implements Iterator{ int index; @Override public boolean hasNext(){ if(index &lt; names.length){ return true; } return false; } @Override public Object Next(){ if(this.hasNext()){ return names[index++]; } return null; } }}// step3public class IteratorPatternDemo{ public static void main(String[] args){ NameReppository namesRepository = new NameRepository(); for(Iterator iter = namesRepository.getIterator(); iter.hasNext;){ String name = (String)iter.next(); System.out.println(&quot;Name: &quot; + name); } }} 中介者模式 Mediator Pattern提供一个中介类处理不同类之间的通信，降低多个对象、类之间的 通信复杂性，支持松耦合，使代码便于维护 意图：用一个中介对象封装一系列对象交互，中介使得个对象 不需要显式的相互引用，从而使其耦合松散，且可以独立地改变 它们之间地交互 解决问题：对象之间存在大量的关联关系，会导致系统结构很 复杂，且若一个对象发生改变，需要跟踪与之关联的对象并作出 相应处理 使用场景：多个类相互耦合形成网状结构 解决方法：将网状结构分离为星形结构 优点 降低类的复杂度，多对多转为一对一 各个类之间解耦 符合迪米特原则 缺点：中介者可能会很庞大、难以维护 1234567891011121314151617181920212223242526272829303132333435// step1import java.util.Date;public class ChatRoom{ public static void showMessage(User user, String message){ System.out.println(new Date().toString() + &quot;[&quot; + use.getName() + &quot;]&quot; + message); }}// step2public class User{ private String name; public String getName(){ return name; } public void setName(String name){ this.name = name; } public User(String name){ this.name = name; } public void sendMessage(String message){ ChatRoom.showMessage(this, message); }}// step3public class MediatorPatternDemo{ public static void main(String[] args){ User robert = new User(&quot;Robert&quot;); User john = new User(&quot;John&quot;); robert.sendMessage(&quot;Hi! John&quot;); john.SendMessage(&quot;Hello! Robert.&quot;); }} 备忘录模式 Memento Pattern保存对象地某个状态以便在适当的时候恢复对象 意图：在不破坏封装性地前提下，捕获对象的内部状态并保存 于对象外 解决问题：同意图 使用场景：需要记录对象的内部状态，允许用户取消不确定或 错误的操作 解决方法：通过备忘录类专门存储对象状态 优点 给用户提供了可以恢复状态的机制 实现信息的封装，用户无需关心状态保存细节 缺点：消耗资源，如果类成员变量过多会占用比较大的资源 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// step2public class Memento{ private String state; public Memento(String state){ this.state = state; } public String getState(){ return state; }}// step2public class Originator{ private String state; public void setState(String state){ this.state = state; } public String getState(){ reutrn state; } public Memento saveStateToMemento(){ return new Memento(state); } public vodi getStateFromMemento(Memento memento){ state = memento.getState(); }}// step3import java.util.ArrayList;import java.util.List;public class CareTaker{ private List&lt;Memento&gt; mementoList = new ArrayList&lt;Memento&gt;(); public void add(Memento state){ mementoList.add(state); } public Memento get(int index){ return mementoList.get(index); }}// step4public class MementoPatternDemo{ public static void main(String[] args){ Originator originator = new Originator(); CareTaker careTaker = new CareTaker(); originator.setState(&quot;State #1&quot;); originator.setState(&quot;State #2&quot;); careTaker.add(originator.saveStateToMemento()); originator.setState(&quot;State #3&quot;); careTaker.add(Originator.saveStateToMemento()); System.out.println(&quot;Current State: &quot; + originator.getState()); origiator.getStateFromMemento(careTaker.get(0)); System.out.println(&quot;First saved State: &quot; + originator.getState()); originator.getStateFromMemento(CareTaker.get(1)); System.out.println(&quot;Second saved State: &quot; + originator.getState()); }} 观察者模式 Observer Pattern 意图：定义对象间的一种一对多的依赖关系，档一个对象状态 发生改变时，所以依赖他的对象都得到通知并被自动更新 解决问题：一个对象状态改变给其他对象通知的问题，需要考虑 易用性和低耦合，同时保证高度协作 使用场景：同问题 解决方法：使用面向对象技术将依赖关系弱化 优点 观察者和被观察者是抽象耦合的 建立一套触发机制 缺点 如果被观察者有很多观察者，通过所有观察者耗费时间长 观察者和被观察之间如果有循环依赖，观察目标可能会触发 循环调用，导致系统崩溃 没有机制让观察者知道所观察的目标是如何发生变化成， 仅仅是知道观察目标发生了变化 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// step1import java.util.ArryaList;import java.util.List;public class Subject{ private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(); private int state; public int getState(){ return state; } public void setState(){ this.state = state; notifyAllObservers(); } public void attach(Observer observer){ observers.add(observer); } public void notifyAllObservers(){ for(Observer observer: observers){ observer.update(); } }}// step2public abstract class Observer{ protected Subject subject; public abstract void update();}// step3public class BinaryObserver extends Observer{ public BinaryObserver(Subject subject){ this.subject = subject; this.subject.attach(this); } @Override public void update(){ System.out.println(&quot;Binary String: &quot; + Interger.toBinaryString(subject.getState())); }}public class OctalObserver extends Observer{ public OctalObserver(Subject subject){ this.subject = subject; this.subject.attach(this); } @Override public void update(){ System.out.println(&quot;Octal String: &quot; + Integer.toOctalString(subject.getState())); }}public class HexaObserver extends Observer{ public HexaObserver(Subject subject){ this.subject = subject; this.subject.attach(this); } @Override public void update(){ System.out.println(&quot;Hex String: &quot; + Integer.toHexString(subject.getState()).toUpperCase()); }}// step4public class ObserverPatternDemo{ public static void main(String[] args){ Subject subject = new Subject(); new HexaObserver(subject); new OctalObserver(subject); new BinaryObserver(subject); System.out.println(&quot;First state change: 15&quot;); subject.setState(15); System.out.println(&quot;Second state change: 10&quot;); subject.setState(16); }} 状态模式 State Pattern创建表示各种状态的对象和一个行为随着状态改变而改变的context 对象 意图：允许在对象的内部状态改变时改变它的行为，看起来好像 修改了其所属的类 解决问题：对象的行为依赖其状态（属性），并且可以根据其 状态改变而改变其相关行为 使用场景：代码中包含大量与对象状态相关的条件语句 解决方法：将各种具体状态类抽象出来 优点 封装了转换规则 枚举了可能状态，在枚举之前需要确定状态种类 将所有与某个状态有关的行为放在一个类中，只需要改变 对象状态就可以改变对象行为，可以方便地增加新状态 允许状态转换逻辑与状态对象合成一体 可以让多个环境对象共享一个状态对象，减少系统中对象 数量 缺点 增加系统类和对象地个数 结构与实现都较为复杂，使用不当将导致结构和代码的混乱 对“开闭原则”支持不太好，增加新的状态类需要修改复杂 状态转换的源代码，修改某状态类的行为也需要修改对应类 的源代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// step1public interface State{ public void doAction(Context context);}// step2public class StartState implements State{ public void doAction(Context context){ System.out.println(&quot;Player is in start state&quot;); context.setState(); } public String toString(){ return &quot;Start State&quot;; }}public class StopState implements State{ public void doAction(Context context){ System.out.println(&quot;Player is in the stop state&quot;); context.setState(this); } public String toString(){ return &quot;Stop State&quot;); }}// step3public class Context{ private State state; public Context(){ state = null; } public void setState(State state){ this.state = state; } public State getState(){ return state; }}// step4public class StatePatternDemo{ public static void main(String[] args){ Context context = new Context(); StartState startState = new StartState(); startState.doAction(context); System.out.println(context.getState().toString()); StopState stopState = new StopState(); stopState.doAction(context); System.out.println(context.getState().toString()); }} 空对象模式 Null Object Pattern创建一个指定各种要执行的操作的抽象类和扩展该类的实体类、一个 未做人实现的空对象类，空对象类将用于需要检查空值的地方取代 NULL对象实例的检查，也可以在数据不可用时提供默认的行为 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// step1public abstract class AbstractCustomer{ protected String name; public abstract boolean isNil(); public abstract String getName();}// step2public class RealCustomer extends AbstractCustomer{ public RealCustomer(String name){ this.name = name; } @Override public String getName(){ return name; } @Override public boolean isNil(){ return false; }}public class NullCustomer extends AbstractCustomer{ @Override public String getName(){ return &quot;Not Available in Customer Database&quot;; } @Override public boolean isNil(){ return true; }}// step3public class CustomerFactory(){ public static final String[] names = {&quot;Rob&quot;, &quot;Joe&quot;, &quot;Julie&quot;}; public static AbstractCustomer getCustomer(String name){ for(int i = 0; i &lt; names.length; i++){ if(names[i].equalsIgnoreCase(name)){ return new RealCustomer(name); } } return NullCustomer(); }}// step4public class NullPatternDemo{ public static void main(String[] args){ AbstractCustomer customer1 = CustomerFactory.getCustomer(&quot;Rob&quot;); AbstractCustomer customer2 = CustomerFactory.getCustomer(&quot;Bob&quot;); AbstractCustomer customer3 = CustomerFactory.getCustomer(&quot;Julie&quot;); AbstractCustomer customer4 = CustomerFactory.getCustomer(&quot;Laura&quot;); System.out.println(&quot;Customers&quot;); System.out.println(customer1.getName()); System.out.println(customer2.getName()); System.out.println(customer3.getName()); System.out.println(customer4.getName()); }} 策略模式 Strategy Pattern创建表示各种策略的对象和一个随着策略对象改变的context对象， 类的行为、算法可以在运行时更改 意图：定义一系列算法并封装，使其可以相互替换 解决问题：有多种相似算法的情况下，使用if...else难以 维护 使用场景：系统中有许多类，只能通过其直接行为区分 解决方法：将算法封装成多个类，任意替换 优点 算法可以自由切换 避免使用多重条件判断 扩展性良好 缺点 策略类增多 所有策略类都需要对外暴露 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// step1public interface Strategy{ public int doOperation(int num1, int num2);}// step2public class OperationAdd implements Strategy{ @Override public int doOperation(int num1, int num2){ return num1 + num2; }}public class OperationSubstract implements Strategy{ @Override public int doOperation(int num1, int num2){ return num1 - num2; }}public class OperationMultiply impliments Strategy{ @Override public int doOperation(int num1, int num2){ return num1 * num2; }}// step3public class Context{ private Strategy strategy; public Context(Strategy strategy){ this.strategy = strategy; } public int executeStrategy(int num1, int num2){ return strategy.doOperation(num1, num2); }}// step4public class StrategyPatternDemo{ public static void main(String[] args){ Context context = new Context(new OperationAdd()); System.out.println(&quot;10 + 5 = &quot; + context.executeStrategy(10, 5)); context = new Context(new OperationSubstract()); System.out.println(&quot;10 - 5 = &quot; + context.executeStrategy(10, 5)); context = new Context(new OperationMultiply()); System.out.println(&quot;10 * 5 = &quot; + context.executeStrategy(10, 5)); }} 模板模式 Template Pattern一个抽象类公开定义执行它的方式（模板），其子类可以按需要重写 的方法实现，但将以抽象类中定义的方式调用 意图：定义一个操作中算法的骨架，将一些步骤延迟到子类中， 使得子类可以不改变算法的接口即可重定义算法的某些步骤 解决问题：一些方法通用，却在每个子类中重写该方法 使用场景：有通用的方法 解决方法：将通用算法抽象出来 优点 封装不变部分，扩展可变部分 提取公共代码，便于维护 行为由父类控制，子类实现 缺点：每个不同的实现都需要子类实现，类的个数增加 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// step1public abstract class Game{ abstract void initializa(); abstract void startPlay(); abstract void endPlay(); public final void play(){ initialize(); startPlay(); endPlay(); }}// step2public class Cricket extends Game{ @Override void endPlay(){ Syste.out.println(&quot;Cricket Game Finished&quot;); } @Override void initialize(){ System.out.println(&quot;Cricket Game Initialized! Start playing.&quot;); } @Override void startPlay(){ System.out.println(&quot;Cricket Game Stared. Enjoy the game!&quot;); }}public class Football extends Game{ @Override void endPlay(){ Syste.out.println(&quot;Football Game Finished&quot;); } @Override void initialize(){ System.out.println(&quot;Football Game Initialized! Start playing.&quot;); } @Override void startPlay(){ System.out.println(&quot;Football Game Stared. Enjoy the game!&quot;); }}// step3public class TemplatePatternDemo{ public static void main(String[] args){ Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); }} 访问者模式 Visitor Pattern使用一个访问者类，其改变元素类的执行算法 意图：将数据结构与数据操作分离 解决问题：稳定的数据结构和易变的操作耦合问题 使用场景：需要对数据结构进行很多不同且不相关的操作，且要 避免让这些操作“污染”数据结构类 解决方法：在数据结构类中增加对外提供接待访问者的接口 优点 符合单一职责原则 优秀的扩展性、灵活性 缺点 具体元素对访问者公布细节，违反迪米特原则 具体元素变更困难 违反依赖倒置原则，依赖具体类而不是抽象类 依赖递归，如果数据结构嵌套层次太深可能有问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// step1public interface ComputerPart{ public void accept(ComputerPartVisitor computerPartVsistor);}// step2public class Keyboard implements ComputerPart{ @Override public void accept(ComputerPartVisitor computerPartVisiter){ computerPartVisitor.visit(this); }}public class Monitor implements ComputerPart{ @Override public void accept(ComputerPartVisitor computerPartVisitor){ computerPartVisitor.visit(this); }}public class Mouse implements ComputerPart{ @Override public void accept(ComputerPartVisitor computerPartVisitor){ computerPartVisitor.visit(this); }}public class Computer implements ComputerPart{ ComputerPart[] parts; public Computer(){ parts = new ComputerPart[]{new Mouse(), new Keyboard(), new Monitor()}; } @Override public void accept(ComputerPartVisitor computerPartVisitor){ for(ComputerPart part: parts){ part.accept(computerPartVisitor); } computerPartVisitor.visit(this); }}// step3public interface ComputerPartVisitor(){ public void visit(Computer computer); public void visit(Mouse mouse); public void visit(Keyboard keyboard); public void visit(Monitor monitor);}// step4public class ComputerDisplayVisitor implements ComputerPartVisitor{ @Override public void visit(Computer computer){ System.out.println(&quot;Display Computer&quot;); } @Override public void visit(Mouse mouse) { System.out.println(&quot;Displaying Mouse.&quot;); } @Override public void visit(Keyboard keyboard) { System.out.println(&quot;Displaying Keyboard.&quot;); } @Override public void visit(Monitor monitor) { System.out.println(&quot;Displaying Monitor.&quot;); }}// step5public class VisitorPatternDemo{ public static void main(String[] args){ Computer computer = new Computer(); computer.accept(new ComputerPartDisplayVisitor()); }} J2EE模式特别关注表示层，由Sun Java Center鉴定 MVC模式 MVC PatternModel-View-Controller模式，用于应用程序的分层开发 Model（模型）：存取数据的对象，可以带有逻辑，在数据变化 时更新控制器 View（视图）：模型包含的数据可视化 Controller（控制器）：作用与模型、视图上，控制数据流向 模型对象，并在数据变化时更新视图，使视图与模型分离 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// step1public class Student{ private String rollNo; private String name; public String getRollNo(){ return rollNo; } public void setRollNo(String rollNo){ this.rollNo = rollNo; } public String getName(){ return name; } public void setName(String name){ this.name = name; }}// step2public class StudentView{ public void printStudentDetails(String studentName, String studentRollNo){ System.out.println(&quot;Student: &quot;); System.out.println(&quot;Name: &quot; + studentName); System.out.println(&quot;Roll No: &quot; + studentRollNo); }}// step3public class StudentController{ private Student model; private StudentView view; public StudentController(Student model, StudentView view){ this.model = model; this.view = view; } public void setStudentName(String name){ model.setName(name); } public String getStudentName(){ return model.getName(); } public void setStudentRollNo(String rollNo){ model.setRollNo(rollNo); } public String getStudentRollNo(){ return model.getRollNo(); } public void updateView(){ view.printStudentDetails(model.getName(), model.getRollNo()); }}// step4public class MVCPatternDemo{ public static void main(String[] args){ Student model = retriveStudentFromDatabase(); StudentView view = new StudentView(); StudentController controller = new StudentController(model, view); controller.updateView(); controller.setStudentName(&quot;John&quot;); controller.updateView(); } private static Student retriveStudentFromDataBase(){ Student student = new Student(); student.setName(&quot;Robert&quot;); student.setRollNo(&quot;10&quot;); return student; }} 业务代表模式 Business Delegate Pattern用于对表示层和业务层解耦，基本上是用来减少通信或对表示层代码 中的业务层代码的远程查询功能，业务层包括以下实体 Client（客户端） Business Delegate（业务代表）：为客户端提实体提供的入口 类，提供了对业务服务方法的访问 LookUp Service（查询服务）：获取相关的业务实现，提供业务 对象对业务代表对象的访问 Business Service（业务服务）：业务服务接口，实现其的具体 类提供了实际的业务实现逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// step1public interface BusinessService{ public void doProcessing();}// step2public class EJBService implements BusinessService{ @Override public void doProcessing(){ System.out.println(&quot;Processing task by invoking EJB Service&quot;); }}public class JMSService implements BusinessService{ @Override public void doProcessing(){ System.out.println(&quot;Processing task by invoking JMS Service&quot;); }}// step3public class BusinessLookUp{ public BusinessService getBusinessService(String serviceType){ if(serviceType.equalsIgnoreCase(&quot;EJB&quot;){ return new EJBService(); }else{ returen new JMSService(); } }}// step4public class BusinessDelegate{ private BusinessLookUp lookupService = new BusinessLookUp(); private BusinessService businessService; private String serviceType; public void setServiceType(String serviceType){ this.serviceType = serviceType; } public void doTask(){ businessService = lookupService.getBusinessService(serviceTpye); businessService.doProcessing(); }}// step5public class Client{ BusinessDelegate businessService; public Client(BusinessDelegate businessService){ this.businessServie = businessService; } public void doTask(){ businessService.doTask(); }}// step6public class BusinessDelegatePatternDemo{ public static void main(String[] args){ BusinessDelegate businessDelegate = new BusinessDelegate(); businessDelegate.setServiceType(&quot;EJB&quot;); Client client = new Client(businessDelegate); cliend.doTask(); businessDelegate.setServiceType(&quot;JMS&quot;); client.doTask(); }} 组合实体模式 Composite Entity Pattern一个组合实体是一个EJB实体bean，代表对象的图解，更新一个组合 实体时，内部依赖对象beans会自动更新，因为其是由EJB实体bean 管理的，组合实体bean参与者包括 Composite Entity（组合实体）：主要的实体bean，可以是 粗粒的，或者包含一个粗粒度对象，用于持续生命周期 Coarse-Grained Object（粗粒度对象）：包含依赖对象，有 自己的生命周期，也能管理依赖对象的生命周期 Dependent Object（依赖对象）：持续生命周期依赖于粗粒度 对象的对象 Strategies（策略）：如何实现组合实体 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// step1public class DependentObject1{ private String data; public void setData(String data){ this.data = data; } public String getData(){ return data; }}public class DependentObject2{ private String data; public void setData(String data){ this.data = data; } public String getData(){ return data; }}// step2public class CoarseGrainedObject{ DependentObject1 do1 = new DependentObject1(); DependentObject2 do2 = new DependentObject2(); public void setData(String data1, String data2){ do1.setData(data1); do2.setData(data2); } public String[] getData(){ return new String[] {do1.getData(), do2.getData()}; }}// step3public class CompositeEntity{ private CoarseGrainedObject cgo = new CaorseGraiendObject(); public void setData(String data1, String data2){ cgo.setData(data1, data2); } public String[] getData(){ return cgo.getData(); }}// step4public class Client{ private CompositeEntity compositeEntity = new CompositeEntity(); public void printData(){ for(String str: compositeEntity.getData()){ System.out.println(&quot;Data: &quot; + str); } } public void setData(String data1, data2){ compositeEntity.setData(data1, data2); }}// step5public class CompositeEntityPatternDemo{ public static void main(String[] args){ Client client = new Client(); client.setData(&quot;test&quot;, &quot;data&quot;); client.printData(); client.setData(second test&quot;, &quot;data2&quot;); client.printData(); }} 数据访问对象模式 Data Access Object Pattern用于把低级的数据访问API、操作从高级的业务服务中分离出来 Data Access Object Interface（数据访问对象接口）：定义 在模型对象上要执行的标准操作 Data Access Object concrete class（数据访问对象实体类） ：实现上述接口，负责从数据源（数据库、xml等）获取数据 Model/Value Object（模型/数值对象）：简单的POJO，包含 get/set方法存储使用DAO类检索到的数据 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394// step1public class Student{ private String name; private int rollNo; Student(String name, int rollNo){ this.name = name; this.rollNo = rollNo; } public String getName(){ return name; } public void setName(String name){ this.name = name; } public int getRollNo(){ return rollNo; } public void setRollNo(int rollNo){ this.rollNo = rollNo; }}// step2import java.util.List;public interface StudentDao{ public List&lt;Student&gt; getAllStudents(); public Student getStudent(int rollNo); public void updateStudent(Student student); public void deleteStudent(Student student);}// step3import java.util.ArrayList;import java.util.List;public class StudentDaoImpl implements StudentDao{ List&lt;Student&gt; students; public StudentDaoImpl(){ students = new ArrayList&lt;Student&gt;(); Student student1 = new Student(&quot;Roberts&quot;, 0); Student student2 = new Student(&quot;John&quot;, 1); students.add(student1); students.add(student2); } @Override public void deleteStudent(Student student){ students.remove(student.getRollNo()); System.out.println(&quot;Student: Roll No &quot; + student.getRollNo() + &quot;, deleted from database&quot; ); } @Override public List&lt;Student&gt; getAllStudents(){ return students; } @Override public Student getStudent(int rollNo){ return students.get(rollNo); } @Override public void updateStudent(Student student){ students.get(student.getRollNo()).setName(student.getName()); System.out.println(&quot;Student: Roll No &quot; + student.getRollNo() + &quot;, updated in the database&quot; ); }}// step4public class DaoPatternDemo{ public static void main(String[] args){ StudentDao studentDao = new StudentDaoImpl(); for(Student student: studentDao:getAllStudents()){ System.out.println(&quot;Student: [RollNo: &quot; + student.getRollNo() + &quot;, Name: &quot; + student.getName() + &quot; ]&quot; ); } Student student = studentDao.getAllStudents().get(0); student.setName(&quot;Micheal&quot;); studentDao.updateStudent(student); studentDao.getStudent(0); System.out.println(&quot;Student: [RollNo: &quot; + student.getRollNo() + &quot;, Name: &quot; + student.getName() + &quot;]&quot; ); }} 前端控制器模式 Front Controller Pattern用于提供一个集中请求处理机制，所有的请求都将由单一的处理程序 处理，该处理程序可以做认证、授权、记录日志、跟踪请求，然后把 请求传给相应的处理程序，包含以下部分 Front Controller（前端控制器）：处理应用程序所有类型请求 的单个处理程序 Dispatcher（调度器）：前端控制器调用，用于调度请求到相应 的具体处理程序 View（视图）：为请求而创建的对象 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// step1public class Homeview(){ public void show(){ System.out.println(&quot;Displaying Home Page&quot;); }}public class StudentView{ public void show(){ System.out.println(&quot;Displaying Student Page&quot;); }}// step2public class Dispatcher{ private StudentView studentView; private HomeView homeView; public Dispatcher(){ studentView = new StudentView(); homeView = new HomeView(); } public void dispatch(String request){ if(request.equalsIgnoreCase(&quot;StudENT&quot;)){ studentView.show(); }else{ homeView.show(); } }}// step3public class FrontController{ private Dispatcher dispatcher; public FrontController(){ dispatcher = new Dispatcher(); } private boolean isAuthenticUser(){ System.out.println(&quot;User is authenticated successfully.&quot;); return true; } private void trackRequest(String request){ System.out.println(&quot;Page requested: &quot; + request); } public void dispatchRequest(String request){ trackReqeust(reqeust); if(isAuthenticUser()){ dispatcher.dispatch(request); } }}// step4public class FrontControllerPatternDemo{ public static void main(String[] args){ FrontController frontController = new FrontController(); frontController.dispatchRequest(&quot;HOMe&quot;); frontController.dispatchRequest(&quot;STUDENT&quot;); }} 拦截过滤器模式 Intercepting Filter Pattern用于应用程序的请求或相应做一些预处理、后处理，定义过滤器， 并将其应用在请求上后再传递给实际目标应用程序，过滤器可以做 认证、授权、记录日志、跟踪请求 Filter（过滤器）：在处理程序执行请求之前或之后执行某些 任务 Filter Chain（过滤器链）：带有多个过滤器，并按定义的顺序 执行这些过滤器 Target：请求处理程序 Filter Manager（过滤管理器）：管理过滤器和过滤器链 Client（客户端）：向Target对象发送请求的对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081// step1public interface Filter{ public void execute(String request);}// step2public class AuthenticationFilter implements Filter{ public void execute(String request){ System.out.println(&quot;Authenticating request: &quot; + request); }}public class DebugFilter implements Filter{ public void execute(String request){ System.out.println(&quot;request log: &quot; + request); }}// step3public class Target{ public void execute(String request）{ System.out.println(&quot;Executing request: &quot; + request); }}// step4import java.util.ArrayList;import java.util.List;public class FilterChain{ private List&lt;Filter&gt; filters = new ArrayList&lt;Filter&gt;(); private Target target; public void addFilter(Filter filter){ filters.add(filter); } public void execute(String request){ for(Filter filter: filters){ filter.execute(reqeust); } target.execute(request); } public vodi setTarget(Target target){ this.target = target; }}// step5public class FilterManager{ FilterChain filterChain; public FilterManager(Target target){ filterChain = new FilterChain(); filterChain.setTarget(target); } public void setFilter(Filter filter){ filterChain.addFilter(filter); } public void filterRequest(String request){ filterChain.execute(request); }}// step6public class Client{ FilterManager filterManager; public void setFilterManager(FilterManager filterManager){ this.filterManager = filterManager; } public void sendRequests(String request){ filterManager.filterRequest(request); }}// step7public class InterceptingFilterDemo{ public static void main(String[] args){ FilterManager filterManager = new FilterManager(new Target()); filterManager.setFilter(new AuthenticationFilter()); filterManager.setFilter(new DebugFilter()); Client client = new Client(); client.setFilterManager(filterManager); client.sendRequest(&quot;HOME&quot;); }} 服务定位器模式 Service Locator Pattern用于使用JNDI查询定位各种服务时，充分利用缓存技术减小为服务 查询JNDI的代价，首次请求服务时，服务定位器在JNDI中查找服务， 并缓存供之后查询相同服务的请求使用 Service（服务）：实际处理请求的服务，其引用可以在JNDI 服务器中查到 Context：JNDI带有要查找的服务的引用 Service Locator（服务定位器）：通过JNDI查找和缓存服务来 获取服务的单点接触 Cache（缓存）：缓存服务引用以便复用 Client（客户端）：通过ServiceLocator调用服务对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103// step1public interface Serivce{ public String getName(); public void execute();}// step2public class Service1 implements Service{ public void execute(){ System.out.println(&quot;Executing Service1&quot;); } @Override public String getName(){ return &quot;Service1&quot;; }}public class Service2 implements Service{ public void execute(){ System.out.println(&quot;Executing Service2&quot;): } @Override public String getName(){ return &quot;Service2&quot;; }}// step3public class InitialContext{ public Object lookup(String jndiName){ if(jndiName.equalsIgnoreCase(&quot;SERVICE1&quot;){ System.out.println(&quot;Looking up and creating a new Service1 object&quot;); return new Service1(); }else if(jndiName.equalsIgnoreCase(&quot;service2&quot;){ System.out.println(&quot;Looking up and creating a new Service2 object.&quot;); return new Service2(); } return null; }}// step4import java.util.ArrayList;import java.uitl.List;public class Cache{ private List&lt;Service&gt; services; public Cache(){ services = new ArrayList&lt;Service&gt;(); } public Service getService(String serviceName){ for(Service service: services){ if(service.getName().equalsIgnoreCase(serviceName)){ System.out.println(&quot;Returning cached &quot; + serviceName + &quot; object&quot; ); } } return null; } public void addService(Service newService){ boolean exists = false; for(Service service: services){ if(service.getName().equalsIgnoreCase(newService.getName())){ exists = true; } } if(!exist){ services.add(newService); } }}// step5public class ServiceLocator{ private static Cache cache; static{ cache = new Cache(); } public static Service getService(String jndiName){ Service service = cache.getService(jndiName); if(service != null){ return service; } InitialContext context = new InitialContext(); Service service1 = (Service)context.lookup(jndiName); cache.addService(service1); return service1; }}// step6public class ServiceLocatorPatternDemo{ public static void main(String[] args){ Service service = ServiceLocator.getService(&quot;Service1&quot;); service.execute(); service = ServiceLocator.getService(&quot;Service2&quot;); service.execute(); service = ServiceLocator.getService(&quot;Service1&quot;); service.execute(); service = ServiceLocator.getService(&quot;Service1&quot;); service.execute(); }} 传输对象模式 Tranfer Object Pattern用于从客户端向服务器一次性传递带有多个属性的数据。传输对象 （数值对象）是具有getter/setter方法的简单POJO类，可 序列化，因此可以通过网络传输，没有任何行为。服务器端业务类 通常从数据库读取数据填充POJO，并发送到客户端或按值传递； 客户端可以自行创建传输对象并传送给服务器，以便一次性更新 数据库中的数值 Business Object（业务对象）：为传输对象填充数据的业务 服务 Transfer Object（传输对象）：简单的POJO，只有设置/获取 属性的方法 Client（客户端）：可以发送请求或发送传输对象到业务对象 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// step1public class StudentVO{ private String name; private int rollNo; StudentVo(String name, int rollNo){ this.name = name; this.rollNo = rollNo; } public String getName(){ return name; } public void setName(String name){ thi.name = name; } public int getRollNo(){ return rollNo; } public void setRollNo(int rollNo){ this.rollNo = rollNo; }}// step2import java.util.ArrayList;import java.util.List;public class StudentBO{ List&lt;StudentVO&gt; students; public StudentBO(){ students = new ArrayList&lt;StudentVO&gt;(); studentVO student1 = new StudentVO(&quot;Robert&quot;, 0); studentVO student2 = new StudentVO(&quot;John&quot;, 1); student1.add(student1); student2.add(student2); } public void deleteStudent(StudentVO student){ students.remove(student.getRollNo()); System.out.println(&quot;Student: Roll No &quot; + student.getRollNo() + &quot;, deleted from database.&quot; ); } public List&lt;StudentVO&gt; getAllStudents(){ return students; } public StudentVO getStudent(int rollNo){ return students.get(rollNo); } public void updateStudent(StudentVO student){ students.get(studentNo()).setName(student.getName()); System.out.println(&quot;Student: Roll No &quot; + student.getRollNo() + &quot;, updated in the database.&quot; ); }}// public class TransferObjectPatternDemo{ public static void main(String[] args){ StudentBO studentBusinessObject = new StudentBO(); for(StudentVO student: studentBusinessObject.getAllStudent()){ System.out.println(&quot;Student: [Roll No: &quot; + student.getRollNo() + &quot;, Name: &quot; + student.getName() + &quot;]&quot; ); } studentVO student = studentBusinessObject.getAllStudents().get(0); student.setName(&quot;Micheal&quot;); studentBusinessObject.updateStudent(student); student = studentBusinessObject.getStudent(0); System.out.println(&quot;Student: [Roll No: &quot; + student.getRollNo() + &quot;, Name: &quot; + student.getName() + &quot;]&quot; ); }}","link":"/CS/Program-Design/design_pattern.html"}],"tags":[{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"Parser","slug":"Parser","link":"/tags/Parser/"},{"name":"Optimization","slug":"Optimization","link":"/tags/Optimization/"},{"name":"CBO","slug":"CBO","link":"/tags/CBO/"},{"name":"RBO","slug":"RBO","link":"/tags/RBO/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Data Structure","slug":"Data-Structure","link":"/tags/Data-Structure/"},{"name":"Twists","slug":"Twists","link":"/tags/Twists/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Configuration","slug":"Configuration","link":"/tags/Configuration/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Tool","slug":"Tool","link":"/tags/Tool/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Version Control","slug":"Version-Control","link":"/tags/Version-Control/"},{"name":"Grub","slug":"Grub","link":"/tags/Grub/"},{"name":"Boot Loader","slug":"Boot-Loader","link":"/tags/Boot-Loader/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"CMD","slug":"CMD","link":"/tags/CMD/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"LaTex","slug":"LaTex","link":"/tags/LaTex/"},{"name":"PDF","slug":"PDF","link":"/tags/PDF/"},{"name":"Pandoc","slug":"Pandoc","link":"/tags/Pandoc/"},{"name":"Compiler","slug":"Compiler","link":"/tags/Compiler/"},{"name":"GCC","slug":"GCC","link":"/tags/GCC/"},{"name":"G++","slug":"G","link":"/tags/G/"},{"name":"Web Server","slug":"Web-Server","link":"/tags/Web-Server/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"Remote","slug":"Remote","link":"/tags/Remote/"},{"name":"Rsync","slug":"Rsync","link":"/tags/Rsync/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"ToDo","slug":"ToDo","link":"/tags/ToDo/"},{"name":"Schedule","slug":"Schedule","link":"/tags/Schedule/"},{"name":"Terminal","slug":"Terminal","link":"/tags/Terminal/"},{"name":"Tmux","slug":"Tmux","link":"/tags/Tmux/"},{"name":"Math","slug":"Math","link":"/tags/Math/"},{"name":"Probability","slug":"Probability","link":"/tags/Probability/"},{"name":"Distribution","slug":"Distribution","link":"/tags/Distribution/"},{"name":"Statistic","slug":"Statistic","link":"/tags/Statistic/"},{"name":"Likelihood","slug":"Likelihood","link":"/tags/Likelihood/"},{"name":"Set","slug":"Set","link":"/tags/Set/"},{"name":"Order","slug":"Order","link":"/tags/Order/"},{"name":"Base","slug":"Base","link":"/tags/Base/"},{"name":"Algbra","slug":"Algbra","link":"/tags/Algbra/"},{"name":"Analysis","slug":"Analysis","link":"/tags/Analysis/"},{"name":"Uncharted","slug":"Uncharted","link":"/tags/Uncharted/"},{"name":"Equality","slug":"Equality","link":"/tags/Equality/"},{"name":"Inequality","slug":"Inequality","link":"/tags/Inequality/"},{"name":"Algbrea","slug":"Algbrea","link":"/tags/Algbrea/"},{"name":"RBF","slug":"RBF","link":"/tags/RBF/"},{"name":"README","slug":"README","link":"/tags/README/"},{"name":"Function","slug":"Function","link":"/tags/Function/"},{"name":"Kernel","slug":"Kernel","link":"/tags/Kernel/"},{"name":"Daily Life","slug":"Daily-Life","link":"/tags/Daily-Life/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Supervised Learning","slug":"Supervised-Learning","link":"/tags/Supervised-Learning/"},{"name":"Unsupervised Learning","slug":"Unsupervised-Learning","link":"/tags/Unsupervised-Learning/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","link":"/tags/Semi-Supervised-Learning/"},{"name":"Reinforcement Learning","slug":"Reinforcement-Learning","link":"/tags/Reinforcement-Learning/"},{"name":"CS","slug":"CS","link":"/tags/CS/"},{"name":"Storage","slug":"Storage","link":"/tags/Storage/"},{"name":"Program Design","slug":"Program-Design","link":"/tags/Program-Design/"},{"name":"AST","slug":"AST","link":"/tags/AST/"},{"name":"Callback","slug":"Callback","link":"/tags/Callback/"},{"name":"Variable","slug":"Variable","link":"/tags/Variable/"},{"name":"Polymorphism","slug":"Polymorphism","link":"/tags/Polymorphism/"},{"name":"Inherit","slug":"Inherit","link":"/tags/Inherit/"},{"name":"Mixin","slug":"Mixin","link":"/tags/Mixin/"},{"name":"Network","slug":"Network","link":"/tags/Network/"},{"name":"OSI","slug":"OSI","link":"/tags/OSI/"},{"name":"Character","slug":"Character","link":"/tags/Character/"},{"name":"Escape Sequence","slug":"Escape-Sequence","link":"/tags/Escape-Sequence/"},{"name":"ANSI","slug":"ANSI","link":"/tags/ANSI/"},{"name":"Encode","slug":"Encode","link":"/tags/Encode/"},{"name":"Unicode","slug":"Unicode","link":"/tags/Unicode/"},{"name":"Font","slug":"Font","link":"/tags/Font/"},{"name":"Parallel","slug":"Parallel","link":"/tags/Parallel/"},{"name":"Lock","slug":"Lock","link":"/tags/Lock/"},{"name":"C&#x2F;C++","slug":"C-C","link":"/tags/C-C/"},{"name":"Lib","slug":"Lib","link":"/tags/Lib/"},{"name":"Cppref","slug":"Cppref","link":"/tags/Cppref/"},{"name":"Exception","slug":"Exception","link":"/tags/Exception/"},{"name":"Expression","slug":"Expression","link":"/tags/Expression/"},{"name":"STL","slug":"STL","link":"/tags/STL/"},{"name":"Lambda","slug":"Lambda","link":"/tags/Lambda/"},{"name":"Cstd","slug":"Cstd","link":"/tags/Cstd/"},{"name":"Memory","slug":"Memory","link":"/tags/Memory/"},{"name":"I&#x2F;O","slug":"I-O","link":"/tags/I-O/"},{"name":"Datetime","slug":"Datetime","link":"/tags/Datetime/"},{"name":"Locale","slug":"Locale","link":"/tags/Locale/"},{"name":"String","slug":"String","link":"/tags/String/"},{"name":"MPI","slug":"MPI","link":"/tags/MPI/"},{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"MapReduce","slug":"MapReduce","link":"/tags/MapReduce/"},{"name":"DAG","slug":"DAG","link":"/tags/DAG/"},{"name":"RDD","slug":"RDD","link":"/tags/RDD/"},{"name":"HBase","slug":"HBase","link":"/tags/HBase/"},{"name":"HFile","slug":"HFile","link":"/tags/HFile/"},{"name":"Flume","slug":"Flume","link":"/tags/Flume/"},{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"Storm","slug":"Storm","link":"/tags/Storm/"},{"name":"YARN","slug":"YARN","link":"/tags/YARN/"},{"name":"Hive","slug":"Hive","link":"/tags/Hive/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"},{"name":"Tez","slug":"Tez","link":"/tags/Tez/"},{"name":"Spark","slug":"Spark","link":"/tags/Spark/"},{"name":"Graph","slug":"Graph","link":"/tags/Graph/"},{"name":"Broadcast","slug":"Broadcast","link":"/tags/Broadcast/"},{"name":"Join","slug":"Join","link":"/tags/Join/"},{"name":"Classification","slug":"Classification","link":"/tags/Classification/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"Collaborative Filtering","slug":"Collaborative-Filtering","link":"/tags/Collaborative-Filtering/"},{"name":"DataFrame","slug":"DataFrame","link":"/tags/DataFrame/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"Streaming","slug":"Streaming","link":"/tags/Streaming/"},{"name":"Optimizer","slug":"Optimizer","link":"/tags/Optimizer/"},{"name":"Catalyst","slug":"Catalyst","link":"/tags/Catalyst/"},{"name":"SQL DB","slug":"SQL-DB","link":"/tags/SQL-DB/"},{"name":"Data Migration","slug":"Data-Migration","link":"/tags/Data-Migration/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"MariaDB","slug":"MariaDB","link":"/tags/MariaDB/"},{"name":"Postgre SQL","slug":"Postgre-SQL","link":"/tags/Postgre-SQL/"},{"name":"Roles","slug":"Roles","link":"/tags/Roles/"},{"name":"Grammer","slug":"Grammer","link":"/tags/Grammer/"},{"name":"CUAD","slug":"CUAD","link":"/tags/CUAD/"},{"name":"Heuristic","slug":"Heuristic","link":"/tags/Heuristic/"},{"name":"Searching","slug":"Searching","link":"/tags/Searching/"},{"name":"Envolution","slug":"Envolution","link":"/tags/Envolution/"},{"name":"Simulation","slug":"Simulation","link":"/tags/Simulation/"},{"name":"Directed Graph","slug":"Directed-Graph","link":"/tags/Directed-Graph/"},{"name":"Hashing","slug":"Hashing","link":"/tags/Hashing/"},{"name":"Undirected Graph","slug":"Undirected-Graph","link":"/tags/Undirected-Graph/"},{"name":"Linear","slug":"Linear","link":"/tags/Linear/"},{"name":"Array","slug":"Array","link":"/tags/Array/"},{"name":"List","slug":"List","link":"/tags/List/"},{"name":"Stack","slug":"Stack","link":"/tags/Stack/"},{"name":"Queue","slug":"Queue","link":"/tags/Queue/"},{"name":"Tree","slug":"Tree","link":"/tags/Tree/"},{"name":"Huffman","slug":"Huffman","link":"/tags/Huffman/"},{"name":"Heap","slug":"Heap","link":"/tags/Heap/"},{"name":"Index","slug":"Index","link":"/tags/Index/"},{"name":"High Dimension","slug":"High-Dimension","link":"/tags/High-Dimension/"},{"name":"Issue","slug":"Issue","link":"/tags/Issue/"},{"name":"Longest","slug":"Longest","link":"/tags/Longest/"},{"name":"Problem","slug":"Problem","link":"/tags/Problem/"},{"name":"Combination","slug":"Combination","link":"/tags/Combination/"},{"name":"Geometry","slug":"Geometry","link":"/tags/Geometry/"},{"name":"Numeric","slug":"Numeric","link":"/tags/Numeric/"},{"name":"Game Theory","slug":"Game-Theory","link":"/tags/Game-Theory/"},{"name":"Specification","slug":"Specification","link":"/tags/Specification/"},{"name":"Platform","slug":"Platform","link":"/tags/Platform/"},{"name":"Digest","slug":"Digest","link":"/tags/Digest/"},{"name":"Encrypt","slug":"Encrypt","link":"/tags/Encrypt/"},{"name":"Random","slug":"Random","link":"/tags/Random/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"NPM","slug":"NPM","link":"/tags/NPM/"},{"name":"CSS","slug":"CSS","link":"/tags/CSS/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Scala","slug":"Scala","link":"/tags/Scala/"},{"name":"Stdlib","slug":"Stdlib","link":"/tags/Stdlib/"},{"name":"SBT","slug":"SBT","link":"/tags/SBT/"},{"name":"Web Browser","slug":"Web-Browser","link":"/tags/Web-Browser/"},{"name":"Proxy","slug":"Proxy","link":"/tags/Proxy/"},{"name":"Keras","slug":"Keras","link":"/tags/Keras/"},{"name":"Readme","slug":"Readme","link":"/tags/Readme/"},{"name":"Matplotlib","slug":"Matplotlib","link":"/tags/Matplotlib/"},{"name":"Data Visualization","slug":"Data-Visualization","link":"/tags/Data-Visualization/"},{"name":"Jupyter","slug":"Jupyter","link":"/tags/Jupyter/"},{"name":"Numpy","slug":"Numpy","link":"/tags/Numpy/"},{"name":"NDArray","slug":"NDArray","link":"/tags/NDArray/"},{"name":"Data Science","slug":"Data-Science","link":"/tags/Data-Science/"},{"name":"Linear Algbra","slug":"Linear-Algbra","link":"/tags/Linear-Algbra/"},{"name":"Fourier Transformation","slug":"Fourier-Transformation","link":"/tags/Fourier-Transformation/"},{"name":"Efficience","slug":"Efficience","link":"/tags/Efficience/"},{"name":"Error","slug":"Error","link":"/tags/Error/"},{"name":"Finance","slug":"Finance","link":"/tags/Finance/"},{"name":"Histogram","slug":"Histogram","link":"/tags/Histogram/"},{"name":"Ufunc","slug":"Ufunc","link":"/tags/Ufunc/"},{"name":"Pandas","slug":"Pandas","link":"/tags/Pandas/"},{"name":"Py3Ref","slug":"Py3Ref","link":"/tags/Py3Ref/"},{"name":"Class","slug":"Class","link":"/tags/Class/"},{"name":"Statements","slug":"Statements","link":"/tags/Statements/"},{"name":"Data Model","slug":"Data-Model","link":"/tags/Data-Model/"},{"name":"Module","slug":"Module","link":"/tags/Module/"},{"name":"Frame","slug":"Frame","link":"/tags/Frame/"},{"name":"Traceback","slug":"Traceback","link":"/tags/Traceback/"},{"name":"Execution Model","slug":"Execution-Model","link":"/tags/Execution-Model/"},{"name":"Lexical","slug":"Lexical","link":"/tags/Lexical/"},{"name":"Cookbook","slug":"Cookbook","link":"/tags/Cookbook/"},{"name":"Py3std","slug":"Py3std","link":"/tags/Py3std/"},{"name":"IO","slug":"IO","link":"/tags/IO/"},{"name":"Pywin32","slug":"Pywin32","link":"/tags/Pywin32/"},{"name":"Python32","slug":"Python32","link":"/tags/Python32/"},{"name":"Automatic","slug":"Automatic","link":"/tags/Automatic/"},{"name":"Device","slug":"Device","link":"/tags/Device/"},{"name":"Driver","slug":"Driver","link":"/tags/Driver/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"},{"name":"GUI","slug":"GUI","link":"/tags/GUI/"},{"name":"Persistence","slug":"Persistence","link":"/tags/Persistence/"},{"name":"Datatype","slug":"Datatype","link":"/tags/Datatype/"},{"name":"Binary","slug":"Binary","link":"/tags/Binary/"},{"name":"File System","slug":"File-System","link":"/tags/File-System/"},{"name":"Internet","slug":"Internet","link":"/tags/Internet/"},{"name":"Data Processing","slug":"Data-Processing","link":"/tags/Data-Processing/"},{"name":"Zip","slug":"Zip","link":"/tags/Zip/"},{"name":"Runtime","slug":"Runtime","link":"/tags/Runtime/"},{"name":"Parameter","slug":"Parameter","link":"/tags/Parameter/"},{"name":"Text","slug":"Text","link":"/tags/Text/"},{"name":"TensorFlow","slug":"TensorFlow","link":"/tags/TensorFlow/"},{"name":"CUDA","slug":"CUDA","link":"/tags/CUDA/"},{"name":"CUDNN","slug":"CUDNN","link":"/tags/CUDNN/"},{"name":"NVCC","slug":"NVCC","link":"/tags/NVCC/"},{"name":"Operators","slug":"Operators","link":"/tags/Operators/"},{"name":"ProtoBuf","slug":"ProtoBuf","link":"/tags/ProtoBuf/"},{"name":"Flow Control","slug":"Flow-Control","link":"/tags/Flow-Control/"},{"name":"Resources","slug":"Resources","link":"/tags/Resources/"},{"name":"Algebra","slug":"Algebra","link":"/tags/Algebra/"},{"name":"Matrix","slug":"Matrix","link":"/tags/Matrix/"},{"name":"Vector","slug":"Vector","link":"/tags/Vector/"},{"name":"Determinant","slug":"Determinant","link":"/tags/Determinant/"},{"name":"Eigen Value","slug":"Eigen-Value","link":"/tags/Eigen-Value/"},{"name":"Eigne Vector","slug":"Eigne-Vector","link":"/tags/Eigne-Vector/"},{"name":"Sherman-Morrison","slug":"Sherman-Morrison","link":"/tags/Sherman-Morrison/"},{"name":"Derivative","slug":"Derivative","link":"/tags/Derivative/"},{"name":"Differential","slug":"Differential","link":"/tags/Differential/"},{"name":"Matrix Decomposition","slug":"Matrix-Decomposition","link":"/tags/Matrix-Decomposition/"},{"name":"SVD","slug":"SVD","link":"/tags/SVD/"},{"name":"QRD","slug":"QRD","link":"/tags/QRD/"},{"name":"LUD","slug":"LUD","link":"/tags/LUD/"},{"name":"Hilbert","slug":"Hilbert","link":"/tags/Hilbert/"},{"name":"Crate","slug":"Crate","link":"/tags/Crate/"},{"name":"Mod","slug":"Mod","link":"/tags/Mod/"},{"name":"Visualization","slug":"Visualization","link":"/tags/Visualization/"},{"name":"Panic","slug":"Panic","link":"/tags/Panic/"},{"name":"Ownership","slug":"Ownership","link":"/tags/Ownership/"},{"name":"Test","slug":"Test","link":"/tags/Test/"},{"name":"Unsafe","slug":"Unsafe","link":"/tags/Unsafe/"},{"name":"Constrained","slug":"Constrained","link":"/tags/Constrained/"},{"name":"Fenchel","slug":"Fenchel","link":"/tags/Fenchel/"},{"name":"Legendre","slug":"Legendre","link":"/tags/Legendre/"},{"name":"Duality","slug":"Duality","link":"/tags/Duality/"},{"name":"Fourier","slug":"Fourier","link":"/tags/Fourier/"},{"name":"DDT","slug":"DDT","link":"/tags/DDT/"},{"name":"DCT","slug":"DCT","link":"/tags/DCT/"},{"name":"Lagrange","slug":"Lagrange","link":"/tags/Lagrange/"},{"name":"Project","slug":"Project","link":"/tags/Project/"},{"name":"Proxmial","slug":"Proxmial","link":"/tags/Proxmial/"},{"name":"Farkas","slug":"Farkas","link":"/tags/Farkas/"},{"name":"Functional","slug":"Functional","link":"/tags/Functional/"},{"name":"Holder","slug":"Holder","link":"/tags/Holder/"},{"name":"Norm","slug":"Norm","link":"/tags/Norm/"},{"name":"Unconstrained","slug":"Unconstrained","link":"/tags/Unconstrained/"},{"name":"Linear Programming","slug":"Linear-Programming","link":"/tags/Linear-Programming/"},{"name":"Convex","slug":"Convex","link":"/tags/Convex/"},{"name":"Conjugate","slug":"Conjugate","link":"/tags/Conjugate/"},{"name":"Descent","slug":"Descent","link":"/tags/Descent/"},{"name":"Momentum","slug":"Momentum","link":"/tags/Momentum/"},{"name":"Learning Rate","slug":"Learning-Rate","link":"/tags/Learning-Rate/"},{"name":"Newton","slug":"Newton","link":"/tags/Newton/"},{"name":"Online","slug":"Online","link":"/tags/Online/"},{"name":"Gauss","slug":"Gauss","link":"/tags/Gauss/"},{"name":"Levenberg","slug":"Levenberg","link":"/tags/Levenberg/"},{"name":"Marquardt","slug":"Marquardt","link":"/tags/Marquardt/"},{"name":"Real Analysis","slug":"Real-Analysis","link":"/tags/Real-Analysis/"},{"name":"Cone","slug":"Cone","link":"/tags/Cone/"},{"name":"Subgredient","slug":"Subgredient","link":"/tags/Subgredient/"},{"name":"Bash","slug":"Bash","link":"/tags/Bash/"},{"name":"Environment","slug":"Environment","link":"/tags/Environment/"},{"name":"Execution","slug":"Execution","link":"/tags/Execution/"},{"name":"CentOS","slug":"CentOS","link":"/tags/CentOS/"},{"name":"Repository","slug":"Repository","link":"/tags/Repository/"},{"name":"Installment","slug":"Installment","link":"/tags/Installment/"},{"name":"Package Manager","slug":"Package-Manager","link":"/tags/Package-Manager/"},{"name":"Dependency","slug":"Dependency","link":"/tags/Dependency/"},{"name":"Compress","slug":"Compress","link":"/tags/Compress/"},{"name":"Tar","slug":"Tar","link":"/tags/Tar/"},{"name":"Crontab","slug":"Crontab","link":"/tags/Crontab/"},{"name":"Systemd","slug":"Systemd","link":"/tags/Systemd/"},{"name":"Startup","slug":"Startup","link":"/tags/Startup/"},{"name":"Shutdown","slug":"Shutdown","link":"/tags/Shutdown/"},{"name":"Monitor","slug":"Monitor","link":"/tags/Monitor/"},{"name":"Profile","slug":"Profile","link":"/tags/Profile/"},{"name":"RC","slug":"RC","link":"/tags/RC/"},{"name":"Editor","slug":"Editor","link":"/tags/Editor/"},{"name":"Viewer","slug":"Viewer","link":"/tags/Viewer/"},{"name":"Ext2&#x2F;3","slug":"Ext2-3","link":"/tags/Ext2-3/"},{"name":"Ext4","slug":"Ext4","link":"/tags/Ext4/"},{"name":"Inode","slug":"Inode","link":"/tags/Inode/"},{"name":"Block","slug":"Block","link":"/tags/Block/"},{"name":"Block Group","slug":"Block-Group","link":"/tags/Block-Group/"},{"name":"Commands","slug":"Commands","link":"/tags/Commands/"},{"name":"IPC","slug":"IPC","link":"/tags/IPC/"},{"name":"Interrupt","slug":"Interrupt","link":"/tags/Interrupt/"},{"name":"Hard Link","slug":"Hard-Link","link":"/tags/Hard-Link/"},{"name":"Symbolic Link","slug":"Symbolic-Link","link":"/tags/Symbolic-Link/"},{"name":"Host","slug":"Host","link":"/tags/Host/"},{"name":"DNS","slug":"DNS","link":"/tags/DNS/"},{"name":"VFS","slug":"VFS","link":"/tags/VFS/"},{"name":"Ping","slug":"Ping","link":"/tags/Ping/"},{"name":"Route","slug":"Route","link":"/tags/Route/"},{"name":"Process Schedual","slug":"Process-Schedual","link":"/tags/Process-Schedual/"},{"name":"Process","slug":"Process","link":"/tags/Process/"},{"name":"Vi","slug":"Vi","link":"/tags/Vi/"},{"name":"Keymapper","slug":"Keymapper","link":"/tags/Keymapper/"},{"name":"VimScripts","slug":"VimScripts","link":"/tags/VimScripts/"},{"name":"Statistics","slug":"Statistics","link":"/tags/Statistics/"},{"name":"Correlation","slug":"Correlation","link":"/tags/Correlation/"},{"name":"Odds","slug":"Odds","link":"/tags/Odds/"},{"name":"WOE","slug":"WOE","link":"/tags/WOE/"},{"name":"IV","slug":"IV","link":"/tags/IV/"},{"name":"Entropy","slug":"Entropy","link":"/tags/Entropy/"},{"name":"Gini","slug":"Gini","link":"/tags/Gini/"},{"name":"KL Divergence","slug":"KL-Divergence","link":"/tags/KL-Divergence/"},{"name":"PSI","slug":"PSI","link":"/tags/PSI/"},{"name":"Maching Learning","slug":"Maching-Learning","link":"/tags/Maching-Learning/"},{"name":"TPR","slug":"TPR","link":"/tags/TPR/"},{"name":"FRP","slug":"FRP","link":"/tags/FRP/"},{"name":"ROC","slug":"ROC","link":"/tags/ROC/"},{"name":"AUC","slug":"AUC","link":"/tags/AUC/"},{"name":"MSE","slug":"MSE","link":"/tags/MSE/"},{"name":"MAE","slug":"MAE","link":"/tags/MAE/"},{"name":"MAPE","slug":"MAPE","link":"/tags/MAPE/"},{"name":"SMAE","slug":"SMAE","link":"/tags/SMAE/"},{"name":"AIC","slug":"AIC","link":"/tags/AIC/"},{"name":"BIC","slug":"BIC","link":"/tags/BIC/"},{"name":"Time Series","slug":"Time-Series","link":"/tags/Time-Series/"},{"name":"Time Series Decomposition","slug":"Time-Series-Decomposition","link":"/tags/Time-Series-Decomposition/"},{"name":"Exponential Smoothing","slug":"Exponential-Smoothing","link":"/tags/Exponential-Smoothing/"},{"name":"Spurious Regression","slug":"Spurious-Regression","link":"/tags/Spurious-Regression/"},{"name":"GARCH","slug":"GARCH","link":"/tags/GARCH/"},{"name":"Statistic Tests","slug":"Statistic-Tests","link":"/tags/Statistic-Tests/"},{"name":"VAR","slug":"VAR","link":"/tags/VAR/"},{"name":"Markup Language","slug":"Markup-Language","link":"/tags/Markup-Language/"},{"name":"IDX","slug":"IDX","link":"/tags/IDX/"},{"name":"Ini","slug":"Ini","link":"/tags/Ini/"},{"name":"Toml","slug":"Toml","link":"/tags/Toml/"},{"name":"Yaml","slug":"Yaml","link":"/tags/Yaml/"},{"name":"Tools","slug":"Tools","link":"/tags/Tools/"},{"name":"Firefox","slug":"Firefox","link":"/tags/Firefox/"},{"name":"TeX","slug":"TeX","link":"/tags/TeX/"},{"name":"LaTeX","slug":"LaTeX","link":"/tags/LaTeX/"},{"name":"ML Technique","slug":"ML-Technique","link":"/tags/ML-Technique/"},{"name":"Feature Engineering","slug":"Feature-Engineering","link":"/tags/Feature-Engineering/"},{"name":"Data Preprocessing","slug":"Data-Preprocessing","link":"/tags/Data-Preprocessing/"},{"name":"Normalization","slug":"Normalization","link":"/tags/Normalization/"},{"name":"Regularization","slug":"Regularization","link":"/tags/Regularization/"},{"name":"RLang","slug":"RLang","link":"/tags/RLang/"},{"name":"GGPlot","slug":"GGPlot","link":"/tags/GGPlot/"},{"name":"Filter","slug":"Filter","link":"/tags/Filter/"},{"name":"Wrapper","slug":"Wrapper","link":"/tags/Wrapper/"},{"name":"Embedded","slug":"Embedded","link":"/tags/Embedded/"},{"name":"Sampling","slug":"Sampling","link":"/tags/Sampling/"},{"name":"Bootstrap","slug":"Bootstrap","link":"/tags/Bootstrap/"},{"name":"One-hot","slug":"One-hot","link":"/tags/One-hot/"},{"name":"Bining","slug":"Bining","link":"/tags/Bining/"},{"name":"PCA","slug":"PCA","link":"/tags/PCA/"},{"name":"LDA","slug":"LDA","link":"/tags/LDA/"},{"name":"Embedding","slug":"Embedding","link":"/tags/Embedding/"},{"name":"ML Model","slug":"ML-Model","link":"/tags/ML-Model/"},{"name":"Model Component","slug":"Model-Component","link":"/tags/Model-Component/"},{"name":"Convolutional","slug":"Convolutional","link":"/tags/Convolutional/"},{"name":"Attention","slug":"Attention","link":"/tags/Attention/"},{"name":"Interaction","slug":"Interaction","link":"/tags/Interaction/"},{"name":"Pooling","slug":"Pooling","link":"/tags/Pooling/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"LSTM","slug":"LSTM","link":"/tags/LSTM/"},{"name":"GRU","slug":"GRU","link":"/tags/GRU/"},{"name":"Seq2Seq","slug":"Seq2Seq","link":"/tags/Seq2Seq/"},{"name":"Linear Model","slug":"Linear-Model","link":"/tags/Linear-Model/"},{"name":"Bayes","slug":"Bayes","link":"/tags/Bayes/"},{"name":"Factorization Machine","slug":"Factorization-Machine","link":"/tags/Factorization-Machine/"},{"name":"External Memory","slug":"External-Memory","link":"/tags/External-Memory/"},{"name":"Perceptron","slug":"Perceptron","link":"/tags/Perceptron/"},{"name":"SGD","slug":"SGD","link":"/tags/SGD/"},{"name":"0-1 Loss","slug":"0-1-Loss","link":"/tags/0-1-Loss/"},{"name":"Logistic Regression","slug":"Logistic-Regression","link":"/tags/Logistic-Regression/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"Ctags","slug":"Ctags","link":"/tags/Ctags/"},{"name":"Office","slug":"Office","link":"/tags/Office/"},{"name":"WebView","slug":"WebView","link":"/tags/WebView/"},{"name":"Setting","slug":"Setting","link":"/tags/Setting/"},{"name":"Netword","slug":"Netword","link":"/tags/Netword/"},{"name":"NAT","slug":"NAT","link":"/tags/NAT/"},{"name":"Bridged","slug":"Bridged","link":"/tags/Bridged/"},{"name":"Virtual Machine","slug":"Virtual-Machine","link":"/tags/Virtual-Machine/"},{"name":"Host-Only","slug":"Host-Only","link":"/tags/Host-Only/"},{"name":"Unsupervised Model","slug":"Unsupervised-Model","link":"/tags/Unsupervised-Model/"},{"name":"Apriori","slug":"Apriori","link":"/tags/Apriori/"},{"name":"FPTree","slug":"FPTree","link":"/tags/FPTree/"},{"name":"Prefix-Projected Pattern","slug":"Prefix-Projected-Pattern","link":"/tags/Prefix-Projected-Pattern/"},{"name":"Auto-Encoders","slug":"Auto-Encoders","link":"/tags/Auto-Encoders/"},{"name":"K-Means","slug":"K-Means","link":"/tags/K-Means/"},{"name":"AGENS","slug":"AGENS","link":"/tags/AGENS/"},{"name":"DBSCAN","slug":"DBSCAN","link":"/tags/DBSCAN/"},{"name":"SOM","slug":"SOM","link":"/tags/SOM/"},{"name":"Fuzzy C-Means","slug":"Fuzzy-C-Means","link":"/tags/Fuzzy-C-Means/"},{"name":"Technique","slug":"Technique","link":"/tags/Technique/"},{"name":"Neural Network","slug":"Neural-Network","link":"/tags/Neural-Network/"},{"name":"Internal Covariate Shift","slug":"Internal-Covariate-Shift","link":"/tags/Internal-Covariate-Shift/"},{"name":"Activation","slug":"Activation","link":"/tags/Activation/"},{"name":"Dropout","slug":"Dropout","link":"/tags/Dropout/"},{"name":"NoLinear Model","slug":"NoLinear-Model","link":"/tags/NoLinear-Model/"},{"name":"KNN","slug":"KNN","link":"/tags/KNN/"},{"name":"Model Enhencement","slug":"Model-Enhencement","link":"/tags/Model-Enhencement/"},{"name":"Boosting","slug":"Boosting","link":"/tags/Boosting/"},{"name":"AdaBoost","slug":"AdaBoost","link":"/tags/AdaBoost/"},{"name":"Pseudo Loss","slug":"Pseudo-Loss","link":"/tags/Pseudo-Loss/"},{"name":"Bagging","slug":"Bagging","link":"/tags/Bagging/"},{"name":"LightGBM","slug":"LightGBM","link":"/tags/LightGBM/"},{"name":"Stacking","slug":"Stacking","link":"/tags/Stacking/"},{"name":"Model Evaluation","slug":"Model-Evaluation","link":"/tags/Model-Evaluation/"},{"name":"Expected Risk","slug":"Expected-Risk","link":"/tags/Expected-Risk/"},{"name":"Empirical Risk","slug":"Empirical-Risk","link":"/tags/Empirical-Risk/"},{"name":"Structural Risk","slug":"Structural-Risk","link":"/tags/Structural-Risk/"},{"name":"Generalization","slug":"Generalization","link":"/tags/Generalization/"},{"name":"Early Stopping","slug":"Early-Stopping","link":"/tags/Early-Stopping/"},{"name":"Loss","slug":"Loss","link":"/tags/Loss/"},{"name":"Surrogate Loss","slug":"Surrogate-Loss","link":"/tags/Surrogate-Loss/"},{"name":"Hinge Loss","slug":"Hinge-Loss","link":"/tags/Hinge-Loss/"},{"name":"Cross Entropy","slug":"Cross-Entropy","link":"/tags/Cross-Entropy/"},{"name":"Logistic SE","slug":"Logistic-SE","link":"/tags/Logistic-SE/"},{"name":"Square Loss","slug":"Square-Loss","link":"/tags/Square-Loss/"},{"name":"Computer Vision","slug":"Computer-Vision","link":"/tags/Computer-Vision/"},{"name":"Local Binary Pattern","slug":"Local-Binary-Pattern","link":"/tags/Local-Binary-Pattern/"},{"name":"LBP","slug":"LBP","link":"/tags/LBP/"},{"name":"SIFT","slug":"SIFT","link":"/tags/SIFT/"},{"name":"SURF","slug":"SURF","link":"/tags/SURF/"},{"name":"Brief","slug":"Brief","link":"/tags/Brief/"},{"name":"FinTech","slug":"FinTech","link":"/tags/FinTech/"},{"name":"Financial Risk","slug":"Financial-Risk","link":"/tags/Financial-Risk/"},{"name":"Anti-Fraud","slug":"Anti-Fraud","link":"/tags/Anti-Fraud/"},{"name":"FPD","slug":"FPD","link":"/tags/FPD/"},{"name":"Credit Risk","slug":"Credit-Risk","link":"/tags/Credit-Risk/"},{"name":"Hard Drive","slug":"Hard-Drive","link":"/tags/Hard-Drive/"},{"name":"SSD","slug":"SSD","link":"/tags/SSD/"},{"name":"SATA","slug":"SATA","link":"/tags/SATA/"},{"name":"PCI-E","slug":"PCI-E","link":"/tags/PCI-E/"},{"name":"NVMe","slug":"NVMe","link":"/tags/NVMe/"},{"name":"AHCI","slug":"AHCI","link":"/tags/AHCI/"},{"name":"M.2","slug":"M-2","link":"/tags/M-2/"},{"name":"Score Card","slug":"Score-Card","link":"/tags/Score-Card/"},{"name":"Swap Set Analysis","slug":"Swap-Set-Analysis","link":"/tags/Swap-Set-Analysis/"},{"name":"Rule Evaluation","slug":"Rule-Evaluation","link":"/tags/Rule-Evaluation/"},{"name":"Corner Point Detection","slug":"Corner-Point-Detection","link":"/tags/Corner-Point-Detection/"},{"name":"Moravec","slug":"Moravec","link":"/tags/Moravec/"},{"name":"Harris","slug":"Harris","link":"/tags/Harris/"},{"name":"Graph Analysis","slug":"Graph-Analysis","link":"/tags/Graph-Analysis/"},{"name":"Social Network","slug":"Social-Network","link":"/tags/Social-Network/"},{"name":"Appliance","slug":"Appliance","link":"/tags/Appliance/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"CBOW","slug":"CBOW","link":"/tags/CBOW/"},{"name":"Skip-Gram","slug":"Skip-Gram","link":"/tags/Skip-Gram/"},{"name":"VSM","slug":"VSM","link":"/tags/VSM/"},{"name":"LSA","slug":"LSA","link":"/tags/LSA/"},{"name":"Word2Vec","slug":"Word2Vec","link":"/tags/Word2Vec/"},{"name":"Hoffuman Tree","slug":"Hoffuman-Tree","link":"/tags/Hoffuman-Tree/"},{"name":"Softmax","slug":"Softmax","link":"/tags/Softmax/"},{"name":"Negtive Sampling","slug":"Negtive-Sampling","link":"/tags/Negtive-Sampling/"},{"name":"Click Through Rate","slug":"Click-Through-Rate","link":"/tags/Click-Through-Rate/"},{"name":"Recommandation System","slug":"Recommandation-System","link":"/tags/Recommandation-System/"},{"name":"ML Models","slug":"ML-Models","link":"/tags/ML-Models/"},{"name":"Deep Crossing","slug":"Deep-Crossing","link":"/tags/Deep-Crossing/"},{"name":"Wide&amp;Deep","slug":"Wide-Deep","link":"/tags/Wide-Deep/"},{"name":"DeepFM","slug":"DeepFM","link":"/tags/DeepFM/"},{"name":"Deep&amp;Cross","slug":"Deep-Cross","link":"/tags/Deep-Cross/"},{"name":"DIN","slug":"DIN","link":"/tags/DIN/"},{"name":"Layer","slug":"Layer","link":"/tags/Layer/"},{"name":"Convolution","slug":"Convolution","link":"/tags/Convolution/"},{"name":"Dense","slug":"Dense","link":"/tags/Dense/"},{"name":"Flatten","slug":"Flatten","link":"/tags/Flatten/"},{"name":"Reshape","slug":"Reshape","link":"/tags/Reshape/"},{"name":"Debug","slug":"Debug","link":"/tags/Debug/"},{"name":"GCC&#x2F;G++","slug":"GCC-G","link":"/tags/GCC-G/"},{"name":"Hash","slug":"Hash","link":"/tags/Hash/"},{"name":"Thread","slug":"Thread","link":"/tags/Thread/"},{"name":"Datetype","slug":"Datetype","link":"/tags/Datetype/"},{"name":"Namespace","slug":"Namespace","link":"/tags/Namespace/"},{"name":"Pointer","slug":"Pointer","link":"/tags/Pointer/"},{"name":"HDFS","slug":"HDFS","link":"/tags/HDFS/"},{"name":"Parquet","slug":"Parquet","link":"/tags/Parquet/"},{"name":"Sorting","slug":"Sorting","link":"/tags/Sorting/"},{"name":"Routine","slug":"Routine","link":"/tags/Routine/"},{"name":"Object","slug":"Object","link":"/tags/Object/"},{"name":"Trait","slug":"Trait","link":"/tags/Trait/"},{"name":"Generic","slug":"Generic","link":"/tags/Generic/"},{"name":"Backend","slug":"Backend","link":"/tags/Backend/"},{"name":"Series","slug":"Series","link":"/tags/Series/"},{"name":"Templates","slug":"Templates","link":"/tags/Templates/"},{"name":"Coroutine","slug":"Coroutine","link":"/tags/Coroutine/"},{"name":"Asynchronous","slug":"Asynchronous","link":"/tags/Asynchronous/"},{"name":"Value","slug":"Value","link":"/tags/Value/"},{"name":"Package","slug":"Package","link":"/tags/Package/"},{"name":"Typedef","slug":"Typedef","link":"/tags/Typedef/"},{"name":"SVM","slug":"SVM","link":"/tags/SVM/"},{"name":"Kernel Trick","slug":"Kernel-Trick","link":"/tags/Kernel-Trick/"},{"name":"SMO","slug":"SMO","link":"/tags/SMO/"},{"name":"Nolinear Model","slug":"Nolinear-Model","link":"/tags/Nolinear-Model/"},{"name":"Decision Tree","slug":"Decision-Tree","link":"/tags/Decision-Tree/"},{"name":"ID3","slug":"ID3","link":"/tags/ID3/"},{"name":"C4.5","slug":"C4-5","link":"/tags/C4-5/"},{"name":"CART","slug":"CART","link":"/tags/CART/"},{"name":"MDLP","slug":"MDLP","link":"/tags/MDLP/"},{"name":"GMM","slug":"GMM","link":"/tags/GMM/"},{"name":"GEM","slug":"GEM","link":"/tags/GEM/"},{"name":"ADMM","slug":"ADMM","link":"/tags/ADMM/"},{"name":"GBDT","slug":"GBDT","link":"/tags/GBDT/"},{"name":"XGBoost","slug":"XGBoost","link":"/tags/XGBoost/"},{"name":"Quantile Sketch","slug":"Quantile-Sketch","link":"/tags/Quantile-Sketch/"},{"name":"Data Analysis","slug":"Data-Analysis","link":"/tags/Data-Analysis/"},{"name":"MOB","slug":"MOB","link":"/tags/MOB/"},{"name":"Vintage Analysis","slug":"Vintage-Analysis","link":"/tags/Vintage-Analysis/"},{"name":"Roll Rate Analysis","slug":"Roll-Rate-Analysis","link":"/tags/Roll-Rate-Analysis/"},{"name":"Flow Rate Analysis","slug":"Flow-Rate-Analysis","link":"/tags/Flow-Rate-Analysis/"},{"name":"Girvan-Newman","slug":"Girvan-Newman","link":"/tags/Girvan-Newman/"},{"name":"Newman Fast Algorithm","slug":"Newman-Fast-Algorithm","link":"/tags/Newman-Fast-Algorithm/"},{"name":"Edge-Clustering Detection","slug":"Edge-Clustering-Detection","link":"/tags/Edge-Clustering-Detection/"},{"name":"Walk Trap","slug":"Walk-Trap","link":"/tags/Walk-Trap/"},{"name":"Random Walk","slug":"Random-Walk","link":"/tags/Random-Walk/"},{"name":"Make","slug":"Make","link":"/tags/Make/"},{"name":"Makefile","slug":"Makefile","link":"/tags/Makefile/"},{"name":"Method","slug":"Method","link":"/tags/Method/"}],"categories":[{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Rust","slug":"Rust","link":"/categories/Rust/"},{"name":"Readme","slug":"Python/Readme","link":"/categories/Python/Readme/"},{"name":"Probability","slug":"Probability","link":"/categories/Probability/"},{"name":"Set","slug":"Set","link":"/categories/Set/"},{"name":"Twists","slug":"Python/Twists","link":"/categories/Python/Twists/"},{"name":"Math Mixin","slug":"Math-Mixin","link":"/categories/Math-Mixin/"},{"name":"Tool","slug":"Linux/Tool","link":"/categories/Linux/Tool/"},{"name":"Daily Life","slug":"Daily-Life","link":"/categories/Daily-Life/"},{"name":"ML Theory","slug":"ML-Theory","link":"/categories/ML-Theory/"},{"name":"CS","slug":"CS","link":"/categories/CS/"},{"name":"C&#x2F;C++","slug":"C-C","link":"/categories/C-C/"},{"name":"Maxism","slug":"Daily-Life/Maxism","link":"/categories/Daily-Life/Maxism/"},{"name":"Hadoop","slug":"Database/Hadoop","link":"/categories/Database/Hadoop/"},{"name":"Storage","slug":"CS/Storage","link":"/categories/CS/Storage/"},{"name":"Spark","slug":"Database/Spark","link":"/categories/Database/Spark/"},{"name":"Program Design","slug":"CS/Program-Design","link":"/categories/CS/Program-Design/"},{"name":"SQL DB","slug":"Database/SQL-DB","link":"/categories/Database/SQL-DB/"},{"name":"Network","slug":"CS/Network","link":"/categories/CS/Network/"},{"name":"Heuristic","slug":"Algorithm/Heuristic","link":"/categories/Algorithm/Heuristic/"},{"name":"Character","slug":"CS/Character","link":"/categories/CS/Character/"},{"name":"Data Structure","slug":"Algorithm/Data-Structure","link":"/categories/Algorithm/Data-Structure/"},{"name":"Parallel","slug":"CS/Parallel","link":"/categories/CS/Parallel/"},{"name":"Issue","slug":"Algorithm/Issue","link":"/categories/Algorithm/Issue/"},{"name":"Problem","slug":"Algorithm/Problem","link":"/categories/Algorithm/Problem/"},{"name":"Cppref","slug":"C-C/Cppref","link":"/categories/C-C/Cppref/"},{"name":"Specification","slug":"Algorithm/Specification","link":"/categories/Algorithm/Specification/"},{"name":"Web","slug":"Web","link":"/categories/Web/"},{"name":"Scala","slug":"Java/Scala","link":"/categories/Java/Scala/"},{"name":"Keras","slug":"Python/Keras","link":"/categories/Python/Keras/"},{"name":"STL","slug":"C-C/STL","link":"/categories/C-C/STL/"},{"name":"Matplotlib","slug":"Python/Matplotlib","link":"/categories/Python/Matplotlib/"},{"name":"Jupyter","slug":"Python/Jupyter","link":"/categories/Python/Jupyter/"},{"name":"Numpy","slug":"Python/Numpy","link":"/categories/Python/Numpy/"},{"name":"Pandas","slug":"Python/Pandas","link":"/categories/Python/Pandas/"},{"name":"Py3Ref","slug":"Python/Py3Ref","link":"/categories/Python/Py3Ref/"},{"name":"Cookbook","slug":"Python/Cookbook","link":"/categories/Python/Cookbook/"},{"name":"Cstd","slug":"C-C/Cstd","link":"/categories/C-C/Cstd/"},{"name":"Py3std","slug":"Python/Py3std","link":"/categories/Python/Py3std/"},{"name":"Pywin32","slug":"Python/Pywin32","link":"/categories/Python/Pywin32/"},{"name":"MPI","slug":"C-C/MPI","link":"/categories/C-C/MPI/"},{"name":"TensorFlow","slug":"Python/TensorFlow","link":"/categories/Python/TensorFlow/"},{"name":"Math Algebra","slug":"Math-Algebra","link":"/categories/Math-Algebra/"},{"name":"Math Analysis","slug":"Math-Analysis","link":"/categories/Math-Analysis/"},{"name":"Bash Programming","slug":"Linux/Bash-Programming","link":"/categories/Linux/Bash-Programming/"},{"name":"Configuration","slug":"Linux/Configuration","link":"/categories/Linux/Configuration/"},{"name":"Shell","slug":"Linux/Shell","link":"/categories/Linux/Shell/"},{"name":"File System","slug":"Linux/File-System","link":"/categories/Linux/File-System/"},{"name":"IPC","slug":"Linux/IPC","link":"/categories/Linux/IPC/"},{"name":"Network","slug":"Linux/Network","link":"/categories/Linux/Network/"},{"name":"Process Schedual","slug":"Linux/Process-Schedual","link":"/categories/Linux/Process-Schedual/"},{"name":"Vi","slug":"Linux/Tool/Vi","link":"/categories/Linux/Tool/Vi/"},{"name":"Statistics","slug":"Math-Mixin/Statistics","link":"/categories/Math-Mixin/Statistics/"},{"name":"Time Series","slug":"Math-Mixin/Time-Series","link":"/categories/Math-Mixin/Time-Series/"},{"name":"Tool","slug":"Tool","link":"/categories/Tool/"},{"name":"ML Technique","slug":"ML-Technique","link":"/categories/ML-Technique/"},{"name":"RLang","slug":"RLang","link":"/categories/RLang/"},{"name":"ML Model","slug":"ML-Model","link":"/categories/ML-Model/"},{"name":"NPM","slug":"Web/NPM","link":"/categories/Web/NPM/"},{"name":"CSS","slug":"Web/CSS","link":"/categories/Web/CSS/"},{"name":"Model Enhencement","slug":"ML-Theory/Model-Enhencement","link":"/categories/ML-Theory/Model-Enhencement/"},{"name":"Optimization","slug":"ML-Theory/Optimization","link":"/categories/ML-Theory/Optimization/"},{"name":"Loss","slug":"ML-Theory/Loss","link":"/categories/ML-Theory/Loss/"},{"name":"ML Specification","slug":"ML-Specification","link":"/categories/ML-Specification/"},{"name":"Proxy","slug":"Web/Proxy","link":"/categories/Web/Proxy/"},{"name":"Thrift","slug":"Web/Thrift","link":"/categories/Web/Thrift/"},{"name":"Linear Algebra","slug":"Math-Algebra/Linear-Algebra","link":"/categories/Math-Algebra/Linear-Algebra/"},{"name":"Universal Algebra","slug":"Math-Algebra/Universal-Algebra","link":"/categories/Math-Algebra/Universal-Algebra/"},{"name":"Optimization","slug":"Math-Analysis/Optimization","link":"/categories/Math-Analysis/Optimization/"},{"name":"Fourier Analysis","slug":"Math-Analysis/Fourier-Analysis","link":"/categories/Math-Analysis/Fourier-Analysis/"},{"name":"Functional Analysis","slug":"Math-Analysis/Functional-Analysis","link":"/categories/Math-Analysis/Functional-Analysis/"},{"name":"Real Analysis","slug":"Math-Analysis/Real-Analysis","link":"/categories/Math-Analysis/Real-Analysis/"},{"name":"Markup Language","slug":"Tool/Markup-Language","link":"/categories/Tool/Markup-Language/"},{"name":"Web Browser","slug":"Tool/Web-Browser","link":"/categories/Tool/Web-Browser/"},{"name":"Feature Engineering","slug":"ML-Technique/Feature-Engineering","link":"/categories/ML-Technique/Feature-Engineering/"},{"name":"Model Component","slug":"ML-Model/Model-Component","link":"/categories/ML-Model/Model-Component/"},{"name":"Linear Model","slug":"ML-Model/Linear-Model","link":"/categories/ML-Model/Linear-Model/"},{"name":"Windows","slug":"Tool/Windows","link":"/categories/Tool/Windows/"},{"name":"Editor","slug":"Tool/Editor","link":"/categories/Tool/Editor/"},{"name":"Unsupervised Model","slug":"ML-Model/Unsupervised-Model","link":"/categories/ML-Model/Unsupervised-Model/"},{"name":"Neural Network","slug":"ML-Technique/Neural-Network","link":"/categories/ML-Technique/Neural-Network/"},{"name":"Nolinear Model","slug":"ML-Model/Nolinear-Model","link":"/categories/ML-Model/Nolinear-Model/"},{"name":"Computer Vision","slug":"ML-Specification/Computer-Vision","link":"/categories/ML-Specification/Computer-Vision/"},{"name":"FinTech","slug":"ML-Specification/FinTech","link":"/categories/ML-Specification/FinTech/"},{"name":"Graph Analysis","slug":"ML-Specification/Graph-Analysis","link":"/categories/ML-Specification/Graph-Analysis/"},{"name":"NLP","slug":"ML-Specification/NLP","link":"/categories/ML-Specification/NLP/"},{"name":"Click Through Rate","slug":"ML-Specification/Click-Through-Rate","link":"/categories/ML-Specification/Click-Through-Rate/"},{"name":"Risk Control","slug":"ML-Specification/FinTech/Risk-Control","link":"/categories/ML-Specification/FinTech/Risk-Control/"},{"name":"Recommandation System","slug":"ML-Specification/Click-Through-Rate/Recommandation-System","link":"/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"}]}