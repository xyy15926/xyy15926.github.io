<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: Unsupervised Model - UBeaRLy</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="UBeaRLy"><meta property="og:url" content="https://xyy15926.github.io/"><meta property="og:site_name" content="UBeaRLy"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:author" content="UBeaRLy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io"},"headline":"UBeaRLy","image":["https://xyy15926.github.io/img/og_image.png"],"author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"UBeaRLy","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":""}</script><link rel="alternate" href="/atom.xml" title="UBeaRLy" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="follow_it-verification-code" content="SVBypAPPHxjjr7Y4hHfn"><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li><a href="/categories/ML-Model/">ML Model</a></li><li class="is-active"><a href="#" aria-current="page">Unsupervised Model</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T08:06:22.000Z" title="7/16/2021, 4:06:22 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Model/">ML Model</a><span> / </span><a class="link-muted" href="/categories/ML-Model/Unsupervised-Model/">Unsupervised Model</a></span><span class="level-item">9 minutes read (About 1297 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Model/Unsupervised-Model/associating.html">频繁项集/序列</a></h1><div class="content"><h2 id="频繁项集"><a href="#频繁项集" class="headerlink" title="频繁项集"></a>频繁项集</h2><blockquote>
<ul>
<li>频繁项集：频繁出现项集合（无序）</li>
<li>频繁项序列：频繁出现项序列（有序）</li>
</ul>
</blockquote>
<ul>
<li>相关关联规则算法：数据量大时，无法直接发现频繁项集</li>
<li>频繁项集评估标准</li>
</ul>
<h3 id="评估标准"><a href="#评估标准" class="headerlink" title="评估标准"></a>评估标准</h3><ul>
<li><p>支持度：数据关联出现概率，关联数据在数据集中出现次数占
总数据集比重</p>
<script type="math/tex; mode=display">
Support(X, Y) = P(XY) = \frac {num(XY)} {num(All)}</script><ul>
<li>支持度高数据不一定构成频繁项集，但支持度数据肯定不能
不构成频繁项集</li>
</ul>
</li>
<li><p>置信度：数据出现条件概率，某个数据出现、另一数据出现概率</p>
<script type="math/tex; mode=display">
Confidence(X \Leftarrow Y) = P(X|Y) = \frac {P(XY)} {P(Y)}</script></li>
<li><p>提升度：数据之间关联关系，某数据出现、另一数据出现概率同
其总体出现概率之比</p>
<script type="math/tex; mode=display">\begin{align*}
Lift(X \Leftarrow Y) & = \frac {P(X|Y)} {P(X)} \\
& = \frac {Confidence(X \Leftarrow)}{P(X)} \\
& = \frac {P(XY)} {P(X)P(Y)}
\end{align*}</script><ul>
<li>提升度大于1则为有效的强关联规则，否则为无效的强关联
规则</li>
<li>若X、Y不相关，则提升度为1</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>选择频繁数据集，一般需要自定义评估标准：自定义支持度、
  自定义支持度和置信度组合</li>
</ul>
</blockquote>
<h2 id="Apriori"><a href="#Apriori" class="headerlink" title="Apriori"></a>Apriori</h2><p>Apriori算法</p>
<ul>
<li>以支持度作为评估标准，找出数据集中<strong>最大的</strong>频繁$k$项集<ul>
<li>找到符合支持度标准的频繁$k$项集</li>
<li>迭代直到无法找到项数更大的频繁项集</li>
</ul>
</li>
</ul>
<p><img src="/imgs/apriori_example.png" alt="apriori_example"></p>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><blockquote>
<ul>
<li>输入：数据集合D、支持度阈值$\alpha$</li>
<li>输出：最大的频繁K项集</li>
</ul>
</blockquote>
<ul>
<li>置$k=1$，扫描整个数据集，以所有出现过数据作为候选1项集</li>
<li>挖掘候选$k$项集<ul>
<li>扫描数据、计算候选$k$项集支持度</li>
<li>去除支持度低于阈值$\alpha$的项集得到频繁$k$项集<ul>
<li>若频繁$k$项集只包含1项，直接返回</li>
<li>若频繁$k$项集为空，返回频繁$k-1$项集</li>
</ul>
</li>
<li>基于频繁$k$项集连接、生成候选$k+1$项集</li>
<li>置$k=k+1$</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>需要频繁扫描数据、效率低</li>
<li>频繁项集的子项集肯定也是频繁项集</li>
</ul>
</blockquote>
<h2 id="FPTree-FPGrowth"><a href="#FPTree-FPGrowth" class="headerlink" title="FPTree/FPGrowth"></a>FPTree/FPGrowth</h2><p>FPTree：对Apriori算法改进，不在需要多次扫描数据</p>
<ul>
<li><p>FPTree引入部分数据结构以临时存储数据</p>
<p><img src="/imgs/fptree_data_structure.png" alt="fptree_data_structure"></p>
<ul>
<li>项头表：按频繁1项集出现频数降序排列的表</li>
<li>FP Tree：包含原始数据、频数的多叉树</li>
<li>节点链表：链接项头表中频繁1项集、FPTree中相应节点
的链表</li>
</ul>
</li>
<li><p>特点：效率高</p>
<ul>
<li>只需要扫描两次数据</li>
<li>使用多叉树存储临时数据，利用高频频繁项集</li>
</ul>
</li>
</ul>
<h3 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h3><ul>
<li><p>建立项头表</p>
<ul>
<li>扫描数据，得到所有1项集频数、剔除支持度低于阈值者，
并按支持度（频数）降序排列</li>
<li>第二次扫描数据，剔除每条数据中非频繁1项集、
<strong>在每条数据内部</strong>按支持度降序排列</li>
</ul>
<p><img src="/imgs/fptree_item_head_table.png" alt="fptree_item_head_table"></p>
</li>
<li><p>建立FPTree：逐条读取处理后排序后数据，依次插入树中</p>
<ul>
<li>每条数据中排序靠前者为祖先节点</li>
<li>若有<strong>直系公共祖先</strong>则公共祖先节点计数+1</li>
<li>新节点通过链表和项头表链接</li>
</ul>
<p><img src="/imgs/fptree_build_fptree.png" alt="fptree_item_head_table"></p>
</li>
<li><p>挖掘FPTree：对项表头中每项，找到其条件模式基</p>
<ul>
<li>将子树中每个节点计数置为叶子节点计数和，则子树中节点
取值即为其与当前项组合出现频数/支持度</li>
<li>删除（当前子树内）支持度/频数低于支持度阈值$\alpha$
节点</li>
<li>剩余节点项、当前项组合即为相应频繁$k$项集</li>
</ul>
<p><img src="/imgs/fptree_mine_item_set.png" alt="fptree_mine_item_set"></p>
<blockquote>
<ul>
<li>条件模式基：节点<strong>作为叶子节点</strong>所对应的FP子树</li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="Prefix-Projected-Pattern-Growth"><a href="#Prefix-Projected-Pattern-Growth" class="headerlink" title="Prefix-Projected Pattern Growth"></a>Prefix-Projected Pattern Growth</h2><p><em>PrefixSpan</em>：前缀投影模式挖掘</p>
<ul>
<li>以支持度为标准，挖掘数据集中<strong>频繁序列</strong><ul>
<li>每条数据为若干项集组成的序列，<strong>序列内项集间有序</strong></li>
<li>为方便，每条数据序列中项集中的项已排序</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>可以将每条数据序列整体视为串</li>
<li>频繁序列：频繁出现<strong>子序列</strong></li>
</ul>
</blockquote>
<h3 id="算法-2"><a href="#算法-2" class="headerlink" title="算法"></a>算法</h3><blockquote>
<ul>
<li>输入：序列数据集$S$、支持度$\alpha$</li>
<li>所有满足阈值要求的频繁序列</li>
</ul>
</blockquote>
<ul>
<li><p>找出所有长度1前缀（即所有项）、对应投影</p>
<ul>
<li>计数、剔除持度小于阈值$\alpha$者，得到频繁1项序列</li>
<li>置$k=1$</li>
</ul>
</li>
<li><p>对每个长度为$k$前缀递归挖掘</p>
<ul>
<li>若前缀对应投影为空，返回</li>
<li>若前缀对应投影中所有项支持度均小于阈值$\alpha$，返回</li>
<li>同满足阈值要求阈值$\alpha$要求项合并，得到新前缀</li>
<li>置$k=k+1$</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li><em>prefix</em>：前缀，正在处理的子序列</li>
<li><em>projected</em>：投影，各数据序列中位于前缀之后子串
?串</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T08:08:56.000Z" title="7/16/2021, 4:08:56 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Model/">ML Model</a><span> / </span><a class="link-muted" href="/categories/ML-Model/Unsupervised-Model/">Unsupervised Model</a></span><span class="level-item">21 minutes read (About 3169 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Model/Unsupervised-Model/clustering.html">聚类</a></h1><div class="content"><h2 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h2><p>聚类：按照某特定标准（如距离准则）把数据集分割成不同类、簇，
簇内数据相似性尽可能大、不同簇间数据对象差异性仅可能大</p>
<ul>
<li><p>属于无监督学习，目标是把相似的样本聚集在一起</p>
<ul>
<li>通常只需要给定相似度的计算即可</li>
<li>无需使用训练数据学习</li>
</ul>
</li>
<li><p>聚类算法分类</p>
<ul>
<li>基于划分</li>
<li>Hierarchical Methods：基于层次</li>
<li>基于密度</li>
<li>基于网络</li>
<li>基于模型</li>
<li>模糊聚类</li>
<li>基于约束</li>
<li>基于粒度</li>
<li>谱聚类</li>
<li>核聚类</li>
<li>量子聚类</li>
</ul>
</li>
</ul>
<h3 id="衡量聚类算法优劣"><a href="#衡量聚类算法优劣" class="headerlink" title="衡量聚类算法优劣"></a>衡量聚类算法优劣</h3><p><img src="/imgs/clustering_comparision.png" alt="clustering_comparision"></p>
<ul>
<li><p>算法的处理能力</p>
<ul>
<li>处理大数据的能力</li>
<li>处理噪声数据能力</li>
<li>处理任意形状数据的能力，如：有间隙的嵌套数据</li>
</ul>
</li>
<li><p>算法是否需要预测条件</p>
<ul>
<li>聚类数目</li>
<li>相关领域知识</li>
</ul>
</li>
<li><p>输入数据关联性</p>
<ul>
<li>结果是否和数据输入顺序相关</li>
<li>对数据维度敏感性（是否能处理高维数据）</li>
<li>对数据类型要求</li>
</ul>
</li>
</ul>
<h2 id="Hierarchical-Methods"><a href="#Hierarchical-Methods" class="headerlink" title="Hierarchical Methods"></a>Hierarchical Methods</h2><p>层次聚类</p>
<ul>
<li><p>自底向上合并的层次聚类</p>
<ul>
<li>最底层开始，通过合并最相似类簇形成上层类簇</li>
<li>全部数据点合并到同一类簇、或达到终止条件时结束</li>
</ul>
</li>
<li><p>自顶向下分裂的层次聚类</p>
<ul>
<li>从包含全部数据点的类簇开始，递归分裂出最相异的下层
类簇</li>
<li>每个类簇仅包含单个数据点时结束</li>
</ul>
</li>
<li><p>优点</p>
<ul>
<li>可解释性好：如需要创建分类方法时</li>
<li>研究表明能产生高质量聚类，可以应用在较大K的K-means
后的合并阶段</li>
<li>可以解决非球形类簇</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>时间复杂度高$O(N^2 log N)$（$N$为数据点数目）</li>
<li>贪心算法无法取得最优解</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>距离选择参见<em>ml_tech/#todo</em></li>
</ul>
</blockquote>
<h3 id="AGENS"><a href="#AGENS" class="headerlink" title="AGENS"></a>AGENS</h3><p>AGENS：自下向上层次聚类</p>
<ul>
<li>组连接：组与组之间距离<ul>
<li>single linkage</li>
<li>average linkage</li>
<li>complete linkage</li>
</ul>
</li>
<li>算法复杂度：$n^2logn$</li>
</ul>
<h4 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h4><ul>
<li>每个数据点视为一类，计算两两直接最小距离</li>
<li>合并距离最小两个两类别为新类</li>
<li>重新计算新类、所有类之间距离</li>
<li>重复以上，直至所有类合并为一类</li>
</ul>
<h3 id="Divisive-Analysis"><a href="#Divisive-Analysis" class="headerlink" title="Divisive Analysis"></a>Divisive Analysis</h3><p><em>DIANA</em>：自定向下层次聚类</p>
<h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ul>
<li>所有数据归为一组$C_1=(p_1, p_2, dots, p_n)$</li>
<li>计算所有点之间的距离矩阵，选择到其他点平均距离最大的点，
记为$q$，取该点作为新组起始点</li>
<li>$\forall p, p \notin C_1$，计算
$d_arg(p, C_1) - d_arg(p, C_2)$，
若小于零则属于$C_1$，否则属于$C_2$</li>
</ul>
<h3 id="Balanced-Itertive-Reducing-and-Clustering-Using-Hierarchies"><a href="#Balanced-Itertive-Reducing-and-Clustering-Using-Hierarchies" class="headerlink" title="Balanced Itertive Reducing and Clustering Using Hierarchies"></a>Balanced Itertive Reducing and Clustering Using Hierarchies</h3><p><em>BIRCH</em>：利用层次方法的平衡迭代规约和聚类，利用层次方法聚类
、规约数据</p>
<ul>
<li>特点<ul>
<li>利用CF树结构快速聚类</li>
<li>只需要单遍扫描数据</li>
<li>适合在数据类型为数值型、数据量大时使用</li>
</ul>
</li>
</ul>
<h3 id="常见算法、改进"><a href="#常见算法、改进" class="headerlink" title="常见算法、改进"></a>常见算法、改进</h3><ul>
<li>A Hierarchical Clustering Algorithm Using Dynamic
Modeling：使用KNN算法计算作为linkage、构建图<ul>
<li>较BIRCH好，但算法复杂度依然为$O(n^2)$</li>
<li>可以处理比较复杂形状</li>
</ul>
</li>
</ul>
<h2 id="Partition-Based-Methods"><a href="#Partition-Based-Methods" class="headerlink" title="Partition-Based Methods"></a>Partition-Based Methods</h2><p>基于划分的方法</p>
<ul>
<li><p>基本流程</p>
<ul>
<li>确定需要聚类的数目，挑选相应数量点作为初始中心点</li>
<li>再根据预定的启发式算法队数据点做迭代</li>
<li>直到达到类簇内点足够近、类簇间点足够远</li>
</ul>
</li>
<li><p>优点</p>
<ul>
<li>对大型数据集同样简单高效、时空复杂度低</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>数据集越大，结果容易越容易陷入局部最优</li>
<li>需要预先设置k值，对初始k中心点选取敏感</li>
<li>对噪声、离群点敏感</li>
<li>只适合数值性</li>
<li>不适合非凸形状</li>
</ul>
</li>
<li><p>影响结果因素</p>
<ul>
<li>原始问题是否可分</li>
<li>分类数目K</li>
<li>初始点选择</li>
</ul>
</li>
</ul>
<h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h3><ul>
<li><p>数据：$\Omega={X_1, X_2, \dots, X_N}$，分k个组</p>
<script type="math/tex; mode=display">
C_1, C_2, \dots, C_k \\
C_1 \cup C_2 \cup \dots \cup C_k = \Omega \\</script><p>每个样本点包含p个特征：$X_i = (x_1, x_2, \dots, x_p)$</p>
</li>
<li><p>目标：极小化每个样本点到聚类中心距离之和</p>
<script type="math/tex; mode=display">
\arg_{C_1, C_2, \dots, C_K} \min \sum_{i=1}^K
   \sum_{x_j in \C_i} d(x_j, C_i)</script><ul>
<li>若定义距离为平方欧式距离，则根据组间+组内=全，
极小化目标就是中心点距离极大化</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>优化问题是NP-hard问题，需要采用近似方法</li>
</ul>
</blockquote>
<h4 id="K值选择"><a href="#K值选择" class="headerlink" title="K值选择"></a>K值选择</h4><ul>
<li>经验选择</li>
<li>特殊方法：Elbow Method，肘部法则，画出距离和K的点图，
选择剧烈变化的点的K值</li>
</ul>
<h4 id="Lloyd’s-Algorithm"><a href="#Lloyd’s-Algorithm" class="headerlink" title="Lloyd’s Algorithm"></a>Lloyd’s Algorithm</h4><ul>
<li>随机选择K对象，每个对象初始地代表类簇中心</li>
<li>对剩余对象，计算与各簇中心距离，归于距离最近地类簇</li>
<li>重新计算各类簇平均值作为新簇中心</li>
<li>不断重复直至准则函数收敛</li>
</ul>
<blockquote>
<ul>
<li>算法时间效率：$\in O(K * N^{\pi})$</li>
</ul>
</blockquote>
<h3 id="常见算法、改进-1"><a href="#常见算法、改进-1" class="headerlink" title="常见算法、改进"></a>常见算法、改进</h3><ul>
<li>K-means++、Intelligent K-means、Genetic K-means：改进
K-means对初值敏感</li>
<li>K-medoids、K-medians：改进K-means对噪声、离群点敏感</li>
<li>K-modes：适用于分类型数据</li>
<li>Kernel-Kmeans：可以解决非凸问题</li>
</ul>
<h2 id="Density-Based-Methods"><a href="#Density-Based-Methods" class="headerlink" title="Density-Based Methods"></a>Density-Based Methods</h2><p>基于密度的方法</p>
<ul>
<li>优点<ul>
<li>对噪声不敏感</li>
<li>能发现任意形状聚类</li>
</ul>
</li>
<li>缺点<ul>
<li>聚类结果和参数关系很大</li>
</ul>
</li>
</ul>
<h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><ul>
<li><p>核心点：半径eps的邻域内点数量不少于阈值MinPts的点</p>
</li>
<li><p>直接可达：核心点半径eps的领域内被称为直接可达</p>
<ul>
<li><strong>没有任何点是由非核心点直接可达的</strong></li>
</ul>
</li>
<li><p>可达：若存在$p_1, \cdots, p_n$点列中相邻点直接可达，
则$p_1, p_n$可达</p>
<ul>
<li>非对称关系，因为核心点没有直接可达点</li>
</ul>
</li>
<li><p>连接性：若存在点$o$可达$p,q$，则$p,q$称为[密度]连接</p>
<ul>
<li>对称关系</li>
<li>聚类内点都是相连接的</li>
<li>若p由q可达，则p在q所属聚类中</li>
</ul>
</li>
<li><p>局外点：不由任何点可达的点</p>
</li>
</ul>
<h3 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h3><blockquote>
<ul>
<li>Density-Based Spatial Clustering of Applications with Noise</li>
</ul>
</blockquote>
<h4 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h4><ul>
<li>从任意对象点p开始</li>
<li>寻找合并核心点p对象直接密度可达对象<ul>
<li>若p是核心点，则找到聚类</li>
<li>若p是边界，则寻找下个对象点</li>
</ul>
</li>
<li>重复直到所有点被处理</li>
</ul>
<h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><ul>
<li><p>DBSCAN用固定参数识别聚类，类簇稀疏程度不同时，相同判断
标准会破坏类自然结构</p>
<ul>
<li>较稀疏类簇会被划分为多个</li>
<li>密度大距离近多个类被合并</li>
</ul>
</li>
<li><p>参数影响</p>
<ul>
<li>eps过大大多数点聚为同一簇中、过小则会导致簇分裂</li>
<li>MinPts值过大则同簇中点被标记为噪声点、过小则有大量
核心点</li>
</ul>
</li>
<li><p>超参半径eps、最小点数量MinPts经验选取</p>
<ul>
<li>计算所有点k距离</li>
<li>对各点k距离排序、绘制折线图</li>
<li>观察折线图，以发现极具变化的位置对应k距离作为半径</li>
<li>k即作为最小点数量</li>
</ul>
<blockquote>
<ul>
<li>k距离：距离点第k近点距离</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="常见算法、改进-2"><a href="#常见算法、改进-2" class="headerlink" title="常见算法、改进"></a>常见算法、改进</h3><ul>
<li>Ordering Points to Indentify Clustering Structure：优先
搜索高密度，然后根据高密度特点设置参数，改善DBSCAN</li>
</ul>
<h2 id="Grid-Based-Methods"><a href="#Grid-Based-Methods" class="headerlink" title="Grid-Based Methods"></a>Grid-Based Methods</h2><p>基于网络的方法</p>
<ul>
<li><p>优点</p>
<ul>
<li>速度快，速度与数据对象个数无关，只依赖数据空间中每维
上单元数目</li>
<li>可以和基于密度算法共同使用</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>对参数敏感</li>
<li>无法处理不规则分布的数据</li>
<li>维数灾难</li>
<li>聚类结果精确性低：算法效率提高的代价</li>
</ul>
</li>
</ul>
<h3 id="流程-1"><a href="#流程-1" class="headerlink" title="流程"></a>流程</h3><ul>
<li>将数据空间划分为网格单元：不同算法主要区别</li>
<li>将数据对象集映射到网格单元中，计算各单元密度</li>
<li>根据预设的阈值判断每个网格单元是否为高密度单元</li>
<li>将相连的高度密度网格单元识别为类簇</li>
</ul>
<h3 id="常见算法、改进-3"><a href="#常见算法、改进-3" class="headerlink" title="常见算法、改进"></a>常见算法、改进</h3><ul>
<li>statistical information grid</li>
<li>wave-cluster</li>
<li>clustering-quest</li>
</ul>
<h2 id="Model-Based-Methods"><a href="#Model-Based-Methods" class="headerlink" title="Model-Based Methods"></a>Model-Based Methods</h2><p>基于模型的方法：为每个类簇假定模型，寻找对给定模型的最佳拟合</p>
<ul>
<li>优点<ul>
<li>对类划分以概率形式表示</li>
<li>每类特征可以用概率表达</li>
</ul>
</li>
<li>缺点<ul>
<li>执行效率不高，尤其是分布数量多、数据量少时</li>
</ul>
</li>
</ul>
<h3 id="SOM"><a href="#SOM" class="headerlink" title="SOM"></a>SOM</h3><p>SOM：假设输入对象中存在一些拓扑结构、顺序，可以实现从输入
空间到输入平面的降维映射，且映射具有拓扑特征保持性质</p>
<ul>
<li><p>网络结构</p>
<ul>
<li>输入层：高维输入向量</li>
<li>输入层：2维网络上的有序节点</li>
</ul>
</li>
<li><p>学习过程</p>
<ul>
<li>找到、更新与输入节点距离最短的输出层单元，即获胜单元</li>
<li>更新邻近区域权值，保持输出节点具有输入向量拓扑特征</li>
</ul>
</li>
</ul>
<h4 id="SOM算法流程"><a href="#SOM算法流程" class="headerlink" title="SOM算法流程"></a>SOM算法流程</h4><ul>
<li>网络初始化：初始化输出层节点权重</li>
<li>随机选取输入样本作为输入向量，找到与输入向量距离最小的
权重向量</li>
<li>定义获胜单元，调整获胜单元邻近区域权重、向输入向量靠拢</li>
<li>收缩邻域半径、减小学习率、重复，直到小于允许值，输出聚类
结果</li>
</ul>
<h3 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h3><ul>
<li>概率生成模型：假设数据是根据潜在概率分布生成<ul>
<li>Gaussian Mixture Model</li>
</ul>
</li>
<li>基于神经网络模型的方法<ul>
<li>Self Organized Maps</li>
</ul>
</li>
</ul>
<h2 id="模糊聚类"><a href="#模糊聚类" class="headerlink" title="模糊聚类"></a>模糊聚类</h2><p>模糊聚类：样本以一定概率属于某个类</p>
<ul>
<li>优点<ul>
<li>对正态分布的数据聚类效果较好</li>
<li>算法对孤立点敏感</li>
</ul>
</li>
</ul>
<h2 id="Fuzzy-C-means-FCM"><a href="#Fuzzy-C-means-FCM" class="headerlink" title="Fuzzy C-means(FCM)"></a>Fuzzy C-means(FCM)</h2><p><em>FCM</em>：对K-means的推广软聚类</p>
<ul>
<li><p>算法最终输出$C$个聚类中心向量、$C*N$模糊划分矩阵</p>
<ul>
<li>表示每个样本点对每个类的隶属度</li>
<li>根据划分矩阵、按照最大隶属原则确定样本点归属</li>
<li>聚类中心表示类平均特征，可以作为类代表</li>
</ul>
</li>
<li><p>特点</p>
<ul>
<li>算法性能依赖初始聚类中心，需要依赖其他算法快速确定
初始聚类中心、或多次执行算法</li>
<li>不能确保收敛于最优解</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li><em>soft cluster</em>：点可以属于多个类</li>
</ul>
</blockquote>
<h4 id="参数选择"><a href="#参数选择" class="headerlink" title="参数选择"></a>参数选择</h4><ul>
<li>聚类数目$C$：$C$远远小于聚类样本总数目，且大于1</li>
<li>柔性参数$m$<ul>
<li>$m$过大：聚类效果差</li>
<li>$m$过小：算法接近HCM聚类算法</li>
</ul>
</li>
</ul>
<h4 id="算法流程-2"><a href="#算法流程-2" class="headerlink" title="算法流程"></a>算法流程</h4><ul>
<li>标准化数据矩阵</li>
<li>建立模糊相似矩阵，初始化隶属矩阵</li>
<li><p>迭代，直到目标函数收敛到极小值</p>
<script type="math/tex; mode=display">
w_k(x_i) = \frac 1 \sum_{i=1}^k 
   (\frac {d(x_i, \mu_k)} {d(x_i, \mu_i} )^{1/(m-2)})</script></li>
<li><p>根据迭代结果，由最终隶属矩阵确定数据所属类，得到聚类结果</p>
</li>
</ul>
<h3 id="常见算法、改进-4"><a href="#常见算法、改进-4" class="headerlink" title="常见算法、改进"></a>常见算法、改进</h3><ul>
<li>HCM算法</li>
</ul>
<h2 id="基于约束的算法"><a href="#基于约束的算法" class="headerlink" title="基于约束的算法"></a>基于约束的算法</h2><p>基于约束的算法：考虑聚类问题中的约束条件，利用约束知识进行
推理</p>
<ul>
<li><p>约束</p>
<ul>
<li>对聚类参数的约束</li>
<li>对数据点的约束</li>
</ul>
</li>
<li><p>典型算法</p>
<ul>
<li>Clustering with Obstructed Distance：用两点之间障碍
距离取代一般的欧式距离计算最小距离</li>
</ul>
</li>
</ul>
<h2 id="量子聚类"><a href="#量子聚类" class="headerlink" title="量子聚类"></a>量子聚类</h2><p>量子聚类：用量子理论解决聚类过程中初值依赖、确定类别数目的
问题</p>
<ul>
<li>典型算法<ul>
<li>基于相关点的Pott自旋、统计机理提供的量子聚类模型：
将聚类问题视为物理系统</li>
</ul>
</li>
</ul>
<h2 id="核聚类"><a href="#核聚类" class="headerlink" title="核聚类"></a>核聚类</h2><p>核聚类：增加对样本特征的优化过程，利用Mercer核把输入空间映射
至高维特征空间，在特征空间中进行聚类</p>
<ul>
<li><p>特点</p>
<ul>
<li>方法普适</li>
<li>性能上优于经典聚类算算法</li>
<li>可以通过非线性映射较好分辨、提取、放大有用特征</li>
<li>收敛速度快</li>
</ul>
</li>
<li><p>典型算法</p>
<ul>
<li>SVDD算法</li>
<li>SVC算法</li>
</ul>
</li>
</ul>
<h2 id="谱聚类"><a href="#谱聚类" class="headerlink" title="谱聚类"></a>谱聚类</h2><p>谱聚类：建立在图论中谱图理论基础上，本质是将聚类问题转换为
图的最优划分问题</p>
<h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h3><ul>
<li>根据样本数据集定义描述成对数据点的相似度亲和矩阵</li>
<li>计算矩阵特征值、特征向量</li>
<li>选择合适的特征向量聚类不同点</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-13T15:26:47.000Z" title="7/13/2019, 11:26:47 PM">2019-07-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T08:07:49.000Z" title="7/16/2021, 4:07:49 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Model/">ML Model</a><span> / </span><a class="link-muted" href="/categories/ML-Model/Unsupervised-Model/">Unsupervised Model</a></span><span class="level-item">a minute read (About 143 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Model/Unsupervised-Model/auto_encoder.html">Auto-Encoders</a></h1><div class="content"><p>自编码机/稀疏编码/堆栈自编码器</p>
<ul>
<li><p>起源：编码理论可以应用于视觉皮层感受野，大脑主要视觉皮层
使用稀疏原理创建可以用于重建输入图像的最小基函数子集</p>
</li>
<li><p>优点</p>
<ul>
<li>简单技术：重建输入</li>
<li>可堆栈多层</li>
<li>直觉型，基于神经科学研究</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>贪婪训练每层</li>
<li>没有全局优化</li>
<li>表现较监督学习差</li>
<li>多层容易失效</li>
<li>输入的重建可能不是学习通用表征的理想<em>metric</em></li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-13T15:26:35.000Z" title="7/13/2019, 11:26:35 PM">2019-07-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T08:09:43.000Z" title="7/16/2021, 4:09:43 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Model/">ML Model</a><span> / </span><a class="link-muted" href="/categories/ML-Model/Unsupervised-Model/">Unsupervised Model</a></span><span class="level-item">25 minutes read (About 3774 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Model/Unsupervised-Model/expectation_maximization.html">EM算法</a></h1><div class="content"><h2 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h2><p><em>expectation maximization algorithm</em>：含有隐变量的概率模型
参数的极大似然估计法、极大后验概率估计法</p>
<ul>
<li><p>模型含有<em>latent variable</em>（潜在变量）、<em>hidden variable</em>
（隐变量）似然函数将没有解析解</p>
</li>
<li><p>所以EM算法需要迭代求解，每次迭代由两步组成</p>
<ul>
<li>E步：求期望expectation</li>
<li>M步：求极大maximization</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>模型变量都是<em>observable variable</em>、给定数据情况下，可以
  直接使用极大似然估计、贝叶斯估计</li>
</ul>
</blockquote>
<h2 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h2><p>对含有隐变量的概率模型，目标是极大化观测数据（不完全数据）
$Y$关于参数$\theta$的对数似然函数，即极大化</p>
<script type="math/tex; mode=display">\begin{align*}
L(\theta) & = log P(Y|\theta) \\
& = log \sum_Z P(Y, Z|\theta) \\
& = log \left(\sum_Z P(Y|Z,\theta) P(Z|\theta) \right)
\end{align*}</script><blockquote>
<ul>
<li>$Y$：观测变量数据</li>
<li>$Z$：隐随机变量数据（未知）</li>
<li>$Y,Z$合在一起称为完全数据</li>
<li>$P(Y,Z|\theta)$：联合分布</li>
<li>$P(Z|Y,\theta)$：条件分布</li>
</ul>
</blockquote>
<ul>
<li>但是极大化目标函数中包括未观测数据$Z$、求和（积分）的
对数，直接求极大化非常困难</li>
<li>EM算法通过<strong>迭代</strong>逐步近似极大化$L(\theta)$</li>
</ul>
<h3 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h3><ul>
<li><p>假设第i次迭代后$\theta$的估计值是$\theta^{(i)}$，希望
新估计值$\theta$能使$L(\theta)$增加，并逐步增加到极大值
，考虑两者之差</p>
<script type="math/tex; mode=display">
L(\theta) - L(\theta^{(i)}) = log (\sum_Z P(Y|Z,\theta)
   P(Z|\theta)) - log P(Y|\theta^{(i)})</script></li>
<li><p>利用Jensen不等式有</p>
<script type="math/tex; mode=display">\begin{align*}
L(\theta) - L(|\theta^{(i)}) & = log(\sum_Z P(Y|Z,
   \theta^{(i)}) \frac {P(Y|Z,\theta) P(Z|\theta)}
   {P(Y|Z,\theta^{(i)})}) - log P(Y|\theta^{(i)}) \\
& \geq \sum_Z P(Z|Y,\theta^{(i)}) log \frac
   {P(Y|Z,\theta) P(Z|\theta)} {P(Z|Y,\theta^{(i)})}
   - log P(Y|\theta^{(i)}) \\
& = \sum_z P(Z|Y,\theta^{(i)}) log \frac
   {P(Y|Z,\theta) P(Z|\theta)}
   {P(Z|Y,\theta^{(i)}) P(Y|\theta^{(i)})}
\end{align*}</script></li>
<li><p>令</p>
<script type="math/tex; mode=display">
B(\theta, \theta^{(i)}) = L(\theta^{(i)}) + \sum_Z
   P(Z|Y,\theta^{(i)}) log \frac
   {P(Y|Z,\theta) P(Z|\theta)}
   {P(Z|Y,\theta^{(i)}) P(Y|\theta^{(i)})}</script><p>则$B(\theta, \theta^{(i)})$是$L(\theta)$的一个下界，即</p>
<script type="math/tex; mode=display">\begin{align*}
L(\theta) & \geq B(\theta, \theta^{(i)}) \\
\end{align*}</script><p>并根据$B(\theta, \theta^{(i)})$定义有</p>
<script type="math/tex; mode=display">\begin{align*}
L(\theta^{(i)}) = B(\theta^{(i)}, \theta^{(i)})
\end{align*}</script></li>
<li><p>则任意$\theta$满足
$B(\theta,\theta^{(i)}) &gt; B(\theta^{(i)},\theta^{(i)})$
，将满足$L(\theta) &gt; L(\theta^{(i)})$，应选择
$\theta^{(i+1)}$使得$B(\theta,\theta^{(i)})$达到极大</p>
<script type="math/tex; mode=display">\begin{align*}
\theta^{(i+1)} & = \arg\max_{\theta}
   B(\theta,\theta^{(i)}) \\
& = \arg\max_{\theta} L(\theta^{(i)}) + \sum_Z
   P(Z|Y,\theta^{(i)}) log \frac
   {P(Y|Z,\theta) P(Z|\theta)}
   {P(Z|Y,\theta^{(i)}) P(Y|\theta^{(i)})} \\
& = \arg\max_{\theta} (\sum_Z P(Z|Y,\theta^{(i)})
   log(P(Y|Z,\theta)P(Z|\theta))) \\
& = \arg\max_{\theta} (\sum_Z P(Z|Y,\theta^{(i)})
   log P(Y,Z|\theta)) \\
& = \arg\max_{\theta} Q(\theta, \theta^{(i)})
\end{align*}</script><blockquote>
<ul>
<li>和$\theta$无关的常数项全部舍去</li>
</ul>
</blockquote>
</li>
</ul>
<blockquote>
<ul>
<li>$Q(\theta, \theta^{(i)})$：Q函数，完全数据的对数似然函数
  $logP(Y,Z|\theta)$，关于在给定观测$Y$和当前参数
  $\theta^{(i)}$下，对未观测数据Z的条件概率分布
  $P(Z|Y,\theta^{(i)})$<script type="math/tex; mode=display">
  Q(\theta, \theta^{(i)}) = E_z
      [logP(Y,Z|\theta)|Y,\theta^{(i)}]</script></li>
</ul>
</blockquote>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><ol>
<li><p>选择参数初值$\theta^{0}$，开始迭代</p>
</li>
<li><p>E步：记$\theta^{(i)}$为第$i$迭代时，参数$\theta$的估计值
，在第$i+1$步迭代的E步时，计算Q函数
$Q(\theta, \theta^{(i)})$</p>
</li>
<li><p>M步：求使得Q函数极大化$\theta$作为第$i+1$次估计值
$\theta^{(i+1)}$</p>
<script type="math/tex; mode=display">
\theta^{(i+1)} = \arg\max_{\theta} Q(\theta, \theta^{(i)})</script></li>
<li><p>重复E步、M步直到待估参数收敛</p>
</li>
</ol>
<blockquote>
<ul>
<li><p>算法初值可以任意选择，但EM算法对初值敏感</p>
</li>
<li><p>E步：参数值估计缺失值分布，计算Q函数（似然函数）</p>
</li>
<li><p>M步：Q函数取极大得新参数估计值</p>
</li>
<li><p>收敛条件一般是对较小正数$\epsilon$，满足
  $|\theta^{(i+1)} - \theta^{(i)}| &lt; \epsilon$或
  $|Q(\theta^{(i+1)},\theta^{(i)}) - Q(\theta^{(i)},\theta^{(i)})| &lt; \epsilon$</p>
</li>
</ul>
</blockquote>
<h3 id="EM算法特点"><a href="#EM算法特点" class="headerlink" title="EM算法特点"></a>EM算法特点</h3><h4 id="EM算法优点"><a href="#EM算法优点" class="headerlink" title="EM算法优点"></a>EM算法优点</h4><ul>
<li>EM算法可以用于估计含有隐变量的模型参数</li>
<li>非常简单，稳定上升的步骤能非常可靠的找到最优估计值</li>
<li>应用广泛，能应用在多个领域中<ul>
<li>生成模型的非监督学习</li>
</ul>
</li>
</ul>
<h4 id="EM算法缺点"><a href="#EM算法缺点" class="headerlink" title="EM算法缺点"></a>EM算法缺点</h4><ul>
<li>EM算法计算复杂、受外较慢，不适合高维数据、大规模数据集</li>
<li>参数估计结果依赖初值，不够稳定，不能保证找到全局最优解</li>
</ul>
<h3 id="算法收敛性"><a href="#算法收敛性" class="headerlink" title="算法收敛性"></a>算法收敛性</h3><h4 id="定理1"><a href="#定理1" class="headerlink" title="定理1"></a>定理1</h4><blockquote>
<ul>
<li>设$P(Y|\theta)$为观测数据的似然函数，$\theta^{(i)}$为
  EM算法得到的参数估计序列，$P(Y|\theta^{(i)}),i=1,2,…$
  为对应的似然函数序列，则$P(Y|\theta^{(i)})$是单调递增的<script type="math/tex; mode=display">
  P(Y|\theta^{(i+1)}) \geq P(Y|\theta^{(i)})</script></li>
</ul>
</blockquote>
<ul>
<li><p>由条件概率</p>
<script type="math/tex; mode=display">\begin{align*}
P(Y|\theta) & = \frac {P(Y,Z|\theta)} {P(Z|Y,\theta)} \\
logP(Y|\theta) & = logP(Y,Z|\theta) - logP(Z|Y,\theta)
\end{align*}</script></li>
</ul>
<ul>
<li><p>则对数似然函数有</p>
<script type="math/tex; mode=display">
logP(Y|\theta) = Q(\theta, \theta^{(i)}) -
   H(\theta, \theta^{(i)})</script><blockquote>
<ul>
<li>$H(\theta, \theta^{(i)}) = \sum_Z log P(Z|Y,\theta) P(Z|Y,\theta)$</li>
<li>$Q(\theta, \theta^{(i)})$：前述Q函数</li>
<li>$logP(Y|\theta)$和$Z$无关，可以直接提出</li>
</ul>
</blockquote>
</li>
<li><p>分别取$\theta^{(i+1)}, \theta^{(i)}$带入，做差</p>
<script type="math/tex; mode=display">
logP(Y|\theta^{(i+1)}) - logP(Y|\theta^{(i)}) =
   [Q(\theta^{(i+1)}, \theta^{(i)}) - 
   Q(\theta^{(i)}, \theta^{(i)}] -
   [H(\theta^{(i+1)}, \theta^{(i)}) -
   H(\theta^{(i)}, \theta^{(i)})]</script><ul>
<li><p>$\theta^{(i+1)}$使得$Q(\theta, \theta^{(i)})$取极大</p>
</li>
<li><p>又有</p>
<script type="math/tex; mode=display">\begin{align*}
& H(\theta^{(i+1)}, \theta^{(i)}) -
  H(\theta^{(i)}, \theta^{(i)}) \\
= & \sum_Z (log \frac {P(Z|Y,\theta^{(i+1)})}
  {P(Z|Y,\theta^{(I)})}) P(Z|Y,\theta^{(i)}) \\
\leq & log (\sum_Z \frac {P(Z|Y,\theta^{(i+1)})}
  {P(Z|Y,\theta^{(I)})} P(Z|Y,\theta^{(i)})) \\
= & log \sum_Z P(Z|Y,\theta^{(i+1)}) = 0
\end{align*}</script></li>
</ul>
</li>
</ul>
<h4 id="定理2"><a href="#定理2" class="headerlink" title="定理2"></a>定理2</h4><blockquote>
<ul>
<li>设$L(\theta)=log P(Y|\theta)$为观测数据的对数似然函数，
  $\theta^{(i)},i=1,2,…$为EM算法得到的参数估计序列，
  $L(\theta^{(i)}),i=1,2,…$为对应的对数似然函数序列<blockquote>
<ul>
<li>若$P(Y|\theta)$有上界，则$L(\theta^{(i)})$收敛到某
 定值$L^{*}$</li>
<li>Q函数$Q(\theta, \theta^{‘})$与$L(\theta)$满足一定
 条件的情况下，由EM算法得到的参数估计序列
 $\theta^{(i)}$的收敛值$\theta^{*}$是$L(\theta)$的
 稳定点</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<ul>
<li>结论1由序列单调、有界显然</li>
</ul>
<blockquote>
<ul>
<li>Q函数$Q(\theta, \theta^{‘})$与$L(\theta)$的条件在大多数
  情况下是满足的</li>
<li>EM算法收敛性包含对数似然序列$L(\theta^{(i)})$、参数估计
  序列$\theta^{(i)}$的收敛性，前者不蕴含后者</li>
<li>此定理只能保证参数估计序列收敛到对数似然序列的稳定点，
  不能保证收敛到极大点，可选取多个不同初值迭代，从多个结果
  中选择最好的</li>
</ul>
</blockquote>
<h2 id="Gaussion-Mixture-Model"><a href="#Gaussion-Mixture-Model" class="headerlink" title="Gaussion Mixture Model"></a><em>Gaussion Mixture Model</em></h2><blockquote>
<ul>
<li>高斯混合模型是指具有如下概率分布模型<script type="math/tex; mode=display">
  P(y|\theta) = \sum_{k=1}^K \alpha_k \phi(y|\theta_k)</script><blockquote>
<ul>
<li>$\alpha<em>k \geq 0, \sum</em>{k=1}^K \alpha_k=1$：系数</li>
<li>$\phi(y|\theta_k)$：高斯分布密度函数</li>
<li>$\theta_k=(\mu_k, \sigma_k)$：第k个分模型参数</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<ul>
<li>用EM算法估计高斯混合模型参数
$\theta=(\alpha_1,…,\alpha_2,\theta_1,…,\theta_K)$</li>
</ul>
<h3 id="推导-1"><a href="#推导-1" class="headerlink" title="推导"></a>推导</h3><h4 id="明确隐变量"><a href="#明确隐变量" class="headerlink" title="明确隐变量"></a>明确隐变量</h4><p>明确隐变量，写出完全数据对数似然函数</p>
<ul>
<li><p>反映观测数据$y_j$来自第k个分模型的数据是未知的</p>
<script type="math/tex; mode=display">\gamma_{j,k} = \left \{ \begin{array}{l}
1, & 第j个观测来自第k个分模型 \\
0, & 否则
\end{array} \right.</script><blockquote>
<ul>
<li>$j=1,2,\cdots,N$：观测编号</li>
<li>$k=1,2,\cdots,K$：模型编号</li>
</ul>
</blockquote>
</li>
<li><p>则完全数据为</p>
<script type="math/tex; mode=display">(y_j,\gamma_{j,1},\cdots,\gamma_{j,K}), j=1,2,...,N</script></li>
<li><p>完全数据似然函数为</p>
<script type="math/tex; mode=display">\begin{align*}
P(y,\gamma|\theta) & = \prod_{j=1}^N
   P(y_j,\gamma_{j,1},\cdots,\gamma_{j,N}|\theta) \\
& = \prod_{k=1}^{K} \prod_{j=1}^N
   [\alpha_k \phi(y_j|\theta_k)]^{\gamma _{j,k}} \\
& = \prod_{k=1}^{K} \alpha_k^{n_k} \prod_{j=1}^N
   [\phi(y_j|\theta_k)]^{\gamma _{j,k}} \\
\end{align*}</script><blockquote>
<ul>
<li>$n<em>k = \sum</em>{j=1}^{N} \gamma_{j,k}$</li>
<li>$\sum_{k=1}^K n_k = N$</li>
</ul>
</blockquote>
</li>
<li><p>完全数据的对数似然函数为</p>
<script type="math/tex; mode=display">
logP(y, \gamma|\theta) = \sum_{k=1}^K \left \{
   n_k log \alpha_k + \sum_{j=1}^N \gamma_{j,k}
   [log \frac 1 {\sqrt {2\pi}} - log \sigma_k -
   \frac 1 {2\sigma_k}(y_j - \mu_k)^2] \right \}</script></li>
</ul>
<h4 id="E步：确定Q函数"><a href="#E步：确定Q函数" class="headerlink" title="E步：确定Q函数"></a>E步：确定Q函数</h4><script type="math/tex; mode=display">\begin{align*}
Q(\theta, \theta^{(i)}) & =
    E_z[logP(y,\gamma|\theta)|Y,\theta^{(i)}] \\
& = E \sum_{k=1}^K \left \{ n_k log\alpha_k + \sum_{j=1}^N
    \gamma_{j,k} [log \frac 1 {\sqrt {2\pi}} - log \sigma_k
    - \frac 1 {2\sigma_k}(y_j - \mu_k)^2] \right \} \\
& = \sum_{k=1}^K \left \{ \sum_{k=1}^K (E\gamma_{j,k})
    log\alpha_k + \sum_{j=1}^N (E\gamma_{j,k})
    [log \frac 1 {\sqrt {2\pi}} - log \sigma_k
    - \frac 1 {2\sigma_k}(y_j - \mu_k)^2] \right \}
\end{align*}</script><blockquote>
<ul>
<li>$E\gamma<em>{j,k} = E(\gamma</em>{j,k}|y,\theta)$：记为
  $\hat \gamma_{j,k}$</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">\begin{align*}
\hat \gamma_{j,k} & = E(\gamma_{j,k}|y,\theta) =
    P(\gamma_{j,k}|y,\theta) \\
& = \frac {P(\gamma_{j,k}=1, y_j|\theta)}
    {\sum_{k=1}^K P(\gamma_{j,k}=1,y_j|\theta)} \\
& = \frac {P(y_j|\gamma_{j,k}=1,\theta)
    P(\gamma_{j,k}=1|\theta)} {\sum_{k=1}^K
    P(y_j|\gamma_{j,k}=1,\theta) P(\gamma_{j,k}|\theta)} \\
& = \frac {\alpha_k \phi(y_j|\theta _k)}
    {\sum_{k=1}^K \alpha_k \phi(y_j|\theta_k)}
\end{align*}</script><p>带入可得</p>
<script type="math/tex; mode=display">
Q(\theta, \theta^{(i)}) = \sum_{k=1}^K \left\{
    n_k log\alpha_k + \sum_{k=1}^N \hat \gamma_{j,k}
    [log \frac 1 {\sqrt{2\pi}} - log \sigma_k -
    \frac 1 {2\sigma^2}(y_j - \mu_k)^2] \right \}</script><h4 id="M步"><a href="#M步" class="headerlink" title="M步"></a>M步</h4><p>求新一轮模型参数
$\theta^{(i+1)}=(\hat \alpha_1,…,\hat \alpha_2,\hat \theta_1,…,\hat \theta_K)$</p>
<script type="math/tex; mode=display">\begin{align*}
\theta^{(i+1)} & = \arg\max_{\theta} Q(\theta,\theta^{(i)}) \\
\hat \mu_k & = \frac {\sum_{j=1}^N \hat \gamma_{j,k} y_j}
    {\sum_{j=1}^N \hat \gamma_{j,k}} \\
\hat \sigma_k^2 & = \frac {\sum_{j=1}^N \hat \gamma_{j,k}
    (y_j - \mu_p)^2} {\sum_{j=1}^N \hat \gamma_{j,k}} \\
\hat \alpha_k & = \frac {n_k} N = \frac {\sum_{j=1}^N
    \hat \gamma_{j,k}} N
\end{align*}</script><blockquote>
<ul>
<li>$\hat \theta_k = (\hat \mu_k, \hat \sigma_k^2)$：直接求
  偏导置0即可得</li>
<li>$\hat \alpha<em>k$：在$\sum</em>{k=1}^K \alpha_k = 1$条件下求
  偏导置0求得</li>
</ul>
</blockquote>
<h3 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h3><blockquote>
<ul>
<li>输入：观测数据$y_1, y_2,\cdots, y_N$，N个高斯混合模型</li>
<li>输出：高斯混合模型参数</li>
</ul>
</blockquote>
<ol>
<li><p>取参数初始值开始迭代</p>
</li>
<li><p>E步：依据当前模型参数，计算分模型k对观测数据$y_j$响应度</p>
<script type="math/tex; mode=display">
\hat \gamma_{j,k} = \frac {\alpha \phi(y_k|\theta_k)}
  {\sum_{k=1}^N \alpha_k \phi(y_j|\theta)}</script></li>
<li><p>M步：计算新一轮迭代的模型参数
$\hat mu_k, \hat \sigma_k^2, \hat \alpha_k$</p>
</li>
<li><p>重复2、3直到收敛</p>
</li>
</ol>
<blockquote>
<ul>
<li>GMM模型的参数估计的EM算法非常类似K-Means算法<blockquote>
<ul>
<li>E步类似于K-Means中计算各点和各聚类中心之间距离，不过
 K-Means将点归类为离其最近类，而EM算法则是算期望</li>
<li>M步根据聚类结果更新聚类中心</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h2 id="GEM"><a href="#GEM" class="headerlink" title="GEM"></a>GEM</h2><h3 id="Maximization-Maximization-Algorithm"><a href="#Maximization-Maximization-Algorithm" class="headerlink" title="Maximization-Maximization Algorithm"></a><em>Maximization-Maximization Algorithm</em></h3><h4 id="Free-Energy函数"><a href="#Free-Energy函数" class="headerlink" title="Free Energy函数"></a><em>Free Energy</em>函数</h4><blockquote>
<ul>
<li>假设隐变量数据Z的概率分布为$\tilde P(Z)$，定义分布
  $\tilde P$与参数$\theta$的函数$F(\tilde P, \theta)$如下<script type="math/tex; mode=display">
  F(\tilde P, \theta) = E_{\tilde P}
      [log P(Y,Z|\theta)] + H(\tilde P)</script></li>
</ul>
<blockquote>
<ul>
<li>$H(\tilde P)=-E_{\tilde P} log \tilde P(Z)$：分布
   $\tilde P(Z)$的熵</li>
<li>通常假设$P(Y,Z|\theta)$是$\theta$的连续函数，则函数
   $F(\tilde P,\theta)$是$\tilde P, \theta$的连续函数</li>
</ul>
</blockquote>
</blockquote>
<h4 id="定理1-1"><a href="#定理1-1" class="headerlink" title="定理1"></a>定理1</h4><blockquote>
<ul>
<li>对于固定$\theta$，存在唯一分布$\tilde P<em>\theta$，极大化
  $F(\tilde P, \theta)$，这时$\tilde P</em>\theta$由下式给出<script type="math/tex; mode=display">
  \tilde P_\theta(Z) = P(Z|Y,\theta)</script>  并且$\tilde P_{\theta}$随$\theta$连续变化</li>
</ul>
</blockquote>
<ul>
<li><p>对于固定的$\theta$，求使得$F(\tilde P, \theta)$的极大，
构造Lagrange函数</p>
<script type="math/tex; mode=display">
L(\tilde P, \lambda, \mu) = F(\tilde P, \theta) +
   \lambda(1 - \sum_Z \tilde P(Z)) - \mu \tilde P(Z)</script><p>因为$\tilde P(Z)$是概率密度，自然包含两个约束</p>
<script type="math/tex; mode=display">\left \{ \begin{array}{l}
\sum_Z \tilde P(Z) = 1 \\
\tilde P(Z) \geq 0
\end{array} \right.</script><p>即Lagrange方程中后两项</p>
</li>
<li><p>对$\tilde P(Z)$求偏导，得</p>
<script type="math/tex; mode=display">
\frac {\partial L} {\partial \tilde P(Z)} =
   log P(Y,Z|\theta) - log \tilde P(Z) - \lambda - \mu</script><p>令偏导为0，有</p>
<script type="math/tex; mode=display">\begin{align*}
log P(Y,Z|\theta) - log \tilde P(Z) & = \lambda + \mu \\
\frac {P(Y,Z|\theta)} {\tilde P(Z)} & = e^{\lambda + \mu}
\end{align*}</script></li>
<li><p>则使得$F(\tilde P, \theta)$极大的$\tilde P_\theta(Z)$
应该和$P(Y,Z|\theta)$成比例，由概率密度自然约束有</p>
<script type="math/tex; mode=display">\tilde P_\theta(Z) = P(Y,Z|\theta)</script><p>而由假设条件，$P(Y,Z|\theta)$是$\theta$的连续函数</p>
</li>
</ul>
<blockquote>
<ul>
<li><p>这里概率密度函数$\tilde P(Z)$是作为自变量出现</p>
</li>
<li><p>理论上对$\tilde P(Z)$和一般的<strong>复合函数求导</strong>没有区别，
  但$E_{\tilde P}, \sum_Z$使得整体看起来非常不和谐</p>
<script type="math/tex; mode=display">\begin{align*}
  E_{\tilde P} f(Z) & = \sum_Z f(Z) \tilde P(Z) \\
  & = \int f(Z) d(\tilde P(Z))
  \end{align*}</script></li>
</ul>
</blockquote>
<h4 id="定理2-1"><a href="#定理2-1" class="headerlink" title="定理2"></a>定理2</h4><blockquote>
<ul>
<li>若$\tilde P_\theta(Z) = P(Z|Y, \theta)$，则<script type="math/tex; mode=display">
  F(\tilde P, \theta) = log P(Y|\theta)</script></li>
</ul>
</blockquote>
<h4 id="定理3"><a href="#定理3" class="headerlink" title="定理3"></a>定理3</h4><blockquote>
<ul>
<li>设$L(\theta)=log P(Y|\theta)$为观测数据的对数似然函数，
  $\theta^{(i)}, i=1,2,\cdots$为EM算法得到的参数估计序列，
  函数$F(\tilde P,\theta)$如上定义<blockquote>
<ul>
<li>若$F(\tilde P,\theta)$在$\tilde P^{<em>}, \theta^{</em>}$
 上有局部极大值，则$L(\theta)$在$\theta^{*}$也有局部
 最大值</li>
<li>若$F(\tilde P,\theta)$在$\tilde P^{<em>}, \theta^{</em>}$
 达到全局最大，则$L(\theta)$在$\theta^{*}$也达到全局
 最大</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<ul>
<li><p>由定理1、定理2有</p>
<script type="math/tex; mode=display">
L(\theta) = logP(Y|\theta) = F(\tilde P_\theta, \theta)</script><p>特别的，对于使$F(\tilde P,\theta)$极大$\theta^{8}$有</p>
<script type="math/tex; mode=display">
L(\theta^{*}) = logP(Y|\theta^{*}) =
   F(\tilde P_\theta^{*}, \theta{*})</script></li>
<li><p>由$\tilde P_\theta$关于$\theta$连续，局部点域内不存在点
$\theta^{<strong>}$使得$L(\theta^{</strong>}) &gt; L(\theta^{<em>})$，否则
与$F(\tilde P, \theta^{</em>})$矛盾</p>
</li>
</ul>
<h4 id="定理4"><a href="#定理4" class="headerlink" title="定理4"></a>定理4</h4><blockquote>
<ul>
<li>EM算法的依次迭代可由F函数的极大-极大算法实现</li>
<li>设$\theta^{(i)}$为第i次迭代参数$\theta$的估计，
  $\tilde P^{(i)}$为第i次迭代参数$\tilde P$的估计，在第
  i+1次迭代的两步为<blockquote>
<ul>
<li>对固定的$\theta^{(i)}$，求$\tilde P^{(i)}$使得
 $F(\tilde P, \theta^{(i)})$极大</li>
<li>对固定的$\tilde P^{(i+1)}$，求$\theta^{(i+1)}$使
 $F(\tilde P^{(t+1)}, \theta)$极大化</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<ul>
<li><p>固定$\theta^{(i)}$</p>
<script type="math/tex; mode=display">\begin{align*}
F(\tilde P^{(i+1)}, \theta^{(i)} & = E_{\tilde P^{(t+1)}}
   [log P(Y,Z|\theta)] + H(\tilde P^{(i+1)}) \\
& = \sum_Z log P(Y,Z|\theta) P(Z|Y,\theta^{(i)}) +
   H(\tilde P^{(i+1)}) \\
& = Q(\theta, \theta^{(i)}) + H(\tilde P^{(i+1)})
\end{align*}</script></li>
<li><p>则固定$\tilde P^{(i+1)}$求极大同EM算法M步</p>
</li>
</ul>
<h3 id="GEM算法"><a href="#GEM算法" class="headerlink" title="GEM算法"></a>GEM算法</h3><blockquote>
<ul>
<li>输入：观测数据，F函数</li>
<li>输出：模型参数</li>
</ul>
</blockquote>
<ol>
<li><p>初始化$\theta^{(0)}$，开始迭代</p>
</li>
<li><p>第i+1次迭代：记$\theta^{(i)}$为参数$\theta$的估计值，
$\tilde P^{(i)}$为函数$\tilde P$的估计，求
$\tilde P^{(t+1)}$使$\tilde P$极大化$F(\tilde P,\theta)$</p>
</li>
<li><p>求$\theta^{(t+1)}$使$F(\tilde P^{(t+1)l}, \theta)$极大化</p>
</li>
<li><p>重复2、3直到收敛</p>
</li>
</ol>
<h3 id="次优解代替最优解"><a href="#次优解代替最优解" class="headerlink" title="次优解代替最优解"></a>次优解代替最优解</h3><blockquote>
<ul>
<li>输入：观测数据，Q函数</li>
<li>输出：模型参数</li>
</ul>
</blockquote>
<ol>
<li><p>初始化参数$\theta^{(0)}$，开始迭代</p>
</li>
<li><p>第i+1次迭代，记$\theta^{(i)}$为参数$\theta$的估计值，
计算</p>
<script type="math/tex; mode=display">\begin{align*}
Q(\theta, \theta^{(i)}) & = E_Z [
  log P(Y,Z|\theta)|Y,\theta^{(i)}] \\
& = \sum_Z P(Z|Y, \theta^{(i)}) log P(Y,Z|\theta)
\end{align*}</script></li>
<li><p>求$\theta^{(i+1)}$使</p>
<script type="math/tex; mode=display">
Q(\theta^{(i+1)}, \theta^{(i)}) >
  Q(\theta^{(i)}, \theta^{(i)})</script></li>
<li><p>重复2、3直到收敛</p>
</li>
</ol>
<blockquote>
<ul>
<li>有时候极大化$Q(\theta, \theta^{(i)})$非常困难，此算法
  仅寻找使目标函数值上升方向</li>
</ul>
</blockquote>
<h3 id="ADMM求次优解"><a href="#ADMM求次优解" class="headerlink" title="ADMM求次优解"></a>ADMM求次优解</h3><blockquote>
<ul>
<li>输入：观测数据，Q函数</li>
<li>输出：函数模型</li>
</ul>
</blockquote>
<ol>
<li><p>初始化参数
$\theta^{(0)} = (\theta_1^{(0)},…,\theta_d^{(0)})$，
开始迭代</p>
</li>
<li><p>第i次迭代，记
$\theta^{(i)} = (\theta_1^{(i)},…,\theta_d^{(i)})$，
为参数$\theta = (\theta_1,…,\theta_d)$的估计值，计算</p>
<script type="math/tex; mode=display">\begin{align*}
Q(\theta, \theta^{(i)}) & = E_Z [
  log P(Y,Z|\theta)|Y,\theta^{(i)}] \\
& = \sum_Z P(Z|Y, \theta^{(i)}) log P(Y,Z|\theta)
\end{align*}</script></li>
<li><p>进行d次条件极大化</p>
<ol>
<li><p>在$\theta<em>1^{(i)},…,\theta</em>{j-1}^{(i)},\theta_{j+1}^{(i)},…,\theta_d^{(i)}$
保持不变条件下
，求使$Q(\theta, \theta^{(i)})$达到极大的
$\theta_j^{(i+1)}$</p>
</li>
<li><p>j从1到d，进行d次条件极大化的，得到
$\theta^{(i+1)} = (\theta_1^{(i+1)},…,\theta_d^{(i+1)})$
使得</p>
<script type="math/tex; mode=display">
Q(\theta^{(i+1)}, \theta^{(i)}) >
Q(\theta^{(i)}, \theta^{(i)})</script></li>
</ol>
</li>
<li><p>重复2、3直到收敛</p>
</li>
</ol>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5385776267343559" data-ad-slot="6995841235" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="https://api.follow.it/subscription-form/WWxwMVBsOUtoNTdMSlJ4Z1lWVnRISERsd2t6ek9MeVpEUWs0YldlZGxUdXlKdDNmMEZVV1hWaFZFYWFSNmFKL25penZodWx3UzRiaVkxcnREWCtOYUJhZWhNbWpzaUdyc1hPangycUh5RTVjRXFnZnFGdVdSTzZvVzJBcTJHKzl8aXpDK1ROWWl4N080YkFEK3QvbEVWNEJuQjFqdWdxODZQcGNoM1NqbERXST0=/8" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>