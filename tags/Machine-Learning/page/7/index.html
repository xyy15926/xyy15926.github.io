<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: Machine Learning - UBeaRLy</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="UBeaRLy"><meta property="og:url" content="https://xyy15926.github.io/"><meta property="og:site_name" content="UBeaRLy"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:author" content="UBeaRLy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io"},"headline":"UBeaRLy","image":["https://xyy15926.github.io/img/og_image.png"],"author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"UBeaRLy","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":""}</script><link rel="alternate" href="/atom.xml" title="UBeaRLy" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Machine Learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-13T04:03:12.000Z" title="7/13/2019, 12:03:12 PM">2019-07-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T08:10:12.000Z" title="7/16/2021, 4:10:12 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Specification/">ML Specification</a><span> / </span><a class="link-muted" href="/categories/ML-Specification/Computer-Vision/">Computer Vision</a></span><span class="level-item">4 minutes read (About 543 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Specification/Computer-Vision/corner_point_detection.html">角点检测特征提取</a></h1><div class="content"><h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><blockquote>
<ul>
<li><em>corner point</em>：角点，邻域各方向上灰度变化值足够高的点，
  是图像边缘曲线上曲率极大值的点</li>
</ul>
</blockquote>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul>
<li><p>基于灰度图像的角点检测</p>
<ul>
<li>基于梯度：计算边缘曲率判断角点</li>
<li>基于模板：考虑像素邻域点的灰度变化，将领域点亮度对比
足够大的点定义为角点</li>
<li>基于模板、梯度组合</li>
</ul>
</li>
<li><p>基于二值图像的角点检测：将二值图像作为单独的检测目标，
可使用各种基于灰度图像的角点检测方法</p>
</li>
<li><p>基于轮廓曲线的角点检测：通过角点强度、曲线曲率提取角点</p>
</li>
</ul>
<h3 id="思想、步骤"><a href="#思想、步骤" class="headerlink" title="思想、步骤"></a>思想、步骤</h3><ul>
<li><p>使用角点检测算子，对图像每个像素计算
<em>cornner response function</em>值</p>
<script type="math/tex; mode=display">
E(u, v) = \sum_{(x,y)} w(x,y)[I(x+u, y+v) - I(x,y)]^2</script><blockquote>
<ul>
<li>$w(x,y)$：<em>window function</em>，窗口函数</li>
<li>$I(x,y)$：图像梯度</li>
<li>$E(x,y)$：角点响应函数，体现灰度变化剧烈程度，变化
 程度剧烈则窗口中心就是角点</li>
</ul>
</blockquote>
</li>
<li><p>阈值化角点响应函数值    </p>
<ul>
<li>根据实际情况选择阈值$T$</li>
<li>小于阈值$T$者设置为0</li>
</ul>
</li>
<li><p>在窗口范围内对角点响应函数值进行非极大值抑制</p>
<ul>
<li>窗口内非响应函数值极大像素点置0</li>
</ul>
</li>
<li><p>获取非零点作为角点</p>
</li>
</ul>
<h2 id="Moravec"><a href="#Moravec" class="headerlink" title="Moravec"></a><em>Moravec</em></h2><h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ul>
<li><p>取偏移量$(\Delta x, \Delta y)$为
$(1,0), (1,1), (0,1), (-1,1)$，分别计算每个像素点灰度
变化</p>
</li>
<li><p>对每个像素点(x_i, y_i)$计算角点响应函数
$R(x) = min {E}$</p>
</li>
<li><p>设定阈值$T$，小于阈值者置0</p>
</li>
<li><p>进行非极大值抑制，选择非0点作为角点检测结果</p>
</li>
</ul>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>二值窗口函数：角点响应函数不够光滑</li>
<li>只在4个方向（偏移量）上计算灰度值变化：角点响应函数会在
多处都有较大响应值</li>
<li>对每个点只考虑响应函数值最小值：算法对边缘敏感</li>
</ul>
<h2 id="Harris"><a href="#Harris" class="headerlink" title="Harris"></a><em>Harris</em></h2><h2 id="Good-Features-to-Track"><a href="#Good-Features-to-Track" class="headerlink" title="Good Features to Track"></a><em>Good Features to Track</em></h2><h2 id="Feature-from-Accelerated-Segment-Test"><a href="#Feature-from-Accelerated-Segment-Test" class="headerlink" title="Feature from Accelerated Segment Test"></a><em>Feature from Accelerated Segment Test</em></h2><p><em>FAST</em>：加速分割测试获得特征</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-13T04:03:12.000Z" title="7/13/2019, 12:03:12 PM">2019-07-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T08:35:29.000Z" title="7/16/2021, 4:35:29 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Specification/">ML Specification</a><span> / </span><a class="link-muted" href="/categories/ML-Specification/NLP/">NLP</a></span><span class="level-item">4 minutes read (About 555 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Specification/NLP/abstract.html">NLP 总述</a></h1><div class="content"><h2 id="文本挖掘"><a href="#文本挖掘" class="headerlink" title="文本挖掘"></a>文本挖掘</h2><ul>
<li><p>文本处理：将非结构化数据转换为结构化数据</p>
</li>
<li><p>预测建模</p>
<ul>
<li>文本分类：根据观察到的对象特征值预测其他特征值</li>
</ul>
</li>
<li><p>描述建模</p>
<ul>
<li>文本聚类：对数据对象进行概括，以看到数据对象的最重要
特征<ul>
<li>适应范围非常广</li>
</ul>
</li>
<li>聚类分析</li>
</ul>
</li>
<li><p>基于相似度方法</p>
<ul>
<li>需要用户显式指定相似度函数</li>
<li>聚类算法根据相似度的计算结果将相似文本分在同一个组</li>
<li>每个文本只能属于一个组，因此也成为“硬聚类”</li>
</ul>
</li>
<li><p>基于模型的方法</p>
<ul>
<li>文本有多个标签，也成为“软聚类”</li>
</ul>
</li>
</ul>
<h2 id="话题检测"><a href="#话题检测" class="headerlink" title="话题检测"></a>话题检测</h2><p>找出文档中的K个话题，计算每个文档对话题的覆盖率</p>
<h3 id="话题表示方法"><a href="#话题表示方法" class="headerlink" title="话题表示方法"></a>话题表示方法</h3><h4 id="基于单个词"><a href="#基于单个词" class="headerlink" title="基于单个词"></a>基于单个词</h4><h4 id="基于词分布"><a href="#基于词分布" class="headerlink" title="基于词分布"></a>基于词分布</h4><h5 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h5><blockquote>
<ul>
<li>输入<blockquote>
<ul>
<li>N个文档构成的文本集C</li>
<li>话题个数K</li>
<li>词典V</li>
</ul>
</blockquote>
</li>
<li>输出<blockquote>
<ul>
<li>K个话题的分布
 $(\theta_1, \theta2, \cdots, \theta_K)$</li>
<li>N个文档在K个话题上的概率分布
 $(\pi_1, \pi_2, \cdots, \pi_N)$</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p>词向量：将向量表示词</p>
<ul>
<li><p><em>1-of-N representation</em>/<em>one hot representation</em>：one-hot
表示词</p>
<p><img src="/imgs/word_vector_one_hot.png" alt="word_vector"></p>
<ul>
<li>词向量维度为整个词汇表大小</li>
<li>简单、效率不高</li>
</ul>
</li>
<li><p><em>distributed representation</em>：embedding思想，通过训练，
将词映射到较短词向量中</p>
<p><img src="/imgs/word_vector_embedding.png" alt="word_vector"></p>
<ul>
<li>词向量维度自定义</li>
<li>容易分析词之间关系</li>
</ul>
</li>
</ul>
<h3 id="Continuous-Bag-of-Words"><a href="#Continuous-Bag-of-Words" class="headerlink" title="Continuous Bag-of-Words"></a>Continuous Bag-of-Words</h3><p><em>CBOW</em>：输入特征词上下文相关词对应词向量，输出特征词的词向量</p>
<ul>
<li>CBOW使用词袋模型<ul>
<li>特征词上下文相关从平等，不考虑和关注的词之间的距离</li>
</ul>
</li>
</ul>
<h3 id="Skip-Gram"><a href="#Skip-Gram" class="headerlink" title="Skip-Gram"></a>Skip-Gram</h3><p><em>Skip-Gram</em>：输入特征词词向量，输出softmax概率靠前的词向量</p>
<h2 id="神经网络词向量"><a href="#神经网络词向量" class="headerlink" title="神经网络词向量"></a>神经网络词向量</h2><p>神经网络词向量：使用神经网络训练词向量</p>
<ul>
<li><p>一般包括三层：输入层、隐层、输出softmax层</p>
</li>
<li><p>从隐藏层到输出softmax层计算量很大</p>
<ul>
<li>需要计算所有词的softmax概率，再去找概率最大值</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-13T04:03:12.000Z" title="7/13/2019, 12:03:12 PM">2019-07-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T08:44:53.000Z" title="7/16/2021, 4:44:53 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Specification/">ML Specification</a><span> / </span><a class="link-muted" href="/categories/ML-Specification/NLP/">NLP</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Specification/NLP/rnn_language_models.html">RNN 语言模型</a></h1><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-10T16:51:41.000Z" title="7/11/2019, 12:51:41 AM">2019-07-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-19T01:01:22.000Z" title="7/19/2021, 9:01:22 AM">2021-07-19</time></span><span class="level-item"><a class="link-muted" href="/categories/Database/">Database</a><span> / </span><a class="link-muted" href="/categories/Database/Spark/">Spark</a></span><span class="level-item">6 minutes read (About 869 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Database/Spark/spark_mllib.html">Spark MLLib</a></h1><div class="content"><h2 id="MLLib"><a href="#MLLib" class="headerlink" title="MLLib"></a>MLLib</h2><p><em>Spark MLLib</em>：Spark平台的机器学习库</p>
<ul>
<li><p>能直接操作RDD数据集，可以和其他BDAS其他组件无缝集成，
使得在全量数据上进行学习成为可能</p>
</li>
<li><p>实现包括以下算法</p>
<ul>
<li>Classification</li>
<li>Regression</li>
<li>Clustering</li>
<li>Collaborative Filtering</li>
<li>Dimensionality Reduction</li>
</ul>
</li>
<li><p>MLLib是MLBase中的一部分</p>
<ul>
<li>MLLib</li>
<li>MLI</li>
<li>MLOptimizer</li>
<li>MLRuntime</li>
</ul>
</li>
<li><p>从Spark1.2起被分为两个模块</p>
<ul>
<li><code>spark.mllib</code>：包含基于RDD的原始算法API</li>
<li><code>spark.ml</code>：包含基于DataFrame的高层次API<ul>
<li>可以用于构建机器学习PipLine</li>
<li>ML PipLine API可以方便的进行数据处理、特征转换、
正则化、联合多个机器算法，构建单一完整的机器学习
流水线</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>MLLib算法代码可以在<code>examples</code>目录下找到，数据则在<code>data</code>
  目录下</li>
<li>机器学习算法往往需要多次迭代到收敛为止，Spark内存计算、
  DAG执行引擎象相较MapReduce更理想</li>
<li>由于Spark核心模块的高性能、通用性，Mahout已经放弃
  MapReduce计算模型，选择Spark作为执行引擎</li>
</ul>
</blockquote>
<h2 id="mllib-classification"><a href="#mllib-classification" class="headerlink" title="mllib.classification"></a><code>mllib.classification</code></h2><h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><h4 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.classification <span class="keyword">import</span> \</span><br><span class="line">	LogisticRegressionWithLBFGS, LogisticRegressionModel</span><br><span class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabledPoint</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_point</span>(<span class="params">line</span>):</span></span><br><span class="line">	value = [<span class="built_in">float</span>(i) <span class="keyword">for</span> i line.split(<span class="string">&quot;, \r\n\t&quot;</span>)</span><br><span class="line"></span><br><span class="line">data = sc.textFile(<span class="string">&quot;data/mllib/sample_svm_data.txt&quot;</span>)</span><br><span class="line">parsed_data = data.<span class="built_in">map</span>(parse_point)</span><br><span class="line">	<span class="comment"># map `parse_point` to all data</span></span><br><span class="line"></span><br><span class="line">model = LogisticRegressionWithLBFGS.train(parsed_data)</span><br><span class="line">labels_and_preds = parsed_data.<span class="built_in">map</span>(<span class="keyword">lambda</span> p: (p.label, model.predict(p.features)))</span><br><span class="line">train_err = labels_and_preds \</span><br><span class="line">	.<span class="built_in">filter</span>(<span class="keyword">lambda</span> lp: lp[<span class="number">0</span>] != lp[<span class="number">1</span>]) \</span><br><span class="line">	.count() / <span class="built_in">float</span>(parsed_data.count())</span><br><span class="line"></span><br><span class="line">model.save(sc, <span class="string">&quot;model_path&quot;</span>)</span><br><span class="line">same_model = LogisticRegressionModel.load(sc, <span class="string">&quot;model.path&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>Decision Tree</li>
<li>Random Forest</li>
<li>Gradient</li>
<li>boosted tree</li>
<li>Multilaye Perceptron</li>
<li>Support Vector Machine</li>
<li>One-vs-Rest Classifier</li>
<li>Naive Bayes</li>
</ul>
<h3 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h3><h4 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pyspark.mllib.clustering <span class="keyword">import</span> KMeans, KMeansModel</span><br><span class="line"></span><br><span class="line">data = sc.textFile(<span class="string">&quot;data/mllib/kmeans_data.txt&quot;</span>)</span><br><span class="line">parsed_data = data.<span class="built_in">map</span>(<span class="keyword">lambda</span> line: np.array([<span class="built_in">float</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> line.split()]))</span><br><span class="line"></span><br><span class="line">cluster_model = KMeans.train(</span><br><span class="line">	parsed_data,</span><br><span class="line">	maxIteration=<span class="number">10</span>,</span><br><span class="line">	initializationMode=<span class="string">&quot;random&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">error</span>(<span class="params">point</span>):</span></span><br><span class="line">	center = cluster_model.centers[cluster.predict(point)]</span><br><span class="line">	<span class="keyword">return</span> np.sqrt(<span class="built_in">sum</span>([i**<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> (point - center)]))</span><br><span class="line">WSSSE = parsed_data \</span><br><span class="line">	.<span class="built_in">map</span>(<span class="keyword">lambda</span> point.error(point)) \</span><br><span class="line">	.reduce(lambd x, y: x + y)</span><br><span class="line"></span><br><span class="line">cluster_model.save(sc, <span class="string">&quot;model_path&quot;</span>)</span><br><span class="line">same_model = KMeansModel.load(sc, <span class="string">&quot;model_path&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Gaussian-Mixture-Model-GMM"><a href="#Gaussian-Mixture-Model-GMM" class="headerlink" title="Gaussian Mixture Model(GMM)"></a>Gaussian Mixture Model(GMM)</h4><ul>
<li>混合密度模型<ul>
<li>有限混合模型：正态分布混合模型可以模拟所有分布</li>
<li>迪利克莱混合模型：类似于泊松过程</li>
</ul>
</li>
<li>应用<ul>
<li>聚类：检验聚类结果是否合适</li>
<li>预测：<h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1></li>
</ul>
</li>
</ul>
<figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from pyspark.mllib.clustering import GussianMixture, \</span><br><span class="line"><span class="code">	GussianMixtureModel</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">data = sc.textFile(&quot;data/mllib/gmm<span class="emphasis">_data.txt&quot;)</span></span><br><span class="line"><span class="emphasis">parsed_</span>data = data.map(lambda line: np.array[float(i) for i in line.strip()]))</span><br><span class="line"></span><br><span class="line">gmm = GaussianMixture.train(parsed<span class="emphasis">_data, 2)</span></span><br><span class="line"><span class="emphasis">for w, g in zip(gmm.weights, gmm.gaussians):</span></span><br><span class="line"><span class="emphasis">	print(&quot;weight = &quot;, w,</span></span><br><span class="line"><span class="emphasis">		&quot;mu = &quot;, g.mu,</span></span><br><span class="line"><span class="emphasis">		&quot;sigma = &quot;, g.sigma.toArray())</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">gmm.save(sc, &quot;model_</span>path&quot;)</span><br><span class="line">same<span class="emphasis">_model = GussainMixtureModel.load(sc, &quot;model_</span>path&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="Latent-Dirichlet-Allocation-LDA"><a href="#Latent-Dirichlet-Allocation-LDA" class="headerlink" title="Latent Dirichlet Allocation(LDA)"></a>Latent Dirichlet Allocation(LDA)</h4><figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.mllib.clustering import LDA, LDAModel</span><br><span class="line">from pyspark.mllib.linalg import Vectors</span><br><span class="line"></span><br><span class="line">data = sc.textFile(&quot;data/mllib/sample<span class="emphasis">_lda_</span>data.txt&quot;)</span><br><span class="line">parsed<span class="emphasis">_data = data.map(lambda line: Vector.dense([float(i) for i in line.strip()]))</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">corpus = parsed_</span>data.zipWithIndex() \</span><br><span class="line"><span class="code">	.map(lambda x: [x[1], x[0]).cache()</span></span><br><span class="line"><span class="code">ldaModel = LDA.train(corpus, k=3)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">topics = ldaModel.topicsMatrix()</span><br><span class="line"></span><br><span class="line">for word in range(0, ldaModel.vocabSize()):</span><br><span class="line"><span class="code">	for topic in word:</span></span><br><span class="line"><span class="code">		print(topic)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">ldaModel.save(sc, &quot;model<span class="emphasis">_path&quot;)</span></span><br><span class="line"><span class="emphasis">same_</span>model = LDAModel.load(&quot;model<span class="emphasis">_path&quot;)</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Disecting K-means</li>
</ul>
<h3 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h3><h4 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h4><ul>
<li>耗时长、无法计算解析解（无意义）</li>
<li>使用MSE作为极小化目标函数，使用SGD算法求解</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabledPoint, \</span><br><span class="line">	LinearRegressionWithSGD, LinearRegressionModel</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_point</span>(<span class="params">line</span>):</span></span><br><span class="line">	value = [<span class="built_in">float</span>(i) <span class="keyword">for</span> i line.split(<span class="string">&quot;, \r\n\t&quot;</span>)</span><br><span class="line"></span><br><span class="line">data = sc.textFile(<span class="string">&quot;data/mllib/ridge-data/lpsa.data&quot;</span>)</span><br><span class="line">parsed_data = data.<span class="built_in">map</span>(parse_point)</span><br><span class="line">	<span class="comment"># map `parse_point` to all data</span></span><br><span class="line"></span><br><span class="line">model = LinearRegressionWithSGD.train(</span><br><span class="line">	parsed_data,</span><br><span class="line">	iteration=<span class="number">100</span>,</span><br><span class="line">	step=<span class="number">0.00000001</span></span><br><span class="line">)</span><br><span class="line">values_and_preds = parsed_data.<span class="built_in">map</span>(<span class="keyword">lambda</span> p:(p.label, model.predict(p.features)))</span><br><span class="line">MSE = values_and_preds \</span><br><span class="line">	.<span class="built_in">map</span>(<span class="keyword">lambda</span> vp: (vp[<span class="number">0</span>] - vp[<span class="number">1</span>]) ** <span class="number">2</span>) \</span><br><span class="line">	.reduce(<span class="keyword">lambda</span> x, y: x + y) / values_and_preds.count()</span><br><span class="line"></span><br><span class="line">model.save(sc, <span class="string">&quot;model_path&quot;</span>)</span><br><span class="line">	<span class="comment"># save model</span></span><br><span class="line">same_model = LinearRegressionModel.load(sc, <span class="string">&quot;model_path&quot;</span>)</span><br><span class="line">	<span class="comment"># load saved model</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Generalized Linear Regression</li>
<li>Decision Tree Regression</li>
<li>Random Forest Regression</li>
<li>Gradient-boosted Tree Regression</li>
<li>Survival Regression</li>
<li>Isotonic Regression</li>
</ul>
<h3 id="Collaborative-Filtering"><a href="#Collaborative-Filtering" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h3></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-21T09:27:37.000Z" title="3/21/2019, 5:27:37 PM">2019-03-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-02-17T03:57:07.000Z" title="2/17/2019, 11:57:07 AM">2019-02-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a><span> / </span><a class="link-muted" href="/categories/Python/Keras/">Keras</a></span><span class="level-item">37 minutes read (About 5531 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Python/Keras/backend.html">Keras 后端</a></h1><div class="content"><h2 id="Keras后端"><a href="#Keras后端" class="headerlink" title="Keras后端"></a>Keras后端</h2><p>Keras是一个模型级的库，提供了快速构建深度学习网络的模块</p>
<ul>
<li><p>Keras并不处理如张量乘法、卷积等底层操作，而是依赖于某种
特定的、优化良好的张量操作库</p>
</li>
<li><p>Keras依赖于处理张量的库就称为“后端引擎”</p>
<ul>
<li>[Theano][Theano]：开源的符号主义张量操作框架，由
蒙特利尔大学LISA/MILA实验室开发</li>
<li>[Tensorflow][Tensorflow]：符号主义的张量操作框架，
由Google开发</li>
<li>[CNTK][CNTK]：由微软开发的商业级工具包</li>
</ul>
</li>
<li><p>Keras将其函数统一封装，使得用户可以以同一个接口调用不同
后端引擎的函数</p>
</li>
</ul>
<ul>
<li>[Theano]: <a target="_blank" rel="noopener" href="http://deeplearning.net/software/theano/">http://deeplearning.net/software/theano/</a></li>
<li>[TensorFlow]: <a target="_blank" rel="noopener" href="http://www.tensorflow.org/">http://www.tensorflow.org/</a></li>
<li>[CNTK]: <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/cognitive-toolkit/">https://www.microsoft.com/en-us/cognitive-toolkit/</a></li>
</ul>
<h3 id="切换后端"><a href="#切换后端" class="headerlink" title="切换后端"></a>切换后端</h3><ul>
<li>修改Keras配置文件</li>
<li>定义环境变量<code>KERAS_BACKEND</code>覆盖配置文件中设置（见python
修改环境变量的3中方式）</li>
</ul>
<h3 id="Keras后端抽象"><a href="#Keras后端抽象" class="headerlink" title="Keras后端抽象"></a>Keras后端抽象</h3><p>可以通过Keras后端接口来编写代码，使得Keras模块能够同时在
Theano和TensorFlow两个后端上使用</p>
<ul>
<li>大多数张量操作都可以通过统一的Keras后端接口完成，不必
关心具体执行后端</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = K.placeholder(shape=(<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="built_in">input</span> = K.placeholder(shape=(<span class="literal">None</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="built_in">input</span> = K.placeholder(ndim=<span class="number">3</span>)</span><br><span class="line">	<span class="comment"># 实例化输出占位符</span></span><br><span class="line"></span><br><span class="line">val = np.random.random((<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">var = K.variable(value=val)</span><br><span class="line">	<span class="comment"># 实例化共享变量</span></span><br><span class="line">	<span class="comment"># 等价于`tf.Variable`、`theano.shared`</span></span><br><span class="line">var = K.zeros(shape=(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">var = K.ones(shape=(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br></pre></td></tr></table></figure>
<h2 id="配置相关函数"><a href="#配置相关函数" class="headerlink" title="配置相关函数"></a>配置相关函数</h2><h3 id="backend"><a href="#backend" class="headerlink" title="backend"></a><code>backend</code></h3><p>返回当前后端</p>
<h3 id="epsilon"><a href="#epsilon" class="headerlink" title="epsilon"></a><code>epsilon</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.epsilon()</span><br></pre></td></tr></table></figure>
<p>返回数字表达式使用<em>fuzz factor</em></p>
<h3 id="set-epsilon"><a href="#set-epsilon" class="headerlink" title="set_epsilon"></a><code>set_epsilon</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.set_epsilon(e(<span class="built_in">float</span>))</span><br></pre></td></tr></table></figure>
<p>设置模糊因子的值</p>
<h3 id="floatx"><a href="#floatx" class="headerlink" title="floatx"></a><code>floatx</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.floatx()</span><br></pre></td></tr></table></figure>
<p>返回默认的浮点数数据类型</p>
<ul>
<li><code>float16</code></li>
<li><code>float32</code></li>
<li><code>float64</code></li>
</ul>
<h3 id="set-floatx"><a href="#set-floatx" class="headerlink" title="set_floatx"></a><code>set_floatx</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">K.set_floatx(</span><br><span class="line">	floatx=<span class="string">&quot;float16&quot;</span>/<span class="string">&quot;float32&quot;</span>/<span class="string">&quot;float64&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>设置默认的浮点数数据类型（字符串表示）</p>
<h3 id="cast-to-floatx"><a href="#cast-to-floatx" class="headerlink" title="cast_to_floatx"></a><code>cast_to_floatx</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.cast_to_floatx(x)</span><br></pre></td></tr></table></figure>
<p>将NDA转换为默认的Keras floatx类型（的NDA）</p>
<ul>
<li><p>例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">K.floatx()</span><br><span class="line">	<span class="comment"># &quot;float32&quot;</span></span><br><span class="line">arr = np.array([<span class="number">1.0</span>, <span class="number">2.0</span>], dtype=<span class="string">&quot;flaot64&quot;</span>)</span><br><span class="line">arr.dtype</span><br><span class="line">	<span class="comment"># &quot;float64&quot;</span></span><br><span class="line">new_arr = K.cast_to_float(arr)</span><br><span class="line">new_arr.dtype</span><br><span class="line">	<span class="comment"># &quot;float32&quot;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="image-data-format"><a href="#image-data-format" class="headerlink" title="image_data_format"></a><code>image_data_format</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.image_data_format()</span><br></pre></td></tr></table></figure>
<p>返回图像的默认维度顺序</p>
<ul>
<li><code>channels_last</code></li>
<li><code>channels_first</code></li>
</ul>
<h3 id="set-image-data-format"><a href="#set-image-data-format" class="headerlink" title="set_image_data_format"></a><code>set_image_data_format</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">K.set_image_data_format(</span><br><span class="line">	data_format=<span class="string">&quot;channel_first&quot;</span>/<span class="string">&quot;channel_last&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>设置图像的默认维度顺序</p>
<h2 id="辅助函数"><a href="#辅助函数" class="headerlink" title="辅助函数"></a>辅助函数</h2><h3 id="is-keras-tensor"><a href="#is-keras-tensor" class="headerlink" title="is_keras_tensor"></a><code>is_keras_tensor</code></h3><p>判断是否是Keras Tensor对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">np_var = np.array([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">K.is_keras_tensor(np_var)</span><br><span class="line">	<span class="comment"># False</span></span><br><span class="line">keras_var = K.variable(np_var)</span><br><span class="line">K.is_keras_tensor(keras_var)</span><br><span class="line">	<span class="comment"># A variable is not a Tensor.</span></span><br><span class="line">	<span class="comment"># False</span></span><br><span class="line">keras_placeholder = K.placeholder(shape=(<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">K.is_keras_tensor(keras_placeholder)</span><br><span class="line">	<span class="comment"># A placeholder is a Tensor.</span></span><br><span class="line">	<span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<h3 id="get-uid"><a href="#get-uid" class="headerlink" title="get_uid"></a><code>get_uid</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.get_uid(prefix=<span class="string">&#x27;&#x27;</span>/<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure>
<p>获得默认计算图的uid</p>
<ul>
<li><p>说明</p>
<ul>
<li>依据给定的前缀提供一个唯一的UID</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>prefix</code>：图的可选前缀</li>
</ul>
</li>
<li><p>返回值：图的唯一标识符</p>
</li>
</ul>
<h3 id="reset-uids"><a href="#reset-uids" class="headerlink" title="reset_uids"></a><code>reset_uids</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.reset_uids()</span><br></pre></td></tr></table></figure>
<p>重置图的标识符</p>
<h3 id="clear-session"><a href="#clear-session" class="headerlink" title="clear_session"></a><code>clear_session</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.clear_session()</span><br></pre></td></tr></table></figure>
<p>结束当前的TF计算图，并创建新图</p>
<ul>
<li>说明<ul>
<li>有效的避免模型/网络层的混乱</li>
</ul>
</li>
</ul>
<h3 id="manual-variable-initialization"><a href="#manual-variable-initialization" class="headerlink" title="manual_variable_initialization"></a><code>manual_variable_initialization</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">K.manual_variable_initialization(</span><br><span class="line">	value=<span class="literal">False</span>/<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>设置变量手动初始化标志</p>
<ul>
<li><p>参数</p>
<ul>
<li><p><code>value</code></p>
<ul>
<li><p><code>False</code>：默认，变量在实例时出事的（由其默认值
初始化）</p>
</li>
<li><p><code>True</code>：用户自行初始化，如
<code>tf.initialize_all_variables()</code></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="learning-phase"><a href="#learning-phase" class="headerlink" title="learning_phase"></a><code>learning_phase</code></h4><p>返回学习阶段标致</p>
<ul>
<li><p>返回值：布尔张量</p>
<ul>
<li><code>0</code>：测试模式</li>
<li><code>1</code>：训练模式</li>
</ul>
</li>
</ul>
<h4 id="set-learning-phase"><a href="#set-learning-phase" class="headerlink" title="set_learning_phase"></a><code>set_learning_phase</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">K.set_learning_phase(</span><br><span class="line">	value=<span class="number">0</span>/<span class="number">1</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>设置学习阶段为固定值</p>
<ul>
<li>参数<ul>
<li><code>value</code>：学习阶段值<ul>
<li><code>0</code>：测试模式</li>
<li><code>1</code>：训练模式</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="OPs、Tensors"><a href="#OPs、Tensors" class="headerlink" title="OPs、Tensors"></a>OPs、Tensors</h3><h4 id="is-sparse"><a href="#is-sparse" class="headerlink" title="is_sparse"></a><code>is_sparse</code></h4><p>判断一个Tensor是不是一个稀疏的Tensor</p>
<ul>
<li>返回值：布尔值</li>
</ul>
<blockquote>
<p>   稀不稀疏由Tensor的类型决定，而不是Tensor实际上有多稀疏</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">a = K.placeholder((<span class="number">2</span>, <span class="number">2</span>), sparse=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(K.is_sparse(a))</span><br><span class="line">	<span class="comment"># False</span></span><br><span class="line">b = K.placeholder((<span class="number">2</span>, <span class="number">2</span>), sparse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(K.is_sparse(b))</span><br><span class="line">	<span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<h4 id="to-dense"><a href="#to-dense" class="headerlink" title="to_dense"></a><code>to_dense</code></h4><p>将一个稀疏tensor转换一个不稀疏的tensor并返回</p>
<h4 id="variable"><a href="#variable" class="headerlink" title="variable"></a><code>variable</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	value,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="string">&#x27;float32&#x27;</span>/<span class="built_in">str</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>实例化一个张量，返回之</p>
<ul>
<li>参数<ul>
<li><code>value</code>：用来初始化张量的值</li>
<li><code>dtype</code>：张量数据类型</li>
<li><code>name</code>：张量的名字（可选）</li>
</ul>
</li>
</ul>
<h4 id="placeholder"><a href="#placeholder" class="headerlink" title="placeholder"></a><code>placeholder</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">placeholder</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	shape=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	ndim=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="string">&#x27;float32&#x27;</span>/<span class="built_in">str</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>实例化一个占位符</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>shape</code>：占位符的shape（整数tuple，可能包含None）</li>
<li><code>ndim</code>: 占位符张量的阶数<ul>
<li>要初始化占位符，至少指定<code>shape</code>和<code>ndim</code>之一，
如果都指定则使用<code>shape</code></li>
</ul>
</li>
<li><code>dtype</code>: 占位符数据类型</li>
<li><code>name</code>: 占位符名称（可选）</li>
</ul>
</li>
</ul>
<h4 id="shape"><a href="#shape" class="headerlink" title="shape"></a><code>shape</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shape</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>返回张量的<em>符号shape</em></p>
<ul>
<li>返回值：OPs（需要执行才能得到值）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">tf_session = K.get_session()</span><br><span class="line">val = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">kvar = K.variable(value=val)</span><br><span class="line"><span class="built_in">input</span> = keras.backend.placeholder(shape=(<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">K.shape(kvar)</span><br><span class="line">	<span class="comment"># &lt;tf.Tensor &#x27;Shape_8:0&#x27; shape=(2,) dtype=int32&gt;</span></span><br><span class="line">K.shape(<span class="built_in">input</span>)</span><br><span class="line">	<span class="comment"># &lt;tf.Tensor &#x27;Shape_9:0&#x27; shape=(3,) dtype=int32&gt;</span></span><br><span class="line">	<span class="comment"># To get integer shape (Instead, you can use K.int_shape(x))</span></span><br><span class="line">K.shape(kvar).<span class="built_in">eval</span>(session=tf_session)</span><br><span class="line">	<span class="comment"># array([2, 2], dtype=int32)</span></span><br><span class="line">K.shape(<span class="built_in">input</span>).<span class="built_in">eval</span>(session=tf_session)</span><br><span class="line">	<span class="comment"># array([2, 4, 5], dtype=int32)</span></span><br></pre></td></tr></table></figure>
<h4 id="int-shape"><a href="#int-shape" class="headerlink" title="int_shape"></a><code>int_shape</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">int_shape</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>返回张量shape</p>
<ul>
<li>返回值：<code>tuple(int)/None</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="built_in">input</span> = K.placeholder(shape=(<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">K.int_shape(<span class="built_in">input</span>)</span><br><span class="line">	<span class="comment"># (2, 4, 5)</span></span><br><span class="line">val = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">kvar = K.variable(value=val)</span><br><span class="line">K.int_shape(kvar)</span><br><span class="line">	<span class="comment"># (2, 2)</span></span><br></pre></td></tr></table></figure>
<h4 id="ndim"><a href="#ndim" class="headerlink" title="ndim"></a><code>ndim</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ndim</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>返回张量的阶数</p>
<ul>
<li>返回值：int</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="built_in">input</span> = K.placeholder(shape=(<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">val = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">kvar = K.variable(value=val)</span><br><span class="line">K.ndim(<span class="built_in">input</span>)</span><br><span class="line">	<span class="comment"># 3</span></span><br><span class="line">K.ndim(kvar)</span><br><span class="line">	<span class="comment"># 2</span></span><br></pre></td></tr></table></figure>
<h4 id="dtype"><a href="#dtype" class="headerlink" title="dtype"></a><code>dtype</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dtype</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>返回张量的数据类型</p>
<ul>
<li>返回值：str<ul>
<li><code>float32</code></li>
<li><code>float32_ref</code></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">K.dtype(K.placeholder(shape=(<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>)))</span><br><span class="line">	<span class="comment"># &#x27;float32&#x27;</span></span><br><span class="line">K.dtype(K.placeholder(shape=(<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>), dtype=<span class="string">&#x27;float32&#x27;</span>))</span><br><span class="line">	<span class="comment"># &#x27;float32&#x27;</span></span><br><span class="line">K.dtype(K.placeholder(shape=(<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>), dtype=<span class="string">&#x27;float64&#x27;</span>))</span><br><span class="line">	<span class="comment"># &#x27;float64&#x27;__Keras variable__</span></span><br><span class="line"></span><br><span class="line">kvar = K.variable(np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]))</span><br><span class="line">K.dtype(kvar)</span><br><span class="line">	<span class="comment"># &#x27;float32_ref&#x27;</span></span><br><span class="line">kvar = K.variable(np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]), dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">K.dtype(kvar)</span><br><span class="line">	<span class="comment"># &#x27;float32_ref&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="eval"><a href="#eval" class="headerlink" title="eval"></a><code>eval</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>求得张量的值</p>
<ul>
<li>返回值：NDA</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">kvar = K.variable(np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]), dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">K.<span class="built_in">eval</span>(kvar)</span><br><span class="line">	<span class="comment"># array([[ 1.,  2.],</span></span><br><span class="line">	<span class="comment">#	[ 3.,  4.]], dtype=float32)</span></span><br></pre></td></tr></table></figure>
<h4 id="zeros"><a href="#zeros" class="headerlink" title="`zeros"></a>`zeros</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zeros</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	shape,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="string">&#x27;float32&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成<code>shape</code>大小的全0张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">kvar = K.zeros((<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">K.<span class="built_in">eval</span>(kvar)</span><br><span class="line">	<span class="comment"># array([[ 0.,  0.,  0.,  0.],</span></span><br><span class="line">	<span class="comment">#	[ 0.,  0.,  0.,  0.],</span></span><br><span class="line">	<span class="comment">#	[ 0.,  0.,  0.,  0.]], dtype=float32)</span></span><br></pre></td></tr></table></figure>
<h4 id="ones"><a href="#ones" class="headerlink" title="ones"></a><code>ones</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ones</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	shape,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="string">&#x27;float32&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成<code>shape</code>大小的全1张量</p>
<h4 id="eye"><a href="#eye" class="headerlink" title="eye"></a><code>eye</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eye</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	size,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="string">&#x27;float32&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成<code>size</code>大小的单位阵</p>
<h4 id="zeros-like"><a href="#zeros-like" class="headerlink" title="zeros_like"></a><code>zeros_like</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zeros_like</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成与<code>x</code> shape相同的全0张量</p>
<h4 id="ones-like"><a href="#ones-like" class="headerlink" title="ones_like"></a><code>ones_like</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ones_like</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成与<code>x</code> shape相同的全1张量</p>
<h3 id="随机常量OPs"><a href="#随机常量OPs" class="headerlink" title="随机常量OPs"></a>随机常量OPs</h3><h4 id="random-uniform-variable"><a href="#random-uniform-variable" class="headerlink" title="random_uniform_variable"></a><code>random_uniform_variable</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_uniform_variable</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	shape,</span></span></span><br><span class="line"><span class="params"><span class="function">	low,</span></span></span><br><span class="line"><span class="params"><span class="function">	high,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	seed=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>初始化均匀分布常量OPs</p>
<ul>
<li>参数<ul>
<li><code>low</code>：浮点数，均匀分布之下界</li>
<li><code>high</code>：浮点数，均匀分布之上界</li>
<li><code>dtype</code>：数据类型</li>
<li><code>name</code>：张量名</li>
<li><code>seed</code>：随机数种子</li>
</ul>
</li>
</ul>
<h4 id="count-params"><a href="#count-params" class="headerlink" title="count_params"></a><code>count_params</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_params</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>返回张量中标量的个数</p>
<h4 id="cast"><a href="#cast" class="headerlink" title="cast"></a><code>cast</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cast</span>(<span class="params">x, dtype</span>)</span></span><br></pre></td></tr></table></figure>
<p>改变张量的数据类型</p>
<ul>
<li>参数<ul>
<li><code>dtype</code>：<code>float16</code>/<code>float32</code>/<code>float64</code></li>
</ul>
</li>
</ul>
<h4 id="update"><a href="#update" class="headerlink" title="update"></a><code>update</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">x, new_x</span>)</span></span><br></pre></td></tr></table></figure>
<p>用<code>new_x</code>更新<code>x</code></p>
<h4 id="update-add"><a href="#update-add" class="headerlink" title="update_add"></a><code>update_add</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_add</span>(<span class="params">x, increment</span>)</span></span><br></pre></td></tr></table></figure>
<p>将<code>x</code>增加<code>increment</code>并更新<code>x</code></p>
<h4 id="update-sub"><a href="#update-sub" class="headerlink" title="update_sub"></a><code>update_sub</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_sub</span>(<span class="params">x, decrement</span>)</span></span><br></pre></td></tr></table></figure>
<p>将<code>x</code>减少<code>decrement</code>并更新<code>x</code></p>
<h4 id="moving-average-update"><a href="#moving-average-update" class="headerlink" title="moving_average_update"></a><code>moving_average_update</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">moving_average_update</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	value,</span></span></span><br><span class="line"><span class="params"><span class="function">	momentum</span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>使用移动平均更新<code>x</code></p>
<h4 id="dot"><a href="#dot" class="headerlink" title="dot"></a><code>dot</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dot</span>(<span class="params">x, y</span>)</span></span><br></pre></td></tr></table></figure>
<p>求两个张量的点乘</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = K.placeholder(shape=(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">y = K.placeholder(shape=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">xy = K.dot(x, y)</span><br><span class="line">xy</span><br><span class="line">	<span class="comment"># &lt;tf.Tensor &#x27;MatMul_9:0&#x27; shape=(2, 4) dtype=float32&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>当试图计算两个N阶张量的乘积时，与Theano行为相同
<code>(2, 3).(4, 3, 5) = (2, 4, 5))</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = K.placeholder(shape=(<span class="number">32</span>, <span class="number">28</span>, <span class="number">3</span>))</span><br><span class="line">y = K.placeholder(shape=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">xy = K.dot(x, y)</span><br><span class="line">xy</span><br><span class="line">	<span class="comment"># &lt;tf.Tensor &#x27;MatMul_9:0&#x27; shape=(32, 28, 4) dtype=float32&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = K.random_uniform_variable(shape=(<span class="number">2</span>, <span class="number">3</span>), low=<span class="number">0</span>, high=<span class="number">1</span>)</span><br><span class="line">y = K.ones((<span class="number">4</span>, <span class="number">3</span>, <span class="number">5</span>))</span><br><span class="line">xy = K.dot(x, y)</span><br><span class="line">K.int_shape(xy)</span><br><span class="line">	<span class="comment"># (2, 4, 5)</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="batch-dot"><a href="#batch-dot" class="headerlink" title="batch_dot"></a><code>batch_dot</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_dot</span>(<span class="params">x, y, axes=<span class="literal">None</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>按批进行张量<code>x</code>和<code>y</code>的点积</p>
<ul>
<li>参数<ul>
<li><code>x</code>：按batch分块的数据</li>
<li><code>y</code>；同<code>x</code></li>
<li><code>axes</code>：指定进行点乘的轴</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_batch = K.ones(shape=(<span class="number">32</span>, <span class="number">20</span>, <span class="number">1</span>))</span><br><span class="line">y_batch = K.ones(shape=(<span class="number">32</span>, <span class="number">30</span>, <span class="number">20</span>))</span><br><span class="line">xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">K.int_shape(xy_batch_dot)</span><br><span class="line">	<span class="comment"># (32, 1, 30)</span></span><br></pre></td></tr></table></figure>
<h4 id="transpose"><a href="#transpose" class="headerlink" title="transpose"></a><code>transpose</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transpose</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>张量转置</p>
<h4 id="gather"><a href="#gather" class="headerlink" title="gather"></a><code>gather</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gather</span>(<span class="params">reference, indices</span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定的张量中检索给定下标的向量</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>reference</code>：张量</li>
<li><code>indices</code>：整数张量，其元素为要查询的下标</li>
</ul>
</li>
<li><p>返回值：同<code>reference</code>数据类型相同的张量</p>
</li>
</ul>
<h4 id="max"><a href="#max" class="headerlink" title="max"></a><code>max</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	axis=<span class="literal">None</span>/<span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	keepdims=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>求张量中的最大值</p>
<h4 id="min"><a href="#min" class="headerlink" title="min"></a><code>min</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">min</span>(<span class="params">x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>求张量中的最小值</p>
<h4 id="sum"><a href="#sum" class="headerlink" title="sum"></a><code>sum</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sum</span>(x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>计算张量中元素之和</p>
<h4 id="prod"><a href="#prod" class="headerlink" title="prod"></a><code>prod</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prod(x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>计算张量中元素之积</p>
<h4 id="cumsum"><a href="#cumsum" class="headerlink" title="cumsum"></a><code>cumsum</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cumsum</span>(<span class="params">x, axis=<span class="number">0</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上求张量的累积和</p>
<h4 id="cumprod"><a href="#cumprod" class="headerlink" title="cumprod"></a><code>cumprod</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cumprod(x, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>在给定轴上求张量的累积积</p>
<h4 id="var"><a href="#var" class="headerlink" title="var"></a><code>var</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">var</span>(<span class="params">x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上计算张量方差</p>
<h4 id="std"><a href="#std" class="headerlink" title="std"></a><code>std</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">std</span>(<span class="params">x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上求张量元素之标准差</p>
<h4 id="mean"><a href="#mean" class="headerlink" title="mean"></a><code>mean</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean</span>(<span class="params">x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上求张量元素之均值</p>
<h4 id="any"><a href="#any" class="headerlink" title="any"></a><code>any</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">any</span>(<span class="params">x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>按位或，返回数据类型为uint8的张量（元素为0或1）</p>
<h4 id="all"><a href="#all" class="headerlink" title="all"></a><code>all</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">any</span>(<span class="params">x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>按位与，返回类型为uint8de tensor</p>
<h4 id="argmax"><a href="#argmax" class="headerlink" title="argmax"></a><code>argmax</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">argmax</span>(<span class="params">x, axis=-<span class="number">1</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上求张量之最大元素下标</p>
<h4 id="argmin"><a href="#argmin" class="headerlink" title="argmin"></a><code>argmin</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">argmin</span>(<span class="params">x, axis=-<span class="number">1</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上求张量之最小元素下标</p>
<h3 id="Element-Wise-OPs"><a href="#Element-Wise-OPs" class="headerlink" title="Element-Wise OPs"></a>Element-Wise OPs</h3><h4 id="square"><a href="#square" class="headerlink" title="square"></a><code>square</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">square</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素平方</p>
<h4 id="abs"><a href="#abs" class="headerlink" title="abs"></a><code>abs</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">abs</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素绝对值</p>
<h4 id="sqrt"><a href="#sqrt" class="headerlink" title="sqrt"></a><code>sqrt</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqrt(x)</span><br></pre></td></tr></table></figure>
<p>逐元素开方</p>
<h4 id="exp"><a href="#exp" class="headerlink" title="exp"></a><code>exp</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exp</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素求自然指数</p>
<h4 id="log"><a href="#log" class="headerlink" title="log"></a><code>log</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素求自然对数</p>
<h4 id="logsumexp"><a href="#logsumexp" class="headerlink" title="logsumexp"></a><code>logsumexp</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logsumexp</span>(<span class="params">x, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上计算<code>log(sum(exp()))</code></p>
<ul>
<li>该函数在数值稳定性上超过手动计算<code>log(sum(exp()))</code>，可以
避免由<code>exp</code>和<code>log</code>导致的上溢和下溢</li>
</ul>
<h4 id="round"><a href="#round" class="headerlink" title="round"></a><code>round</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">round</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素四舍五入</p>
<h4 id="sign"><a href="#sign" class="headerlink" title="sign"></a><code>sign</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sign</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素求元素的符号</p>
<ul>
<li>返回值<ul>
<li><code>+1</code></li>
<li><code>-1</code></li>
</ul>
</li>
</ul>
<h4 id="pow"><a href="#pow" class="headerlink" title="pow"></a><code>pow</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pow</span>(<span class="params">x, a</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素求x的a次方</p>
<h4 id="clip"><a href="#clip" class="headerlink" title="clip"></a><code>clip</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	min_value,</span></span></span><br><span class="line"><span class="params"><span class="function">	max_value</span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素clip（将超出指定范围的数强制变为边界值）</p>
<h4 id="equal"><a href="#equal" class="headerlink" title="equal"></a><code>equal</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">equal</span>(<span class="params">x, y</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素判相等关系</p>
<ul>
<li>返回值：布尔张量OP</li>
</ul>
<h4 id="not-equal"><a href="#not-equal" class="headerlink" title="not_equal"></a><code>not_equal</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">not_equal</span>(<span class="params">x, y</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素判不等关系</p>
<h4 id="greater"><a href="#greater" class="headerlink" title="greater"></a><code>greater</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greater</span>(<span class="params">x,y</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素判断<code>x&gt;y</code>关系</p>
<h4 id="greater-equal"><a href="#greater-equal" class="headerlink" title="greater_equal"></a><code>greater_equal</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greater_equal</span>(<span class="params">x,y</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素判断<code>x&gt;=y</code>关系</p>
<h4 id="lesser"><a href="#lesser" class="headerlink" title="lesser"></a><code>lesser</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lesser</span>(<span class="params">x,y</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素判断<code>x&lt;y</code>关系</p>
<h4 id="lesser-equal"><a href="#lesser-equal" class="headerlink" title="lesser_equal"></a><code>lesser_equal</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lesser_equal</span>(<span class="params">x,y</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素判断<code>x&lt;=y</code>关系</p>
<h4 id="maximum"><a href="#maximum" class="headerlink" title="maximum"></a><code>maximum</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maximum</span>(<span class="params">x, y</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素取两个张量的最大值</p>
<h4 id="minimum"><a href="#minimum" class="headerlink" title="minimum"></a><code>minimum</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minimum</span>(<span class="params">x, y</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素取两个张量的最小值</p>
<h4 id="sin"><a href="#sin" class="headerlink" title="sin"></a><code>sin</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sin</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素求正弦值</p>
<h4 id="cos"><a href="#cos" class="headerlink" title="cos"></a><code>cos</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cos</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素求余弦值</p>
<h3 id="变换OPs"><a href="#变换OPs" class="headerlink" title="变换OPs"></a>变换OPs</h3><h4 id="batch-normalization"><a href="#batch-normalization" class="headerlink" title="batch_normalization"></a><code>batch_normalization</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_normalization</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	mean,</span></span></span><br><span class="line"><span class="params"><span class="function">	var,</span></span></span><br><span class="line"><span class="params"><span class="function">	beta,</span></span></span><br><span class="line"><span class="params"><span class="function">	gamma,</span></span></span><br><span class="line"><span class="params"><span class="function">	epsilon=<span class="number">0.0001</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>对batch的数据进行<em>batch_normalization</em>，计算公式为：
$output = (x-mean)/(\sqrt(var)+\epsilon)*\gamma+\beta$</p>
<ul>
<li>手动指定<code>mean</code>、<code>var</code></li>
</ul>
<h4 id="normalize-batch-in-training"><a href="#normalize-batch-in-training" class="headerlink" title="normalize_batch_in_training"></a><code>normalize_batch_in_training</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_batch_in_training</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	gamma,</span></span></span><br><span class="line"><span class="params"><span class="function">	beta,</span></span></span><br><span class="line"><span class="params"><span class="function">	reduction_axes,</span></span></span><br><span class="line"><span class="params"><span class="function">	epsilon=<span class="number">0.0001</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>对batch数据先计算其均值和方差，然后再进行
<code>batch_normalization</code></p>
<h4 id="concatenate"><a href="#concatenate" class="headerlink" title="concatenate"></a><code>concatenate</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">concatenate</span>(<span class="params">tensors, axis=-<span class="number">1</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上将一个列表中的张量串联为一个张量</p>
<h4 id="reshape"><a href="#reshape" class="headerlink" title="reshape"></a><code>reshape</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape</span>(<span class="params">x, shape</span>)</span></span><br></pre></td></tr></table></figure>
<p>将张量的shape变换为指定shape</p>
<h4 id="permute-dimensions"><a href="#permute-dimensions" class="headerlink" title="permute_dimensions"></a><code>permute_dimensions</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">permute_dimensions</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	pattern(<span class="params"><span class="built_in">tuple</span>(<span class="params"><span class="built_in">int</span></span>)</span>)</span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>按照给定的模式重排一个张量的轴</p>
<ul>
<li>参数<ul>
<li><code>pattern</code>：代表维度下标的tuple如<code>(0, 2, 1)</code></li>
</ul>
</li>
</ul>
<h4 id="resize-images"><a href="#resize-images" class="headerlink" title="resize_images"></a><code>resize_images</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resize_images</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	X,</span></span></span><br><span class="line"><span class="params"><span class="function">	height_factor(<span class="params">uint</span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	width_factor(<span class="params">uint</span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering=<span class="literal">None</span>/<span class="string">&#x27;th&#x27;</span>/<span class="string">&#x27;tf&#x27;</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>依据给定的缩放因子<code>height_factor</code>、<code>width_factor</code>，改变batch
数据（图片）的shape</p>
<ul>
<li>参数<ul>
<li><code>height_factor</code>/<code>width_factor</code>：正整数</li>
</ul>
</li>
</ul>
<h4 id="resize-volumes"><a href="#resize-volumes" class="headerlink" title="resize_volumes"></a><code>resize_volumes</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resize_volumes</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	X,</span></span></span><br><span class="line"><span class="params"><span class="function">	depth_factor,</span></span></span><br><span class="line"><span class="params"><span class="function">	height_factor,</span></span></span><br><span class="line"><span class="params"><span class="function">	width_factor,</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering</span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>依据给定的缩放因子，改变一个5D张量数据的shape</p>
<h4 id="repeat-elements"><a href="#repeat-elements" class="headerlink" title="repeat_elements"></a><code>repeat_elements</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">repeat_elements</span>(<span class="params">x, rep, axis</span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上重复张量<strong>元素</strong><code>rep</code>次</p>
<ul>
<li>与<code>np.repeat</code>类似</li>
</ul>
<h4 id="repeat"><a href="#repeat" class="headerlink" title="repeat"></a><code>repeat</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">repeat</span>(<span class="params">x, n</span>)</span></span><br></pre></td></tr></table></figure>
<p>重复2D张量</p>
<h4 id="arange"><a href="#arange" class="headerlink" title="arange"></a><code>arange</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">arange</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	start,</span></span></span><br><span class="line"><span class="params"><span class="function">	stop=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	step=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="string">&quot;int32&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成1D的整数序列张量</p>
<ul>
<li><p>参数：同<code>np.arange</code></p>
<ul>
<li>如果只有一个参数被提供了，则<code>0~stop</code></li>
</ul>
</li>
<li><p>返回值：默认数据类型是<code>int32</code>的张量</p>
</li>
</ul>
<h4 id="tile"><a href="#tile" class="headerlink" title="tile"></a><code>tile</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tile</span>(<span class="params">x, n</span>)</span></span><br></pre></td></tr></table></figure>
<p>将<code>x</code>在各个维度上重复<code>n[i]</code>次</p>
<h4 id="batch-flatten"><a href="#batch-flatten" class="headerlink" title="batch_flatten"></a><code>batch_flatten</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_flatten</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>将n阶张量转变为2阶张量，第一维度保留不变</p>
<h4 id="expand-dims"><a href="#expand-dims" class="headerlink" title="expand_dims"></a><code>expand_dims</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_dims</span>(<span class="params">x, dim=-<span class="number">1</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>在<code>dim</code>指定轴后增加一维（轴）</p>
<h4 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze"></a><code>squeeze</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squeeze</span>(<span class="params">x, axis</span>)</span></span><br></pre></td></tr></table></figure>
<p>将<code>axis</code>指定的轴从张量中移除（保留轴上首组张量切片）</p>
<h4 id="temporal-padding"><a href="#temporal-padding" class="headerlink" title="temporal_padding"></a><code>temporal_padding</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">temporal_padding</span>(<span class="params">x, padding=<span class="number">1</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>向3D张量中间那个维度的左右两端填充<code>padding</code>个0值</p>
<h4 id="asymmetric-temporal-padding"><a href="#asymmetric-temporal-padding" class="headerlink" title="asymmetric_temporal_padding"></a><code>asymmetric_temporal_padding</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">asymmetric_temporal_padding</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	left_pad=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	right_pad=<span class="number">1</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>向3D张量中间的那个维度的左右分别填充0值</p>
<h4 id="spatial-2d-padding"><a href="#spatial-2d-padding" class="headerlink" title="spatial_2d_padding"></a><code>spatial_2d_padding</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spatial_2d_padding</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	padding=(<span class="params"><span class="number">1</span>, <span class="number">1</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering=<span class="string">&#x27;th&#x27;</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>向4D张量高度、宽度左右两端填充<code>padding[0]</code>和<code>padding[1]</code>
个0值</p>
<h4 id="spatial-3d-padding"><a href="#spatial-3d-padding" class="headerlink" title="spatial_3d_padding"></a><code>spatial_3d_padding</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spatial_3d_padding</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	padding=(<span class="params"><span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering=<span class="string">&#x27;th&#x27;</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>向5D张量深度、高度、宽度三个维度上填充0值</p>
<h4 id="stack"><a href="#stack" class="headerlink" title="stack"></a><code>stack</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stack</span>(<span class="params">x, axis=<span class="number">0</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>将列表<code>x</code>中张量堆积起来形成维度+1的新张量</p>
<h4 id="one-hot"><a href="#one-hot" class="headerlink" title="one_hot"></a><code>one_hot</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_hot</span>(<span class="params">indices, nb_classes</span>)</span></span><br></pre></td></tr></table></figure>
<p>为张量<code>indices</code>进行<em>one_hot</em>编码</p>
<ul>
<li>参数<ul>
<li><code>indices</code>：n维的整数张量</li>
<li><code>nb_classes</code>：<em>one_hot</em>编码列表</li>
</ul>
</li>
<li>输出：n+1维整数张量，最后维为编码</li>
</ul>
<h4 id="reverse"><a href="#reverse" class="headerlink" title="reverse"></a><code>reverse</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reverse</span>(<span class="params">x, axes</span>)</span></span><br></pre></td></tr></table></figure>
<p>将一个张量在给定轴上反转</p>
<h4 id="get-value"><a href="#get-value" class="headerlink" title="get_value"></a><code>get_value</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_value</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>以NDA的形式返回张量的值</p>
<h4 id="batch-get-value"><a href="#batch-get-value" class="headerlink" title="batch_get_value"></a><code>batch_get_value</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_get_value</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>以<code>[NDA]</code>的形式返回多个张量的值</p>
<h4 id="set-value"><a href="#set-value" class="headerlink" title="set_value"></a><code>set_value</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_value</span>(<span class="params">x, value</span>)</span></span><br></pre></td></tr></table></figure>
<p>从NDA将值载入张量中</p>
<h4 id="batch-set-value"><a href="#batch-set-value" class="headerlink" title="batch_set_value"></a><code>batch_set_value</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_set_value</span>(<span class="params">tuples</span>)</span></span><br></pre></td></tr></table></figure>
<p>将多个值载入多个张量变量中</p>
<h4 id="print-tensor"><a href="#print-tensor" class="headerlink" title="print_tensor"></a><code>print_tensor</code></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def print_tensor(x, message=&#x27;&#x27;)</span><br></pre></td></tr></table></figure>
<p>在求值时打印张量的信息，并返回原张量</p>
<h4 id="function"><a href="#function" class="headerlink" title="function"></a><code>function</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function</span>(<span class="params">inputs, outputs, updates=[]</span>)</span></span><br></pre></td></tr></table></figure>
<p>实例化一个Keras函数</p>
<ul>
<li>参数<ul>
<li><code>inputs</code>：列表，其元素为占位符或张量变量</li>
<li><code>outputs</code>：输出张量的列表</li>
<li><code>updates</code>：张量列表</li>
</ul>
</li>
</ul>
<h4 id="gradients"><a href="#gradients" class="headerlink" title="gradients"></a><code>gradients</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradients</span>(<span class="params">loss, variables</span>)</span></span><br></pre></td></tr></table></figure>
<p>返回<code>loss</code>函数关于<code>variables</code>的梯度</p>
<h4 id="stop-gradient"><a href="#stop-gradient" class="headerlink" title="stop_gradient"></a><code>stop_gradient</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stop_gradient</span>(<span class="params">variables</span>)</span></span><br></pre></td></tr></table></figure>
<p>Returns <code>variables</code> but with zero gradient with respect to every other variables.</p>
<h4 id="rnn"><a href="#rnn" class="headerlink" title="rnn"></a><code>rnn</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	step_function,</span></span></span><br><span class="line"><span class="params"><span class="function">	inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">	initial_states,</span></span></span><br><span class="line"><span class="params"><span class="function">	go_backwards=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	mask=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	constants=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	unroll=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	input_length=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>在张量的时间维上迭代</p>
<ul>
<li><p>参数：</p>
<ul>
<li><p><code>inputs</code>：时域信号的张量，阶数至少为3</p>
</li>
<li><p><code>step_function</code>：每个时间步要执行的函数</p>
<p>参数</p>
<ul>
<li><code>input</code>：不含时间维张量，代表某时间步batch样本</li>
<li><code>states</code>：张量列表</li>
</ul>
<p>返回值</p>
<ul>
<li><code>output</code>：形如<code>(samples, ...)</code>的张量</li>
<li><code>new_states</code>：张量列表，与<code>states</code>的长度相同    </li>
</ul>
</li>
<li><p><code>initial_states</code>：包含<code>step_function</code>状态初始值</p>
</li>
<li><p><code>go_backwards</code>：逆向迭代序列</p>
</li>
<li><p><code>mask</code>：需要屏蔽的数据元素上值为1</p>
</li>
<li><p><code>constants</code>：按时间步传递给函数的常数列表</p>
</li>
<li><p><code>unroll</code></p>
<ul>
<li>当使用TF时，RNN总是展开的’</li>
<li>当使用Theano时，设置该值为<code>True</code>将展开递归网络</li>
</ul>
</li>
<li><p><code>input_length</code></p>
<ul>
<li>TF：不需要此值</li>
<li>Theano：如果要展开递归网络，必须指定输入序列</li>
</ul>
</li>
</ul>
</li>
<li><p>返回值：形如<code>(last_output, outputs, new_states)</code>的张量</p>
<ul>
<li><code>last_output</code>：RNN最后的输出</li>
<li><code>outputs</code>：每个在[s,t]点的输出对应于样本s在t时间的输出</li>
<li><code>new_states</code>: 每个样本的最后一个状态列表</li>
</ul>
</li>
</ul>
<h4 id="switch"><a href="#switch" class="headerlink" title="switch"></a><code>switch</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">switch</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	condition,</span></span></span><br><span class="line"><span class="params"><span class="function">	then_expression,</span></span></span><br><span class="line"><span class="params"><span class="function">	else_expression</span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>依据给定<code>condition</code>（整数或布尔值）在两个表达式之间切换</p>
<ul>
<li>参数<ul>
<li><code>condition</code>：标量张量</li>
<li><code>then_expression</code>：TensorFlow表达式</li>
<li><code>else_expression</code>: TensorFlow表达式</li>
</ul>
</li>
</ul>
<h4 id="in-train-phase"><a href="#in-train-phase" class="headerlink" title="in_train_phase"></a><code>in_train_phase</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">in_train_phase</span>(<span class="params">x, alt</span>)</span></span><br></pre></td></tr></table></figure>
<p>如果处于训练模式，则选择<code>x</code>，否则选择<code>alt</code></p>
<ul>
<li>注意<code>alt</code>应该与<code>x</code>的<code>shape</code>相同</li>
</ul>
<h4 id="in-test-phase"><a href="#in-test-phase" class="headerlink" title="in_test_phase"></a><code>in_test_phase</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">in_test_phase</span>(<span class="params">x, alt</span>)</span></span><br></pre></td></tr></table></figure>
<p>如果处于测试模式，则选择<code>x</code>，否则选择<code>alt</code></p>
<ul>
<li>注意：<code>alt</code>应该与<code>x</code>的shape相同</li>
</ul>
<h2 id="预定义（激活）函数"><a href="#预定义（激活）函数" class="headerlink" title="预定义（激活）函数"></a>预定义（激活）函数</h2><h4 id="relu"><a href="#relu" class="headerlink" title="relu"></a><code>relu</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	alpha=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	max_value=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>修正线性单元</p>
<ul>
<li>参数<ul>
<li><code>alpha</code>：负半区斜率</li>
<li><code>max_value</code>: 饱和门限</li>
</ul>
</li>
</ul>
<h4 id="elu"><a href="#elu" class="headerlink" title="elu"></a><code>elu</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">elu</span>(<span class="params">x, alpha=<span class="number">1.0</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>指数线性单元</p>
<ul>
<li>参数<ul>
<li><code>x</code>：输入张量</li>
<li><code>alpha</code>: 标量</li>
</ul>
</li>
</ul>
<h4 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a><code>softmax</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>计算张量的softmax值</p>
<h4 id="softplus"><a href="#softplus" class="headerlink" title="softplus"></a><code>softplus</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softplus</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>返回张量的softplus值</p>
<h4 id="softsign"><a href="#softsign" class="headerlink" title="softsign"></a><code>softsign</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softsign</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>返回张量的softsign值</p>
<h4 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a><code>sigmoid</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素计算sigmoid值</p>
<h4 id="hard-sigmoid"><a href="#hard-sigmoid" class="headerlink" title="hard_sigmoid"></a><code>hard_sigmoid</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hard_sigmoid</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>分段线性近似的sigmoid，计算速度更快</p>
<h4 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a><code>tanh</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span>(<span class="params">x</span>)</span></span><br></pre></td></tr></table></figure>
<p>逐元素计算tanh值 </p>
<h2 id="预定义目标函数"><a href="#预定义目标函数" class="headerlink" title="预定义目标函数"></a>预定义目标函数</h2><h4 id="categorical-crossentropy"><a href="#categorical-crossentropy" class="headerlink" title="categorical_crossentropy"></a><code>categorical_crossentropy</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">categorical_crossentropy</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	output,</span></span></span><br><span class="line"><span class="params"><span class="function">	target,</span></span></span><br><span class="line"><span class="params"><span class="function">	from_logits=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>计算<code>output</code>、<code>target</code>的Categorical Crossentropy（类别交叉熵）</p>
<ul>
<li>参数<ul>
<li><code>output</code>/<code>target</code>：shape相等</li>
</ul>
</li>
</ul>
<h4 id="sparse-categorical-crossentropy"><a href="#sparse-categorical-crossentropy" class="headerlink" title="sparse_categorical_crossentropy"></a><code>sparse_categorical_crossentropy</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sparse_categorical_crossentropy</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	output,</span></span></span><br><span class="line"><span class="params"><span class="function">	target,</span></span></span><br><span class="line"><span class="params"><span class="function">	from_logits=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>计算<code>output</code>、<code>target</code>的Categorical Crossentropy（类别交叉熵）</p>
<ul>
<li>参数<ul>
<li><code>output</code></li>
<li><code>target</code>：同<code>output</code> shape相等，需为整形张量</li>
</ul>
</li>
</ul>
<h4 id="binary-crossentropy"><a href="#binary-crossentropy" class="headerlink" title="binary_crossentropy"></a><code>binary_crossentropy</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_crossentropy</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	output,</span></span></span><br><span class="line"><span class="params"><span class="function">	target,</span></span></span><br><span class="line"><span class="params"><span class="function">	from_logits=<span class="literal">False</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>计算输出张量和目标张量的交叉熵</p>
<h4 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a><code>dropout</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout</span>(<span class="params">x, level, seed=<span class="literal">None</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>随机将<code>x</code>中一定比例的值设置为0，并放缩整个Tensor</p>
<h4 id="l2-normalize"><a href="#l2-normalize" class="headerlink" title="l2_normalize"></a><code>l2_normalize</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l2_normalize</span>(<span class="params">x, axis</span>)</span></span><br></pre></td></tr></table></figure>
<p>在给定轴上对张量进行L2范数规范化</p>
<h4 id="in-top-k"><a href="#in-top-k" class="headerlink" title="in_top_k"></a><code>in_top_k</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">in_top_k</span>(<span class="params">predictions, targets, k</span>)</span></span><br></pre></td></tr></table></figure>
<p>判断目标是否在<code>predictions</code>的前k大值位置</p>
<p>参数</p>
<ul>
<li><code>predictions</code>：预测值张量</li>
<li><code>targets</code>：真值张量</li>
<li><code>k</code>：整数</li>
</ul>
<h4 id="conv1d"><a href="#conv1d" class="headerlink" title="conv1d"></a><code>conv1d</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv1d</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	kernel,</span></span></span><br><span class="line"><span class="params"><span class="function">	strides=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	border_mode=<span class="string">&quot;valid&quot;</span>/<span class="string">&quot;same&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	image_shape=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	filter_shape=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>1D卷积</p>
<ul>
<li>参数<ul>
<li><code>kernel</code>：卷积核张量</li>
<li><code>strides</code>：步长，整型</li>
<li><code>border_mode</code><ul>
<li>“same”：</li>
<li>“valid”：</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="conv2d"><a href="#conv2d" class="headerlink" title="conv2d"></a><code>conv2d</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	kernel,</span></span></span><br><span class="line"><span class="params"><span class="function">	strides=(<span class="params"><span class="number">1</span>, <span class="number">1</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	border_mode=<span class="string">&quot;valid&quot;</span>/<span class="string">&quot;same&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering=<span class="string">&quot;th&quot;</span>/<span class="string">&quot;tf&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	image_shape=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	filter_shape=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>2D卷积</p>
<ul>
<li>参数<ul>
<li><code>kernel</code>：卷积核张量</li>
<li><code>strides</code>：步长，长为2的tuple</li>
</ul>
</li>
</ul>
<h4 id="deconv2d"><a href="#deconv2d" class="headerlink" title="deconv2d"></a><code>deconv2d</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deconv2d</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	kernel,</span></span></span><br><span class="line"><span class="params"><span class="function">	output_shape,</span></span></span><br><span class="line"><span class="params"><span class="function">	strides=(<span class="params"><span class="number">1</span>, <span class="number">1</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	border_mode=<span class="string">&quot;valid&quot;</span>/<span class="string">&quot;same&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering=<span class="string">&quot;th&quot;</span>/<span class="string">&quot;tf&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	image_shape=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	filter_shape=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>2D反卷积（转置卷积）</p>
<ul>
<li>参数<ul>
<li><code>x</code>：输入张量</li>
<li><code>kernel</code>：卷积核张量</li>
<li><code>output_shape</code>: 输出shape的1D的整数张量</li>
<li><code>strides</code>：步长，tuple类型</li>
</ul>
</li>
</ul>
<h4 id="conv3d"><a href="#conv3d" class="headerlink" title="conv3d"></a><code>conv3d</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv3d</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	kernel,</span></span></span><br><span class="line"><span class="params"><span class="function">	strides=(<span class="params"><span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	border_mode=<span class="string">&quot;valid&quot;</span>/<span class="string">&quot;same&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering=<span class="string">&quot;th&quot;</span>/<span class="string">&quot;tf&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	volume_shape=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	filter_shape=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>3D卷积</p>
<h4 id="pool2d"><a href="#pool2d" class="headerlink" title="pool2d"></a><code>pool2d</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool2d</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	pool_size,</span></span></span><br><span class="line"><span class="params"><span class="function">	strides=(<span class="params"><span class="number">1</span>, <span class="number">1</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	border_mode=<span class="string">&quot;valid&quot;</span>/<span class="string">&quot;same&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering=<span class="string">&quot;th&quot;</span>/<span class="string">&quot;tf&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	pool_mode=<span class="string">&quot;max&quot;</span>/<span class="string">&quot;avg&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>2D池化</p>
<ul>
<li>参数<ul>
<li><code>pool_size</code>：含有两个整数的tuple，池的大小</li>
<li><code>strides</code>：含有两个整数的tuple，步长</li>
<li><code>pool_mode</code>: “max”，“avg”之一，池化方式</li>
</ul>
</li>
</ul>
<h4 id="pool3d"><a href="#pool3d" class="headerlink" title="pool3d"></a><code>pool3d</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool3d</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	x,</span></span></span><br><span class="line"><span class="params"><span class="function">	pool_size,</span></span></span><br><span class="line"><span class="params"><span class="function">	strides=(<span class="params"><span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="function">	border_mode=<span class="string">&quot;valid&quot;</span>/<span class="string">&quot;same&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dim_ordering=<span class="string">&quot;th&quot;</span>/<span class="string">&quot;tf&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	pool_mode=<span class="string">&quot;max&quot;</span>/<span class="string">&quot;avg&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>3D池化</p>
<h4 id="bias-add"><a href="#bias-add" class="headerlink" title="bias_add"></a><code>bias_add</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_add</span>(<span class="params">x, bias, data_format=<span class="literal">None</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>为张量增加一个偏置项</p>
<h4 id="random-normal"><a href="#random-normal" class="headerlink" title="random_normal"></a><code>random_normal</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_normal</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	shape,</span></span></span><br><span class="line"><span class="params"><span class="function">	mean=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	stddev=<span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	seed=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成服从正态分布的张量</p>
<ul>
<li>参数<ul>
<li><code>mean</code>：均值</li>
<li><code>stddev</code>：标准差</li>
</ul>
</li>
</ul>
<h4 id="random-uniform"><a href="#random-uniform" class="headerlink" title="random_uniform"></a><code>random_uniform</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_uniform</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	shape,</span></span></span><br><span class="line"><span class="params"><span class="function">	minval=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	maxval=<span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	seed=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成服从均匀分布值的张量</p>
<ul>
<li>参数<ul>
<li><code>minval</code>：上界</li>
<li><code>maxval</code>：上界</li>
</ul>
</li>
</ul>
<h4 id="random-binomial"><a href="#random-binomial" class="headerlink" title="random_binomial"></a><code>random_binomial</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_binomial</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	shape,</span></span></span><br><span class="line"><span class="params"><span class="function">	p=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	seed=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>返回具有二项分布值的张量</p>
<ul>
<li>参数<ul>
<li><code>p</code>：二项分布参数</li>
</ul>
</li>
</ul>
<h4 id="truncated-normall"><a href="#truncated-normall" class="headerlink" title="truncated_normall"></a><code>truncated_normall</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">truncated_normal</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	shape,</span></span></span><br><span class="line"><span class="params"><span class="function">	mean=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	stddev=<span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dtype=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	seed=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>生成服从截尾正态分布值的张量，即在距离均值两个标准差之外的
数据将会被截断并重新生成</p>
<h4 id="ctc-label-dense-to-sparse"><a href="#ctc-label-dense-to-sparse" class="headerlink" title="ctc_label_dense_to_sparse"></a><code>ctc_label_dense_to_sparse</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ctc_label_dense_to_sparse</span>(<span class="params">labels, label_lengths</span>)</span></span><br></pre></td></tr></table></figure>
<p>将ctc标签从稠密形式转换为稀疏形式</p>
<h4 id="ctc-batch-cost"><a href="#ctc-batch-cost" class="headerlink" title="ctc_batch_cost"></a><code>ctc_batch_cost</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ctc_batch_cost</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	y_true,</span></span></span><br><span class="line"><span class="params"><span class="function">	y_pred,</span></span></span><br><span class="line"><span class="params"><span class="function">	input_length,</span></span></span><br><span class="line"><span class="params"><span class="function">	label_length</span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>在batch上运行CTC损失算法</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>y_true</code>：包含标签的真值张量</li>
<li><code>y_pred</code>：包含预测值或输出的softmax值的张量</li>
<li><code>input_length</code>：包含<code>y_pred</code>中每个batch的序列长</li>
<li><code>label_length</code>：包含<code>y_true</code>中每个batch的序列长张量</li>
</ul>
</li>
<li><p>返回值：包含了每个元素的CTC损失的张量</p>
</li>
</ul>
<h4 id="ctc-decode"><a href="#ctc-decode" class="headerlink" title="ctc_decode"></a><code>ctc_decode</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ctc_decode</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	y_pred,</span></span></span><br><span class="line"><span class="params"><span class="function">	input_length,</span></span></span><br><span class="line"><span class="params"><span class="function">	greedy=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	beam_width=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dict_seq_lens=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	dict_values=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>使用贪婪算法或带约束的字典搜索算法解码softmax的输出</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>y_pred</code>：包含预测值或输出的softmax值的张量</li>
<li><code>input_length</code>：包含<code>y_pred</code>中每个batch序列长的张量</li>
<li><code>greedy</code>：使用贪婪算法</li>
<li><code>dict_seq_lens</code>：<code>dic_values</code>列表中各元素的长度</li>
<li><code>dict_values</code>：列表的列表，代表字典</li>
</ul>
</li>
<li><p>返回值：包含了路径可能性（以softmax概率的形式）张量</p>
</li>
<li><p>注意仍然需要一个用来取出argmax和处理空白标签的函数</p>
</li>
</ul>
<h4 id="map-fn"><a href="#map-fn" class="headerlink" title="map_fn"></a><code>map_fn</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map_fn</span>(<span class="params">fn, elems, name=<span class="literal">None</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>元素elems在函数fn上的映射，并返回结果</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>fn</code>：函数</li>
<li><code>elems</code>：张量</li>
<li><code>name</code>：节点的名字</li>
</ul>
</li>
<li><p>返回值：张量的第一维度等于<code>elems</code>，第二维度取决于<code>fn</code></p>
</li>
</ul>
<h4 id="foldl"><a href="#foldl" class="headerlink" title="foldl"></a><code>foldl</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foldl</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	fn,</span></span></span><br><span class="line"><span class="params"><span class="function">	elems,</span></span></span><br><span class="line"><span class="params"><span class="function">	initializer=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>用fn从左到右连接它们，以减少<code>elems</code>值</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>fn</code>：函数，例如：lambda acc, x: acc + x</li>
<li><code>elems</code>：张量</li>
<li><code>initializer</code>：初始化的值(elems[0])</li>
<li><code>name</code>：节点名</li>
</ul>
</li>
<li><p>返回值：与<code>initializer</code>类型和形状一致</p>
</li>
</ul>
<h4 id="foldr"><a href="#foldr" class="headerlink" title="foldr"></a><code>foldr</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foldr</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	fn,</span></span></span><br><span class="line"><span class="params"><span class="function">	elems,</span></span></span><br><span class="line"><span class="params"><span class="function">	initializer=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>减少<code>elems</code>，用<code>fn</code>从右到左连接它们</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>fn</code>：函数，例如：lambda acc, x: acc + x</li>
<li><code>elems</code>：张量</li>
<li><code>initializer</code>：初始化的值（elems[-1]）</li>
<li><code>name</code>：节点名</li>
</ul>
</li>
<li><p>返回值：与<code>initializer</code>类型和形状一致</p>
</li>
</ul>
<p>_width=None,
    dict_seq_lens=None,
    dict_values=None
)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">使用贪婪算法或带约束的字典搜索算法解码softmax的输出</span><br><span class="line"></span><br><span class="line">-	参数</span><br><span class="line"></span><br><span class="line">	-	`y_pred`：包含预测值或输出的softmax值的张量</span><br><span class="line">	-	`input_length`：包含`y_pred`中每个batch序列长的张量</span><br><span class="line">	-	`greedy`：使用贪婪算法</span><br><span class="line">	-	`dict_seq_lens`：`dic_values`列表中各元素的长度</span><br><span class="line">	-	`dict_values`：列表的列表，代表字典</span><br><span class="line"></span><br><span class="line">-	返回值：包含了路径可能性（以softmax概率的形式）张量</span><br><span class="line"></span><br><span class="line">-	注意仍然需要一个用来取出argmax和处理空白标签的函数</span><br><span class="line"></span><br><span class="line">####	`map_fn`</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">def map_fn(fn, elems, name=None)</span><br></pre></td></tr></table></figure></p>
<p>元素elems在函数fn上的映射，并返回结果</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>fn</code>：函数</li>
<li><code>elems</code>：张量</li>
<li><code>name</code>：节点的名字</li>
</ul>
</li>
<li><p>返回值：张量的第一维度等于<code>elems</code>，第二维度取决于<code>fn</code></p>
</li>
</ul>
<h4 id="foldl-1"><a href="#foldl-1" class="headerlink" title="foldl"></a><code>foldl</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foldl</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	fn,</span></span></span><br><span class="line"><span class="params"><span class="function">	elems,</span></span></span><br><span class="line"><span class="params"><span class="function">	initializer=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>用fn从左到右连接它们，以减少<code>elems</code>值</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>fn</code>：函数，例如：lambda acc, x: acc + x</li>
<li><code>elems</code>：张量</li>
<li><code>initializer</code>：初始化的值(elems[0])</li>
<li><code>name</code>：节点名</li>
</ul>
</li>
<li><p>返回值：与<code>initializer</code>类型和形状一致</p>
</li>
</ul>
<h4 id="foldr-1"><a href="#foldr-1" class="headerlink" title="foldr"></a><code>foldr</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foldr</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">	fn,</span></span></span><br><span class="line"><span class="params"><span class="function">	elems,</span></span></span><br><span class="line"><span class="params"><span class="function">	initializer=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	name=<span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span>)</span></span><br></pre></td></tr></table></figure>
<p>减少<code>elems</code>，用<code>fn</code>从右到左连接它们</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>fn</code>：函数，例如：lambda acc, x: acc + x</li>
<li><code>elems</code>：张量</li>
<li><code>initializer</code>：初始化的值（elems[-1]）</li>
<li><code>name</code>：节点名</li>
</ul>
</li>
<li><p>返回值：与<code>initializer</code>类型和形状一致</p>
</li>
<li><p><code>name</code>：节点名</p>
</li>
<li><p>返回值：与<code>initializer</code>类型和形状一致</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-02-20T15:58:15.000Z" title="2/20/2019, 11:58:15 PM">2019-02-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-02-17T03:57:07.000Z" title="2/17/2019, 11:57:07 AM">2019-02-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a><span> / </span><a class="link-muted" href="/categories/Python/Keras/">Keras</a></span><span class="level-item">14 minutes read (About 2173 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Python/Keras/convolutional_layers.html">卷积层</a></h1><div class="content"><h2 id="Conv1D"><a href="#Conv1D" class="headerlink" title="Conv1D"></a>Conv1D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.Conv1D(</span><br><span class="line">	filters(<span class="built_in">int</span>),</span><br><span class="line">	kernel_size(<span class="built_in">int</span>),</span><br><span class="line">	strides=<span class="number">1</span>,</span><br><span class="line">	padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">	dilation_rate=<span class="number">1</span>,</span><br><span class="line">	activation=<span class="literal">None</span>,</span><br><span class="line">	use_bias=<span class="literal">True</span>,</span><br><span class="line">	kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line">	bias_initializer=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line">	kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">	bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">	activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">	kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">	bias_constraint=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>一维卷积层（即时域卷积）</p>
<ul>
<li><p>说明</p>
<ul>
<li>用以在一维输入信号上进行邻域滤波</li>
<li>作为首层时，需要提供关键字参数<code>input_shape</code></li>
<li>该层生成将输入信号与卷积核按照单一的空域（或时域）
方向进行卷积</li>
<li>可以将Convolution1D看作Convolution2D的快捷版</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><p><code>filters</code>：卷积核的数目（即输出的维度）</p>
</li>
<li><p><code>kernel_size</code>：整数或由单个整数构成的list/tuple，
卷积核的空域或时域窗长度</p>
</li>
<li><p><code>strides</code>：整数或由单个整数构成的list/tuple，为卷积
步长</p>
<ul>
<li>任何不为1的strides均与任何不为1的dilation_rate
均不兼容</li>
</ul>
</li>
<li><p><code>padding</code>：补0策略</p>
</li>
<li><p><code>activation</code>：激活函数</p>
</li>
<li><p><code>dilation_rate</code>：整数或由单个整数构成的list/tuple，
指定dilated convolution中的膨胀比例</p>
<ul>
<li>任何不为1的dilation_rate均与任何不为1的strides
均不兼容</li>
</ul>
</li>
<li><p><code>use_bias</code>：布尔值，是否使用偏置项</p>
</li>
<li><p><code>kernel_initializer</code>：权值初始化方法</p>
<ul>
<li>预定义初始化方法名的字符串</li>
<li>用于初始化权重的初始化器（参考initializers）</li>
</ul>
</li>
<li><p><code>bias_initializer</code>：偏置初始化方法</p>
<ul>
<li>为预定义初始化方法名的字符串</li>
<li>用于初始化偏置的初始化器</li>
</ul>
</li>
<li><p><code>kernel_regularizer</code>：施加在权重上的正则项，为
Regularizer对象</p>
</li>
<li><p><code>bias_regularizer</code>：施加在偏置向量上的正则项</p>
</li>
<li><p><code>activity_regularizer</code>：施加在输出上的正则项</p>
</li>
<li><p><code>kernel_constraints</code>：施加在权重上的约束项</p>
</li>
<li><p><code>bias_constraints</code>：施加在偏置上的约束项</p>
</li>
</ul>
</li>
<li><p>输入：形如<code>(batch, steps, input_dim)</code>的3D张量</p>
</li>
<li><p>输出：形如<code>(batch, new_steps, filters)</code>的3D张量</p>
<ul>
<li>因为有向量填充的原因，<code>steps</code>的值会改变</li>
</ul>
</li>
</ul>
<h2 id="Conv2D"><a href="#Conv2D" class="headerlink" title="Conv2D"></a>Conv2D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.Conv2D(</span><br><span class="line">	filters,</span><br><span class="line">	kernel_size,</span><br><span class="line">	strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">	data_format=<span class="literal">None</span>,</span><br><span class="line">	dilation_rate=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	activation=<span class="literal">None</span>,</span><br><span class="line">	use_bias=<span class="literal">True</span>,</span><br><span class="line">	kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line">	bias_initializer=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line">	kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">	bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">	activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">	kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">	bias_constraint=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>二维卷积层，即对图像的空域卷积</p>
<ul>
<li><p>说明</p>
<ul>
<li>该层对二维输入进行滑动窗卷积</li>
<li>当使用该层作为第一层时，应提供</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><p><code>filters</code>：卷积核的数目（即输出的维度）</p>
</li>
<li><p><code>kernel_size</code>：单个整数或由两个整数构成的list/tuple，
卷积核的宽度和长度</p>
<ul>
<li>如为单个整数，则表示在各个空间维度的相同长度</li>
</ul>
</li>
<li><p><code>strides</code>：单个整数或由两个整数构成的list/tuple，
卷积的步长</p>
<ul>
<li>如为单个整数，则表示在各个空间维度的相同步长</li>
<li>任何不为1的strides均与任何不为1的dilation_rate
均不兼容</li>
</ul>
</li>
<li><p><code>padding</code>：补0策略</p>
</li>
<li><p><code>activation</code>：激活函数</p>
</li>
<li><p><code>dilation_rate</code>：单个或两个整数构成的list/tuple，
指定dilated convolution中的膨胀比例</p>
<ul>
<li>任何不为1的dilation_rate均与任何不为1的strides
均不兼容</li>
</ul>
</li>
</ul>
</li>
<li><p>输入：<code>(batch, channels, rows, cols)</code>
（”channels_first”）4D张量</p>
</li>
<li><p>输出：<code>(batch, filters, new_rows, new_cols)</code>
（”channels_first”）4D张量</p>
<ul>
<li>输出的行列数可能会因为填充方法而改变</li>
</ul>
</li>
</ul>
<h2 id="SeparableConv2D"><a href="#SeparableConv2D" class="headerlink" title="SeparableConv2D"></a>SeparableConv2D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.SeparableConv2D(</span><br><span class="line">	filters,</span><br><span class="line">	kernel_size,</span><br><span class="line">	strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">	data_format=<span class="literal">None</span>,</span><br><span class="line">	depth_multiplier=<span class="number">1</span>,</span><br><span class="line">	activation=<span class="literal">None</span>,</span><br><span class="line">	use_bias=<span class="literal">True</span>,</span><br><span class="line">	depthwise_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line">	pointwise_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line">	bias_initializer=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line">	depthwise_regularizer=<span class="literal">None</span>,</span><br><span class="line">	pointwise_regularizer=<span class="literal">None</span>,</span><br><span class="line">	bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">	activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">	depthwise_constraint=<span class="literal">None</span>,</span><br><span class="line">	pointwise_constraint=<span class="literal">None</span>,</span><br><span class="line">	bias_constraint=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>该层是在深度方向上的可分离卷积。</p>
<ul>
<li><p>说明</p>
<ul>
<li>首先按深度方向进行卷积（对每个输入通道分别卷积）</li>
<li>然后逐点卷积，将上步卷积结果混合到输出通道中</li>
<li>直观来说，可分离卷积可以看做讲一个卷积核分解为两个小
卷积核，或看作Inception模块的一种极端情况</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><p><code>depth_multiplier</code>：按深度卷积的步骤中，每个输入通道
使用（产生）多少个输出通道</p>
</li>
<li><p><code>depthwise_regularizer</code>：按深度卷积的权重上的正则项</p>
</li>
<li><p><code>pointwise_regularizer</code>：按点卷积的权重上的正则项</p>
</li>
<li><p><code>depthwise_constraint</code>：按深度卷积权重上的约束项</p>
</li>
<li><p><code>pointwise_constraint</code>：在按点卷积权重的约束项</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>输入：<code>(batch, channels, rows, cols)</code>4DT
（”channels_first”)</p>
</li>
<li><p>输出：<code>(batch, filters, new_rows, new_cols)</code>4DTK
（”channels_first”）</p>
<ul>
<li>输出的行列数可能会因为填充方法而改变</li>
</ul>
</li>
</ul>
<h2 id="Conv2DTranspose"><a href="#Conv2DTranspose" class="headerlink" title="Conv2DTranspose"></a>Conv2DTranspose</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.Conv2DTranspose(</span><br><span class="line">	filters,</span><br><span class="line">	kernel_size,</span><br><span class="line">	strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	padding=<span class="string">&quot;valid&quot;</span>,</span><br><span class="line">	output_padding=<span class="literal">None</span>/<span class="built_in">int</span>/<span class="built_in">tuple</span>,</span><br><span class="line">	data_format=<span class="literal">None</span>,</span><br><span class="line">	activation=<span class="literal">None</span>,</span><br><span class="line">	use_bias=<span class="literal">True</span>,</span><br><span class="line">	kernel_initializer=<span class="string">&quot;glorot_uniform&quot;</span>,</span><br><span class="line">	bias_initializer=<span class="string">&quot;zeros&quot;</span>,</span><br><span class="line">	kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">	bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">	activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">	kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">	bias_constraint=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>该层是反卷积操作（转置卷积）</p>
<ul>
<li><p>说明</p>
<ul>
<li>通常发生在用户想要对普通卷积的结果做反方向的变换</li>
<li>参考文献<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.07285">A guide to convolution arithmetic for deep learning</a></li>
<li><a target="_blank" rel="noopener" href="http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic">Transposed convolution arithmetic</a></li>
<li><a target="_blank" rel="noopener" href="http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf">Deconvolutional Networks</a></li>
</ul>
</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>output_padding</code>：指定输出的长、宽padding<ul>
<li>必须小于相应的<code>stride</code></li>
</ul>
</li>
</ul>
</li>
<li><p>输入：<code>(batch, rows, cols, channels)</code>4DT
（”channels_last”)</p>
</li>
<li><p>输出：<code>(batch, new_rows, new_cols, filters)</code>4DT
（”channels_last”）</p>
<ul>
<li>输出的行列数可能会因为填充方法而改变</li>
</ul>
</li>
</ul>
<h2 id="Conv3D"><a href="#Conv3D" class="headerlink" title="Conv3D"></a>Conv3D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.Conv3D(</span><br><span class="line">	filters,</span><br><span class="line">	kernel_size,</span><br><span class="line">	strides=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">	data_format=<span class="literal">None</span>,</span><br><span class="line">	dilation_rate=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	activation=<span class="literal">None</span>,</span><br><span class="line">	use_bias=<span class="literal">True</span>,</span><br><span class="line">	kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line">	bias_initializer=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line">	kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">	bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">	activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">	kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">	bias_constraint=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>三维卷积对三维的输入（视频）进行滑动窗卷积</p>
<ul>
<li>输入：<code>(batch, channels, conv_dim1, conv_dim2, conv_dim3)</code>
5D张量（”channnels_first”）</li>
</ul>
<h2 id="Cropping1D"><a href="#Cropping1D" class="headerlink" title="Cropping1D"></a>Cropping1D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.Cropping1D(</span><br><span class="line">	cropping=(<span class="number">1</span>, <span class="number">1</span>)/<span class="built_in">tuple</span>/<span class="built_in">int</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>在时间轴上对1D输入（即时间序列）进行裁剪</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>cropping</code>：指定在序列的首尾要裁剪掉多少个元素<ul>
<li>单值表示首尾裁剪相同</li>
</ul>
</li>
</ul>
</li>
<li><p>输入：<code>(batch, axis_to_crop, features)</code>的3DT</p>
</li>
<li><p>输出：<code>(batch, cropped_axis, features)</code>的3DT</p>
</li>
</ul>
<h2 id="Cropping2D"><a href="#Cropping2D" class="headerlink" title="Cropping2D"></a>Cropping2D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.Cropping2D(</span><br><span class="line">	cropping=((<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>)),</span><br><span class="line">	data_format=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>对2D输入（图像）进行裁剪</p>
<ul>
<li><p>说明</p>
<ul>
<li>将在空域维度，即宽和高的方向上裁剪</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>cropping</code>：长为2的整数tuple，分别为宽和高方向上头部
与尾部需要裁剪掉的元素数<ul>
<li>单值表示宽高、首尾相同</li>
<li>单元组类似</li>
</ul>
</li>
</ul>
</li>
<li><p>输入：<code>(batch, rows, cols, channels)</code>4DT（”channels_last”）</p>
</li>
<li><p>输出：<code>(batch, cropped_rows, cropped_cols, channels)</code></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">	<span class="comment"># Crop the input 2D images or feature maps</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Cropping2D(cropping=((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">                     input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">3</span>)))</span><br><span class="line">	<span class="comment"># now model.output_shape == (None, 24, 20, 3)</span></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(Cropping2D(cropping=((<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>))))</span><br><span class="line">	<span class="comment"># now model.output_shape == (None, 20, 16, 64)</span></span><br></pre></td></tr></table></figure>
<h2 id="Cropping3D"><a href="#Cropping3D" class="headerlink" title="Cropping3D"></a>Cropping3D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.Cropping3D(</span><br><span class="line">	cropping=((<span class="number">1</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">	data_format=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>对3D输入（空间、时空）进行裁剪</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>cropping</code>：长为3的整数tuple，分别为三个方向上头部
与尾部需要裁剪掉的元素数</li>
</ul>
</li>
<li><p>输入：<code>(batch, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)</code>
（”channels_first”）</p>
</li>
<li><p>输出：<code>(batch, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)</code></p>
</li>
</ul>
<h2 id="UpSampling1D"><a href="#UpSampling1D" class="headerlink" title="UpSampling1D"></a>UpSampling1D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.UpSampling1D(</span><br><span class="line">	size=<span class="number">2</span>/integer</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>在时间轴上，将每个时间步重复<code>size</code>次</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>size</code>：轴上采样因子</li>
</ul>
</li>
<li><p>输入：<code>(batch, steps, features)</code>的3D张量</p>
</li>
<li><p>输出：<code>(batch, upsampled_steps, feature)</code>的3D张量</p>
</li>
</ul>
<h2 id="UpSampling2D"><a href="#UpSampling2D" class="headerlink" title="UpSampling2D"></a>UpSampling2D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.UpSampling2D(</span><br><span class="line">	size=(<span class="number">2</span>, <span class="number">2</span>)/<span class="built_in">tuple</span>/<span class="built_in">int</span>,</span><br><span class="line">	data_format=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>将数据的行和列分别重复<code>size[0]</code>和<code>size[1]</code>次</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>size</code>：分别为行和列上采样因子</li>
</ul>
</li>
<li><p>输入：<code>(batch, channels, rows, cols)</code>的4D张量
（”channels_first”）</p>
</li>
<li><p>输出：<code>(batch, channels, upsampled_rows, upsampled_cols)</code></p>
</li>
</ul>
<h2 id="UpSampling3D"><a href="#UpSampling3D" class="headerlink" title="UpSampling3D"></a>UpSampling3D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.UpSampling3D(</span><br><span class="line">	size=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)/<span class="built_in">tuple</span>/<span class="built_in">int</span>,</span><br><span class="line">	data_format=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>将数据的三个维度上分别重复<code>size</code>次</p>
<ul>
<li><p>说明</p>
<ul>
<li>本层目前只能在使用Theano为后端时可用</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>size</code>：代表在三个维度上的上采样因子</li>
</ul>
</li>
</ul>
<ul>
<li><p>输入：<code>(batch, dim1, dim2, dim3, channels)</code>5DT
（”channels_last”）</p>
</li>
<li><p>输出：<code>(batch, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)</code></p>
</li>
</ul>
<h2 id="ZeroPadding1D"><a href="#ZeroPadding1D" class="headerlink" title="ZeroPadding1D"></a>ZeroPadding1D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.ZeroPadding1D(</span><br><span class="line">	padding=<span class="number">1</span>/<span class="built_in">int</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>对1D输入的首尾端（如时域序列）填充0</p>
<ul>
<li><p>说明</p>
<ul>
<li>以控制卷积以后向量的长度</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>padding</code>：整数，在axis 1起始和结束处填充0数目</li>
</ul>
</li>
<li><p>输入：<code>(batch, axis_to_pad, features)</code>3DT</p>
</li>
<li><p>输出：<code>(batch, paded_axis, features)</code>3DT</p>
</li>
</ul>
<h2 id="ZeroPadding2D"><a href="#ZeroPadding2D" class="headerlink" title="ZeroPadding2D"></a>ZeroPadding2D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.ZeroPadding2D(</span><br><span class="line">	padding=(<span class="number">1</span>, <span class="number">1</span>)/<span class="built_in">tuple</span>/<span class="built_in">int</span>,</span><br><span class="line">	data_format=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>对2D输入（如图片）的边界填充0</p>
<ul>
<li><p>说明</p>
<ul>
<li>以控制卷积以后特征图的大小</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>padding</code>：在要填充的轴的起始和结束处填充0的数目</li>
</ul>
</li>
</ul>
<h2 id="ZeroPadding3D"><a href="#ZeroPadding3D" class="headerlink" title="ZeroPadding3D"></a>ZeroPadding3D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.ZeroPadding3D(</span><br><span class="line">	padding=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	data_format=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>将数据的三个维度上填充0</p>
<ul>
<li>说明<ul>
<li>本层目前只能在使用Theano为后端时可用</li>
</ul>
</li>
</ul>
<p>结束处填充0的数目</p>
<h2 id="ZeroPadding3D-1"><a href="#ZeroPadding3D-1" class="headerlink" title="ZeroPadding3D"></a>ZeroPadding3D</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.convolutional.ZeroPadding3D(</span><br><span class="line">	padding=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	data_format=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>将数据的三个维度上填充0</p>
<ul>
<li>说明<ul>
<li>本层目前只能在使用Theano为后端时可用</li>
</ul>
</li>
</ul>
<p>?时可用</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-02-20T15:58:15.000Z" title="2/20/2019, 11:58:15 PM">2019-02-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:42:51.000Z" title="8/4/2021, 11:42:51 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a><span> / </span><a class="link-muted" href="/categories/Python/Keras/">Keras</a></span><span class="level-item">4 minutes read (About 578 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Python/Keras/about_layers.html">Layers 总述</a></h1><div class="content"><h3 id="Layer方法"><a href="#Layer方法" class="headerlink" title="Layer方法"></a>Layer方法</h3><p>所有的Keras层对象都有如下方法：</p>
<ul>
<li><p><code>layer.get_weights()</code>：返回层的权重NDA</p>
</li>
<li><p><code>layer.set_weights(weights)</code>：从NDA中将权重加载到该层中
，要求NDA的形状与<code>layer.get_weights()</code>的形状相同</p>
</li>
<li><p><code>layer.get_config()</code>：返回当前层配置信息的字典，层也可以
借由配置信息重构</p>
</li>
<li><p><code>layer.from_config(config)</code>：根据<code>config</code>配置信息重构层</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">layer = Dense(<span class="number">32</span>)</span><br><span class="line">config = layer.get_config()</span><br><span class="line">reconstructed_layer = Dense.from_config(config)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">config = layer.get_config()</span><br><span class="line">layer = layers.deserialize(&#123;<span class="string">&#x27;class_name&#x27;</span>: layer.__class__.__name__,</span><br><span class="line">							<span class="string">&#x27;config&#x27;</span>: config&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="非共享层"><a href="#非共享层" class="headerlink" title="非共享层"></a>非共享层</h4><p>如果层仅有一个计算节点（即该层不是共享层），则可以通过下列
方法获得</p>
<ul>
<li>输入张量：<code>layer.input</code></li>
<li>输出张量：<code>layer.output</code></li>
<li>输入数据的形状：<code>layer.input_shape</code></li>
<li>输出数据的形状：<code>layer.output_shape</code></li>
</ul>
<h4 id="共享层"><a href="#共享层" class="headerlink" title="共享层"></a>共享层</h4><p>如果该层有多个计算节点（参考层计算节点和共享层）</p>
<ul>
<li>输入张量：<code>layer.get_input_at(node_index)</code></li>
<li>输出张量：<code>layer.get_output_at(node_index)</code></li>
<li>输入数据形状：<code>layer.get_input_shape_at(node_index)</code></li>
<li>输出数据形状：<code>layer.get_output_shape_at(node_index)</code></li>
</ul>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><h4 id="shape类型"><a href="#shape类型" class="headerlink" title="shape类型"></a>shape类型</h4><ul>
<li><p>batch_size</p>
<ul>
<li>batch_size在实际数据输入中为首维（0维）</li>
<li>shape类型参数传递的tuple中一般不包括batch_size维度</li>
<li>输出时使用<code>None</code>表示<code>(batch_size,...)</code></li>
</ul>
</li>
<li><p>time_step</p>
<ul>
<li>对时序数据，time_step在实际数据输入中第二维（1维）</li>
</ul>
</li>
</ul>
<h5 id="input-shape"><a href="#input-shape" class="headerlink" title="input_shape"></a><code>input_shape</code></h5><ul>
<li><p>是<code>Layer</code>的初始化参数，所有<code>Layer</code>子类都具有</p>
</li>
<li><p>如果Layer是首层，需要传递该参数指明输入数据形状，否则
无需传递该参数</p>
<ul>
<li>有些子类有类似于<code>input_dim</code>等参数具有<code>input_shape</code>
部分功能</li>
</ul>
</li>
<li><p><code>None</code>：表示该维度变长</p>
</li>
</ul>
<h3 id="输入、输出"><a href="#输入、输出" class="headerlink" title="输入、输出"></a>输入、输出</h3><ul>
<li><p>channels/depth/features：时间、空间单位上独立的数据，
卷积应该在每个channal分别“独立”进行</p>
<ul>
<li>对1维时序（时间），channels就是每时刻的features</li>
<li>对2维图片（空间），channels就是色彩通道</li>
<li>对3维视频（时空），channels就是每帧色彩通道</li>
<li>中间数据，channnels就是每个filters的输出</li>
</ul>
</li>
<li><p><em>1D</em>：<code>(batch, dim, channels)</code>（<em>channels_last</em>）</p>
</li>
<li><p><em>2D</em>：<code>(batch, dim_1, dim_2, channels)</code>
（<em>channels_last</em>）</p>
</li>
<li><p><em>3D</em>：<code>(batch, dim_1, dim_2, dim_3, channels)</code>
（<em>channels_last</em>）</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-02-20T15:58:15.000Z" title="2/20/2019, 11:58:15 PM">2019-02-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-02-17T03:57:07.000Z" title="2/17/2019, 11:57:07 AM">2019-02-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a><span> / </span><a class="link-muted" href="/categories/Python/Keras/">Keras</a></span><span class="level-item">3 minutes read (About 472 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Python/Keras/advanced_activations_layers.html">高级激活层</a></h1><div class="content"><h3 id="LeakyReLU"><a href="#LeakyReLU" class="headerlink" title="LeakyReLU"></a>LeakyReLU</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.LeakyReLU(alpha=<span class="number">0.3</span>)</span><br></pre></td></tr></table></figure>
<p>带泄漏的修正线性单元。</p>
<ul>
<li><p>返回值：当神经元未激活时，它仍可以赋予其一个很小的梯度</p>
<ul>
<li><code>x &lt; 0</code>：<code>alpha * x</code></li>
<li><code>x &gt;= 0</code>：<code>x</code></li>
</ul>
</li>
<li><p>输入尺寸</p>
<ul>
<li>可以是任意的。如果将该层作为模型的第一层，需要指定
<code>input_shape</code>参数（整数元组，不包含样本数量的维度）</li>
</ul>
</li>
<li><p>输出尺寸：与输入相同</p>
</li>
<li><p>参数</p>
<ul>
<li><code>alpha</code>：<code>float &gt;= 0</code>，负斜率系数。</li>
</ul>
</li>
<li><p>参考文献</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf">Rectifier Nonlinearities Improve Neural Network Acoustic Models</a></li>
</ul>
</li>
</ul>
<h3 id="PReLU"><a href="#PReLU" class="headerlink" title="PReLU"></a>PReLU</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.PReLU(</span><br><span class="line">	alpha_initializer=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line">	alpha_regularizer=<span class="literal">None</span>,</span><br><span class="line">	alpha_constraint=<span class="literal">None</span>,</span><br><span class="line">	shared_axes=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>参数化的修正线性单元。</p>
<ul>
<li><p>返回值</p>
<ul>
<li><code>x &lt; 0</code>：<code>alpha * x</code></li>
<li><code>x &gt;= 0</code>：<code>x</code></li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>alpha_initializer</code>: 权重的初始化函数。</li>
<li><code>alpha_regularizer</code>: 权重的正则化方法。</li>
<li><code>alpha_constraint</code>: 权重的约束。</li>
<li><code>shared_axes</code>: 激活函数共享可学习参数的轴。
如果输入特征图来自输出形状为
<code>(batch, height, width, channels)</code>
的2D卷积层，而且你希望跨空间共享参数，以便每个滤波
器只有一组参数，可设置<code>shared_axes=[1, 2]</code></li>
</ul>
</li>
<li><p>参考文献</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.01852">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></li>
</ul>
</li>
</ul>
<h3 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.ELU(alpha=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<p>指数线性单元</p>
<ul>
<li><p>返回值</p>
<ul>
<li><code>x &lt; 0</code>：<code>alpha * (exp(x) - 1.)</code></li>
<li><code>x &gt;= 0</code>：<code>x</code></li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>alpha</code>：负因子的尺度。</li>
</ul>
</li>
<li><p>参考文献</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.07289v1">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</a></li>
</ul>
</li>
</ul>
<h3 id="ThresholdedReLU"><a href="#ThresholdedReLU" class="headerlink" title="ThresholdedReLU"></a>ThresholdedReLU</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.ThresholdedReLU(theta=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<p>带阈值的修正线性单元。</p>
<ul>
<li><p>返回值</p>
<ul>
<li><code>x &gt; theta</code>：<code>x</code></li>
<li><code>x &lt;= theta</code>：0</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>theta</code>：<code>float &gt;= 0</code>激活的阈值位。</li>
</ul>
</li>
<li><p>参考文献</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1402.3337">Zero-Bias Autoencoders and the Benefits of Co-Adapting Features</a></li>
</ul>
</li>
</ul>
<h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Softmax(axis=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>Softmax激活函数</p>
<ul>
<li>参数<ul>
<li><code>axis</code>: 整数，应用 softmax 标准化的轴。</li>
</ul>
</li>
</ul>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.ReLU(max_value=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>ReLU激活函数</p>
<ul>
<li>参数<ul>
<li><code>max_value</code>：浮点数，最大的输出值。</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-02-20T15:58:15.000Z" title="2/20/2019, 11:58:15 PM">2019-02-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-02-17T03:57:07.000Z" title="2/17/2019, 11:57:07 AM">2019-02-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a><span> / </span><a class="link-muted" href="/categories/Python/Keras/">Keras</a></span><span class="level-item">11 minutes read (About 1690 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Python/Keras/core_layers.html">常用层</a></h1><div class="content"><p>常用层对应于core模块，core内部定义了一系列常用的网络层，包括
全连接、激活层等</p>
<h2 id="Dense层"><a href="#Dense层" class="headerlink" title="Dense层"></a>Dense层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.Dense(</span><br><span class="line">	units,</span><br><span class="line">	activation=<span class="literal">None</span>,</span><br><span class="line">	use_bias=<span class="literal">True</span>,</span><br><span class="line">	kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line">	bias_initializer=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line">	kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">	bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">	activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">	kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">	bias_constraint=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Dense就是常用的全连接层</p>
<ul>
<li><p>用途：实现运算$output = activation(dot(input, kernel)+bias)$</p>
<ul>
<li><code>activation</code>：是逐元素计算的激活函数</li>
<li><code>kernel</code>：是本层的权值矩阵</li>
<li><code>bias</code>：为偏置向量，只有当<code>use_bias=True</code>才会添加</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><p><code>units</code>：大于0的整数，代表该层的输出维度。</p>
</li>
<li><p><code>activation</code>：激活函数</p>
<ul>
<li>为预定义的激活函数名（参考激活函数）</li>
<li>逐元素（element-wise）的Theano函数</li>
<li>不指定该参数，将不会使用任何激活函数
（即使用线性激活函数：a(x)=x）</li>
</ul>
</li>
<li><p><code>use_bias</code>: 布尔值，是否使用偏置项</p>
</li>
<li><p><code>kernel_initializer</code>：权值初始化方法</p>
<ul>
<li>预定义初始化方法名的字符串</li>
<li>用于初始化权重的初始化器（参考initializers）</li>
</ul>
</li>
<li><p><code>bias_initializer</code>：偏置向量初始化方法</p>
<ul>
<li>为预定义初始化方法名的字符串</li>
<li>用于初始化偏置向量的初始化器（参考initializers）</li>
</ul>
</li>
<li><p><code>kernel_regularizer</code>：施加在权重上的正则项，为
Regularizer对象</p>
</li>
<li><p><code>bias_regularizer</code>：施加在偏置向量上的正则项，为
Regularizer对象</p>
</li>
<li><p><code>activity_regularizer</code>：施加在输出上的正则项，为
Regularizer对象</p>
</li>
<li><p><code>kernel_constraints</code>：施加在权重上的约束项，为<br>Constraints对象</p>
</li>
<li><p><code>bias_constraints</code>：施加在偏置上的约束项，为
Constraints对象</p>
</li>
</ul>
</li>
<li><p>输入</p>
<ul>
<li>形如<code>(batch_size, ..., input_dim)</code>的NDT，最常见情况
为<code>(batch_size, input_dim)</code>的2DT</li>
<li>数据的维度大于2，则会先被压为与<code>kernel</code>相匹配的大小</li>
</ul>
</li>
<li><p>输出</p>
<ul>
<li>形如<code>(batch_size, ..., units)</code>的NDT，最常见的情况为
$(batch_size, units)$的2DT</li>
</ul>
</li>
</ul>
<h2 id="Activation层"><a href="#Activation层" class="headerlink" title="Activation层"></a>Activation层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.Activation(</span><br><span class="line">	activation,</span><br><span class="line">	input_shape</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>激活层对一个层的输出施加激活函数</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>activation</code>：将要使用的激活函数<ul>
<li>预定义激活函数名</li>
<li>Tensorflow/Theano的函数（参考激活函数）</li>
</ul>
</li>
</ul>
</li>
<li><p>输入：任意，使用激活层作为第一层时，要指定<code>input_shape</code></p>
</li>
<li><p>输出：与输入shape相同</p>
</li>
</ul>
<h2 id="Dropout层"><a href="#Dropout层" class="headerlink" title="Dropout层"></a>Dropout层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.Dropout(</span><br><span class="line">	rate,</span><br><span class="line">	noise_shape=<span class="literal">None</span>,</span><br><span class="line">	seed=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>为输入数据施加Dropout</p>
<ul>
<li><p>说明</p>
<ul>
<li><p>Dropout将在训练过程中每次更新参数时按一定概率<code>rate</code>
随机断开输入神经元</p>
</li>
<li><p>可以用于防止过拟合</p>
</li>
<li><p>参考文献：<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>参数</p>
<ul>
<li><p><code>rate</code>：0~1的浮点数，控制需要断开的神经元的比例</p>
</li>
<li><p><code>noise_shape</code>：整数张量，为将要应用在输入上的二值
Dropout mask的shape</p>
</li>
<li><p><code>seed</code>：整数，使用的随机数种子</p>
</li>
</ul>
</li>
<li><p>输入</p>
<ul>
<li>例：<code>(batch_size, timesteps, features)</code>，希望在各个
时间步上Dropout mask都相同，则可传入
<code>noise_shape=(batch_size, 1, features)</code></li>
</ul>
</li>
</ul>
<h2 id="Flatten层"><a href="#Flatten层" class="headerlink" title="Flatten层"></a>Flatten层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.Flatten()</span><br></pre></td></tr></table></figure>
<p>Flatten层用来将输入“压平”，把多维的输入一维化</p>
<ul>
<li>常用在从卷积层到全连接层的过渡</li>
<li>Flatten不影响batch的大小。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Convolution2D(<span class="number">64</span>, <span class="number">3</span>, <span class="number">3</span>,</span><br><span class="line">            border_mode=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">            input_shape=(<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)))</span><br><span class="line">	<span class="comment"># now: model.output_shape == (None, 64, 32, 32)</span></span><br><span class="line"></span><br><span class="line">model.add(Flatten())</span><br><span class="line">	<span class="comment"># now: model.output_shape == (None, 65536)</span></span><br></pre></td></tr></table></figure>
<h2 id="Reshape层"><a href="#Reshape层" class="headerlink" title="Reshape层"></a>Reshape层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.Reshape(</span><br><span class="line">	target_shape,</span><br><span class="line">	input_shape</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Reshape层用来将输入shape转换为特定的shape</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>target_shape</code>：目标shape，为整数的tuple，不包含样本
数目的维度（batch大小）<ul>
<li>包含<code>-1</code>表示推断该维度大小</li>
</ul>
</li>
</ul>
</li>
<li><p>输入：输入的shape必须固定（和<code>target_shape</code>积相同）</p>
</li>
<li><p>输出：<code>(batch_size, *target_shape)</code></p>
</li>
<li><p>例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Reshape((<span class="number">3</span>, <span class="number">4</span>), input_shape=(<span class="number">12</span>,)))</span><br><span class="line">	<span class="comment"># now: model.output_shape == (None, 3, 4)</span></span><br><span class="line">	<span class="comment"># note: `None` is the batch dimension</span></span><br><span class="line"></span><br><span class="line">model.add(Reshape((<span class="number">6</span>, <span class="number">2</span>)))</span><br><span class="line">	<span class="comment"># now: model.output_shape == (None, 6, 2)</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># also supports shape inference using `-1` as dimension</span></span><br><span class="line">model.add(Reshape((-<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">	<span class="comment"># now: model.output_shape == (None, 3, 2, 2)</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Permute层"><a href="#Permute层" class="headerlink" title="Permute层"></a>Permute层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.Permute(</span><br><span class="line">	dims(<span class="built_in">tuple</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Permute层将输入的维度按照给定模式进行重排</p>
<ul>
<li><p>说明</p>
<ul>
<li>当需要将RNN和CNN网络连接时，可能会用到该层。</li>
</ul>
</li>
<li><p>参数</p>
<ul>
<li><code>dims</code>：指定重排的模式，不包含样本数的维度（即下标
从1开始）</li>
</ul>
</li>
<li><p>输出shape</p>
<ul>
<li>与输入相同，但是其维度按照指定的模式重新排列</li>
</ul>
</li>
<li><p>例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Permute((<span class="number">2</span>, <span class="number">1</span>), input_shape=(<span class="number">10</span>, <span class="number">64</span>)))</span><br><span class="line">	<span class="comment"># now: model.output_shape == (None, 64, 10)</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="RepeatVector层"><a href="#RepeatVector层" class="headerlink" title="RepeatVector层"></a>RepeatVector层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.RepeatVector(</span><br><span class="line">	n(<span class="built_in">int</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>RepeatVector层将输入重复n次</p>
<ul>
<li><p>参数</p>
<ul>
<li><code>n</code>：整数，重复的次数</li>
</ul>
</li>
<li><p>输入：形如<code>(batch_size, features)</code>的张量</p>
</li>
<li><p>输出：形如<code>(bathc_size, n, features)</code>的张量</p>
</li>
<li><p>例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_dim=<span class="number">32</span>))</span><br><span class="line">	<span class="comment"># now: model.output_shape == (None, 32)</span></span><br><span class="line"></span><br><span class="line">model.add(RepeatVector(<span class="number">3</span>))</span><br><span class="line">	<span class="comment"># now: model.output_shape == (None, 3, 32)</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Lambda层"><a href="#Lambda层" class="headerlink" title="Lambda层"></a>Lambda层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.Lambda(</span><br><span class="line">	function,</span><br><span class="line">	output_shape=<span class="literal">None</span>,</span><br><span class="line">	mask=<span class="literal">None</span>,</span><br><span class="line">	arguments=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>对上一层的输出施以任何Theano/TensorFlow表达式</p>
<ul>
<li><p>参数</p>
<ul>
<li><p><code>function</code>：要实现的函数，该函数仅接受一个变量，即
上一层的输出</p>
</li>
<li><p><code>output_shape</code>：函数应该返回的值的shape，可以是一个
tuple，也可以是一个根据输入shape计算输出shape的函数</p>
</li>
<li><p><code>mask</code>: 掩膜</p>
</li>
<li><p><code>arguments</code>：可选，字典，用来记录向函数中传递的其他
关键字参数</p>
</li>
</ul>
</li>
<li><p>输出：<code>output_shape</code>参数指定的输出shape，使用TF时可自动
推断</p>
</li>
</ul>
<ul>
<li><p>例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.add(Lambda(<span class="keyword">lambda</span> x: x ** <span class="number">2</span>))</span><br><span class="line">	<span class="comment"># add a x -&gt; x^2 layer</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add a layer that returns the concatenation</span></span><br><span class="line"><span class="comment"># of the positive part of the input and</span></span><br><span class="line"><span class="comment"># the opposite of the negative part</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">antirectifier</span>(<span class="params">x</span>):</span></span><br><span class="line">	x -= K.mean(x, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">	x = K.l2_normalize(x, axis=<span class="number">1</span>)</span><br><span class="line">	pos = K.relu(x)</span><br><span class="line">	neg = K.relu(-x)</span><br><span class="line">	<span class="keyword">return</span> K.concatenate([pos, neg], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">antirectifier_output_shape</span>(<span class="params">input_shape</span>):</span></span><br><span class="line">	shape = <span class="built_in">list</span>(input_shape)</span><br><span class="line">	<span class="keyword">assert</span> <span class="built_in">len</span>(shape) == <span class="number">2</span>  <span class="comment"># only valid for 2D tensors</span></span><br><span class="line">	shape[-<span class="number">1</span>] *= <span class="number">2</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">tuple</span>(shape)</span><br><span class="line"></span><br><span class="line">model.add(Lambda(antirectifier,</span><br><span class="line">		 output_shape=antirectifier_output_shape))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="ActivityRegularizer层"><a href="#ActivityRegularizer层" class="headerlink" title="ActivityRegularizer层"></a>ActivityRegularizer层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.ActivityRegularization(</span><br><span class="line">	l1=<span class="number">0.0</span>,</span><br><span class="line">	l2=<span class="number">0.0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>经过本层的数据不会有任何变化，但会基于其激活值更新损失函数值</p>
<ul>
<li>参数<ul>
<li><code>l1</code>：1范数正则因子（正浮点数）</li>
<li><code>l2</code>：2范数正则因子（正浮点数）</li>
</ul>
</li>
</ul>
<h2 id="Masking层"><a href="#Masking层" class="headerlink" title="Masking层"></a>Masking层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.core.Masking(mask_value=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<p>使用给定的值对输入的序列信号进行“屏蔽”</p>
<ul>
<li><p>说明</p>
<ul>
<li>用以定位需要跳过的时间步</li>
<li>对于输入张量的时间步，如果输入张量在该时间步上都等于
<code>mask_value</code>，则该时间步将在模型接下来的所有层
（只要支持masking）被跳过（屏蔽）。</li>
<li>如果模型接下来的一些层不支持masking，却接受到masking
过的数据，则抛出异常</li>
</ul>
</li>
<li><p>输入：形如<code>(samples,timesteps,features)</code>的张量</p>
</li>
</ul>
<ul>
<li>例：缺少时间步为3和5的信号，希望将其掩盖<ul>
<li>方法：赋值<code>x[:,3,:] = 0., x[:,5,:] = 0.</code></li>
<li>在LSTM层之前插入<code>mask_value=0.</code>的Masking层<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Masking(mask_value=<span class="number">0.</span>, input_shape=(timesteps, features)))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>.`的Masking层
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Masking(mask_value=<span class="number">0.</span>, input_shape=(timesteps, features)))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>))</span><br></pre></td></tr></table></figure></p>
<p>```</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-02-20T15:58:15.000Z" title="2/20/2019, 11:58:15 PM">2019-02-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-02-17T03:57:07.000Z" title="2/17/2019, 11:57:07 AM">2019-02-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a><span> / </span><a class="link-muted" href="/categories/Python/Keras/">Keras</a></span><span class="level-item">2 minutes read (About 229 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Python/Keras/locally_connected_layers.html">LocallyConnceted 局部连接层</a></h1><div class="content"><p>LocallyConnnected和Conv差不多，只是Conv每层共享卷积核，
这里不同位置卷积核独立</p>
<h2 id="LocallyConnected1D层"><a href="#LocallyConnected1D层" class="headerlink" title="LocallyConnected1D层"></a>LocallyConnected1D层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.local.LocallyConnected1D(</span><br><span class="line">	filters,</span><br><span class="line">	kernel_size,</span><br><span class="line">	strides=<span class="number">1</span>,</span><br><span class="line">	padding=<span class="string">&quot;valid&quot;</span>,</span><br><span class="line">	data_format=<span class="literal">None</span>,</span><br><span class="line">	activation=<span class="literal">None</span>,</span><br><span class="line">	use_bias=<span class="literal">True</span>,</span><br><span class="line">	kernel_initializer=<span class="string">&quot;glorot_uniform&quot;</span>,</span><br><span class="line">	bias_initializer=<span class="string">&quot;zeros&quot;</span>,</span><br><span class="line">	kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">	bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">	activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">	kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">	bias_constraint=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>类似于<code>Conv1D</code>，单卷积核权重不共享</p>
<h2 id="LocallyConnected2D层"><a href="#LocallyConnected2D层" class="headerlink" title="LocallyConnected2D层"></a>LocallyConnected2D层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.local.LocallyConnected2D(</span><br><span class="line">	filters,</span><br><span class="line">	kernel_size,</span><br><span class="line">	strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">	padding=<span class="string">&quot;valid&quot;</span>,</span><br><span class="line">	data_format=<span class="literal">None</span>,</span><br><span class="line">	activation=<span class="literal">None</span>,</span><br><span class="line">	use_bias=<span class="literal">True</span>,</span><br><span class="line">	kernel_initializer=<span class="string">&quot;glorot_uniform&quot;</span>,</span><br><span class="line">	bias_initializer=<span class="string">&quot;zeros&quot;</span>,</span><br><span class="line">	kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">	bias_regularizer=<span class="literal">None</span>,</span><br><span class="line">	activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">	kernel_constraint=<span class="literal">None</span>,</span><br><span class="line">	bias_constraint=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>类似<code>Conv2D</code>，区别是不进行权值共享</p>
<ul>
<li>说明<ul>
<li>输出的行列数可能会因为填充方法而改变</li>
</ul>
</li>
<li>例<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(LocallyConnected2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)))</span><br><span class="line">	<span class="comment"># apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image</span></span><br><span class="line">	<span class="comment"># with `data_format=&quot;channels_last&quot;`:</span></span><br><span class="line">	<span class="comment"># now model.output_shape == (None, 30, 30, 64)</span></span><br><span class="line">	<span class="comment"># notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64 parameters</span></span><br><span class="line"></span><br><span class="line">model.add(LocallyConnected2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line">	<span class="comment"># now model.output_shape == (None, 28, 28, 32)</span></span><br><span class="line">	<span class="comment"># add a 3x3 unshared weights convolution on top, with 32 output filters:</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/tags/Machine-Learning/page/6/">Previous</a></div><div class="pagination-next"><a href="/tags/Machine-Learning/page/8/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/tags/Machine-Learning/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/tags/Machine-Learning/page/6/">6</a></li><li><a class="pagination-link is-current" href="/tags/Machine-Learning/page/7/">7</a></li><li><a class="pagination-link" href="/tags/Machine-Learning/page/8/">8</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5385776267343559" data-ad-slot="6995841235" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>