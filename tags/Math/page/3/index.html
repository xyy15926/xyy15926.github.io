<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: Math - UBeaRLy</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="UBeaRLy"><meta property="og:url" content="https://xyy15926.github.io/"><meta property="og:site_name" content="UBeaRLy"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:author" content="UBeaRLy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io"},"headline":"UBeaRLy","image":["https://xyy15926.github.io/img/og_image.png"],"author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"UBeaRLy","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":""}</script><link rel="alternate" href="/atom.xml" title="UBeaRLy" type="application/atom+xml"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="follow_it-verification-code" content="SVBypAPPHxjjr7Y4hHfn"><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Math</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:18:42.000Z" title="8/4/2021, 11:18:42 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Functional-Analysis/">Functional Analysis</a></span><span class="level-item">a few seconds read (About 55 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Functional-Analysis/norm.html">Norm</a></h1><div class="content"><h2 id="Norm"><a href="#Norm" class="headerlink" title="Norm"></a><em>Norm</em></h2><h3 id="mathcal-L-p-范数"><a href="#mathcal-L-p-范数" class="headerlink" title="$\mathcal{L_p}$ 范数"></a>$\mathcal{L_p}$ 范数</h3><ul>
<li><p>$\mathcal{L_p}$ 范数</p>
<script type="math/tex; mode=display">
\|x\|_p = (|x_1|^p + |x_2|^p + \cdots + |x_N|^p)^{1/p}</script><blockquote>
<ul>
<li>$x \in R^n$</li>
</ul>
</blockquote>
</li>
<li><p>$\mathcal{L_p}$ <em>Dual Norm</em> 对偶范数</p>
<script type="math/tex; mode=display">
\|x\|^{*} = \mathop \sup_{z}{x^Tz|\|z\| \leq 1}</script><blockquote>
<ul>
<li>$x \in R^N$</li>
<li>$|x|$：$x$的某个范数</li>
</ul>
</blockquote>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">7 minutes read (About 1060 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/unconstrained_problems_thoeries.html">无约束优化</a></h1><div class="content"><h2 id="无约束局部解"><a href="#无约束局部解" class="headerlink" title="无约束局部解"></a>无约束局部解</h2><script type="math/tex; mode=display">
minf(x), x \in R^n</script><blockquote>
<ul>
<li>若存在$x^{ <em> } \in R^n, \epsilon &gt; 0, \forall x \in R^n$
  使得$|x - x^{ </em> }| &lt; \epsilon$时，恒有</li>
<li>$f(x) \geq f(x^{ <em> })$：则称$x^{ </em> }$为f(x)的
  <em>local minimum point/solution</em>（局部极小点/局部解）</li>
<li>$f(x) &gt; f(x^{ <em> })$：则称$x^{ </em> }$为f(x)的
  严格局部极小点/局部解</li>
</ul>
</blockquote>
<h2 id="最优性条件"><a href="#最优性条件" class="headerlink" title="最优性条件"></a>最优性条件</h2><h3 id="First-Order-Necessary-Condtion"><a href="#First-Order-Necessary-Condtion" class="headerlink" title="First-Order Necessary Condtion"></a><em>First-Order Necessary Condtion</em></h3><blockquote>
<ul>
<li>无约束问题局部解的一阶必要条件：设f(x)有连续的一阶偏导，
  弱$x^{ * }$是无约束问题的局部解，则<script type="math/tex; mode=display">\triangledown f(x{* }) = 0</script></li>
</ul>
</blockquote>
<h3 id="Second-Order-Necessary-Condition"><a href="#Second-Order-Necessary-Condition" class="headerlink" title="Second-Order Necessary Condition"></a><em>Second-Order Necessary Condition</em></h3><blockquote>
<ul>
<li>无约束问题局部解的二阶必要条件：设f(x)有连续二阶偏导，
  若$x^{ * }$是无约束问题的局部解，则<blockquote>
<ul>
<li><script type="math/tex; mode=display">\triangledown f(x^{ * }) = 0</script></li>
<li><script type="math/tex; mode=display">\triangledown^2 f(x^{ * })半正定</script></li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h3 id="Second-Order-Sufficient-Condition"><a href="#Second-Order-Sufficient-Condition" class="headerlink" title="Second-Order Sufficient Condition"></a><em>Second-Order Sufficient Condition</em></h3><blockquote>
<ul>
<li>无约束问题局部解的二阶充分条件：设f(x)有连续二阶偏导，
  若在$x^{ <em> }$处满足以下，则x^{ </em> }是无约束问题的
  <strong>严格局部解</strong><blockquote>
<ul>
<li><script type="math/tex; mode=display">\triangledown f(x^{ * }) = 0</script></li>
<li><script type="math/tex; mode=display">\triangledown^2 f(x^{ * })正定</script></li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h2 id="下降算法"><a href="#下降算法" class="headerlink" title="下降算法"></a>下降算法</h2><p>迭代算法：将当前迭代点<strong>向正确方向</strong>移动<strong>一定步长</strong>，然后
检验目标值是否满足一定要求</p>
<ul>
<li><strong>方向</strong>、<strong>步长</strong>就是不同优化算法主要关心的两个方面</li>
<li>还关心算法的<em>rate of convergence</em>（收敛速率）</li>
</ul>
<h3 id="一般下降算法框架"><a href="#一般下降算法框架" class="headerlink" title="一般下降算法框架"></a>一般下降算法框架</h3><ol>
<li><p>取初始点$x^{(1)}$，置精度要求$\epsilon$，置k=1</p>
</li>
<li><p>若在点$x^{(k)}$处满足某个终止准则，则停止计算，得无约束
优化问题最优解$x^{(k)}$，否则<strong>适当地选择</strong>$x^{(k)}$处
<strong>搜索方向</strong></p>
</li>
<li><p>进行<strong>适当的一维搜索</strong>，求解一维问题</p>
<script type="math/tex; mode=display">
\arg\min_{\alpha} \phi(\alpha) =
  f(x^{(k)} + \alpha d^{(k)})</script></li>
<li><p>置k=k+1，转2</p>
</li>
</ol>
<p>要使下降算法可行，需要确定</p>
<ul>
<li>某点出搜索方向<ul>
<li>负梯度方向</li>
<li>Newton方向：求方向的时候已确定步长，也可用做步长搜索</li>
<li>拟Newton方向</li>
</ul>
</li>
<li>求步长地一维搜索方式<ul>
<li>试探法<ul>
<li>0.618法</li>
<li>Fibonacci方法（分数法）</li>
<li>二分法</li>
</ul>
</li>
<li>插值法<ul>
<li>三点二次插值法</li>
<li>二点二次插值法</li>
<li>两点三次插值法</li>
</ul>
</li>
<li>非精确一维搜索方法<ul>
<li>Glodstein方法</li>
<li>Armijo方法</li>
<li>Wolfe-Powell方法</li>
</ul>
</li>
</ul>
</li>
<li><p>算法终止准则</p>
<ul>
<li>$|\triangledown f(x^{(k)})| &lt; \epsilon$</li>
<li>$|x^{(k+1)} - x^{(k)}| &lt; \epsilon$</li>
<li>$|f(x^{(k+1)}) - f(x^{(k)})| &lt; \epsilon$</li>
</ul>
<blockquote>
<ul>
<li>实际计算中最优解可能永远无法迭代达到，应该采用较弱
 终止准则</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="算法收敛性"><a href="#算法收敛性" class="headerlink" title="算法收敛性"></a>算法收敛性</h3><blockquote>
<ul>
<li>收敛：序列${x^{(k)}}$或其一个子列（仍记${x^{(k)}}$）
  满足<script type="math/tex; mode=display">
  \lim_{k \rightarrow \infty} x^{(k)} = x^{ * }</script><blockquote>
<ul>
<li>$x^{ * }$：无约束问题局部解</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<p>但是这样强的结果难以证明</p>
<ul>
<li>往往只能证明${x^{(k)}}$的任一聚点的稳定点</li>
<li>或是更弱的<script type="math/tex; mode=display">
\lim_{k \rightarrow \infty} inf
   \|\triangledown f(x^{(k)}) \| = 0</script></li>
</ul>
<blockquote>
<ul>
<li>局部收敛算法：只有初始点充分靠近极小点时，才能保证产生
  序列收敛</li>
<li>全局收敛算法：对任意初始点，产生序列均能收敛</li>
</ul>
</blockquote>
<h4 id="收敛速率"><a href="#收敛速率" class="headerlink" title="收敛速率"></a>收敛速率</h4><p>设序列${x^{(k)}}$收敛到$x^{ * }$，若以下极限存在</p>
<script type="math/tex; mode=display">
\lim _ {k \rightarrow \infty} \frac {\|x^{(k+1)} - x^{*}\|}
    {\|x^{(k)} - x^{*}\|} = \beta</script><blockquote>
<ul>
<li>$0 &lt; \beta &lt; 1$：线性收敛</li>
<li>$\beta = 0$：超线性收敛</li>
<li>$\beta = 1$：次线性收敛（收敛速率太慢，一般不考虑）</li>
</ul>
</blockquote>
<h4 id="算法的二次终止性"><a href="#算法的二次终止性" class="headerlink" title="算法的二次终止性"></a>算法的二次终止性</h4><blockquote>
<ul>
<li>二次终止性：若某算法对任意正定二次函数，从任意初始点出发
  ，都能经过有限步迭代达到其极小点，则称该算法有二次终止性</li>
</ul>
</blockquote>
<p>具有二次终止性的算法被认为时好算法，否则计算效果较差，原因</p>
<ul>
<li><p>正定二次目标函数有某些好的性质，好的算法应该能在有限步内
达到其极小点</p>
</li>
<li><p>对于一个一般的目标函数，若其在极小点处的Hesse矩阵
$\triangledown f(x^{( * )})$，则由泰勒展开式得到</p>
<script type="math/tex; mode=display">\begin{align*}
f(x) & = f(x^{*}) + \triangledown f(x^ {*})^T(x - x^{*}) \\
   & + \frac 1 2 (x - x^{*})^T \triangledown^2 f(x^{*})
       (x - x^{*}) \\
   & + o(\|x - x^{*}\|^2)
\end{align*}</script><p>即目标函数f(x)在极小点附近与一个正定二次函数近似，所以对
正定二次函数好的算法，对一般目标函数也应该具有较好的性质</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">17 minutes read (About 2586 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/optimization_problems.html">凸优化问题</a></h1><div class="content"><h2 id="Linear-Programming"><a href="#Linear-Programming" class="headerlink" title="Linear Programming"></a><em>Linear Programming</em></h2><h3 id="数学模型"><a href="#数学模型" class="headerlink" title="数学模型"></a>数学模型</h3><h4 id="一般数学模型"><a href="#一般数学模型" class="headerlink" title="一般数学模型"></a>一般数学模型</h4><p>线性规划问题（LP）可以抽象为一般的数学模型</p>
<script type="math/tex; mode=display">\begin{array}{l}
(\min_x, \max_x) & S=c_1 x_1 + c_2 x_2 + \cdots + c_n x_n \\
s.t. & \left \{ \begin{array} {l}
        a_{1,1} x_1 + a_{1,2} x_2 + \cdots + a_{1,n} x_n (\geq = \leq) b_1 \\
        a_{2,1} x_1 + a_{2,2} x_2 + \cdots + a_{2,n} x_n (\geq = \leq) b_2 \\
        \vdots \\
        a_{m,1} x_1 + a_{m,2} x_2 + \cdots + a_{m,n} x_n (\geq = \leq) b_m
    \end{array} \right.
\end{array}</script><blockquote>
<ul>
<li>$S = c_1 x_1 + c_2 x_2 + \cdots + c_n x_n$：目标函数</li>
<li>$x_1, x_2, …, x_n$：待求解变量</li>
<li>$b<em>i、c_i、a</em>{ij}$：实常数</li>
<li>$(\geq = \leq)$：在三种符号中取一种</li>
</ul>
</blockquote>
<h4 id="标准形式"><a href="#标准形式" class="headerlink" title="标准形式"></a>标准形式</h4><script type="math/tex; mode=display">\begin{array}{l}
\min_x & S=c_1 x_1 + c_2 x_2 + \cdots + c_n x_n \\
s.t. & a_{1,1} x_1 + a_{1,2} x_2 + \cdots + a_{1,n} x_n = b_1 \\
& \vdots \\
& a_{t,1} x_1 + a_{t,2} x_2 + \cdots + a_{t,n} x_n = b_t \\
& a_{t+1,1} x_1 + a_{t+1,2} x_2 + \cdots + a_{t+1, n} x_n
    \leq b_{t+1} \\
& \vdots \\
& a_{t+l,1} x_1 + a_{t+l,2} x_2 + \cdots + a_{t+l, n} x_n
    \leq b_{t+l} \\
\end{array}</script><blockquote>
<ul>
<li>$\max_x$：目标函数取翻转换为$\min_x$</li>
<li><p>$\geq$：不等式左右取反转换为$\leq$</p>
</li>
<li><p>线性规划一般模式都可以等价转换为标准形式</p>
</li>
</ul>
</blockquote>
<h3 id="Simplex-Method"><a href="#Simplex-Method" class="headerlink" title="Simplex Method"></a>Simplex Method</h3><p>单纯型法：利用线性规划极值点必然在单纯型顶点取得，不断迭代顶点求出极值</p>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><ul>
<li>初始化：标准化线性规划问题，建立初始表格<ul>
<li>最小化目标函数：目标函数系数取反，求极大</li>
<li>不等式约束：加入松弛变量（代表不等式两端差值）</li>
<li>变量非负：定义为两个非负变量之差</li>
</ul>
</li>
<li>最优测试<ul>
<li>若目标行系数都为非负，得到最优解，迭代停止</li>
<li>基变量解在右端列中，非基变量解为 0</li>
</ul>
</li>
<li>确定主元列<ul>
<li>从目标行的前 $n$ 个单元格中选择一个非负单元格，确定主元列</li>
<li>选择首个非负：解稳定，若存在最优解总是能取到</li>
<li>选择绝对值最大：目标函数下降快，但有可能陷入死循环，无法得到最优解（不满足最优条件）</li>
</ul>
</li>
<li><p>确定主元（分离变量）（行）</p>
<ul>
<li>对主元列所有正系数，计算右端项和其比值 $\Theta$ 比率</li>
<li>最小 $\Theta$ 比率确定主元（行）（类似的为避免死循环，总是选择首个最小者）</li>
</ul>
</li>
<li><p>转轴变换（建立新单纯形表）</p>
<ul>
<li>主元变 1：主元行所有变量除以主元</li>
<li>主元列变 0：其余行减去其主元列倍主元行</li>
<li>交换基变量：主元行变量标记为主元列对应变量</li>
</ul>
</li>
</ul>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>算法时间效率<ul>
<li>极点规模随着问题规模指数增长，所以最差效率是指数级</li>
<li>实际应用表明，对 $m$ 个约束、$n$ 个变量的问题，算法迭代次数在 $m$ 到 $3m$ 之间，每次迭代次数正比于 $nm$</li>
</ul>
</li>
<li>迭代改进</li>
</ul>
<h3 id="Two-Phase-Simplex-Method"><a href="#Two-Phase-Simplex-Method" class="headerlink" title="Two-Phase Simplex Method"></a>Two-Phase Simplex Method</h3><p>两阶段单纯形法：单纯型表中没有单元矩阵，无法方便找到基本可行解时使用</p>
<ul>
<li>在给定问题的约束等式中加入人工变量，使得新问题具有明显可行解</li>
<li>利用单纯形法求解最小化新的线性规划问题</li>
</ul>
<h3 id="其他一些算法"><a href="#其他一些算法" class="headerlink" title="其他一些算法"></a>其他一些算法</h3><ul>
<li>大 M 算法</li>
<li><em>Ellipsoid Method</em> 椭球算法<ul>
<li>算法时间效率<ul>
<li>可以在多项式时间内对任意线性规划问题求解</li>
<li>实际应用效果较单纯形法差，但是最差效率更好</li>
</ul>
</li>
</ul>
</li>
<li><em>Karmarkar</em> 算法<ul>
<li>内点法（迭代改进）</li>
</ul>
</li>
</ul>
<h2 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h2><script type="math/tex; mode=display">\begin{array}{l}
\min_x & f(x) \\
s.t. & g_i(x) \leq 0, i=1，2,\cdots,k \\
& h_i(x) = 0, i=1,2,\cdots,l
\end{array}</script><blockquote>
<ul>
<li>$f(x), g(x)$：$R^n$ 上连续可微的凸函数</li>
<li>$h_i(x)$：$R^n$ 上仿射函数</li>
<li>仿射函数：满足 $f(x)=ax+b, a \in R^n, b \in R, x \in R^n$</li>
</ul>
</blockquote>
<h3 id="二次规划"><a href="#二次规划" class="headerlink" title="二次规划"></a>二次规划</h3><script type="math/tex; mode=display">\begin{array}{l}
\min_x & f(x)=\frac 1 2 x^TGx + c^Tx \\
s.t. & Ax \leq b
\end{array}</script><blockquote>
<ul>
<li>$G \in R^{n * n}$：$n$ 阶实对称矩阵</li>
<li>$A \in R^{m <em> n}$：$m </em> n$ 实矩阵</li>
<li>$b \in R^m$</li>
<li>$c \in R^n$</li>
</ul>
</blockquote>
<ul>
<li><p>$G$ 正定</p>
<ul>
<li>此时目标函数 $f(x)$ 为凸函数</li>
<li>凸二次规划</li>
<li>问题有唯一全局最小值</li>
<li>问题可可由椭球法在多项式时间内求解</li>
</ul>
</li>
<li><p>$G$ 半正定</p>
<ul>
<li>此时目标函数 $f(x)$ 为凸函数</li>
<li>半定规划</li>
<li>若约束条件可行域不空，且目标函数在此可行域有下界，则问题有全局最小值</li>
</ul>
</li>
<li><p>$G$非正定</p>
<ul>
<li>目标函数有多个平稳点（局部极小），<em>NP-hard</em> 问题</li>
</ul>
</li>
</ul>
<h4 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h4><ul>
<li>椭球法</li>
<li>内点法</li>
<li>增广拉格朗日法</li>
<li>投影梯度法</li>
</ul>
<h3 id="二阶锥规划"><a href="#二阶锥规划" class="headerlink" title="二阶锥规划"></a>二阶锥规划</h3><script type="math/tex; mode=display">\begin{array}{l}
\min_x & f^Tx \\
s.t. & \|A_ix + b_i \|_2 \leq c_i^Tx + d_i, i=1,2,\cdots,m  \\
    & Bx=g
\end{array}</script><blockquote>
<ul>
<li>$f \in R^n$</li>
<li>$A_i \in R^{n_i * n}$，$b_i \in R^{n_i}$，$c_i \in R^{n_i}$，$d_i \in R$</li>
<li>$B \in R^{p * n}$，$g \in R^n$</li>
</ul>
</blockquote>
<ul>
<li><p>$A_i=0,i=1,\cdots,m$：退化为线性规划</p>
</li>
<li><p>一般的二阶规划可以转换为二阶锥规划</p>
<script type="math/tex; mode=display">
X^TAX + qTX + C \leq 0 \Rightarrow
   \|A^{1/2}x + \frac 1 2 A^{-1/2}q\|^{1/2} \leq
   -\frac 1 4 q^TA^{-1}q - c</script></li>
</ul>
<blockquote>
<ul>
<li>二阶锥规划可以使用内点法很快求解（多项式时间）</li>
</ul>
</blockquote>
<h2 id="非线性最小二乘"><a href="#非线性最小二乘" class="headerlink" title="非线性最小二乘"></a>非线性最小二乘</h2><script type="math/tex; mode=display">\begin{align*}
f(x) & = \frac 1 2 \sum_{i=1}^m r^2_i(x) \\
& = \frac 1 2 r(x) r^T(x)
\end{align*}</script><blockquote>
<ul>
<li>$r_i(x)$：通常为非线性函数</li>
<li>$r(x) = (r_1(x), \cdots, r_n(x))^T$</li>
<li>$x \in R^n, m \geq n$</li>
</ul>
</blockquote>
<ul>
<li><p>考虑目标函数梯度、<em>Hesse</em> 矩阵</p>
<script type="math/tex; mode=display">\begin{align*}
\nabla f(x) & = \sum_{i=1}^m \nabla r_i(x)
   r_i(x) \\
& = J(x)^T r(x) \\

\nabla^2 f(x) & = \sum_{i=1}^m \nabla r_i(x)
   r_i(x) + \sum_{i=1}^m r_i \nabla^2 r_i(x) \\
& = J(x)^T J(x) + \sum_{i=1}^m r_i(x) \nabla^2 r_i(x)
\end{align*}</script></li>
</ul>
<blockquote>
<ul>
<li><script type="math/tex; mode=display">
  J(x) = \begin{bmatrix}
  \frac {\partial r_1} {\partial x_1} &
      \frac {\partial r_1} {\partial x_2} & \cdots &
      \frac {\partial r_1} {\partial x_n} \\
  \frac {\partial r_2} {\partial x_1} &
      \frac {\partial r_2} {\partial x_2} & \cdots &
      \frac {\partial r_2} {\partial x_n} \\
  \vdots & \vdots & \ddots & \vdots \\
  \frac {\partial r_m} {\partial x_1} &
      \frac {\partial r_m} {\partial x_2} & \cdots &
      \frac {\partial r_m} {\partial x_n}
  \end{bmatrix}
  = \begin{bmatrix}
  \nabla r_1(x)^T \\
  \nabla r_2(x)^T \\
  \vdots \\
  \nabla r_m(x)^T \\
  \end{bmatrix}</script>  为$r(x)$的 <em>Jacobi</em> 矩阵</li>
</ul>
</blockquote>
<h3 id="Gauss-Newton-法"><a href="#Gauss-Newton-法" class="headerlink" title="Gauss-Newton 法"></a><em>Gauss-Newton</em> 法</h3><ul>
<li><p>为简化计算，略去 <em>Newton</em> 法中 <em>Hesse</em> 矩阵中 $\sum_{i=1}^m r_i(x) \nabla^2 r_i(x)$ 项，即直接求解方程组</p>
<script type="math/tex; mode=display">
J(x^{(k)})^T J(x^{(k)}) d = -J(x^{(k)})^T r(x^{(k)})</script></li>
<li><p>求解同一般 <em>Newton</em> 法</p>
</li>
</ul>
<h4 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h4><ul>
<li><p>实际问题中</p>
<ul>
<li>局部解 $x^{ <em> }$ 对应的目标函数值 $f(x^{ </em> })$ 接近 0 时，采用 <em>Gauss-Newton</em> 法效果较好，此时<ul>
<li>$|r(x^{(k)})|$ 较小</li>
<li>曲线$r_i(x)$接近直线</li>
<li>$\nabla^2 r_i(x) \approx 0$</li>
</ul>
</li>
<li>否则效果一般</li>
</ul>
</li>
<li><p>矩阵 $J(x^{(k)})^T J(x^{(k)})$ 是半正定矩阵</p>
<ul>
<li>当 <em>Jacobi</em> 矩阵列满秩时为正定矩阵，此时虽然 $d^{(k)}$ 是下降方向，但仍需类似修正牛顿法增加一维搜索策略保证目标函数值不上升</li>
</ul>
</li>
</ul>
<h3 id="Levenberg-Marquardt-方法"><a href="#Levenberg-Marquardt-方法" class="headerlink" title="Levenberg-Marquardt 方法"></a><em>Levenberg-Marquardt</em> 方法</h3><ul>
<li><p>考虑到 $J(x^{(k)})$ 中各列线性相关、接近线性相关，求解 <em>Newton-Gauss </em>方法中的方程组会出现困难，可以改为求解</p>
<script type="math/tex; mode=display">
(J(x^{(k)})^T J(x^{(k)}) + vI) d = -J(x^{(k)})^T r(x^{(k)})</script></li>
</ul>
<blockquote>
<ul>
<li>$v$：迭代过程中需要调整的参数，<em>LM</em> 方法的关键即如何调整</li>
</ul>
</blockquote>
<h4 id="定理1"><a href="#定理1" class="headerlink" title="定理1"></a>定理1</h4><blockquote>
<ul>
<li>若 $d(v)$ 是以上方程组的解，则 $|d(v)|^2$ 是 $v$ 的连续下降函数，且 $v \rightarrow +\infty, |d(v)| \rightarrow 0$</li>
</ul>
</blockquote>
<ul>
<li><p>$J(x^{(k)})^T J(x^{(k)})$ 是对称半正定矩阵，则存在正交阵</p>
<script type="math/tex; mode=display">
(P^{(k)})^T J(x^{(k)})^T J(x^{(k)}) P^{(k)} = \Lambda^{(k)}</script></li>
<li><p>则可以解出 $|d(v)|^2$</p>
</li>
</ul>
<blockquote>
<ul>
<li>增大 $v$ 可以限制 $|d^{(k)}|$，所以 <em>LM</em> 方法也被称为阻尼最小二乘法</li>
</ul>
</blockquote>
<h4 id="定理2"><a href="#定理2" class="headerlink" title="定理2"></a>定理2</h4><blockquote>
<ul>
<li>若 $d(v)$ 是以上方程的解，则 $d(v)$ 是 $f(x)$ 在 $x^{(k)}$ 处的下降方向，且 $v \rightarrow + \infty$ 时，$d(v)$ 的方向与 $-J(x^{(k)})^T r(x^{(k)})$ 方向一致</li>
</ul>
</blockquote>
<ul>
<li>下降方向：$\nabla f(x^{(k)}) d(v) &lt; 0$ 即可</li>
<li>方向一致：夹角余弦</li>
</ul>
<blockquote>
<ul>
<li>$v$充分大时，<em>LM</em> 方法产生的搜索方向 $d^{(k)}$ 和负梯度方向一致</li>
</ul>
</blockquote>
<h4 id="参数调整方法"><a href="#参数调整方法" class="headerlink" title="参数调整方法"></a>参数调整方法</h4><blockquote>
<ul>
<li>使用梯度、近似 <em>Hesse</em> 矩阵定义二次函数<script type="math/tex; mode=display">
  q(d) = f(x^{(k)}) + (J(x^{(k)})^T r(x^{(k)}))^T d + \frac 1 2 d^T (J(x^{(k)})^T J(x^{(k)})) d</script></li>
</ul>
</blockquote>
<ul>
<li><p>其增量为</p>
<script type="math/tex; mode=display">\begin{align*}
\Delta q^{(k)} & = q(d^{(k)}) - q(0) \\
& = (J(x^{(k)})^T r(x^{(k)}))^T d^{(k)} + \frac 1 2
   (d^{(k)})^T (J(x^{(k)})^T J(x^{(k)})) d^{(k)}
\end{align*}</script></li>
<li><p>目标函数增量</p>
<script type="math/tex; mode=display">\begin{align*}
\Delta f^{(k)} & = f(x^{(k)} + d^{(k)}) - f(x^{(k)}) \\
& = f(x^{(k+1)}) - f(x^{(k)})
\end{align*}</script></li>
<li><p>定义$\gamma_k = \frac {\Delta f^{(k)}} {\Delta q^{(k)}}$</p>
<ul>
<li><p>$\gamma_k$接近1说明$\Delta f^{(k)}$接近$\Delta q^{(k)}$</p>
<ul>
<li>即$f(x^{(k)} + d^{(k+1)})$接近$q(d^{(k)})$</li>
<li>即$f(x)$在$x^{(k)}$附近接近二次函数</li>
<li>即使用Gauss-Newton方法求解最小二乘问题效果较好</li>
<li>即LM方法求解时$v$参数应该较小</li>
</ul>
</li>
<li><p>$\gamma_k$接近0说明$\Delta f^{(k)}$与$\Delta q^{(k)}$
近似程度不好</p>
<ul>
<li>$d^{(k)}$不应取得过大，应减少$d^{(k)}$得模长</li>
<li>应该增加参数$v$进行限制</li>
<li>迭代方向趋近于负梯度方向</li>
</ul>
</li>
<li><p>$\gamma_k$适中时，认为参数$v$选取合适，不做调整</p>
<ul>
<li>临界值通常为0.25、0.75</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h4><ol>
<li><p>初始点 $x^{(1)}$、初始参数 $v$（小值）、精度要求 $\epsilon$，置 $k=k+1$</p>
</li>
<li><p>若 $|J(x^{(k)})^T r(x^{(k)})| &lt; \epsilon$，则停止计算，得到问题解 $x^{(k)}$，否则求解线性方程组</p>
<script type="math/tex; mode=display">
(J(x^{(k)})^T J(x^{(k)}) + v_kI) d = -J(x^{(k)})^T
  r(x^{(k)})</script><p>得到 $d^{(k)}$</p>
</li>
<li><p>置 $x^{(k+1)} = x^{(k)} + d^{(k)}$，计算 $\gamma_k$</p>
</li>
<li><p>考虑 $\gamma$</p>
<ul>
<li>$\gamma &lt; 0.25$，置$v_{k+1} = 4 v_k$</li>
<li>$\gamma &gt; 0.75$，置$v_{k+1} = v_k / 2$</li>
<li>否则置$v_{k+1} = v_k$</li>
</ul>
</li>
<li><p>置k=k+1，转2</p>
</li>
</ol>
<h2 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h2><h3 id="整形规划"><a href="#整形规划" class="headerlink" title="整形规划"></a>整形规划</h3><p>整形规划：求线性函数的最值，函数包含若干<strong>整数变量</strong>，并且满足线性等式、不等式的有限约束</p>
<h3 id="Unregularized-Least-Squares-Learning-Problem"><a href="#Unregularized-Least-Squares-Learning-Problem" class="headerlink" title="Unregularized Least Squares Learning Problem"></a><em>Unregularized Least Squares Learning Problem</em></h3><script type="math/tex; mode=display">
w_T = \frac \gamma n \sum_{i=0}^{T-1} (I - \frac \gamma n
    {\hat X}^T \hat X)^i {\hat X}^T \hat Y</script><blockquote>
<ul>
<li>$\gamma$：被引入保证 $|I - \frac \gamma n {\hat X}^T \hat X| &lt; 1$</li>
</ul>
</blockquote>
<h4 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h4><ul>
<li><p>考虑</p>
<script type="math/tex; mode=display">
\min_w I_s(w) = \frac 1 {2n} \|\hat X w - \hat Y\|^2</script></li>
<li><p>将$w_{t+1}$带入$I_s(w)$即可证明每次迭代$I_s(w)$减小</p>
<script type="math/tex; mode=display">
w_0 = 0 \\
w_{t+1} = (I - \frac \gamma n {\hat X}^T \hat X)w_t + \frac \gamma n {\hat X}^T \hat Y</script></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Optimization/">Optimization</a></span><span class="level-item">7 minutes read (About 1121 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Optimization/unconstrained_specials.html">无约束优化特殊问题</a></h1><div class="content"><h2 id="正定二次目标函数"><a href="#正定二次目标函数" class="headerlink" title="正定二次目标函数"></a>正定二次目标函数</h2><script type="math/tex; mode=display">
min f(x) = \frac 1 2 x^T G x + r^T x + \sigma</script><h2 id="非线性最小二乘"><a href="#非线性最小二乘" class="headerlink" title="非线性最小二乘"></a>非线性最小二乘</h2><script type="math/tex; mode=display">\begin{align*}
f(x) & = \frac 1 2 \sum_{i=1}^m r^2_i(x) \\
& = \frac 1 2 r(x) r^T(x)
\end{align*}</script><blockquote>
<ul>
<li>$r_i(x)$：通常为非线性函数</li>
<li>$r(x) = (r_1(x), \cdots, r_n(x))^T$</li>
<li>$x \in R^n, m \geq n$</li>
</ul>
</blockquote>
<p>则</p>
<script type="math/tex; mode=display">\begin{align*}
\nabla f(x) & = \sum_{i=1}^m \nabla r_i(x)
    r_i(x) \\
& = J(x)^T r(x) \\

\nabla^2 f(x) & = \sum_{i=1}^m \nabla r_i(x)
    r_i(x) + \sum_{i=1}^m r_i \nabla^2 r_i(x) \\
& = J(x)^T J(x) + \sum_{i=1}^m r_i(x) \nabla^2 r_i(x)
\end{align*}</script><blockquote>
<ul>
<li><script type="math/tex; mode=display">
  J(x) = \begin{bmatrix}
  \frac {\partial r_1} {\partial x_1} &
      \frac {\partial r_1} {\partial x_2} & \cdots &
      \frac {\partial r_1} {\partial x_n} \\
  \frac {\partial r_2} {\partial x_1} &
      \frac {\partial r_2} {\partial x_2} & \cdots &
      \frac {\partial r_2} {\partial x_n} \\
  \vdots & \vdots & \ddots & \vdots \\
  \frac {\partial r_m} {\partial x_1} &
      \frac {\partial r_m} {\partial x_2} & \cdots &
      \frac {\partial r_m} {\partial x_n}
  \end{bmatrix}
  = \begin{bmatrix}
  \nabla r_1(x)^T \\
  \nabla r_2(x)^T \\
  \vdots \\
  \nabla r_m(x)^T \\
  \end{bmatrix}</script>  为$r(x)$的Jacobi矩阵</li>
</ul>
</blockquote>
<h3 id="Gauss-Newton法"><a href="#Gauss-Newton法" class="headerlink" title="Gauss-Newton法"></a>Gauss-Newton法</h3><p>Newton法中为简化计算，略去其Hesse矩阵中
$\sum_{i=1}^m r_i(x) \nabla^2 r_i(x)$项，即直接求解
方程组</p>
<script type="math/tex; mode=display">
J(x^{(k)})^T J(x^{(k)}) d = -J(x^{(k)})^T r(x^{(k)})</script><h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>同Newton法，仅求解Newton方程改为求解以上方程组</p>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul>
<li><p>实际问题中</p>
<ul>
<li>局部解$x^{ <em> }$对应的目标函数值$f(x^{ </em> })$接近0
时，$|r(x^{(k)})|$较小</li>
<li>曲线$r_i(x)$接近直线，
$\nabla^2 r_i(x) \approx 0$</li>
</ul>
<p>采用Gauss-Newton法效果较好，否则效果一般</p>
</li>
<li><p>矩阵$J(x^{(k)})^T J(x^{(k)})$是半正定矩阵，当Jacobi矩阵
列满秩时为正定矩阵，此时虽然$d^{(k)}$是下降方向，但仍需
类似修正牛顿法增加一维搜索策略保证目标函数值不上升</p>
</li>
</ul>
<h3 id="Levenberg-Marquardt方法"><a href="#Levenberg-Marquardt方法" class="headerlink" title="Levenberg-Marquardt方法"></a>Levenberg-Marquardt方法</h3><p>但$J(x^{(k)})$中各列线性相关、接近线性相关，则求解
Newton-Gauss方法中的方程组会出现困难，可以改为求解</p>
<script type="math/tex; mode=display">
(J(x^{(k)})^T J(x^{(k)}) + vI) d = -J(x^{(k)})^T r(x^{(k)})</script><blockquote>
<ul>
<li>$v$：迭代过程中需要调整的参数，LM方法的关键即如何调整</li>
</ul>
</blockquote>
<h4 id="定理1"><a href="#定理1" class="headerlink" title="定理1"></a>定理1</h4><blockquote>
<ul>
<li>若$d(v)$是以上方程组的解，则$|d(v)|^2$是$v$的连续下降
  函数，且$v \rightarrow +\infty, |d(v)| \rightarrow 0$</li>
</ul>
</blockquote>
<ul>
<li><p>$J(x^{(k)})^T J(x^{(k)})$是对称半正定矩阵，则存在正交阵</p>
<script type="math/tex; mode=display">
(P^{(k)})^T J(x^{(k)})^T J(x^{(k)}) P^{(k)} =
   \Lambda^{(k)}</script></li>
<li><p>则可以解出$|d(v)|^2$</p>
</li>
</ul>
<blockquote>
<ul>
<li>增大$v$可以限制$|d^{(k)}|$，所以LM方法也被称为阻尼最小
  二乘法</li>
</ul>
</blockquote>
<h4 id="定理2"><a href="#定理2" class="headerlink" title="定理2"></a>定理2</h4><blockquote>
<ul>
<li>若$d(v)$是以上方程的解，则$d(v)$是$f(x)$在$x^{(k)}$处的
  下降方向，且$v \rightarrow + \infty$时，$d(v)$的方向与
  $-J(x^{(k)})^T r(x^{(k)})$方向一致</li>
</ul>
</blockquote>
<ul>
<li>下降方向：$\nabla f(x^{(k)}) d(v) &lt; 0$即可</li>
<li>方向一致：夹角余弦</li>
</ul>
<blockquote>
<ul>
<li>$v$充分大时，LM方法产生的搜索方向$d^{(k)}$和负梯度方向
  一致</li>
</ul>
</blockquote>
<h4 id="参数调整方法"><a href="#参数调整方法" class="headerlink" title="参数调整方法"></a>参数调整方法</h4><p>使用梯度、近似Hesse矩阵定义二次函数</p>
<script type="math/tex; mode=display">
q(d) = f(x^{(k)}) + (J(x^{(k)})^T r(x^{(k)}))^T d +
    \frac 1 2 d^T (J(x^{(k)})^T J(x^{(k)})) d</script><blockquote>
<ul>
<li><p>其增量为</p>
<script type="math/tex; mode=display">\begin{align*}
  \Delta q^{(k)} & = q(d^{(k)}) - q(0) \\
  & = (J(x^{(k)})^T r(x^{(k)}))^T d^{(k)} + \frac 1 2
      (d^{(k)})^T (J(x^{(k)})^T J(x^{(k)})) d^{(k)}
  \end{align*}</script></li>
<li><p>目标函数增量</p>
<script type="math/tex; mode=display">\begin{align*}
  \Delta f^{(k)} & = f(x^{(k)} + d^{(k)}) - f(x^{(k)}) \\
  & = f(x^{(k+1)}) - f(x^{(k)})
  \end{align*}</script></li>
<li><p>定义$\gamma_k = \frac {\Delta f^{(k)}} {\Delta q^{(k)}}$</p>
</li>
</ul>
</blockquote>
<ul>
<li><p>$\gamma_k$接近1说明$\Delta f^{(k)}$接近$\Delta q^{(k)}$</p>
<ul>
<li>即$f(x^{(k)} + d^{(k+1)})$接近$q(d^{(k)})$</li>
<li>即$f(x)$在$x^{(k)}$附近接近二次函数</li>
<li>即使用Gauss-Newton方法求解最小二乘问题效果较好</li>
<li>即LM方法求解时$v$参数应该较小</li>
</ul>
</li>
<li><p>$\gamma_k$接近0说明$\Delta f^{(k)}$与$\Delta q^{(k)}$
近似程度不好</p>
<ul>
<li>$d^{(k)}$不应取得过大，应减少$d^{(k)}$得模长</li>
<li>应该增加参数$v$进行限制</li>
<li>迭代方向趋近于负梯度方向</li>
</ul>
</li>
<li><p>$\gamma_k$适中时，认为参数$v$选取合适，不做调整</p>
<ul>
<li>临界值通常为0.25、0.75</li>
</ul>
</li>
</ul>
<h4 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h4><ol>
<li><p>初始点$x^{(1)}$、初始参数$v$（小值）、精度要求$\epsilon$
，置k=k+1</p>
</li>
<li><p>若$|J(x^{(k)})^T r(x^{(k)})| &lt; \epsilon$，则停止计算，
得到问题解$x^{(k)}$，否则求解线性方程组</p>
<script type="math/tex; mode=display">
(J(x^{(k)})^T J(x^{(k)}) + v_kI) d = -J(x^{(k)})^T
  r(x^{(k)})</script><p>得到$d^{(k)}$</p>
</li>
<li><p>置$x^{(k+1)} = x^{(k)} + d^{(k)}$，计算$\gamma_k$</p>
</li>
<li><p>若</p>
<ul>
<li>$\gamma &lt; 0.25$，置$v_{k+1} = 4 v_k$</li>
<li>$\gamma &gt; 0.75$，置$v_{k+1} = v_k / 2$</li>
<li>否则置$v_{k+1} = v_k$</li>
</ul>
</li>
<li><p>置k=k+1，转2</p>
</li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:29:45.000Z" title="8/4/2021, 11:29:45 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Real-Analysis/">Real Analysis</a></span><span class="level-item">a minute read (About 120 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Real-Analysis/cone.html">Cone</a></h1><div class="content"><h2 id="Cone"><a href="#Cone" class="headerlink" title="Cone"></a><em>Cone</em></h2><ul>
<li><p>锥：$C \subset V, \forall x \in C, a&gt;0 \Rightarrow  ax \in C$</p>
<ul>
<li>锥总是无界的</li>
</ul>
<blockquote>
<ul>
<li>$V$：向量空间</li>
</ul>
</blockquote>
</li>
<li><p><em>Convex Cone</em> 凸锥：$\forall x,y \in C, \forall a,b &gt; 0 \Rightarrow ax + by \in C$</p>
<ul>
<li>凸锥必然是凸集</li>
<li>非凸锥：凸锥的补集</li>
</ul>
</li>
<li><p><em>Norm Cone</em> $n$ 维标准锥：$C = { (x,t)| |x|_2 \leq t, x \in R^{n-1}, t \in R }$</p>
</li>
<li><p><em>Second Order Cone</em> 二阶锥：$C = { (x,t)|Ax+b|_2 \leq c^Tx + d }$</p>
<ul>
<li>二阶锥相对于对标准锥做了仿射变换（平移变换）</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Real-Analysis/">Real Analysis</a></span><span class="level-item">a minute read (About 168 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Real-Analysis/convex.html">凸分析</a></h1><div class="content"><h2 id="Notations-and-Terminology"><a href="#Notations-and-Terminology" class="headerlink" title="Notations and Terminology"></a>Notations and Terminology</h2><h3 id="Strong-Convexity"><a href="#Strong-Convexity" class="headerlink" title="Strong Convexity"></a><em>Strong Convexity</em></h3><ul>
<li><p>凸函数 $f$ 满足</p>
<script type="math/tex; mode=display">
\forall x, y \in R, \forall \lambda \in (0,1), 
   f(\lambda x + (1-\lambda) y) \leq \lambda f(x) +
   (1-\lambda)f(y)</script></li>
<li><p>强凸函数：不等式严格不等的凸函数</p>
<ul>
<li>为保证强凸性，常添加二次项保证，如：增广拉格朗日</li>
</ul>
</li>
</ul>
<h3 id="凸集相关标记"><a href="#凸集相关标记" class="headerlink" title="凸集相关标记"></a>凸集相关标记</h3><blockquote>
<ul>
<li>$C \subseteq R^N$：非空凸集</li>
<li>$x \in R^N$</li>
</ul>
</blockquote>
<ul>
<li><p>点 $x \in R^N$ 到 $C$ 的距离为</p>
<script type="math/tex; mode=display">D_C(x) = \min_{y \in C} \|x-y\|_2</script></li>
<li><p>点 $x \in R^N$ 在 $C$ 上投影为</p>
<script type="math/tex; mode=display">P_Cx \in C, D_C(x) = \|x - P_Cx\|_2</script><ul>
<li>$C \subseteq R^N$：闭凸集</li>
</ul>
</li>
<li><p><em>Indicator Function</em> 凸集 $C$ 的示性函数为</p>
<script type="math/tex; mode=display">
l_C(x) = \left \{ \begin{array}
   0 & if x \in C \\
   +\infty & if x \notin C
\end{array} \right.</script></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Real-Analysis/">Real Analysis</a></span><span class="level-item">a minute read (About 146 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Real-Analysis/functions.html">函数</a></h1><div class="content"><h3 id="齐次函数"><a href="#齐次函数" class="headerlink" title="齐次函数"></a>齐次函数</h3><p>齐次函数：有倍数性质的函数，若变量乘以系数 $\alpha$，则新函数为原函数乘上 $\alpha^k$ 倍</p>
<script type="math/tex; mode=display">
f(\alpha x) = \alpha^k f(x)</script><blockquote>
<ul>
<li>$\alpha \neq 0 \in F, x \in X$</li>
<li>$f: X \rightarrow W$：域 $F$ 内两个向量空间之间的 $k$ 次齐次函数</li>
</ul>
</blockquote>
<ul>
<li>线性函数 $f: X \rightarrow W$ 是一次齐次函数</li>
<li>多线性函数 $f: x_1 <em> x_2 </em> \cdots * x_n \rightarrow W$ 是 $n$ 次齐次函数</li>
</ul>
<h4 id="基本定理"><a href="#基本定理" class="headerlink" title="基本定理"></a>基本定理</h4><blockquote>
<ul>
<li>欧拉定理：函数 $f: R^n \rightarrow R$ 可导、$k$ 次齐次函数，则有 $x \nabla f(x) = kf(x)$</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:31:21.000Z" title="8/4/2021, 11:31:21 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Analysis/">Math Analysis</a><span> / </span><a class="link-muted" href="/categories/Math-Analysis/Real-Analysis/">Real Analysis</a></span><span class="level-item">7 minutes read (About 1092 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Analysis/Real-Analysis/subgredient.html">次梯度</a></h1><div class="content"><h2 id="次梯度"><a href="#次梯度" class="headerlink" title="次梯度"></a>次梯度</h2><ul>
<li><p>次梯度：实变量凸函数 $f$ 在点 $x_0$ 的次梯度 $c$ 满足</p>
<script type="math/tex; mode=display">
\forall x, f(x) - f(x_0) \geq c(x - x_0)</script></li>
<li><p>可证明凸函数 $f$ 在 $x_0$ 处所有次梯度的集合 $\partial f(x)$ 是非空凸紧集</p>
<ul>
<li><p>$\partial f(x) = [a, b]$，其中$a, b$为单侧极限</p>
<script type="math/tex; mode=display">\begin{align*}
a & = lim_{x \rightarrow x_0^{-}} \frac {f(x) - f_0(x)} {x - x_0} \\
b & = lim_{x \rightarrow x_0^{+}} \frac {f(x) - f_0(x)} {x - x_0}
\end{align*}</script></li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>凸函数均指下凸函数，梯度不减</li>
</ul>
</blockquote>
<h3 id="次梯度性质"><a href="#次梯度性质" class="headerlink" title="次梯度性质"></a>次梯度性质</h3><h4 id="运算性质"><a href="#运算性质" class="headerlink" title="运算性质"></a>运算性质</h4><ul>
<li><p>数乘性质</p>
<script type="math/tex; mode=display">
\partial(\alpha f)(x) = \alpha \partial f(x), \alpha > 0</script></li>
<li><p>加法性质</p>
<script type="math/tex; mode=display">\begin{align*}
f &= f_1 + f_2 + \cdots + f_m, \\
\partial f &= \partial f_1 + \cdots + \partial f_m
\end{align*}</script></li>
<li><p>仿射性质：$f$为凸函数</p>
<script type="math/tex; mode=display">\begin{align*}
h(x) &=  f(Ax + b) \\
\partial h(x) &= A^T \partial f(Ax + b)
\end{align*}</script></li>
</ul>
<h4 id="最优化性质"><a href="#最优化性质" class="headerlink" title="最优化性质"></a>最优化性质</h4><ul>
<li><p>凸函数 $f$ 在点 $x_0$ 可导，当且仅当次梯度仅包含一个点，即该点导数</p>
</li>
<li><p>点 $x_0$ 是凸函数 $f$ 最小值，当且仅当次微分中包含 0
（此性质为“可导函数极小点导数为 0 ”推广）</p>
</li>
<li><p>负次梯度方向不一定是下降方向</p>
</li>
</ul>
<h2 id="次梯度求解"><a href="#次梯度求解" class="headerlink" title="次梯度求解"></a>次梯度求解</h2><ul>
<li>逐点（分段）极值的函数求次梯度</li>
<li>求出该点相应极值函数</li>
<li>求出对应梯度即为次梯度</li>
</ul>
<h3 id="Pointwise-Maximum"><a href="#Pointwise-Maximum" class="headerlink" title="Pointwise Maximum"></a><em>Pointwise Maximum</em></h3><p>逐点最大函数：目标函数为</p>
<script type="math/tex; mode=display">\begin{align*}
f(x) & = max \{f_1(x), f_2(x), \cdots, f_m(x)\} \\
I(x) & = \{i | f_i(x) = f(x)\}
\end{align*}</script><blockquote>
<ul>
<li>$I(x)$：保存 $x$ 处取值最大的函数下标</li>
</ul>
</blockquote>
<ul>
<li><p>弱结果：$I(x)$ 中随机抽取，以 $f_i(x)$ 在该处梯度作为次梯度</p>
</li>
<li><p>强结果</p>
<script type="math/tex; mode=display">
\partial f(x) = conv \cup_{i \in I(x)} \partial f_i(x)</script><ul>
<li>先求支撑平面，再求所有支撑平面的凸包</li>
<li>可导情况实际上是不可导的特殊情况</li>
</ul>
</li>
</ul>
<h4 id="分段函数"><a href="#分段函数" class="headerlink" title="分段函数"></a>分段函数</h4><p><img src="/imgs/subgredient_piecewise_function.png" alt="subgredient_piecewise_function"></p>
<ul>
<li><p>折点处</p>
<script type="math/tex; mode=display">
\partial f(x) = conv\{a_i, a_{i+1}\} = [a_i, a_{i+1}]</script></li>
<li><p>非折点处</p>
<script type="math/tex; mode=display">\partial f(x) = {a_i}</script></li>
</ul>
<h4 id="L-1-范数"><a href="#L-1-范数" class="headerlink" title="$L_1$范数"></a>$L_1$范数</h4><p><img src="/imgs/subgredient_l1norm.png" alt="subgredient_l1norm"></p>
<h3 id="PointWise-Supremum"><a href="#PointWise-Supremum" class="headerlink" title="PointWise Supremum"></a><em>PointWise Supremum</em></h3><p>逐点上确界：目标函数为</p>
<script type="math/tex; mode=display">\begin{align*}
f(x) &= \sup_{\alpha \in A} f_{\alpha}(x) \\
I(x) &= \{\alpha \in A | f_{\alpha}(x) = f(x)\}
\end{align*}</script><ul>
<li><p>弱结果：可行梯度为</p>
<script type="math/tex; mode=display">
\partial (\max_{\alpha} f_{\alpha}(x)) \in partial f(x)</script></li>
<li><p>强结果</p>
<script type="math/tex; mode=display">
\partial f(x) = conv \cup_{\alpha \in I(x)} \partial f_{alpha}(x) \subseteq \partial f(x)</script></li>
</ul>
<h4 id="最大特征值"><a href="#最大特征值" class="headerlink" title="最大特征值"></a>最大特征值</h4><script type="math/tex; mode=display">\begin{align*}
f(x) & = \lambda_{max}(A(x)) = \sup_{\|y\|_2 = 1} \\
A(x) & = A_0 + x_1 A_1 + \cdots + x_n A_n
\end{align*}</script><blockquote>
<ul>
<li>$A_n$：对称矩阵</li>
</ul>
</blockquote>
<ul>
<li><p>对确定 $\hat {x}$，$A(x)$ 最大特征值 $\lambda_{max}$、对应特征向量 $y$，则该点此梯度为</p>
<script type="math/tex; mode=display">(y^T A_0 y, \cdots, y^T A_n y)</script></li>
</ul>
<h3 id="Pointwise-Inferior"><a href="#Pointwise-Inferior" class="headerlink" title="Pointwise Inferior"></a><em>Pointwise Inferior</em></h3><p>逐点下确界：目标函数为</p>
<script type="math/tex; mode=display">
f(x) = \inf_y h(x, y)</script><blockquote>
<ul>
<li>$h$：凸函数</li>
</ul>
</blockquote>
<ul>
<li><p>弱结果：给定$x = \hat x$，可行次梯度为</p>
<script type="math/tex; mode=display">
(\partial h(x, \hat y)|_{x=\hat x}, 0) \in \partial f(x)</script></li>
</ul>
<h3 id="复合函数"><a href="#复合函数" class="headerlink" title="复合函数"></a>复合函数</h3><script type="math/tex; mode=display">
f(x) = h(f_1(x), \cdots, f_n(x))</script><blockquote>
<ul>
<li>$h$：凸、不降函数</li>
<li>$f_i$：凸函数</li>
</ul>
</blockquote>
<ul>
<li><p>弱结果：给定$x = \hat x$，可行次梯度为</p>
<script type="math/tex; mode=display">
g = z_1 g_1 + \cdots + z_k g_k \in \partial f(\hat x)</script><blockquote>
<ul>
<li>$z \in \partial h(f_1(\hat x), \cdots, f_k(\hat x))$</li>
<li>$g_i \in \partial f_i(\hat x)$</li>
</ul>
</blockquote>
<ul>
<li><p>证明</p>
<script type="math/tex; mode=display">\begin{align*}
f(x) & \geq h(f_1(\hat x) + g_1^T(x - \hat x), \cdots,
  f_k(\hat x) + g_k^T(x - \hat x) \\
& \geq h(f_1(\hat x), \cdots, f_k(\hat x)) +
  z^T(g_1^T(x - \hat x), \cdots, g_k^T(x - \hat x)) \\
& = f(\hat x) + g^T(x - \hat x)
\end{align*}</script></li>
</ul>
</li>
</ul>
<h2 id="次梯度法"><a href="#次梯度法" class="headerlink" title="次梯度法"></a>次梯度法</h2><script type="math/tex; mode=display">\begin{align*}
x^{(k+1)} & = x^{(k)} + \alpha_k g^{(k)} \\
f_{best}^{(k+1)} & = min{f_{best}^{(k)}, f(x^{(k+1)})}
\end{align*}</script><blockquote>
<ul>
<li>$g^{(k)}$：函数$f$在$x^{(k)}$处次梯度</li>
</ul>
</blockquote>
<ul>
<li><p>求解凸函数最优化的问题的一种迭代方法</p>
</li>
<li><p>相较于较内点法、牛顿法慢</p>
<ul>
<li>应用范围更广泛：能够用于不可微目标函数，目标函数可微时，无约束问题次梯度与梯度下降法有同样搜索方向</li>
<li>空间复杂度更小</li>
<li>可以和分解技术结合，得到简单分配算法</li>
<li>通常不会产生稀疏解</li>
</ul>
</li>
</ul>
<h3 id="步长选择"><a href="#步长选择" class="headerlink" title="步长选择"></a>步长选择</h3><blockquote>
<ul>
<li>次梯度法选取步长方法很多，以下为保证收敛步长规则</li>
</ul>
</blockquote>
<ul>
<li>恒定步长：$\alpha_k = \alpha$</li>
<li>恒定间隔：$\alpha_k = \gamma / |g^{(k)}|_2$</li>
<li>步长平方可加、步长不可加：$\sum<em>{k=1}^{\infty} \alpha_k^2 &lt; \infty, \sum</em>{k=1}^{\infty} \alpha_k = \infty$</li>
<li>步长不可加、但递减：$lim_{k \rightarrow \infty} \alpha_k = 0$</li>
<li>间隔不可加、但递减：$lim_{k \rightarrow \gamma_k} \gamma_k = 0$</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-07-20T16:46:35.000Z" title="7/21/2019, 12:46:35 AM">2019-07-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a></span><span class="level-item">27 minutes read (About 4010 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/func_hash.html">Hashing</a></h1><div class="content"><h2 id="Hash-Function"><a href="#Hash-Function" class="headerlink" title="Hash Function"></a><em>Hash Function</em></h2><blockquote>
<ul>
<li><em>hash</em>：散列/哈希，将任意类型值转换为关键码值</li>
<li><em>hash function</em>：哈希/散列函数，从任何数据中创建小的数字“指纹”的方法</li>
<li><em>hash value</em>：哈希值，哈希函数产生关键码值</li>
<li><em>collision</em>：冲突，不同两个数据得到相同哈希值</li>
</ul>
</blockquote>
<ul>
<li>哈希函数应该尽可能使得哈希值均匀分布在目标空间中<ul>
<li>降维：将高维数据映射到低维空间</li>
<li>数据应该低维空间中尽量均匀分布</li>
</ul>
</li>
</ul>
<h3 id="数据相关性"><a href="#数据相关性" class="headerlink" title="数据相关性"></a>数据相关性</h3><ul>
<li><p><em>Data Independent Hashing</em>：数据无关哈希，无监督，哈希函数基于某种概率理论</p>
<ul>
<li>对原始的特征空间作均匀划分</li>
<li>对分布不均、有趋向性的数据集时，可能会导致高密度区域哈希桶臃肿，降低索引效率</li>
</ul>
</li>
<li><p><em>Data Dependent Hashing</em>：数据依赖哈希，有监督，通过学习数据集的分布从而给出较好划分的哈希函数</p>
<ul>
<li>得到针对数据密度动态划分的哈希索引</li>
<li>破坏了传统哈希函数的数据无关性，索引不具备普适性</li>
</ul>
</li>
</ul>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ul>
<li>查找数据结构：<em>cs_algorithm/data_structure/hash_table</em><ul>
<li>哈希表</li>
</ul>
</li>
<li>信息安全方向：<em>cs_algorithm/specification/info_security</em><ul>
<li>文件检验</li>
<li>数字签名</li>
<li>鉴权协议</li>
</ul>
</li>
</ul>
<h2 id="哈希函数"><a href="#哈希函数" class="headerlink" title="哈希函数"></a>哈希函数</h2><ul>
<li><p>简单哈希函数主要用于提升查找效率（构建哈希表）</p>
<ul>
<li>要求哈希函数的降维、缩小查找空间性质</li>
<li>计算简单、效率高</li>
</ul>
</li>
<li><p>复杂哈希函数主要用于信息提取</p>
<ul>
<li>要求哈希函数的信息提取不可逆、非单调映射</li>
<li>查表哈希<ul>
<li><em>CRC</em> 系列算法：本身不是查表，但查表是其最快实现</li>
<li><em>Zobrist Hashing</em></li>
</ul>
</li>
<li>混合哈希：利用以上各种方式<ul>
<li><em>MD5</em></li>
<li><em>Tiger</em></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="单值输入"><a href="#单值输入" class="headerlink" title="单值输入"></a>单值输入</h3><ul>
<li><p>直接寻址法：取关键字、或其某个线性函数值 $hash(key) = (a * key + b) \% prime$</p>
<ul>
<li>$prime$：一般为质数，以使哈希值尽量均匀分布，常用的如：$2^{32}-5$</li>
</ul>
</li>
<li><p>数字分析法：寻找、利用数据规律构造冲突几率较小者</p>
<ul>
<li>如：生日信息前 2、3 位大体相同，冲突概率较大，优先舍去</li>
</ul>
</li>
<li><p>平方取中法：取关键字平方后中间几位</p>
</li>
<li><p>折叠法：将关键字分割为位数相同部分，取其叠加和</p>
</li>
<li><p>随机数法：以关键字作为随机数种子生成随机值</p>
<ul>
<li>适合关键字长度不同场合</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>常用于之前哈希结果再次映射为更小范围的最终哈希值</li>
</ul>
</blockquote>
<h3 id="序列输入"><a href="#序列输入" class="headerlink" title="序列输入"></a>序列输入</h3><h4 id="加法哈希"><a href="#加法哈希" class="headerlink" title="加法哈希"></a>加法哈希</h4><p>加法哈希：将输入元素相加得到哈希值</p>
<ul>
<li><p>标准加法哈希</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">AddingHash(<span class="built_in">input</span>):</span><br><span class="line">	<span class="built_in">hash</span> = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> ele <span class="keyword">in</span> <span class="built_in">input</span>:</span><br><span class="line">		<span class="built_in">hash</span> += ele</span><br><span class="line">	<span class="comment"># prime 为任意质数，常用 2^32 - 5</span></span><br><span class="line">	<span class="built_in">hash</span> = <span class="built_in">hash</span>  % prime</span><br></pre></td></tr></table></figure>
<ul>
<li>最终哈希结果 $\in [0, prime-1]$</li>
</ul>
</li>
</ul>
<h4 id="位运算哈希"><a href="#位运算哈希" class="headerlink" title="位运算哈希"></a>位运算哈希</h4><p>位运算哈希：利用位运算（移位、异或等）充分混合输入元素</p>
<ul>
<li><p>标准旋转哈希</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">RotationHash(<span class="built_in">input</span>):</span><br><span class="line">	<span class="built_in">hash</span> = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> ele <span class="keyword">in</span> <span class="built_in">input</span>:</span><br><span class="line">		<span class="built_in">hash</span> = (<span class="built_in">hash</span> &lt;&lt; <span class="number">4</span>) ^ (<span class="built_in">hash</span> &gt;&gt; <span class="number">28</span>) ^ ele</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">hash</span> % prime</span><br></pre></td></tr></table></figure>
</li>
<li><p>变形 1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span> = (<span class="built_in">hash</span>&lt;&lt; <span class="number">5</span>) ^ (<span class="built_in">hash</span> &gt;&gt; <span class="number">27</span>) ^ ele</span><br></pre></td></tr></table></figure>
</li>
<li><p>变形2</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span> += ele</span><br><span class="line"><span class="built_in">hash</span> ^= (<span class="built_in">hash</span> &lt;&lt; <span class="number">10</span>)</span><br><span class="line"><span class="built_in">hash</span> ^= (<span class="built_in">hash</span> &gt;&gt; <span class="number">6</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>变形3</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ele &amp; <span class="number">1</span>) == <span class="number">0</span>:</span><br><span class="line">	<span class="built_in">hash</span> ^= (<span class="built_in">hash</span> &lt;&lt; <span class="number">7</span>) ^ ele ^ (<span class="built_in">hash</span> &gt;&gt; <span class="number">3</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	<span class="built_in">hash</span> ^= ~((<span class="built_in">hash</span> &lt;&lt; <span class="number">11</span>) ^ ele ^ (<span class="built_in">hash</span> &gt;&gt; <span class="number">5</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>变形4</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span> += (<span class="built_in">hash</span> &lt;&lt; <span class="number">5</span>) + ele</span><br></pre></td></tr></table></figure>
</li>
<li><p>变形5</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span> = ele + (<span class="built_in">hash</span> &lt;&lt; <span class="number">6</span>) + (<span class="built_in">hash</span> &gt;&gt; <span class="number">16</span>) - <span class="built_in">hash</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>变形6</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span> ^= (<span class="built_in">hash</span> &lt;&lt; <span class="number">5</span>) + ele + (<span class="built_in">hash</span> &gt;&gt; <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="乘法哈希"><a href="#乘法哈希" class="headerlink" title="乘法哈希"></a>乘法哈希</h4><p>乘法哈希：利用乘法的不相关性</p>
<ul>
<li><p>平方取头尾随机数生成法：效果不好</p>
</li>
<li><p><em>Bernstein</em> 算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Bernstein(<span class="built_in">input</span>):</span><br><span class="line">	<span class="built_in">hash</span> = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> ele <span class="keyword">in</span> <span class="built_in">input</span>:</span><br><span class="line">		<span class="built_in">hash</span> = <span class="number">33</span> * <span class="built_in">hash</span> + ele</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">hash</span></span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>其他常用乘数：31、131、1313、13131、131313</li>
</ul>
</blockquote>
</li>
<li><p>32位 <em>FNV</em> 算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">M_SHIFT =</span><br><span class="line">M_MASK =</span><br><span class="line">FNVHash(<span class="built_in">input</span>):</span><br><span class="line">	<span class="built_in">hash</span> = <span class="number">2166136261</span>;</span><br><span class="line">	<span class="keyword">for</span> ele <span class="keyword">in</span> <span class="built_in">input</span>:</span><br><span class="line">		<span class="built_in">hash</span> = (<span class="built_in">hash</span> * <span class="number">16777619</span>) ^ ele</span><br><span class="line">	<span class="keyword">return</span> (<span class="built_in">hash</span> ^ (<span class="built_in">hash</span> &gt;&gt; M_SHIFT)) &amp; M_MASK</span><br></pre></td></tr></table></figure>
</li>
<li><p>改进的 <em>FNV</em> 算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FNVHash_2(<span class="built_in">input</span>):</span><br><span class="line">	<span class="built_in">hash</span> = <span class="number">2166136261</span>;</span><br><span class="line">	<span class="keyword">for</span> ele <span class="keyword">in</span> <span class="built_in">input</span>:</span><br><span class="line">		<span class="built_in">hash</span> = (<span class="built_in">hash</span> ^ ele) * <span class="number">16777619</span></span><br><span class="line">	<span class="built_in">hash</span> += <span class="built_in">hash</span> &lt;&lt; <span class="number">13</span></span><br><span class="line">	<span class="built_in">hash</span> ^= <span class="built_in">hash</span> &gt;&gt; <span class="number">7</span></span><br><span class="line">	<span class="built_in">hash</span> += <span class="built_in">hash</span> &lt;&lt; <span class="number">3</span></span><br><span class="line">	<span class="built_in">hash</span> ^= <span class="built_in">hash</span> &gt;&gt; <span class="number">17</span></span><br><span class="line">	<span class="built_in">hash</span> += <span class="built_in">hash</span> &lt;&lt; <span class="number">5</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">hash</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>乘数不固定</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">RSHash(<span class="built_in">input</span>):</span><br><span class="line">	<span class="built_in">hash</span> = <span class="number">0</span></span><br><span class="line">	a, b = <span class="number">378551</span>, <span class="number">63689</span></span><br><span class="line">	<span class="keyword">for</span> ele <span class="keyword">in</span> <span class="built_in">input</span>:</span><br><span class="line">		<span class="built_in">hash</span> = <span class="built_in">hash</span> * a + ele</span><br><span class="line">		a *= b</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">hash</span> &amp; <span class="number">0x7FFFFFFF</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<ul>
<li>除法也类似乘法具有不相关性，但太慢</li>
</ul>
</blockquote>
<h3 id="定长序列"><a href="#定长序列" class="headerlink" title="定长序列"></a>定长序列</h3><ul>
<li><p>两步随机数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">main_rand_seq = randint(k)</span><br><span class="line">TwoHashing(<span class="built_in">input</span>[<span class="number">0</span>,...,k]):</span><br><span class="line">	<span class="built_in">hash</span> = <span class="number">0</span></span><br><span class="line">	<span class="keyword">from</span> i=<span class="number">0</span> to k:</span><br><span class="line">		<span class="built_in">hash</span> += <span class="built_in">input</span>[i] * main_rand_seq[i]</span><br><span class="line">	<span class="built_in">hash</span> = <span class="built_in">hash</span> mod prime</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Universal-Hashing"><a href="#Universal-Hashing" class="headerlink" title="Universal Hashing"></a><em>Universal Hashing</em></h2><blockquote>
<ul>
<li>全域哈希：键集合 $U$ 包含 $n$ 个键、哈希函数族 $H$ 中哈希函数 $h_i: U \rightarrow 0..m$，若 $H$ 满足以下则为全域哈希 $$<pre><code>  \forall x \neq y \in U, | \&#123;h|h \in H, h(x) = h(y) \&#125; | = \frac &#123;|H|&#125; m
</code></pre>  $$<blockquote>
<ul>
<li>$|H|$：哈希函数集合 $H$ 中函数数量</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<ul>
<li>独立与键值随机从中选择哈希函数，避免发生最差情况</li>
<li>可利用全域哈希构建完美哈希</li>
</ul>
<h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><ul>
<li><p>全域哈希 $H$ 中任选哈希函数 $h_i$，对任意键 $x \neq y \in U$ 冲突概率小于 $\frac 1 m$</p>
<ul>
<li>由全域哈希函数定义，显然</li>
</ul>
</li>
<li><p>全域哈希 $H$ 中任选哈希函数 $h<em>i$，对任意键 $x \in U$，与其冲突键数目期望为 $\frac n m$，即 $E</em>{[collision_x]}=\frac n m$</p>
<script type="math/tex; mode=display">\begin{align*}
E(C_x) &= E[\sum_{y \in U - \{x\}} C_{xy}] \\
   &= \sum_{y \in U - \{x\}} E[C_{xy}] \\
   &= \sum_{y \in U - \{x\}} \frac 1 m \\
   &= \frac {n-1} m
\end{align*}</script><blockquote>
<ul>
<li>$C_x$：任选哈希函数，与 $x$ 冲突的键数量</li>
<li>$C_{xy} = \left { \begin{matrix} 1, &amp; h_i(x) = h_i(y) \ 0, &amp; otherwise \end{matrix} \right.$：指示 $x,y$ 是否冲突的指示变量</li>
</ul>
</blockquote>
<ul>
<li>$m = n^2$ 时，冲突期望小于 0.5<ul>
<li>$n$ 个键两两组合数目为 $C_n^2$</li>
<li>则 $E_{total} &lt; C_n^2 \frac 1 n &lt; 0.5$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="例"><a href="#例" class="headerlink" title="例"></a>例</h3><blockquote>
<ul>
<li>以下构造 $[0,p-1] \rightarrow [0,m-1]$ 全域哈希</li>
</ul>
</blockquote>
<ul>
<li><p>$p$ 为足够大素数使得所有键值 $\in [0,p-1]$</p>
<ul>
<li>记 $Z_p = { 0,1,\cdots,p-1 }$</li>
<li>记 $Z_p^{*}={ 1,2,\cdots,p-1 }$</li>
<li>且哈希函数映射上限（哈希表长度） $m &lt; max(U) &lt; p$</li>
</ul>
</li>
<li><p>记哈希函数</p>
<script type="math/tex; mode=display">
\forall a \in Z_p^{*}, b \in Z_p, h_{a, b}(k) = ((a k + b) \% p) \% m</script></li>
<li><p>则以下哈希函数族即为全域哈希</p>
<script type="math/tex; mode=display">
H_{p,m} = {h_{a,b}|a \in Z_p^{*}, b \in Z_p}</script></li>
</ul>
<h2 id="Locality-Sensitive-Hashing"><a href="#Locality-Sensitive-Hashing" class="headerlink" title="Locality Sensitive Hashing"></a><em>Locality Sensitive Hashing</em></h2><p><em>LSH</em>：局部敏感哈希</p>
<blockquote>
<ul>
<li>$(r_1,r_2,P_1,P_2)-sensitive$ 哈希函数族 $H$ 需满足如下条件 $$
  \begin{align*}<pre><code>  Pr_&#123;H&#125;[h(v) = h(q)] \geq P_1, &amp; \forall q \in B(v, r_1) \\
  Pr_&#123;H&#125;[h(v) = h(q)] \geq P_2, &amp; \forall q \notin B(v, r_2) \\
</code></pre>  \end{align*}$$<blockquote>
<ul>
<li>$h \in H$</li>
<li>$r_1 &lt; r_2, P_1 &gt; P_2$：函数族有效的条件</li>
<li>$B(v, r)$：点 $v$ 的 $r$ 邻域</li>
<li>$r_1, r_2$：距离，强调比例时会表示为 $r_1 = R, r_2 = cR$</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<ul>
<li>此时 <strong>相似目标（距离小）有更大概率发生冲突</strong></li>
</ul>
<h3 id="LSH查找"><a href="#LSH查找" class="headerlink" title="LSH查找"></a>LSH查找</h3><h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><p><img src="/imgs/general_lsh_comparsion.png" alt="general_lsh_comparsion"></p>
<ul>
<li><p>相似目标更有可能映射到相同哈希桶中</p>
<ul>
<li>则只需要在目标所属的哈希桶中进行比较、查找即可</li>
<li>无需和全集数据比较，大大缩小查找空间</li>
</ul>
</li>
<li><p>可视为降维查找方法</p>
<ul>
<li>将高维空间数据映射到 1 维空间，寻找可能近邻的数据点</li>
<li>缩小范围后再进行精确比较</li>
</ul>
</li>
</ul>
<h4 id="概率放大"><a href="#概率放大" class="headerlink" title="概率放大"></a>概率放大</h4><blockquote>
<ul>
<li>期望放大局部敏感哈希函数族 $Pr_1, Pr_2$ 之间差距</li>
</ul>
</blockquote>
<ul>
<li><p>增加哈希值长度（级联哈希函数中基本哈希函数数量） $k$</p>
<ul>
<li>每个哈希函数独立选择，则对每个级联哈希函数 $g_i$ 有 $Pr[g_i(v) = g_i(q)] \geq P_1^k$</li>
<li>虽然增加哈希键位长会减小目标和近邻碰撞的概率，但同时也更大程度上减少了和非近邻碰撞的概率、减少搜索空间</li>
</ul>
<blockquote>
<ul>
<li>级联哈希函数返回向量，需要对其再做哈希映射为标量，方便查找</li>
</ul>
</blockquote>
</li>
<li><p>增加级联哈希函数数量（哈希表数量） $L$</p>
<ul>
<li>$L$个哈希表中候选项包含真实近邻概率 <strong>至少</strong> 为 $1 - (1 - P_1^k)^L$</li>
<li>增加哈希表数量能有效增加候选集包含近邻可能性</li>
<li>但同时也会增大搜索空间</li>
</ul>
</li>
</ul>
<h4 id="搜索近似最近邻"><a href="#搜索近似最近邻" class="headerlink" title="搜索近似最近邻"></a>搜索近似最近邻</h4><ul>
<li>使用 $L$ 个级联哈希函数分别处理待搜索目标</li>
<li>在 $L$ 个哈希表分别寻找落入相同哈希桶个体作为候选项</li>
<li>在所有候选项中线性搜索近邻</li>
</ul>
<h3 id="基于汉明距离的-LSH"><a href="#基于汉明距离的-LSH" class="headerlink" title="基于汉明距离的 LSH"></a>基于汉明距离的 <em>LSH</em></h3><ul>
<li>在汉明距离空间中搜索近邻<ul>
<li>要求数据为二进制表示</li>
<li>其他距离需要嵌入汉明距离空间才能使用<ul>
<li>欧几里得距离没有直接嵌入汉明空间的方法<ul>
<li>一般假设欧几里得距离和曼哈顿距离差别不大</li>
<li>直接使用对曼哈顿距离保距嵌入方式</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="设计哈希函数族"><a href="#设计哈希函数族" class="headerlink" title="设计哈希函数族"></a>设计哈希函数族</h4><ul>
<li><p>考虑哈希函数族 $H = { h_1, h_2, \cdots, h_m }$</p>
<ul>
<li>其中函数 $h_i$ 为 ${0, 1}^d$ 到 ${0, 1}$ 的映射：随机返回特定比特位上的值</li>
</ul>
</li>
<li><p>从 $H$ 中随机的选择哈希函数 $h_i$</p>
<ul>
<li>则 $Pr[h_i(v) = h_i(q)]$ 等于 $v, q$ 相同比特数比例，则<ul>
<li>$Pr_1 = 1 - \frac R d$</li>
<li>$Pr_2 = 1 - \frac {cR} d$</li>
</ul>
</li>
<li>考虑到 $Pr_1 &gt; Pr_2$，即此哈希函数族是局部敏感的</li>
</ul>
</li>
</ul>
<h3 id="基于-Jaccard-系数的-LSH"><a href="#基于-Jaccard-系数的-LSH" class="headerlink" title="基于 Jaccard 系数的 LSH"></a>基于 <em>Jaccard</em> 系数的 <em>LSH</em></h3><ul>
<li><p>考虑 $M * N$ 矩阵 $A$，元素为 0、1</p>
<ul>
<li>其中<ul>
<li>$M$：集合元素数量</li>
<li>$N$：需要比较的集合数量</li>
</ul>
</li>
<li>目标：寻找相似集合，即矩阵中相似列</li>
</ul>
</li>
<li><p>用 <em>Jaccard</em> 系数代表集合间相似距离，用于搜索近邻</p>
<ul>
<li>要求各数据向量元素仅包含 0、1：表示集合是否包含该元素</li>
</ul>
</li>
</ul>
<h4 id="定义-Min-hashing-函数族"><a href="#定义-Min-hashing-函数族" class="headerlink" title="定义 Min-hashing 函数族"></a>定义 <em>Min-hashing</em> 函数族</h4><ul>
<li><p>对矩阵 $A$ 进行 <strong>行随机重排</strong> $\pi$，定义 <em>Min-hashing</em> 如下</p>
<script type="math/tex; mode=display">h_{\pi}(C) = \min \pi(C)</script><blockquote>
<ul>
<li>$C$：列，表示带比较集合</li>
<li>$\min \pi(C)$：$\pi$ 重排矩阵中 $C$ 列中首个 1 所在行数</li>
</ul>
</blockquote>
</li>
<li><p>则不同列（集合） <em>Min-hashing</em> 相等概率等于二者 <em>Jaccard</em> 系数</p>
<script type="math/tex; mode=display">\begin{align*}
Pr(h_{\pi}(C_1)  = h_{\pi}(C_2)) & = \frac a {a + b} \\
& = Jaccard_d(C_1, C_2)
\end{align*}</script><blockquote>
<ul>
<li>$a$：列 $C_1, C_2$ 取值均为 1 的行数</li>
<li>$b$：列 $C_1, C_2$ 中仅有一者取值为 1 的行数</li>
<li>根据 <em>Min-hashing</em> 定义，不同列均取 0 行被忽略</li>
</ul>
</blockquote>
</li>
</ul>
<h4 id="Min-hashing-实现"><a href="#Min-hashing-实现" class="headerlink" title="Min-hashing 实现"></a><em>Min-hashing</em> 实现</h4><ul>
<li><p>数据量过大时，对行随机重排仍然非常耗时，考虑使用哈希函数模拟行随机重排</p>
<ul>
<li>每个哈希函数对应一次随机重排<ul>
<li>哈希函数视为线性变换</li>
<li>然后用哈希函数结果对总行数取模</li>
</ul>
</li>
<li>原行号经过哈希函数映射即为新行号</li>
</ul>
</li>
<li><p>为减少遍历数据次数，考虑使用迭代方法求解</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i from <span class="number">0</span> to N<span class="number">-1</span>:</span><br><span class="line">	<span class="keyword">for</span> j from <span class="number">0</span> to M<span class="number">-1</span>:</span><br><span class="line">		<span class="keyword">if</span> D[i][j] == <span class="number">1</span>:</span><br><span class="line">			<span class="keyword">for</span> k from <span class="number">1</span> to K:</span><br><span class="line">				# 更新随机重拍后，第 `j` 列首个 <span class="number">1</span> 位置</span><br><span class="line">				DD[k][j] = min(h_k(i), DD[k][j])</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>$D$：原始数据特征矩阵</li>
<li>$DD$：$Min-hashing* 签名矩阵</li>
<li>$N$：特征数量，原始特征矩阵行数</li>
<li>$M$：集合数量，原始特征矩阵列数</li>
<li>$K$：模拟的随机重排次数，<em>Min-hashing</em> 签名矩阵行数</li>
<li>$h_k,k=1,…,K$：$K$ 个模拟随机重排的哈希函数，如 $h(x) = (2x + 7) mod N$</li>
</ul>
</blockquote>
<ul>
<li>初始化 <em>Min-hashing</em> 签名矩阵所有值为 $\infty$</li>
<li>遍历 $N$ 个特征、$M$ 个集合<ul>
<li>查看每个对应元素是否为 1</li>
<li>若元素为 1，则分别使用 $K$ 个哈希函数计算模拟重排后对应的行数</li>
<li>若计算出行数小于当前 *Min-hash$ 签名矩阵相应哈希函数、集合对应行数，更新</li>
</ul>
</li>
<li>遍历一遍原始数据之后即得到所有模拟重排的签名矩阵</li>
</ul>
</li>
</ul>
<h3 id="Exact-Euclidean-LSH"><a href="#Exact-Euclidean-LSH" class="headerlink" title="Exact Euclidean LSH"></a><em>Exact Euclidean LSH</em></h3><ul>
<li><p>$E^2LSH$：欧式局部LSH，<em>LSH Based-on P-stable Distribution</em></p>
<ul>
<li>使用内积将向量随机映射到哈希值</li>
<li><em>p-stable</em> 分布性质将欧式距离同哈希值相联系，实现局部敏感</li>
</ul>
</li>
<li><p>$E^2LSH$ 特点</p>
<ul>
<li>基于概率模型生成索引编码结果不稳定</li>
<li>随编码位数 $k$ 增加的，准确率提升缓慢</li>
<li>级联哈希函数数量 $L$ 较多时，需要大量存储空间，不适合大规模数据索引</li>
</ul>
</li>
</ul>
<h4 id="p-stable-哈希函数族"><a href="#p-stable-哈希函数族" class="headerlink" title="p-stable 哈希函数族"></a><em>p-stable</em> 哈希函数族</h4><script type="math/tex; mode=display">
h_{a, b}(v) = \lfloor \frac {av + b} r \rfloor</script><blockquote>
<ul>
<li>$v$：$n$ 维特征向量</li>
<li>$a = (X_1,X_2,\cdots,X_n)$：其中分量为独立同 <em>p-stable</em> 分布的随机变量</li>
<li>$b \in [0, r]$：均匀分布随机变量</li>
</ul>
</blockquote>
<h4 id="p-stable-哈希函数碰撞概率"><a href="#p-stable-哈希函数碰撞概率" class="headerlink" title="p-stable 哈希函数碰撞概率"></a><em>p-stable</em> 哈希函数碰撞概率</h4><blockquote>
<ul>
<li>考虑$|v_1 - v_2|_p = c$的两个样本碰撞概率</li>
</ul>
</blockquote>
<ul>
<li><p>显然，仅在 $|av<em>1 - av_2| \leq r$ 时，才存在合适的 $b$ 使得 $h</em>{a,b}(v<em>1) = h</em>{a,b}(v_2)$</p>
<ul>
<li>即两个样本碰撞，不失一般性可设 $av_1 \leq av_2$</li>
<li>此 $r$ 即代表局部敏感的 <strong>局部范围</strong></li>
</ul>
</li>
<li><p>若 $(k-1)r \leq av_1 \leq av_2 &lt; kr$，即两个样本与 $a$ 内积在同一分段内</p>
<ul>
<li>易得满足条件的 $b \in [0,kr-av_2) \cup [kr-av_1, r]$</li>
<li>即随机变量 $b$ 取值合适的概率为 $1 - \frac {av_2 - av_1} r$</li>
</ul>
</li>
<li><p>若 $(k-1)r \leq av_1 \leq kr \leq av_2$，即两个样本 $a$ 在相邻分段内</p>
<ul>
<li>易得满足条件的 $b \in [kr-av_1, (k+1)r-av_2)$</li>
<li>即随机变量 $b$ 取值合适的概率同样为 $1 - \frac {av_2 - av_1} r$</li>
</ul>
</li>
<li><p>考虑 $av_2 - av_1$ 分布为 $cX$，则两样本碰撞概率为</p>
<script type="math/tex; mode=display">\begin{align*}
p(c)  & = Pr_{a,b}(h_{a,b}(v_1) = h_{a,b}(v_2)) \\
& = \int_0^r \frac 1 c f_p(\frac t c)(1 - \frac t r)dt
\end{align*}</script><blockquote>
<ul>
<li>$c = |v_1 - v_2|_p$：特征向量之间$L_p$范数距离</li>
<li>$t = a(v_1 - v_2)$</li>
<li>$f$：p稳定分布的概率密度函数</li>
</ul>
</blockquote>
<ul>
<li><p>$p=1$ 柯西分布</p>
<script type="math/tex; mode=display">
p(c) = 2 \frac {tan^{-1}(r/c)} \pi - \frac 1 {\pi(r/c)} ln(1 + (r/c)^2)</script></li>
<li><p>$p=2$ 正态分布</p>
<script type="math/tex; mode=display">
p(c) = 1 - 2norm(-r/c) - \frac 2 {\sqrt{2\pi} r/c} (1 - e^{-(r^2/2c^2)})</script></li>
</ul>
</li>
</ul>
<h4 id="性质、实现"><a href="#性质、实现" class="headerlink" title="性质、实现"></a>性质、实现</h4><h5 id="限制近邻碰撞概率"><a href="#限制近邻碰撞概率" class="headerlink" title="限制近邻碰撞概率"></a>限制近邻碰撞概率</h5><ul>
<li><p>$r$ 最优值取决于数据集、查询点</p>
<ul>
<li>根据文献，建议$r = 4$</li>
</ul>
</li>
<li><p>若要求近邻 $v \in B(q,R)$以不小于$1-\sigma$ 概率碰撞，则有</p>
<script type="math/tex; mode=display">\begin{align*}
1 - (1 - p(R)^k)^L & \geq 1 - \sigma \\
\Rightarrow L & \geq \frac {log \sigma} {log(1 - p(R)^k)}
\end{align*}</script><p>则可取</p>
<script type="math/tex; mode=display">
L = \lceil \frac {log \sigma} {log(1-p(R)^k)} \rceil</script></li>
<li><p>$k$ 最优值是使得 $T_g + T_c$ 最小者</p>
<ul>
<li>$T_g = O(dkL)$：建表时间复杂度</li>
<li>$T_c = O(d |collisions|)$：精确搜索时间复杂度</li>
<li>$T_g$、$T_c$ 随着 $k$ 增大而增大、减小</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>具体实现参考<a target="_blank" rel="noopener" href="https://www.mit.edu/~andoni/LSH/manual.pdf">https://www.mit.edu/~andoni/LSH/manual.pdf</a></li>
</ul>
</blockquote>
<h5 id="限制搜索空间"><a href="#限制搜索空间" class="headerlink" title="限制搜索空间"></a>限制搜索空间</h5><ul>
<li><p>哈希表数量 $L$ 较多时，所有碰撞样本数量可能非常大，考虑只选择 $3L$ 个样本点</p>
</li>
<li><p>此时每个哈希键位长 $k$、哈希表数量 $L$ 保证以下条件，则算法正确</p>
<ul>
<li>若存在 $v^{ <em> }$ 距离待检索点 $q$ 距离小于 $r_1$，则存在 $g_j(v^{ </em> }) = g_j(q)$</li>
<li><p>与 $q$ 距离大于 $r_2$、可能和 $q$ 碰撞的点的数量小于 $3L$</p>
<script type="math/tex; mode=display">
\sum_{j=1}^L |(P-B(q,r_2)) \cap g_j^{-1}(g_j(q))|
  < 3L</script></li>
</ul>
</li>
<li><p>可以证明，$k, L$ 取以下值时，以上两个条件以常数概率成立
（此性质是局部敏感函数性质，不要求是 $E^2LSH$）</p>
<script type="math/tex; mode=display">\begin{align*}
k & = log_{1/p_2} n\\
L & = n^{\rho} \\
\rho & = \frac {ln 1/p_1} {ln 1/p_2}
\end{align*}</script></li>
<li><p>$\rho$ 对算法效率起决定性作用，且有以下定理</p>
<blockquote>
<ul>
<li>距离尺度 $D$ 下，若 $H$ 为 $(R,cR,p<em>1,p_2)$-敏感哈希函数族，则存在适合 <em>(R,c)-NN</em> 的算法，其空间复杂度为 $O(dn + n^{1+\rho})$、查询时间为 $O(n^{\rho})$ 倍距离计算、哈希函数计算为 $O(n^{\rho} log</em>{1/p_2}n)$， 其中 $\rho = \frac {ln 1/p_1} {ln 1/p_2}$</li>
</ul>
</blockquote>
<ul>
<li>$r$ 足够大、充分远离 0 时，$\rho$ 对其不是很敏感</li>
<li>$p<em>1, p_2$ 随 $r$ 增大而增大，而 $k = log</em>{1/p_2} n$ 也随之增大，所以 $r$ 不能取过大值</li>
</ul>
</li>
</ul>
<h4 id="Scalable-LSH"><a href="#Scalable-LSH" class="headerlink" title="Scalable LSH"></a><em>Scalable LSH</em></h4><p><em>Scalable LSH</em>：可扩展的 <em>LSH</em></p>
<ul>
<li><p>对动态变化的数据集，固定哈希编码的局部敏感哈希方法对数据 <strong>动态支持性有限</strong>，无法很好的适应数据集动态变化</p>
<ul>
<li>受限于初始数据集分布特性，无法持续保证有效性</li>
<li>虽然在原理上支持数据集动态变化，但若数据集大小发生较大变化，则其相应哈希参数（如哈希编码长度）等需要随之调整，需要从新索引整个数据库</li>
</ul>
</li>
<li><p>在 $E^2LSH$ 基础上通过 <strong>动态增强哈希键长</strong>，增强哈希函数区分能力，实现可扩展 <em>LSH</em></p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-14T12:04:44.000Z" title="7/14/2019, 8:04:44 PM">2019-07-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T03:32:19.000Z" title="8/4/2021, 11:32:19 AM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/Math-Mixin/">Math Mixin</a><span> / </span><a class="link-muted" href="/categories/Math-Mixin/Statistics/">Statistics</a></span><span class="level-item">13 minutes read (About 2022 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Math-Mixin/Statistics/stat_evaluation.html">常用统计量</a></h1><div class="content"><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><ul>
<li>对比实际类别值、预测类别值，编制混淆矩阵</li>
<li>基于混淆矩阵，计算各类错判率、总错判率（总错判率会受到数据不平衡性的影响）</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>真实情况\预测结果</th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td>正例</td>
<td><em>TP</em>（真正例）</td>
<td><em>FN</em>（假反例）</td>
</tr>
<tr>
<td>反例</td>
<td><em>FP</em>（假正例）</td>
<td><em>TN</em>（真反例）</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/imgs/confusion_matrix.png" alt="confusion_matrix"></p>
<h3 id="F-Measure"><a href="#F-Measure" class="headerlink" title="F-Measure"></a><em>F-Measure</em></h3><p><em>F-测度</em>：准率率和召回率综合值，越大越好</p>
<script type="math/tex; mode=display">
F-measure = \frac {(\beta^2 + 1) * P * R} {\beta^2 * P + R}</script><blockquote>
<ul>
<li>$P = \frac {TP} {TP+FP}$：查准率、精确率</li>
<li>$R = \frac {TP} {TP+FN}$：查全率、召回率、覆盖率</li>
</ul>
</blockquote>
<h4 id="F1-值"><a href="#F1-值" class="headerlink" title="F1 值"></a><em>F1</em> 值</h4><p><em>F1值</em>：$\beta=1$ 时的 <em>F测度</em></p>
<script type="math/tex; mode=display">\begin{align*}
\frac {1} {F_{1}} &= \frac {1} {2} \left( \frac {1} {P} + \frac {1} {R} \right) \\
\Rightarrow F_{1} &= \frac {2 * P * R} {P + R} = \frac {2 * TP} {样例总数 + TP - TN}
\end{align*}</script><h3 id="TPR、FPR"><a href="#TPR、FPR" class="headerlink" title="TPR、FPR"></a><em>TPR</em>、<em>FPR</em></h3><ul>
<li><p><em>TPR</em>、<em>FPR</em> 可视为对 <em>TP</em>、<em>FP</em> 用样本数量归一化的结果</p>
<ul>
<li>样本全体中正、负样本数量往往差距很大，直接比较 <em>TP</em>、<em>FP</em> 不合理</li>
<li>考虑使用样本正、负数量归一化，即计算正比例 <em>TPR</em>、负比例 <em>FPR</em></li>
</ul>
</li>
<li><p><em>TPR</em> 越高越好，<em>FPR</em> 越低越好，但是这两个指标相互制约，两者同时增加、减小</p>
<ul>
<li>模型倾向于将样本 <strong>判定为</strong> 为正例，则 <em>TP</em>、<em>FP</em> 同时增加，<em>TPR</em>、<em>FPR</em> 同时变大</li>
<li>即模型取不同阈值，会产生正相关的 <em>TPR</em>、<em>FPR</em> 的点列</li>
</ul>
</li>
</ul>
<h3 id="Recevier-Operating-Characteristic-Curve"><a href="#Recevier-Operating-Characteristic-Curve" class="headerlink" title="Recevier Operating Characteristic Curve"></a><em>Recevier Operating Characteristic Curve</em></h3><p><em>ROC</em> 曲线：不同 <strong>正样本概率</strong> 划分阈值下 <em>TPR</em>、<em>FPR</em> 绘制的折线/曲线</p>
<script type="math/tex; mode=display">
TPR = \frac {TP} {TP+FN} \\
FPR = \frac {FP} {FP+TN}</script><ul>
<li><p><em>ROC</em> 曲线即以 <em>FPR</em> 为横坐标、<em>TPR</em> 为正坐标绘制曲线</p>
<ul>
<li><em>FPR</em> 接近 1 时，<em>TPR</em> 也接近 1，这是不可避免的</li>
<li>而 <em>FPR</em> 接近 0 时，<em>TPR</em> 越大越好</li>
<li>所以模型 <em>ROC</em> 曲线下方面积越大，模型判断正确效果越好</li>
</ul>
</li>
<li><p>理解</p>
<ul>
<li>将正负样本的正样本概率值分别绘制在 <code>x=1</code>、<code>x=-1</code> 两条直线上</li>
<li>阈值即为 <code>y=threshold</code> 直线</li>
<li><em>TPR</em>、<em>FPR</em> 则为 <code>x=1</code>、<code>x=-1</code> 两条直线在阈值直线上方点数量，与各直线上所有点数量比值</li>
</ul>
</li>
</ul>
<h3 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a><em>Accuracy</em></h3><p>准确率、误分率：评价分类器性能一般指标</p>
<script type="math/tex; mode=display">\begin{align*}
acc & = \frac 1 N sign(y_i = \hat y_i) \\
& = \frac {TP+TN} N \\
mis & = 1 - acc
\end{align*}</script><blockquote>
<ul>
<li>$y_i$：第 $i$ 样本实际类别</li>
<li>$\hat y_i$：第 $i$ 样本预测类别</li>
<li>$N$：样本数量</li>
</ul>
</blockquote>
<ul>
<li>对给定测试集，分类器正确分类样本数与总样本数比值</li>
<li>即 <em>0-1</em> 损失函数时经验风险</li>
</ul>
<h3 id="Top-PR"><a href="#Top-PR" class="headerlink" title="Top PR"></a><em>Top PR</em></h3><p>头部准召：评估模型头部性能</p>
<script type="math/tex; mode=display">
pr_{top} = \frac {TP_{top}} {TOP}</script><blockquote>
<ul>
<li>$TOP$：指定的头部数量</li>
<li>$TP_{top}$：头部中正例数量（正例指已知原 $TOP$ 样本）</li>
</ul>
</blockquote>
<h2 id="Area-Under-Curve"><a href="#Area-Under-Curve" class="headerlink" title="Area Under Curve"></a><em>Area Under Curve</em></h2><p><em>AUC</em> 值：<em>ROC</em> 曲线下方面积，越大越好</p>
<ul>
<li><p><em>AUC</em> 值实际含义：随机抽取一对正、负样本，对其中正样本的正样本预测概率值、大于负样本的正样本预测概率值的概率</p>
<ul>
<li>$=1$：完美预测，存在一个阈值可以让模型 <em>TPR</em> 为 1，<em>FPR</em> 为 0</li>
<li>$(0.5, 1)$ ：优于随机预测，至少存在某个阈值，模型 $TPR &gt; FPR$</li>
<li>$=0.5$：同随机预测，无价值</li>
<li>$[0, 0.5)$：差于随机预测，但是可以反向取预测值</li>
</ul>
</li>
</ul>
<h3 id="AUC-计算"><a href="#AUC-计算" class="headerlink" title="AUC 计算"></a><em>AUC</em> 计算</h3><ul>
<li><p>绘制 <em>ROC</em> 曲线，计算曲线下面积</p>
<ul>
<li>给定一系列阈值（最精确时为样本数量），分别计算 <em>TPR</em>、<em>FPR</em></li>
<li>根据 <em>TPR</em>、<em>FPR</em> 计算 <em>AUC</em></li>
</ul>
</li>
<li><p>正负样本分别配对，计算正样本预测概率大于负样本比例</p>
<script type="math/tex; mode=display">\begin{align*}
auc & = \frac {\sum I(P_P > P_N)} {M * N} \\
I(P_P, P_N) & = \left \{ \begin{array}{l}
   1, & P_P > P_N, \\
   0.5, & P_P = P_N, \\
   0, & P_P < P_N
\end{array} \right.
\end{align*}</script><blockquote>
<ul>
<li>$M, N$：正、负样本数量</li>
</ul>
</blockquote>
</li>
<li><p><em>Mann-Witney U</em> 检验：即正、负样本分别配对的简化公式</p>
<script type="math/tex; mode=display">
auc = \frac {\sum_{i \in Pos} rank(i) - \frac {M * (M+1)} 2} {M * N}</script><blockquote>
<ul>
<li>$Pos$：正样本集合</li>
<li>$rank(i)$：样本 $i$ 的按正样本概率排序的秩（对正样本概率值相同样本，应将秩加和求平均保证其秩相等）</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="Weighted-AUC"><a href="#Weighted-AUC" class="headerlink" title="Weighted-AUC"></a><em>Weighted-AUC</em></h3><p><em>WAUC</em>：给 <strong>每个样本</strong> 赋权，计算统计量时考虑样本权重</p>
<ul>
<li><p><em>FPR</em>、<em>TPR</em> 绘图</p>
<script type="math/tex; mode=display">\begin{align*}
WTPR & = \frac {\sum_{i \in Pos} w_i I(\hat y_i=1)}
   {\sum_{i \in Pos} w_i} \\
WFPR & = \frac {\sum_{j \in Neg} w_j I(\hat y_j=1)}
   {\sum_{j \in Neg} w_j}
\end{align*}</script><blockquote>
<ul>
<li>$WTPR, WFPR$：加权 <em>TPR</em>、加权 <em>FPR</em></li>
<li>$\hat y_i$：样本预测类别</li>
<li>$w_i$：样本权重</li>
</ul>
</blockquote>
</li>
<li><p><em>Mann-Witney U</em> 检验：考虑其意义，带入权重即可得</p>
<script type="math/tex; mode=display">\begin{align*}
auc = \frac {\sum_{i \in Pos} w_i * rank(i) -
   \sum_{i \in Pos} w_i * rank_{pos}(i)}
   {\sum_{i \in Pos} w_i * \sum_{j \in Neg} w_j}
\end{align*}</script><blockquote>
<ul>
<li>$rank_{pos}(i)$：正样本内部排序，样本$i$秩</li>
<li>$Neg$：负样本集合</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="多分类-AUC"><a href="#多分类-AUC" class="headerlink" title="多分类 AUC"></a>多分类 <em>AUC</em></h3><ul>
<li><p><em>Micro-AUC</em>：将每个类别视为样本标签，计算全体样本的正标签、负标签的 <em>AUC</em></p>
<ul>
<li>$n$ 个样本的 $m$ 维标签展平， 则其中有 $n$ 个正样本、$n * (m-1)$ 个负样本</li>
<li>$n$ 个样本的 $m$ 个分类器共 $n * m$ 个得分展平</li>
<li>使用以上预测得分、标签计算 <em>AUC</em></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># one-vs-rest分类器得分</span></span><br><span class="line">y_score = classifer.transform(X_test)</span><br><span class="line"><span class="comment"># 展平后计算fpr、tpr</span></span><br><span class="line">fpr_micro, tpr_micro, threshhold_micro = \</span><br><span class="line">	skilearn.metrics.roc_curve(y_test.ravel(), y_score.ravel())</span><br><span class="line"><span class="comment"># 利用fpr、tpr计算auc</span></span><br><span class="line">auc_micro = skilearn.metrics.auc(fpr_micro, tpr_micro)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等价于直接调用</span></span><br><span class="line">auc_micro = skilearn.metrics.roc_auc_score(y_test, y_score, average=<span class="string">&quot;micro&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><em>Macro-AUC</em>：对各类别，分别以计算 <em>ROC</em> 曲线（即 <em>TPR</em>、<em>FPR</em>），计算平均 <em>ROC</em> 曲线得到 <em>AUC</em></p>
<ul>
<li>对各类别分别计算 <em>TPR</em>、<em>FPR</em>，共 $m$ 组 <em>TPR</em>、<em>FPR</em></li>
<li><p>平均合并 <em>TPR</em>、<em>FPR</em>，计算 <em>AUC</em></p>
<ul>
<li><p>方法1：合并 <em>FPR</em>、去除重复值，使用 $m$ 组 <em>TPR</em>、<em>FPR</em> 分别求合并后 <em>FPR</em> 插值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分别计算各类别fpr、tpr</span></span><br><span class="line">fprs, tprs = [<span class="number">0</span>] * n_classes, [<span class="number">0</span>] * n_classes</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">	fprs[idx], tprs[idx], _ = sklearn.metrics.ruc_curve(</span><br><span class="line">		y_test[:, i], y_score[:, i])</span><br><span class="line"><span class="comment"># 合并fpr</span></span><br><span class="line">all_fpr = np.unique(np.concatenate(fprs))</span><br><span class="line">mean_tpr = np.zeros_like(all_fpr)</span><br><span class="line"><span class="comment"># 计算合并后fpr插值</span></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">	mean_tpr += scipy.interp(all_fpr, fpr[idx], tpr[idx])</span><br><span class="line">mean_tpr /= n_classes</span><br><span class="line">auc_macro = sklearn.metrics.auc(all_fpr, mean_tpr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 但是和以下结果不同</span></span><br><span class="line">auc_macro = sklearn.metrics.roc_auc_score(fprs)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>以上分类器均为 <em>one-vs-rest</em> 分类器，$m$ 个类别则 $m$ 个分类器、每个样本 $m$ 个得分</li>
</ul>
</blockquote>
<h3 id="Kolmogorov-Smirnov-统计量"><a href="#Kolmogorov-Smirnov-统计量" class="headerlink" title="Kolmogorov-Smirnov 统计量"></a><em>Kolmogorov-Smirnov</em> 统计量</h3><p><em>KS</em> 值：刻画区分正负样本能力</p>
<script type="math/tex; mode=display">
KS = max \{|TPR - FPR|\}</script><ul>
<li><em>KS</em> 值体现 <strong>最理想情况</strong> 下，对正负样本区分能力<ul>
<li>即 <em>ROC</em> 曲线与 $TPR = FPR$ 直线的最远距离</li>
</ul>
</li>
</ul>
<h2 id="Squared-Error"><a href="#Squared-Error" class="headerlink" title="Squared Error"></a><em>Squared Error</em></h2><h3 id="Mean-Squared-Error"><a href="#Mean-Squared-Error" class="headerlink" title="Mean Squared Error"></a><em>Mean Squared Error</em></h3><p><em>MSE</em>：均方误差（偏差）</p>
<script type="math/tex; mode=display">
MSE = \frac 1 n \sum_{i=1}^{n} (y_{i} - \hat{y_{i}})^{2}</script><h4 id="Mean-Absolute-Error"><a href="#Mean-Absolute-Error" class="headerlink" title="Mean Absolute Error"></a><em>Mean Absolute Error</em></h4><p><em>MAE</em>：平均绝对误差</p>
<script type="math/tex; mode=display">
MAE = \frac 1 n \sum_{i=1}^n |y_i - \hat {y_i}|</script><h4 id="Mean-Absolute-Percentage-Error"><a href="#Mean-Absolute-Percentage-Error" class="headerlink" title="Mean Absolute Percentage Error"></a><em>Mean Absolute Percentage Error</em></h4><p><em>MAPE</em>：平均绝对百分比误差</p>
<script type="math/tex; mode=display">
MAPE = \frac 1 n \sum_{i=1}^n |\frac {y_i - \hat {y_i}} {y_i}|</script><h4 id="Symmetric-Mean-Absolute-Percentage-Error"><a href="#Symmetric-Mean-Absolute-Percentage-Error" class="headerlink" title="Symmetric Mean Absolute Percentage Error"></a><em>Symmetric Mean Absolute Percentage Error</em></h4><p><em>SMAPE</em>：对称平均绝对百分比误差</p>
<script type="math/tex; mode=display">
MAPE = \frac 1 n \sum_{i=1}^n |\frac {y_i - \hat {y_i}} {(|y_i| + |\hat {y_i}|) / 2}|</script><h3 id="R-2"><a href="#R-2" class="headerlink" title="$R^2$"></a>$R^2$</h3><script type="math/tex; mode=display">\begin{align*}
R^2 & = 1 - \frac {SSE} {SST} = \frac {SSR} {SST} \\
R^2_{adj} & = 1 - \frac {1 - R^2} {n - p - 1}
\end{align*}</script><blockquote>
<ul>
<li>$n, p$：样本量、特征数量</li>
<li>$SSE$：残差平方和</li>
<li>$SSR$：回归平方和、组内平方和</li>
<li>$SST$：离差平方和</li>
<li>$R^2_{adj}$：调整的$R^2$</li>
</ul>
</blockquote>
<h3 id="Akaike-Information-Criterion"><a href="#Akaike-Information-Criterion" class="headerlink" title="Akaike Information Criterion"></a><em>Akaike Information Criterion</em></h3><p><em>AIC</em> ：赤池信息准则</p>
<script type="math/tex; mode=display">\begin{align*}
AIC & = -2log(L(\hat \theta, x)) + 2p \\
& = nln(SSE/n) + 2p
\end{align*}</script><blockquote>
<ul>
<li>$n, p$：样本量、特征数量</li>
<li>$\theta$：带估参数</li>
<li>$L(\theta, x)$：似然函数</li>
<li>$SSE$：残差平方和</li>
</ul>
</blockquote>
<h3 id="Bayesian-Information-Criterion"><a href="#Bayesian-Information-Criterion" class="headerlink" title="Bayesian Information Criterion"></a><em>Bayesian Information Criterion</em></h3><p><em>BIC</em>：贝叶斯信息准则</p>
<script type="math/tex; mode=display">\begin{align*}
BIC & = -2log(L(\hat \theta, x)) + ln(n)p \\
& = nln(SSE/n) + ln(n)p
\end{align*}</script><h3 id="C-p"><a href="#C-p" class="headerlink" title="$C_p$"></a>$C_p$</h3><script type="math/tex; mode=display">\begin{align*}
C_p & = \frac {SSE} {\hat {\sigma^2}} - n + 2p \\
& = (n - m - 1) \frac {SSE_p} {SSE_m} - n + 2p
\end{align*}</script><blockquote>
<ul>
<li>$p$：选模型特征子集中特征数量</li>
<li>$m$：所有特征数量</li>
<li>$SSE_p$：选模型中残差平方和</li>
<li>$SSE_m$：全模型中残差平方和</li>
</ul>
</blockquote>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/tags/Math/page/2/">Previous</a></div><div class="pagination-next"><a href="/tags/Math/page/4/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/tags/Math/">1</a></li><li><a class="pagination-link" href="/tags/Math/page/2/">2</a></li><li><a class="pagination-link is-current" href="/tags/Math/page/3/">3</a></li><li><a class="pagination-link" href="/tags/Math/page/4/">4</a></li><li><a class="pagination-link" href="/tags/Math/page/5/">5</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="pub-5385776267343559" data-ad-slot="6995841235" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="https://api.follow.it/subscription-form/WWxwMVBsOUtoNTdMSlJ4Z1lWVnRISERsd2t6ek9MeVpEUWs0YldlZGxUdXlKdDNmMEZVV1hWaFZFYWFSNmFKL25penZodWx3UzRiaVkxcnREWCtOYUJhZWhNbWpzaUdyc1hPangycUh5RTVjRXFnZnFGdVdSTzZvVzJBcTJHKzl8aXpDK1ROWWl4N080YkFEK3QvbEVWNEJuQjFqdWdxODZQcGNoM1NqbERXST0=/8" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="UBeaRLy" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>