<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: Loss - Hexo</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="UBeaRLy&#039;s Proxy"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="UBeaRLy&#039;s Proxy"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Hexo"><meta property="og:url" content="https://xyy15926.github.io/"><meta property="og:site_name" content="Hexo"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xyy15926.github.io/img/og_image.png"><meta property="article:author" content="UBeaRLy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xyy15926.github.io"},"headline":"Hexo","image":["https://xyy15926.github.io/img/og_image.png"],"author":{"@type":"Person","name":"UBeaRLy"},"publisher":{"@type":"Organization","name":"Hexo","logo":{"@type":"ImageObject","url":"https://xyy15926.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/darcula.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="ca-pub-5385776267343559" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Hexo" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li><a href="/categories/ML-Theory/">ML Theory</a></li><li class="is-active"><a href="#" aria-current="page">Loss</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-08-25T13:53:20.000Z" title="8/25/2019, 9:53:20 PM">2019-08-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T09:40:21.000Z" title="8/4/2021, 5:40:21 PM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Loss/">Loss</a></span><span class="level-item">21 minutes read (About 3154 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Loss/loss_thoery.html">损失函数理论</a></h1><div class="content"><h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><ul>
<li><p>矩估计：<strong>建立参数和总体矩的关系</strong>，求解参数</p>
<ul>
<li>除非参数本身即为样本矩，否则基本无应用价值</li>
<li>应用场合<ul>
<li>均值：对应二次损失 $\arg\min<em>{\mu} \sum</em>{i=1}^N (x_i - \mu)^2$</li>
<li>方差：对应二次损失?</li>
</ul>
</li>
</ul>
</li>
<li><p>极大似然估计：极大化似然函数，求解概率上最合理参数</p>
<ul>
<li>需知道（假设）总体 <strong>概率分布形式</strong></li>
<li>似然函数形式复杂，求解困难<ul>
<li>往往无法直接给出参数的解析解，只能求数值解</li>
</ul>
</li>
<li>应用场合<ul>
<li>估计回归参数：对数损失
$\mathop{\arg\min}<em>{\beta} \sum</em>{i=1}^N lnP(y_i|x_i, \beta)$</li>
</ul>
</li>
</ul>
</li>
<li><p>损失函数估计：极小化损失函数，求解损失最小的参数</p>
<ul>
<li>最泛用的参数求解方法<ul>
<li>适合求解有大量参数的待求解的问题</li>
<li>往往通过迭代方式逐步求解</li>
</ul>
</li>
<li>特别的<ul>
<li>线性回归使用 <em>MSE</em> 作为损失函数时，也被称为最小二乘估计</li>
<li>极大似然估计同对数损失函数</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>参数估计都可以找到合适损失函数，通过迭代求解损失最小化</li>
</ul>
</blockquote>
<h3 id="随机模拟估计参数"><a href="#随机模拟估计参数" class="headerlink" title="随机模拟估计参数"></a>随机模拟估计参数</h3><ul>
<li>需要<strong>设计随机模拟实验</strong>估计参数</li>
<li>应用场合<ul>
<li>蒙特卡洛类似算法：随机化损失</li>
</ul>
</li>
</ul>
<h3 id="迭代求解参数"><a href="#迭代求解参数" class="headerlink" title="迭代求解参数"></a>迭代求解参数</h3><ul>
<li><p>损失函数定义不同</p>
<ul>
<li>包含样本量数量不同</li>
<li>惩罚项设置不同</li>
</ul>
</li>
<li><p>异步更新参数</p>
<ul>
<li>同时求解参数数量：全部、部分、单个</li>
<li>参数升维</li>
</ul>
</li>
<li><p>更新方向</p>
<ul>
<li>梯度</li>
<li>海瑟矩阵</li>
<li>次梯度</li>
</ul>
</li>
<li><p>更新方式</p>
<ul>
<li>叠加惯性</li>
<li>动态学习率</li>
</ul>
</li>
</ul>
<h2 id="Loss-Models"><a href="#Loss-Models" class="headerlink" title="Loss Models"></a><em>Loss Models</em></h2><p>模型（目标函数）在样本整体的损失：度量模型整体预测效果</p>
<ul>
<li>代表模型在整体上的性质，有不同的设计形式</li>
<li><p>可以用于 <strong>设计学习策略、评价模型</strong></p>
<ul>
<li>风险函数</li>
<li>评价函数</li>
</ul>
</li>
<li><p>有时在算法中也会使用整体损失</p>
</li>
</ul>
<h3 id="Expected-Risk-Expected-Loss-Generalization-Loss"><a href="#Expected-Risk-Expected-Loss-Generalization-Loss" class="headerlink" title="Expected Risk / Expected Loss / Generalization Loss"></a><em>Expected Risk</em> / <em>Expected Loss</em> / <em>Generalization Loss</em></h3><p>期望风险（函数）：损失函数 $L(Y, f(X))$（随机变量）期望</p>
<script type="math/tex; mode=display">
R_{exp}(f) = E_p[L(Y, f(X))] = \int_{x*y} L(y,f(x))P(x,y) dxdy</script><blockquote>
<ul>
<li>$P(X, Y)$：随机变量 $(X, Y)$ 遵循的联合分布，未知</li>
</ul>
</blockquote>
<ul>
<li><p>风险函数值度量模型预测错误程度</p>
<ul>
<li>反映了学习方法的泛化能力</li>
<li>评价标准（<strong>监督学习目标</strong>）就应该是选择期望风险最小</li>
</ul>
</li>
<li><p>联合分布未知，所以才需要学习，否则可以直接计算条件分布概率，而计算期望损失需要知道联合分布，因此监督学习是一个病态问题</p>
</li>
</ul>
<h3 id="Empirical-Risk-Empirical-Loss"><a href="#Empirical-Risk-Empirical-Loss" class="headerlink" title="Empirical Risk / Empirical Loss"></a><em>Empirical Risk</em> / <em>Empirical Loss</em></h3><p>经验风险：模型关于给定训练数据集的平均损失</p>
<script type="math/tex; mode=display">\begin{align*}
R_{emp}(f) & = \sum_{i=1}^N D_i L(y_i, f(x_i;\theta)) \\
E(R_{emp}(f)) & = R_{exp}(f)
\end{align*}</script><blockquote>
<ul>
<li>$\theta$：模型参数</li>
<li>$D_i$：样本损失权重，常为 $\frac 1 N$，在 <em>Boosting</em> 框架中不同</li>
</ul>
</blockquote>
<ul>
<li><p>经验风险损失是模型 $f(x)$ 的函数</p>
<ul>
<li>训练时，模型是模型参数的函数</li>
<li>即其为模型参数函数</li>
</ul>
</li>
<li><p>根据大数定律，样本量容量 $N$ 趋于无穷时，$R<em>{emp}(f)$ 趋于 $R</em>{exp}(f)$</p>
<ul>
<li>但是现实中训练样本数目有限、很小</li>
<li>利用经验风险估计期望常常并不理想，需要对经验风险进行矫正</li>
</ul>
</li>
<li><p>例子</p>
<ul>
<li><em>maximum probability estimation</em>：极大似然估计<ul>
<li>模型：条件概率分布（贝叶斯生成模型、逻辑回归）</li>
<li>损失函数：对数损失函数</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Structual-Risk-Structual-Loss"><a href="#Structual-Risk-Structual-Loss" class="headerlink" title="Structual Risk / Structual Loss"></a><em>Structual Risk</em> / <em>Structual Loss</em></h3><p>结构风险：在经验风险上加上表示 <strong>模型复杂度</strong> 的 <em>regularizer</em>（<em>penalty term</em>）</p>
<script type="math/tex; mode=display">
R_{srm} = \frac 1 N \sum_{i=1}^N L(y_i, f(x_i)) +
    \lambda J(f)</script><blockquote>
<ul>
<li>$J(f)$：模型复杂度，定义在假设空间$F$上的泛函</li>
<li>$\lambda$：权衡经验风险、模型复杂度的系数</li>
</ul>
</blockquote>
<ul>
<li>结构风险最小化<ul>
<li>添加 <em>regularization</em>（正则化），调节损失函数（目标函数）</li>
</ul>
</li>
<li>模型复杂度 $J(f)$ 表示对复杂模型的惩罚：模型 $f$ 越复杂，复杂项 $J(f)$ 越大</li>
<li>案例<ul>
<li><em>maximum posterior probability estimation</em>：最大后验概率估计<ul>
<li>损失函数：对数损失函数</li>
<li>模型复杂度：模型先验概率对数后取负</li>
<li>先验概率对应模型复杂度，先验概率越小，复杂度越大</li>
</ul>
</li>
<li>岭回归：平方损失 + $L<em>2$ 正则化
$\mathop{\arg\min}</em>{\beta} \sum_{i=1}^N (y_i - f(x_i, \beta))^2 + |\beta|$</li>
<li><em>LASSO</em>：平方损失 + $L<em>1$ 正则化
$\mathop{\arg\min}</em>{\beta} \sum_{i=1}^N (y_i - f(x_i, \beta))^2 + |\beta|_1$</li>
</ul>
</li>
</ul>
<h2 id="Generalization-Ability"><a href="#Generalization-Ability" class="headerlink" title="Generalization Ability"></a><em>Generalization Ability</em></h2><p>泛化能力：方法学习到的模型对未知数据的预测能力，是学习方法本质、重要的性质</p>
<ul>
<li>测试误差衡量学习方法的泛化能力不可靠，其依赖于测试集，而测试集有限</li>
<li>学习方法的泛化能力往往是通过研究泛化误差的概率上界进行</li>
</ul>
<h3 id="Generalization-Error-Bound"><a href="#Generalization-Error-Bound" class="headerlink" title="Generalization Error Bound"></a>Generalization Error Bound</h3><p>泛化误差上界：泛化误差的 <strong>概率</strong> 上界</p>
<ul>
<li>是样本容量函数，样本容量增加时，泛化上界趋于 0</li>
<li>是假设空间容量函数，假设空间容量越大，模型越难学习，泛化误差上界越大</li>
</ul>
<h4 id="泛化误差"><a href="#泛化误差" class="headerlink" title="泛化误差"></a>泛化误差</h4><ul>
<li><p>根据 <em>Hoeffding</em> 不等式，泛化误差满足</p>
<script type="math/tex; mode=display">\begin{align*}
& \forall h \in H, & P(|E(h) - \hat E(h)| \geq \epsilon) \leq 2 e^{-2 N \epsilon^2} \\
\Rightarrow & \forall h \in H, & P(|E(h) - \hat E(h)|
   \leq \epsilon) \geq 1 - 2|H|e^{-2N\epsilon^2}
\end{align*}</script><blockquote>
<ul>
<li>$H$：假设空间</li>
<li>$N$：样本数量</li>
<li>$E(h) := R_{exp}(h)$</li>
<li>$\hat E(h) := R_{emp}(h)$</li>
</ul>
</blockquote>
</li>
<li><p>证明如下：</p>
<script type="math/tex; mode=display">\begin{align*}
P(\forall h \in H: |E(h) - \hat E(h)| \leq \epsilon|)
   & = 1 - P(\exists h \in H: |E(h) - \hat E(h)|
   \geq \epsilon) \\
& = 1 - P((|E(h_1) - \hat E(h_1) \geq \epsilon) \vee \cdots
   \vee (|E(h_{|H|}) - \hat E_{|H|}| \geq \epsilon)) \\
& \geq 1 - \sum_{i=1}^{|H|} P(|E(h_i) - \hat E(h_i)|
   \geq \epsilon) \\
& \geq 1 - 2|H|e^{-2N \epsilon^2}
\end{align*}</script></li>
<li><p>对任意 $\epsilon$，随样本数量 $m$ 增大， $|E(h) - \hat E(h)| \leq \epsilon$ 概率增大，可以使用经验误差近似泛化误差</p>
</li>
</ul>
<h4 id="二分类泛化误差上界"><a href="#二分类泛化误差上界" class="headerlink" title="二分类泛化误差上界"></a>二分类泛化误差上界</h4><ul>
<li><p>由 <em>Hoeffding</em> 不等式</p>
<script type="math/tex; mode=display">\begin{align*}
P(E(h) - \hat E(h) & \geq \epsilon) \leq exp(-2N\epsilon^2) \\
P(\exists h \in H: E(h) - \hat E(h) \geq \epsilon) & =
   P(\bigcup_{h \in H} \{ E(h) - \hat E(h) \geq \epsilon \}) \\
& \leq \sum_{h \in H} P(E(h) - \hat E(h) \geq \epsilon) \\
& \leq |H| exp(-2 N \epsilon^2)
\end{align*}</script></li>
<li><p>则 $\forall h \in H$，有</p>
<script type="math/tex; mode=display">
P(E(h) - \hat E(h) < \epsilon) \geq 1 - |H| exp(-2 N \epsilon)</script><p>则令 $\sigma = |H| exp(-2N\epsilon^2)$，则至少以概率 $1-\sigma$ 满足如下，即得到泛化误差上界</p>
<script type="math/tex; mode=display">\begin{align*}
E(h)  & \leq \hat E(h) + \epsilon(|H|, N, \sigma) \\
\epsilon(|H|, N, \sigma) & = \sqrt
   {\frac 1 {2N} (log |H| + log \frac 1 {\sigma})}
\end{align*}</script></li>
</ul>
<h3 id="Probably-Approximate-Correct-可学习"><a href="#Probably-Approximate-Correct-可学习" class="headerlink" title="Probably Approximate Correct 可学习"></a><em>Probably Approximate Correct</em> 可学习</h3><p><em>PAC</em> 可学习：在短时间内利用少量（多项式级别）样本能够找到假设 $h^{‘}$，满足</p>
<script type="math/tex; mode=display">
P(E(h^{'}) \leq \epsilon) \geq 1 - \sigma, 0 < \epsilon, \sigma < 1</script><ul>
<li><p>即需要假设满足两个 <em>PAC</em> 辨识条件</p>
<ul>
<li>近似条件：泛化误差 $E(h^{‘})$ 足够小</li>
<li>可能正确：满足近似条件概率足够大</li>
</ul>
</li>
<li><p>同等条件下</p>
<ul>
<li>模型越复杂，泛化误差越大</li>
<li>满足条件的样本数量越大，模型泛化误差越小</li>
</ul>
</li>
<li><p><em>PAC</em> 学习理论关心能否从假设空间 $H$ 中学习到好的假设 $h$</p>
<ul>
<li>由以上泛化误差可得，取 $\sigma = 2|H|e^{-2N\epsilon^2}$，则样本量满足 $N = \frac {ln \frac {2|H|} \sigma} {2 \epsilon^2}$ 时，模型是 <em>PAC</em> 可学习的</li>
</ul>
</li>
</ul>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a><em>Regularization</em></h2><p>正则化：（向目标函数）添加额外信息以求解病态问题、避免过拟合</p>
<ul>
<li><p>常应用在机器学习、逆问题求解</p>
<ul>
<li>对模型（目标函数）复杂度惩罚</li>
<li>提高学习模型的泛化能力、避免过拟合</li>
<li>学习简单模型：稀疏模型、引入组结构</li>
</ul>
</li>
<li><p>有多种用途</p>
<ul>
<li>最小二乘也可以看作是简单的正则化</li>
<li>岭回归中的 $\mathcal{l_2}$ 范数</li>
</ul>
</li>
</ul>
<h3 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h3><p>模型复杂度：经常作为正则化项添加作为额外信息添加的，衡量模型复杂度方式有很多种</p>
<ul>
<li><p>函数光滑限制</p>
<ul>
<li>多项式最高次数</li>
</ul>
</li>
<li><p>向量空间范数</p>
<ul>
<li>$\mathcal{L_0} - norm$：参数个数</li>
<li>$\mathcal{L_1} - norm$：参数绝对值和</li>
<li>$\mathcal{L_2}$- norm$：参数平方和</li>
</ul>
</li>
</ul>
<h3 id="mathcal-L-0-norm"><a href="#mathcal-L-0-norm" class="headerlink" title="$\mathcal{L_0} - norm$"></a>$\mathcal{L_0} - norm$</h3><ul>
<li>$\mathcal{l_0} - norm$ 特点<ul>
<li>稀疏化约束</li>
<li>解 $\mathcal{L_0}$ 范数正则化是 <em>NP-hard</em> 问题</li>
</ul>
</li>
</ul>
<h3 id="mathcal-L-1-norm"><a href="#mathcal-L-1-norm" class="headerlink" title="$\mathcal{L_1} - norm$"></a>$\mathcal{L_1} - norm$</h3><ul>
<li><p>$\mathcal{L_1} - norm$ 特点</p>
<ul>
<li>$\mathcal{L_1}$ 范数可以通过凸松弛得到 $\mathcal{L_0}$ 的近似解</li>
<li>有时候出现解不唯一的情况</li>
<li>$\mathcal{L_1}$ 范数凸但不严格可导，可以使用依赖次梯度的方法求解极小化问题</li>
</ul>
</li>
<li><p>应用</p>
<ul>
<li><em>LASSO</em></li>
</ul>
</li>
<li><p>求解</p>
<ul>
<li><em>Proximal Method</em></li>
<li><em>LARS</em></li>
</ul>
</li>
</ul>
<h3 id="mathcal-L-2-norm"><a href="#mathcal-L-2-norm" class="headerlink" title="$\mathcal{L_2} - norm$"></a>$\mathcal{L_2} - norm$</h3><ul>
<li>$\mathcal{L_2} - norm$ 特点<ul>
<li>凸且严格可导，极小化问题有解析解</li>
</ul>
</li>
</ul>
<h3 id="mathcal-L-1-L-2"><a href="#mathcal-L-1-L-2" class="headerlink" title="$\mathcal{L_1 + L_2}$"></a>$\mathcal{L_1 + L_2}$</h3><ul>
<li><p>$\mathcal{L_1 + L_2}$ 特点</p>
<ul>
<li>有组效应，相关变量权重倾向于相同</li>
</ul>
</li>
<li><p>应用</p>
<ul>
<li><em>Elastic Net</em></li>
</ul>
</li>
</ul>
<h3 id="稀疏解产生"><a href="#稀疏解产生" class="headerlink" title="稀疏解产生"></a>稀疏解产生</h3><p>稀疏解：待估参数系数在某些分量上为 0</p>
<h4 id="mathcal-L-1-norm-稀疏解的产生"><a href="#mathcal-L-1-norm-稀疏解的产生" class="headerlink" title="$\mathcal{L_1} - norm$ 稀疏解的产生"></a>$\mathcal{L_1} - norm$ 稀疏解的产生</h4><blockquote>
<ul>
<li>$\mathcal{L_1}$ 范数在参数满足 <strong>一定条件</strong> 情况下，能对 <strong>平方损失</strong> 产生稀疏效果</li>
</ul>
</blockquote>
<ul>
<li><p>在 $[-1,1]$ 内 $y=|x|$ 导数大于 $y=x^2$（除 0 点）</p>
<ul>
<li>则特征在 0 点附近内变动时，为了取到极小值，参数必须始终为 0</li>
<li>高阶项在 0 点附近增加速度较慢，所以 $\mathcal{L_1} - norm$ 能产生稀疏解是很广泛的</li>
<li>$mathcal{L_1} - norm$ 前系数（权重）越大，能够容许高阶项增加的幅度越大，即压缩能力越强</li>
</ul>
</li>
<li><p>在 0 附近导数 “不小”，即导数在 0 点非 0</p>
<ul>
<li>对多项式正则化项<ul>
<li>$\mathcal{L_1} - norm$ 项对稀疏化解起决定性作用</li>
<li>其他项对稀疏解无帮助</li>
</ul>
</li>
<li>对“非多项式”正则化项<ul>
<li>$e^{|x|}-1$、$ln(|x|+1)$ 等在0点泰勒展开同样得到 $\mathcal{L_1} - norm$ 项</li>
<li>但是此类正则化项难以计算数值，不常用</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="mathcal-L-1-norm-稀疏解推广"><a href="#mathcal-L-1-norm-稀疏解推广" class="headerlink" title="$\mathcal{L_1} - norm$ 稀疏解推广"></a>$\mathcal{L_1} - norm$ 稀疏解推广</h4><ul>
<li><p>正负差异化：在正负设置权重不同的 $\mathcal{L_1}$，赋予在正负不同的压缩能力，甚至某侧完全不压缩</p>
</li>
<li><p>分段函数压缩：即只要保证在 0 点附近包含 $\mathcal{L_1}$ 用于产生稀疏解，远离 0 处可以设计为常数等不影响精确解的值</p>
<ul>
<li><p><em>Smoothly Clipped Absolute Deviation</em></p>
<script type="math/tex; mode=display">
R(x|\lambda, \gamma) = \left \{ \begin{array} {l}
  \lambda|x| \qquad & if |x| \leq \lambda \\
  \frac {2\gamma\lambda|x| - x^2 - {\lambda}^2 }
      {2(\gamma - 1)} &
      if \gamma< |x| <\gamma\lambda \\
  \frac { {\lambda}^2(\gamma+1)} 2 &
      if |x| \geq \gamma\lambda
\end{array} \right.</script></li>
<li><p><em>Derivate of SCAD</em></p>
<script type="math/tex; mode=display">
R(x; \lambda, \gamma) = \left \{ \begin{array} {l}
  \lambda \qquad & if |x| \leq \gamma \\
  \frac {\gamma\lambda - |x|} {\gamma - 1} &
      if \lambda < |x| < \gamma\lambda \\
  0 & if |x| \geq \gamma\lambda
\end{array} \right.</script></li>
<li><p><em>Minimax Concave Penalty</em></p>
<script type="math/tex; mode=display">
R_{\gamma}(x;\lambda) = \left \{ \begin{array} {l}
  \lambda|x| - \frac {x^2} {2\gamma} \qquad &
      if |x| \leq \gamma\lambda \\
  \frac 1 2 \gamma{\lambda}^2 &
      if |x| > \gamma\lambda
\end{array} \right.</script></li>
</ul>
</li>
<li><p>分指标：对不同指标动态设置 $\mathcal{L_0}$ 系数</p>
<ul>
<li><em>Adaptive Lasso</em>：$\lambda \sum_J w_jx_j$</li>
</ul>
</li>
</ul>
<h4 id="稀疏本质"><a href="#稀疏本质" class="headerlink" title="稀疏本质"></a>稀疏本质</h4><p>稀疏本质：极值、<strong>不光滑</strong>，即导数符号突然变化</p>
<ul>
<li><p>若某约束项导数符号突然变化、其余项在该点处导数为 0，为保证仍然取得极小值，解会聚集（极小）、疏远（极大）该点（类似坡的陡峭程度）</p>
<ul>
<li>即此类不光滑点会<strong>抑制解的变化</strong>，不光滑程度即导数变化幅度越大，抑制解变化能力越强，即吸引、排斥解能力越强</li>
<li>容易构造压缩至任意点的约束项</li>
<li>特殊的，不光滑点为 0 时，即得到稀疏解</li>
</ul>
</li>
<li><p>可以设置的多个极小不光滑点，使得解都在不连续集合中</p>
<ul>
<li>可以使用三角函数、锯齿函数等构造，但此类约束项要起效果，必然会使得目标函数非凸<ul>
<li>但是多变量场合，每个变量实际解只会在某个候选解附近，其邻域内仍然是凸的</li>
<li>且锯齿函数这样的突变非凸可能和凸函数具有相当的优秀性质</li>
</ul>
</li>
<li>当这些点均为整数时，这似乎可以近似求解 <strong>整数规划</strong></li>
</ul>
</li>
</ul>
<h2 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a><em>Early Stopping</em></h2><p><em>Early Stopping</em>：提前终止（训练）</p>
<ul>
<li><em>Early Stopping</em> 也可以被视为是 <em>regularizing on time</em><ul>
<li>迭代式训练随着迭代次数增加，往往会有学习复杂模型的倾向</li>
<li>对时间施加正则化，可以减小模型复杂度、提高泛化能力</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-08-02T15:17:39.000Z" title="8/2/2019, 11:17:39 PM">2019-08-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-04T08:41:29.000Z" title="8/4/2021, 4:41:29 PM">2021-08-04</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Loss/">Loss</a></span><span class="level-item">9 minutes read (About 1280 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Loss/model_evaluation.html">模型评估</a></h1><div class="content"><h2 id="评估方向"><a href="#评估方向" class="headerlink" title="评估方向"></a>评估方向</h2><h3 id="模型误差"><a href="#模型误差" class="headerlink" title="模型误差"></a>模型误差</h3><blockquote>
<ul>
<li>给定损失函数时，基于损失函数的误差显然评估学习方法的标准</li>
</ul>
</blockquote>
<ul>
<li>回归预测模型：模型误差主要使用 <em>MSE</em></li>
<li>分类预测模型：模型误差主要是分类错误率 <em>ERR=1-ACC</em></li>
</ul>
<blockquote>
<ul>
<li>模型训练时采用损失函数不一定是评估时使用的</li>
</ul>
</blockquote>
<h4 id="Training-Error"><a href="#Training-Error" class="headerlink" title="Training Error"></a><em>Training Error</em></h4><p>训练误差：模型在训练集上的误差，损失函数 $L(Y, F(X))$ 均值</p>
<script type="math/tex; mode=display">
e_{train} = R_{emp}(\hat f) = \frac 1 N \sum_{i=1}^N
    L(y_i, \hat {f(x_i)})</script><blockquote>
<ul>
<li>$\hat f$：学习到的模型</li>
<li>$N$：训练样本容量</li>
</ul>
</blockquote>
<ul>
<li>训练时采用的损失函数和评估时一致时，训练误差等于经验风险</li>
<li>训练误差对盘对给定问题是否容易学习是有意义的，但是本质上不重要<ul>
<li>模型训练本身就以最小化训练误差为标准，如：最小化 <em>MSE</em>、最大化预测准确率，一般偏低，不能作为模型预测误差的估计</li>
<li>训练误差随模型复杂度增加单调下降（不考虑模型中随机因素）</li>
</ul>
</li>
</ul>
<h4 id="Test-Error"><a href="#Test-Error" class="headerlink" title="Test Error"></a><em>Test Error</em></h4><p>测试误差：模型在测试集上的误差，损失函数 $L(Y, f(X))$ 均值</p>
<script type="math/tex; mode=display">
e_{test} = \frac 1 {N^{'}} \sum_{i=1}^{N^{'}}
    L(y_i,\hat {f(x_i)})</script><blockquote>
<ul>
<li>$\hat f$：学习到的模型</li>
<li>$N$：测试样本容量</li>
</ul>
</blockquote>
<ul>
<li><p>测试误差反映了学习方法对未知测试数据集的预测能力，是模型 <em>generalization ability</em> 的度量，可以作为模型误差估计</p>
</li>
<li><p>测试误差随模型复杂度增加呈U型</p>
<ul>
<li>偏差降低程度大于方差增加程度，测试误差降低</li>
<li>偏差降低程度小于方差增加程度，测试误差增大</li>
</ul>
</li>
<li>训练误差小但测试误差大表明模型过拟合，使测试误差最小的模型为理想模型</li>
</ul>
<h3 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h3><blockquote>
<ul>
<li><em>approximation error</em>：近似误差，模型偏差，代表模型对训练集的拟合程度</li>
<li><em>estimation error</em>：估计误差，模型方差，代表模型对训练集波动的稳健性</li>
</ul>
</blockquote>
<ul>
<li><p>模型复杂度越高</p>
<ul>
<li>低偏差：对训练集的拟合充分</li>
<li>高方差：模型紧跟特定数据点，受其影响较大，预测结果不稳定</li>
<li>远离真实关系，模型在来自同系统中其他尚未观测的数据集上预测误差大</li>
</ul>
</li>
<li><p>而训练集、测试集往往不完全相同</p>
<ul>
<li>复杂度较高的模型（过拟合）在测试集上往往由于其高方差效果不好，而建立模型最终目的是用于预测未知数据</li>
<li>所以要兼顾偏差和方差，通过不同建模策略，找到恰当模型，其复杂度不太大且误差在可接受的水平</li>
<li>使得模型更贴近真实关系，泛化能力较好</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>简单模型：低方差高偏差</li>
<li><p>复杂模型：低偏差高方差</p>
</li>
<li><p>模型复杂度衡量参<em>data_science/loss</em></p>
</li>
</ul>
</blockquote>
<h4 id="Over-Fitting"><a href="#Over-Fitting" class="headerlink" title="Over-Fitting"></a><em>Over-Fitting</em></h4><p>过拟合：学习时选择的所包含的模型复杂度大（参数过多），导致模型对已知数据预测很好，对未知数据预测效果很差</p>
<ul>
<li>若在假设空间中存在“真模型”，则选择的模型应该逼近真模型（参数个数相近）</li>
<li>一味追求对训练集的预测能力，复杂度往往会比“真模型”更高</li>
</ul>
<h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><ul>
<li>减少预测变量数量<ul>
<li>最优子集回归：选择合适评价函数（带罚）选择最优模型</li>
<li>验证集挑选模型：将训练集使用 <em>抽样技术</em> 分出部分作为 <em>validation set</em>，使用额外验证集挑选使得损失最小的模型</li>
<li>正则化（罚、结构化风险最小策略）<ul>
<li>岭回归：平方损失，$L_2$ 范数</li>
<li><em>LASSO</em>：绝对值损失，$L_1$ 范数</li>
<li><em>Elastic Net</em></li>
</ul>
</li>
</ul>
</li>
<li>减弱变量特化程度：仅适合迭代求参数的方法<ul>
<li><em>EarlyStop</em>：提前终止模型训练</li>
<li><em>Dropout</em>：每次训练部分神经元</li>
</ul>
</li>
</ul>
<h3 id="模型信息来源"><a href="#模型信息来源" class="headerlink" title="模型信息来源"></a>模型信息来源</h3><ul>
<li>训练数据包含信息</li>
<li>模型形成过程中提供的先验信息<ul>
<li>模型：采用特定内在结构（如深度学习不同网络结构）、条件假设、其他约束条件（正则项）</li>
<li>数据：调整、变换、扩展训练数据，让其展现更多、更有用的信息</li>
</ul>
</li>
</ul>
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><ul>
<li><p><em>Classification</em> 分类问题：输出变量$Y$为有限个离散变量</p>
<ul>
<li>混淆矩阵<ul>
<li><em>F-Measure</em></li>
<li><em>TPR</em>、<em>FPR</em></li>
</ul>
</li>
<li><em>ROC</em></li>
<li><em>AUC</em></li>
</ul>
</li>
<li><p><em>Tagging</em> 标注问题：输入 $X^{(1)}, X^{(2)}, \cdots, X^{(n)}$、输出 $Y^{(1)}, Y^{(2)}, \cdots, Y^{(n)}$ <strong>均为变量序列</strong></p>
<ul>
<li>类似分类问题</li>
</ul>
</li>
<li><p><em>Regression</em> 回归问题</p>
<ul>
<li><em>Squared Error</em><ul>
<li><em>MSE</em></li>
<li>$R^2$、$R^2_{Adj}$</li>
<li><em>AIC</em></li>
<li><em>BIC</em></li>
</ul>
</li>
<li><em>Absolute Error</em><ul>
<li><em>MAE</em></li>
<li><em>MAPE</em></li>
<li><em>SMAPE</em></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<ul>
<li>经验损失、结构损失总是能用作评价模型，但是意义不明确</li>
</ul>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-31T17:48:22.000Z" title="8/1/2019, 1:48:22 AM">2019-08-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-16T07:06:49.000Z" title="7/16/2021, 3:06:49 PM">2021-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/ML-Theory/">ML Theory</a><span> / </span><a class="link-muted" href="/categories/ML-Theory/Loss/">Loss</a></span><span class="level-item">9 minutes read (About 1379 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/ML-Theory/Loss/func_loss.html">Loss Function</a></h1><div class="content"><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><ul>
<li>损失函数可以视为<strong>模型与真实的距离</strong>的度量<ul>
<li>因此损失函数设计关键即，寻找可以代表模型与真实的距离的统计量</li>
<li>同时为求解方便，应该损失函数最好应满足导数存在</li>
</ul>
</li>
</ul>
<h3 id="Surrogate-Loss"><a href="#Surrogate-Loss" class="headerlink" title="Surrogate Loss"></a>Surrogate Loss</h3><p>代理损失函数：用优化方便的损失函数代替难以优化的损失函数，间接达到优化原损失函数的目标</p>
<ul>
<li>如 0-1 损失难以优化，考虑使用二次损失、交叉熵损失替代</li>
</ul>
<h3 id="损失函数设计"><a href="#损失函数设计" class="headerlink" title="损失函数设计"></a>损失函数设计</h3><ul>
<li><p>对有监督学习：<strong>真实</strong> 已知，可以直接设计损失函数</p>
</li>
<li><p>对无监督学习：<strong>真实</strong> 未知，需要给定 <strong>真实标准</strong></p>
<ul>
<li><em>NLP</em>：需要给出语言模型</li>
<li><em>EM</em> 算法：熵最大原理</li>
</ul>
</li>
</ul>
<h2 id="常用损失函数"><a href="#常用损失函数" class="headerlink" title="常用损失函数"></a>常用损失函数</h2><p><img src="/imgs/01_se_ce_hinge_loss.png" alt="01_se_ce_hinge_loss"></p>
<h3 id="0-1-Loss"><a href="#0-1-Loss" class="headerlink" title="0-1 Loss"></a>0-1 Loss</h3><script type="math/tex; mode=display">
L(y, f(x)) = \left \{ \begin{array}{l}
    1, & y \neq f(x) \\
    0, & y = f(x)
\end{array} \right.</script><ul>
<li><p>0-1 损失函数梯度要么为 0、要么不存在，无法通过梯度下降方法优化 0-1 损失</p>
</li>
<li><p>适用场合</p>
<ul>
<li>二分类：<em>Adaboost</em></li>
<li>多分类：<em>Adaboost.M1</em></li>
</ul>
</li>
</ul>
<h3 id="Quadratic-Squared-Error-Loss"><a href="#Quadratic-Squared-Error-Loss" class="headerlink" title="Quadratic / Squared Error Loss"></a><em>Quadratic</em> / <em>Squared Error Loss</em></h3><script type="math/tex; mode=display">
L(y, f(x)) = \frac 1 2 (y - f(x))^2</script><ul>
<li><p>平方错误损失函数可导，可以基于梯度下降算法优化损失函数</p>
</li>
<li><p>适用场合</p>
<ul>
<li>回归预测：线性回归</li>
<li>分类预测：0-1 二分类（根据预测得分、阈值划分）</li>
</ul>
</li>
</ul>
<h3 id="Logistic-SE"><a href="#Logistic-SE" class="headerlink" title="Logistic SE"></a><em>Logistic SE</em></h3><ul>
<li><p>平方损失用于二分类时存在如下问题（模型输出无限制）</p>
<ul>
<li>若模型对某样本非常确信为正例，给出大于1预测值</li>
<li>此时模型会进行不必要、开销较大的优化</li>
</ul>
</li>
<li><p>考虑对模型输出进行 <em>sigmoid</em> 变换后作为预测值，再应用平方错误损失函数</p>
<script type="math/tex; mode=display">
L(y, f(x)) = \frac 1 2 (y - \sigma(f(x)))^2</script><ul>
<li><em>Logistic SE</em> 损失函数曲线对 0-1 损失拟合优于平方损失</li>
<li>但负区间存在饱和问题，损失最大只有 0.5</li>
</ul>
</li>
</ul>
<h3 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a><em>Cross Entropy</em></h3><p>交叉熵损失</p>
<script type="math/tex; mode=display">\begin{align*}
L(y, f(x)) & = -ylog(f(x)) \\
& = - \sum_{k=1}^K y_k log f(x)_k
\end{align*}</script><blockquote>
<ul>
<li>$y$：样本实际值</li>
<li>$f(x)$：各类别预测概率</li>
<li>$K$：分类数目</li>
</ul>
</blockquote>
<ul>
<li><p>交叉熵损失综合二次损失、<em>logistic SE</em> 优势，以正样本为例</p>
<ul>
<li>预测值较大时：损失接近 0，避免无效优化</li>
<li>预测值较小时：损失偏导趋近于 -1，不会出现饱和现象</li>
</ul>
</li>
<li><p>$y$ 为 <em>one-hot</em> 编码时实际值时</p>
<ul>
<li>分类问题仅某分量为 1：此时交叉熵损失同对数损失（负对数极大似然函数）</li>
<li>标签问题则可有分量为 1</li>
</ul>
</li>
<li><p>适合场合</p>
<ul>
<li>多分类问题</li>
<li>标签问题</li>
</ul>
</li>
</ul>
<h3 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a><em>Hinge Loss</em></h3><script type="math/tex; mode=display">\begin{align*}
L(y, f(x)) & = [1 - yf(x)]_{+} \\
[z]_{+} & = \left \{ \begin{array}{l}
    z, & z > 0 \\
    0, & z \leq 0
\end{array} \right.
\end{align*}</script><blockquote>
<ul>
<li>$y \in {-1, +1}$</li>
</ul>
</blockquote>
<ul>
<li><p>合页损失函数：0-1 损失函数的上界，效果类似交叉熵损失函数</p>
<ul>
<li>要求分类不仅正确，还要求确信度足够高损失才为 0</li>
<li>即对学习有更高的要求</li>
</ul>
</li>
<li><p>适用场合</p>
<ul>
<li>二分类：线性支持向量机</li>
</ul>
</li>
</ul>
<h3 id="收敛速度对比"><a href="#收敛速度对比" class="headerlink" title="收敛速度对比"></a>收敛速度对比</h3><ul>
<li><p>指数激活函数时：相较于二次损失，收敛速度更快</p>
</li>
<li><p>二次损失对 $w$ 偏导</p>
<script type="math/tex; mode=display">
\frac {\partial L} {\partial w} = (\sigma(z) - y) \sigma^{'}(z) x</script><blockquote>
<ul>
<li>$\sigma$：<em>sigmoid</em>、<em>softmax</em> 激活函数</li>
<li>$z = wx + b$</li>
</ul>
</blockquote>
<ul>
<li>考虑到 <em>sigmoid</em> 函数输入值绝对值较大时，其导数较小</li>
<li>激活函数输入 $z=wx+b$ 较大时，$\sigma^{‘}(z)$ 较小，更新速率较慢</li>
</ul>
</li>
<li><p><em>Softmax</em> 激活函数时，交叉熵对 $w$ 偏导</p>
<script type="math/tex; mode=display">\begin{align*}
\frac {\partial L} {\partial w} & = -y\frac 1 {\sigma(z)}
   \sigma^{'}(z) x \\
& = y(\sigma(z) - 1)x
\end{align*}</script></li>
<li><p>特别的，对 <em>sigmoid</em> 二分类</p>
<script type="math/tex; mode=display">\begin{align*}
\frac {\partial L} {\partial w_j} & = -(\frac y {\sigma(z)}
   - \frac {(1-y)} {1-\sigma(z)}) \sigma^{'}(z) x \\
& = -\frac {\sigma^{'}(z) x} {\sigma(z)(1-\sigma(z))}
   (\sigma(z) - y) \\
& = x(\sigma(z) - y)
\end{align*}</script><ul>
<li>考虑 $y \in {(0,1), (1,0)}$、$w$ 有两组</li>
<li>带入一般形式多分类也可以得到二分类结果</li>
</ul>
</li>
</ul>
<h2 id="不常用损失函数"><a href="#不常用损失函数" class="headerlink" title="不常用损失函数"></a>不常用损失函数</h2><h3 id="Absolute-Loss"><a href="#Absolute-Loss" class="headerlink" title="Absolute Loss"></a><em>Absolute Loss</em></h3><p>绝对损失函数</p>
<script type="math/tex; mode=display">
L(y, f(x)) = |y-f(x)|</script><ul>
<li>适用场合<ul>
<li>回归预测</li>
</ul>
</li>
</ul>
<h3 id="Logarithmic-Loss"><a href="#Logarithmic-Loss" class="headerlink" title="Logarithmic Loss"></a><em>Logarithmic Loss</em></h3><p>对数损失函数（负对数极大似然损失函数）</p>
<script type="math/tex; mode=display">
L(y, P(y|x)) = -logP(y|x)</script><ul>
<li>适用场合<ul>
<li>多分类：贝叶斯生成模型、逻辑回归</li>
</ul>
</li>
</ul>
<h3 id="Exponential-Loss"><a href="#Exponential-Loss" class="headerlink" title="Exponential Loss"></a><em>Exponential Loss</em></h3><p>指数函数函数</p>
<script type="math/tex; mode=display">
L(y, f(x)) = exp\{-yf(x)\}</script><ul>
<li>适用场合<ul>
<li>二分类：前向分步算法</li>
</ul>
</li>
</ul>
<h3 id="Pseudo-Loss"><a href="#Pseudo-Loss" class="headerlink" title="Pseudo Loss"></a><em>Pseudo Loss</em></h3><p>伪损失：考虑个体损失 $(x_i, y_i)$ 如下，据此构造伪损失</p>
<ul>
<li>$h(x_i, y_i)=1, \sum h(x_i, y)=0$：完全正确预测</li>
<li>$h(x_i, y_i)=0, \sum h(x_i, y)=1$：完全错误预测</li>
<li>$h(x_i, y_i)=1/M$：随机预测（M为分类数目）</li>
</ul>
<script type="math/tex; mode=display">
L(y, f(x)) = \frac 1 2 \sum_{y^{(j)} \neq f(x)} w_j (1 - f(x, y) + f(x, y^{(j)}))</script><blockquote>
<ul>
<li>$w_j$：样本个体错误标签权重，对不同个体分布可不同</li>
<li>$f(x, y^{(j)})$：分类器将输入 $x$ 预测为第 $j$ 类 $y^{(j)}$ 的置信度</li>
</ul>
</blockquote>
<ul>
<li><p>伪损失函数考虑了预测 <strong>标签</strong> 的权重分布</p>
<ul>
<li>通过改变此分布，能够更明确的关注难以预测的个体标签，而不仅仅个体</li>
</ul>
</li>
<li><p>伪损失随着分类器预测准确率增加而减小</p>
<ul>
<li>分类器 $f$ 对所有可能类别输出置信度相同时，伪损失最大达到 0.5，此时就是随机预测</li>
<li>伪损失大于 0.5 时，应该将使用 $1-f$</li>
</ul>
</li>
<li><p>适用场景</p>
<ul>
<li>多分类：<em>Adaboost.M2</em></li>
</ul>
</li>
</ul>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Heuristic/"><span class="level-start"><span class="level-item">Heuristic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Issue/"><span class="level-start"><span class="level-item">Issue</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Problem/"><span class="level-start"><span class="level-item">Problem</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Algorithm/Specification/"><span class="level-start"><span class="level-item">Specification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">34</span></span></a><ul><li><a class="level is-mobile" href="/categories/C-C/Cppref/"><span class="level-start"><span class="level-item">Cppref</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/Cstd/"><span class="level-start"><span class="level-item">Cstd</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/MPI/"><span class="level-start"><span class="level-item">MPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/C-C/STL/"><span class="level-start"><span class="level-item">STL</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/CS/"><span class="level-start"><span class="level-item">CS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/CS/Character/"><span class="level-start"><span class="level-item">Character</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Parallel/"><span class="level-start"><span class="level-item">Parallel</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Program-Design/"><span class="level-start"><span class="level-item">Program Design</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/CS/Storage/"><span class="level-start"><span class="level-item">Storage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Daily-Life/"><span class="level-start"><span class="level-item">Daily Life</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Daily-Life/Maxism/"><span class="level-start"><span class="level-item">Maxism</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">27</span></span></a><ul><li><a class="level is-mobile" href="/categories/Database/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/SQL-DB/"><span class="level-start"><span class="level-item">SQL DB</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Database/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Bash-Programming/"><span class="level-start"><span class="level-item">Bash Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Configuration/"><span class="level-start"><span class="level-item">Configuration</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/File-System/"><span class="level-start"><span class="level-item">File System</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/IPC/"><span class="level-start"><span class="level-item">IPC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Process-Schedual/"><span class="level-start"><span class="level-item">Process Schedual</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Shell/"><span class="level-start"><span class="level-item">Shell</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Tool/Vi/"><span class="level-start"><span class="level-item">Vi</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Model/"><span class="level-start"><span class="level-item">ML Model</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Model/Linear-Model/"><span class="level-start"><span class="level-item">Linear Model</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Model-Component/"><span class="level-start"><span class="level-item">Model Component</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Nolinear-Model/"><span class="level-start"><span class="level-item">Nolinear Model</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Model/Unsupervised-Model/"><span class="level-start"><span class="level-item">Unsupervised Model</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/"><span class="level-start"><span class="level-item">ML Specification</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/"><span class="level-start"><span class="level-item">Click Through Rate</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/Click-Through-Rate/Recommandation-System/"><span class="level-start"><span class="level-item">Recommandation System</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Computer-Vision/"><span class="level-start"><span class="level-item">Computer Vision</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/"><span class="level-start"><span class="level-item">FinTech</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Specification/FinTech/Risk-Control/"><span class="level-start"><span class="level-item">Risk Control</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Specification/Graph-Analysis/"><span class="level-start"><span class="level-item">Graph Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Specification/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Technique/"><span class="level-start"><span class="level-item">ML Technique</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Technique/Feature-Engineering/"><span class="level-start"><span class="level-item">Feature Engineering</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Technique/Neural-Network/"><span class="level-start"><span class="level-item">Neural Network</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ML-Theory/"><span class="level-start"><span class="level-item">ML Theory</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/ML-Theory/Loss/"><span class="level-start"><span class="level-item">Loss</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Model-Enhencement/"><span class="level-start"><span class="level-item">Model Enhencement</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/ML-Theory/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Algebra/"><span class="level-start"><span class="level-item">Math Algebra</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Algebra/Linear-Algebra/"><span class="level-start"><span class="level-item">Linear Algebra</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Algebra/Universal-Algebra/"><span class="level-start"><span class="level-item">Universal Algebra</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Analysis/"><span class="level-start"><span class="level-item">Math Analysis</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Analysis/Fourier-Analysis/"><span class="level-start"><span class="level-item">Fourier Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Functional-Analysis/"><span class="level-start"><span class="level-item">Functional Analysis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Optimization/"><span class="level-start"><span class="level-item">Optimization</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Analysis/Real-Analysis/"><span class="level-start"><span class="level-item">Real Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math-Mixin/"><span class="level-start"><span class="level-item">Math Mixin</span></span><span class="level-end"><span class="level-item tag">18</span></span></a><ul><li><a class="level is-mobile" href="/categories/Math-Mixin/Statistics/"><span class="level-start"><span class="level-item">Statistics</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Math-Mixin/Time-Series/"><span class="level-start"><span class="level-item">Time Series</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Probability/"><span class="level-start"><span class="level-item">Probability</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">89</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Cookbook/"><span class="level-start"><span class="level-item">Cookbook</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Jupyter/"><span class="level-start"><span class="level-item">Jupyter</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Keras/"><span class="level-start"><span class="level-item">Keras</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3Ref/"><span class="level-start"><span class="level-item">Py3Ref</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Py3std/"><span class="level-start"><span class="level-item">Py3std</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pywin32/"><span class="level-start"><span class="level-item">Pywin32</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Readme/"><span class="level-start"><span class="level-item">Readme</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/TensorFlow/"><span class="level-start"><span class="level-item">TensorFlow</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Twists/"><span class="level-start"><span class="level-item">Twists</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/RLang/"><span class="level-start"><span class="level-item">RLang</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Set/"><span class="level-start"><span class="level-item">Set</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/"><span class="level-start"><span class="level-item">Tool</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/Tool/Editor/"><span class="level-start"><span class="level-item">Editor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Markup-Language/"><span class="level-start"><span class="level-item">Markup Language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Web-Browser/"><span class="level-start"><span class="level-item">Web Browser</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Tool/Windows/"><span class="level-start"><span class="level-item">Windows</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Web/CSS/"><span class="level-start"><span class="level-item">CSS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/NPM/"><span class="level-start"><span class="level-item">NPM</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Proxy/"><span class="level-start"><span class="level-item">Proxy</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Web/Thrift/"><span class="level-start"><span class="level-item">Thrift</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://octodex.github.com/images/hula_loop_octodex03.gif" alt="UBeaRLy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">UBeaRLy</p><p class="is-size-6 is-block">Protector of Proxy</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Earth, Solar System</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">392</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">93</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">522</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xyy15926" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xyy15926"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T15:07:54.896Z">2021-08-04</time></p><p class="title"><a href="/uncategorized/README.html"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T07:46:51.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/hexo_config.html">Hexo 建站</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-03T02:32:45.000Z">2021-08-03</time></p><p class="title"><a href="/Web/NPM/config.html">NPM 总述</a></p><p class="categories"><a href="/categories/Web/">Web</a> / <a href="/categories/Web/NPM/">NPM</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-02T08:11:11.000Z">2021-08-02</time></p><p class="title"><a href="/Python/Py3std/internet_data.html">互联网数据</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Py3std/">Py3std</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-29T13:55:00.000Z">2021-07-29</time></p><p class="title"><a href="/Linux/Shell/sh_apps.html">Shell 应用程序</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Shell/">Shell</a></p></div></article></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-5385776267343559" data-ad-slot="6371777973" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Hexo" height="28"></a><p class="is-size-7"><span>&copy; 2021 UBeaRLy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xyy15926/proxy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>